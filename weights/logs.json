[
    {
        "step": 15161,
        "tokens": 7948730368,
        "learning_rate": 0.0003402956590745824,
        "gradient_norm": 0.3110346794128418,
        "train_loss": 3.1035428047180176,
        "val_loss": 3.0762484073638916,
        "hellaswag_acc": 0.28211510181427,
        "hellaswag_acc_norm": 0.2914758026599884
    },
    {
        "step": 15162,
        "tokens": 7949254656,
        "learning_rate": 0.00034026703407644354,
        "gradient_norm": 0.2909014821052551,
        "train_loss": 3.1569530963897705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15163,
        "tokens": 7949778944,
        "learning_rate": 0.0003402384089627363,
        "gradient_norm": 0.34018194675445557,
        "train_loss": 3.0922250747680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15164,
        "tokens": 7950303232,
        "learning_rate": 0.0003402097837337832,
        "gradient_norm": 0.2874945104122162,
        "train_loss": 3.0673532485961914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15165,
        "tokens": 7950827520,
        "learning_rate": 0.00034018115838990617,
        "gradient_norm": 0.3265642523765564,
        "train_loss": 3.091482162475586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15166,
        "tokens": 7951351808,
        "learning_rate": 0.00034015253293142754,
        "gradient_norm": 0.29979005455970764,
        "train_loss": 3.0680434703826904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15167,
        "tokens": 7951876096,
        "learning_rate": 0.00034012390735866944,
        "gradient_norm": 0.31561145186424255,
        "train_loss": 3.1043055057525635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15168,
        "tokens": 7952400384,
        "learning_rate": 0.0003400952816719542,
        "gradient_norm": 0.3011340796947479,
        "train_loss": 3.0944995880126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15169,
        "tokens": 7952924672,
        "learning_rate": 0.0003400666558716039,
        "gradient_norm": 0.35048907995224,
        "train_loss": 3.131399154663086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15170,
        "tokens": 7953448960,
        "learning_rate": 0.0003400380299579409,
        "gradient_norm": 0.2832714319229126,
        "train_loss": 3.055121898651123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15171,
        "tokens": 7953973248,
        "learning_rate": 0.00034000940393128735,
        "gradient_norm": 0.3440222442150116,
        "train_loss": 3.1610894203186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15172,
        "tokens": 7954497536,
        "learning_rate": 0.00033998077779196547,
        "gradient_norm": 0.33468854427337646,
        "train_loss": 3.1394407749176025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15173,
        "tokens": 7955021824,
        "learning_rate": 0.00033995215154029754,
        "gradient_norm": 0.30571305751800537,
        "train_loss": 3.1163296699523926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15174,
        "tokens": 7955546112,
        "learning_rate": 0.00033992352517660566,
        "gradient_norm": 0.3299710154533386,
        "train_loss": 3.112006187438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15175,
        "tokens": 7956070400,
        "learning_rate": 0.0003398948987012122,
        "gradient_norm": 0.326352596282959,
        "train_loss": 3.144115447998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15176,
        "tokens": 7956594688,
        "learning_rate": 0.0003398662721144393,
        "gradient_norm": 0.3261159062385559,
        "train_loss": 3.1343541145324707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15177,
        "tokens": 7957118976,
        "learning_rate": 0.0003398376454166092,
        "gradient_norm": 0.3404512107372284,
        "train_loss": 3.149381160736084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15178,
        "tokens": 7957643264,
        "learning_rate": 0.00033980901860804414,
        "gradient_norm": 0.3104759752750397,
        "train_loss": 3.1069934368133545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15179,
        "tokens": 7958167552,
        "learning_rate": 0.0003397803916890664,
        "gradient_norm": 0.32926425337791443,
        "train_loss": 3.098222255706787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15180,
        "tokens": 7958691840,
        "learning_rate": 0.00033975176465999814,
        "gradient_norm": 0.3044302761554718,
        "train_loss": 3.0948541164398193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15181,
        "tokens": 7959216128,
        "learning_rate": 0.0003397231375211616,
        "gradient_norm": 0.33117300271987915,
        "train_loss": 3.070394992828369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15182,
        "tokens": 7959740416,
        "learning_rate": 0.000339694510272879,
        "gradient_norm": 0.3334874212741852,
        "train_loss": 3.107058525085449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15183,
        "tokens": 7960264704,
        "learning_rate": 0.00033966588291547257,
        "gradient_norm": 0.4287455677986145,
        "train_loss": 3.1130595207214355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15184,
        "tokens": 7960788992,
        "learning_rate": 0.00033963725544926466,
        "gradient_norm": 0.4001893997192383,
        "train_loss": 3.150773048400879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15185,
        "tokens": 7961313280,
        "learning_rate": 0.00033960862787457745,
        "gradient_norm": 0.34821245074272156,
        "train_loss": 3.0699539184570312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15186,
        "tokens": 7961837568,
        "learning_rate": 0.00033958000019173305,
        "gradient_norm": 0.3372342884540558,
        "train_loss": 3.0965161323547363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15187,
        "tokens": 7962361856,
        "learning_rate": 0.0003395513724010539,
        "gradient_norm": 0.33588606119155884,
        "train_loss": 3.120948314666748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15188,
        "tokens": 7962886144,
        "learning_rate": 0.00033952274450286206,
        "gradient_norm": 0.361654132604599,
        "train_loss": 3.096360206604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15189,
        "tokens": 7963410432,
        "learning_rate": 0.00033949411649747993,
        "gradient_norm": 0.28444185853004456,
        "train_loss": 3.098893642425537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15190,
        "tokens": 7963934720,
        "learning_rate": 0.0003394654883852296,
        "gradient_norm": 0.3349205553531647,
        "train_loss": 3.1144533157348633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15191,
        "tokens": 7964459008,
        "learning_rate": 0.0003394368601664335,
        "gradient_norm": 0.2802223861217499,
        "train_loss": 3.1339855194091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15192,
        "tokens": 7964983296,
        "learning_rate": 0.00033940823184141366,
        "gradient_norm": 0.3366372287273407,
        "train_loss": 3.071369171142578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15193,
        "tokens": 7965507584,
        "learning_rate": 0.00033937960341049253,
        "gradient_norm": 0.31099000573158264,
        "train_loss": 3.066039800643921,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15194,
        "tokens": 7966031872,
        "learning_rate": 0.0003393509748739923,
        "gradient_norm": 0.3140978217124939,
        "train_loss": 3.1129915714263916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15195,
        "tokens": 7966556160,
        "learning_rate": 0.0003393223462322351,
        "gradient_norm": 0.2947978973388672,
        "train_loss": 3.082585096359253,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15196,
        "tokens": 7967080448,
        "learning_rate": 0.0003392937174855433,
        "gradient_norm": 0.2878948152065277,
        "train_loss": 3.1344730854034424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15197,
        "tokens": 7967604736,
        "learning_rate": 0.0003392650886342392,
        "gradient_norm": 0.3147738575935364,
        "train_loss": 3.1475300788879395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15198,
        "tokens": 7968129024,
        "learning_rate": 0.00033923645967864495,
        "gradient_norm": 0.27805447578430176,
        "train_loss": 3.122745990753174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15199,
        "tokens": 7968653312,
        "learning_rate": 0.0003392078306190828,
        "gradient_norm": 0.3050709664821625,
        "train_loss": 3.118532419204712,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15200,
        "tokens": 7969177600,
        "learning_rate": 0.00033917920145587504,
        "gradient_norm": 0.2843673527240753,
        "train_loss": 3.117520332336426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15201,
        "tokens": 7969701888,
        "learning_rate": 0.0003391505721893439,
        "gradient_norm": 0.2852212190628052,
        "train_loss": 3.0901174545288086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15202,
        "tokens": 7970226176,
        "learning_rate": 0.0003391219428198117,
        "gradient_norm": 0.3048762083053589,
        "train_loss": 3.1295523643493652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15203,
        "tokens": 7970750464,
        "learning_rate": 0.0003390933133476007,
        "gradient_norm": 0.2664462625980377,
        "train_loss": 3.1051502227783203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15204,
        "tokens": 7971274752,
        "learning_rate": 0.000339064683773033,
        "gradient_norm": 0.3152540922164917,
        "train_loss": 3.11899995803833,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15205,
        "tokens": 7971799040,
        "learning_rate": 0.00033903605409643114,
        "gradient_norm": 0.28705403208732605,
        "train_loss": 3.09102201461792,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15206,
        "tokens": 7972323328,
        "learning_rate": 0.00033900742431811716,
        "gradient_norm": 0.31139451265335083,
        "train_loss": 3.196937084197998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15207,
        "tokens": 7972847616,
        "learning_rate": 0.00033897879443841336,
        "gradient_norm": 0.28720369935035706,
        "train_loss": 3.0721888542175293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15208,
        "tokens": 7973371904,
        "learning_rate": 0.00033895016445764203,
        "gradient_norm": 0.31911081075668335,
        "train_loss": 3.2080817222595215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15209,
        "tokens": 7973896192,
        "learning_rate": 0.0003389215343761255,
        "gradient_norm": 0.3952793776988983,
        "train_loss": 3.068985939025879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15210,
        "tokens": 7974420480,
        "learning_rate": 0.0003388929041941859,
        "gradient_norm": 0.3516595661640167,
        "train_loss": 3.104827404022217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15211,
        "tokens": 7974944768,
        "learning_rate": 0.00033886427391214565,
        "gradient_norm": 0.3345606327056885,
        "train_loss": 3.0730230808258057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15212,
        "tokens": 7975469056,
        "learning_rate": 0.0003388356435303269,
        "gradient_norm": 0.35178834199905396,
        "train_loss": 3.115382671356201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15213,
        "tokens": 7975993344,
        "learning_rate": 0.000338807013049052,
        "gradient_norm": 0.33738720417022705,
        "train_loss": 3.1277313232421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15214,
        "tokens": 7976517632,
        "learning_rate": 0.00033877838246864316,
        "gradient_norm": 0.3007920980453491,
        "train_loss": 3.114168405532837,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15215,
        "tokens": 7977041920,
        "learning_rate": 0.00033874975178942277,
        "gradient_norm": 0.31693634390830994,
        "train_loss": 3.1488654613494873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15216,
        "tokens": 7977566208,
        "learning_rate": 0.00033872112101171296,
        "gradient_norm": 0.2988033592700958,
        "train_loss": 3.0939829349517822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15217,
        "tokens": 7978090496,
        "learning_rate": 0.000338692490135836,
        "gradient_norm": 0.28582045435905457,
        "train_loss": 3.099405288696289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15218,
        "tokens": 7978614784,
        "learning_rate": 0.0003386638591621143,
        "gradient_norm": 0.32253000140190125,
        "train_loss": 3.070401906967163,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15219,
        "tokens": 7979139072,
        "learning_rate": 0.00033863522809087003,
        "gradient_norm": 0.3041906952857971,
        "train_loss": 3.087494373321533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15220,
        "tokens": 7979663360,
        "learning_rate": 0.0003386065969224256,
        "gradient_norm": 0.3147096037864685,
        "train_loss": 3.1272659301757812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15221,
        "tokens": 7980187648,
        "learning_rate": 0.0003385779656571031,
        "gradient_norm": 0.3175480365753174,
        "train_loss": 3.137331008911133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15222,
        "tokens": 7980711936,
        "learning_rate": 0.00033854933429522486,
        "gradient_norm": 0.373291015625,
        "train_loss": 3.2514874935150146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15223,
        "tokens": 7981236224,
        "learning_rate": 0.00033852070283711325,
        "gradient_norm": 0.38828980922698975,
        "train_loss": 3.069075107574463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15224,
        "tokens": 7981760512,
        "learning_rate": 0.00033849207128309057,
        "gradient_norm": 0.32933714985847473,
        "train_loss": 3.116710901260376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15225,
        "tokens": 7982284800,
        "learning_rate": 0.000338463439633479,
        "gradient_norm": 0.33212095499038696,
        "train_loss": 3.116513252258301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15226,
        "tokens": 7982809088,
        "learning_rate": 0.00033843480788860083,
        "gradient_norm": 0.33917608857154846,
        "train_loss": 3.100954294204712,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15227,
        "tokens": 7983333376,
        "learning_rate": 0.00033840617604877845,
        "gradient_norm": 0.3658008873462677,
        "train_loss": 3.1171116828918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15228,
        "tokens": 7983857664,
        "learning_rate": 0.000338377544114334,
        "gradient_norm": 0.35066068172454834,
        "train_loss": 3.11881160736084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15229,
        "tokens": 7984381952,
        "learning_rate": 0.0003383489120855899,
        "gradient_norm": 0.3623082935810089,
        "train_loss": 3.0815672874450684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15230,
        "tokens": 7984906240,
        "learning_rate": 0.00033832027996286845,
        "gradient_norm": 0.37446993589401245,
        "train_loss": 3.104987382888794,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15231,
        "tokens": 7985430528,
        "learning_rate": 0.0003382916477464918,
        "gradient_norm": 0.3493821918964386,
        "train_loss": 3.1252827644348145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15232,
        "tokens": 7985954816,
        "learning_rate": 0.00033826301543678233,
        "gradient_norm": 0.3478783667087555,
        "train_loss": 3.081676721572876,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15233,
        "tokens": 7986479104,
        "learning_rate": 0.00033823438303406234,
        "gradient_norm": 0.3165680170059204,
        "train_loss": 3.0503740310668945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15234,
        "tokens": 7987003392,
        "learning_rate": 0.000338205750538654,
        "gradient_norm": 0.3634053170681,
        "train_loss": 3.0515518188476562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15235,
        "tokens": 7987527680,
        "learning_rate": 0.00033817711795087986,
        "gradient_norm": 0.29312703013420105,
        "train_loss": 3.126894474029541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15236,
        "tokens": 7988051968,
        "learning_rate": 0.000338148485271062,
        "gradient_norm": 0.34316137433052063,
        "train_loss": 3.103531837463379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15237,
        "tokens": 7988576256,
        "learning_rate": 0.00033811985249952275,
        "gradient_norm": 0.306233674287796,
        "train_loss": 3.0814199447631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15238,
        "tokens": 7989100544,
        "learning_rate": 0.00033809121963658447,
        "gradient_norm": 0.30150920152664185,
        "train_loss": 3.1254403591156006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15239,
        "tokens": 7989624832,
        "learning_rate": 0.00033806258668256947,
        "gradient_norm": 0.30802199244499207,
        "train_loss": 3.108011484146118,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15240,
        "tokens": 7990149120,
        "learning_rate": 0.0003380339536377999,
        "gradient_norm": 0.29055607318878174,
        "train_loss": 3.1988537311553955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15241,
        "tokens": 7990673408,
        "learning_rate": 0.00033800532050259826,
        "gradient_norm": 0.3522915244102478,
        "train_loss": 3.0952792167663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15242,
        "tokens": 7991197696,
        "learning_rate": 0.0003379766872772867,
        "gradient_norm": 0.26961055397987366,
        "train_loss": 3.103100299835205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15243,
        "tokens": 7991721984,
        "learning_rate": 0.0003379480539621876,
        "gradient_norm": 0.3242338001728058,
        "train_loss": 3.088655471801758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15244,
        "tokens": 7992246272,
        "learning_rate": 0.00033791942055762323,
        "gradient_norm": 0.2832890748977661,
        "train_loss": 3.1030380725860596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15245,
        "tokens": 7992770560,
        "learning_rate": 0.000337890787063916,
        "gradient_norm": 0.341307133436203,
        "train_loss": 3.158036947250366,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15246,
        "tokens": 7993294848,
        "learning_rate": 0.000337862153481388,
        "gradient_norm": 0.2877214550971985,
        "train_loss": 3.09248423576355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15247,
        "tokens": 7993819136,
        "learning_rate": 0.00033783351981036175,
        "gradient_norm": 0.31753987073898315,
        "train_loss": 3.094825267791748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15248,
        "tokens": 7994343424,
        "learning_rate": 0.00033780488605115945,
        "gradient_norm": 0.3224203884601593,
        "train_loss": 3.112107515335083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15249,
        "tokens": 7994867712,
        "learning_rate": 0.0003377762522041034,
        "gradient_norm": 0.3221660554409027,
        "train_loss": 3.1365156173706055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15250,
        "tokens": 7995392000,
        "learning_rate": 0.000337747618269516,
        "gradient_norm": 0.30903348326683044,
        "train_loss": 3.1474714279174805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15251,
        "tokens": 7995916288,
        "learning_rate": 0.0003377189842477195,
        "gradient_norm": 0.31614255905151367,
        "train_loss": 3.1161279678344727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15252,
        "tokens": 7996440576,
        "learning_rate": 0.00033769035013903607,
        "gradient_norm": 0.3199191093444824,
        "train_loss": 3.112692356109619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15253,
        "tokens": 7996964864,
        "learning_rate": 0.00033766171594378825,
        "gradient_norm": 0.33540618419647217,
        "train_loss": 3.0675296783447266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15254,
        "tokens": 7997489152,
        "learning_rate": 0.00033763308166229823,
        "gradient_norm": 0.3695123791694641,
        "train_loss": 3.155179262161255,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15255,
        "tokens": 7998013440,
        "learning_rate": 0.00033760444729488844,
        "gradient_norm": 0.33070653676986694,
        "train_loss": 3.0804905891418457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15256,
        "tokens": 7998537728,
        "learning_rate": 0.0003375758128418811,
        "gradient_norm": 0.33281904458999634,
        "train_loss": 3.1053318977355957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15257,
        "tokens": 7999062016,
        "learning_rate": 0.00033754717830359856,
        "gradient_norm": 0.29169830679893494,
        "train_loss": 3.1085309982299805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15258,
        "tokens": 7999586304,
        "learning_rate": 0.0003375185436803631,
        "gradient_norm": 0.3432205319404602,
        "train_loss": 3.0796642303466797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15259,
        "tokens": 8000110592,
        "learning_rate": 0.000337489908972497,
        "gradient_norm": 0.3459024131298065,
        "train_loss": 3.110657215118408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15260,
        "tokens": 8000634880,
        "learning_rate": 0.0003374612741803227,
        "gradient_norm": 0.30037638545036316,
        "train_loss": 3.1416759490966797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15261,
        "tokens": 8001159168,
        "learning_rate": 0.00033743263930416243,
        "gradient_norm": 0.33537963032722473,
        "train_loss": 3.1223602294921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15262,
        "tokens": 8001683456,
        "learning_rate": 0.0003374040043443385,
        "gradient_norm": 0.2793135941028595,
        "train_loss": 3.1291985511779785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15263,
        "tokens": 8002207744,
        "learning_rate": 0.00033737536930117336,
        "gradient_norm": 0.31136980652809143,
        "train_loss": 3.044055461883545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15264,
        "tokens": 8002732032,
        "learning_rate": 0.00033734673417498923,
        "gradient_norm": 0.28739383816719055,
        "train_loss": 3.1276822090148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15265,
        "tokens": 8003256320,
        "learning_rate": 0.0003373180989661084,
        "gradient_norm": 0.2814570963382721,
        "train_loss": 3.0939674377441406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15266,
        "tokens": 8003780608,
        "learning_rate": 0.0003372894636748533,
        "gradient_norm": 0.3109213411808014,
        "train_loss": 3.057419776916504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15267,
        "tokens": 8004304896,
        "learning_rate": 0.00033726082830154615,
        "gradient_norm": 0.29987624287605286,
        "train_loss": 3.053061008453369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15268,
        "tokens": 8004829184,
        "learning_rate": 0.0003372321928465093,
        "gradient_norm": 0.28796663880348206,
        "train_loss": 3.118617534637451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15269,
        "tokens": 8005353472,
        "learning_rate": 0.0003372035573100652,
        "gradient_norm": 0.3207767903804779,
        "train_loss": 3.1493172645568848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15270,
        "tokens": 8005877760,
        "learning_rate": 0.000337174921692536,
        "gradient_norm": 0.2955422103404999,
        "train_loss": 3.0234580039978027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15271,
        "tokens": 8006402048,
        "learning_rate": 0.00033714628599424416,
        "gradient_norm": 0.3417680859565735,
        "train_loss": 3.11545467376709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15272,
        "tokens": 8006926336,
        "learning_rate": 0.0003371176502155119,
        "gradient_norm": 0.29900476336479187,
        "train_loss": 3.110264301300049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15273,
        "tokens": 8007450624,
        "learning_rate": 0.00033708901435666164,
        "gradient_norm": 0.3086017370223999,
        "train_loss": 3.1005940437316895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15274,
        "tokens": 8007974912,
        "learning_rate": 0.00033706037841801576,
        "gradient_norm": 0.2868609130382538,
        "train_loss": 3.099766254425049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15275,
        "tokens": 8008499200,
        "learning_rate": 0.00033703174239989645,
        "gradient_norm": 0.3238776922225952,
        "train_loss": 3.068035125732422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15276,
        "tokens": 8009023488,
        "learning_rate": 0.00033700310630262615,
        "gradient_norm": 0.2840365767478943,
        "train_loss": 3.123286247253418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15277,
        "tokens": 8009547776,
        "learning_rate": 0.00033697447012652715,
        "gradient_norm": 0.34841054677963257,
        "train_loss": 3.059152126312256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15278,
        "tokens": 8010072064,
        "learning_rate": 0.0003369458338719218,
        "gradient_norm": 0.27476176619529724,
        "train_loss": 3.079746961593628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15279,
        "tokens": 8010596352,
        "learning_rate": 0.0003369171975391324,
        "gradient_norm": 0.30653443932533264,
        "train_loss": 3.145379066467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15280,
        "tokens": 8011120640,
        "learning_rate": 0.0003368885611284814,
        "gradient_norm": 0.2850874662399292,
        "train_loss": 3.046753406524658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15281,
        "tokens": 8011644928,
        "learning_rate": 0.000336859924640291,
        "gradient_norm": 0.2912698984146118,
        "train_loss": 3.093550682067871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15282,
        "tokens": 8012169216,
        "learning_rate": 0.00033683128807488356,
        "gradient_norm": 0.312220960855484,
        "train_loss": 3.061800956726074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15283,
        "tokens": 8012693504,
        "learning_rate": 0.0003368026514325815,
        "gradient_norm": 0.31181710958480835,
        "train_loss": 3.1416664123535156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15284,
        "tokens": 8013217792,
        "learning_rate": 0.0003367740147137071,
        "gradient_norm": 0.32527807354927063,
        "train_loss": 3.121856451034546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15285,
        "tokens": 8013742080,
        "learning_rate": 0.00033674537791858277,
        "gradient_norm": 0.3277167081832886,
        "train_loss": 3.084266185760498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15286,
        "tokens": 8014266368,
        "learning_rate": 0.0003367167410475307,
        "gradient_norm": 0.3216552138328552,
        "train_loss": 3.112255096435547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15287,
        "tokens": 8014790656,
        "learning_rate": 0.00033668810410087346,
        "gradient_norm": 0.34314849972724915,
        "train_loss": 3.0832622051239014,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15288,
        "tokens": 8015314944,
        "learning_rate": 0.00033665946707893326,
        "gradient_norm": 0.34432798624038696,
        "train_loss": 3.085200786590576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15289,
        "tokens": 8015839232,
        "learning_rate": 0.00033663082998203236,
        "gradient_norm": 0.31896039843559265,
        "train_loss": 3.1067862510681152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15290,
        "tokens": 8016363520,
        "learning_rate": 0.00033660219281049324,
        "gradient_norm": 0.3579792082309723,
        "train_loss": 3.0841846466064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15291,
        "tokens": 8016887808,
        "learning_rate": 0.00033657355556463824,
        "gradient_norm": 0.3164311647415161,
        "train_loss": 3.0538480281829834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15292,
        "tokens": 8017412096,
        "learning_rate": 0.0003365449182447896,
        "gradient_norm": 0.32711780071258545,
        "train_loss": 3.1241402626037598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15293,
        "tokens": 8017936384,
        "learning_rate": 0.00033651628085126984,
        "gradient_norm": 0.32245975732803345,
        "train_loss": 3.072375535964966,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15294,
        "tokens": 8018460672,
        "learning_rate": 0.0003364876433844012,
        "gradient_norm": 0.32177361845970154,
        "train_loss": 3.1318697929382324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15295,
        "tokens": 8018984960,
        "learning_rate": 0.000336459005844506,
        "gradient_norm": 0.3193958103656769,
        "train_loss": 3.0307445526123047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15296,
        "tokens": 8019509248,
        "learning_rate": 0.00033643036823190664,
        "gradient_norm": 0.31787219643592834,
        "train_loss": 3.0960423946380615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15297,
        "tokens": 8020033536,
        "learning_rate": 0.00033640173054692553,
        "gradient_norm": 0.29434871673583984,
        "train_loss": 3.1426849365234375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15298,
        "tokens": 8020557824,
        "learning_rate": 0.00033637309278988493,
        "gradient_norm": 0.32953011989593506,
        "train_loss": 3.064774513244629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15299,
        "tokens": 8021082112,
        "learning_rate": 0.00033634445496110723,
        "gradient_norm": 0.28732970356941223,
        "train_loss": 3.1082522869110107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15300,
        "tokens": 8021606400,
        "learning_rate": 0.0003363158170609148,
        "gradient_norm": 0.2997782528400421,
        "train_loss": 3.1007626056671143,
        "val_loss": 3.0726609230041504,
        "hellaswag_acc": 0.2803226709365845,
        "hellaswag_acc_norm": 0.29107749462127686
    },
    {
        "step": 15301,
        "tokens": 8022130688,
        "learning_rate": 0.00033628717908962995,
        "gradient_norm": 0.2955686151981354,
        "train_loss": 3.133575439453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15302,
        "tokens": 8022654976,
        "learning_rate": 0.000336258541047575,
        "gradient_norm": 0.30512893199920654,
        "train_loss": 3.10494327545166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15303,
        "tokens": 8023179264,
        "learning_rate": 0.0003362299029350724,
        "gradient_norm": 0.2931418716907501,
        "train_loss": 3.0881662368774414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15304,
        "tokens": 8023703552,
        "learning_rate": 0.0003362012647524445,
        "gradient_norm": 0.2873494327068329,
        "train_loss": 3.1273789405822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15305,
        "tokens": 8024227840,
        "learning_rate": 0.0003361726265000137,
        "gradient_norm": 0.2932302951812744,
        "train_loss": 3.0882158279418945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15306,
        "tokens": 8024752128,
        "learning_rate": 0.00033614398817810224,
        "gradient_norm": 0.3266833424568176,
        "train_loss": 3.1584746837615967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15307,
        "tokens": 8025276416,
        "learning_rate": 0.00033611534978703257,
        "gradient_norm": 0.327010840177536,
        "train_loss": 3.196382522583008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15308,
        "tokens": 8025800704,
        "learning_rate": 0.00033608671132712696,
        "gradient_norm": 0.2897050380706787,
        "train_loss": 3.149207353591919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15309,
        "tokens": 8026324992,
        "learning_rate": 0.00033605807279870784,
        "gradient_norm": 0.34079569578170776,
        "train_loss": 3.1511757373809814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15310,
        "tokens": 8026849280,
        "learning_rate": 0.00033602943420209757,
        "gradient_norm": 0.3100281059741974,
        "train_loss": 3.093733549118042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15311,
        "tokens": 8027373568,
        "learning_rate": 0.0003360007955376185,
        "gradient_norm": 0.3202269375324249,
        "train_loss": 3.1075868606567383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15312,
        "tokens": 8027897856,
        "learning_rate": 0.00033597215680559295,
        "gradient_norm": 0.348984032869339,
        "train_loss": 3.07295823097229,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15313,
        "tokens": 8028422144,
        "learning_rate": 0.0003359435180063434,
        "gradient_norm": 0.3072529137134552,
        "train_loss": 3.12312912940979,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15314,
        "tokens": 8028946432,
        "learning_rate": 0.0003359148791401921,
        "gradient_norm": 0.34093451499938965,
        "train_loss": 3.096714735031128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15315,
        "tokens": 8029470720,
        "learning_rate": 0.0003358862402074615,
        "gradient_norm": 0.30532586574554443,
        "train_loss": 3.124948740005493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15316,
        "tokens": 8029995008,
        "learning_rate": 0.0003358576012084739,
        "gradient_norm": 0.3342145085334778,
        "train_loss": 3.134481906890869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15317,
        "tokens": 8030519296,
        "learning_rate": 0.0003358289621435517,
        "gradient_norm": 0.316863089799881,
        "train_loss": 3.1367921829223633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15318,
        "tokens": 8031043584,
        "learning_rate": 0.0003358003230130173,
        "gradient_norm": 0.32165029644966125,
        "train_loss": 3.1003808975219727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15319,
        "tokens": 8031567872,
        "learning_rate": 0.00033577168381719304,
        "gradient_norm": 0.31696775555610657,
        "train_loss": 3.046598434448242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15320,
        "tokens": 8032092160,
        "learning_rate": 0.0003357430445564012,
        "gradient_norm": 0.2918691039085388,
        "train_loss": 3.1483209133148193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15321,
        "tokens": 8032616448,
        "learning_rate": 0.0003357144052309643,
        "gradient_norm": 0.3047002851963043,
        "train_loss": 3.0909423828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15322,
        "tokens": 8033140736,
        "learning_rate": 0.0003356857658412046,
        "gradient_norm": 0.2885085642337799,
        "train_loss": 3.0997865200042725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15323,
        "tokens": 8033665024,
        "learning_rate": 0.0003356571263874445,
        "gradient_norm": 0.2886572480201721,
        "train_loss": 3.0651297569274902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15324,
        "tokens": 8034189312,
        "learning_rate": 0.0003356284868700065,
        "gradient_norm": 0.3274001479148865,
        "train_loss": 3.1465811729431152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15325,
        "tokens": 8034713600,
        "learning_rate": 0.00033559984728921276,
        "gradient_norm": 0.26054564118385315,
        "train_loss": 3.0373239517211914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15326,
        "tokens": 8035237888,
        "learning_rate": 0.0003355712076453858,
        "gradient_norm": 0.32095545530319214,
        "train_loss": 3.1098031997680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15327,
        "tokens": 8035762176,
        "learning_rate": 0.000335542567938848,
        "gradient_norm": 0.27204471826553345,
        "train_loss": 3.1523258686065674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15328,
        "tokens": 8036286464,
        "learning_rate": 0.0003355139281699217,
        "gradient_norm": 0.2979492247104645,
        "train_loss": 3.067934989929199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15329,
        "tokens": 8036810752,
        "learning_rate": 0.0003354852883389292,
        "gradient_norm": 0.2997676134109497,
        "train_loss": 3.1249806880950928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15330,
        "tokens": 8037335040,
        "learning_rate": 0.00033545664844619294,
        "gradient_norm": 0.30614370107650757,
        "train_loss": 3.109137535095215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15331,
        "tokens": 8037859328,
        "learning_rate": 0.0003354280084920353,
        "gradient_norm": 0.29206016659736633,
        "train_loss": 3.097015857696533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15332,
        "tokens": 8038383616,
        "learning_rate": 0.0003353993684767786,
        "gradient_norm": 0.29885542392730713,
        "train_loss": 3.1297693252563477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15333,
        "tokens": 8038907904,
        "learning_rate": 0.0003353707284007454,
        "gradient_norm": 0.2843479514122009,
        "train_loss": 3.1108694076538086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15334,
        "tokens": 8039432192,
        "learning_rate": 0.0003353420882642579,
        "gradient_norm": 0.326196551322937,
        "train_loss": 3.169424533843994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15335,
        "tokens": 8039956480,
        "learning_rate": 0.00033531344806763855,
        "gradient_norm": 0.2880862355232239,
        "train_loss": 3.111417293548584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15336,
        "tokens": 8040480768,
        "learning_rate": 0.00033528480781120967,
        "gradient_norm": 0.3074468672275543,
        "train_loss": 3.1319453716278076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15337,
        "tokens": 8041005056,
        "learning_rate": 0.00033525616749529376,
        "gradient_norm": 0.29018858075141907,
        "train_loss": 3.0255160331726074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15338,
        "tokens": 8041529344,
        "learning_rate": 0.0003352275271202131,
        "gradient_norm": 0.32247379422187805,
        "train_loss": 3.0604286193847656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15339,
        "tokens": 8042053632,
        "learning_rate": 0.0003351988866862901,
        "gradient_norm": 0.28676638007164,
        "train_loss": 3.0946407318115234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15340,
        "tokens": 8042577920,
        "learning_rate": 0.0003351702461938472,
        "gradient_norm": 0.326343297958374,
        "train_loss": 3.1223597526550293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15341,
        "tokens": 8043102208,
        "learning_rate": 0.0003351416056432067,
        "gradient_norm": 0.3151206374168396,
        "train_loss": 3.1009488105773926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15342,
        "tokens": 8043626496,
        "learning_rate": 0.000335112965034691,
        "gradient_norm": 0.3101927638053894,
        "train_loss": 3.1490349769592285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15343,
        "tokens": 8044150784,
        "learning_rate": 0.0003350843243686225,
        "gradient_norm": 0.3221699297428131,
        "train_loss": 3.084890604019165,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15344,
        "tokens": 8044675072,
        "learning_rate": 0.00033505568364532363,
        "gradient_norm": 0.33238235116004944,
        "train_loss": 3.066035032272339,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15345,
        "tokens": 8045199360,
        "learning_rate": 0.00033502704286511673,
        "gradient_norm": 0.3080245554447174,
        "train_loss": 3.0479650497436523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15346,
        "tokens": 8045723648,
        "learning_rate": 0.00033499840202832424,
        "gradient_norm": 0.3130560517311096,
        "train_loss": 3.1099236011505127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15347,
        "tokens": 8046247936,
        "learning_rate": 0.00033496976113526843,
        "gradient_norm": 0.3332047164440155,
        "train_loss": 3.0774693489074707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15348,
        "tokens": 8046772224,
        "learning_rate": 0.00033494112018627175,
        "gradient_norm": 0.2979264557361603,
        "train_loss": 3.1357617378234863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15349,
        "tokens": 8047296512,
        "learning_rate": 0.0003349124791816567,
        "gradient_norm": 0.3520645201206207,
        "train_loss": 3.0975942611694336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15350,
        "tokens": 8047820800,
        "learning_rate": 0.00033488383812174547,
        "gradient_norm": 0.30045244097709656,
        "train_loss": 3.1174120903015137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15351,
        "tokens": 8048345088,
        "learning_rate": 0.00033485519700686054,
        "gradient_norm": 0.3342539370059967,
        "train_loss": 3.1513161659240723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15352,
        "tokens": 8048869376,
        "learning_rate": 0.0003348265558373244,
        "gradient_norm": 0.3092212677001953,
        "train_loss": 3.1102943420410156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15353,
        "tokens": 8049393664,
        "learning_rate": 0.0003347979146134593,
        "gradient_norm": 0.3340755105018616,
        "train_loss": 3.150115728378296,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15354,
        "tokens": 8049917952,
        "learning_rate": 0.00033476927333558773,
        "gradient_norm": 0.3381889760494232,
        "train_loss": 3.1195743083953857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15355,
        "tokens": 8050442240,
        "learning_rate": 0.00033474063200403205,
        "gradient_norm": 0.3198096454143524,
        "train_loss": 3.106678009033203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15356,
        "tokens": 8050966528,
        "learning_rate": 0.00033471199061911464,
        "gradient_norm": 0.3660908341407776,
        "train_loss": 3.1676788330078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15357,
        "tokens": 8051490816,
        "learning_rate": 0.00033468334918115785,
        "gradient_norm": 0.32504549622535706,
        "train_loss": 3.0657565593719482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15358,
        "tokens": 8052015104,
        "learning_rate": 0.0003346547076904842,
        "gradient_norm": 0.3221770226955414,
        "train_loss": 3.1921041011810303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15359,
        "tokens": 8052539392,
        "learning_rate": 0.0003346260661474159,
        "gradient_norm": 0.3271856904029846,
        "train_loss": 3.0879077911376953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15360,
        "tokens": 8053063680,
        "learning_rate": 0.0003345974245522756,
        "gradient_norm": 0.28952184319496155,
        "train_loss": 3.089679718017578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15361,
        "tokens": 8053587968,
        "learning_rate": 0.00033456878290538547,
        "gradient_norm": 0.328722208738327,
        "train_loss": 3.045994758605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15362,
        "tokens": 8054112256,
        "learning_rate": 0.000334540141207068,
        "gradient_norm": 0.27053725719451904,
        "train_loss": 3.116231918334961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15363,
        "tokens": 8054636544,
        "learning_rate": 0.0003345114994576456,
        "gradient_norm": 0.3224177360534668,
        "train_loss": 3.145197629928589,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15364,
        "tokens": 8055160832,
        "learning_rate": 0.00033448285765744066,
        "gradient_norm": 0.2881374955177307,
        "train_loss": 3.120539665222168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15365,
        "tokens": 8055685120,
        "learning_rate": 0.0003344542158067756,
        "gradient_norm": 0.34269583225250244,
        "train_loss": 3.154329299926758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15366,
        "tokens": 8056209408,
        "learning_rate": 0.0003344255739059727,
        "gradient_norm": 0.315600723028183,
        "train_loss": 3.1167516708374023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15367,
        "tokens": 8056733696,
        "learning_rate": 0.0003343969319553545,
        "gradient_norm": 0.32340940833091736,
        "train_loss": 3.095461368560791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15368,
        "tokens": 8057257984,
        "learning_rate": 0.0003343682899552434,
        "gradient_norm": 0.3231428861618042,
        "train_loss": 3.1031746864318848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15369,
        "tokens": 8057782272,
        "learning_rate": 0.00033433964790596164,
        "gradient_norm": 0.32083913683891296,
        "train_loss": 3.0897345542907715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15370,
        "tokens": 8058306560,
        "learning_rate": 0.00033431100580783176,
        "gradient_norm": 0.32037121057510376,
        "train_loss": 3.031569480895996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15371,
        "tokens": 8058830848,
        "learning_rate": 0.0003342823636611762,
        "gradient_norm": 0.3348386287689209,
        "train_loss": 3.118269443511963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15372,
        "tokens": 8059355136,
        "learning_rate": 0.00033425372146631726,
        "gradient_norm": 0.2936163544654846,
        "train_loss": 3.0629217624664307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15373,
        "tokens": 8059879424,
        "learning_rate": 0.00033422507922357736,
        "gradient_norm": 0.28677231073379517,
        "train_loss": 3.0596160888671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15374,
        "tokens": 8060403712,
        "learning_rate": 0.00033419643693327893,
        "gradient_norm": 0.2930864691734314,
        "train_loss": 3.1069984436035156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15375,
        "tokens": 8060928000,
        "learning_rate": 0.0003341677945957444,
        "gradient_norm": 0.31217122077941895,
        "train_loss": 3.155494213104248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15376,
        "tokens": 8061452288,
        "learning_rate": 0.0003341391522112962,
        "gradient_norm": 0.2851426899433136,
        "train_loss": 3.093757152557373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15377,
        "tokens": 8061976576,
        "learning_rate": 0.00033411050978025657,
        "gradient_norm": 0.339895635843277,
        "train_loss": 3.110877513885498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15378,
        "tokens": 8062500864,
        "learning_rate": 0.0003340818673029481,
        "gradient_norm": 0.3106703460216522,
        "train_loss": 3.0594234466552734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15379,
        "tokens": 8063025152,
        "learning_rate": 0.00033405322477969313,
        "gradient_norm": 0.34054896235466003,
        "train_loss": 3.121201515197754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15380,
        "tokens": 8063549440,
        "learning_rate": 0.00033402458221081405,
        "gradient_norm": 0.30852341651916504,
        "train_loss": 3.1296582221984863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15381,
        "tokens": 8064073728,
        "learning_rate": 0.0003339959395966332,
        "gradient_norm": 0.3275374472141266,
        "train_loss": 3.1225051879882812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15382,
        "tokens": 8064598016,
        "learning_rate": 0.00033396729693747315,
        "gradient_norm": 0.28539177775382996,
        "train_loss": 3.0951104164123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15383,
        "tokens": 8065122304,
        "learning_rate": 0.0003339386542336563,
        "gradient_norm": 0.3290731608867645,
        "train_loss": 3.085585117340088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15384,
        "tokens": 8065646592,
        "learning_rate": 0.00033391001148550486,
        "gradient_norm": 0.2870793342590332,
        "train_loss": 3.1460161209106445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15385,
        "tokens": 8066170880,
        "learning_rate": 0.0003338813686933414,
        "gradient_norm": 0.3523917496204376,
        "train_loss": 3.0948193073272705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15386,
        "tokens": 8066695168,
        "learning_rate": 0.0003338527258574883,
        "gradient_norm": 0.28855225443840027,
        "train_loss": 3.1111977100372314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15387,
        "tokens": 8067219456,
        "learning_rate": 0.000333824082978268,
        "gradient_norm": 0.3307308852672577,
        "train_loss": 3.1231279373168945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15388,
        "tokens": 8067743744,
        "learning_rate": 0.0003337954400560028,
        "gradient_norm": 0.29293614625930786,
        "train_loss": 3.1704001426696777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15389,
        "tokens": 8068268032,
        "learning_rate": 0.00033376679709101525,
        "gradient_norm": 0.3492126166820526,
        "train_loss": 3.1456761360168457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15390,
        "tokens": 8068792320,
        "learning_rate": 0.0003337381540836278,
        "gradient_norm": 0.2841205596923828,
        "train_loss": 3.064274787902832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15391,
        "tokens": 8069316608,
        "learning_rate": 0.00033370951103416265,
        "gradient_norm": 0.3014019727706909,
        "train_loss": 3.0647010803222656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15392,
        "tokens": 8069840896,
        "learning_rate": 0.00033368086794294233,
        "gradient_norm": 0.27573952078819275,
        "train_loss": 3.1005301475524902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15393,
        "tokens": 8070365184,
        "learning_rate": 0.00033365222481028924,
        "gradient_norm": 0.31438174843788147,
        "train_loss": 3.096045732498169,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15394,
        "tokens": 8070889472,
        "learning_rate": 0.0003336235816365259,
        "gradient_norm": 0.2890251576900482,
        "train_loss": 3.116513252258301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15395,
        "tokens": 8071413760,
        "learning_rate": 0.0003335949384219745,
        "gradient_norm": 0.2889237701892853,
        "train_loss": 3.0664761066436768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15396,
        "tokens": 8071938048,
        "learning_rate": 0.0003335662951669577,
        "gradient_norm": 0.28556501865386963,
        "train_loss": 3.0744495391845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15397,
        "tokens": 8072462336,
        "learning_rate": 0.0003335376518717977,
        "gradient_norm": 0.316946804523468,
        "train_loss": 3.117856979370117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15398,
        "tokens": 8072986624,
        "learning_rate": 0.0003335090085368171,
        "gradient_norm": 0.3012259900569916,
        "train_loss": 3.1709437370300293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15399,
        "tokens": 8073510912,
        "learning_rate": 0.0003334803651623383,
        "gradient_norm": 0.30461350083351135,
        "train_loss": 3.1288232803344727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15400,
        "tokens": 8074035200,
        "learning_rate": 0.0003334517217486835,
        "gradient_norm": 0.29868200421333313,
        "train_loss": 3.1413776874542236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15401,
        "tokens": 8074559488,
        "learning_rate": 0.0003334230782961753,
        "gradient_norm": 0.3255228102207184,
        "train_loss": 3.0726447105407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15402,
        "tokens": 8075083776,
        "learning_rate": 0.0003333944348051361,
        "gradient_norm": 0.306100457906723,
        "train_loss": 3.0428223609924316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15403,
        "tokens": 8075608064,
        "learning_rate": 0.00033336579127588836,
        "gradient_norm": 0.36443719267845154,
        "train_loss": 3.1788058280944824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15404,
        "tokens": 8076132352,
        "learning_rate": 0.00033333714770875436,
        "gradient_norm": 0.3038978576660156,
        "train_loss": 3.118142604827881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15405,
        "tokens": 8076656640,
        "learning_rate": 0.00033330850410405666,
        "gradient_norm": 0.3896782696247101,
        "train_loss": 3.1419105529785156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15406,
        "tokens": 8077180928,
        "learning_rate": 0.00033327986046211765,
        "gradient_norm": 0.3177175521850586,
        "train_loss": 3.101311445236206,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15407,
        "tokens": 8077705216,
        "learning_rate": 0.0003332512167832597,
        "gradient_norm": 0.41487398743629456,
        "train_loss": 3.0962471961975098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15408,
        "tokens": 8078229504,
        "learning_rate": 0.0003332225730678052,
        "gradient_norm": 0.31731128692626953,
        "train_loss": 3.099289655685425,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15409,
        "tokens": 8078753792,
        "learning_rate": 0.00033319392931607664,
        "gradient_norm": 0.32991787791252136,
        "train_loss": 3.111281394958496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15410,
        "tokens": 8079278080,
        "learning_rate": 0.00033316528552839646,
        "gradient_norm": 0.31302163004875183,
        "train_loss": 3.1060194969177246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15411,
        "tokens": 8079802368,
        "learning_rate": 0.00033313664170508695,
        "gradient_norm": 0.3083849549293518,
        "train_loss": 3.102302074432373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15412,
        "tokens": 8080326656,
        "learning_rate": 0.00033310799784647073,
        "gradient_norm": 0.2810806334018707,
        "train_loss": 3.094119071960449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15413,
        "tokens": 8080850944,
        "learning_rate": 0.00033307935395287007,
        "gradient_norm": 0.2847054898738861,
        "train_loss": 3.094604015350342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15414,
        "tokens": 8081375232,
        "learning_rate": 0.0003330507100246075,
        "gradient_norm": 0.27879106998443604,
        "train_loss": 3.104220390319824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15415,
        "tokens": 8081899520,
        "learning_rate": 0.00033302206606200535,
        "gradient_norm": 0.27659040689468384,
        "train_loss": 3.111264705657959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15416,
        "tokens": 8082423808,
        "learning_rate": 0.00033299342206538613,
        "gradient_norm": 0.2727591097354889,
        "train_loss": 3.1312613487243652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15417,
        "tokens": 8082948096,
        "learning_rate": 0.0003329647780350722,
        "gradient_norm": 0.29120099544525146,
        "train_loss": 3.1433136463165283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15418,
        "tokens": 8083472384,
        "learning_rate": 0.0003329361339713859,
        "gradient_norm": 0.30415213108062744,
        "train_loss": 3.0933661460876465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15419,
        "tokens": 8083996672,
        "learning_rate": 0.00033290748987464987,
        "gradient_norm": 0.3018726706504822,
        "train_loss": 3.116948366165161,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15420,
        "tokens": 8084520960,
        "learning_rate": 0.00033287884574518633,
        "gradient_norm": 0.2884630560874939,
        "train_loss": 3.1442880630493164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15421,
        "tokens": 8085045248,
        "learning_rate": 0.0003328502015833178,
        "gradient_norm": 0.28628718852996826,
        "train_loss": 3.13273024559021,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15422,
        "tokens": 8085569536,
        "learning_rate": 0.0003328215573893667,
        "gradient_norm": 0.2817147374153137,
        "train_loss": 3.092288017272949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15423,
        "tokens": 8086093824,
        "learning_rate": 0.00033279291316365547,
        "gradient_norm": 0.29237934947013855,
        "train_loss": 3.073146343231201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15424,
        "tokens": 8086618112,
        "learning_rate": 0.00033276426890650653,
        "gradient_norm": 0.30406638979911804,
        "train_loss": 3.0933070182800293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15425,
        "tokens": 8087142400,
        "learning_rate": 0.00033273562461824235,
        "gradient_norm": 0.29834336042404175,
        "train_loss": 3.081247329711914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15426,
        "tokens": 8087666688,
        "learning_rate": 0.00033270698029918525,
        "gradient_norm": 0.29475221037864685,
        "train_loss": 3.154193878173828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15427,
        "tokens": 8088190976,
        "learning_rate": 0.0003326783359496577,
        "gradient_norm": 0.3087981045246124,
        "train_loss": 3.118204355239868,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15428,
        "tokens": 8088715264,
        "learning_rate": 0.00033264969156998213,
        "gradient_norm": 0.3097371459007263,
        "train_loss": 3.086009979248047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15429,
        "tokens": 8089239552,
        "learning_rate": 0.00033262104716048105,
        "gradient_norm": 0.29844385385513306,
        "train_loss": 3.1187591552734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15430,
        "tokens": 8089763840,
        "learning_rate": 0.00033259240272147676,
        "gradient_norm": 0.31009724736213684,
        "train_loss": 3.0725955963134766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15431,
        "tokens": 8090288128,
        "learning_rate": 0.0003325637582532917,
        "gradient_norm": 0.2791065275669098,
        "train_loss": 3.096966028213501,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15432,
        "tokens": 8090812416,
        "learning_rate": 0.00033253511375624836,
        "gradient_norm": 0.30352455377578735,
        "train_loss": 3.106369972229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15433,
        "tokens": 8091336704,
        "learning_rate": 0.0003325064692306693,
        "gradient_norm": 0.27473101019859314,
        "train_loss": 3.0639829635620117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15434,
        "tokens": 8091860992,
        "learning_rate": 0.00033247782467687667,
        "gradient_norm": 0.29498857259750366,
        "train_loss": 3.08561372756958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15435,
        "tokens": 8092385280,
        "learning_rate": 0.00033244918009519306,
        "gradient_norm": 0.3167640268802643,
        "train_loss": 3.0593953132629395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15436,
        "tokens": 8092909568,
        "learning_rate": 0.00033242053548594085,
        "gradient_norm": 0.37294548749923706,
        "train_loss": 3.0216431617736816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15437,
        "tokens": 8093433856,
        "learning_rate": 0.0003323918908494426,
        "gradient_norm": 0.3515309691429138,
        "train_loss": 3.127939462661743,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15438,
        "tokens": 8093958144,
        "learning_rate": 0.0003323632461860205,
        "gradient_norm": 0.3534432649612427,
        "train_loss": 3.155412197113037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15439,
        "tokens": 8094482432,
        "learning_rate": 0.0003323346014959972,
        "gradient_norm": 0.33784863352775574,
        "train_loss": 3.114863872528076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15440,
        "tokens": 8095006720,
        "learning_rate": 0.00033230595677969505,
        "gradient_norm": 0.31822261214256287,
        "train_loss": 3.055633544921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15441,
        "tokens": 8095531008,
        "learning_rate": 0.0003322773120374365,
        "gradient_norm": 0.3086976408958435,
        "train_loss": 3.113905906677246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15442,
        "tokens": 8096055296,
        "learning_rate": 0.00033224866726954387,
        "gradient_norm": 0.3730148375034332,
        "train_loss": 3.142310380935669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15443,
        "tokens": 8096579584,
        "learning_rate": 0.0003322200224763398,
        "gradient_norm": 0.3581947684288025,
        "train_loss": 3.1494617462158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15444,
        "tokens": 8097103872,
        "learning_rate": 0.00033219137765814653,
        "gradient_norm": 0.3061777651309967,
        "train_loss": 3.12174654006958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15445,
        "tokens": 8097628160,
        "learning_rate": 0.00033216273281528664,
        "gradient_norm": 0.3178941309452057,
        "train_loss": 3.039422035217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15446,
        "tokens": 8098152448,
        "learning_rate": 0.0003321340879480824,
        "gradient_norm": 0.3270883560180664,
        "train_loss": 3.1953883171081543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15447,
        "tokens": 8098676736,
        "learning_rate": 0.0003321054430568564,
        "gradient_norm": 0.3179742395877838,
        "train_loss": 3.117725372314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15448,
        "tokens": 8099201024,
        "learning_rate": 0.000332076798141931,
        "gradient_norm": 0.3234119117259979,
        "train_loss": 3.0978333950042725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15449,
        "tokens": 8099725312,
        "learning_rate": 0.0003320481532036287,
        "gradient_norm": 0.33274951577186584,
        "train_loss": 3.088395118713379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15450,
        "tokens": 8100249600,
        "learning_rate": 0.0003320195082422718,
        "gradient_norm": 0.3052355647087097,
        "train_loss": 3.082240104675293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15451,
        "tokens": 8100773888,
        "learning_rate": 0.00033199086325818287,
        "gradient_norm": 0.33184006810188293,
        "train_loss": 3.1037611961364746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15452,
        "tokens": 8101298176,
        "learning_rate": 0.0003319622182516842,
        "gradient_norm": 0.29980596899986267,
        "train_loss": 3.1243014335632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15453,
        "tokens": 8101822464,
        "learning_rate": 0.0003319335732230984,
        "gradient_norm": 0.3437916040420532,
        "train_loss": 3.114285945892334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15454,
        "tokens": 8102346752,
        "learning_rate": 0.00033190492817274786,
        "gradient_norm": 0.29939547181129456,
        "train_loss": 3.1258225440979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15455,
        "tokens": 8102871040,
        "learning_rate": 0.00033187628310095494,
        "gradient_norm": 0.3394247591495514,
        "train_loss": 3.1138417720794678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15456,
        "tokens": 8103395328,
        "learning_rate": 0.0003318476380080421,
        "gradient_norm": 0.30646127462387085,
        "train_loss": 3.0572714805603027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15457,
        "tokens": 8103919616,
        "learning_rate": 0.00033181899289433186,
        "gradient_norm": 0.3465258777141571,
        "train_loss": 3.0821077823638916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15458,
        "tokens": 8104443904,
        "learning_rate": 0.0003317903477601465,
        "gradient_norm": 0.2810189127922058,
        "train_loss": 3.1022844314575195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15459,
        "tokens": 8104968192,
        "learning_rate": 0.0003317617026058086,
        "gradient_norm": 0.28869935870170593,
        "train_loss": 3.085383892059326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15460,
        "tokens": 8105492480,
        "learning_rate": 0.0003317330574316405,
        "gradient_norm": 0.31510499119758606,
        "train_loss": 3.120065212249756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15461,
        "tokens": 8106016768,
        "learning_rate": 0.0003317044122379646,
        "gradient_norm": 0.2970471680164337,
        "train_loss": 3.13159441947937,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15462,
        "tokens": 8106541056,
        "learning_rate": 0.0003316757670251035,
        "gradient_norm": 0.2964041531085968,
        "train_loss": 3.1280293464660645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15463,
        "tokens": 8107065344,
        "learning_rate": 0.0003316471217933796,
        "gradient_norm": 0.3065732717514038,
        "train_loss": 3.1139204502105713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15464,
        "tokens": 8107589632,
        "learning_rate": 0.00033161847654311524,
        "gradient_norm": 0.28185421228408813,
        "train_loss": 3.0593557357788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15465,
        "tokens": 8108113920,
        "learning_rate": 0.000331589831274633,
        "gradient_norm": 0.3025174140930176,
        "train_loss": 3.0983424186706543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15466,
        "tokens": 8108638208,
        "learning_rate": 0.0003315611859882551,
        "gradient_norm": 0.32077738642692566,
        "train_loss": 3.131181001663208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15467,
        "tokens": 8109162496,
        "learning_rate": 0.0003315325406843042,
        "gradient_norm": 0.2882489264011383,
        "train_loss": 3.073075294494629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15468,
        "tokens": 8109686784,
        "learning_rate": 0.0003315038953631026,
        "gradient_norm": 0.2934964895248413,
        "train_loss": 3.1021878719329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15469,
        "tokens": 8110211072,
        "learning_rate": 0.00033147525002497275,
        "gradient_norm": 0.30378296971321106,
        "train_loss": 3.1226229667663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15470,
        "tokens": 8110735360,
        "learning_rate": 0.00033144660467023716,
        "gradient_norm": 0.2860387861728668,
        "train_loss": 3.06174373626709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15471,
        "tokens": 8111259648,
        "learning_rate": 0.00033141795929921816,
        "gradient_norm": 0.3101729452610016,
        "train_loss": 3.1412415504455566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15472,
        "tokens": 8111783936,
        "learning_rate": 0.00033138931391223835,
        "gradient_norm": 0.2832200825214386,
        "train_loss": 3.114008903503418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15473,
        "tokens": 8112308224,
        "learning_rate": 0.00033136066850962006,
        "gradient_norm": 0.3020983636379242,
        "train_loss": 3.146974563598633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15474,
        "tokens": 8112832512,
        "learning_rate": 0.0003313320230916858,
        "gradient_norm": 0.308187872171402,
        "train_loss": 3.115093469619751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15475,
        "tokens": 8113356800,
        "learning_rate": 0.00033130337765875786,
        "gradient_norm": 0.29691281914711,
        "train_loss": 3.139106273651123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15476,
        "tokens": 8113881088,
        "learning_rate": 0.00033127473221115884,
        "gradient_norm": 0.3036709725856781,
        "train_loss": 3.161914587020874,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15477,
        "tokens": 8114405376,
        "learning_rate": 0.0003312460867492111,
        "gradient_norm": 0.3078465759754181,
        "train_loss": 3.1075081825256348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15478,
        "tokens": 8114929664,
        "learning_rate": 0.0003312174412732371,
        "gradient_norm": 0.29361799359321594,
        "train_loss": 3.0957841873168945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15479,
        "tokens": 8115453952,
        "learning_rate": 0.0003311887957835593,
        "gradient_norm": 0.28972816467285156,
        "train_loss": 3.101365327835083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15480,
        "tokens": 8115978240,
        "learning_rate": 0.0003311601502805001,
        "gradient_norm": 0.30993443727493286,
        "train_loss": 3.0490427017211914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15481,
        "tokens": 8116502528,
        "learning_rate": 0.0003311315047643819,
        "gradient_norm": 0.31608331203460693,
        "train_loss": 3.0879805088043213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15482,
        "tokens": 8117026816,
        "learning_rate": 0.0003311028592355273,
        "gradient_norm": 0.3122197687625885,
        "train_loss": 3.168480396270752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15483,
        "tokens": 8117551104,
        "learning_rate": 0.0003310742136942586,
        "gradient_norm": 0.35940226912498474,
        "train_loss": 3.185511589050293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15484,
        "tokens": 8118075392,
        "learning_rate": 0.00033104556814089834,
        "gradient_norm": 0.30617573857307434,
        "train_loss": 3.149245262145996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15485,
        "tokens": 8118599680,
        "learning_rate": 0.00033101692257576893,
        "gradient_norm": 0.3237614035606384,
        "train_loss": 3.1051383018493652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15486,
        "tokens": 8119123968,
        "learning_rate": 0.00033098827699919273,
        "gradient_norm": 0.30775511264801025,
        "train_loss": 3.1202688217163086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15487,
        "tokens": 8119648256,
        "learning_rate": 0.00033095963141149224,
        "gradient_norm": 0.3157329261302948,
        "train_loss": 3.0535874366760254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15488,
        "tokens": 8120172544,
        "learning_rate": 0.0003309309858129899,
        "gradient_norm": 0.30904650688171387,
        "train_loss": 3.0849270820617676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15489,
        "tokens": 8120696832,
        "learning_rate": 0.0003309023402040081,
        "gradient_norm": 0.3134489357471466,
        "train_loss": 3.048860549926758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15490,
        "tokens": 8121221120,
        "learning_rate": 0.0003308736945848694,
        "gradient_norm": 0.31708890199661255,
        "train_loss": 3.1462626457214355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15491,
        "tokens": 8121745408,
        "learning_rate": 0.0003308450489558962,
        "gradient_norm": 0.3102779686450958,
        "train_loss": 3.0688788890838623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15492,
        "tokens": 8122269696,
        "learning_rate": 0.0003308164033174109,
        "gradient_norm": 0.32586345076560974,
        "train_loss": 3.103242874145508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15493,
        "tokens": 8122793984,
        "learning_rate": 0.00033078775766973595,
        "gradient_norm": 0.3281331956386566,
        "train_loss": 3.13023042678833,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15494,
        "tokens": 8123318272,
        "learning_rate": 0.0003307591120131939,
        "gradient_norm": 0.3378869891166687,
        "train_loss": 3.045170783996582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15495,
        "tokens": 8123842560,
        "learning_rate": 0.00033073046634810694,
        "gradient_norm": 0.3311387896537781,
        "train_loss": 3.081115245819092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15496,
        "tokens": 8124366848,
        "learning_rate": 0.00033070182067479774,
        "gradient_norm": 0.2963722348213196,
        "train_loss": 3.1845593452453613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15497,
        "tokens": 8124891136,
        "learning_rate": 0.00033067317499358865,
        "gradient_norm": 0.31990954279899597,
        "train_loss": 3.058034896850586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15498,
        "tokens": 8125415424,
        "learning_rate": 0.0003306445293048022,
        "gradient_norm": 0.2753346562385559,
        "train_loss": 3.1478652954101562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15499,
        "tokens": 8125939712,
        "learning_rate": 0.00033061588360876074,
        "gradient_norm": 0.30331116914749146,
        "train_loss": 3.1027801036834717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15500,
        "tokens": 8126464000,
        "learning_rate": 0.00033058723790578673,
        "gradient_norm": 0.28535568714141846,
        "train_loss": 3.178194522857666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15501,
        "tokens": 8126988288,
        "learning_rate": 0.0003305585921962026,
        "gradient_norm": 0.27356353402137756,
        "train_loss": 3.093613624572754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15502,
        "tokens": 8127512576,
        "learning_rate": 0.00033052994648033083,
        "gradient_norm": 0.36563244462013245,
        "train_loss": 3.1284523010253906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15503,
        "tokens": 8128036864,
        "learning_rate": 0.0003305013007584939,
        "gradient_norm": 0.29920369386672974,
        "train_loss": 3.0999929904937744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15504,
        "tokens": 8128561152,
        "learning_rate": 0.00033047265503101413,
        "gradient_norm": 0.28509706258773804,
        "train_loss": 3.093916893005371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15505,
        "tokens": 8129085440,
        "learning_rate": 0.0003304440092982141,
        "gradient_norm": 0.3005754351615906,
        "train_loss": 3.0846614837646484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15506,
        "tokens": 8129609728,
        "learning_rate": 0.0003304153635604162,
        "gradient_norm": 0.29122981429100037,
        "train_loss": 3.1601428985595703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15507,
        "tokens": 8130134016,
        "learning_rate": 0.0003303867178179428,
        "gradient_norm": 0.29405897855758667,
        "train_loss": 3.069855213165283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15508,
        "tokens": 8130658304,
        "learning_rate": 0.0003303580720711165,
        "gradient_norm": 0.28368815779685974,
        "train_loss": 3.0968732833862305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15509,
        "tokens": 8131182592,
        "learning_rate": 0.00033032942632025956,
        "gradient_norm": 0.2696828246116638,
        "train_loss": 3.069901466369629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15510,
        "tokens": 8131706880,
        "learning_rate": 0.00033030078056569455,
        "gradient_norm": 0.3064562976360321,
        "train_loss": 3.1001639366149902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15511,
        "tokens": 8132231168,
        "learning_rate": 0.00033027213480774385,
        "gradient_norm": 0.2998511493206024,
        "train_loss": 3.135918617248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15512,
        "tokens": 8132755456,
        "learning_rate": 0.00033024348904672995,
        "gradient_norm": 0.28911662101745605,
        "train_loss": 3.0979509353637695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15513,
        "tokens": 8133279744,
        "learning_rate": 0.0003302148432829753,
        "gradient_norm": 0.2826698422431946,
        "train_loss": 3.097351551055908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15514,
        "tokens": 8133804032,
        "learning_rate": 0.00033018619751680234,
        "gradient_norm": 0.27645885944366455,
        "train_loss": 3.0807228088378906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15515,
        "tokens": 8134328320,
        "learning_rate": 0.0003301575517485335,
        "gradient_norm": 0.29435646533966064,
        "train_loss": 3.0537915229797363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15516,
        "tokens": 8134852608,
        "learning_rate": 0.00033012890597849113,
        "gradient_norm": 0.3014584481716156,
        "train_loss": 3.0738754272460938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15517,
        "tokens": 8135376896,
        "learning_rate": 0.0003301002602069978,
        "gradient_norm": 0.3036406338214874,
        "train_loss": 3.0732364654541016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15518,
        "tokens": 8135901184,
        "learning_rate": 0.000330071614434376,
        "gradient_norm": 0.31662270426750183,
        "train_loss": 3.0973961353302,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15519,
        "tokens": 8136425472,
        "learning_rate": 0.00033004296866094807,
        "gradient_norm": 0.31254586577415466,
        "train_loss": 3.0812935829162598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15520,
        "tokens": 8136949760,
        "learning_rate": 0.0003300143228870364,
        "gradient_norm": 0.3194674551486969,
        "train_loss": 3.1220004558563232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15521,
        "tokens": 8137474048,
        "learning_rate": 0.00032998567711296355,
        "gradient_norm": 0.3273378610610962,
        "train_loss": 3.0581583976745605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15522,
        "tokens": 8137998336,
        "learning_rate": 0.0003299570313390519,
        "gradient_norm": 0.3214511573314667,
        "train_loss": 3.1286234855651855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15523,
        "tokens": 8138522624,
        "learning_rate": 0.000329928385565624,
        "gradient_norm": 0.35091888904571533,
        "train_loss": 3.1292078495025635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15524,
        "tokens": 8139046912,
        "learning_rate": 0.00032989973979300207,
        "gradient_norm": 0.3357543647289276,
        "train_loss": 3.1335554122924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15525,
        "tokens": 8139571200,
        "learning_rate": 0.0003298710940215088,
        "gradient_norm": 0.36529359221458435,
        "train_loss": 3.1988463401794434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15526,
        "tokens": 8140095488,
        "learning_rate": 0.00032984244825146644,
        "gradient_norm": 0.353592187166214,
        "train_loss": 3.0966479778289795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15527,
        "tokens": 8140619776,
        "learning_rate": 0.0003298138024831975,
        "gradient_norm": 0.30344071984291077,
        "train_loss": 3.100374221801758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15528,
        "tokens": 8141144064,
        "learning_rate": 0.0003297851567170246,
        "gradient_norm": 0.3483946621417999,
        "train_loss": 3.107667922973633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15529,
        "tokens": 8141668352,
        "learning_rate": 0.0003297565109532699,
        "gradient_norm": 0.33998268842697144,
        "train_loss": 3.068206787109375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15530,
        "tokens": 8142192640,
        "learning_rate": 0.0003297278651922561,
        "gradient_norm": 0.39174625277519226,
        "train_loss": 3.1733269691467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15531,
        "tokens": 8142716928,
        "learning_rate": 0.0003296992194343054,
        "gradient_norm": 0.3517475724220276,
        "train_loss": 3.1217191219329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15532,
        "tokens": 8143241216,
        "learning_rate": 0.00032967057367974044,
        "gradient_norm": 0.40862715244293213,
        "train_loss": 3.1037282943725586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15533,
        "tokens": 8143765504,
        "learning_rate": 0.00032964192792888345,
        "gradient_norm": 0.3280991017818451,
        "train_loss": 3.1494688987731934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15534,
        "tokens": 8144289792,
        "learning_rate": 0.00032961328218205716,
        "gradient_norm": 0.3861156404018402,
        "train_loss": 3.1516761779785156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15535,
        "tokens": 8144814080,
        "learning_rate": 0.00032958463643958377,
        "gradient_norm": 0.3258592486381531,
        "train_loss": 3.1436052322387695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15536,
        "tokens": 8145338368,
        "learning_rate": 0.0003295559907017858,
        "gradient_norm": 0.3770614266395569,
        "train_loss": 3.1290457248687744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15537,
        "tokens": 8145862656,
        "learning_rate": 0.0003295273449689858,
        "gradient_norm": 0.34021222591400146,
        "train_loss": 3.155386447906494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15538,
        "tokens": 8146386944,
        "learning_rate": 0.000329498699241506,
        "gradient_norm": 0.34077906608581543,
        "train_loss": 3.1092119216918945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15539,
        "tokens": 8146911232,
        "learning_rate": 0.0003294700535196691,
        "gradient_norm": 0.296026349067688,
        "train_loss": 3.0324482917785645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15540,
        "tokens": 8147435520,
        "learning_rate": 0.0003294414078037973,
        "gradient_norm": 0.34488773345947266,
        "train_loss": 3.0555977821350098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15541,
        "tokens": 8147959808,
        "learning_rate": 0.00032941276209421327,
        "gradient_norm": 0.30561378598213196,
        "train_loss": 3.0913398265838623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15542,
        "tokens": 8148484096,
        "learning_rate": 0.00032938411639123915,
        "gradient_norm": 0.3402818739414215,
        "train_loss": 3.0978586673736572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15543,
        "tokens": 8149008384,
        "learning_rate": 0.0003293554706951978,
        "gradient_norm": 0.32855018973350525,
        "train_loss": 3.1269288063049316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15544,
        "tokens": 8149532672,
        "learning_rate": 0.00032932682500641123,
        "gradient_norm": 0.3215126395225525,
        "train_loss": 3.131943702697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15545,
        "tokens": 8150056960,
        "learning_rate": 0.00032929817932520226,
        "gradient_norm": 0.34244659543037415,
        "train_loss": 3.1370320320129395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15546,
        "tokens": 8150581248,
        "learning_rate": 0.00032926953365189295,
        "gradient_norm": 1.6706104278564453,
        "train_loss": 2.8695602416992188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15547,
        "tokens": 8151105536,
        "learning_rate": 0.00032924088798680606,
        "gradient_norm": 0.4114045798778534,
        "train_loss": 3.1192893981933594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15548,
        "tokens": 8151629824,
        "learning_rate": 0.000329212242330264,
        "gradient_norm": 0.3511497676372528,
        "train_loss": 3.124093532562256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15549,
        "tokens": 8152154112,
        "learning_rate": 0.000329183596682589,
        "gradient_norm": 0.3517296612262726,
        "train_loss": 3.086635112762451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15550,
        "tokens": 8152678400,
        "learning_rate": 0.0003291549510441037,
        "gradient_norm": 0.3812650740146637,
        "train_loss": 3.1266226768493652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15551,
        "tokens": 8153202688,
        "learning_rate": 0.0003291263054151305,
        "gradient_norm": 0.32552778720855713,
        "train_loss": 3.1304993629455566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15552,
        "tokens": 8153726976,
        "learning_rate": 0.0003290976597959918,
        "gradient_norm": 0.3964124023914337,
        "train_loss": 3.0863163471221924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15553,
        "tokens": 8154251264,
        "learning_rate": 0.00032906901418701005,
        "gradient_norm": 0.332072913646698,
        "train_loss": 3.126769542694092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15554,
        "tokens": 8154775552,
        "learning_rate": 0.0003290403685885077,
        "gradient_norm": 0.3560897707939148,
        "train_loss": 3.1327762603759766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15555,
        "tokens": 8155299840,
        "learning_rate": 0.00032901172300080727,
        "gradient_norm": 0.3638046383857727,
        "train_loss": 3.095226287841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15556,
        "tokens": 8155824128,
        "learning_rate": 0.00032898307742423096,
        "gradient_norm": 0.34837543964385986,
        "train_loss": 3.0928573608398438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15557,
        "tokens": 8156348416,
        "learning_rate": 0.0003289544318591016,
        "gradient_norm": 0.3564063012599945,
        "train_loss": 3.1359481811523438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15558,
        "tokens": 8156872704,
        "learning_rate": 0.00032892578630574126,
        "gradient_norm": 0.279045432806015,
        "train_loss": 3.116403818130493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15559,
        "tokens": 8157396992,
        "learning_rate": 0.0003288971407644726,
        "gradient_norm": 0.32703250646591187,
        "train_loss": 3.1742734909057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15560,
        "tokens": 8157921280,
        "learning_rate": 0.00032886849523561793,
        "gradient_norm": 0.29851290583610535,
        "train_loss": 3.063821315765381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15561,
        "tokens": 8158445568,
        "learning_rate": 0.0003288398497194999,
        "gradient_norm": 0.2930644452571869,
        "train_loss": 3.1160759925842285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15562,
        "tokens": 8158969856,
        "learning_rate": 0.0003288112042164406,
        "gradient_norm": 0.29736632108688354,
        "train_loss": 3.106736421585083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15563,
        "tokens": 8159494144,
        "learning_rate": 0.00032878255872676284,
        "gradient_norm": 0.28260567784309387,
        "train_loss": 3.087386131286621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15564,
        "tokens": 8160018432,
        "learning_rate": 0.00032875391325078884,
        "gradient_norm": 0.27458399534225464,
        "train_loss": 3.1125333309173584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15565,
        "tokens": 8160542720,
        "learning_rate": 0.00032872526778884116,
        "gradient_norm": 0.26843151450157166,
        "train_loss": 3.082289457321167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15566,
        "tokens": 8161067008,
        "learning_rate": 0.00032869662234124203,
        "gradient_norm": 0.3126584589481354,
        "train_loss": 3.123073101043701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15567,
        "tokens": 8161591296,
        "learning_rate": 0.0003286679769083141,
        "gradient_norm": 0.28739696741104126,
        "train_loss": 3.1099488735198975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15568,
        "tokens": 8162115584,
        "learning_rate": 0.00032863933149037983,
        "gradient_norm": 0.2991214394569397,
        "train_loss": 3.0645761489868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15569,
        "tokens": 8162639872,
        "learning_rate": 0.00032861068608776154,
        "gradient_norm": 0.30538466572761536,
        "train_loss": 3.11584210395813,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15570,
        "tokens": 8163164160,
        "learning_rate": 0.0003285820407007817,
        "gradient_norm": 0.30307868123054504,
        "train_loss": 3.199198007583618,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15571,
        "tokens": 8163688448,
        "learning_rate": 0.0003285533953297627,
        "gradient_norm": 0.3295307755470276,
        "train_loss": 3.0850353240966797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15572,
        "tokens": 8164212736,
        "learning_rate": 0.0003285247499750272,
        "gradient_norm": 0.29063910245895386,
        "train_loss": 3.0510456562042236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15573,
        "tokens": 8164737024,
        "learning_rate": 0.00032849610463689735,
        "gradient_norm": 0.3110077679157257,
        "train_loss": 3.1306614875793457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15574,
        "tokens": 8165261312,
        "learning_rate": 0.0003284674593156958,
        "gradient_norm": 0.3143670856952667,
        "train_loss": 3.1329715251922607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15575,
        "tokens": 8165785600,
        "learning_rate": 0.0003284388140117448,
        "gradient_norm": 0.309688538312912,
        "train_loss": 3.1295599937438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15576,
        "tokens": 8166309888,
        "learning_rate": 0.0003284101687253669,
        "gradient_norm": 0.29890871047973633,
        "train_loss": 3.1026711463928223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15577,
        "tokens": 8166834176,
        "learning_rate": 0.00032838152345688465,
        "gradient_norm": 0.318877249956131,
        "train_loss": 3.0993874073028564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15578,
        "tokens": 8167358464,
        "learning_rate": 0.0003283528782066203,
        "gradient_norm": 0.3361530601978302,
        "train_loss": 3.0920486450195312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15579,
        "tokens": 8167882752,
        "learning_rate": 0.0003283242329748964,
        "gradient_norm": 0.3438936173915863,
        "train_loss": 3.0634255409240723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15580,
        "tokens": 8168407040,
        "learning_rate": 0.0003282955877620352,
        "gradient_norm": 0.3606683611869812,
        "train_loss": 3.135585308074951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15581,
        "tokens": 8168931328,
        "learning_rate": 0.0003282669425683595,
        "gradient_norm": 0.3359644114971161,
        "train_loss": 3.147409439086914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15582,
        "tokens": 8169455616,
        "learning_rate": 0.00032823829739419137,
        "gradient_norm": 0.3708833158016205,
        "train_loss": 3.07759428024292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15583,
        "tokens": 8169979904,
        "learning_rate": 0.0003282096522398535,
        "gradient_norm": 0.3419432044029236,
        "train_loss": 3.1226139068603516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15584,
        "tokens": 8170504192,
        "learning_rate": 0.0003281810071056681,
        "gradient_norm": 0.3189815282821655,
        "train_loss": 3.113342761993408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15585,
        "tokens": 8171028480,
        "learning_rate": 0.00032815236199195785,
        "gradient_norm": 0.327357679605484,
        "train_loss": 3.0911855697631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15586,
        "tokens": 8171552768,
        "learning_rate": 0.000328123716899045,
        "gradient_norm": 0.3309783935546875,
        "train_loss": 3.1096949577331543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15587,
        "tokens": 8172077056,
        "learning_rate": 0.00032809507182725203,
        "gradient_norm": 0.3217671811580658,
        "train_loss": 3.0982911586761475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15588,
        "tokens": 8172601344,
        "learning_rate": 0.0003280664267769015,
        "gradient_norm": 0.34182798862457275,
        "train_loss": 3.0878264904022217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15589,
        "tokens": 8173125632,
        "learning_rate": 0.0003280377817483156,
        "gradient_norm": 0.32228314876556396,
        "train_loss": 3.0890603065490723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15590,
        "tokens": 8173649920,
        "learning_rate": 0.0003280091367418171,
        "gradient_norm": 0.3148607909679413,
        "train_loss": 3.124213218688965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15591,
        "tokens": 8174174208,
        "learning_rate": 0.0003279804917577281,
        "gradient_norm": 0.3419041633605957,
        "train_loss": 3.100680351257324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15592,
        "tokens": 8174698496,
        "learning_rate": 0.0003279518467963713,
        "gradient_norm": 0.3249906003475189,
        "train_loss": 3.077274799346924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15593,
        "tokens": 8175222784,
        "learning_rate": 0.00032792320185806887,
        "gradient_norm": 0.32603031396865845,
        "train_loss": 3.1278724670410156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15594,
        "tokens": 8175747072,
        "learning_rate": 0.0003278945569431436,
        "gradient_norm": 0.2966916263103485,
        "train_loss": 3.112151622772217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15595,
        "tokens": 8176271360,
        "learning_rate": 0.0003278659120519175,
        "gradient_norm": 0.3315960764884949,
        "train_loss": 3.1167635917663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15596,
        "tokens": 8176795648,
        "learning_rate": 0.00032783726718471336,
        "gradient_norm": 0.2891421616077423,
        "train_loss": 3.1159510612487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15597,
        "tokens": 8177319936,
        "learning_rate": 0.00032780862234185336,
        "gradient_norm": 0.33602410554885864,
        "train_loss": 3.1138339042663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15598,
        "tokens": 8177844224,
        "learning_rate": 0.00032777997752366016,
        "gradient_norm": 0.294398695230484,
        "train_loss": 3.034254312515259,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15599,
        "tokens": 8178368512,
        "learning_rate": 0.000327751332730456,
        "gradient_norm": 0.3112950325012207,
        "train_loss": 3.066384792327881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15600,
        "tokens": 8178892800,
        "learning_rate": 0.00032772268796256345,
        "gradient_norm": 0.30927574634552,
        "train_loss": 3.0842299461364746,
        "val_loss": 3.0699329376220703,
        "hellaswag_acc": 0.2797251343727112,
        "hellaswag_acc_norm": 0.290081650018692
    },
    {
        "step": 15601,
        "tokens": 8179417088,
        "learning_rate": 0.0003276940432203049,
        "gradient_norm": 0.309736043214798,
        "train_loss": 3.0975847244262695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15602,
        "tokens": 8179941376,
        "learning_rate": 0.00032766539850400273,
        "gradient_norm": 0.31210488080978394,
        "train_loss": 3.1047050952911377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15603,
        "tokens": 8180465664,
        "learning_rate": 0.0003276367538139794,
        "gradient_norm": 0.3033566474914551,
        "train_loss": 3.086782932281494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15604,
        "tokens": 8180989952,
        "learning_rate": 0.00032760810915055736,
        "gradient_norm": 0.31072986125946045,
        "train_loss": 3.0904300212860107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15605,
        "tokens": 8181514240,
        "learning_rate": 0.00032757946451405904,
        "gradient_norm": 0.3472561538219452,
        "train_loss": 3.1371006965637207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15606,
        "tokens": 8182038528,
        "learning_rate": 0.0003275508199048069,
        "gradient_norm": 0.2975385785102844,
        "train_loss": 3.1322126388549805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15607,
        "tokens": 8182562816,
        "learning_rate": 0.0003275221753231232,
        "gradient_norm": 0.35320886969566345,
        "train_loss": 3.1413543224334717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15608,
        "tokens": 8183087104,
        "learning_rate": 0.00032749353076933066,
        "gradient_norm": 0.31141403317451477,
        "train_loss": 3.125999927520752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15609,
        "tokens": 8183611392,
        "learning_rate": 0.0003274648862437514,
        "gradient_norm": 0.31319504976272583,
        "train_loss": 3.071852445602417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15610,
        "tokens": 8184135680,
        "learning_rate": 0.0003274362417467082,
        "gradient_norm": 0.29773253202438354,
        "train_loss": 3.058055877685547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15611,
        "tokens": 8184659968,
        "learning_rate": 0.0003274075972785232,
        "gradient_norm": 0.35497844219207764,
        "train_loss": 3.065189838409424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15612,
        "tokens": 8185184256,
        "learning_rate": 0.00032737895283951895,
        "gradient_norm": 0.3145357668399811,
        "train_loss": 3.1122922897338867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15613,
        "tokens": 8185708544,
        "learning_rate": 0.00032735030843001776,
        "gradient_norm": 0.312027245759964,
        "train_loss": 3.0689942836761475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15614,
        "tokens": 8186232832,
        "learning_rate": 0.00032732166405034227,
        "gradient_norm": 0.30444642901420593,
        "train_loss": 3.174760341644287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15615,
        "tokens": 8186757120,
        "learning_rate": 0.0003272930197008147,
        "gradient_norm": 0.3199392557144165,
        "train_loss": 3.091923713684082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15616,
        "tokens": 8187281408,
        "learning_rate": 0.00032726437538175754,
        "gradient_norm": 0.33409368991851807,
        "train_loss": 3.0652265548706055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15617,
        "tokens": 8187805696,
        "learning_rate": 0.00032723573109349336,
        "gradient_norm": 0.3110884130001068,
        "train_loss": 3.133253574371338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15618,
        "tokens": 8188329984,
        "learning_rate": 0.00032720708683634436,
        "gradient_norm": 0.30002617835998535,
        "train_loss": 3.0377917289733887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15619,
        "tokens": 8188854272,
        "learning_rate": 0.0003271784426106332,
        "gradient_norm": 0.3269573450088501,
        "train_loss": 3.1515626907348633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15620,
        "tokens": 8189378560,
        "learning_rate": 0.00032714979841668205,
        "gradient_norm": 0.3364119827747345,
        "train_loss": 3.1346516609191895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15621,
        "tokens": 8189902848,
        "learning_rate": 0.0003271211542548136,
        "gradient_norm": 0.2969166338443756,
        "train_loss": 3.0077133178710938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15622,
        "tokens": 8190427136,
        "learning_rate": 0.0003270925101253501,
        "gradient_norm": 0.3205215334892273,
        "train_loss": 3.1117172241210938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15623,
        "tokens": 8190951424,
        "learning_rate": 0.00032706386602861405,
        "gradient_norm": 0.31248828768730164,
        "train_loss": 3.101330280303955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15624,
        "tokens": 8191475712,
        "learning_rate": 0.00032703522196492776,
        "gradient_norm": 0.3116108179092407,
        "train_loss": 3.1056337356567383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15625,
        "tokens": 8192000000,
        "learning_rate": 0.00032700657793461387,
        "gradient_norm": 0.3310701847076416,
        "train_loss": 3.120579242706299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15626,
        "tokens": 8192524288,
        "learning_rate": 0.00032697793393799454,
        "gradient_norm": 0.32330095767974854,
        "train_loss": 3.126269817352295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15627,
        "tokens": 8193048576,
        "learning_rate": 0.0003269492899753924,
        "gradient_norm": 0.3361155688762665,
        "train_loss": 3.0612826347351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15628,
        "tokens": 8193572864,
        "learning_rate": 0.0003269206460471298,
        "gradient_norm": 0.30277737975120544,
        "train_loss": 3.1213037967681885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15629,
        "tokens": 8194097152,
        "learning_rate": 0.00032689200215352916,
        "gradient_norm": 0.3323499262332916,
        "train_loss": 3.031768321990967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15630,
        "tokens": 8194621440,
        "learning_rate": 0.00032686335829491294,
        "gradient_norm": 0.29541200399398804,
        "train_loss": 3.0254058837890625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15631,
        "tokens": 8195145728,
        "learning_rate": 0.00032683471447160343,
        "gradient_norm": 0.32938605546951294,
        "train_loss": 3.0083439350128174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15632,
        "tokens": 8195670016,
        "learning_rate": 0.0003268060706839233,
        "gradient_norm": 0.3389850854873657,
        "train_loss": 3.0496299266815186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15633,
        "tokens": 8196194304,
        "learning_rate": 0.0003267774269321947,
        "gradient_norm": 0.30872660875320435,
        "train_loss": 3.050854444503784,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15634,
        "tokens": 8196718592,
        "learning_rate": 0.00032674878321674035,
        "gradient_norm": 0.33425527811050415,
        "train_loss": 3.085972785949707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15635,
        "tokens": 8197242880,
        "learning_rate": 0.0003267201395378823,
        "gradient_norm": 0.28092432022094727,
        "train_loss": 3.1116318702697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15636,
        "tokens": 8197767168,
        "learning_rate": 0.00032669149589594317,
        "gradient_norm": 0.33313530683517456,
        "train_loss": 3.1368160247802734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15637,
        "tokens": 8198291456,
        "learning_rate": 0.0003266628522912455,
        "gradient_norm": 0.3190983235836029,
        "train_loss": 3.045665979385376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15638,
        "tokens": 8198815744,
        "learning_rate": 0.0003266342087241115,
        "gradient_norm": 0.3084002137184143,
        "train_loss": 3.093397617340088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15639,
        "tokens": 8199340032,
        "learning_rate": 0.00032660556519486383,
        "gradient_norm": 0.30370423197746277,
        "train_loss": 3.0392072200775146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15640,
        "tokens": 8199864320,
        "learning_rate": 0.00032657692170382456,
        "gradient_norm": 0.29984498023986816,
        "train_loss": 3.090949058532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15641,
        "tokens": 8200388608,
        "learning_rate": 0.0003265482782513165,
        "gradient_norm": 0.3276965916156769,
        "train_loss": 3.0485410690307617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15642,
        "tokens": 8200912896,
        "learning_rate": 0.00032651963483766166,
        "gradient_norm": 0.2887009084224701,
        "train_loss": 3.0465590953826904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15643,
        "tokens": 8201437184,
        "learning_rate": 0.00032649099146318285,
        "gradient_norm": 0.3005233108997345,
        "train_loss": 3.100648880004883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15644,
        "tokens": 8201961472,
        "learning_rate": 0.0003264623481282022,
        "gradient_norm": 0.30341649055480957,
        "train_loss": 3.143629312515259,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15645,
        "tokens": 8202485760,
        "learning_rate": 0.0003264337048330423,
        "gradient_norm": 0.2950660288333893,
        "train_loss": 3.1001362800598145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15646,
        "tokens": 8203010048,
        "learning_rate": 0.0003264050615780254,
        "gradient_norm": 0.31430962681770325,
        "train_loss": 3.140756607055664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15647,
        "tokens": 8203534336,
        "learning_rate": 0.0003263764183634741,
        "gradient_norm": 0.2922278642654419,
        "train_loss": 3.069796323776245,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15648,
        "tokens": 8204058624,
        "learning_rate": 0.00032634777518971065,
        "gradient_norm": 0.3121984899044037,
        "train_loss": 3.040797710418701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15649,
        "tokens": 8204582912,
        "learning_rate": 0.0003263191320570576,
        "gradient_norm": 0.2946387827396393,
        "train_loss": 3.0315475463867188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15650,
        "tokens": 8205107200,
        "learning_rate": 0.0003262904889658373,
        "gradient_norm": 0.33226025104522705,
        "train_loss": 3.1049845218658447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15651,
        "tokens": 8205631488,
        "learning_rate": 0.00032626184591637216,
        "gradient_norm": 0.2965199053287506,
        "train_loss": 3.0508861541748047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15652,
        "tokens": 8206155776,
        "learning_rate": 0.00032623320290898464,
        "gradient_norm": 0.3239562213420868,
        "train_loss": 3.0826311111450195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15653,
        "tokens": 8206680064,
        "learning_rate": 0.00032620455994399706,
        "gradient_norm": 0.2999842166900635,
        "train_loss": 3.1098618507385254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15654,
        "tokens": 8207204352,
        "learning_rate": 0.00032617591702173193,
        "gradient_norm": 0.3013496398925781,
        "train_loss": 3.1077733039855957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15655,
        "tokens": 8207728640,
        "learning_rate": 0.00032614727414251164,
        "gradient_norm": 0.308114230632782,
        "train_loss": 3.110077381134033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15656,
        "tokens": 8208252928,
        "learning_rate": 0.00032611863130665845,
        "gradient_norm": 0.2952161133289337,
        "train_loss": 3.092662811279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15657,
        "tokens": 8208777216,
        "learning_rate": 0.0003260899885144951,
        "gradient_norm": 0.2923438847064972,
        "train_loss": 3.0687756538391113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15658,
        "tokens": 8209301504,
        "learning_rate": 0.0003260613457663436,
        "gradient_norm": 0.3311062157154083,
        "train_loss": 3.0766396522521973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15659,
        "tokens": 8209825792,
        "learning_rate": 0.00032603270306252673,
        "gradient_norm": 0.3203240633010864,
        "train_loss": 3.124880790710449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15660,
        "tokens": 8210350080,
        "learning_rate": 0.0003260040604033667,
        "gradient_norm": 0.3015439212322235,
        "train_loss": 3.0007505416870117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15661,
        "tokens": 8210874368,
        "learning_rate": 0.00032597541778918595,
        "gradient_norm": 0.34854012727737427,
        "train_loss": 3.1078691482543945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15662,
        "tokens": 8211398656,
        "learning_rate": 0.00032594677522030676,
        "gradient_norm": 0.30546998977661133,
        "train_loss": 3.050720691680908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15663,
        "tokens": 8211922944,
        "learning_rate": 0.0003259181326970519,
        "gradient_norm": 0.3495771288871765,
        "train_loss": 3.0163049697875977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15664,
        "tokens": 8212447232,
        "learning_rate": 0.0003258894902197433,
        "gradient_norm": 0.30141401290893555,
        "train_loss": 3.0304455757141113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15665,
        "tokens": 8212971520,
        "learning_rate": 0.0003258608477887038,
        "gradient_norm": 0.3431496322154999,
        "train_loss": 3.1198697090148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15666,
        "tokens": 8213495808,
        "learning_rate": 0.0003258322054042555,
        "gradient_norm": 0.3217290937900543,
        "train_loss": 3.1023435592651367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15667,
        "tokens": 8214020096,
        "learning_rate": 0.0003258035630667209,
        "gradient_norm": 0.3156617283821106,
        "train_loss": 3.0490458011627197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15668,
        "tokens": 8214544384,
        "learning_rate": 0.00032577492077642253,
        "gradient_norm": 0.3205612301826477,
        "train_loss": 3.096552848815918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15669,
        "tokens": 8215068672,
        "learning_rate": 0.00032574627853368263,
        "gradient_norm": 0.3081446588039398,
        "train_loss": 3.056643009185791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15670,
        "tokens": 8215592960,
        "learning_rate": 0.00032571763633882376,
        "gradient_norm": 0.3315213620662689,
        "train_loss": 3.1402010917663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15671,
        "tokens": 8216117248,
        "learning_rate": 0.00032568899419216813,
        "gradient_norm": 0.3015074133872986,
        "train_loss": 3.0877163410186768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15672,
        "tokens": 8216641536,
        "learning_rate": 0.0003256603520940383,
        "gradient_norm": 0.3243245780467987,
        "train_loss": 3.0336809158325195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15673,
        "tokens": 8217165824,
        "learning_rate": 0.00032563171004475655,
        "gradient_norm": 0.2947077751159668,
        "train_loss": 3.050410747528076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15674,
        "tokens": 8217690112,
        "learning_rate": 0.0003256030680446455,
        "gradient_norm": 0.3144989013671875,
        "train_loss": 3.071708917617798,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15675,
        "tokens": 8218214400,
        "learning_rate": 0.0003255744260940272,
        "gradient_norm": 0.2810405194759369,
        "train_loss": 3.1010818481445312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15676,
        "tokens": 8218738688,
        "learning_rate": 0.0003255457841932243,
        "gradient_norm": 0.30834856629371643,
        "train_loss": 3.08180570602417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15677,
        "tokens": 8219262976,
        "learning_rate": 0.0003255171423425593,
        "gradient_norm": 0.28283318877220154,
        "train_loss": 3.0397558212280273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15678,
        "tokens": 8219787264,
        "learning_rate": 0.0003254885005423542,
        "gradient_norm": 0.3188382089138031,
        "train_loss": 3.1378331184387207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15679,
        "tokens": 8220311552,
        "learning_rate": 0.00032545985879293195,
        "gradient_norm": 0.29912087321281433,
        "train_loss": 3.0251922607421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15680,
        "tokens": 8220835840,
        "learning_rate": 0.0003254312170946144,
        "gradient_norm": 0.2752455770969391,
        "train_loss": 3.0359997749328613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15681,
        "tokens": 8221360128,
        "learning_rate": 0.0003254025754477244,
        "gradient_norm": 0.3227265179157257,
        "train_loss": 3.1126084327697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15682,
        "tokens": 8221884416,
        "learning_rate": 0.00032537393385258397,
        "gradient_norm": 0.3114990293979645,
        "train_loss": 3.0582215785980225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15683,
        "tokens": 8222408704,
        "learning_rate": 0.0003253452923095158,
        "gradient_norm": 0.32254377007484436,
        "train_loss": 3.1031110286712646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15684,
        "tokens": 8222932992,
        "learning_rate": 0.00032531665081884204,
        "gradient_norm": 0.3141108751296997,
        "train_loss": 3.0812854766845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15685,
        "tokens": 8223457280,
        "learning_rate": 0.00032528800938088536,
        "gradient_norm": 0.3132834732532501,
        "train_loss": 3.0373523235321045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15686,
        "tokens": 8223981568,
        "learning_rate": 0.0003252593679959679,
        "gradient_norm": 0.3408870995044708,
        "train_loss": 3.093683958053589,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15687,
        "tokens": 8224505856,
        "learning_rate": 0.00032523072666441216,
        "gradient_norm": 0.2941311299800873,
        "train_loss": 3.102785110473633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15688,
        "tokens": 8225030144,
        "learning_rate": 0.00032520208538654063,
        "gradient_norm": 0.2928909957408905,
        "train_loss": 3.0954763889312744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15689,
        "tokens": 8225554432,
        "learning_rate": 0.0003251734441626755,
        "gradient_norm": 0.29305499792099,
        "train_loss": 3.049447536468506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15690,
        "tokens": 8226078720,
        "learning_rate": 0.0003251448029931394,
        "gradient_norm": 0.30699461698532104,
        "train_loss": 3.0805160999298096,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15691,
        "tokens": 8226603008,
        "learning_rate": 0.0003251161618782545,
        "gradient_norm": 0.31119000911712646,
        "train_loss": 3.0952181816101074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15692,
        "tokens": 8227127296,
        "learning_rate": 0.0003250875208183433,
        "gradient_norm": 0.31928765773773193,
        "train_loss": 3.0701849460601807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15693,
        "tokens": 8227651584,
        "learning_rate": 0.00032505887981372814,
        "gradient_norm": 0.3439914584159851,
        "train_loss": 3.06835675239563,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15694,
        "tokens": 8228175872,
        "learning_rate": 0.00032503023886473157,
        "gradient_norm": 0.3216313421726227,
        "train_loss": 3.043788194656372,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15695,
        "tokens": 8228700160,
        "learning_rate": 0.0003250015979716757,
        "gradient_norm": 0.2842000722885132,
        "train_loss": 2.9540939331054688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15696,
        "tokens": 8229224448,
        "learning_rate": 0.0003249729571348832,
        "gradient_norm": 0.3204960823059082,
        "train_loss": 3.04740047454834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15697,
        "tokens": 8229748736,
        "learning_rate": 0.00032494431635467626,
        "gradient_norm": 0.31022214889526367,
        "train_loss": 3.0327324867248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15698,
        "tokens": 8230273024,
        "learning_rate": 0.0003249156756313774,
        "gradient_norm": 0.3125746250152588,
        "train_loss": 3.1379382610321045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15699,
        "tokens": 8230797312,
        "learning_rate": 0.0003248870349653089,
        "gradient_norm": 0.29719918966293335,
        "train_loss": 3.0879547595977783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15700,
        "tokens": 8231321600,
        "learning_rate": 0.00032485839435679323,
        "gradient_norm": 0.31915509700775146,
        "train_loss": 3.0522141456604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15701,
        "tokens": 8231845888,
        "learning_rate": 0.0003248297538061527,
        "gradient_norm": 0.2874755859375,
        "train_loss": 3.069974422454834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15702,
        "tokens": 8232370176,
        "learning_rate": 0.0003248011133137098,
        "gradient_norm": 0.30594703555107117,
        "train_loss": 3.062990188598633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15703,
        "tokens": 8232894464,
        "learning_rate": 0.0003247724728797868,
        "gradient_norm": 0.294736385345459,
        "train_loss": 3.046721935272217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15704,
        "tokens": 8233418752,
        "learning_rate": 0.0003247438325047061,
        "gradient_norm": 0.30533456802368164,
        "train_loss": 3.0676050186157227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15705,
        "tokens": 8233943040,
        "learning_rate": 0.0003247151921887902,
        "gradient_norm": 0.30259594321250916,
        "train_loss": 3.0732507705688477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15706,
        "tokens": 8234467328,
        "learning_rate": 0.0003246865519323614,
        "gradient_norm": 0.3192526400089264,
        "train_loss": 3.070598602294922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15707,
        "tokens": 8234991616,
        "learning_rate": 0.000324657911735742,
        "gradient_norm": 0.322630375623703,
        "train_loss": 3.1302201747894287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15708,
        "tokens": 8235515904,
        "learning_rate": 0.00032462927159925453,
        "gradient_norm": 0.3215499222278595,
        "train_loss": 3.0711357593536377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15709,
        "tokens": 8236040192,
        "learning_rate": 0.0003246006315232213,
        "gradient_norm": 0.3152255713939667,
        "train_loss": 3.104391098022461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15710,
        "tokens": 8236564480,
        "learning_rate": 0.00032457199150796466,
        "gradient_norm": 0.3165898621082306,
        "train_loss": 3.131615161895752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15711,
        "tokens": 8237088768,
        "learning_rate": 0.000324543351553807,
        "gradient_norm": 0.31625035405158997,
        "train_loss": 3.0779547691345215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15712,
        "tokens": 8237613056,
        "learning_rate": 0.00032451471166107076,
        "gradient_norm": 0.36423003673553467,
        "train_loss": 3.0195565223693848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15713,
        "tokens": 8238137344,
        "learning_rate": 0.00032448607183007826,
        "gradient_norm": 0.31275323033332825,
        "train_loss": 3.1062276363372803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15714,
        "tokens": 8238661632,
        "learning_rate": 0.00032445743206115194,
        "gradient_norm": 0.3621513843536377,
        "train_loss": 3.113328456878662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15715,
        "tokens": 8239185920,
        "learning_rate": 0.0003244287923546141,
        "gradient_norm": 0.3174845576286316,
        "train_loss": 3.094907283782959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15716,
        "tokens": 8239710208,
        "learning_rate": 0.0003244001527107871,
        "gradient_norm": 0.34773945808410645,
        "train_loss": 3.061201572418213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15717,
        "tokens": 8240234496,
        "learning_rate": 0.00032437151312999347,
        "gradient_norm": 0.2932009696960449,
        "train_loss": 3.1397864818573,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15718,
        "tokens": 8240758784,
        "learning_rate": 0.0003243428736125553,
        "gradient_norm": 0.33898410201072693,
        "train_loss": 3.0694761276245117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15719,
        "tokens": 8241283072,
        "learning_rate": 0.0003243142341587953,
        "gradient_norm": 0.3055543005466461,
        "train_loss": 3.146702289581299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15720,
        "tokens": 8241807360,
        "learning_rate": 0.0003242855947690356,
        "gradient_norm": 0.3728179335594177,
        "train_loss": 3.136380672454834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15721,
        "tokens": 8242331648,
        "learning_rate": 0.0003242569554435988,
        "gradient_norm": 0.32590657472610474,
        "train_loss": 3.071712017059326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15722,
        "tokens": 8242855936,
        "learning_rate": 0.0003242283161828069,
        "gradient_norm": 0.29780662059783936,
        "train_loss": 3.0487396717071533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15723,
        "tokens": 8243380224,
        "learning_rate": 0.0003241996769869827,
        "gradient_norm": 0.339568555355072,
        "train_loss": 3.0733654499053955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15724,
        "tokens": 8243904512,
        "learning_rate": 0.00032417103785644817,
        "gradient_norm": 0.2947080731391907,
        "train_loss": 3.060335159301758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15725,
        "tokens": 8244428800,
        "learning_rate": 0.0003241423987915259,
        "gradient_norm": 0.33351394534111023,
        "train_loss": 3.116614818572998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15726,
        "tokens": 8244953088,
        "learning_rate": 0.0003241137597925384,
        "gradient_norm": 0.31086376309394836,
        "train_loss": 3.0383987426757812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15727,
        "tokens": 8245477376,
        "learning_rate": 0.0003240851208598078,
        "gradient_norm": 0.3360910415649414,
        "train_loss": 3.058651924133301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15728,
        "tokens": 8246001664,
        "learning_rate": 0.00032405648199365655,
        "gradient_norm": 0.32986485958099365,
        "train_loss": 3.102451801300049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15729,
        "tokens": 8246525952,
        "learning_rate": 0.0003240278431944069,
        "gradient_norm": 0.3311765789985657,
        "train_loss": 3.110704183578491,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15730,
        "tokens": 8247050240,
        "learning_rate": 0.0003239992044623815,
        "gradient_norm": 0.32973480224609375,
        "train_loss": 3.1164023876190186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15731,
        "tokens": 8247574528,
        "learning_rate": 0.0003239705657979023,
        "gradient_norm": 0.31449979543685913,
        "train_loss": 3.1012890338897705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15732,
        "tokens": 8248098816,
        "learning_rate": 0.0003239419272012921,
        "gradient_norm": 0.308960884809494,
        "train_loss": 3.1281626224517822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15733,
        "tokens": 8248623104,
        "learning_rate": 0.00032391328867287293,
        "gradient_norm": 0.3056269586086273,
        "train_loss": 3.1416497230529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15734,
        "tokens": 8249147392,
        "learning_rate": 0.00032388465021296743,
        "gradient_norm": 0.31199437379837036,
        "train_loss": 3.1282639503479004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15735,
        "tokens": 8249671680,
        "learning_rate": 0.00032385601182189765,
        "gradient_norm": 0.3516731858253479,
        "train_loss": 3.2412445545196533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15736,
        "tokens": 8250195968,
        "learning_rate": 0.00032382737349998615,
        "gradient_norm": 0.3130870759487152,
        "train_loss": 3.07012939453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15737,
        "tokens": 8250720256,
        "learning_rate": 0.00032379873524755536,
        "gradient_norm": 0.30940383672714233,
        "train_loss": 3.083566188812256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15738,
        "tokens": 8251244544,
        "learning_rate": 0.0003237700970649274,
        "gradient_norm": 0.2932395339012146,
        "train_loss": 3.115893840789795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15739,
        "tokens": 8251768832,
        "learning_rate": 0.0003237414589524249,
        "gradient_norm": 0.31735700368881226,
        "train_loss": 3.0717129707336426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15740,
        "tokens": 8252293120,
        "learning_rate": 0.00032371282091037,
        "gradient_norm": 0.5283472537994385,
        "train_loss": 3.097227096557617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15741,
        "tokens": 8252817408,
        "learning_rate": 0.0003236841829390852,
        "gradient_norm": 0.5402923822402954,
        "train_loss": 3.1129071712493896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15742,
        "tokens": 8253341696,
        "learning_rate": 0.00032365554503889266,
        "gradient_norm": 0.3554961085319519,
        "train_loss": 3.0737075805664062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15743,
        "tokens": 8253865984,
        "learning_rate": 0.00032362690721011506,
        "gradient_norm": 0.4300013482570648,
        "train_loss": 3.1291089057922363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15744,
        "tokens": 8254390272,
        "learning_rate": 0.0003235982694530744,
        "gradient_norm": 0.401147723197937,
        "train_loss": 3.0863471031188965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15745,
        "tokens": 8254914560,
        "learning_rate": 0.0003235696317680932,
        "gradient_norm": 0.3696106970310211,
        "train_loss": 3.0532851219177246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15746,
        "tokens": 8255438848,
        "learning_rate": 0.0003235409941554939,
        "gradient_norm": 0.359993577003479,
        "train_loss": 3.0591132640838623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15747,
        "tokens": 8255963136,
        "learning_rate": 0.0003235123566155987,
        "gradient_norm": 0.3648752272129059,
        "train_loss": 3.032618522644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15748,
        "tokens": 8256487424,
        "learning_rate": 0.0003234837191487301,
        "gradient_norm": 0.3066219091415405,
        "train_loss": 3.0919148921966553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15749,
        "tokens": 8257011712,
        "learning_rate": 0.00032345508175521024,
        "gradient_norm": 0.3407250940799713,
        "train_loss": 3.092545509338379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15750,
        "tokens": 8257536000,
        "learning_rate": 0.00032342644443536175,
        "gradient_norm": 0.2916162610054016,
        "train_loss": 3.032099723815918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15751,
        "tokens": 8258060288,
        "learning_rate": 0.00032339780718950665,
        "gradient_norm": 0.3218332529067993,
        "train_loss": 3.0464367866516113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15752,
        "tokens": 8258584576,
        "learning_rate": 0.00032336917001796764,
        "gradient_norm": 0.304476261138916,
        "train_loss": 3.0262608528137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15753,
        "tokens": 8259108864,
        "learning_rate": 0.00032334053292106674,
        "gradient_norm": 0.32921311259269714,
        "train_loss": 3.135830879211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15754,
        "tokens": 8259633152,
        "learning_rate": 0.00032331189589912654,
        "gradient_norm": 0.34450405836105347,
        "train_loss": 3.0559306144714355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15755,
        "tokens": 8260157440,
        "learning_rate": 0.00032328325895246917,
        "gradient_norm": 0.31349673867225647,
        "train_loss": 3.0573246479034424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15756,
        "tokens": 8260681728,
        "learning_rate": 0.0003232546220814172,
        "gradient_norm": 0.3056652545928955,
        "train_loss": 3.0716724395751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15757,
        "tokens": 8261206016,
        "learning_rate": 0.00032322598528629283,
        "gradient_norm": 0.311325341463089,
        "train_loss": 3.1087145805358887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15758,
        "tokens": 8261730304,
        "learning_rate": 0.0003231973485674184,
        "gradient_norm": 0.31956401467323303,
        "train_loss": 3.1294162273406982,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15759,
        "tokens": 8262254592,
        "learning_rate": 0.00032316871192511633,
        "gradient_norm": 0.29409465193748474,
        "train_loss": 3.078423023223877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15760,
        "tokens": 8262778880,
        "learning_rate": 0.00032314007535970895,
        "gradient_norm": 0.29380467534065247,
        "train_loss": 3.088913917541504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15761,
        "tokens": 8263303168,
        "learning_rate": 0.00032311143887151856,
        "gradient_norm": 0.3128219544887543,
        "train_loss": 3.102949380874634,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15762,
        "tokens": 8263827456,
        "learning_rate": 0.0003230828024608675,
        "gradient_norm": 0.2783184349536896,
        "train_loss": 3.107215404510498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15763,
        "tokens": 8264351744,
        "learning_rate": 0.0003230541661280781,
        "gradient_norm": 0.3112640678882599,
        "train_loss": 3.0811262130737305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15764,
        "tokens": 8264876032,
        "learning_rate": 0.00032302552987347274,
        "gradient_norm": 0.271180123090744,
        "train_loss": 3.054161548614502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15765,
        "tokens": 8265400320,
        "learning_rate": 0.0003229968936973737,
        "gradient_norm": 0.3307841718196869,
        "train_loss": 3.1521029472351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15766,
        "tokens": 8265924608,
        "learning_rate": 0.00032296825760010344,
        "gradient_norm": 0.33256253600120544,
        "train_loss": 3.114258289337158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15767,
        "tokens": 8266448896,
        "learning_rate": 0.0003229396215819841,
        "gradient_norm": 0.33118489384651184,
        "train_loss": 3.052725315093994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15768,
        "tokens": 8266973184,
        "learning_rate": 0.00032291098564333825,
        "gradient_norm": 0.3495071232318878,
        "train_loss": 3.0477676391601562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15769,
        "tokens": 8267497472,
        "learning_rate": 0.00032288234978448797,
        "gradient_norm": 0.28591984510421753,
        "train_loss": 2.999699115753174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15770,
        "tokens": 8268021760,
        "learning_rate": 0.0003228537140057558,
        "gradient_norm": 0.3267756402492523,
        "train_loss": 3.0686066150665283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15771,
        "tokens": 8268546048,
        "learning_rate": 0.00032282507830746387,
        "gradient_norm": 0.32147496938705444,
        "train_loss": 3.058102607727051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15772,
        "tokens": 8269070336,
        "learning_rate": 0.0003227964426899348,
        "gradient_norm": 0.3400053083896637,
        "train_loss": 3.1298704147338867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15773,
        "tokens": 8269594624,
        "learning_rate": 0.0003227678071534906,
        "gradient_norm": 0.2946917712688446,
        "train_loss": 3.0533547401428223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15774,
        "tokens": 8270118912,
        "learning_rate": 0.00032273917169845385,
        "gradient_norm": 0.2967430651187897,
        "train_loss": 3.0323314666748047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15775,
        "tokens": 8270643200,
        "learning_rate": 0.00032271053632514665,
        "gradient_norm": 0.2916059195995331,
        "train_loss": 3.0514795780181885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15776,
        "tokens": 8271167488,
        "learning_rate": 0.0003226819010338915,
        "gradient_norm": 0.30919766426086426,
        "train_loss": 3.080277681350708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15777,
        "tokens": 8271691776,
        "learning_rate": 0.0003226532658250107,
        "gradient_norm": 0.3040107488632202,
        "train_loss": 3.0998733043670654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15778,
        "tokens": 8272216064,
        "learning_rate": 0.00032262463069882653,
        "gradient_norm": 0.3247179388999939,
        "train_loss": 3.058227777481079,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15779,
        "tokens": 8272740352,
        "learning_rate": 0.00032259599565566144,
        "gradient_norm": 0.2922999858856201,
        "train_loss": 3.0570566654205322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15780,
        "tokens": 8273264640,
        "learning_rate": 0.00032256736069583746,
        "gradient_norm": 0.33230939507484436,
        "train_loss": 3.1625378131866455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15781,
        "tokens": 8273788928,
        "learning_rate": 0.0003225387258196773,
        "gradient_norm": 0.3000350892543793,
        "train_loss": 3.02754282951355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15782,
        "tokens": 8274313216,
        "learning_rate": 0.00032251009102750295,
        "gradient_norm": 0.3045148551464081,
        "train_loss": 3.086268663406372,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15783,
        "tokens": 8274837504,
        "learning_rate": 0.0003224814563196369,
        "gradient_norm": 0.2928713858127594,
        "train_loss": 3.026702404022217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15784,
        "tokens": 8275361792,
        "learning_rate": 0.0003224528216964014,
        "gradient_norm": 0.31840378046035767,
        "train_loss": 3.0504703521728516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15785,
        "tokens": 8275886080,
        "learning_rate": 0.0003224241871581188,
        "gradient_norm": 0.3810994625091553,
        "train_loss": 3.059457540512085,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15786,
        "tokens": 8276410368,
        "learning_rate": 0.00032239555270511145,
        "gradient_norm": 0.29196155071258545,
        "train_loss": 3.0119500160217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15787,
        "tokens": 8276934656,
        "learning_rate": 0.0003223669183377016,
        "gradient_norm": 0.3130491077899933,
        "train_loss": 3.0439014434814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15788,
        "tokens": 8277458944,
        "learning_rate": 0.0003223382840562117,
        "gradient_norm": 0.30258142948150635,
        "train_loss": 3.0673458576202393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15789,
        "tokens": 8277983232,
        "learning_rate": 0.0003223096498609638,
        "gradient_norm": 0.3042493164539337,
        "train_loss": 3.0411481857299805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15790,
        "tokens": 8278507520,
        "learning_rate": 0.00032228101575228056,
        "gradient_norm": 0.2981838583946228,
        "train_loss": 3.163912057876587,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15791,
        "tokens": 8279031808,
        "learning_rate": 0.00032225238173048395,
        "gradient_norm": 0.3251562714576721,
        "train_loss": 3.095227003097534,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15792,
        "tokens": 8279556096,
        "learning_rate": 0.00032222374779589656,
        "gradient_norm": 0.30980244278907776,
        "train_loss": 3.054112195968628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15793,
        "tokens": 8280080384,
        "learning_rate": 0.0003221951139488405,
        "gradient_norm": 0.2927698493003845,
        "train_loss": 3.0164248943328857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15794,
        "tokens": 8280604672,
        "learning_rate": 0.00032216648018963825,
        "gradient_norm": 0.28891807794570923,
        "train_loss": 3.01218318939209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15795,
        "tokens": 8281128960,
        "learning_rate": 0.0003221378465186119,
        "gradient_norm": 0.29192861914634705,
        "train_loss": 3.0816879272460938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15796,
        "tokens": 8281653248,
        "learning_rate": 0.00032210921293608386,
        "gradient_norm": 0.2933638393878937,
        "train_loss": 3.109386444091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15797,
        "tokens": 8282177536,
        "learning_rate": 0.00032208057944237665,
        "gradient_norm": 0.29795435070991516,
        "train_loss": 3.106966972351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15798,
        "tokens": 8282701824,
        "learning_rate": 0.0003220519460378123,
        "gradient_norm": 0.2965954840183258,
        "train_loss": 3.0753111839294434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15799,
        "tokens": 8283226112,
        "learning_rate": 0.00032202331272271323,
        "gradient_norm": 0.2963680922985077,
        "train_loss": 3.1016016006469727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15800,
        "tokens": 8283750400,
        "learning_rate": 0.00032199467949740163,
        "gradient_norm": 0.28092893958091736,
        "train_loss": 3.0560851097106934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15801,
        "tokens": 8284274688,
        "learning_rate": 0.0003219660463622,
        "gradient_norm": 0.3274025022983551,
        "train_loss": 3.071803331375122,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15802,
        "tokens": 8284798976,
        "learning_rate": 0.00032193741331743047,
        "gradient_norm": 0.2896084487438202,
        "train_loss": 3.074165105819702,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15803,
        "tokens": 8285323264,
        "learning_rate": 0.00032190878036341547,
        "gradient_norm": 0.3123665750026703,
        "train_loss": 3.0865793228149414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15804,
        "tokens": 8285847552,
        "learning_rate": 0.00032188014750047714,
        "gradient_norm": 0.2932773530483246,
        "train_loss": 3.081181049346924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15805,
        "tokens": 8286371840,
        "learning_rate": 0.0003218515147289379,
        "gradient_norm": 0.30334872007369995,
        "train_loss": 2.9953670501708984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15806,
        "tokens": 8286896128,
        "learning_rate": 0.0003218228820491201,
        "gradient_norm": 0.29669389128685,
        "train_loss": 3.065645217895508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15807,
        "tokens": 8287420416,
        "learning_rate": 0.00032179424946134587,
        "gradient_norm": 0.29239726066589355,
        "train_loss": 3.0944719314575195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15808,
        "tokens": 8287944704,
        "learning_rate": 0.0003217656169659376,
        "gradient_norm": 0.3173767626285553,
        "train_loss": 3.013716459274292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15809,
        "tokens": 8288468992,
        "learning_rate": 0.0003217369845632176,
        "gradient_norm": 0.26043128967285156,
        "train_loss": 3.0807504653930664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15810,
        "tokens": 8288993280,
        "learning_rate": 0.00032170835225350813,
        "gradient_norm": 0.2927522659301758,
        "train_loss": 3.0692036151885986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15811,
        "tokens": 8289517568,
        "learning_rate": 0.0003216797200371315,
        "gradient_norm": 0.2750115394592285,
        "train_loss": 3.0775489807128906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15812,
        "tokens": 8290041856,
        "learning_rate": 0.00032165108791440996,
        "gradient_norm": 0.3239035904407501,
        "train_loss": 3.1001129150390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15813,
        "tokens": 8290566144,
        "learning_rate": 0.0003216224558856659,
        "gradient_norm": 0.2983216643333435,
        "train_loss": 3.1463847160339355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15814,
        "tokens": 8291090432,
        "learning_rate": 0.0003215938239512215,
        "gradient_norm": 0.31645381450653076,
        "train_loss": 3.0643815994262695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15815,
        "tokens": 8291614720,
        "learning_rate": 0.00032156519211139906,
        "gradient_norm": 0.3096887469291687,
        "train_loss": 3.1335391998291016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15816,
        "tokens": 8292139008,
        "learning_rate": 0.0003215365603665209,
        "gradient_norm": 0.3312504291534424,
        "train_loss": 3.0949795246124268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15817,
        "tokens": 8292663296,
        "learning_rate": 0.0003215079287169094,
        "gradient_norm": 0.31579768657684326,
        "train_loss": 3.0454349517822266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15818,
        "tokens": 8293187584,
        "learning_rate": 0.0003214792971628866,
        "gradient_norm": 0.34088829159736633,
        "train_loss": 3.1357555389404297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15819,
        "tokens": 8293711872,
        "learning_rate": 0.0003214506657047751,
        "gradient_norm": 0.3226417601108551,
        "train_loss": 3.0633435249328613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15820,
        "tokens": 8294236160,
        "learning_rate": 0.0003214220343428968,
        "gradient_norm": 0.28314852714538574,
        "train_loss": 3.155308723449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15821,
        "tokens": 8294760448,
        "learning_rate": 0.0003213934030775744,
        "gradient_norm": 0.32999733090400696,
        "train_loss": 3.117079257965088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15822,
        "tokens": 8295284736,
        "learning_rate": 0.00032136477190912986,
        "gradient_norm": 0.2986305058002472,
        "train_loss": 3.1250391006469727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15823,
        "tokens": 8295809024,
        "learning_rate": 0.00032133614083788565,
        "gradient_norm": 0.35226568579673767,
        "train_loss": 3.097999095916748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15824,
        "tokens": 8296333312,
        "learning_rate": 0.0003213075098641639,
        "gradient_norm": 0.2790471911430359,
        "train_loss": 3.1461708545684814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15825,
        "tokens": 8296857600,
        "learning_rate": 0.0003212788789882869,
        "gradient_norm": 0.3146822452545166,
        "train_loss": 3.096112012863159,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15826,
        "tokens": 8297381888,
        "learning_rate": 0.0003212502482105772,
        "gradient_norm": 0.2856835126876831,
        "train_loss": 3.1075034141540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15827,
        "tokens": 8297906176,
        "learning_rate": 0.0003212216175313567,
        "gradient_norm": 0.321231871843338,
        "train_loss": 3.0648789405822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15828,
        "tokens": 8298430464,
        "learning_rate": 0.0003211929869509479,
        "gradient_norm": 0.29669007658958435,
        "train_loss": 3.1105809211730957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15829,
        "tokens": 8298954752,
        "learning_rate": 0.000321164356469673,
        "gradient_norm": 0.3093816637992859,
        "train_loss": 3.042300224304199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15830,
        "tokens": 8299479040,
        "learning_rate": 0.0003211357260878543,
        "gradient_norm": 0.32183951139450073,
        "train_loss": 3.0867016315460205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15831,
        "tokens": 8300003328,
        "learning_rate": 0.00032110709580581397,
        "gradient_norm": 0.3180798292160034,
        "train_loss": 3.1108644008636475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15832,
        "tokens": 8300527616,
        "learning_rate": 0.0003210784656238745,
        "gradient_norm": 0.32341688871383667,
        "train_loss": 3.0842809677124023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15833,
        "tokens": 8301051904,
        "learning_rate": 0.0003210498355423579,
        "gradient_norm": 0.32926493883132935,
        "train_loss": 3.0865120887756348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15834,
        "tokens": 8301576192,
        "learning_rate": 0.00032102120556158663,
        "gradient_norm": 0.3433757424354553,
        "train_loss": 3.125669479370117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15835,
        "tokens": 8302100480,
        "learning_rate": 0.0003209925756818828,
        "gradient_norm": 0.322724312543869,
        "train_loss": 3.068471908569336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15836,
        "tokens": 8302624768,
        "learning_rate": 0.00032096394590356875,
        "gradient_norm": 0.29753655195236206,
        "train_loss": 3.1197309494018555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15837,
        "tokens": 8303149056,
        "learning_rate": 0.0003209353162269669,
        "gradient_norm": 0.3023103177547455,
        "train_loss": 3.0862996578216553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15838,
        "tokens": 8303673344,
        "learning_rate": 0.0003209066866523992,
        "gradient_norm": 0.32530999183654785,
        "train_loss": 3.0815582275390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15839,
        "tokens": 8304197632,
        "learning_rate": 0.00032087805718018824,
        "gradient_norm": 0.28078630566596985,
        "train_loss": 3.010812759399414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15840,
        "tokens": 8304721920,
        "learning_rate": 0.000320849427810656,
        "gradient_norm": 0.31733807921409607,
        "train_loss": 3.098461627960205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15841,
        "tokens": 8305246208,
        "learning_rate": 0.00032082079854412496,
        "gradient_norm": 0.3096652925014496,
        "train_loss": 3.1704583168029785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15842,
        "tokens": 8305770496,
        "learning_rate": 0.00032079216938091714,
        "gradient_norm": 0.3125373125076294,
        "train_loss": 3.1333775520324707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15843,
        "tokens": 8306294784,
        "learning_rate": 0.00032076354032135505,
        "gradient_norm": 0.28969821333885193,
        "train_loss": 3.1386208534240723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15844,
        "tokens": 8306819072,
        "learning_rate": 0.0003207349113657607,
        "gradient_norm": 0.2985106110572815,
        "train_loss": 3.138683795928955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15845,
        "tokens": 8307343360,
        "learning_rate": 0.0003207062825144565,
        "gradient_norm": 0.31489551067352295,
        "train_loss": 3.091810703277588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15846,
        "tokens": 8307867648,
        "learning_rate": 0.0003206776537677648,
        "gradient_norm": 0.30987823009490967,
        "train_loss": 3.120217800140381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15847,
        "tokens": 8308391936,
        "learning_rate": 0.00032064902512600756,
        "gradient_norm": 0.28539571166038513,
        "train_loss": 3.104982614517212,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15848,
        "tokens": 8308916224,
        "learning_rate": 0.00032062039658950736,
        "gradient_norm": 0.2918696999549866,
        "train_loss": 3.037665605545044,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15849,
        "tokens": 8309440512,
        "learning_rate": 0.00032059176815858617,
        "gradient_norm": 0.303611159324646,
        "train_loss": 3.0860955715179443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15850,
        "tokens": 8309964800,
        "learning_rate": 0.0003205631398335665,
        "gradient_norm": 0.3034685254096985,
        "train_loss": 3.135040283203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15851,
        "tokens": 8310489088,
        "learning_rate": 0.0003205345116147703,
        "gradient_norm": 0.2879931628704071,
        "train_loss": 3.096355676651001,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15852,
        "tokens": 8311013376,
        "learning_rate": 0.00032050588350252007,
        "gradient_norm": 0.32524967193603516,
        "train_loss": 3.1372861862182617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15853,
        "tokens": 8311537664,
        "learning_rate": 0.0003204772554971378,
        "gradient_norm": 0.3091786503791809,
        "train_loss": 3.1738314628601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15854,
        "tokens": 8312061952,
        "learning_rate": 0.0003204486275989461,
        "gradient_norm": 0.324807345867157,
        "train_loss": 3.183931827545166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15855,
        "tokens": 8312586240,
        "learning_rate": 0.0003204199998082669,
        "gradient_norm": 0.3342052102088928,
        "train_loss": 3.0719499588012695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15856,
        "tokens": 8313110528,
        "learning_rate": 0.00032039137212542255,
        "gradient_norm": 0.33259546756744385,
        "train_loss": 3.0417065620422363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15857,
        "tokens": 8313634816,
        "learning_rate": 0.0003203627445507352,
        "gradient_norm": 0.3081800639629364,
        "train_loss": 3.1151609420776367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15858,
        "tokens": 8314159104,
        "learning_rate": 0.0003203341170845273,
        "gradient_norm": 0.3841612637042999,
        "train_loss": 3.128502607345581,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15859,
        "tokens": 8314683392,
        "learning_rate": 0.00032030548972712095,
        "gradient_norm": 0.3697771430015564,
        "train_loss": 3.1284689903259277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15860,
        "tokens": 8315207680,
        "learning_rate": 0.0003202768624788384,
        "gradient_norm": 0.3183833956718445,
        "train_loss": 3.0732991695404053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15861,
        "tokens": 8315731968,
        "learning_rate": 0.0003202482353400018,
        "gradient_norm": 0.34902721643447876,
        "train_loss": 3.111379623413086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15862,
        "tokens": 8316256256,
        "learning_rate": 0.00032021960831093353,
        "gradient_norm": 0.2997669577598572,
        "train_loss": 3.118967056274414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15863,
        "tokens": 8316780544,
        "learning_rate": 0.00032019098139195575,
        "gradient_norm": 0.32689353823661804,
        "train_loss": 3.061990737915039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15864,
        "tokens": 8317304832,
        "learning_rate": 0.00032016235458339073,
        "gradient_norm": 0.30762889981269836,
        "train_loss": 3.092637062072754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15865,
        "tokens": 8317829120,
        "learning_rate": 0.00032013372788556053,
        "gradient_norm": 0.3103024363517761,
        "train_loss": 3.0889809131622314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15866,
        "tokens": 8318353408,
        "learning_rate": 0.0003201051012987877,
        "gradient_norm": 0.33568042516708374,
        "train_loss": 3.149610996246338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15867,
        "tokens": 8318877696,
        "learning_rate": 0.0003200764748233942,
        "gradient_norm": 0.3023186922073364,
        "train_loss": 3.0945353507995605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15868,
        "tokens": 8319401984,
        "learning_rate": 0.0003200478484597024,
        "gradient_norm": 0.30426087975502014,
        "train_loss": 3.090423583984375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15869,
        "tokens": 8319926272,
        "learning_rate": 0.00032001922220803436,
        "gradient_norm": 0.3157757818698883,
        "train_loss": 3.1331472396850586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15870,
        "tokens": 8320450560,
        "learning_rate": 0.0003199905960687126,
        "gradient_norm": 0.30473601818084717,
        "train_loss": 3.128765106201172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15871,
        "tokens": 8320974848,
        "learning_rate": 0.000319961970042059,
        "gradient_norm": 0.303084135055542,
        "train_loss": 3.0939793586730957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15872,
        "tokens": 8321499136,
        "learning_rate": 0.00031993334412839603,
        "gradient_norm": 0.2743389904499054,
        "train_loss": 3.113424301147461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15873,
        "tokens": 8322023424,
        "learning_rate": 0.00031990471832804573,
        "gradient_norm": 0.27474892139434814,
        "train_loss": 3.0776078701019287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15874,
        "tokens": 8322547712,
        "learning_rate": 0.0003198760926413305,
        "gradient_norm": 0.26881977915763855,
        "train_loss": 3.0708985328674316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15875,
        "tokens": 8323072000,
        "learning_rate": 0.0003198474670685724,
        "gradient_norm": 0.276752233505249,
        "train_loss": 3.070937156677246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15876,
        "tokens": 8323596288,
        "learning_rate": 0.0003198188416100937,
        "gradient_norm": 0.31517964601516724,
        "train_loss": 3.1054835319519043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15877,
        "tokens": 8324120576,
        "learning_rate": 0.0003197902162662167,
        "gradient_norm": 0.3101446330547333,
        "train_loss": 3.08205509185791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15878,
        "tokens": 8324644864,
        "learning_rate": 0.00031976159103726346,
        "gradient_norm": 0.3022288382053375,
        "train_loss": 3.079845666885376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15879,
        "tokens": 8325169152,
        "learning_rate": 0.0003197329659235564,
        "gradient_norm": 0.3176957964897156,
        "train_loss": 3.0599753856658936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15880,
        "tokens": 8325693440,
        "learning_rate": 0.0003197043409254175,
        "gradient_norm": 0.2843775749206543,
        "train_loss": 3.0410685539245605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15881,
        "tokens": 8326217728,
        "learning_rate": 0.0003196757160431692,
        "gradient_norm": 0.30657675862312317,
        "train_loss": 3.0958757400512695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15882,
        "tokens": 8326742016,
        "learning_rate": 0.0003196470912771334,
        "gradient_norm": 0.30300796031951904,
        "train_loss": 3.1435468196868896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15883,
        "tokens": 8327266304,
        "learning_rate": 0.00031961846662763267,
        "gradient_norm": 0.29342055320739746,
        "train_loss": 3.093822479248047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15884,
        "tokens": 8327790592,
        "learning_rate": 0.0003195898420949889,
        "gradient_norm": 0.3305230140686035,
        "train_loss": 3.12286376953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15885,
        "tokens": 8328314880,
        "learning_rate": 0.00031956121767952447,
        "gradient_norm": 0.3072073757648468,
        "train_loss": 3.102451801300049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15886,
        "tokens": 8328839168,
        "learning_rate": 0.00031953259338156164,
        "gradient_norm": 0.3377726078033447,
        "train_loss": 3.0727386474609375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15887,
        "tokens": 8329363456,
        "learning_rate": 0.00031950396920142236,
        "gradient_norm": 0.3622143268585205,
        "train_loss": 3.149857997894287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15888,
        "tokens": 8329887744,
        "learning_rate": 0.00031947534513942913,
        "gradient_norm": 0.3417658507823944,
        "train_loss": 3.147630453109741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15889,
        "tokens": 8330412032,
        "learning_rate": 0.0003194467211959039,
        "gradient_norm": 0.41378095746040344,
        "train_loss": 3.1253466606140137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15890,
        "tokens": 8330936320,
        "learning_rate": 0.00031941809737116915,
        "gradient_norm": 0.3256267309188843,
        "train_loss": 3.0657620429992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15891,
        "tokens": 8331460608,
        "learning_rate": 0.00031938947366554673,
        "gradient_norm": 0.3874032199382782,
        "train_loss": 3.1192331314086914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15892,
        "tokens": 8331984896,
        "learning_rate": 0.0003193608500793591,
        "gradient_norm": 0.29515931010246277,
        "train_loss": 3.1371610164642334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15893,
        "tokens": 8332509184,
        "learning_rate": 0.0003193322266129283,
        "gradient_norm": 0.37161728739738464,
        "train_loss": 3.092299461364746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15894,
        "tokens": 8333033472,
        "learning_rate": 0.00031930360326657667,
        "gradient_norm": 0.2917880117893219,
        "train_loss": 3.1114726066589355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15895,
        "tokens": 8333557760,
        "learning_rate": 0.0003192749800406262,
        "gradient_norm": 0.3687584400177002,
        "train_loss": 3.122624158859253,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15896,
        "tokens": 8334082048,
        "learning_rate": 0.00031924635693539923,
        "gradient_norm": 0.3141612112522125,
        "train_loss": 3.092484474182129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15897,
        "tokens": 8334606336,
        "learning_rate": 0.00031921773395121806,
        "gradient_norm": 0.3743480443954468,
        "train_loss": 3.2499024868011475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15898,
        "tokens": 8335130624,
        "learning_rate": 0.0003191891110884046,
        "gradient_norm": 0.2968961000442505,
        "train_loss": 3.0887818336486816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15899,
        "tokens": 8335654912,
        "learning_rate": 0.00031916048834728126,
        "gradient_norm": 0.31488338112831116,
        "train_loss": 3.12187123298645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15900,
        "tokens": 8336179200,
        "learning_rate": 0.00031913186572817,
        "gradient_norm": 0.34272974729537964,
        "train_loss": 3.0588812828063965,
        "val_loss": 3.0657405853271484,
        "hellaswag_acc": 0.2800239026546478,
        "hellaswag_acc_norm": 0.29038041830062866
    },
    {
        "step": 15901,
        "tokens": 8336703488,
        "learning_rate": 0.0003191032432313933,
        "gradient_norm": 0.31278133392333984,
        "train_loss": 3.104922294616699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15902,
        "tokens": 8337227776,
        "learning_rate": 0.000319074620857273,
        "gradient_norm": 0.3083566427230835,
        "train_loss": 3.1071977615356445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15903,
        "tokens": 8337752064,
        "learning_rate": 0.00031904599860613166,
        "gradient_norm": 0.35693252086639404,
        "train_loss": 3.0688836574554443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15904,
        "tokens": 8338276352,
        "learning_rate": 0.0003190173764782911,
        "gradient_norm": 0.34880775213241577,
        "train_loss": 3.038438320159912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15905,
        "tokens": 8338800640,
        "learning_rate": 0.0003189887544740737,
        "gradient_norm": 0.35275548696517944,
        "train_loss": 3.094780921936035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15906,
        "tokens": 8339324928,
        "learning_rate": 0.00031896013259380163,
        "gradient_norm": 0.3141692280769348,
        "train_loss": 3.1186342239379883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15907,
        "tokens": 8339849216,
        "learning_rate": 0.00031893151083779703,
        "gradient_norm": 0.278242290019989,
        "train_loss": 3.071136951446533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15908,
        "tokens": 8340373504,
        "learning_rate": 0.00031890288920638206,
        "gradient_norm": 0.3094693720340729,
        "train_loss": 3.108017921447754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15909,
        "tokens": 8340897792,
        "learning_rate": 0.0003188742676998789,
        "gradient_norm": 0.2833409607410431,
        "train_loss": 3.0778136253356934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15910,
        "tokens": 8341422080,
        "learning_rate": 0.00031884564631860974,
        "gradient_norm": 0.3002690076828003,
        "train_loss": 3.0696451663970947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15911,
        "tokens": 8341946368,
        "learning_rate": 0.00031881702506289674,
        "gradient_norm": 0.28153905272483826,
        "train_loss": 3.0819311141967773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15912,
        "tokens": 8342470656,
        "learning_rate": 0.000318788403933062,
        "gradient_norm": 0.292512983083725,
        "train_loss": 3.0816662311553955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15913,
        "tokens": 8342994944,
        "learning_rate": 0.0003187597829294278,
        "gradient_norm": 0.29340192675590515,
        "train_loss": 3.1327972412109375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15914,
        "tokens": 8343519232,
        "learning_rate": 0.0003187311620523163,
        "gradient_norm": 0.2995562255382538,
        "train_loss": 3.086989164352417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15915,
        "tokens": 8344043520,
        "learning_rate": 0.00031870254130204954,
        "gradient_norm": 0.2861860692501068,
        "train_loss": 3.099315643310547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15916,
        "tokens": 8344567808,
        "learning_rate": 0.00031867392067894975,
        "gradient_norm": 0.3010123670101166,
        "train_loss": 3.094299793243408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15917,
        "tokens": 8345092096,
        "learning_rate": 0.0003186453001833391,
        "gradient_norm": 0.29485905170440674,
        "train_loss": 3.0935916900634766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15918,
        "tokens": 8345616384,
        "learning_rate": 0.00031861667981553977,
        "gradient_norm": 0.2770698666572571,
        "train_loss": 3.1381704807281494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15919,
        "tokens": 8346140672,
        "learning_rate": 0.000318588059575874,
        "gradient_norm": 0.29097017645835876,
        "train_loss": 3.0493617057800293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15920,
        "tokens": 8346664960,
        "learning_rate": 0.0003185594394646637,
        "gradient_norm": 0.2818724811077118,
        "train_loss": 3.0678248405456543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15921,
        "tokens": 8347189248,
        "learning_rate": 0.00031853081948223123,
        "gradient_norm": 0.3089410960674286,
        "train_loss": 3.1207427978515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15922,
        "tokens": 8347713536,
        "learning_rate": 0.0003185021996288987,
        "gradient_norm": 0.28708621859550476,
        "train_loss": 3.140498638153076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15923,
        "tokens": 8348237824,
        "learning_rate": 0.00031847357990498823,
        "gradient_norm": 0.3073529303073883,
        "train_loss": 3.0817365646362305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15924,
        "tokens": 8348762112,
        "learning_rate": 0.000318444960310822,
        "gradient_norm": 0.31344249844551086,
        "train_loss": 3.1423726081848145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15925,
        "tokens": 8349286400,
        "learning_rate": 0.00031841634084672207,
        "gradient_norm": 0.29045066237449646,
        "train_loss": 3.095792293548584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15926,
        "tokens": 8349810688,
        "learning_rate": 0.0003183877215130108,
        "gradient_norm": 0.315622478723526,
        "train_loss": 3.0747385025024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15927,
        "tokens": 8350334976,
        "learning_rate": 0.00031835910231001007,
        "gradient_norm": 0.31856343150138855,
        "train_loss": 3.0762505531311035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15928,
        "tokens": 8350859264,
        "learning_rate": 0.00031833048323804227,
        "gradient_norm": 0.29298731684684753,
        "train_loss": 3.0552821159362793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15929,
        "tokens": 8351383552,
        "learning_rate": 0.0003183018642974293,
        "gradient_norm": 0.32030150294303894,
        "train_loss": 3.129847526550293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15930,
        "tokens": 8351907840,
        "learning_rate": 0.00031827324548849357,
        "gradient_norm": 0.3051995635032654,
        "train_loss": 3.1595067977905273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15931,
        "tokens": 8352432128,
        "learning_rate": 0.00031824462681155695,
        "gradient_norm": 0.3324742317199707,
        "train_loss": 3.082159996032715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15932,
        "tokens": 8352956416,
        "learning_rate": 0.00031821600826694184,
        "gradient_norm": 0.33988404273986816,
        "train_loss": 3.0806384086608887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15933,
        "tokens": 8353480704,
        "learning_rate": 0.0003181873898549701,
        "gradient_norm": 0.31091612577438354,
        "train_loss": 3.1314737796783447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15934,
        "tokens": 8354004992,
        "learning_rate": 0.00031815877157596417,
        "gradient_norm": 0.32040515542030334,
        "train_loss": 3.113612651824951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15935,
        "tokens": 8354529280,
        "learning_rate": 0.00031813015343024585,
        "gradient_norm": 0.3480457663536072,
        "train_loss": 3.1145853996276855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15936,
        "tokens": 8355053568,
        "learning_rate": 0.0003181015354181375,
        "gradient_norm": 0.30746009945869446,
        "train_loss": 3.124314785003662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15937,
        "tokens": 8355577856,
        "learning_rate": 0.0003180729175399613,
        "gradient_norm": 0.3324924409389496,
        "train_loss": 3.041142463684082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15938,
        "tokens": 8356102144,
        "learning_rate": 0.00031804429979603914,
        "gradient_norm": 0.33070018887519836,
        "train_loss": 3.0721054077148438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15939,
        "tokens": 8356626432,
        "learning_rate": 0.0003180156821866934,
        "gradient_norm": 0.31664642691612244,
        "train_loss": 3.117116928100586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15940,
        "tokens": 8357150720,
        "learning_rate": 0.0003179870647122461,
        "gradient_norm": 0.3327920138835907,
        "train_loss": 3.080897092819214,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15941,
        "tokens": 8357675008,
        "learning_rate": 0.00031795844737301935,
        "gradient_norm": 0.2803037464618683,
        "train_loss": 3.08848237991333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15942,
        "tokens": 8358199296,
        "learning_rate": 0.0003179298301693352,
        "gradient_norm": 0.3615504205226898,
        "train_loss": 3.106753349304199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15943,
        "tokens": 8358723584,
        "learning_rate": 0.00031790121310151597,
        "gradient_norm": 0.26565057039260864,
        "train_loss": 3.0684304237365723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15944,
        "tokens": 8359247872,
        "learning_rate": 0.00031787259616988356,
        "gradient_norm": 0.35129913687705994,
        "train_loss": 3.136996269226074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15945,
        "tokens": 8359772160,
        "learning_rate": 0.0003178439793747602,
        "gradient_norm": 0.3335261046886444,
        "train_loss": 3.0761280059814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15946,
        "tokens": 8360296448,
        "learning_rate": 0.0003178153627164681,
        "gradient_norm": 0.3534071445465088,
        "train_loss": 3.1351962089538574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15947,
        "tokens": 8360820736,
        "learning_rate": 0.00031778674619532924,
        "gradient_norm": 0.3272167444229126,
        "train_loss": 3.1494414806365967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15948,
        "tokens": 8361345024,
        "learning_rate": 0.0003177581298116658,
        "gradient_norm": 0.3338068425655365,
        "train_loss": 3.0745511054992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15949,
        "tokens": 8361869312,
        "learning_rate": 0.0003177295135657998,
        "gradient_norm": 0.310508668422699,
        "train_loss": 3.061256170272827,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15950,
        "tokens": 8362393600,
        "learning_rate": 0.00031770089745805354,
        "gradient_norm": 0.2843819260597229,
        "train_loss": 3.121415376663208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15951,
        "tokens": 8362917888,
        "learning_rate": 0.0003176722814887489,
        "gradient_norm": 0.2985124886035919,
        "train_loss": 3.118452548980713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15952,
        "tokens": 8363442176,
        "learning_rate": 0.00031764366565820813,
        "gradient_norm": 0.29260504245758057,
        "train_loss": 3.0729994773864746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15953,
        "tokens": 8363966464,
        "learning_rate": 0.00031761504996675327,
        "gradient_norm": 0.3052837550640106,
        "train_loss": 3.102391242980957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15954,
        "tokens": 8364490752,
        "learning_rate": 0.0003175864344147066,
        "gradient_norm": 0.32804974913597107,
        "train_loss": 3.1486520767211914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15955,
        "tokens": 8365015040,
        "learning_rate": 0.0003175578190023899,
        "gradient_norm": 0.29077330231666565,
        "train_loss": 3.086209297180176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15956,
        "tokens": 8365539328,
        "learning_rate": 0.0003175292037301255,
        "gradient_norm": 0.3402920961380005,
        "train_loss": 3.078660726547241,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15957,
        "tokens": 8366063616,
        "learning_rate": 0.00031750058859823555,
        "gradient_norm": 0.29925116896629333,
        "train_loss": 3.0946311950683594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15958,
        "tokens": 8366587904,
        "learning_rate": 0.00031747197360704194,
        "gradient_norm": 0.3108884394168854,
        "train_loss": 3.1805102825164795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15959,
        "tokens": 8367112192,
        "learning_rate": 0.000317443358756867,
        "gradient_norm": 0.31081312894821167,
        "train_loss": 3.0134408473968506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15960,
        "tokens": 8367636480,
        "learning_rate": 0.00031741474404803257,
        "gradient_norm": 0.30778083205223083,
        "train_loss": 3.098647117614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15961,
        "tokens": 8368160768,
        "learning_rate": 0.00031738612948086105,
        "gradient_norm": 0.2857411205768585,
        "train_loss": 3.1271896362304688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15962,
        "tokens": 8368685056,
        "learning_rate": 0.00031735751505567426,
        "gradient_norm": 0.31778770685195923,
        "train_loss": 3.0985076427459717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15963,
        "tokens": 8369209344,
        "learning_rate": 0.0003173289007727945,
        "gradient_norm": 0.27561309933662415,
        "train_loss": 3.0589940547943115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15964,
        "tokens": 8369733632,
        "learning_rate": 0.0003173002866325436,
        "gradient_norm": 0.3064502775669098,
        "train_loss": 3.0575308799743652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15965,
        "tokens": 8370257920,
        "learning_rate": 0.0003172716726352439,
        "gradient_norm": 0.30773162841796875,
        "train_loss": 3.0961642265319824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15966,
        "tokens": 8370782208,
        "learning_rate": 0.00031724305878121735,
        "gradient_norm": 0.311715692281723,
        "train_loss": 3.076341152191162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15967,
        "tokens": 8371306496,
        "learning_rate": 0.0003172144450707861,
        "gradient_norm": 0.30835485458374023,
        "train_loss": 3.1422386169433594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15968,
        "tokens": 8371830784,
        "learning_rate": 0.0003171858315042722,
        "gradient_norm": 0.29175466299057007,
        "train_loss": 3.030714511871338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15969,
        "tokens": 8372355072,
        "learning_rate": 0.0003171572180819978,
        "gradient_norm": 0.28926917910575867,
        "train_loss": 3.1062428951263428,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15970,
        "tokens": 8372879360,
        "learning_rate": 0.00031712860480428485,
        "gradient_norm": 0.28350311517715454,
        "train_loss": 3.0904946327209473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15971,
        "tokens": 8373403648,
        "learning_rate": 0.00031709999167145556,
        "gradient_norm": 0.30078279972076416,
        "train_loss": 3.0997252464294434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15972,
        "tokens": 8373927936,
        "learning_rate": 0.0003170713786838319,
        "gradient_norm": 0.28679782152175903,
        "train_loss": 3.1471283435821533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15973,
        "tokens": 8374452224,
        "learning_rate": 0.00031704276584173597,
        "gradient_norm": 0.30734777450561523,
        "train_loss": 3.067355155944824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15974,
        "tokens": 8374976512,
        "learning_rate": 0.0003170141531454899,
        "gradient_norm": 0.41398248076438904,
        "train_loss": 3.261559009552002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15975,
        "tokens": 8375500800,
        "learning_rate": 0.0003169855405954157,
        "gradient_norm": 0.3560192286968231,
        "train_loss": 3.070770740509033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15976,
        "tokens": 8376025088,
        "learning_rate": 0.0003169569281918354,
        "gradient_norm": 0.3061092793941498,
        "train_loss": 3.0244598388671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15977,
        "tokens": 8376549376,
        "learning_rate": 0.0003169283159350713,
        "gradient_norm": 0.3352029323577881,
        "train_loss": 3.1286566257476807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15978,
        "tokens": 8377073664,
        "learning_rate": 0.0003168997038254451,
        "gradient_norm": 0.3019229471683502,
        "train_loss": 3.088458299636841,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15979,
        "tokens": 8377597952,
        "learning_rate": 0.0003168710918632792,
        "gradient_norm": 0.3279532492160797,
        "train_loss": 3.117759943008423,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15980,
        "tokens": 8378122240,
        "learning_rate": 0.0003168424800488955,
        "gradient_norm": 0.30828532576560974,
        "train_loss": 3.103569746017456,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15981,
        "tokens": 8378646528,
        "learning_rate": 0.00031681386838261613,
        "gradient_norm": 0.3119620680809021,
        "train_loss": 3.0706944465637207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15982,
        "tokens": 8379170816,
        "learning_rate": 0.000316785256864763,
        "gradient_norm": 0.3002319037914276,
        "train_loss": 3.1378142833709717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15983,
        "tokens": 8379695104,
        "learning_rate": 0.0003167566454956584,
        "gradient_norm": 0.29842427372932434,
        "train_loss": 3.113400936126709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15984,
        "tokens": 8380219392,
        "learning_rate": 0.0003167280342756241,
        "gradient_norm": 0.2950786054134369,
        "train_loss": 3.129415512084961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15985,
        "tokens": 8380743680,
        "learning_rate": 0.0003166994232049824,
        "gradient_norm": 0.31277352571487427,
        "train_loss": 3.1214888095855713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15986,
        "tokens": 8381267968,
        "learning_rate": 0.00031667081228405536,
        "gradient_norm": 0.2925463318824768,
        "train_loss": 3.0686838626861572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15987,
        "tokens": 8381792256,
        "learning_rate": 0.0003166422015131648,
        "gradient_norm": 0.3003699481487274,
        "train_loss": 3.1654839515686035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15988,
        "tokens": 8382316544,
        "learning_rate": 0.00031661359089263304,
        "gradient_norm": 0.2889232635498047,
        "train_loss": 3.051985263824463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15989,
        "tokens": 8382840832,
        "learning_rate": 0.0003165849804227819,
        "gradient_norm": 0.2993727922439575,
        "train_loss": 3.0653510093688965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15990,
        "tokens": 8383365120,
        "learning_rate": 0.0003165563701039336,
        "gradient_norm": 0.29460322856903076,
        "train_loss": 3.079225540161133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15991,
        "tokens": 8383889408,
        "learning_rate": 0.00031652775993641006,
        "gradient_norm": 0.29329100251197815,
        "train_loss": 3.117384433746338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15992,
        "tokens": 8384413696,
        "learning_rate": 0.00031649914992053343,
        "gradient_norm": 0.297913521528244,
        "train_loss": 3.0894808769226074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15993,
        "tokens": 8384937984,
        "learning_rate": 0.0003164705400566256,
        "gradient_norm": 0.2913421392440796,
        "train_loss": 3.086759090423584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15994,
        "tokens": 8385462272,
        "learning_rate": 0.00031644193034500886,
        "gradient_norm": 0.28727132081985474,
        "train_loss": 3.1104612350463867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15995,
        "tokens": 8385986560,
        "learning_rate": 0.00031641332078600494,
        "gradient_norm": 0.3162355422973633,
        "train_loss": 3.09421706199646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15996,
        "tokens": 8386510848,
        "learning_rate": 0.00031638471137993604,
        "gradient_norm": 0.4138164818286896,
        "train_loss": 3.10548996925354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15997,
        "tokens": 8387035136,
        "learning_rate": 0.0003163561021271243,
        "gradient_norm": 0.3228437900543213,
        "train_loss": 3.107247829437256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15998,
        "tokens": 8387559424,
        "learning_rate": 0.00031632749302789155,
        "gradient_norm": 0.3319135904312134,
        "train_loss": 3.1275928020477295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15999,
        "tokens": 8388083712,
        "learning_rate": 0.00031629888408256,
        "gradient_norm": 0.3415372371673584,
        "train_loss": 3.1286873817443848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16000,
        "tokens": 8388608000,
        "learning_rate": 0.0003162702752914514,
        "gradient_norm": 0.35629433393478394,
        "train_loss": 3.033984661102295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16001,
        "tokens": 8389132288,
        "learning_rate": 0.00031624166665488823,
        "gradient_norm": 0.31280338764190674,
        "train_loss": 3.0752739906311035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16002,
        "tokens": 8389656576,
        "learning_rate": 0.00031621305817319204,
        "gradient_norm": 0.31754010915756226,
        "train_loss": 3.1240453720092773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16003,
        "tokens": 8390180864,
        "learning_rate": 0.0003161844498466852,
        "gradient_norm": 0.3159211575984955,
        "train_loss": 3.0767393112182617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16004,
        "tokens": 8390705152,
        "learning_rate": 0.0003161558416756895,
        "gradient_norm": 0.3235042095184326,
        "train_loss": 3.084817409515381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16005,
        "tokens": 8391229440,
        "learning_rate": 0.00031612723366052705,
        "gradient_norm": 0.30674436688423157,
        "train_loss": 3.1017799377441406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16006,
        "tokens": 8391753728,
        "learning_rate": 0.00031609862580152,
        "gradient_norm": 0.30900314450263977,
        "train_loss": 3.0536580085754395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16007,
        "tokens": 8392278016,
        "learning_rate": 0.0003160700180989901,
        "gradient_norm": 0.30361729860305786,
        "train_loss": 3.1187610626220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16008,
        "tokens": 8392802304,
        "learning_rate": 0.00031604141055325966,
        "gradient_norm": 0.3290722370147705,
        "train_loss": 3.097179412841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16009,
        "tokens": 8393326592,
        "learning_rate": 0.0003160128031646504,
        "gradient_norm": 0.31092897057533264,
        "train_loss": 3.0788145065307617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16010,
        "tokens": 8393850880,
        "learning_rate": 0.0003159841959334846,
        "gradient_norm": 0.3188740015029907,
        "train_loss": 3.0905818939208984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16011,
        "tokens": 8394375168,
        "learning_rate": 0.00031595558886008405,
        "gradient_norm": 0.314290314912796,
        "train_loss": 3.1581993103027344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16012,
        "tokens": 8394899456,
        "learning_rate": 0.00031592698194477095,
        "gradient_norm": 0.28722116351127625,
        "train_loss": 3.054953098297119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16013,
        "tokens": 8395423744,
        "learning_rate": 0.0003158983751878671,
        "gradient_norm": 0.32001015543937683,
        "train_loss": 3.1290414333343506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16014,
        "tokens": 8395948032,
        "learning_rate": 0.00031586976858969474,
        "gradient_norm": 0.29622989892959595,
        "train_loss": 3.071261167526245,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16015,
        "tokens": 8396472320,
        "learning_rate": 0.0003158411621505756,
        "gradient_norm": 0.3200169503688812,
        "train_loss": 3.0576367378234863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16016,
        "tokens": 8396996608,
        "learning_rate": 0.0003158125558708319,
        "gradient_norm": 0.3217099905014038,
        "train_loss": 3.0532867908477783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16017,
        "tokens": 8397520896,
        "learning_rate": 0.0003157839497507856,
        "gradient_norm": 0.32065504789352417,
        "train_loss": 3.078767776489258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16018,
        "tokens": 8398045184,
        "learning_rate": 0.00031575534379075864,
        "gradient_norm": 0.311549574136734,
        "train_loss": 3.1257238388061523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16019,
        "tokens": 8398569472,
        "learning_rate": 0.0003157267379910731,
        "gradient_norm": 0.3343021273612976,
        "train_loss": 3.161313533782959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16020,
        "tokens": 8399093760,
        "learning_rate": 0.0003156981323520508,
        "gradient_norm": 0.2770611047744751,
        "train_loss": 3.0806326866149902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16021,
        "tokens": 8399618048,
        "learning_rate": 0.0003156695268740139,
        "gradient_norm": 0.32285553216934204,
        "train_loss": 3.1136317253112793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16022,
        "tokens": 8400142336,
        "learning_rate": 0.0003156409215572844,
        "gradient_norm": 0.2960435748100281,
        "train_loss": 3.132838249206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16023,
        "tokens": 8400666624,
        "learning_rate": 0.0003156123164021842,
        "gradient_norm": 0.3621737062931061,
        "train_loss": 3.0565714836120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16024,
        "tokens": 8401190912,
        "learning_rate": 0.00031558371140903523,
        "gradient_norm": 0.2906806468963623,
        "train_loss": 3.030820369720459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16025,
        "tokens": 8401715200,
        "learning_rate": 0.00031555510657815957,
        "gradient_norm": 0.30715516209602356,
        "train_loss": 3.098543882369995,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16026,
        "tokens": 8402239488,
        "learning_rate": 0.00031552650190987933,
        "gradient_norm": 0.2783864140510559,
        "train_loss": 3.0981831550598145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16027,
        "tokens": 8402763776,
        "learning_rate": 0.0003154978974045162,
        "gradient_norm": 0.29100385308265686,
        "train_loss": 3.0857324600219727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16028,
        "tokens": 8403288064,
        "learning_rate": 0.0003154692930623924,
        "gradient_norm": 0.30690398812294006,
        "train_loss": 3.096250057220459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16029,
        "tokens": 8403812352,
        "learning_rate": 0.00031544068888382976,
        "gradient_norm": 0.3114127814769745,
        "train_loss": 3.106431484222412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16030,
        "tokens": 8404336640,
        "learning_rate": 0.0003154120848691504,
        "gradient_norm": 0.3213930130004883,
        "train_loss": 3.128690242767334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16031,
        "tokens": 8404860928,
        "learning_rate": 0.00031538348101867614,
        "gradient_norm": 0.31736522912979126,
        "train_loss": 3.054075241088867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16032,
        "tokens": 8405385216,
        "learning_rate": 0.0003153548773327291,
        "gradient_norm": 0.3138543367385864,
        "train_loss": 3.092719554901123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16033,
        "tokens": 8405909504,
        "learning_rate": 0.000315326273811631,
        "gradient_norm": 0.3249450922012329,
        "train_loss": 3.050942897796631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16034,
        "tokens": 8406433792,
        "learning_rate": 0.00031529767045570417,
        "gradient_norm": 0.3218585252761841,
        "train_loss": 3.0651068687438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16035,
        "tokens": 8406958080,
        "learning_rate": 0.00031526906726527025,
        "gradient_norm": 0.3000367283821106,
        "train_loss": 3.1022531986236572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16036,
        "tokens": 8407482368,
        "learning_rate": 0.00031524046424065134,
        "gradient_norm": 0.3281286954879761,
        "train_loss": 3.093447685241699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16037,
        "tokens": 8408006656,
        "learning_rate": 0.00031521186138216956,
        "gradient_norm": 0.30207347869873047,
        "train_loss": 3.094660758972168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16038,
        "tokens": 8408530944,
        "learning_rate": 0.00031518325869014653,
        "gradient_norm": 0.3028905391693115,
        "train_loss": 3.0716958045959473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16039,
        "tokens": 8409055232,
        "learning_rate": 0.00031515465616490453,
        "gradient_norm": 0.3130471706390381,
        "train_loss": 3.1046745777130127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16040,
        "tokens": 8409579520,
        "learning_rate": 0.00031512605380676524,
        "gradient_norm": 0.29187846183776855,
        "train_loss": 3.1465001106262207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16041,
        "tokens": 8410103808,
        "learning_rate": 0.00031509745161605095,
        "gradient_norm": 0.32026946544647217,
        "train_loss": 3.149352788925171,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16042,
        "tokens": 8410628096,
        "learning_rate": 0.0003150688495930832,
        "gradient_norm": 0.286895751953125,
        "train_loss": 3.1249539852142334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16043,
        "tokens": 8411152384,
        "learning_rate": 0.00031504024773818434,
        "gradient_norm": 0.32428744435310364,
        "train_loss": 3.1332201957702637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16044,
        "tokens": 8411676672,
        "learning_rate": 0.00031501164605167605,
        "gradient_norm": 0.28215473890304565,
        "train_loss": 3.112612009048462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16045,
        "tokens": 8412200960,
        "learning_rate": 0.0003149830445338803,
        "gradient_norm": 0.299355685710907,
        "train_loss": 3.071697235107422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16046,
        "tokens": 8412725248,
        "learning_rate": 0.0003149544431851193,
        "gradient_norm": 0.29517656564712524,
        "train_loss": 3.096867561340332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16047,
        "tokens": 8413249536,
        "learning_rate": 0.0003149258420057146,
        "gradient_norm": 0.2822783291339874,
        "train_loss": 3.1089706420898438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16048,
        "tokens": 8413773824,
        "learning_rate": 0.0003148972409959885,
        "gradient_norm": 0.3136567771434784,
        "train_loss": 3.119905471801758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16049,
        "tokens": 8414298112,
        "learning_rate": 0.00031486864015626263,
        "gradient_norm": 0.31110092997550964,
        "train_loss": 3.0866904258728027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16050,
        "tokens": 8414822400,
        "learning_rate": 0.00031484003948685925,
        "gradient_norm": 0.2973989248275757,
        "train_loss": 3.097508430480957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16051,
        "tokens": 8415346688,
        "learning_rate": 0.0003148114389880999,
        "gradient_norm": 0.3086351156234741,
        "train_loss": 3.086351156234741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16052,
        "tokens": 8415870976,
        "learning_rate": 0.00031478283866030694,
        "gradient_norm": 0.29975929856300354,
        "train_loss": 3.036421298980713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16053,
        "tokens": 8416395264,
        "learning_rate": 0.000314754238503802,
        "gradient_norm": 0.2901539206504822,
        "train_loss": 3.0762338638305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16054,
        "tokens": 8416919552,
        "learning_rate": 0.0003147256385189072,
        "gradient_norm": 0.3638412654399872,
        "train_loss": 3.1816375255584717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16055,
        "tokens": 8417443840,
        "learning_rate": 0.0003146970387059442,
        "gradient_norm": 0.3586982190608978,
        "train_loss": 3.1199705600738525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16056,
        "tokens": 8417968128,
        "learning_rate": 0.00031466843906523517,
        "gradient_norm": 0.33637863397598267,
        "train_loss": 3.040916919708252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16057,
        "tokens": 8418492416,
        "learning_rate": 0.0003146398395971021,
        "gradient_norm": 0.3044312000274658,
        "train_loss": 3.07399845123291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16058,
        "tokens": 8419016704,
        "learning_rate": 0.00031461124030186664,
        "gradient_norm": 0.3323025107383728,
        "train_loss": 3.1009974479675293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16059,
        "tokens": 8419540992,
        "learning_rate": 0.00031458264117985096,
        "gradient_norm": 0.3275485932826996,
        "train_loss": 3.171279191970825,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16060,
        "tokens": 8420065280,
        "learning_rate": 0.00031455404223137675,
        "gradient_norm": 0.32308951020240784,
        "train_loss": 3.070706605911255,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16061,
        "tokens": 8420589568,
        "learning_rate": 0.00031452544345676617,
        "gradient_norm": 0.33373787999153137,
        "train_loss": 3.115049362182617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16062,
        "tokens": 8421113856,
        "learning_rate": 0.0003144968448563409,
        "gradient_norm": 0.3141646385192871,
        "train_loss": 3.1123876571655273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16063,
        "tokens": 8421638144,
        "learning_rate": 0.0003144682464304231,
        "gradient_norm": 0.3150748312473297,
        "train_loss": 3.1078734397888184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16064,
        "tokens": 8422162432,
        "learning_rate": 0.00031443964817933444,
        "gradient_norm": 0.32573261857032776,
        "train_loss": 3.061734914779663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16065,
        "tokens": 8422686720,
        "learning_rate": 0.00031441105010339697,
        "gradient_norm": 0.3082587420940399,
        "train_loss": 3.0635557174682617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16066,
        "tokens": 8423211008,
        "learning_rate": 0.0003143824522029326,
        "gradient_norm": 0.3253442943096161,
        "train_loss": 3.09187650680542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16067,
        "tokens": 8423735296,
        "learning_rate": 0.0003143538544782631,
        "gradient_norm": 0.3458402752876282,
        "train_loss": 3.0431599617004395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16068,
        "tokens": 8424259584,
        "learning_rate": 0.0003143252569297106,
        "gradient_norm": 0.3074638545513153,
        "train_loss": 3.083890914916992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16069,
        "tokens": 8424783872,
        "learning_rate": 0.0003142966595575968,
        "gradient_norm": 0.3459394872188568,
        "train_loss": 3.1580662727355957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16070,
        "tokens": 8425308160,
        "learning_rate": 0.00031426806236224366,
        "gradient_norm": 0.30592402815818787,
        "train_loss": 3.085693836212158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16071,
        "tokens": 8425832448,
        "learning_rate": 0.0003142394653439731,
        "gradient_norm": 0.3148818612098694,
        "train_loss": 3.1064486503601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16072,
        "tokens": 8426356736,
        "learning_rate": 0.00031421086850310704,
        "gradient_norm": 0.3422726094722748,
        "train_loss": 3.087522506713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16073,
        "tokens": 8426881024,
        "learning_rate": 0.0003141822718399673,
        "gradient_norm": 0.3117032051086426,
        "train_loss": 3.108142375946045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16074,
        "tokens": 8427405312,
        "learning_rate": 0.0003141536753548758,
        "gradient_norm": 0.28897625207901,
        "train_loss": 3.1037509441375732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16075,
        "tokens": 8427929600,
        "learning_rate": 0.0003141250790481545,
        "gradient_norm": 0.2938123941421509,
        "train_loss": 3.1299734115600586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16076,
        "tokens": 8428453888,
        "learning_rate": 0.0003140964829201251,
        "gradient_norm": 0.338358998298645,
        "train_loss": 3.048865556716919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16077,
        "tokens": 8428978176,
        "learning_rate": 0.00031406788697110975,
        "gradient_norm": 0.30303114652633667,
        "train_loss": 3.0818045139312744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16078,
        "tokens": 8429502464,
        "learning_rate": 0.00031403929120143005,
        "gradient_norm": 0.3289026916027069,
        "train_loss": 3.123076915740967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16079,
        "tokens": 8430026752,
        "learning_rate": 0.0003140106956114082,
        "gradient_norm": 0.3378918766975403,
        "train_loss": 3.088587522506714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16080,
        "tokens": 8430551040,
        "learning_rate": 0.00031398210020136574,
        "gradient_norm": 0.3069623112678528,
        "train_loss": 3.0901904106140137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16081,
        "tokens": 8431075328,
        "learning_rate": 0.0003139535049716248,
        "gradient_norm": 0.2918395400047302,
        "train_loss": 3.0980160236358643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16082,
        "tokens": 8431599616,
        "learning_rate": 0.00031392490992250706,
        "gradient_norm": 0.29710647463798523,
        "train_loss": 3.1148157119750977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16083,
        "tokens": 8432123904,
        "learning_rate": 0.00031389631505433465,
        "gradient_norm": 0.3168790936470032,
        "train_loss": 3.080117702484131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16084,
        "tokens": 8432648192,
        "learning_rate": 0.0003138677203674292,
        "gradient_norm": 0.33705270290374756,
        "train_loss": 3.124964952468872,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16085,
        "tokens": 8433172480,
        "learning_rate": 0.00031383912586211256,
        "gradient_norm": 0.33273670077323914,
        "train_loss": 3.057962417602539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16086,
        "tokens": 8433696768,
        "learning_rate": 0.0003138105315387069,
        "gradient_norm": 0.3632538914680481,
        "train_loss": 3.1779866218566895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16087,
        "tokens": 8434221056,
        "learning_rate": 0.00031378193739753374,
        "gradient_norm": 0.3247537314891815,
        "train_loss": 3.1168885231018066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16088,
        "tokens": 8434745344,
        "learning_rate": 0.0003137533434389152,
        "gradient_norm": 0.3378230035305023,
        "train_loss": 3.1064178943634033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16089,
        "tokens": 8435269632,
        "learning_rate": 0.000313724749663173,
        "gradient_norm": 0.32793110609054565,
        "train_loss": 3.0559933185577393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16090,
        "tokens": 8435793920,
        "learning_rate": 0.00031369615607062905,
        "gradient_norm": 0.3407568037509918,
        "train_loss": 3.071035146713257,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16091,
        "tokens": 8436318208,
        "learning_rate": 0.0003136675626616051,
        "gradient_norm": 0.34233152866363525,
        "train_loss": 3.083082675933838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16092,
        "tokens": 8436842496,
        "learning_rate": 0.0003136389694364232,
        "gradient_norm": 0.3023594617843628,
        "train_loss": 3.082016944885254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16093,
        "tokens": 8437366784,
        "learning_rate": 0.000313610376395405,
        "gradient_norm": 0.3244777023792267,
        "train_loss": 3.107041358947754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16094,
        "tokens": 8437891072,
        "learning_rate": 0.0003135817835388724,
        "gradient_norm": 0.2911863625049591,
        "train_loss": 3.0492539405822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16095,
        "tokens": 8438415360,
        "learning_rate": 0.0003135531908671475,
        "gradient_norm": 0.29774367809295654,
        "train_loss": 3.056678295135498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16096,
        "tokens": 8438939648,
        "learning_rate": 0.00031352459838055173,
        "gradient_norm": 0.3039807081222534,
        "train_loss": 3.0785210132598877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16097,
        "tokens": 8439463936,
        "learning_rate": 0.0003134960060794073,
        "gradient_norm": 0.29116272926330566,
        "train_loss": 3.1461894512176514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16098,
        "tokens": 8439988224,
        "learning_rate": 0.00031346741396403574,
        "gradient_norm": 0.32055771350860596,
        "train_loss": 3.1082406044006348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16099,
        "tokens": 8440512512,
        "learning_rate": 0.0003134388220347592,
        "gradient_norm": 0.31005197763442993,
        "train_loss": 3.1183032989501953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16100,
        "tokens": 8441036800,
        "learning_rate": 0.00031341023029189923,
        "gradient_norm": 0.32535868883132935,
        "train_loss": 3.0860342979431152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16101,
        "tokens": 8441561088,
        "learning_rate": 0.0003133816387357779,
        "gradient_norm": 0.3036328852176666,
        "train_loss": 3.094566822052002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16102,
        "tokens": 8442085376,
        "learning_rate": 0.0003133530473667169,
        "gradient_norm": 0.2971867620944977,
        "train_loss": 3.1517834663391113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16103,
        "tokens": 8442609664,
        "learning_rate": 0.0003133244561850381,
        "gradient_norm": 0.3003697991371155,
        "train_loss": 3.1381311416625977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16104,
        "tokens": 8443133952,
        "learning_rate": 0.00031329586519106327,
        "gradient_norm": 0.30676671862602234,
        "train_loss": 3.162209987640381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16105,
        "tokens": 8443658240,
        "learning_rate": 0.00031326727438511434,
        "gradient_norm": 0.28649255633354187,
        "train_loss": 3.0850391387939453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16106,
        "tokens": 8444182528,
        "learning_rate": 0.0003132386837675132,
        "gradient_norm": 0.3142969012260437,
        "train_loss": 3.091485023498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16107,
        "tokens": 8444706816,
        "learning_rate": 0.0003132100933385814,
        "gradient_norm": 0.2821830213069916,
        "train_loss": 3.057239532470703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16108,
        "tokens": 8445231104,
        "learning_rate": 0.0003131815030986411,
        "gradient_norm": 0.3205408751964569,
        "train_loss": 3.092869281768799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16109,
        "tokens": 8445755392,
        "learning_rate": 0.0003131529130480138,
        "gradient_norm": 0.2923419177532196,
        "train_loss": 3.0639076232910156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16110,
        "tokens": 8446279680,
        "learning_rate": 0.0003131243231870216,
        "gradient_norm": 0.3175754249095917,
        "train_loss": 3.103285551071167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16111,
        "tokens": 8446803968,
        "learning_rate": 0.00031309573351598607,
        "gradient_norm": 0.284151554107666,
        "train_loss": 3.088622570037842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16112,
        "tokens": 8447328256,
        "learning_rate": 0.0003130671440352292,
        "gradient_norm": 0.34293657541275024,
        "train_loss": 3.0835063457489014,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16113,
        "tokens": 8447852544,
        "learning_rate": 0.0003130385547450726,
        "gradient_norm": 0.31153014302253723,
        "train_loss": 3.0940003395080566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16114,
        "tokens": 8448376832,
        "learning_rate": 0.00031300996564583835,
        "gradient_norm": 0.3072088956832886,
        "train_loss": 3.0921027660369873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16115,
        "tokens": 8448901120,
        "learning_rate": 0.00031298137673784805,
        "gradient_norm": 0.31486976146698,
        "train_loss": 3.1157450675964355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16116,
        "tokens": 8449425408,
        "learning_rate": 0.0003129527880214236,
        "gradient_norm": 0.3116396367549896,
        "train_loss": 3.0964090824127197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16117,
        "tokens": 8449949696,
        "learning_rate": 0.0003129241994968868,
        "gradient_norm": 0.30766746401786804,
        "train_loss": 3.101095676422119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16118,
        "tokens": 8450473984,
        "learning_rate": 0.00031289561116455933,
        "gradient_norm": 0.34448903799057007,
        "train_loss": 3.069542407989502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16119,
        "tokens": 8450998272,
        "learning_rate": 0.0003128670230247631,
        "gradient_norm": 0.3126079738140106,
        "train_loss": 3.047434091567993,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16120,
        "tokens": 8451522560,
        "learning_rate": 0.00031283843507782,
        "gradient_norm": 0.31132495403289795,
        "train_loss": 3.122358798980713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16121,
        "tokens": 8452046848,
        "learning_rate": 0.0003128098473240516,
        "gradient_norm": 0.32800278067588806,
        "train_loss": 3.0434093475341797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16122,
        "tokens": 8452571136,
        "learning_rate": 0.00031278125976377975,
        "gradient_norm": 0.29366081953048706,
        "train_loss": 3.1447315216064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16123,
        "tokens": 8453095424,
        "learning_rate": 0.0003127526723973264,
        "gradient_norm": 0.3288593590259552,
        "train_loss": 3.0471627712249756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16124,
        "tokens": 8453619712,
        "learning_rate": 0.00031272408522501315,
        "gradient_norm": 0.28595829010009766,
        "train_loss": 3.116157054901123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16125,
        "tokens": 8454144000,
        "learning_rate": 0.00031269549824716183,
        "gradient_norm": 0.30530181527137756,
        "train_loss": 3.0939879417419434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16126,
        "tokens": 8454668288,
        "learning_rate": 0.0003126669114640943,
        "gradient_norm": 0.32223644852638245,
        "train_loss": 3.1320137977600098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16127,
        "tokens": 8455192576,
        "learning_rate": 0.0003126383248761323,
        "gradient_norm": 0.31107795238494873,
        "train_loss": 3.1521501541137695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16128,
        "tokens": 8455716864,
        "learning_rate": 0.00031260973848359756,
        "gradient_norm": 0.317219614982605,
        "train_loss": 3.110419511795044,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16129,
        "tokens": 8456241152,
        "learning_rate": 0.00031258115228681194,
        "gradient_norm": 0.30980101227760315,
        "train_loss": 3.083244800567627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16130,
        "tokens": 8456765440,
        "learning_rate": 0.00031255256628609713,
        "gradient_norm": 0.32653969526290894,
        "train_loss": 3.058357000350952,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16131,
        "tokens": 8457289728,
        "learning_rate": 0.0003125239804817749,
        "gradient_norm": 0.2945926785469055,
        "train_loss": 3.140857219696045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16132,
        "tokens": 8457814016,
        "learning_rate": 0.00031249539487416715,
        "gradient_norm": 0.3142361640930176,
        "train_loss": 3.096522808074951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16133,
        "tokens": 8458338304,
        "learning_rate": 0.00031246680946359545,
        "gradient_norm": 0.2998760938644409,
        "train_loss": 3.077418804168701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16134,
        "tokens": 8458862592,
        "learning_rate": 0.00031243822425038167,
        "gradient_norm": 0.27848726511001587,
        "train_loss": 3.082495927810669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16135,
        "tokens": 8459386880,
        "learning_rate": 0.00031240963923484766,
        "gradient_norm": 0.3145110607147217,
        "train_loss": 3.082573890686035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16136,
        "tokens": 8459911168,
        "learning_rate": 0.000312381054417315,
        "gradient_norm": 0.2964633107185364,
        "train_loss": 3.078183174133301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16137,
        "tokens": 8460435456,
        "learning_rate": 0.0003123524697981056,
        "gradient_norm": 0.2930372953414917,
        "train_loss": 3.0979175567626953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16138,
        "tokens": 8460959744,
        "learning_rate": 0.00031232388537754107,
        "gradient_norm": 0.32132214307785034,
        "train_loss": 3.1163363456726074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16139,
        "tokens": 8461484032,
        "learning_rate": 0.00031229530115594337,
        "gradient_norm": 0.3502422273159027,
        "train_loss": 3.1602158546447754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16140,
        "tokens": 8462008320,
        "learning_rate": 0.000312266717133634,
        "gradient_norm": 0.3516499698162079,
        "train_loss": 3.1214945316314697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16141,
        "tokens": 8462532608,
        "learning_rate": 0.00031223813331093494,
        "gradient_norm": 0.3293931484222412,
        "train_loss": 3.0863423347473145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16142,
        "tokens": 8463056896,
        "learning_rate": 0.0003122095496881677,
        "gradient_norm": 0.31084659695625305,
        "train_loss": 3.139010190963745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16143,
        "tokens": 8463581184,
        "learning_rate": 0.0003121809662656543,
        "gradient_norm": 0.3329315185546875,
        "train_loss": 3.072237491607666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16144,
        "tokens": 8464105472,
        "learning_rate": 0.00031215238304371616,
        "gradient_norm": 0.2895945608615875,
        "train_loss": 3.0984153747558594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16145,
        "tokens": 8464629760,
        "learning_rate": 0.0003121238000226753,
        "gradient_norm": 0.32560020685195923,
        "train_loss": 3.066215991973877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16146,
        "tokens": 8465154048,
        "learning_rate": 0.0003120952172028534,
        "gradient_norm": 0.32246893644332886,
        "train_loss": 3.086432456970215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16147,
        "tokens": 8465678336,
        "learning_rate": 0.00031206663458457207,
        "gradient_norm": 0.3131175637245178,
        "train_loss": 3.0675628185272217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16148,
        "tokens": 8466202624,
        "learning_rate": 0.00031203805216815315,
        "gradient_norm": 0.29490137100219727,
        "train_loss": 3.0624334812164307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16149,
        "tokens": 8466726912,
        "learning_rate": 0.0003120094699539183,
        "gradient_norm": 0.3211541473865509,
        "train_loss": 3.091059684753418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16150,
        "tokens": 8467251200,
        "learning_rate": 0.0003119808879421894,
        "gradient_norm": 0.308161199092865,
        "train_loss": 3.120150089263916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16151,
        "tokens": 8467775488,
        "learning_rate": 0.000311952306133288,
        "gradient_norm": 0.31796538829803467,
        "train_loss": 3.09468412399292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16152,
        "tokens": 8468299776,
        "learning_rate": 0.0003119237245275359,
        "gradient_norm": 0.3157420754432678,
        "train_loss": 3.117006540298462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16153,
        "tokens": 8468824064,
        "learning_rate": 0.0003118951431252548,
        "gradient_norm": 0.3247794806957245,
        "train_loss": 3.0537195205688477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16154,
        "tokens": 8469348352,
        "learning_rate": 0.00031186656192676635,
        "gradient_norm": 0.31278103590011597,
        "train_loss": 3.1374783515930176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16155,
        "tokens": 8469872640,
        "learning_rate": 0.0003118379809323925,
        "gradient_norm": 0.3046947717666626,
        "train_loss": 3.1253695487976074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16156,
        "tokens": 8470396928,
        "learning_rate": 0.00031180940014245473,
        "gradient_norm": 0.325611412525177,
        "train_loss": 3.121840238571167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16157,
        "tokens": 8470921216,
        "learning_rate": 0.0003117808195572749,
        "gradient_norm": 0.3068663477897644,
        "train_loss": 3.1295738220214844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16158,
        "tokens": 8471445504,
        "learning_rate": 0.0003117522391771746,
        "gradient_norm": 0.31036850810050964,
        "train_loss": 3.1087303161621094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16159,
        "tokens": 8471969792,
        "learning_rate": 0.00031172365900247566,
        "gradient_norm": 0.2962203621864319,
        "train_loss": 3.0838401317596436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16160,
        "tokens": 8472494080,
        "learning_rate": 0.0003116950790334996,
        "gradient_norm": 0.35966989398002625,
        "train_loss": 3.161313772201538,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16161,
        "tokens": 8473018368,
        "learning_rate": 0.0003116664992705684,
        "gradient_norm": 0.3907220661640167,
        "train_loss": 3.0826308727264404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16162,
        "tokens": 8473542656,
        "learning_rate": 0.00031163791971400344,
        "gradient_norm": 0.31897786259651184,
        "train_loss": 3.0736865997314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16163,
        "tokens": 8474066944,
        "learning_rate": 0.00031160934036412677,
        "gradient_norm": 0.324201375246048,
        "train_loss": 3.092028856277466,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16164,
        "tokens": 8474591232,
        "learning_rate": 0.0003115807612212597,
        "gradient_norm": 0.31512171030044556,
        "train_loss": 3.1168909072875977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16165,
        "tokens": 8475115520,
        "learning_rate": 0.00031155218228572415,
        "gradient_norm": 0.35510608553886414,
        "train_loss": 3.1226089000701904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16166,
        "tokens": 8475639808,
        "learning_rate": 0.00031152360355784196,
        "gradient_norm": 0.3092941343784332,
        "train_loss": 3.0766305923461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16167,
        "tokens": 8476164096,
        "learning_rate": 0.00031149502503793447,
        "gradient_norm": 0.31335723400115967,
        "train_loss": 3.1087374687194824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16168,
        "tokens": 8476688384,
        "learning_rate": 0.0003114664467263236,
        "gradient_norm": 0.3344672620296478,
        "train_loss": 3.0948638916015625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16169,
        "tokens": 8477212672,
        "learning_rate": 0.00031143786862333094,
        "gradient_norm": 0.3052440285682678,
        "train_loss": 3.153170585632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16170,
        "tokens": 8477736960,
        "learning_rate": 0.00031140929072927834,
        "gradient_norm": 0.3228742778301239,
        "train_loss": 3.069460868835449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16171,
        "tokens": 8478261248,
        "learning_rate": 0.0003113807130444872,
        "gradient_norm": 0.3002149760723114,
        "train_loss": 3.094399929046631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16172,
        "tokens": 8478785536,
        "learning_rate": 0.00031135213556927947,
        "gradient_norm": 0.2923320531845093,
        "train_loss": 3.1343555450439453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16173,
        "tokens": 8479309824,
        "learning_rate": 0.0003113235583039765,
        "gradient_norm": 0.2893039584159851,
        "train_loss": 3.068500518798828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16174,
        "tokens": 8479834112,
        "learning_rate": 0.0003112949812489003,
        "gradient_norm": 0.30260729789733887,
        "train_loss": 3.096792697906494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16175,
        "tokens": 8480358400,
        "learning_rate": 0.00031126640440437244,
        "gradient_norm": 0.29481780529022217,
        "train_loss": 3.1019394397735596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16176,
        "tokens": 8480882688,
        "learning_rate": 0.0003112378277707145,
        "gradient_norm": 0.30574116110801697,
        "train_loss": 3.1091856956481934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16177,
        "tokens": 8481406976,
        "learning_rate": 0.0003112092513482482,
        "gradient_norm": 0.3004301190376282,
        "train_loss": 3.1015076637268066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16178,
        "tokens": 8481931264,
        "learning_rate": 0.0003111806751372952,
        "gradient_norm": 0.3003360331058502,
        "train_loss": 3.156768560409546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16179,
        "tokens": 8482455552,
        "learning_rate": 0.00031115209913817714,
        "gradient_norm": 0.32459312677383423,
        "train_loss": 3.0807318687438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16180,
        "tokens": 8482979840,
        "learning_rate": 0.0003111235233512157,
        "gradient_norm": 0.32191532850265503,
        "train_loss": 3.1264584064483643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16181,
        "tokens": 8483504128,
        "learning_rate": 0.00031109494777673257,
        "gradient_norm": 0.3062163293361664,
        "train_loss": 3.1188037395477295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16182,
        "tokens": 8484028416,
        "learning_rate": 0.00031106637241504935,
        "gradient_norm": 0.29915177822113037,
        "train_loss": 3.072364568710327,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16183,
        "tokens": 8484552704,
        "learning_rate": 0.0003110377972664877,
        "gradient_norm": 0.3282492756843567,
        "train_loss": 3.1062731742858887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16184,
        "tokens": 8485076992,
        "learning_rate": 0.0003110092223313693,
        "gradient_norm": 0.3150818347930908,
        "train_loss": 3.0738816261291504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16185,
        "tokens": 8485601280,
        "learning_rate": 0.0003109806476100157,
        "gradient_norm": 0.3181571364402771,
        "train_loss": 3.106926441192627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16186,
        "tokens": 8486125568,
        "learning_rate": 0.00031095207310274876,
        "gradient_norm": 0.34233930706977844,
        "train_loss": 3.1004793643951416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16187,
        "tokens": 8486649856,
        "learning_rate": 0.0003109234988098899,
        "gradient_norm": 0.3214660882949829,
        "train_loss": 3.1472930908203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16188,
        "tokens": 8487174144,
        "learning_rate": 0.0003108949247317609,
        "gradient_norm": 0.34498390555381775,
        "train_loss": 3.1303465366363525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16189,
        "tokens": 8487698432,
        "learning_rate": 0.0003108663508686832,
        "gradient_norm": 0.3131248950958252,
        "train_loss": 3.0790786743164062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16190,
        "tokens": 8488222720,
        "learning_rate": 0.0003108377772209787,
        "gradient_norm": 0.2926681637763977,
        "train_loss": 3.082310199737549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16191,
        "tokens": 8488747008,
        "learning_rate": 0.0003108092037889688,
        "gradient_norm": 0.3227677643299103,
        "train_loss": 3.0757579803466797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16192,
        "tokens": 8489271296,
        "learning_rate": 0.0003107806305729754,
        "gradient_norm": 0.31528255343437195,
        "train_loss": 3.0931339263916016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16193,
        "tokens": 8489795584,
        "learning_rate": 0.0003107520575733197,
        "gradient_norm": 0.282646507024765,
        "train_loss": 3.05301570892334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16194,
        "tokens": 8490319872,
        "learning_rate": 0.0003107234847903237,
        "gradient_norm": 0.29082566499710083,
        "train_loss": 3.089409828186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16195,
        "tokens": 8490844160,
        "learning_rate": 0.00031069491222430903,
        "gradient_norm": 0.3363819420337677,
        "train_loss": 3.159442901611328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16196,
        "tokens": 8491368448,
        "learning_rate": 0.00031066633987559704,
        "gradient_norm": 0.34950757026672363,
        "train_loss": 3.1034834384918213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16197,
        "tokens": 8491892736,
        "learning_rate": 0.0003106377677445096,
        "gradient_norm": 0.33070462942123413,
        "train_loss": 3.0782556533813477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16198,
        "tokens": 8492417024,
        "learning_rate": 0.00031060919583136815,
        "gradient_norm": 0.32564932107925415,
        "train_loss": 3.1365933418273926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16199,
        "tokens": 8492941312,
        "learning_rate": 0.00031058062413649447,
        "gradient_norm": 0.3297848403453827,
        "train_loss": 3.0806336402893066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16200,
        "tokens": 8493465600,
        "learning_rate": 0.0003105520526602099,
        "gradient_norm": 0.32396164536476135,
        "train_loss": 3.1623730659484863,
        "val_loss": 3.0616583824157715,
        "hellaswag_acc": 0.2816171944141388,
        "hellaswag_acc_norm": 0.2909778952598572
    },
    {
        "step": 16201,
        "tokens": 8493989888,
        "learning_rate": 0.0003105234814028364,
        "gradient_norm": 0.3165873885154724,
        "train_loss": 3.068653106689453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16202,
        "tokens": 8494514176,
        "learning_rate": 0.0003104949103646953,
        "gradient_norm": 0.2943322956562042,
        "train_loss": 3.108016014099121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16203,
        "tokens": 8495038464,
        "learning_rate": 0.0003104663395461083,
        "gradient_norm": 0.31467360258102417,
        "train_loss": 3.0914571285247803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16204,
        "tokens": 8495562752,
        "learning_rate": 0.00031043776894739696,
        "gradient_norm": 0.3248480558395386,
        "train_loss": 3.058506488800049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16205,
        "tokens": 8496087040,
        "learning_rate": 0.00031040919856888295,
        "gradient_norm": 0.2978167235851288,
        "train_loss": 3.1351470947265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16206,
        "tokens": 8496611328,
        "learning_rate": 0.0003103806284108879,
        "gradient_norm": 0.3205081522464752,
        "train_loss": 3.1443090438842773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16207,
        "tokens": 8497135616,
        "learning_rate": 0.0003103520584737332,
        "gradient_norm": 0.30205488204956055,
        "train_loss": 3.125751256942749,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16208,
        "tokens": 8497659904,
        "learning_rate": 0.0003103234887577407,
        "gradient_norm": 0.3436230421066284,
        "train_loss": 3.073823928833008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16209,
        "tokens": 8498184192,
        "learning_rate": 0.00031029491926323175,
        "gradient_norm": 0.3127431869506836,
        "train_loss": 3.1331725120544434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16210,
        "tokens": 8498708480,
        "learning_rate": 0.0003102663499905282,
        "gradient_norm": 0.35223904252052307,
        "train_loss": 3.098552703857422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16211,
        "tokens": 8499232768,
        "learning_rate": 0.0003102377809399513,
        "gradient_norm": 0.32311731576919556,
        "train_loss": 3.1205074787139893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16212,
        "tokens": 8499757056,
        "learning_rate": 0.000310209212111823,
        "gradient_norm": 0.3409883975982666,
        "train_loss": 3.0708062648773193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16213,
        "tokens": 8500281344,
        "learning_rate": 0.00031018064350646455,
        "gradient_norm": 0.3519607484340668,
        "train_loss": 3.0378293991088867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16214,
        "tokens": 8500805632,
        "learning_rate": 0.0003101520751241976,
        "gradient_norm": 0.3158455789089203,
        "train_loss": 3.1165108680725098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16215,
        "tokens": 8501329920,
        "learning_rate": 0.000310123506965344,
        "gradient_norm": 0.33717358112335205,
        "train_loss": 3.0701117515563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16216,
        "tokens": 8501854208,
        "learning_rate": 0.0003100949390302249,
        "gradient_norm": 0.31018370389938354,
        "train_loss": 3.1412553787231445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16217,
        "tokens": 8502378496,
        "learning_rate": 0.0003100663713191622,
        "gradient_norm": 0.32799333333969116,
        "train_loss": 3.1069178581237793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16218,
        "tokens": 8502902784,
        "learning_rate": 0.0003100378038324773,
        "gradient_norm": 0.3416886627674103,
        "train_loss": 3.1072473526000977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16219,
        "tokens": 8503427072,
        "learning_rate": 0.00031000923657049185,
        "gradient_norm": 0.30662471055984497,
        "train_loss": 3.0322978496551514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16220,
        "tokens": 8503951360,
        "learning_rate": 0.00030998066953352726,
        "gradient_norm": 0.3213737905025482,
        "train_loss": 3.086670398712158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16221,
        "tokens": 8504475648,
        "learning_rate": 0.0003099521027219053,
        "gradient_norm": 0.3291127383708954,
        "train_loss": 3.0900559425354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16222,
        "tokens": 8504999936,
        "learning_rate": 0.0003099235361359473,
        "gradient_norm": 0.35732755064964294,
        "train_loss": 3.079245090484619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16223,
        "tokens": 8505524224,
        "learning_rate": 0.0003098949697759751,
        "gradient_norm": 0.3572588860988617,
        "train_loss": 3.0921640396118164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16224,
        "tokens": 8506048512,
        "learning_rate": 0.00030986640364230985,
        "gradient_norm": 0.3282235264778137,
        "train_loss": 3.0560431480407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16225,
        "tokens": 8506572800,
        "learning_rate": 0.00030983783773527344,
        "gradient_norm": 0.30273303389549255,
        "train_loss": 3.0582852363586426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16226,
        "tokens": 8507097088,
        "learning_rate": 0.0003098092720551873,
        "gradient_norm": 0.33788010478019714,
        "train_loss": 3.1045994758605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16227,
        "tokens": 8507621376,
        "learning_rate": 0.00030978070660237297,
        "gradient_norm": 0.2947721481323242,
        "train_loss": 3.147768974304199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16228,
        "tokens": 8508145664,
        "learning_rate": 0.000309752141377152,
        "gradient_norm": 0.33236929774284363,
        "train_loss": 3.0896968841552734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16229,
        "tokens": 8508669952,
        "learning_rate": 0.0003097235763798459,
        "gradient_norm": 0.31165966391563416,
        "train_loss": 3.132826566696167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16230,
        "tokens": 8509194240,
        "learning_rate": 0.0003096950116107763,
        "gradient_norm": 0.3329329192638397,
        "train_loss": 3.122180938720703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16231,
        "tokens": 8509718528,
        "learning_rate": 0.00030966644707026454,
        "gradient_norm": 0.2992382347583771,
        "train_loss": 3.0607385635375977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16232,
        "tokens": 8510242816,
        "learning_rate": 0.0003096378827586323,
        "gradient_norm": 0.3081740438938141,
        "train_loss": 3.0728654861450195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16233,
        "tokens": 8510767104,
        "learning_rate": 0.0003096093186762011,
        "gradient_norm": 0.2828961908817291,
        "train_loss": 3.050748348236084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16234,
        "tokens": 8511291392,
        "learning_rate": 0.00030958075482329236,
        "gradient_norm": 0.3150781989097595,
        "train_loss": 3.1046833992004395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16235,
        "tokens": 8511815680,
        "learning_rate": 0.0003095521912002278,
        "gradient_norm": 0.2708972990512848,
        "train_loss": 3.1306004524230957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16236,
        "tokens": 8512339968,
        "learning_rate": 0.00030952362780732866,
        "gradient_norm": 0.31227561831474304,
        "train_loss": 3.084972381591797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16237,
        "tokens": 8512864256,
        "learning_rate": 0.0003094950646449168,
        "gradient_norm": 0.27334898710250854,
        "train_loss": 3.1313722133636475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16238,
        "tokens": 8513388544,
        "learning_rate": 0.00030946650171331336,
        "gradient_norm": 0.30043354630470276,
        "train_loss": 3.0910282135009766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16239,
        "tokens": 8513912832,
        "learning_rate": 0.0003094379390128402,
        "gradient_norm": 0.30270034074783325,
        "train_loss": 3.249194622039795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16240,
        "tokens": 8514437120,
        "learning_rate": 0.00030940937654381855,
        "gradient_norm": 0.35999682545661926,
        "train_loss": 3.028761386871338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16241,
        "tokens": 8514961408,
        "learning_rate": 0.00030938081430657014,
        "gradient_norm": 0.30537310242652893,
        "train_loss": 3.134780168533325,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16242,
        "tokens": 8515485696,
        "learning_rate": 0.0003093522523014163,
        "gradient_norm": 0.33464139699935913,
        "train_loss": 3.143507957458496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16243,
        "tokens": 8516009984,
        "learning_rate": 0.00030932369052867864,
        "gradient_norm": 0.3691839873790741,
        "train_loss": 3.132498264312744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16244,
        "tokens": 8516534272,
        "learning_rate": 0.00030929512898867853,
        "gradient_norm": 0.33407503366470337,
        "train_loss": 3.0402426719665527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16245,
        "tokens": 8517058560,
        "learning_rate": 0.00030926656768173754,
        "gradient_norm": 0.3425823450088501,
        "train_loss": 3.0484819412231445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16246,
        "tokens": 8517582848,
        "learning_rate": 0.0003092380066081773,
        "gradient_norm": 0.3303498923778534,
        "train_loss": 3.1403448581695557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16247,
        "tokens": 8518107136,
        "learning_rate": 0.0003092094457683191,
        "gradient_norm": 0.37353742122650146,
        "train_loss": 3.065335273742676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16248,
        "tokens": 8518631424,
        "learning_rate": 0.0003091808851624846,
        "gradient_norm": 0.33293673396110535,
        "train_loss": 3.087348222732544,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16249,
        "tokens": 8519155712,
        "learning_rate": 0.000309152324790995,
        "gradient_norm": 0.3533107042312622,
        "train_loss": 3.069334030151367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16250,
        "tokens": 8519680000,
        "learning_rate": 0.0003091237646541722,
        "gradient_norm": 0.3326807916164398,
        "train_loss": 3.1120829582214355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16251,
        "tokens": 8520204288,
        "learning_rate": 0.00030909520475233727,
        "gradient_norm": 0.3395938277244568,
        "train_loss": 3.132154941558838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16252,
        "tokens": 8520728576,
        "learning_rate": 0.000309066645085812,
        "gradient_norm": 0.31899550557136536,
        "train_loss": 3.125946044921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16253,
        "tokens": 8521252864,
        "learning_rate": 0.0003090380856549176,
        "gradient_norm": 0.3040289878845215,
        "train_loss": 3.0610909461975098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16254,
        "tokens": 8521777152,
        "learning_rate": 0.00030900952645997567,
        "gradient_norm": 0.31449419260025024,
        "train_loss": 3.058605909347534,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16255,
        "tokens": 8522301440,
        "learning_rate": 0.00030898096750130784,
        "gradient_norm": 0.3107473850250244,
        "train_loss": 3.080162286758423,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16256,
        "tokens": 8522825728,
        "learning_rate": 0.0003089524087792353,
        "gradient_norm": 0.3046489357948303,
        "train_loss": 3.107133388519287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16257,
        "tokens": 8523350016,
        "learning_rate": 0.00030892385029407973,
        "gradient_norm": 0.3240783214569092,
        "train_loss": 3.1261746883392334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16258,
        "tokens": 8523874304,
        "learning_rate": 0.00030889529204616243,
        "gradient_norm": 0.32084354758262634,
        "train_loss": 3.100621461868286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16259,
        "tokens": 8524398592,
        "learning_rate": 0.00030886673403580494,
        "gradient_norm": 0.3144959807395935,
        "train_loss": 3.1032304763793945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16260,
        "tokens": 8524922880,
        "learning_rate": 0.00030883817626332867,
        "gradient_norm": 0.3397168815135956,
        "train_loss": 3.086808204650879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16261,
        "tokens": 8525447168,
        "learning_rate": 0.0003088096187290552,
        "gradient_norm": 0.3132037818431854,
        "train_loss": 3.138195037841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16262,
        "tokens": 8525971456,
        "learning_rate": 0.00030878106143330576,
        "gradient_norm": 0.34970635175704956,
        "train_loss": 3.0982346534729004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16263,
        "tokens": 8526495744,
        "learning_rate": 0.00030875250437640205,
        "gradient_norm": 0.6270915269851685,
        "train_loss": 3.25070858001709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16264,
        "tokens": 8527020032,
        "learning_rate": 0.00030872394755866527,
        "gradient_norm": 0.44038116931915283,
        "train_loss": 3.1061599254608154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16265,
        "tokens": 8527544320,
        "learning_rate": 0.000308695390980417,
        "gradient_norm": 0.4088039696216583,
        "train_loss": 3.112299680709839,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16266,
        "tokens": 8528068608,
        "learning_rate": 0.00030866683464197877,
        "gradient_norm": 0.3562397360801697,
        "train_loss": 3.0537168979644775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16267,
        "tokens": 8528592896,
        "learning_rate": 0.00030863827854367177,
        "gradient_norm": 0.3579728603363037,
        "train_loss": 3.07045316696167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16268,
        "tokens": 8529117184,
        "learning_rate": 0.0003086097226858177,
        "gradient_norm": 0.3335799276828766,
        "train_loss": 3.074144124984741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16269,
        "tokens": 8529641472,
        "learning_rate": 0.00030858116706873774,
        "gradient_norm": 0.34989336133003235,
        "train_loss": 3.11337947845459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16270,
        "tokens": 8530165760,
        "learning_rate": 0.0003085526116927536,
        "gradient_norm": 0.33688294887542725,
        "train_loss": 3.117900848388672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16271,
        "tokens": 8530690048,
        "learning_rate": 0.0003085240565581864,
        "gradient_norm": 0.3352656066417694,
        "train_loss": 3.0993828773498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16272,
        "tokens": 8531214336,
        "learning_rate": 0.00030849550166535785,
        "gradient_norm": 0.3171979486942291,
        "train_loss": 3.089707374572754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16273,
        "tokens": 8531738624,
        "learning_rate": 0.00030846694701458906,
        "gradient_norm": 0.3329892158508301,
        "train_loss": 3.1490206718444824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16274,
        "tokens": 8532262912,
        "learning_rate": 0.00030843839260620174,
        "gradient_norm": 0.31005600094795227,
        "train_loss": 3.09857439994812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16275,
        "tokens": 8532787200,
        "learning_rate": 0.00030840983844051715,
        "gradient_norm": 0.3239201009273529,
        "train_loss": 3.0952706336975098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16276,
        "tokens": 8533311488,
        "learning_rate": 0.00030838128451785674,
        "gradient_norm": 0.32693564891815186,
        "train_loss": 3.1248812675476074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16277,
        "tokens": 8533835776,
        "learning_rate": 0.000308352730838542,
        "gradient_norm": 0.3858902156352997,
        "train_loss": 3.0804834365844727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16278,
        "tokens": 8534360064,
        "learning_rate": 0.0003083241774028942,
        "gradient_norm": 0.3060016334056854,
        "train_loss": 3.156942844390869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16279,
        "tokens": 8534884352,
        "learning_rate": 0.00030829562421123477,
        "gradient_norm": 0.38423919677734375,
        "train_loss": 3.1183266639709473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16280,
        "tokens": 8535408640,
        "learning_rate": 0.0003082670712638852,
        "gradient_norm": 0.31638041138648987,
        "train_loss": 3.100881338119507,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16281,
        "tokens": 8535932928,
        "learning_rate": 0.00030823851856116684,
        "gradient_norm": 0.3490220606327057,
        "train_loss": 3.052011251449585,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16282,
        "tokens": 8536457216,
        "learning_rate": 0.00030820996610340104,
        "gradient_norm": 0.340903639793396,
        "train_loss": 3.2016496658325195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16283,
        "tokens": 8536981504,
        "learning_rate": 0.0003081814138909092,
        "gradient_norm": 0.36176297068595886,
        "train_loss": 3.0870041847229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16284,
        "tokens": 8537505792,
        "learning_rate": 0.00030815286192401286,
        "gradient_norm": 0.3167528808116913,
        "train_loss": 3.0861682891845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16285,
        "tokens": 8538030080,
        "learning_rate": 0.00030812431020303313,
        "gradient_norm": 0.35302236676216125,
        "train_loss": 3.1173031330108643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16286,
        "tokens": 8538554368,
        "learning_rate": 0.0003080957587282917,
        "gradient_norm": 0.3128497004508972,
        "train_loss": 3.1573987007141113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16287,
        "tokens": 8539078656,
        "learning_rate": 0.00030806720750010974,
        "gradient_norm": 0.38312384486198425,
        "train_loss": 3.1253104209899902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16288,
        "tokens": 8539602944,
        "learning_rate": 0.0003080386565188088,
        "gradient_norm": 0.30116936564445496,
        "train_loss": 3.0929629802703857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16289,
        "tokens": 8540127232,
        "learning_rate": 0.00030801010578471,
        "gradient_norm": 0.32148832082748413,
        "train_loss": 3.0818238258361816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16290,
        "tokens": 8540651520,
        "learning_rate": 0.000307981555298135,
        "gradient_norm": 0.30405181646347046,
        "train_loss": 3.123368740081787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16291,
        "tokens": 8541175808,
        "learning_rate": 0.0003079530050594049,
        "gradient_norm": 0.29232901334762573,
        "train_loss": 3.146271228790283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16292,
        "tokens": 8541700096,
        "learning_rate": 0.0003079244550688414,
        "gradient_norm": 0.32409754395484924,
        "train_loss": 3.0410776138305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16293,
        "tokens": 8542224384,
        "learning_rate": 0.0003078959053267655,
        "gradient_norm": 0.29294657707214355,
        "train_loss": 3.107208251953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16294,
        "tokens": 8542748672,
        "learning_rate": 0.00030786735583349876,
        "gradient_norm": 0.33773088455200195,
        "train_loss": 3.0175423622131348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16295,
        "tokens": 8543272960,
        "learning_rate": 0.00030783880658936263,
        "gradient_norm": 0.32219982147216797,
        "train_loss": 3.078951120376587,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16296,
        "tokens": 8543797248,
        "learning_rate": 0.0003078102575946783,
        "gradient_norm": 0.349086731672287,
        "train_loss": 3.1528568267822266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16297,
        "tokens": 8544321536,
        "learning_rate": 0.0003077817088497672,
        "gradient_norm": 0.37611454725265503,
        "train_loss": 3.1777076721191406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16298,
        "tokens": 8544845824,
        "learning_rate": 0.0003077531603549506,
        "gradient_norm": 0.3046390414237976,
        "train_loss": 3.0619864463806152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16299,
        "tokens": 8545370112,
        "learning_rate": 0.00030772461211054996,
        "gradient_norm": 0.36383897066116333,
        "train_loss": 3.1370837688446045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16300,
        "tokens": 8545894400,
        "learning_rate": 0.00030769606411688654,
        "gradient_norm": 0.2759060263633728,
        "train_loss": 3.0418946743011475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16301,
        "tokens": 8546418688,
        "learning_rate": 0.00030766751637428184,
        "gradient_norm": 0.3742218017578125,
        "train_loss": 3.0929296016693115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16302,
        "tokens": 8546942976,
        "learning_rate": 0.00030763896888305695,
        "gradient_norm": 0.2879343330860138,
        "train_loss": 3.0861639976501465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16303,
        "tokens": 8547467264,
        "learning_rate": 0.0003076104216435334,
        "gradient_norm": 0.3284763991832733,
        "train_loss": 3.1140005588531494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16304,
        "tokens": 8547991552,
        "learning_rate": 0.0003075818746560324,
        "gradient_norm": 0.3256490230560303,
        "train_loss": 3.1068150997161865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16305,
        "tokens": 8548515840,
        "learning_rate": 0.00030755332792087536,
        "gradient_norm": 0.30668920278549194,
        "train_loss": 3.1217057704925537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16306,
        "tokens": 8549040128,
        "learning_rate": 0.00030752478143838367,
        "gradient_norm": 0.33527350425720215,
        "train_loss": 3.1290488243103027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16307,
        "tokens": 8549564416,
        "learning_rate": 0.0003074962352088785,
        "gradient_norm": 0.27692437171936035,
        "train_loss": 3.0758485794067383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16308,
        "tokens": 8550088704,
        "learning_rate": 0.00030746768923268136,
        "gradient_norm": 0.32643961906433105,
        "train_loss": 3.080350875854492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16309,
        "tokens": 8550612992,
        "learning_rate": 0.0003074391435101133,
        "gradient_norm": 0.27140921354293823,
        "train_loss": 3.1012420654296875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16310,
        "tokens": 8551137280,
        "learning_rate": 0.000307410598041496,
        "gradient_norm": 0.3383631408214569,
        "train_loss": 3.1437580585479736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16311,
        "tokens": 8551661568,
        "learning_rate": 0.0003073820528271504,
        "gradient_norm": 0.2804173231124878,
        "train_loss": 3.052030563354492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16312,
        "tokens": 8552185856,
        "learning_rate": 0.00030735350786739816,
        "gradient_norm": 0.29581308364868164,
        "train_loss": 3.1088247299194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16313,
        "tokens": 8552710144,
        "learning_rate": 0.0003073249631625603,
        "gradient_norm": 0.27802011370658875,
        "train_loss": 3.055006980895996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16314,
        "tokens": 8553234432,
        "learning_rate": 0.00030729641871295817,
        "gradient_norm": 0.2720981240272522,
        "train_loss": 3.0691795349121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16315,
        "tokens": 8553758720,
        "learning_rate": 0.0003072678745189133,
        "gradient_norm": 0.2944222092628479,
        "train_loss": 3.139955997467041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16316,
        "tokens": 8554283008,
        "learning_rate": 0.00030723933058074675,
        "gradient_norm": 0.25296279788017273,
        "train_loss": 3.0818862915039062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16317,
        "tokens": 8554807296,
        "learning_rate": 0.00030721078689878,
        "gradient_norm": 0.3207700848579407,
        "train_loss": 3.1280388832092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16318,
        "tokens": 8555331584,
        "learning_rate": 0.00030718224347333413,
        "gradient_norm": 0.29642847180366516,
        "train_loss": 3.094162940979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16319,
        "tokens": 8555855872,
        "learning_rate": 0.00030715370030473066,
        "gradient_norm": 0.2918941378593445,
        "train_loss": 3.092276096343994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16320,
        "tokens": 8556380160,
        "learning_rate": 0.00030712515739329067,
        "gradient_norm": 0.30560317635536194,
        "train_loss": 3.073878765106201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16321,
        "tokens": 8556904448,
        "learning_rate": 0.0003070966147393357,
        "gradient_norm": 0.2990630269050598,
        "train_loss": 3.135549306869507,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16322,
        "tokens": 8557428736,
        "learning_rate": 0.00030706807234318675,
        "gradient_norm": 0.3060612678527832,
        "train_loss": 3.092411518096924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16323,
        "tokens": 8557953024,
        "learning_rate": 0.0003070395302051653,
        "gradient_norm": 0.3175763785839081,
        "train_loss": 3.055727481842041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16324,
        "tokens": 8558477312,
        "learning_rate": 0.00030701098832559246,
        "gradient_norm": 0.3139387369155884,
        "train_loss": 3.0757975578308105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16325,
        "tokens": 8559001600,
        "learning_rate": 0.00030698244670478966,
        "gradient_norm": 0.3052706718444824,
        "train_loss": 3.0605592727661133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16326,
        "tokens": 8559525888,
        "learning_rate": 0.0003069539053430782,
        "gradient_norm": 0.301750510931015,
        "train_loss": 3.0472946166992188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16327,
        "tokens": 8560050176,
        "learning_rate": 0.0003069253642407791,
        "gradient_norm": 0.3646909296512604,
        "train_loss": 3.083545684814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16328,
        "tokens": 8560574464,
        "learning_rate": 0.00030689682339821395,
        "gradient_norm": 0.3171713948249817,
        "train_loss": 3.133389711380005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16329,
        "tokens": 8561098752,
        "learning_rate": 0.0003068682828157037,
        "gradient_norm": 0.3548644185066223,
        "train_loss": 3.144239902496338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16330,
        "tokens": 8561623040,
        "learning_rate": 0.0003068397424935699,
        "gradient_norm": 0.31531575322151184,
        "train_loss": 3.1043553352355957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16331,
        "tokens": 8562147328,
        "learning_rate": 0.00030681120243213354,
        "gradient_norm": 0.3159358501434326,
        "train_loss": 3.123591899871826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16332,
        "tokens": 8562671616,
        "learning_rate": 0.00030678266263171617,
        "gradient_norm": 0.34945595264434814,
        "train_loss": 3.0843899250030518,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16333,
        "tokens": 8563195904,
        "learning_rate": 0.0003067541230926387,
        "gradient_norm": 0.31513747572898865,
        "train_loss": 3.0998477935791016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16334,
        "tokens": 8563720192,
        "learning_rate": 0.0003067255838152226,
        "gradient_norm": 0.34584110975265503,
        "train_loss": 3.087092399597168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16335,
        "tokens": 8564244480,
        "learning_rate": 0.00030669704479978913,
        "gradient_norm": 0.33374181389808655,
        "train_loss": 3.1005382537841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16336,
        "tokens": 8564768768,
        "learning_rate": 0.0003066685060466594,
        "gradient_norm": 0.3450465202331543,
        "train_loss": 3.109104871749878,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16337,
        "tokens": 8565293056,
        "learning_rate": 0.00030663996755615476,
        "gradient_norm": 0.3474930226802826,
        "train_loss": 3.1340627670288086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16338,
        "tokens": 8565817344,
        "learning_rate": 0.0003066114293285964,
        "gradient_norm": 0.2968888282775879,
        "train_loss": 3.103693962097168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16339,
        "tokens": 8566341632,
        "learning_rate": 0.0003065828913643055,
        "gradient_norm": 0.3619409501552582,
        "train_loss": 3.1449763774871826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16340,
        "tokens": 8566865920,
        "learning_rate": 0.00030655435366360345,
        "gradient_norm": 0.2988753020763397,
        "train_loss": 3.100283622741699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16341,
        "tokens": 8567390208,
        "learning_rate": 0.00030652581622681133,
        "gradient_norm": 0.3754798173904419,
        "train_loss": 3.096235752105713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16342,
        "tokens": 8567914496,
        "learning_rate": 0.0003064972790542504,
        "gradient_norm": 0.32948827743530273,
        "train_loss": 3.040719509124756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16343,
        "tokens": 8568438784,
        "learning_rate": 0.00030646874214624193,
        "gradient_norm": 0.36299392580986023,
        "train_loss": 3.1537623405456543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16344,
        "tokens": 8568963072,
        "learning_rate": 0.00030644020550310704,
        "gradient_norm": 0.35212311148643494,
        "train_loss": 3.1257481575012207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16345,
        "tokens": 8569487360,
        "learning_rate": 0.000306411669125167,
        "gradient_norm": 0.3243744671344757,
        "train_loss": 3.1445021629333496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16346,
        "tokens": 8570011648,
        "learning_rate": 0.0003063831330127431,
        "gradient_norm": 0.32980892062187195,
        "train_loss": 3.076704978942871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16347,
        "tokens": 8570535936,
        "learning_rate": 0.00030635459716615637,
        "gradient_norm": 0.3041800260543823,
        "train_loss": 3.0936050415039062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16348,
        "tokens": 8571060224,
        "learning_rate": 0.00030632606158572826,
        "gradient_norm": 0.2955448627471924,
        "train_loss": 3.0921571254730225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16349,
        "tokens": 8571584512,
        "learning_rate": 0.0003062975262717797,
        "gradient_norm": 0.3127877414226532,
        "train_loss": 3.080720901489258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16350,
        "tokens": 8572108800,
        "learning_rate": 0.0003062689912246321,
        "gradient_norm": 0.2672867178916931,
        "train_loss": 3.1349735260009766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16351,
        "tokens": 8572633088,
        "learning_rate": 0.00030624045644460655,
        "gradient_norm": 0.364399254322052,
        "train_loss": 3.0742642879486084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16352,
        "tokens": 8573157376,
        "learning_rate": 0.00030621192193202435,
        "gradient_norm": 0.27616026997566223,
        "train_loss": 3.051548480987549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16353,
        "tokens": 8573681664,
        "learning_rate": 0.0003061833876872065,
        "gradient_norm": 0.3665587604045868,
        "train_loss": 3.1332850456237793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16354,
        "tokens": 8574205952,
        "learning_rate": 0.0003061548537104744,
        "gradient_norm": 0.31647032499313354,
        "train_loss": 3.080906629562378,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16355,
        "tokens": 8574730240,
        "learning_rate": 0.00030612632000214917,
        "gradient_norm": 0.3215673565864563,
        "train_loss": 3.1257529258728027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16356,
        "tokens": 8575254528,
        "learning_rate": 0.0003060977865625519,
        "gradient_norm": 0.26875534653663635,
        "train_loss": 3.0412497520446777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16357,
        "tokens": 8575778816,
        "learning_rate": 0.0003060692533920039,
        "gradient_norm": 0.33336326479911804,
        "train_loss": 3.08804988861084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16358,
        "tokens": 8576303104,
        "learning_rate": 0.0003060407204908262,
        "gradient_norm": 0.2798670530319214,
        "train_loss": 3.07291316986084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16359,
        "tokens": 8576827392,
        "learning_rate": 0.00030601218785934015,
        "gradient_norm": 0.4553944170475006,
        "train_loss": 3.143191337585449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16360,
        "tokens": 8577351680,
        "learning_rate": 0.0003059836554978668,
        "gradient_norm": 0.40440404415130615,
        "train_loss": 3.1474769115448,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16361,
        "tokens": 8577875968,
        "learning_rate": 0.00030595512340672734,
        "gradient_norm": 0.36508747935295105,
        "train_loss": 3.125034809112549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16362,
        "tokens": 8578400256,
        "learning_rate": 0.00030592659158624287,
        "gradient_norm": 0.33892756700515747,
        "train_loss": 3.0798192024230957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16363,
        "tokens": 8578924544,
        "learning_rate": 0.0003058980600367348,
        "gradient_norm": 0.33638790249824524,
        "train_loss": 3.1002655029296875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16364,
        "tokens": 8579448832,
        "learning_rate": 0.0003058695287585239,
        "gradient_norm": 0.31549108028411865,
        "train_loss": 3.1084165573120117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16365,
        "tokens": 8579973120,
        "learning_rate": 0.0003058409977519315,
        "gradient_norm": 0.33042970299720764,
        "train_loss": 3.1211442947387695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16366,
        "tokens": 8580497408,
        "learning_rate": 0.000305812467017279,
        "gradient_norm": 0.3311423659324646,
        "train_loss": 3.0799155235290527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16367,
        "tokens": 8581021696,
        "learning_rate": 0.0003057839365548872,
        "gradient_norm": 0.3535885214805603,
        "train_loss": 3.1589157581329346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16368,
        "tokens": 8581545984,
        "learning_rate": 0.0003057554063650775,
        "gradient_norm": 0.33699947595596313,
        "train_loss": 3.109663963317871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16369,
        "tokens": 8582070272,
        "learning_rate": 0.00030572687644817075,
        "gradient_norm": 0.32234713435173035,
        "train_loss": 3.104621410369873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16370,
        "tokens": 8582594560,
        "learning_rate": 0.0003056983468044884,
        "gradient_norm": 0.3795437514781952,
        "train_loss": 3.0317440032958984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16371,
        "tokens": 8583118848,
        "learning_rate": 0.0003056698174343514,
        "gradient_norm": 0.33165690302848816,
        "train_loss": 3.1271538734436035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16372,
        "tokens": 8583643136,
        "learning_rate": 0.000305641288338081,
        "gradient_norm": 0.40080246329307556,
        "train_loss": 3.0920145511627197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16373,
        "tokens": 8584167424,
        "learning_rate": 0.00030561275951599814,
        "gradient_norm": 0.3781645596027374,
        "train_loss": 3.157681465148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16374,
        "tokens": 8584691712,
        "learning_rate": 0.00030558423096842404,
        "gradient_norm": 0.38071244955062866,
        "train_loss": 3.0818324089050293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16375,
        "tokens": 8585216000,
        "learning_rate": 0.00030555570269568,
        "gradient_norm": 0.3634258806705475,
        "train_loss": 2.996029853820801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16376,
        "tokens": 8585740288,
        "learning_rate": 0.00030552717469808693,
        "gradient_norm": 0.3428124487400055,
        "train_loss": 3.1183385848999023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16377,
        "tokens": 8586264576,
        "learning_rate": 0.0003054986469759661,
        "gradient_norm": 0.35820916295051575,
        "train_loss": 3.1031410694122314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16378,
        "tokens": 8586788864,
        "learning_rate": 0.0003054701195296384,
        "gradient_norm": 0.3306438624858856,
        "train_loss": 3.069572925567627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16379,
        "tokens": 8587313152,
        "learning_rate": 0.00030544159235942523,
        "gradient_norm": 0.30701926350593567,
        "train_loss": 3.1022214889526367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16380,
        "tokens": 8587837440,
        "learning_rate": 0.00030541306546564743,
        "gradient_norm": 0.317554235458374,
        "train_loss": 3.1767303943634033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16381,
        "tokens": 8588361728,
        "learning_rate": 0.0003053845388486263,
        "gradient_norm": 0.3311207592487335,
        "train_loss": 3.0775113105773926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16382,
        "tokens": 8588886016,
        "learning_rate": 0.0003053560125086828,
        "gradient_norm": 0.32565492391586304,
        "train_loss": 3.095339775085449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16383,
        "tokens": 8589410304,
        "learning_rate": 0.0003053274864461382,
        "gradient_norm": 0.3242415487766266,
        "train_loss": 3.0829453468322754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16384,
        "tokens": 8589934592,
        "learning_rate": 0.0003052989606613134,
        "gradient_norm": 0.37342071533203125,
        "train_loss": 3.141188383102417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16385,
        "tokens": 8590458880,
        "learning_rate": 0.00030527043515452955,
        "gradient_norm": 0.35559946298599243,
        "train_loss": 3.064180374145508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16386,
        "tokens": 8590983168,
        "learning_rate": 0.00030524190992610786,
        "gradient_norm": 0.4172815978527069,
        "train_loss": 3.154730796813965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16387,
        "tokens": 8591507456,
        "learning_rate": 0.00030521338497636934,
        "gradient_norm": 0.3093419671058655,
        "train_loss": 3.1145501136779785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16388,
        "tokens": 8592031744,
        "learning_rate": 0.00030518486030563506,
        "gradient_norm": 0.37099146842956543,
        "train_loss": 3.106257915496826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16389,
        "tokens": 8592556032,
        "learning_rate": 0.0003051563359142261,
        "gradient_norm": 0.3180887997150421,
        "train_loss": 3.0396225452423096,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16390,
        "tokens": 8593080320,
        "learning_rate": 0.00030512781180246356,
        "gradient_norm": 0.33478185534477234,
        "train_loss": 3.0858168601989746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16391,
        "tokens": 8593604608,
        "learning_rate": 0.00030509928797066855,
        "gradient_norm": 0.2996201515197754,
        "train_loss": 3.129270076751709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16392,
        "tokens": 8594128896,
        "learning_rate": 0.00030507076441916203,
        "gradient_norm": 0.3271024525165558,
        "train_loss": 3.0885276794433594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16393,
        "tokens": 8594653184,
        "learning_rate": 0.00030504224114826515,
        "gradient_norm": 0.3335723280906677,
        "train_loss": 3.131822109222412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16394,
        "tokens": 8595177472,
        "learning_rate": 0.00030501371815829886,
        "gradient_norm": 0.2969840168952942,
        "train_loss": 3.1157445907592773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16395,
        "tokens": 8595701760,
        "learning_rate": 0.0003049851954495845,
        "gradient_norm": 0.32122698426246643,
        "train_loss": 3.143176317214966,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16396,
        "tokens": 8596226048,
        "learning_rate": 0.0003049566730224428,
        "gradient_norm": 0.2929063141345978,
        "train_loss": 3.1268692016601562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16397,
        "tokens": 8596750336,
        "learning_rate": 0.000304928150877195,
        "gradient_norm": 0.28632652759552,
        "train_loss": 3.1088621616363525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16398,
        "tokens": 8597274624,
        "learning_rate": 0.0003048996290141621,
        "gradient_norm": 0.28775298595428467,
        "train_loss": 3.132503032684326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16399,
        "tokens": 8597798912,
        "learning_rate": 0.0003048711074336653,
        "gradient_norm": 0.2949816584587097,
        "train_loss": 3.062328338623047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16400,
        "tokens": 8598323200,
        "learning_rate": 0.00030484258613602534,
        "gradient_norm": 0.3096942603588104,
        "train_loss": 3.072080612182617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16401,
        "tokens": 8598847488,
        "learning_rate": 0.00030481406512156356,
        "gradient_norm": 0.2949785590171814,
        "train_loss": 3.141575336456299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16402,
        "tokens": 8599371776,
        "learning_rate": 0.0003047855443906007,
        "gradient_norm": 0.3138865530490875,
        "train_loss": 3.147164821624756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16403,
        "tokens": 8599896064,
        "learning_rate": 0.0003047570239434582,
        "gradient_norm": 0.3170110881328583,
        "train_loss": 3.062243938446045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16404,
        "tokens": 8600420352,
        "learning_rate": 0.00030472850378045663,
        "gradient_norm": 0.33422815799713135,
        "train_loss": 3.0712332725524902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16405,
        "tokens": 8600944640,
        "learning_rate": 0.0003046999839019173,
        "gradient_norm": 0.3596447706222534,
        "train_loss": 3.1048288345336914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16406,
        "tokens": 8601468928,
        "learning_rate": 0.0003046714643081613,
        "gradient_norm": 0.2968239486217499,
        "train_loss": 3.0520925521850586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16407,
        "tokens": 8601993216,
        "learning_rate": 0.00030464294499950946,
        "gradient_norm": 0.33505305647850037,
        "train_loss": 3.135568380355835,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16408,
        "tokens": 8602517504,
        "learning_rate": 0.000304614425976283,
        "gradient_norm": 0.29666972160339355,
        "train_loss": 3.1133885383605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16409,
        "tokens": 8603041792,
        "learning_rate": 0.00030458590723880265,
        "gradient_norm": 0.33476901054382324,
        "train_loss": 3.1275248527526855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16410,
        "tokens": 8603566080,
        "learning_rate": 0.00030455738878738977,
        "gradient_norm": 0.2895374894142151,
        "train_loss": 3.0990400314331055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16411,
        "tokens": 8604090368,
        "learning_rate": 0.000304528870622365,
        "gradient_norm": 0.33024483919143677,
        "train_loss": 3.0569827556610107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16412,
        "tokens": 8604614656,
        "learning_rate": 0.0003045003527440497,
        "gradient_norm": 0.29665783047676086,
        "train_loss": 3.0691027641296387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16413,
        "tokens": 8605138944,
        "learning_rate": 0.0003044718351527646,
        "gradient_norm": 0.2804720997810364,
        "train_loss": 3.1202659606933594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16414,
        "tokens": 8605663232,
        "learning_rate": 0.0003044433178488308,
        "gradient_norm": 0.3172847330570221,
        "train_loss": 3.1155457496643066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16415,
        "tokens": 8606187520,
        "learning_rate": 0.0003044148008325695,
        "gradient_norm": 0.28801435232162476,
        "train_loss": 3.0783801078796387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16416,
        "tokens": 8606711808,
        "learning_rate": 0.00030438628410430136,
        "gradient_norm": 0.30619049072265625,
        "train_loss": 3.0978317260742188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16417,
        "tokens": 8607236096,
        "learning_rate": 0.0003043577676643476,
        "gradient_norm": 0.3077922463417053,
        "train_loss": 3.142948865890503,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16418,
        "tokens": 8607760384,
        "learning_rate": 0.00030432925151302904,
        "gradient_norm": 0.3055625855922699,
        "train_loss": 3.081636428833008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16419,
        "tokens": 8608284672,
        "learning_rate": 0.00030430073565066687,
        "gradient_norm": 0.3178471624851227,
        "train_loss": 3.093282699584961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16420,
        "tokens": 8608808960,
        "learning_rate": 0.0003042722200775818,
        "gradient_norm": 0.2816630005836487,
        "train_loss": 3.112165927886963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16421,
        "tokens": 8609333248,
        "learning_rate": 0.00030424370479409515,
        "gradient_norm": 0.3196013271808624,
        "train_loss": 3.079860210418701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16422,
        "tokens": 8609857536,
        "learning_rate": 0.0003042151898005275,
        "gradient_norm": 0.29517269134521484,
        "train_loss": 3.0984458923339844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16423,
        "tokens": 8610381824,
        "learning_rate": 0.0003041866750972002,
        "gradient_norm": 0.3040854036808014,
        "train_loss": 3.1295931339263916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16424,
        "tokens": 8610906112,
        "learning_rate": 0.000304158160684434,
        "gradient_norm": 0.3032240867614746,
        "train_loss": 3.1111416816711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16425,
        "tokens": 8611430400,
        "learning_rate": 0.0003041296465625498,
        "gradient_norm": 0.31107309460639954,
        "train_loss": 3.061450958251953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16426,
        "tokens": 8611954688,
        "learning_rate": 0.0003041011327318689,
        "gradient_norm": 0.33361420035362244,
        "train_loss": 3.1279780864715576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16427,
        "tokens": 8612478976,
        "learning_rate": 0.0003040726191927118,
        "gradient_norm": 0.33308160305023193,
        "train_loss": 3.089285135269165,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16428,
        "tokens": 8613003264,
        "learning_rate": 0.00030404410594539986,
        "gradient_norm": 0.33046504855155945,
        "train_loss": 3.0441431999206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16429,
        "tokens": 8613527552,
        "learning_rate": 0.0003040155929902537,
        "gradient_norm": 0.3443213105201721,
        "train_loss": 3.131936550140381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16430,
        "tokens": 8614051840,
        "learning_rate": 0.00030398708032759465,
        "gradient_norm": 0.33292555809020996,
        "train_loss": 3.1015701293945312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16431,
        "tokens": 8614576128,
        "learning_rate": 0.00030395856795774323,
        "gradient_norm": 0.3253139853477478,
        "train_loss": 3.114206075668335,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16432,
        "tokens": 8615100416,
        "learning_rate": 0.00030393005588102084,
        "gradient_norm": 0.33462825417518616,
        "train_loss": 3.181976079940796,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16433,
        "tokens": 8615624704,
        "learning_rate": 0.0003039015440977479,
        "gradient_norm": 0.34873083233833313,
        "train_loss": 3.0961413383483887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16434,
        "tokens": 8616148992,
        "learning_rate": 0.0003038730326082457,
        "gradient_norm": 0.3308403789997101,
        "train_loss": 3.0908737182617188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16435,
        "tokens": 8616673280,
        "learning_rate": 0.00030384452141283516,
        "gradient_norm": 0.2879912555217743,
        "train_loss": 3.107429027557373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16436,
        "tokens": 8617197568,
        "learning_rate": 0.0003038160105118371,
        "gradient_norm": 0.3344271183013916,
        "train_loss": 3.0565061569213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16437,
        "tokens": 8617721856,
        "learning_rate": 0.0003037874999055725,
        "gradient_norm": 0.2717357575893402,
        "train_loss": 3.102259635925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16438,
        "tokens": 8618246144,
        "learning_rate": 0.0003037589895943622,
        "gradient_norm": 0.2986298203468323,
        "train_loss": 3.1167707443237305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16439,
        "tokens": 8618770432,
        "learning_rate": 0.0003037304795785272,
        "gradient_norm": 0.3376084268093109,
        "train_loss": 3.064100742340088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16440,
        "tokens": 8619294720,
        "learning_rate": 0.00030370196985838845,
        "gradient_norm": 0.3121582567691803,
        "train_loss": 3.128392219543457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16441,
        "tokens": 8619819008,
        "learning_rate": 0.00030367346043426674,
        "gradient_norm": 0.32900869846343994,
        "train_loss": 3.128350257873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16442,
        "tokens": 8620343296,
        "learning_rate": 0.0003036449513064831,
        "gradient_norm": 0.29502031207084656,
        "train_loss": 3.117715835571289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16443,
        "tokens": 8620867584,
        "learning_rate": 0.00030361644247535837,
        "gradient_norm": 0.2989515960216522,
        "train_loss": 3.0533604621887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16444,
        "tokens": 8621391872,
        "learning_rate": 0.00030358793394121345,
        "gradient_norm": 0.29410648345947266,
        "train_loss": 3.066913604736328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16445,
        "tokens": 8621916160,
        "learning_rate": 0.00030355942570436923,
        "gradient_norm": 0.28960591554641724,
        "train_loss": 3.089175224304199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16446,
        "tokens": 8622440448,
        "learning_rate": 0.00030353091776514675,
        "gradient_norm": 0.3084312975406647,
        "train_loss": 3.1064586639404297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16447,
        "tokens": 8622964736,
        "learning_rate": 0.00030350241012386665,
        "gradient_norm": 0.302043080329895,
        "train_loss": 3.089235305786133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16448,
        "tokens": 8623489024,
        "learning_rate": 0.00030347390278085004,
        "gradient_norm": 0.3084045648574829,
        "train_loss": 3.1079354286193848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16449,
        "tokens": 8624013312,
        "learning_rate": 0.00030344539573641765,
        "gradient_norm": 0.27918681502342224,
        "train_loss": 3.065674304962158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16450,
        "tokens": 8624537600,
        "learning_rate": 0.00030341688899089054,
        "gradient_norm": 0.31164494156837463,
        "train_loss": 3.1056861877441406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16451,
        "tokens": 8625061888,
        "learning_rate": 0.00030338838254458935,
        "gradient_norm": 0.3656601011753082,
        "train_loss": 3.130242347717285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16452,
        "tokens": 8625586176,
        "learning_rate": 0.0003033598763978352,
        "gradient_norm": 0.31267493963241577,
        "train_loss": 3.1398556232452393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16453,
        "tokens": 8626110464,
        "learning_rate": 0.00030333137055094876,
        "gradient_norm": 0.3223135769367218,
        "train_loss": 3.0731658935546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16454,
        "tokens": 8626634752,
        "learning_rate": 0.000303302865004251,
        "gradient_norm": 0.35649973154067993,
        "train_loss": 3.0980782508850098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16455,
        "tokens": 8627159040,
        "learning_rate": 0.0003032743597580629,
        "gradient_norm": 0.27188611030578613,
        "train_loss": 3.1159121990203857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16456,
        "tokens": 8627683328,
        "learning_rate": 0.00030324585481270505,
        "gradient_norm": 0.34403863549232483,
        "train_loss": 3.0616438388824463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16457,
        "tokens": 8628207616,
        "learning_rate": 0.0003032173501684985,
        "gradient_norm": 0.2923823595046997,
        "train_loss": 3.0974624156951904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16458,
        "tokens": 8628731904,
        "learning_rate": 0.00030318884582576405,
        "gradient_norm": 0.30875933170318604,
        "train_loss": 3.0250186920166016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16459,
        "tokens": 8629256192,
        "learning_rate": 0.00030316034178482263,
        "gradient_norm": 0.3125956058502197,
        "train_loss": 3.0949299335479736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16460,
        "tokens": 8629780480,
        "learning_rate": 0.0003031318380459949,
        "gradient_norm": 0.27196502685546875,
        "train_loss": 3.1077237129211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16461,
        "tokens": 8630304768,
        "learning_rate": 0.00030310333460960195,
        "gradient_norm": 0.3220229744911194,
        "train_loss": 3.130280017852783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16462,
        "tokens": 8630829056,
        "learning_rate": 0.0003030748314759644,
        "gradient_norm": 0.29139596223831177,
        "train_loss": 3.1471915245056152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16463,
        "tokens": 8631353344,
        "learning_rate": 0.00030304632864540317,
        "gradient_norm": 0.32579439878463745,
        "train_loss": 3.1242480278015137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16464,
        "tokens": 8631877632,
        "learning_rate": 0.0003030178261182392,
        "gradient_norm": 0.2946140766143799,
        "train_loss": 3.0794081687927246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16465,
        "tokens": 8632401920,
        "learning_rate": 0.00030298932389479313,
        "gradient_norm": 0.31091034412384033,
        "train_loss": 3.084385633468628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16466,
        "tokens": 8632926208,
        "learning_rate": 0.000302960821975386,
        "gradient_norm": 0.31373268365859985,
        "train_loss": 3.0699832439422607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16467,
        "tokens": 8633450496,
        "learning_rate": 0.0003029323203603384,
        "gradient_norm": 0.2993675768375397,
        "train_loss": 3.169316291809082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16468,
        "tokens": 8633974784,
        "learning_rate": 0.00030290381904997144,
        "gradient_norm": 0.31147411465644836,
        "train_loss": 3.14197039604187,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16469,
        "tokens": 8634499072,
        "learning_rate": 0.0003028753180446056,
        "gradient_norm": 0.35572612285614014,
        "train_loss": 3.364259719848633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16470,
        "tokens": 8635023360,
        "learning_rate": 0.00030284681734456205,
        "gradient_norm": 0.3349613547325134,
        "train_loss": 3.1033670902252197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16471,
        "tokens": 8635547648,
        "learning_rate": 0.00030281831695016127,
        "gradient_norm": 0.32407253980636597,
        "train_loss": 3.0914711952209473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16472,
        "tokens": 8636071936,
        "learning_rate": 0.00030278981686172434,
        "gradient_norm": 0.32268470525741577,
        "train_loss": 3.0792927742004395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16473,
        "tokens": 8636596224,
        "learning_rate": 0.00030276131707957177,
        "gradient_norm": 0.3242731988430023,
        "train_loss": 3.081871509552002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16474,
        "tokens": 8637120512,
        "learning_rate": 0.0003027328176040246,
        "gradient_norm": 0.3603162169456482,
        "train_loss": 3.2970409393310547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16475,
        "tokens": 8637644800,
        "learning_rate": 0.0003027043184354036,
        "gradient_norm": 0.3887053430080414,
        "train_loss": 3.0584850311279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16476,
        "tokens": 8638169088,
        "learning_rate": 0.0003026758195740295,
        "gradient_norm": 0.34994229674339294,
        "train_loss": 3.1155500411987305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16477,
        "tokens": 8638693376,
        "learning_rate": 0.0003026473210202231,
        "gradient_norm": 0.35651591420173645,
        "train_loss": 3.072570323944092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16478,
        "tokens": 8639217664,
        "learning_rate": 0.0003026188227743052,
        "gradient_norm": 0.36569467186927795,
        "train_loss": 3.1287481784820557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16479,
        "tokens": 8639741952,
        "learning_rate": 0.00030259032483659663,
        "gradient_norm": 0.35716360807418823,
        "train_loss": 3.074284791946411,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16480,
        "tokens": 8640266240,
        "learning_rate": 0.00030256182720741803,
        "gradient_norm": 0.3388639986515045,
        "train_loss": 3.126807451248169,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16481,
        "tokens": 8640790528,
        "learning_rate": 0.00030253332988709037,
        "gradient_norm": 0.3400701582431793,
        "train_loss": 3.063666820526123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16482,
        "tokens": 8641314816,
        "learning_rate": 0.0003025048328759342,
        "gradient_norm": 0.3131266236305237,
        "train_loss": 3.085552215576172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16483,
        "tokens": 8641839104,
        "learning_rate": 0.0003024763361742705,
        "gradient_norm": 0.33639127016067505,
        "train_loss": 3.075212001800537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16484,
        "tokens": 8642363392,
        "learning_rate": 0.0003024478397824199,
        "gradient_norm": 0.33277207612991333,
        "train_loss": 3.0821290016174316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16485,
        "tokens": 8642887680,
        "learning_rate": 0.00030241934370070327,
        "gradient_norm": 0.3699226379394531,
        "train_loss": 3.0746188163757324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16486,
        "tokens": 8643411968,
        "learning_rate": 0.00030239084792944127,
        "gradient_norm": 0.3364934027194977,
        "train_loss": 3.098367214202881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16487,
        "tokens": 8643936256,
        "learning_rate": 0.0003023623524689547,
        "gradient_norm": 0.37691646814346313,
        "train_loss": 3.120877742767334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16488,
        "tokens": 8644460544,
        "learning_rate": 0.0003023338573195643,
        "gradient_norm": 0.282814621925354,
        "train_loss": 3.0629472732543945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16489,
        "tokens": 8644984832,
        "learning_rate": 0.00030230536248159086,
        "gradient_norm": 0.37256765365600586,
        "train_loss": 3.1269171237945557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16490,
        "tokens": 8645509120,
        "learning_rate": 0.000302276867955355,
        "gradient_norm": 0.30925989151000977,
        "train_loss": 3.0783307552337646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16491,
        "tokens": 8646033408,
        "learning_rate": 0.0003022483737411776,
        "gradient_norm": 0.33145853877067566,
        "train_loss": 3.0692689418792725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16492,
        "tokens": 8646557696,
        "learning_rate": 0.00030221987983937936,
        "gradient_norm": 0.2817670404911041,
        "train_loss": 3.062331199645996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16493,
        "tokens": 8647081984,
        "learning_rate": 0.000302191386250281,
        "gradient_norm": 0.3195221722126007,
        "train_loss": 3.1096458435058594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16494,
        "tokens": 8647606272,
        "learning_rate": 0.0003021628929742032,
        "gradient_norm": 0.3024643659591675,
        "train_loss": 3.0827672481536865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16495,
        "tokens": 8648130560,
        "learning_rate": 0.0003021344000114668,
        "gradient_norm": 0.29641473293304443,
        "train_loss": 3.1503219604492188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16496,
        "tokens": 8648654848,
        "learning_rate": 0.00030210590736239236,
        "gradient_norm": 0.28831008076667786,
        "train_loss": 3.0578622817993164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16497,
        "tokens": 8649179136,
        "learning_rate": 0.00030207741502730087,
        "gradient_norm": 0.28433406352996826,
        "train_loss": 3.0878427028656006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16498,
        "tokens": 8649703424,
        "learning_rate": 0.00030204892300651277,
        "gradient_norm": 0.3311336636543274,
        "train_loss": 3.101595401763916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16499,
        "tokens": 8650227712,
        "learning_rate": 0.0003020204313003489,
        "gradient_norm": 0.2744573652744293,
        "train_loss": 3.02955961227417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16500,
        "tokens": 8650752000,
        "learning_rate": 0.00030199193990912995,
        "gradient_norm": 0.3124951422214508,
        "train_loss": 3.066873073577881,
        "val_loss": 3.058150291442871,
        "hellaswag_acc": 0.2795259952545166,
        "hellaswag_acc_norm": 0.29247161746025085
    },
    {
        "step": 16501,
        "tokens": 8651276288,
        "learning_rate": 0.00030196344883317666,
        "gradient_norm": 0.3017459809780121,
        "train_loss": 3.114272117614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16502,
        "tokens": 8651800576,
        "learning_rate": 0.0003019349580728097,
        "gradient_norm": 0.32467755675315857,
        "train_loss": 3.0921270847320557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16503,
        "tokens": 8652324864,
        "learning_rate": 0.0003019064676283497,
        "gradient_norm": 0.29514622688293457,
        "train_loss": 3.100342273712158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16504,
        "tokens": 8652849152,
        "learning_rate": 0.0003018779775001175,
        "gradient_norm": 0.290286123752594,
        "train_loss": 3.074206829071045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16505,
        "tokens": 8653373440,
        "learning_rate": 0.0003018494876884336,
        "gradient_norm": 0.29369619488716125,
        "train_loss": 3.0680556297302246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16506,
        "tokens": 8653897728,
        "learning_rate": 0.00030182099819361897,
        "gradient_norm": 0.26100656390190125,
        "train_loss": 3.086660861968994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16507,
        "tokens": 8654422016,
        "learning_rate": 0.000301792509015994,
        "gradient_norm": 0.29361289739608765,
        "train_loss": 3.078673839569092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16508,
        "tokens": 8654946304,
        "learning_rate": 0.0003017640201558796,
        "gradient_norm": 0.29103511571884155,
        "train_loss": 3.1323888301849365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16509,
        "tokens": 8655470592,
        "learning_rate": 0.00030173553161359627,
        "gradient_norm": 0.2881931960582733,
        "train_loss": 3.134277820587158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16510,
        "tokens": 8655994880,
        "learning_rate": 0.0003017070433894649,
        "gradient_norm": 0.29998692870140076,
        "train_loss": 3.1075708866119385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16511,
        "tokens": 8656519168,
        "learning_rate": 0.00030167855548380587,
        "gradient_norm": 0.30499982833862305,
        "train_loss": 3.089046001434326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16512,
        "tokens": 8657043456,
        "learning_rate": 0.0003016500678969401,
        "gradient_norm": 0.3131633400917053,
        "train_loss": 3.0648560523986816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16513,
        "tokens": 8657567744,
        "learning_rate": 0.00030162158062918814,
        "gradient_norm": 0.29163658618927,
        "train_loss": 3.085927963256836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16514,
        "tokens": 8658092032,
        "learning_rate": 0.0003015930936808705,
        "gradient_norm": 0.31580477952957153,
        "train_loss": 3.060202121734619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16515,
        "tokens": 8658616320,
        "learning_rate": 0.0003015646070523083,
        "gradient_norm": 0.2812296450138092,
        "train_loss": 3.0266048908233643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16516,
        "tokens": 8659140608,
        "learning_rate": 0.00030153612074382166,
        "gradient_norm": 0.4154832363128662,
        "train_loss": 3.1053342819213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16517,
        "tokens": 8659664896,
        "learning_rate": 0.0003015076347557316,
        "gradient_norm": 0.3649201989173889,
        "train_loss": 3.08821177482605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16518,
        "tokens": 8660189184,
        "learning_rate": 0.0003014791490883585,
        "gradient_norm": 0.338227242231369,
        "train_loss": 3.149080276489258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16519,
        "tokens": 8660713472,
        "learning_rate": 0.0003014506637420233,
        "gradient_norm": 0.34778764843940735,
        "train_loss": 3.0427000522613525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16520,
        "tokens": 8661237760,
        "learning_rate": 0.0003014221787170463,
        "gradient_norm": 0.37040257453918457,
        "train_loss": 3.09965181350708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16521,
        "tokens": 8661762048,
        "learning_rate": 0.00030139369401374844,
        "gradient_norm": 0.3400523364543915,
        "train_loss": 3.1279332637786865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16522,
        "tokens": 8662286336,
        "learning_rate": 0.00030136520963245,
        "gradient_norm": 0.3510003089904785,
        "train_loss": 3.0876173973083496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16523,
        "tokens": 8662810624,
        "learning_rate": 0.000301336725573472,
        "gradient_norm": 0.35384514927864075,
        "train_loss": 3.093416929244995,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16524,
        "tokens": 8663334912,
        "learning_rate": 0.00030130824183713487,
        "gradient_norm": 0.3107018768787384,
        "train_loss": 3.1210060119628906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16525,
        "tokens": 8663859200,
        "learning_rate": 0.0003012797584237592,
        "gradient_norm": 0.36569273471832275,
        "train_loss": 3.078653335571289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16526,
        "tokens": 8664383488,
        "learning_rate": 0.0003012512753336657,
        "gradient_norm": 0.31809139251708984,
        "train_loss": 3.1001553535461426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16527,
        "tokens": 8664907776,
        "learning_rate": 0.00030122279256717484,
        "gradient_norm": 0.3393189013004303,
        "train_loss": 3.0448460578918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16528,
        "tokens": 8665432064,
        "learning_rate": 0.00030119431012460743,
        "gradient_norm": 0.303587943315506,
        "train_loss": 3.0902280807495117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16529,
        "tokens": 8665956352,
        "learning_rate": 0.00030116582800628387,
        "gradient_norm": 0.3499685823917389,
        "train_loss": 3.1444835662841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16530,
        "tokens": 8666480640,
        "learning_rate": 0.00030113734621252494,
        "gradient_norm": 0.28966471552848816,
        "train_loss": 3.0744261741638184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16531,
        "tokens": 8667004928,
        "learning_rate": 0.0003011088647436511,
        "gradient_norm": 0.3374461531639099,
        "train_loss": 3.1083970069885254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16532,
        "tokens": 8667529216,
        "learning_rate": 0.00030108038359998306,
        "gradient_norm": 0.30816665291786194,
        "train_loss": 3.0844802856445312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16533,
        "tokens": 8668053504,
        "learning_rate": 0.0003010519027818413,
        "gradient_norm": 0.3038564622402191,
        "train_loss": 3.0387377738952637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16534,
        "tokens": 8668577792,
        "learning_rate": 0.0003010234222895464,
        "gradient_norm": 0.3148021996021271,
        "train_loss": 3.0762648582458496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16535,
        "tokens": 8669102080,
        "learning_rate": 0.00030099494212341917,
        "gradient_norm": 0.3407565653324127,
        "train_loss": 3.1024622917175293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16536,
        "tokens": 8669626368,
        "learning_rate": 0.00030096646228377984,
        "gradient_norm": 0.36751094460487366,
        "train_loss": 3.149055004119873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16537,
        "tokens": 8670150656,
        "learning_rate": 0.0003009379827709493,
        "gradient_norm": 0.3414647877216339,
        "train_loss": 3.123544454574585,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16538,
        "tokens": 8670674944,
        "learning_rate": 0.0003009095035852479,
        "gradient_norm": 0.32836100459098816,
        "train_loss": 3.1153347492218018,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16539,
        "tokens": 8671199232,
        "learning_rate": 0.0003008810247269964,
        "gradient_norm": 0.3223329186439514,
        "train_loss": 3.129302740097046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16540,
        "tokens": 8671723520,
        "learning_rate": 0.0003008525461965152,
        "gradient_norm": 0.35584574937820435,
        "train_loss": 3.172048568725586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16541,
        "tokens": 8672247808,
        "learning_rate": 0.00030082406799412497,
        "gradient_norm": 0.3153356909751892,
        "train_loss": 3.092595100402832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16542,
        "tokens": 8672772096,
        "learning_rate": 0.0003007955901201462,
        "gradient_norm": 0.35141777992248535,
        "train_loss": 3.1256163120269775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16543,
        "tokens": 8673296384,
        "learning_rate": 0.0003007671125748994,
        "gradient_norm": 0.3196195960044861,
        "train_loss": 3.06534481048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16544,
        "tokens": 8673820672,
        "learning_rate": 0.00030073863535870526,
        "gradient_norm": 0.3076176643371582,
        "train_loss": 3.060115337371826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16545,
        "tokens": 8674344960,
        "learning_rate": 0.00030071015847188426,
        "gradient_norm": 0.3157750070095062,
        "train_loss": 3.1141910552978516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16546,
        "tokens": 8674869248,
        "learning_rate": 0.0003006816819147569,
        "gradient_norm": 0.3070942163467407,
        "train_loss": 3.144224166870117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16547,
        "tokens": 8675393536,
        "learning_rate": 0.0003006532056876438,
        "gradient_norm": 0.3279845118522644,
        "train_loss": 3.0699262619018555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16548,
        "tokens": 8675917824,
        "learning_rate": 0.0003006247297908654,
        "gradient_norm": 0.3115561902523041,
        "train_loss": 3.0954689979553223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16549,
        "tokens": 8676442112,
        "learning_rate": 0.0003005962542247423,
        "gradient_norm": 0.31300681829452515,
        "train_loss": 3.0712149143218994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16550,
        "tokens": 8676966400,
        "learning_rate": 0.000300567778989595,
        "gradient_norm": 0.3049107789993286,
        "train_loss": 3.050159454345703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16551,
        "tokens": 8677490688,
        "learning_rate": 0.00030053930408574406,
        "gradient_norm": 0.30599895119667053,
        "train_loss": 3.074431896209717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16552,
        "tokens": 8678014976,
        "learning_rate": 0.00030051082951351,
        "gradient_norm": 0.3057918846607208,
        "train_loss": 3.067835807800293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16553,
        "tokens": 8678539264,
        "learning_rate": 0.00030048235527321333,
        "gradient_norm": 0.30823400616645813,
        "train_loss": 3.06988787651062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16554,
        "tokens": 8679063552,
        "learning_rate": 0.0003004538813651744,
        "gradient_norm": 0.29693329334259033,
        "train_loss": 3.0909786224365234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16555,
        "tokens": 8679587840,
        "learning_rate": 0.00030042540778971405,
        "gradient_norm": 0.33100640773773193,
        "train_loss": 3.1255483627319336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16556,
        "tokens": 8680112128,
        "learning_rate": 0.0003003969345471524,
        "gradient_norm": 0.28167006373405457,
        "train_loss": 3.1298000812530518,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16557,
        "tokens": 8680636416,
        "learning_rate": 0.0003003684616378104,
        "gradient_norm": 0.3048969805240631,
        "train_loss": 3.1071624755859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16558,
        "tokens": 8681160704,
        "learning_rate": 0.00030033998906200813,
        "gradient_norm": 0.3000587224960327,
        "train_loss": 3.0943470001220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16559,
        "tokens": 8681684992,
        "learning_rate": 0.00030031151682006634,
        "gradient_norm": 0.31169548630714417,
        "train_loss": 3.0954959392547607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16560,
        "tokens": 8682209280,
        "learning_rate": 0.00030028304491230536,
        "gradient_norm": 0.3156162202358246,
        "train_loss": 3.0897674560546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16561,
        "tokens": 8682733568,
        "learning_rate": 0.00030025457333904585,
        "gradient_norm": 0.3155065178871155,
        "train_loss": 3.071072816848755,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16562,
        "tokens": 8683257856,
        "learning_rate": 0.00030022610210060803,
        "gradient_norm": 0.29008084535598755,
        "train_loss": 3.094503879547119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16563,
        "tokens": 8683782144,
        "learning_rate": 0.0003001976311973126,
        "gradient_norm": 0.31268808245658875,
        "train_loss": 3.0676395893096924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16564,
        "tokens": 8684306432,
        "learning_rate": 0.0003001691606294801,
        "gradient_norm": 0.27539321780204773,
        "train_loss": 3.0672810077667236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16565,
        "tokens": 8684830720,
        "learning_rate": 0.00030014069039743075,
        "gradient_norm": 0.2989460229873657,
        "train_loss": 3.1076555252075195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16566,
        "tokens": 8685355008,
        "learning_rate": 0.0003001122205014853,
        "gradient_norm": 0.32009539008140564,
        "train_loss": 3.173241138458252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16567,
        "tokens": 8685879296,
        "learning_rate": 0.00030008375094196386,
        "gradient_norm": 0.30093318223953247,
        "train_loss": 3.1440227031707764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16568,
        "tokens": 8686403584,
        "learning_rate": 0.0003000552817191873,
        "gradient_norm": 0.3380189836025238,
        "train_loss": 3.127542495727539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16569,
        "tokens": 8686927872,
        "learning_rate": 0.0003000268128334757,
        "gradient_norm": 0.3002541661262512,
        "train_loss": 3.064976692199707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16570,
        "tokens": 8687452160,
        "learning_rate": 0.00029999834428514986,
        "gradient_norm": 0.3123416602611542,
        "train_loss": 3.089921474456787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16571,
        "tokens": 8687976448,
        "learning_rate": 0.0002999698760745299,
        "gradient_norm": 0.31272417306900024,
        "train_loss": 3.0384416580200195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16572,
        "tokens": 8688500736,
        "learning_rate": 0.0002999414082019365,
        "gradient_norm": 0.3297242224216461,
        "train_loss": 3.0914065837860107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16573,
        "tokens": 8689025024,
        "learning_rate": 0.00029991294066768995,
        "gradient_norm": 0.29984050989151,
        "train_loss": 3.0855679512023926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16574,
        "tokens": 8689549312,
        "learning_rate": 0.00029988447347211074,
        "gradient_norm": 0.3278155028820038,
        "train_loss": 3.0740203857421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16575,
        "tokens": 8690073600,
        "learning_rate": 0.0002998560066155195,
        "gradient_norm": 0.3215157389640808,
        "train_loss": 3.088747978210449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16576,
        "tokens": 8690597888,
        "learning_rate": 0.0002998275400982363,
        "gradient_norm": 0.3055576980113983,
        "train_loss": 3.021528720855713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16577,
        "tokens": 8691122176,
        "learning_rate": 0.0002997990739205818,
        "gradient_norm": 0.29391446709632874,
        "train_loss": 3.0831305980682373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16578,
        "tokens": 8691646464,
        "learning_rate": 0.00029977060808287635,
        "gradient_norm": 0.3184669613838196,
        "train_loss": 3.111445426940918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16579,
        "tokens": 8692170752,
        "learning_rate": 0.0002997421425854405,
        "gradient_norm": 0.33745336532592773,
        "train_loss": 3.0801072120666504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16580,
        "tokens": 8692695040,
        "learning_rate": 0.0002997136774285944,
        "gradient_norm": 0.30626511573791504,
        "train_loss": 3.1148719787597656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16581,
        "tokens": 8693219328,
        "learning_rate": 0.00029968521261265876,
        "gradient_norm": 0.3447287976741791,
        "train_loss": 3.1349291801452637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16582,
        "tokens": 8693743616,
        "learning_rate": 0.00029965674813795375,
        "gradient_norm": 0.2921122908592224,
        "train_loss": 3.0807414054870605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16583,
        "tokens": 8694267904,
        "learning_rate": 0.00029962828400479974,
        "gradient_norm": 0.43525391817092896,
        "train_loss": 3.1393532752990723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16584,
        "tokens": 8694792192,
        "learning_rate": 0.00029959982021351755,
        "gradient_norm": 0.31332629919052124,
        "train_loss": 3.0579166412353516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16585,
        "tokens": 8695316480,
        "learning_rate": 0.000299571356764427,
        "gradient_norm": 0.3214355409145355,
        "train_loss": 3.0522751808166504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16586,
        "tokens": 8695840768,
        "learning_rate": 0.000299542893657849,
        "gradient_norm": 0.31769299507141113,
        "train_loss": 3.0860610008239746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16587,
        "tokens": 8696365056,
        "learning_rate": 0.00029951443089410346,
        "gradient_norm": 0.31359565258026123,
        "train_loss": 3.0648279190063477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16588,
        "tokens": 8696889344,
        "learning_rate": 0.0002994859684735112,
        "gradient_norm": 0.31966257095336914,
        "train_loss": 3.052051544189453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16589,
        "tokens": 8697413632,
        "learning_rate": 0.00029945750639639226,
        "gradient_norm": 0.31492331624031067,
        "train_loss": 3.087428569793701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16590,
        "tokens": 8697937920,
        "learning_rate": 0.0002994290446630673,
        "gradient_norm": 0.31884676218032837,
        "train_loss": 3.0673136711120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16591,
        "tokens": 8698462208,
        "learning_rate": 0.0002994005832738564,
        "gradient_norm": 0.310131311416626,
        "train_loss": 3.0636911392211914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16592,
        "tokens": 8698986496,
        "learning_rate": 0.0002993721222290802,
        "gradient_norm": 0.30302587151527405,
        "train_loss": 3.0974278450012207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16593,
        "tokens": 8699510784,
        "learning_rate": 0.00029934366152905884,
        "gradient_norm": 0.29631027579307556,
        "train_loss": 3.1046719551086426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16594,
        "tokens": 8700035072,
        "learning_rate": 0.0002993152011741128,
        "gradient_norm": 0.3833674192428589,
        "train_loss": 3.208512306213379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16595,
        "tokens": 8700559360,
        "learning_rate": 0.0002992867411645625,
        "gradient_norm": 0.3293011486530304,
        "train_loss": 3.049825668334961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16596,
        "tokens": 8701083648,
        "learning_rate": 0.00029925828150072816,
        "gradient_norm": 0.3271655738353729,
        "train_loss": 3.083399772644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16597,
        "tokens": 8701607936,
        "learning_rate": 0.0002992298221829302,
        "gradient_norm": 0.3189418315887451,
        "train_loss": 3.17636775970459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16598,
        "tokens": 8702132224,
        "learning_rate": 0.0002992013632114889,
        "gradient_norm": 0.3202003538608551,
        "train_loss": 3.135481595993042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16599,
        "tokens": 8702656512,
        "learning_rate": 0.00029917290458672475,
        "gradient_norm": 0.3053937554359436,
        "train_loss": 3.108919143676758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16600,
        "tokens": 8703180800,
        "learning_rate": 0.0002991444463089579,
        "gradient_norm": 0.331909716129303,
        "train_loss": 3.0890555381774902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16601,
        "tokens": 8703705088,
        "learning_rate": 0.0002991159883785088,
        "gradient_norm": 0.3096786439418793,
        "train_loss": 3.0475687980651855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16602,
        "tokens": 8704229376,
        "learning_rate": 0.0002990875307956977,
        "gradient_norm": 0.31632786989212036,
        "train_loss": 3.0936965942382812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16603,
        "tokens": 8704753664,
        "learning_rate": 0.000299059073560845,
        "gradient_norm": 0.2985345423221588,
        "train_loss": 3.1357674598693848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16604,
        "tokens": 8705277952,
        "learning_rate": 0.00029903061667427104,
        "gradient_norm": 0.31217408180236816,
        "train_loss": 3.1156716346740723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16605,
        "tokens": 8705802240,
        "learning_rate": 0.0002990021601362961,
        "gradient_norm": 0.31816986203193665,
        "train_loss": 3.053330421447754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16606,
        "tokens": 8706326528,
        "learning_rate": 0.00029897370394724046,
        "gradient_norm": 0.3066505491733551,
        "train_loss": 3.0275938510894775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16607,
        "tokens": 8706850816,
        "learning_rate": 0.00029894524810742437,
        "gradient_norm": 0.3231002986431122,
        "train_loss": 3.101985454559326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16608,
        "tokens": 8707375104,
        "learning_rate": 0.0002989167926171684,
        "gradient_norm": 0.33742523193359375,
        "train_loss": 3.086352825164795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16609,
        "tokens": 8707899392,
        "learning_rate": 0.00029888833747679247,
        "gradient_norm": 0.347960889339447,
        "train_loss": 3.0776195526123047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16610,
        "tokens": 8708423680,
        "learning_rate": 0.00029885988268661727,
        "gradient_norm": 0.32080382108688354,
        "train_loss": 3.098947048187256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16611,
        "tokens": 8708947968,
        "learning_rate": 0.0002988314282469628,
        "gradient_norm": 0.36453938484191895,
        "train_loss": 3.1266255378723145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16612,
        "tokens": 8709472256,
        "learning_rate": 0.0002988029741581495,
        "gradient_norm": 0.29775968194007874,
        "train_loss": 3.109818458557129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16613,
        "tokens": 8709996544,
        "learning_rate": 0.0002987745204204975,
        "gradient_norm": 0.3968826234340668,
        "train_loss": 3.2290868759155273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16614,
        "tokens": 8710520832,
        "learning_rate": 0.0002987460670343273,
        "gradient_norm": 0.3377733528614044,
        "train_loss": 3.0936989784240723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16615,
        "tokens": 8711045120,
        "learning_rate": 0.00029871761399995916,
        "gradient_norm": 0.327681303024292,
        "train_loss": 3.0747790336608887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16616,
        "tokens": 8711569408,
        "learning_rate": 0.0002986891613177131,
        "gradient_norm": 0.3252873420715332,
        "train_loss": 3.0892229080200195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16617,
        "tokens": 8712093696,
        "learning_rate": 0.0002986607089879097,
        "gradient_norm": 0.3455287516117096,
        "train_loss": 3.1550581455230713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16618,
        "tokens": 8712617984,
        "learning_rate": 0.0002986322570108689,
        "gradient_norm": 0.298467218875885,
        "train_loss": 3.105440855026245,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16619,
        "tokens": 8713142272,
        "learning_rate": 0.0002986038053869114,
        "gradient_norm": 0.3382904529571533,
        "train_loss": 3.1186695098876953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16620,
        "tokens": 8713666560,
        "learning_rate": 0.00029857535411635704,
        "gradient_norm": 0.35528331995010376,
        "train_loss": 3.075256824493408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16621,
        "tokens": 8714190848,
        "learning_rate": 0.00029854690319952636,
        "gradient_norm": 0.3540942370891571,
        "train_loss": 3.0631120204925537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16622,
        "tokens": 8714715136,
        "learning_rate": 0.0002985184526367393,
        "gradient_norm": 0.3420496881008148,
        "train_loss": 3.0634846687316895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16623,
        "tokens": 8715239424,
        "learning_rate": 0.0002984900024283164,
        "gradient_norm": 0.3521425426006317,
        "train_loss": 3.16391921043396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16624,
        "tokens": 8715763712,
        "learning_rate": 0.00029846155257457787,
        "gradient_norm": 0.3231957256793976,
        "train_loss": 3.1093382835388184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16625,
        "tokens": 8716288000,
        "learning_rate": 0.0002984331030758437,
        "gradient_norm": 0.3428609371185303,
        "train_loss": 3.076122283935547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16626,
        "tokens": 8716812288,
        "learning_rate": 0.0002984046539324345,
        "gradient_norm": 0.32928264141082764,
        "train_loss": 3.0722925662994385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16627,
        "tokens": 8717336576,
        "learning_rate": 0.0002983762051446702,
        "gradient_norm": 0.317993700504303,
        "train_loss": 3.0798048973083496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16628,
        "tokens": 8717860864,
        "learning_rate": 0.0002983477567128712,
        "gradient_norm": 0.3057912588119507,
        "train_loss": 3.0972681045532227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16629,
        "tokens": 8718385152,
        "learning_rate": 0.0002983193086373576,
        "gradient_norm": 0.36049070954322815,
        "train_loss": 3.0835134983062744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16630,
        "tokens": 8718909440,
        "learning_rate": 0.00029829086091844975,
        "gradient_norm": 0.29697665572166443,
        "train_loss": 3.121184825897217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16631,
        "tokens": 8719433728,
        "learning_rate": 0.0002982624135564677,
        "gradient_norm": 0.31425368785858154,
        "train_loss": 3.122166395187378,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16632,
        "tokens": 8719958016,
        "learning_rate": 0.0002982339665517318,
        "gradient_norm": 0.3230701684951782,
        "train_loss": 3.195302724838257,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16633,
        "tokens": 8720482304,
        "learning_rate": 0.00029820551990456206,
        "gradient_norm": 0.3154654800891876,
        "train_loss": 3.096656322479248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16634,
        "tokens": 8721006592,
        "learning_rate": 0.00029817707361527897,
        "gradient_norm": 0.3774021863937378,
        "train_loss": 3.0841054916381836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16635,
        "tokens": 8721530880,
        "learning_rate": 0.0002981486276842026,
        "gradient_norm": 0.3371909558773041,
        "train_loss": 3.0770983695983887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16636,
        "tokens": 8722055168,
        "learning_rate": 0.00029812018211165304,
        "gradient_norm": 0.2994767725467682,
        "train_loss": 3.125093460083008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16637,
        "tokens": 8722579456,
        "learning_rate": 0.00029809173689795065,
        "gradient_norm": 0.4052066206932068,
        "train_loss": 3.1024599075317383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16638,
        "tokens": 8723103744,
        "learning_rate": 0.0002980632920434155,
        "gradient_norm": 0.33848467469215393,
        "train_loss": 3.0977389812469482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16639,
        "tokens": 8723628032,
        "learning_rate": 0.00029803484754836783,
        "gradient_norm": 0.3508285582065582,
        "train_loss": 3.0673866271972656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16640,
        "tokens": 8724152320,
        "learning_rate": 0.00029800640341312774,
        "gradient_norm": 0.44404128193855286,
        "train_loss": 3.181288957595825,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16641,
        "tokens": 8724676608,
        "learning_rate": 0.0002979779596380155,
        "gradient_norm": 0.3613851070404053,
        "train_loss": 3.110490322113037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16642,
        "tokens": 8725200896,
        "learning_rate": 0.0002979495162233512,
        "gradient_norm": 0.35921311378479004,
        "train_loss": 3.1131858825683594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16643,
        "tokens": 8725725184,
        "learning_rate": 0.00029792107316945507,
        "gradient_norm": 0.36102017760276794,
        "train_loss": 3.088563919067383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16644,
        "tokens": 8726249472,
        "learning_rate": 0.00029789263047664725,
        "gradient_norm": 0.3505585193634033,
        "train_loss": 3.1127967834472656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16645,
        "tokens": 8726773760,
        "learning_rate": 0.000297864188145248,
        "gradient_norm": 0.3419675827026367,
        "train_loss": 3.064816474914551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16646,
        "tokens": 8727298048,
        "learning_rate": 0.00029783574617557726,
        "gradient_norm": 0.2977873682975769,
        "train_loss": 3.0807528495788574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16647,
        "tokens": 8727822336,
        "learning_rate": 0.00029780730456795525,
        "gradient_norm": 0.366026371717453,
        "train_loss": 3.1496033668518066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16648,
        "tokens": 8728346624,
        "learning_rate": 0.00029777886332270223,
        "gradient_norm": 0.31953057646751404,
        "train_loss": 3.1067821979522705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16649,
        "tokens": 8728870912,
        "learning_rate": 0.00029775042244013826,
        "gradient_norm": 0.3136763274669647,
        "train_loss": 3.1134085655212402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16650,
        "tokens": 8729395200,
        "learning_rate": 0.0002977219819205835,
        "gradient_norm": 0.3010035455226898,
        "train_loss": 3.0933828353881836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16651,
        "tokens": 8729919488,
        "learning_rate": 0.00029769354176435806,
        "gradient_norm": 0.2977306842803955,
        "train_loss": 3.139970064163208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16652,
        "tokens": 8730443776,
        "learning_rate": 0.00029766510197178206,
        "gradient_norm": 0.296566903591156,
        "train_loss": 3.1171722412109375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16653,
        "tokens": 8730968064,
        "learning_rate": 0.0002976366625431757,
        "gradient_norm": 0.29678553342819214,
        "train_loss": 3.049509286880493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16654,
        "tokens": 8731492352,
        "learning_rate": 0.0002976082234788589,
        "gradient_norm": 0.2825058698654175,
        "train_loss": 3.1323189735412598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16655,
        "tokens": 8732016640,
        "learning_rate": 0.0002975797847791521,
        "gradient_norm": 0.30648982524871826,
        "train_loss": 3.078287124633789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16656,
        "tokens": 8732540928,
        "learning_rate": 0.0002975513464443751,
        "gradient_norm": 0.2896045744419098,
        "train_loss": 3.079705238342285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16657,
        "tokens": 8733065216,
        "learning_rate": 0.00029752290847484823,
        "gradient_norm": 0.31689679622650146,
        "train_loss": 3.1423277854919434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16658,
        "tokens": 8733589504,
        "learning_rate": 0.00029749447087089147,
        "gradient_norm": 0.30000123381614685,
        "train_loss": 3.1269431114196777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16659,
        "tokens": 8734113792,
        "learning_rate": 0.00029746603363282496,
        "gradient_norm": 0.3268797993659973,
        "train_loss": 3.0400948524475098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16660,
        "tokens": 8734638080,
        "learning_rate": 0.00029743759676096877,
        "gradient_norm": 0.3368973731994629,
        "train_loss": 3.0271081924438477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16661,
        "tokens": 8735162368,
        "learning_rate": 0.00029740916025564317,
        "gradient_norm": 0.28332436084747314,
        "train_loss": 3.0966858863830566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16662,
        "tokens": 8735686656,
        "learning_rate": 0.0002973807241171679,
        "gradient_norm": 0.32622385025024414,
        "train_loss": 3.083458423614502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16663,
        "tokens": 8736210944,
        "learning_rate": 0.0002973522883458632,
        "gradient_norm": 0.2993812561035156,
        "train_loss": 3.0938303470611572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16664,
        "tokens": 8736735232,
        "learning_rate": 0.0002973238529420494,
        "gradient_norm": 0.33080965280532837,
        "train_loss": 3.1013824939727783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16665,
        "tokens": 8737259520,
        "learning_rate": 0.00029729541790604624,
        "gradient_norm": 0.3465907871723175,
        "train_loss": 3.118051528930664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16666,
        "tokens": 8737783808,
        "learning_rate": 0.000297266983238174,
        "gradient_norm": 0.3076063096523285,
        "train_loss": 3.047708034515381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16667,
        "tokens": 8738308096,
        "learning_rate": 0.0002972385489387526,
        "gradient_norm": 0.33446916937828064,
        "train_loss": 3.0496115684509277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16668,
        "tokens": 8738832384,
        "learning_rate": 0.0002972101150081022,
        "gradient_norm": 0.3352297842502594,
        "train_loss": 3.0660479068756104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16669,
        "tokens": 8739356672,
        "learning_rate": 0.0002971816814465428,
        "gradient_norm": 0.3277219533920288,
        "train_loss": 3.108765125274658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16670,
        "tokens": 8739880960,
        "learning_rate": 0.00029715324825439456,
        "gradient_norm": 0.30511489510536194,
        "train_loss": 3.0689382553100586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16671,
        "tokens": 8740405248,
        "learning_rate": 0.0002971248154319774,
        "gradient_norm": 0.3048160672187805,
        "train_loss": 3.0947611331939697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16672,
        "tokens": 8740929536,
        "learning_rate": 0.00029709638297961146,
        "gradient_norm": 0.297197163105011,
        "train_loss": 3.0811972618103027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16673,
        "tokens": 8741453824,
        "learning_rate": 0.00029706795089761665,
        "gradient_norm": 0.2951534688472748,
        "train_loss": 3.0990471839904785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16674,
        "tokens": 8741978112,
        "learning_rate": 0.0002970395191863131,
        "gradient_norm": 0.2995472252368927,
        "train_loss": 3.0715198516845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16675,
        "tokens": 8742502400,
        "learning_rate": 0.00029701108784602095,
        "gradient_norm": 0.380230188369751,
        "train_loss": 3.0992207527160645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16676,
        "tokens": 8743026688,
        "learning_rate": 0.00029698265687706007,
        "gradient_norm": 0.32033130526542664,
        "train_loss": 3.0673885345458984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16677,
        "tokens": 8743550976,
        "learning_rate": 0.0002969542262797506,
        "gradient_norm": 0.3399379849433899,
        "train_loss": 3.1266918182373047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16678,
        "tokens": 8744075264,
        "learning_rate": 0.0002969257960544124,
        "gradient_norm": 0.3638124167919159,
        "train_loss": 3.1047139167785645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16679,
        "tokens": 8744599552,
        "learning_rate": 0.00029689736620136574,
        "gradient_norm": 0.29447054862976074,
        "train_loss": 3.0618510246276855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16680,
        "tokens": 8745123840,
        "learning_rate": 0.00029686893672093036,
        "gradient_norm": 0.33439457416534424,
        "train_loss": 3.1176061630249023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16681,
        "tokens": 8745648128,
        "learning_rate": 0.0002968405076134265,
        "gradient_norm": 0.2955671548843384,
        "train_loss": 3.1313109397888184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16682,
        "tokens": 8746172416,
        "learning_rate": 0.00029681207887917395,
        "gradient_norm": 0.37889567017555237,
        "train_loss": 3.164263963699341,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16683,
        "tokens": 8746696704,
        "learning_rate": 0.0002967836505184928,
        "gradient_norm": 0.33307915925979614,
        "train_loss": 3.0854411125183105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16684,
        "tokens": 8747220992,
        "learning_rate": 0.00029675522253170324,
        "gradient_norm": 0.3571782112121582,
        "train_loss": 3.1053032875061035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16685,
        "tokens": 8747745280,
        "learning_rate": 0.00029672679491912497,
        "gradient_norm": 0.33163341879844666,
        "train_loss": 3.0891201496124268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16686,
        "tokens": 8748269568,
        "learning_rate": 0.00029669836768107815,
        "gradient_norm": 0.3431865870952606,
        "train_loss": 3.04852294921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16687,
        "tokens": 8748793856,
        "learning_rate": 0.00029666994081788264,
        "gradient_norm": 0.3241634666919708,
        "train_loss": 3.101365089416504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16688,
        "tokens": 8749318144,
        "learning_rate": 0.0002966415143298586,
        "gradient_norm": 0.3960777521133423,
        "train_loss": 3.0932698249816895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16689,
        "tokens": 8749842432,
        "learning_rate": 0.00029661308821732585,
        "gradient_norm": 0.3203377425670624,
        "train_loss": 3.0979974269866943,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16690,
        "tokens": 8750366720,
        "learning_rate": 0.0002965846624806044,
        "gradient_norm": 0.36329376697540283,
        "train_loss": 3.1168415546417236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16691,
        "tokens": 8750891008,
        "learning_rate": 0.0002965562371200142,
        "gradient_norm": 0.3221704959869385,
        "train_loss": 3.1832780838012695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16692,
        "tokens": 8751415296,
        "learning_rate": 0.0002965278121358753,
        "gradient_norm": 0.45772305130958557,
        "train_loss": 3.1089975833892822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16693,
        "tokens": 8751939584,
        "learning_rate": 0.00029649938752850753,
        "gradient_norm": 0.3477817475795746,
        "train_loss": 3.122018575668335,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16694,
        "tokens": 8752463872,
        "learning_rate": 0.00029647096329823096,
        "gradient_norm": 0.410253643989563,
        "train_loss": 3.163914203643799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16695,
        "tokens": 8752988160,
        "learning_rate": 0.0002964425394453655,
        "gradient_norm": 0.34727853536605835,
        "train_loss": 3.0434670448303223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16696,
        "tokens": 8753512448,
        "learning_rate": 0.0002964141159702311,
        "gradient_norm": 0.3767082691192627,
        "train_loss": 3.098128318786621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16697,
        "tokens": 8754036736,
        "learning_rate": 0.00029638569287314767,
        "gradient_norm": 0.329430490732193,
        "train_loss": 3.1182661056518555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16698,
        "tokens": 8754561024,
        "learning_rate": 0.0002963572701544351,
        "gradient_norm": 0.3581995666027069,
        "train_loss": 3.136887550354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16699,
        "tokens": 8755085312,
        "learning_rate": 0.0002963288478144135,
        "gradient_norm": 0.35504859685897827,
        "train_loss": 3.117647647857666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16700,
        "tokens": 8755609600,
        "learning_rate": 0.00029630042585340266,
        "gradient_norm": 0.3179376423358917,
        "train_loss": 3.0129330158233643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16701,
        "tokens": 8756133888,
        "learning_rate": 0.0002962720042717225,
        "gradient_norm": 0.35407206416130066,
        "train_loss": 3.110183000564575,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16702,
        "tokens": 8756658176,
        "learning_rate": 0.00029624358306969297,
        "gradient_norm": 0.331167995929718,
        "train_loss": 3.1308116912841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16703,
        "tokens": 8757182464,
        "learning_rate": 0.000296215162247634,
        "gradient_norm": 0.3161289393901825,
        "train_loss": 3.0619657039642334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16704,
        "tokens": 8757706752,
        "learning_rate": 0.0002961867418058655,
        "gradient_norm": 0.3297470808029175,
        "train_loss": 3.125305652618408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16705,
        "tokens": 8758231040,
        "learning_rate": 0.00029615832174470735,
        "gradient_norm": 0.31687241792678833,
        "train_loss": 3.0944619178771973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16706,
        "tokens": 8758755328,
        "learning_rate": 0.00029612990206447955,
        "gradient_norm": 0.33856135606765747,
        "train_loss": 3.0956931114196777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16707,
        "tokens": 8759279616,
        "learning_rate": 0.00029610148276550184,
        "gradient_norm": 0.2887817621231079,
        "train_loss": 3.049504280090332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16708,
        "tokens": 8759803904,
        "learning_rate": 0.00029607306384809423,
        "gradient_norm": 0.33083751797676086,
        "train_loss": 3.1053900718688965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16709,
        "tokens": 8760328192,
        "learning_rate": 0.00029604464531257657,
        "gradient_norm": 0.3080838620662689,
        "train_loss": 3.1407413482666016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16710,
        "tokens": 8760852480,
        "learning_rate": 0.0002960162271592688,
        "gradient_norm": 0.3261561095714569,
        "train_loss": 3.0734946727752686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16711,
        "tokens": 8761376768,
        "learning_rate": 0.00029598780938849074,
        "gradient_norm": 0.31649038195610046,
        "train_loss": 3.0500571727752686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16712,
        "tokens": 8761901056,
        "learning_rate": 0.00029595939200056226,
        "gradient_norm": 0.320398211479187,
        "train_loss": 3.0852887630462646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16713,
        "tokens": 8762425344,
        "learning_rate": 0.0002959309749958032,
        "gradient_norm": 0.30070194602012634,
        "train_loss": 3.1302199363708496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16714,
        "tokens": 8762949632,
        "learning_rate": 0.0002959025583745335,
        "gradient_norm": 0.28960010409355164,
        "train_loss": 3.0933942794799805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16715,
        "tokens": 8763473920,
        "learning_rate": 0.00029587414213707306,
        "gradient_norm": 0.3162967562675476,
        "train_loss": 3.1057982444763184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16716,
        "tokens": 8763998208,
        "learning_rate": 0.0002958457262837417,
        "gradient_norm": 0.3023863136768341,
        "train_loss": 3.0875775814056396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16717,
        "tokens": 8764522496,
        "learning_rate": 0.0002958173108148593,
        "gradient_norm": 0.2836441993713379,
        "train_loss": 3.1423637866973877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16718,
        "tokens": 8765046784,
        "learning_rate": 0.00029578889573074555,
        "gradient_norm": 0.3071762025356293,
        "train_loss": 3.086427688598633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16719,
        "tokens": 8765571072,
        "learning_rate": 0.00029576048103172053,
        "gradient_norm": 0.301368772983551,
        "train_loss": 3.108525276184082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16720,
        "tokens": 8766095360,
        "learning_rate": 0.0002957320667181039,
        "gradient_norm": 0.284180223941803,
        "train_loss": 3.11523175239563,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16721,
        "tokens": 8766619648,
        "learning_rate": 0.0002957036527902157,
        "gradient_norm": 0.33831462264060974,
        "train_loss": 3.099734306335449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16722,
        "tokens": 8767143936,
        "learning_rate": 0.00029567523924837547,
        "gradient_norm": 0.3180873990058899,
        "train_loss": 3.0955467224121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16723,
        "tokens": 8767668224,
        "learning_rate": 0.0002956468260929033,
        "gradient_norm": 0.31224554777145386,
        "train_loss": 3.0998222827911377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16724,
        "tokens": 8768192512,
        "learning_rate": 0.00029561841332411895,
        "gradient_norm": 0.3330850601196289,
        "train_loss": 3.081648826599121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16725,
        "tokens": 8768716800,
        "learning_rate": 0.0002955900009423421,
        "gradient_norm": 0.32092100381851196,
        "train_loss": 3.094371795654297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16726,
        "tokens": 8769241088,
        "learning_rate": 0.00029556158894789285,
        "gradient_norm": 0.33533722162246704,
        "train_loss": 3.099381923675537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16727,
        "tokens": 8769765376,
        "learning_rate": 0.00029553317734109066,
        "gradient_norm": 0.32290202379226685,
        "train_loss": 3.055300235748291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16728,
        "tokens": 8770289664,
        "learning_rate": 0.00029550476612225573,
        "gradient_norm": 0.3426513373851776,
        "train_loss": 3.101688861846924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16729,
        "tokens": 8770813952,
        "learning_rate": 0.0002954763552917075,
        "gradient_norm": 0.3190706670284271,
        "train_loss": 3.0696449279785156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16730,
        "tokens": 8771338240,
        "learning_rate": 0.00029544794484976603,
        "gradient_norm": 0.29551032185554504,
        "train_loss": 3.070833206176758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16731,
        "tokens": 8771862528,
        "learning_rate": 0.00029541953479675094,
        "gradient_norm": 0.32580623030662537,
        "train_loss": 3.123495578765869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16732,
        "tokens": 8772386816,
        "learning_rate": 0.00029539112513298215,
        "gradient_norm": 0.32523879408836365,
        "train_loss": 3.0033204555511475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16733,
        "tokens": 8772911104,
        "learning_rate": 0.00029536271585877923,
        "gradient_norm": 0.31794533133506775,
        "train_loss": 3.0555472373962402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16734,
        "tokens": 8773435392,
        "learning_rate": 0.0002953343069744622,
        "gradient_norm": 0.30994749069213867,
        "train_loss": 3.084402322769165,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16735,
        "tokens": 8773959680,
        "learning_rate": 0.0002953058984803509,
        "gradient_norm": 0.34424933791160583,
        "train_loss": 3.076639175415039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16736,
        "tokens": 8774483968,
        "learning_rate": 0.0002952774903767648,
        "gradient_norm": 0.33477386832237244,
        "train_loss": 3.141961097717285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16737,
        "tokens": 8775008256,
        "learning_rate": 0.0002952490826640239,
        "gradient_norm": 0.317025363445282,
        "train_loss": 3.0828418731689453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16738,
        "tokens": 8775532544,
        "learning_rate": 0.0002952206753424478,
        "gradient_norm": 0.32203978300094604,
        "train_loss": 3.099324941635132,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16739,
        "tokens": 8776056832,
        "learning_rate": 0.0002951922684123565,
        "gradient_norm": 0.38330188393592834,
        "train_loss": 3.1692893505096436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16740,
        "tokens": 8776581120,
        "learning_rate": 0.0002951638618740695,
        "gradient_norm": 0.35801151394844055,
        "train_loss": 3.0910181999206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16741,
        "tokens": 8777105408,
        "learning_rate": 0.00029513545572790677,
        "gradient_norm": 0.3376174569129944,
        "train_loss": 3.0797276496887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16742,
        "tokens": 8777629696,
        "learning_rate": 0.00029510704997418784,
        "gradient_norm": 0.2939926087856293,
        "train_loss": 3.055881977081299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16743,
        "tokens": 8778153984,
        "learning_rate": 0.0002950786446132325,
        "gradient_norm": 0.36161935329437256,
        "train_loss": 3.1080634593963623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16744,
        "tokens": 8778678272,
        "learning_rate": 0.0002950502396453607,
        "gradient_norm": 0.3383941352367401,
        "train_loss": 3.1306748390197754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16745,
        "tokens": 8779202560,
        "learning_rate": 0.0002950218350708919,
        "gradient_norm": 0.33957403898239136,
        "train_loss": 3.122676372528076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16746,
        "tokens": 8779726848,
        "learning_rate": 0.00029499343089014606,
        "gradient_norm": 0.35853150486946106,
        "train_loss": 3.0819666385650635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16747,
        "tokens": 8780251136,
        "learning_rate": 0.00029496502710344265,
        "gradient_norm": 0.32544460892677307,
        "train_loss": 3.091249465942383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16748,
        "tokens": 8780775424,
        "learning_rate": 0.00029493662371110174,
        "gradient_norm": 0.32716691493988037,
        "train_loss": 3.0613296031951904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16749,
        "tokens": 8781299712,
        "learning_rate": 0.0002949082207134426,
        "gradient_norm": 0.3033716380596161,
        "train_loss": 3.0927765369415283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16750,
        "tokens": 8781824000,
        "learning_rate": 0.00029487981811078534,
        "gradient_norm": 0.31062638759613037,
        "train_loss": 3.098196506500244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16751,
        "tokens": 8782348288,
        "learning_rate": 0.00029485141590344943,
        "gradient_norm": 0.323457270860672,
        "train_loss": 3.0885307788848877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16752,
        "tokens": 8782872576,
        "learning_rate": 0.0002948230140917547,
        "gradient_norm": 0.3171015977859497,
        "train_loss": 3.0553975105285645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16753,
        "tokens": 8783396864,
        "learning_rate": 0.0002947946126760207,
        "gradient_norm": 0.3256360590457916,
        "train_loss": 3.0813560485839844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16754,
        "tokens": 8783921152,
        "learning_rate": 0.00029476621165656734,
        "gradient_norm": 0.32659000158309937,
        "train_loss": 3.0582809448242188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16755,
        "tokens": 8784445440,
        "learning_rate": 0.00029473781103371414,
        "gradient_norm": 0.31534281373023987,
        "train_loss": 3.100212574005127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16756,
        "tokens": 8784969728,
        "learning_rate": 0.0002947094108077808,
        "gradient_norm": 0.3284819722175598,
        "train_loss": 3.0946550369262695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16757,
        "tokens": 8785494016,
        "learning_rate": 0.0002946810109790871,
        "gradient_norm": 0.339472234249115,
        "train_loss": 3.080312728881836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16758,
        "tokens": 8786018304,
        "learning_rate": 0.00029465261154795264,
        "gradient_norm": 0.3271673619747162,
        "train_loss": 3.0772366523742676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16759,
        "tokens": 8786542592,
        "learning_rate": 0.0002946242125146971,
        "gradient_norm": 0.31835371255874634,
        "train_loss": 3.1074953079223633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16760,
        "tokens": 8787066880,
        "learning_rate": 0.00029459581387964004,
        "gradient_norm": 0.33130183815956116,
        "train_loss": 3.1341261863708496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16761,
        "tokens": 8787591168,
        "learning_rate": 0.00029456741564310134,
        "gradient_norm": 0.3016144037246704,
        "train_loss": 3.0930867195129395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16762,
        "tokens": 8788115456,
        "learning_rate": 0.0002945390178054005,
        "gradient_norm": 0.3202361464500427,
        "train_loss": 3.0654280185699463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16763,
        "tokens": 8788639744,
        "learning_rate": 0.00029451062036685717,
        "gradient_norm": 0.2847336530685425,
        "train_loss": 3.06906795501709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16764,
        "tokens": 8789164032,
        "learning_rate": 0.00029448222332779115,
        "gradient_norm": 0.33702602982521057,
        "train_loss": 3.0806360244750977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16765,
        "tokens": 8789688320,
        "learning_rate": 0.00029445382668852186,
        "gradient_norm": 0.2838144898414612,
        "train_loss": 3.08872127532959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16766,
        "tokens": 8790212608,
        "learning_rate": 0.0002944254304493692,
        "gradient_norm": 0.3130476474761963,
        "train_loss": 3.0650534629821777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16767,
        "tokens": 8790736896,
        "learning_rate": 0.0002943970346106525,
        "gradient_norm": 0.29995962977409363,
        "train_loss": 3.10709810256958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16768,
        "tokens": 8791261184,
        "learning_rate": 0.00029436863917269176,
        "gradient_norm": 0.2949018180370331,
        "train_loss": 3.051640033721924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16769,
        "tokens": 8791785472,
        "learning_rate": 0.0002943402441358062,
        "gradient_norm": 0.29249677062034607,
        "train_loss": 3.1270382404327393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16770,
        "tokens": 8792309760,
        "learning_rate": 0.0002943118495003158,
        "gradient_norm": 0.3082297444343567,
        "train_loss": 3.069401741027832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16771,
        "tokens": 8792834048,
        "learning_rate": 0.00029428345526653996,
        "gradient_norm": 0.33026617765426636,
        "train_loss": 3.0958609580993652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16772,
        "tokens": 8793358336,
        "learning_rate": 0.0002942550614347984,
        "gradient_norm": 0.3209971785545349,
        "train_loss": 3.0424227714538574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16773,
        "tokens": 8793882624,
        "learning_rate": 0.00029422666800541056,
        "gradient_norm": 0.3029884397983551,
        "train_loss": 3.0688672065734863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16774,
        "tokens": 8794406912,
        "learning_rate": 0.0002941982749786962,
        "gradient_norm": 0.3033788502216339,
        "train_loss": 3.088418960571289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16775,
        "tokens": 8794931200,
        "learning_rate": 0.00029416988235497494,
        "gradient_norm": 0.3076305687427521,
        "train_loss": 3.038262128829956,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16776,
        "tokens": 8795455488,
        "learning_rate": 0.0002941414901345662,
        "gradient_norm": 0.2931973934173584,
        "train_loss": 3.1149089336395264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16777,
        "tokens": 8795979776,
        "learning_rate": 0.0002941130983177899,
        "gradient_norm": 0.31222230195999146,
        "train_loss": 3.035285711288452,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16778,
        "tokens": 8796504064,
        "learning_rate": 0.00029408470690496524,
        "gradient_norm": 0.2994222044944763,
        "train_loss": 3.108628749847412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16779,
        "tokens": 8797028352,
        "learning_rate": 0.0002940563158964121,
        "gradient_norm": 0.3140084445476532,
        "train_loss": 3.1288559436798096,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16780,
        "tokens": 8797552640,
        "learning_rate": 0.0002940279252924498,
        "gradient_norm": 0.36366650462150574,
        "train_loss": 3.1269302368164062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16781,
        "tokens": 8798076928,
        "learning_rate": 0.00029399953509339817,
        "gradient_norm": 0.31533971428871155,
        "train_loss": 3.107630491256714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16782,
        "tokens": 8798601216,
        "learning_rate": 0.0002939711452995765,
        "gradient_norm": 0.345851331949234,
        "train_loss": 3.1585545539855957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16783,
        "tokens": 8799125504,
        "learning_rate": 0.0002939427559113045,
        "gradient_norm": 0.3946404755115509,
        "train_loss": 3.103102445602417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16784,
        "tokens": 8799649792,
        "learning_rate": 0.0002939143669289019,
        "gradient_norm": 0.3032236397266388,
        "train_loss": 3.1168065071105957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16785,
        "tokens": 8800174080,
        "learning_rate": 0.00029388597835268795,
        "gradient_norm": 0.42068156599998474,
        "train_loss": 2.986133098602295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16786,
        "tokens": 8800698368,
        "learning_rate": 0.0002938575901829824,
        "gradient_norm": 0.3150220513343811,
        "train_loss": 3.1221704483032227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16787,
        "tokens": 8801222656,
        "learning_rate": 0.00029382920242010467,
        "gradient_norm": 0.38152578473091125,
        "train_loss": 3.0845375061035156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16788,
        "tokens": 8801746944,
        "learning_rate": 0.00029380081506437443,
        "gradient_norm": 0.3162817656993866,
        "train_loss": 3.0974955558776855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16789,
        "tokens": 8802271232,
        "learning_rate": 0.000293772428116111,
        "gradient_norm": 0.34342247247695923,
        "train_loss": 3.1087639331817627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16790,
        "tokens": 8802795520,
        "learning_rate": 0.00029374404157563424,
        "gradient_norm": 0.3319615125656128,
        "train_loss": 3.1066150665283203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16791,
        "tokens": 8803319808,
        "learning_rate": 0.0002937156554432633,
        "gradient_norm": 0.3472961485385895,
        "train_loss": 3.089480400085449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16792,
        "tokens": 8803844096,
        "learning_rate": 0.00029368726971931806,
        "gradient_norm": 0.33415359258651733,
        "train_loss": 3.0881710052490234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16793,
        "tokens": 8804368384,
        "learning_rate": 0.00029365888440411773,
        "gradient_norm": 0.33708468079566956,
        "train_loss": 3.095367431640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16794,
        "tokens": 8804892672,
        "learning_rate": 0.00029363049949798195,
        "gradient_norm": 0.3393864333629608,
        "train_loss": 3.082026481628418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16795,
        "tokens": 8805416960,
        "learning_rate": 0.00029360211500123034,
        "gradient_norm": 0.31456178426742554,
        "train_loss": 3.1053171157836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16796,
        "tokens": 8805941248,
        "learning_rate": 0.0002935737309141822,
        "gradient_norm": 0.31682053208351135,
        "train_loss": 3.0323357582092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16797,
        "tokens": 8806465536,
        "learning_rate": 0.00029354534723715725,
        "gradient_norm": 0.3199838399887085,
        "train_loss": 3.1342344284057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16798,
        "tokens": 8806989824,
        "learning_rate": 0.0002935169639704747,
        "gradient_norm": 0.30841609835624695,
        "train_loss": 3.1170802116394043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16799,
        "tokens": 8807514112,
        "learning_rate": 0.00029348858111445436,
        "gradient_norm": 0.352924644947052,
        "train_loss": 3.0686533451080322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16800,
        "tokens": 8808038400,
        "learning_rate": 0.0002934601986694154,
        "gradient_norm": 0.34526386857032776,
        "train_loss": 3.121051788330078,
        "val_loss": 3.0558881759643555,
        "hellaswag_acc": 0.2837084233760834,
        "hellaswag_acc_norm": 0.29187414050102234
    },
    {
        "step": 16801,
        "tokens": 8808562688,
        "learning_rate": 0.0002934318166356776,
        "gradient_norm": 0.30625760555267334,
        "train_loss": 3.075167179107666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16802,
        "tokens": 8809086976,
        "learning_rate": 0.00029340343501356014,
        "gradient_norm": 0.3389253318309784,
        "train_loss": 3.1669623851776123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16803,
        "tokens": 8809611264,
        "learning_rate": 0.00029337505380338266,
        "gradient_norm": 0.3109404444694519,
        "train_loss": 3.059053421020508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16804,
        "tokens": 8810135552,
        "learning_rate": 0.0002933466730054647,
        "gradient_norm": 0.30939871072769165,
        "train_loss": 3.116133689880371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16805,
        "tokens": 8810659840,
        "learning_rate": 0.0002933182926201256,
        "gradient_norm": 0.3374287784099579,
        "train_loss": 3.1175637245178223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16806,
        "tokens": 8811184128,
        "learning_rate": 0.0002932899126476848,
        "gradient_norm": 0.30166828632354736,
        "train_loss": 3.031198501586914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16807,
        "tokens": 8811708416,
        "learning_rate": 0.0002932615330884618,
        "gradient_norm": 0.3244827389717102,
        "train_loss": 3.099346160888672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16808,
        "tokens": 8812232704,
        "learning_rate": 0.00029323315394277606,
        "gradient_norm": 0.3410704731941223,
        "train_loss": 3.1618411540985107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16809,
        "tokens": 8812756992,
        "learning_rate": 0.000293204775210947,
        "gradient_norm": 0.3014117479324341,
        "train_loss": 3.0868918895721436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16810,
        "tokens": 8813281280,
        "learning_rate": 0.0002931763968932941,
        "gradient_norm": 0.3479260206222534,
        "train_loss": 3.1296470165252686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16811,
        "tokens": 8813805568,
        "learning_rate": 0.00029314801899013663,
        "gradient_norm": 0.31365564465522766,
        "train_loss": 3.0674304962158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16812,
        "tokens": 8814329856,
        "learning_rate": 0.0002931196415017943,
        "gradient_norm": 0.32097315788269043,
        "train_loss": 3.0457301139831543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16813,
        "tokens": 8814854144,
        "learning_rate": 0.0002930912644285863,
        "gradient_norm": 0.31867679953575134,
        "train_loss": 3.049534320831299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16814,
        "tokens": 8815378432,
        "learning_rate": 0.0002930628877708321,
        "gradient_norm": 0.3088100552558899,
        "train_loss": 3.066054344177246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16815,
        "tokens": 8815902720,
        "learning_rate": 0.0002930345115288512,
        "gradient_norm": 0.30584916472435,
        "train_loss": 3.078223943710327,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16816,
        "tokens": 8816427008,
        "learning_rate": 0.0002930061357029628,
        "gradient_norm": 0.336023211479187,
        "train_loss": 3.0769975185394287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16817,
        "tokens": 8816951296,
        "learning_rate": 0.0002929777602934867,
        "gradient_norm": 0.310305655002594,
        "train_loss": 3.1278076171875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16818,
        "tokens": 8817475584,
        "learning_rate": 0.00029294938530074186,
        "gradient_norm": 0.326198011636734,
        "train_loss": 3.0850253105163574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16819,
        "tokens": 8817999872,
        "learning_rate": 0.00029292101072504804,
        "gradient_norm": 0.30577215552330017,
        "train_loss": 3.0752663612365723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16820,
        "tokens": 8818524160,
        "learning_rate": 0.0002928926365667243,
        "gradient_norm": 0.32028186321258545,
        "train_loss": 3.1062159538269043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16821,
        "tokens": 8819048448,
        "learning_rate": 0.0002928642628260903,
        "gradient_norm": 0.3375677168369293,
        "train_loss": 3.00101900100708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16822,
        "tokens": 8819572736,
        "learning_rate": 0.0002928358895034652,
        "gradient_norm": 0.30920809507369995,
        "train_loss": 3.0331077575683594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16823,
        "tokens": 8820097024,
        "learning_rate": 0.00029280751659916857,
        "gradient_norm": 0.32725024223327637,
        "train_loss": 3.0986814498901367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16824,
        "tokens": 8820621312,
        "learning_rate": 0.00029277914411351974,
        "gradient_norm": 0.29388925433158875,
        "train_loss": 3.0940518379211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16825,
        "tokens": 8821145600,
        "learning_rate": 0.00029275077204683796,
        "gradient_norm": 0.3211309313774109,
        "train_loss": 3.049262762069702,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16826,
        "tokens": 8821669888,
        "learning_rate": 0.00029272240039944275,
        "gradient_norm": 0.3082345426082611,
        "train_loss": 3.0407471656799316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16827,
        "tokens": 8822194176,
        "learning_rate": 0.0002926940291716533,
        "gradient_norm": 0.34490638971328735,
        "train_loss": 3.165292501449585,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16828,
        "tokens": 8822718464,
        "learning_rate": 0.00029266565836378916,
        "gradient_norm": 0.31818899512290955,
        "train_loss": 3.093842029571533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16829,
        "tokens": 8823242752,
        "learning_rate": 0.0002926372879761695,
        "gradient_norm": 0.3533223271369934,
        "train_loss": 3.078646183013916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16830,
        "tokens": 8823767040,
        "learning_rate": 0.0002926089180091138,
        "gradient_norm": 0.36177822947502136,
        "train_loss": 3.0957460403442383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16831,
        "tokens": 8824291328,
        "learning_rate": 0.00029258054846294126,
        "gradient_norm": 0.34782758355140686,
        "train_loss": 3.1067018508911133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16832,
        "tokens": 8824815616,
        "learning_rate": 0.0002925521793379714,
        "gradient_norm": 0.30804383754730225,
        "train_loss": 3.1550846099853516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16833,
        "tokens": 8825339904,
        "learning_rate": 0.0002925238106345233,
        "gradient_norm": 0.34956225752830505,
        "train_loss": 3.097749948501587,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16834,
        "tokens": 8825864192,
        "learning_rate": 0.0002924954423529164,
        "gradient_norm": 0.3203674256801605,
        "train_loss": 3.117931365966797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16835,
        "tokens": 8826388480,
        "learning_rate": 0.00029246707449347023,
        "gradient_norm": 0.34383881092071533,
        "train_loss": 3.0716052055358887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16836,
        "tokens": 8826912768,
        "learning_rate": 0.00029243870705650374,
        "gradient_norm": 0.29994747042655945,
        "train_loss": 3.1274468898773193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16837,
        "tokens": 8827437056,
        "learning_rate": 0.00029241034004233663,
        "gradient_norm": 0.3402952551841736,
        "train_loss": 3.0984725952148438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16838,
        "tokens": 8827961344,
        "learning_rate": 0.0002923819734512878,
        "gradient_norm": 0.30433133244514465,
        "train_loss": 3.091096878051758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16839,
        "tokens": 8828485632,
        "learning_rate": 0.000292353607283677,
        "gradient_norm": 0.3349410891532898,
        "train_loss": 3.090275764465332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16840,
        "tokens": 8829009920,
        "learning_rate": 0.000292325241539823,
        "gradient_norm": 0.3526194393634796,
        "train_loss": 3.0440673828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16841,
        "tokens": 8829534208,
        "learning_rate": 0.0002922968762200455,
        "gradient_norm": 0.3169030249118805,
        "train_loss": 3.0734670162200928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16842,
        "tokens": 8830058496,
        "learning_rate": 0.00029226851132466364,
        "gradient_norm": 0.4006844758987427,
        "train_loss": 3.1047396659851074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16843,
        "tokens": 8830582784,
        "learning_rate": 0.00029224014685399666,
        "gradient_norm": 0.3304407298564911,
        "train_loss": 3.0936458110809326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16844,
        "tokens": 8831107072,
        "learning_rate": 0.00029221178280836404,
        "gradient_norm": 0.36738893389701843,
        "train_loss": 3.1238718032836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16845,
        "tokens": 8831631360,
        "learning_rate": 0.00029218341918808475,
        "gradient_norm": 0.3606436252593994,
        "train_loss": 3.079911470413208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16846,
        "tokens": 8832155648,
        "learning_rate": 0.00029215505599347835,
        "gradient_norm": 0.4337950646877289,
        "train_loss": 3.241921901702881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16847,
        "tokens": 8832679936,
        "learning_rate": 0.0002921266932248639,
        "gradient_norm": 0.36828869581222534,
        "train_loss": 3.098264694213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16848,
        "tokens": 8833204224,
        "learning_rate": 0.00029209833088256074,
        "gradient_norm": 0.39066824316978455,
        "train_loss": 3.0719029903411865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16849,
        "tokens": 8833728512,
        "learning_rate": 0.00029206996896688806,
        "gradient_norm": 0.35007521510124207,
        "train_loss": 3.1154932975769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16850,
        "tokens": 8834252800,
        "learning_rate": 0.00029204160747816526,
        "gradient_norm": 0.38683637976646423,
        "train_loss": 3.060178756713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16851,
        "tokens": 8834777088,
        "learning_rate": 0.0002920132464167114,
        "gradient_norm": 0.35116663575172424,
        "train_loss": 3.133493423461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16852,
        "tokens": 8835301376,
        "learning_rate": 0.00029198488578284585,
        "gradient_norm": 0.385550320148468,
        "train_loss": 3.0507583618164062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16853,
        "tokens": 8835825664,
        "learning_rate": 0.0002919565255768878,
        "gradient_norm": 0.4152224361896515,
        "train_loss": 3.1133432388305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16854,
        "tokens": 8836349952,
        "learning_rate": 0.00029192816579915647,
        "gradient_norm": 0.31889069080352783,
        "train_loss": 3.0778462886810303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16855,
        "tokens": 8836874240,
        "learning_rate": 0.0002918998064499711,
        "gradient_norm": 0.3711252808570862,
        "train_loss": 3.0958034992218018,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16856,
        "tokens": 8837398528,
        "learning_rate": 0.0002918714475296509,
        "gradient_norm": 0.3576768636703491,
        "train_loss": 3.08660888671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16857,
        "tokens": 8837922816,
        "learning_rate": 0.000291843089038515,
        "gradient_norm": 0.3468247652053833,
        "train_loss": 3.07413911819458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16858,
        "tokens": 8838447104,
        "learning_rate": 0.0002918147309768828,
        "gradient_norm": 0.32261234521865845,
        "train_loss": 3.089966297149658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16859,
        "tokens": 8838971392,
        "learning_rate": 0.0002917863733450734,
        "gradient_norm": 0.3428122401237488,
        "train_loss": 3.13668155670166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16860,
        "tokens": 8839495680,
        "learning_rate": 0.000291758016143406,
        "gradient_norm": 0.29769250750541687,
        "train_loss": 3.0550456047058105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16861,
        "tokens": 8840019968,
        "learning_rate": 0.00029172965937219976,
        "gradient_norm": 0.30985429883003235,
        "train_loss": 3.11460280418396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16862,
        "tokens": 8840544256,
        "learning_rate": 0.00029170130303177394,
        "gradient_norm": 0.28286004066467285,
        "train_loss": 3.054603099822998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16863,
        "tokens": 8841068544,
        "learning_rate": 0.0002916729471224476,
        "gradient_norm": 0.2908211648464203,
        "train_loss": 3.103597640991211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16864,
        "tokens": 8841592832,
        "learning_rate": 0.0002916445916445402,
        "gradient_norm": 0.31632089614868164,
        "train_loss": 3.2006425857543945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16865,
        "tokens": 8842117120,
        "learning_rate": 0.00029161623659837053,
        "gradient_norm": 0.3243429660797119,
        "train_loss": 3.1573872566223145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16866,
        "tokens": 8842641408,
        "learning_rate": 0.00029158788198425814,
        "gradient_norm": 0.2989332973957062,
        "train_loss": 3.0570404529571533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16867,
        "tokens": 8843165696,
        "learning_rate": 0.0002915595278025219,
        "gradient_norm": 0.30662861466407776,
        "train_loss": 3.0749073028564453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16868,
        "tokens": 8843689984,
        "learning_rate": 0.0002915311740534812,
        "gradient_norm": 0.2863861620426178,
        "train_loss": 3.0398316383361816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16869,
        "tokens": 8844214272,
        "learning_rate": 0.0002915028207374549,
        "gradient_norm": 0.301151841878891,
        "train_loss": 3.053797721862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16870,
        "tokens": 8844738560,
        "learning_rate": 0.00029147446785476254,
        "gradient_norm": 0.32695141434669495,
        "train_loss": 3.081838607788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16871,
        "tokens": 8845262848,
        "learning_rate": 0.00029144611540572296,
        "gradient_norm": 0.35325726866722107,
        "train_loss": 3.123894691467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16872,
        "tokens": 8845787136,
        "learning_rate": 0.00029141776339065536,
        "gradient_norm": 0.3301966190338135,
        "train_loss": 3.058979034423828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16873,
        "tokens": 8846311424,
        "learning_rate": 0.00029138941180987903,
        "gradient_norm": 0.2951601445674896,
        "train_loss": 3.086768627166748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16874,
        "tokens": 8846835712,
        "learning_rate": 0.00029136106066371295,
        "gradient_norm": 0.3139895498752594,
        "train_loss": 3.0995705127716064,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16875,
        "tokens": 8847360000,
        "learning_rate": 0.0002913327099524764,
        "gradient_norm": 0.3139093220233917,
        "train_loss": 3.083284854888916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16876,
        "tokens": 8847884288,
        "learning_rate": 0.0002913043596764883,
        "gradient_norm": 0.32676833868026733,
        "train_loss": 3.0884695053100586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16877,
        "tokens": 8848408576,
        "learning_rate": 0.0002912760098360679,
        "gradient_norm": 0.341113418340683,
        "train_loss": 3.1135072708129883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16878,
        "tokens": 8848932864,
        "learning_rate": 0.00029124766043153423,
        "gradient_norm": 0.3104698061943054,
        "train_loss": 3.092008113861084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16879,
        "tokens": 8849457152,
        "learning_rate": 0.0002912193114632066,
        "gradient_norm": 0.3144189715385437,
        "train_loss": 3.0457370281219482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16880,
        "tokens": 8849981440,
        "learning_rate": 0.00029119096293140376,
        "gradient_norm": 0.29774466156959534,
        "train_loss": 3.114335060119629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16881,
        "tokens": 8850505728,
        "learning_rate": 0.00029116261483644513,
        "gradient_norm": 0.33551087975502014,
        "train_loss": 3.09087872505188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16882,
        "tokens": 8851030016,
        "learning_rate": 0.0002911342671786496,
        "gradient_norm": 0.3236178457736969,
        "train_loss": 3.117926836013794,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16883,
        "tokens": 8851554304,
        "learning_rate": 0.00029110591995833634,
        "gradient_norm": 0.30733951926231384,
        "train_loss": 3.0979788303375244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16884,
        "tokens": 8852078592,
        "learning_rate": 0.00029107757317582456,
        "gradient_norm": 0.2947241961956024,
        "train_loss": 3.057490348815918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16885,
        "tokens": 8852602880,
        "learning_rate": 0.00029104922683143307,
        "gradient_norm": 0.28163886070251465,
        "train_loss": 3.051309585571289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16886,
        "tokens": 8853127168,
        "learning_rate": 0.00029102088092548123,
        "gradient_norm": 0.28835663199424744,
        "train_loss": 3.053872585296631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16887,
        "tokens": 8853651456,
        "learning_rate": 0.0002909925354582878,
        "gradient_norm": 0.3005547821521759,
        "train_loss": 3.1303205490112305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16888,
        "tokens": 8854175744,
        "learning_rate": 0.0002909641904301722,
        "gradient_norm": 0.287494033575058,
        "train_loss": 3.124481201171875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16889,
        "tokens": 8854700032,
        "learning_rate": 0.00029093584584145306,
        "gradient_norm": 0.30802440643310547,
        "train_loss": 3.1091041564941406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16890,
        "tokens": 8855224320,
        "learning_rate": 0.00029090750169244987,
        "gradient_norm": 0.2966769337654114,
        "train_loss": 3.0893056392669678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16891,
        "tokens": 8855748608,
        "learning_rate": 0.0002908791579834814,
        "gradient_norm": 0.3059656620025635,
        "train_loss": 3.1105828285217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16892,
        "tokens": 8856272896,
        "learning_rate": 0.0002908508147148667,
        "gradient_norm": 0.334622323513031,
        "train_loss": 3.049264430999756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16893,
        "tokens": 8856797184,
        "learning_rate": 0.00029082247188692503,
        "gradient_norm": 0.31435948610305786,
        "train_loss": 3.093982458114624,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16894,
        "tokens": 8857321472,
        "learning_rate": 0.0002907941294999751,
        "gradient_norm": 0.2883697748184204,
        "train_loss": 3.061051368713379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16895,
        "tokens": 8857845760,
        "learning_rate": 0.0002907657875543363,
        "gradient_norm": 0.3005853593349457,
        "train_loss": 3.118887424468994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16896,
        "tokens": 8858370048,
        "learning_rate": 0.0002907374460503273,
        "gradient_norm": 0.29316380620002747,
        "train_loss": 3.0995216369628906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16897,
        "tokens": 8858894336,
        "learning_rate": 0.0002907091049882675,
        "gradient_norm": 0.3161131739616394,
        "train_loss": 3.0419058799743652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16898,
        "tokens": 8859418624,
        "learning_rate": 0.0002906807643684755,
        "gradient_norm": 0.2976153492927551,
        "train_loss": 2.9774680137634277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16899,
        "tokens": 8859942912,
        "learning_rate": 0.0002906524241912706,
        "gradient_norm": 0.3014906048774719,
        "train_loss": 3.102248191833496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16900,
        "tokens": 8860467200,
        "learning_rate": 0.00029062408445697165,
        "gradient_norm": 0.32978492975234985,
        "train_loss": 3.070106029510498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16901,
        "tokens": 8860991488,
        "learning_rate": 0.0002905957451658979,
        "gradient_norm": 0.3140166103839874,
        "train_loss": 3.1262807846069336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16902,
        "tokens": 8861515776,
        "learning_rate": 0.00029056740631836793,
        "gradient_norm": 0.3474453091621399,
        "train_loss": 3.149165391921997,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16903,
        "tokens": 8862040064,
        "learning_rate": 0.000290539067914701,
        "gradient_norm": 0.3202333152294159,
        "train_loss": 3.1077613830566406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16904,
        "tokens": 8862564352,
        "learning_rate": 0.0002905107299552161,
        "gradient_norm": 0.29757559299468994,
        "train_loss": 3.0765843391418457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16905,
        "tokens": 8863088640,
        "learning_rate": 0.00029048239244023217,
        "gradient_norm": 0.3238966464996338,
        "train_loss": 3.1127724647521973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16906,
        "tokens": 8863612928,
        "learning_rate": 0.0002904540553700681,
        "gradient_norm": 0.33203551173210144,
        "train_loss": 3.0631155967712402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16907,
        "tokens": 8864137216,
        "learning_rate": 0.00029042571874504305,
        "gradient_norm": 0.3055283725261688,
        "train_loss": 3.0730948448181152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16908,
        "tokens": 8864661504,
        "learning_rate": 0.0002903973825654758,
        "gradient_norm": 0.3106693625450134,
        "train_loss": 3.105283260345459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16909,
        "tokens": 8865185792,
        "learning_rate": 0.0002903690468316854,
        "gradient_norm": 0.3252583146095276,
        "train_loss": 3.076446533203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16910,
        "tokens": 8865710080,
        "learning_rate": 0.00029034071154399076,
        "gradient_norm": 0.2940237522125244,
        "train_loss": 3.058593511581421,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16911,
        "tokens": 8866234368,
        "learning_rate": 0.00029031237670271084,
        "gradient_norm": 0.3474659323692322,
        "train_loss": 3.1101250648498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16912,
        "tokens": 8866758656,
        "learning_rate": 0.00029028404230816454,
        "gradient_norm": 0.2936166226863861,
        "train_loss": 3.087993860244751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16913,
        "tokens": 8867282944,
        "learning_rate": 0.0002902557083606709,
        "gradient_norm": 0.32646849751472473,
        "train_loss": 3.094928026199341,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16914,
        "tokens": 8867807232,
        "learning_rate": 0.00029022737486054885,
        "gradient_norm": 0.32462725043296814,
        "train_loss": 3.1098947525024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16915,
        "tokens": 8868331520,
        "learning_rate": 0.0002901990418081172,
        "gradient_norm": 0.29593348503112793,
        "train_loss": 3.1254796981811523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16916,
        "tokens": 8868855808,
        "learning_rate": 0.000290170709203695,
        "gradient_norm": 0.3028445243835449,
        "train_loss": 3.084259033203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16917,
        "tokens": 8869380096,
        "learning_rate": 0.0002901423770476011,
        "gradient_norm": 0.3017506003379822,
        "train_loss": 3.0901689529418945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16918,
        "tokens": 8869904384,
        "learning_rate": 0.00029011404534015444,
        "gradient_norm": 0.2890804708003998,
        "train_loss": 3.129488468170166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16919,
        "tokens": 8870428672,
        "learning_rate": 0.00029008571408167393,
        "gradient_norm": 0.3243772089481354,
        "train_loss": 3.150341272354126,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16920,
        "tokens": 8870952960,
        "learning_rate": 0.00029005738327247846,
        "gradient_norm": 0.351741224527359,
        "train_loss": 3.0492544174194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16921,
        "tokens": 8871477248,
        "learning_rate": 0.0002900290529128869,
        "gradient_norm": 0.28203073143959045,
        "train_loss": 3.077070713043213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16922,
        "tokens": 8872001536,
        "learning_rate": 0.00029000072300321817,
        "gradient_norm": 0.3572100102901459,
        "train_loss": 3.111600399017334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16923,
        "tokens": 8872525824,
        "learning_rate": 0.00028997239354379114,
        "gradient_norm": 0.3175908625125885,
        "train_loss": 3.0751686096191406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16924,
        "tokens": 8873050112,
        "learning_rate": 0.0002899440645349248,
        "gradient_norm": 0.3131052255630493,
        "train_loss": 3.0516929626464844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16925,
        "tokens": 8873574400,
        "learning_rate": 0.0002899157359769379,
        "gradient_norm": 0.3477179706096649,
        "train_loss": 3.2346930503845215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16926,
        "tokens": 8874098688,
        "learning_rate": 0.0002898874078701494,
        "gradient_norm": 0.3481443226337433,
        "train_loss": 3.065279483795166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16927,
        "tokens": 8874622976,
        "learning_rate": 0.00028985908021487804,
        "gradient_norm": 0.3245695233345032,
        "train_loss": 3.110347270965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16928,
        "tokens": 8875147264,
        "learning_rate": 0.00028983075301144284,
        "gradient_norm": 0.35536813735961914,
        "train_loss": 3.0083436965942383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16929,
        "tokens": 8875671552,
        "learning_rate": 0.0002898024262601625,
        "gradient_norm": 0.31360548734664917,
        "train_loss": 3.142550468444824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16930,
        "tokens": 8876195840,
        "learning_rate": 0.0002897740999613561,
        "gradient_norm": 0.3293575942516327,
        "train_loss": 3.0529894828796387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16931,
        "tokens": 8876720128,
        "learning_rate": 0.00028974577411534225,
        "gradient_norm": 0.39011818170547485,
        "train_loss": 3.0911552906036377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16932,
        "tokens": 8877244416,
        "learning_rate": 0.00028971744872243984,
        "gradient_norm": 0.3617619276046753,
        "train_loss": 3.053020477294922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16933,
        "tokens": 8877768704,
        "learning_rate": 0.0002896891237829679,
        "gradient_norm": 0.29424989223480225,
        "train_loss": 3.1109328269958496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16934,
        "tokens": 8878292992,
        "learning_rate": 0.000289660799297245,
        "gradient_norm": 0.39953669905662537,
        "train_loss": 3.0891647338867188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16935,
        "tokens": 8878817280,
        "learning_rate": 0.0002896324752655902,
        "gradient_norm": 0.3385492265224457,
        "train_loss": 3.109799385070801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16936,
        "tokens": 8879341568,
        "learning_rate": 0.0002896041516883221,
        "gradient_norm": 0.34366995096206665,
        "train_loss": 3.088583469390869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16937,
        "tokens": 8879865856,
        "learning_rate": 0.0002895758285657597,
        "gradient_norm": 0.38454127311706543,
        "train_loss": 3.0940070152282715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16938,
        "tokens": 8880390144,
        "learning_rate": 0.00028954750589822167,
        "gradient_norm": 0.3224390149116516,
        "train_loss": 3.1136629581451416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16939,
        "tokens": 8880914432,
        "learning_rate": 0.000289519183686027,
        "gradient_norm": 0.3938133716583252,
        "train_loss": 3.1393260955810547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16940,
        "tokens": 8881438720,
        "learning_rate": 0.00028949086192949424,
        "gradient_norm": 0.31492897868156433,
        "train_loss": 3.0819785594940186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16941,
        "tokens": 8881963008,
        "learning_rate": 0.0002894625406289425,
        "gradient_norm": 0.35656338930130005,
        "train_loss": 3.0780229568481445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16942,
        "tokens": 8882487296,
        "learning_rate": 0.0002894342197846902,
        "gradient_norm": 0.3473586440086365,
        "train_loss": 3.033416986465454,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16943,
        "tokens": 8883011584,
        "learning_rate": 0.00028940589939705635,
        "gradient_norm": 0.33923768997192383,
        "train_loss": 3.1190125942230225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16944,
        "tokens": 8883535872,
        "learning_rate": 0.00028937757946635983,
        "gradient_norm": 0.31479719281196594,
        "train_loss": 3.0585267543792725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16945,
        "tokens": 8884060160,
        "learning_rate": 0.00028934925999291917,
        "gradient_norm": 0.3190937936306,
        "train_loss": 3.0850589275360107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16946,
        "tokens": 8884584448,
        "learning_rate": 0.00028932094097705336,
        "gradient_norm": 0.3493405282497406,
        "train_loss": 3.065181255340576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16947,
        "tokens": 8885108736,
        "learning_rate": 0.000289292622419081,
        "gradient_norm": 0.3371333181858063,
        "train_loss": 3.0539729595184326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16948,
        "tokens": 8885633024,
        "learning_rate": 0.00028926430431932106,
        "gradient_norm": 0.3308658003807068,
        "train_loss": 3.10014271736145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16949,
        "tokens": 8886157312,
        "learning_rate": 0.0002892359866780919,
        "gradient_norm": 0.3203370273113251,
        "train_loss": 3.1167855262756348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16950,
        "tokens": 8886681600,
        "learning_rate": 0.00028920766949571276,
        "gradient_norm": 0.3336746096611023,
        "train_loss": 3.0806894302368164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16951,
        "tokens": 8887205888,
        "learning_rate": 0.000289179352772502,
        "gradient_norm": 0.3442156910896301,
        "train_loss": 3.019484281539917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16952,
        "tokens": 8887730176,
        "learning_rate": 0.0002891510365087785,
        "gradient_norm": 0.346527636051178,
        "train_loss": 3.129348039627075,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16953,
        "tokens": 8888254464,
        "learning_rate": 0.0002891227207048611,
        "gradient_norm": 0.3496639132499695,
        "train_loss": 3.0937819480895996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16954,
        "tokens": 8888778752,
        "learning_rate": 0.00028909440536106833,
        "gradient_norm": 0.3485029339790344,
        "train_loss": 3.097646713256836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16955,
        "tokens": 8889303040,
        "learning_rate": 0.0002890660904777192,
        "gradient_norm": 0.36672213673591614,
        "train_loss": 3.173464775085449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16956,
        "tokens": 8889827328,
        "learning_rate": 0.00028903777605513207,
        "gradient_norm": 0.38358524441719055,
        "train_loss": 3.0825133323669434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16957,
        "tokens": 8890351616,
        "learning_rate": 0.00028900946209362596,
        "gradient_norm": 0.3396682143211365,
        "train_loss": 3.1533560752868652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16958,
        "tokens": 8890875904,
        "learning_rate": 0.00028898114859351933,
        "gradient_norm": 0.3589898943901062,
        "train_loss": 3.0770344734191895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16959,
        "tokens": 8891400192,
        "learning_rate": 0.00028895283555513114,
        "gradient_norm": 0.3272075355052948,
        "train_loss": 3.0433738231658936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16960,
        "tokens": 8891924480,
        "learning_rate": 0.0002889245229787797,
        "gradient_norm": 0.3383323550224304,
        "train_loss": 3.061105251312256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16961,
        "tokens": 8892448768,
        "learning_rate": 0.00028889621086478426,
        "gradient_norm": 0.317490816116333,
        "train_loss": 3.162642478942871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16962,
        "tokens": 8892973056,
        "learning_rate": 0.00028886789921346297,
        "gradient_norm": 0.33884096145629883,
        "train_loss": 3.112152576446533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16963,
        "tokens": 8893497344,
        "learning_rate": 0.0002888395880251349,
        "gradient_norm": 0.31308016180992126,
        "train_loss": 3.055338144302368,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16964,
        "tokens": 8894021632,
        "learning_rate": 0.00028881127730011856,
        "gradient_norm": 0.33482685685157776,
        "train_loss": 3.086951732635498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16965,
        "tokens": 8894545920,
        "learning_rate": 0.0002887829670387325,
        "gradient_norm": 0.318656861782074,
        "train_loss": 3.0869529247283936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16966,
        "tokens": 8895070208,
        "learning_rate": 0.0002887546572412957,
        "gradient_norm": 0.3435041010379791,
        "train_loss": 3.076580286026001,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16967,
        "tokens": 8895594496,
        "learning_rate": 0.00028872634790812657,
        "gradient_norm": 0.34347864985466003,
        "train_loss": 3.045693874359131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16968,
        "tokens": 8896118784,
        "learning_rate": 0.00028869803903954383,
        "gradient_norm": 0.34155794978141785,
        "train_loss": 3.0738728046417236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16969,
        "tokens": 8896643072,
        "learning_rate": 0.0002886697306358662,
        "gradient_norm": 0.30961310863494873,
        "train_loss": 3.0609259605407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16970,
        "tokens": 8897167360,
        "learning_rate": 0.0002886414226974122,
        "gradient_norm": 0.30769166350364685,
        "train_loss": 3.1064000129699707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16971,
        "tokens": 8897691648,
        "learning_rate": 0.0002886131152245006,
        "gradient_norm": 0.33824536204338074,
        "train_loss": 3.111185073852539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16972,
        "tokens": 8898215936,
        "learning_rate": 0.0002885848082174498,
        "gradient_norm": 0.3938748836517334,
        "train_loss": 3.1281657218933105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16973,
        "tokens": 8898740224,
        "learning_rate": 0.0002885565016765789,
        "gradient_norm": 0.3309827744960785,
        "train_loss": 3.084949016571045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16974,
        "tokens": 8899264512,
        "learning_rate": 0.000288528195602206,
        "gradient_norm": 0.37305447459220886,
        "train_loss": 3.0936598777770996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16975,
        "tokens": 8899788800,
        "learning_rate": 0.00028849988999465014,
        "gradient_norm": 0.3571207821369171,
        "train_loss": 3.2164323329925537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16976,
        "tokens": 8900313088,
        "learning_rate": 0.0002884715848542296,
        "gradient_norm": 0.341316819190979,
        "train_loss": 3.081404685974121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16977,
        "tokens": 8900837376,
        "learning_rate": 0.00028844328018126327,
        "gradient_norm": 0.3398135304450989,
        "train_loss": 3.064581871032715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16978,
        "tokens": 8901361664,
        "learning_rate": 0.00028841497597606946,
        "gradient_norm": 0.33060044050216675,
        "train_loss": 3.1602301597595215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16979,
        "tokens": 8901885952,
        "learning_rate": 0.00028838667223896703,
        "gradient_norm": 0.34084564447402954,
        "train_loss": 3.095057487487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16980,
        "tokens": 8902410240,
        "learning_rate": 0.0002883583689702744,
        "gradient_norm": 0.32208964228630066,
        "train_loss": 3.129634141921997,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16981,
        "tokens": 8902934528,
        "learning_rate": 0.00028833006617031044,
        "gradient_norm": 0.3306727409362793,
        "train_loss": 3.0655007362365723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16982,
        "tokens": 8903458816,
        "learning_rate": 0.00028830176383939335,
        "gradient_norm": 0.30568447709083557,
        "train_loss": 3.1403801441192627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16983,
        "tokens": 8903983104,
        "learning_rate": 0.00028827346197784186,
        "gradient_norm": 0.32428666949272156,
        "train_loss": 3.0897397994995117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16984,
        "tokens": 8904507392,
        "learning_rate": 0.00028824516058597466,
        "gradient_norm": 0.31940215826034546,
        "train_loss": 3.0973620414733887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16985,
        "tokens": 8905031680,
        "learning_rate": 0.0002882168596641102,
        "gradient_norm": 0.2880235016345978,
        "train_loss": 3.0874247550964355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16986,
        "tokens": 8905555968,
        "learning_rate": 0.0002881885592125671,
        "gradient_norm": 0.32553228735923767,
        "train_loss": 3.037946939468384,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16987,
        "tokens": 8906080256,
        "learning_rate": 0.0002881602592316638,
        "gradient_norm": 0.27928248047828674,
        "train_loss": 3.030165195465088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16988,
        "tokens": 8906604544,
        "learning_rate": 0.00028813195972171904,
        "gradient_norm": 0.347533643245697,
        "train_loss": 3.1524569988250732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16989,
        "tokens": 8907128832,
        "learning_rate": 0.0002881036606830512,
        "gradient_norm": 0.34150439500808716,
        "train_loss": 3.072716236114502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16990,
        "tokens": 8907653120,
        "learning_rate": 0.00028807536211597896,
        "gradient_norm": 0.33480021357536316,
        "train_loss": 3.172600269317627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16991,
        "tokens": 8908177408,
        "learning_rate": 0.00028804706402082064,
        "gradient_norm": 0.35814377665519714,
        "train_loss": 3.1231987476348877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16992,
        "tokens": 8908701696,
        "learning_rate": 0.00028801876639789493,
        "gradient_norm": 0.40267637372016907,
        "train_loss": 3.100831985473633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16993,
        "tokens": 8909225984,
        "learning_rate": 0.00028799046924752046,
        "gradient_norm": 0.3235754072666168,
        "train_loss": 3.13330078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16994,
        "tokens": 8909750272,
        "learning_rate": 0.0002879621725700155,
        "gradient_norm": 0.3359977602958679,
        "train_loss": 3.020042896270752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16995,
        "tokens": 8910274560,
        "learning_rate": 0.0002879338763656988,
        "gradient_norm": 0.3749238848686218,
        "train_loss": 3.1344001293182373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16996,
        "tokens": 8910798848,
        "learning_rate": 0.00028790558063488867,
        "gradient_norm": 0.38209888339042664,
        "train_loss": 3.1525073051452637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16997,
        "tokens": 8911323136,
        "learning_rate": 0.0002878772853779038,
        "gradient_norm": 0.3881172835826874,
        "train_loss": 3.1156609058380127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16998,
        "tokens": 8911847424,
        "learning_rate": 0.00028784899059506247,
        "gradient_norm": 0.36415529251098633,
        "train_loss": 3.0636584758758545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16999,
        "tokens": 8912371712,
        "learning_rate": 0.0002878206962866834,
        "gradient_norm": 0.3292727470397949,
        "train_loss": 3.071070432662964,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17000,
        "tokens": 8912896000,
        "learning_rate": 0.0002877924024530849,
        "gradient_norm": 0.43403834104537964,
        "train_loss": 3.1790852546691895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17001,
        "tokens": 8913420288,
        "learning_rate": 0.0002877641090945856,
        "gradient_norm": 0.5055148601531982,
        "train_loss": 3.1531529426574707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17002,
        "tokens": 8913944576,
        "learning_rate": 0.0002877358162115038,
        "gradient_norm": 0.383376806974411,
        "train_loss": 3.109912395477295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17003,
        "tokens": 8914468864,
        "learning_rate": 0.00028770752380415804,
        "gradient_norm": 0.3773877024650574,
        "train_loss": 3.1047329902648926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17004,
        "tokens": 8914993152,
        "learning_rate": 0.00028767923187286693,
        "gradient_norm": 0.34390440583229065,
        "train_loss": 3.0978951454162598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17005,
        "tokens": 8915517440,
        "learning_rate": 0.0002876509404179488,
        "gradient_norm": 0.3436972498893738,
        "train_loss": 3.0910370349884033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17006,
        "tokens": 8916041728,
        "learning_rate": 0.0002876226494397221,
        "gradient_norm": 0.33974334597587585,
        "train_loss": 3.1478047370910645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17007,
        "tokens": 8916566016,
        "learning_rate": 0.0002875943589385053,
        "gradient_norm": 0.35619914531707764,
        "train_loss": 3.0642435550689697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17008,
        "tokens": 8917090304,
        "learning_rate": 0.0002875660689146169,
        "gradient_norm": 0.3416300415992737,
        "train_loss": 3.053730010986328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17009,
        "tokens": 8917614592,
        "learning_rate": 0.0002875377793683752,
        "gradient_norm": 0.31948453187942505,
        "train_loss": 3.1338143348693848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17010,
        "tokens": 8918138880,
        "learning_rate": 0.00028750949030009884,
        "gradient_norm": 0.3348160684108734,
        "train_loss": 3.0963528156280518,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17011,
        "tokens": 8918663168,
        "learning_rate": 0.0002874812017101061,
        "gradient_norm": 0.30436694622039795,
        "train_loss": 3.1038670539855957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17012,
        "tokens": 8919187456,
        "learning_rate": 0.0002874529135987154,
        "gradient_norm": 0.3234592080116272,
        "train_loss": 3.060647964477539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17013,
        "tokens": 8919711744,
        "learning_rate": 0.0002874246259662452,
        "gradient_norm": 0.32441022992134094,
        "train_loss": 3.15036678314209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17014,
        "tokens": 8920236032,
        "learning_rate": 0.00028739633881301387,
        "gradient_norm": 0.32387346029281616,
        "train_loss": 3.0941364765167236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17015,
        "tokens": 8920760320,
        "learning_rate": 0.0002873680521393399,
        "gradient_norm": 0.32369720935821533,
        "train_loss": 3.1514053344726562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17016,
        "tokens": 8921284608,
        "learning_rate": 0.00028733976594554165,
        "gradient_norm": 0.3244786262512207,
        "train_loss": 3.109389305114746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17017,
        "tokens": 8921808896,
        "learning_rate": 0.0002873114802319375,
        "gradient_norm": 0.3010571002960205,
        "train_loss": 3.103518009185791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17018,
        "tokens": 8922333184,
        "learning_rate": 0.0002872831949988459,
        "gradient_norm": 0.33607980608940125,
        "train_loss": 3.059400796890259,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17019,
        "tokens": 8922857472,
        "learning_rate": 0.00028725491024658516,
        "gradient_norm": 0.3037354052066803,
        "train_loss": 3.1016764640808105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17020,
        "tokens": 8923381760,
        "learning_rate": 0.0002872266259754736,
        "gradient_norm": 0.313337504863739,
        "train_loss": 3.0916318893432617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17021,
        "tokens": 8923906048,
        "learning_rate": 0.0002871983421858298,
        "gradient_norm": 0.30434778332710266,
        "train_loss": 3.0906715393066406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17022,
        "tokens": 8924430336,
        "learning_rate": 0.00028717005887797195,
        "gradient_norm": 0.29336339235305786,
        "train_loss": 3.096677780151367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17023,
        "tokens": 8924954624,
        "learning_rate": 0.00028714177605221845,
        "gradient_norm": 0.32595786452293396,
        "train_loss": 3.033726692199707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17024,
        "tokens": 8925478912,
        "learning_rate": 0.00028711349370888776,
        "gradient_norm": 0.2952682375907898,
        "train_loss": 3.089292526245117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17025,
        "tokens": 8926003200,
        "learning_rate": 0.0002870852118482981,
        "gradient_norm": 0.31318458914756775,
        "train_loss": 3.1023826599121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17026,
        "tokens": 8926527488,
        "learning_rate": 0.000287056930470768,
        "gradient_norm": 0.2973329424858093,
        "train_loss": 3.120588779449463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17027,
        "tokens": 8927051776,
        "learning_rate": 0.00028702864957661547,
        "gradient_norm": 0.33868518471717834,
        "train_loss": 3.1007447242736816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17028,
        "tokens": 8927576064,
        "learning_rate": 0.0002870003691661592,
        "gradient_norm": 0.40749579668045044,
        "train_loss": 3.11865496635437,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17029,
        "tokens": 8928100352,
        "learning_rate": 0.0002869720892397173,
        "gradient_norm": 0.3723565638065338,
        "train_loss": 3.1835789680480957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17030,
        "tokens": 8928624640,
        "learning_rate": 0.0002869438097976083,
        "gradient_norm": 0.48323875665664673,
        "train_loss": 2.9898548126220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17031,
        "tokens": 8929148928,
        "learning_rate": 0.0002869155308401502,
        "gradient_norm": 0.41628211736679077,
        "train_loss": 3.1116130352020264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17032,
        "tokens": 8929673216,
        "learning_rate": 0.0002868872523676616,
        "gradient_norm": 0.39256751537323,
        "train_loss": 3.039684295654297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17033,
        "tokens": 8930197504,
        "learning_rate": 0.0002868589743804608,
        "gradient_norm": 0.38371098041534424,
        "train_loss": 3.1743226051330566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17034,
        "tokens": 8930721792,
        "learning_rate": 0.0002868306968788659,
        "gradient_norm": 0.32675406336784363,
        "train_loss": 3.099867105484009,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17035,
        "tokens": 8931246080,
        "learning_rate": 0.0002868024198631954,
        "gradient_norm": 0.34770825505256653,
        "train_loss": 3.1361522674560547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17036,
        "tokens": 8931770368,
        "learning_rate": 0.0002867741433337674,
        "gradient_norm": 0.34538769721984863,
        "train_loss": 3.004075050354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17037,
        "tokens": 8932294656,
        "learning_rate": 0.0002867458672909004,
        "gradient_norm": 0.3229648768901825,
        "train_loss": 3.111739158630371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17038,
        "tokens": 8932818944,
        "learning_rate": 0.0002867175917349125,
        "gradient_norm": 0.33225682377815247,
        "train_loss": 3.0087461471557617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17039,
        "tokens": 8933343232,
        "learning_rate": 0.0002866893166661222,
        "gradient_norm": 0.32020893692970276,
        "train_loss": 3.0745797157287598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17040,
        "tokens": 8933867520,
        "learning_rate": 0.00028666104208484745,
        "gradient_norm": 0.34096962213516235,
        "train_loss": 3.1373250484466553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17041,
        "tokens": 8934391808,
        "learning_rate": 0.0002866327679914069,
        "gradient_norm": 0.33536645770072937,
        "train_loss": 3.1202194690704346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17042,
        "tokens": 8934916096,
        "learning_rate": 0.0002866044943861184,
        "gradient_norm": 0.3113020062446594,
        "train_loss": 3.0971593856811523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17043,
        "tokens": 8935440384,
        "learning_rate": 0.00028657622126930044,
        "gradient_norm": 0.3258044719696045,
        "train_loss": 3.0568740367889404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17044,
        "tokens": 8935964672,
        "learning_rate": 0.0002865479486412714,
        "gradient_norm": 0.3328840136528015,
        "train_loss": 3.0923051834106445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17045,
        "tokens": 8936488960,
        "learning_rate": 0.0002865196765023492,
        "gradient_norm": 0.36788153648376465,
        "train_loss": 3.0877881050109863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17046,
        "tokens": 8937013248,
        "learning_rate": 0.00028649140485285235,
        "gradient_norm": 0.3172314465045929,
        "train_loss": 3.074410915374756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17047,
        "tokens": 8937537536,
        "learning_rate": 0.00028646313369309884,
        "gradient_norm": 0.37004271149635315,
        "train_loss": 3.0774755477905273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17048,
        "tokens": 8938061824,
        "learning_rate": 0.0002864348630234072,
        "gradient_norm": 0.3531636893749237,
        "train_loss": 3.040264844894409,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17049,
        "tokens": 8938586112,
        "learning_rate": 0.00028640659284409533,
        "gradient_norm": 0.35288354754447937,
        "train_loss": 3.0539164543151855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17050,
        "tokens": 8939110400,
        "learning_rate": 0.00028637832315548176,
        "gradient_norm": 0.2930002808570862,
        "train_loss": 3.1256117820739746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17051,
        "tokens": 8939634688,
        "learning_rate": 0.0002863500539578844,
        "gradient_norm": 0.38307175040245056,
        "train_loss": 3.156193733215332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17052,
        "tokens": 8940158976,
        "learning_rate": 0.0002863217852516215,
        "gradient_norm": 0.3560480773448944,
        "train_loss": 3.109386682510376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17053,
        "tokens": 8940683264,
        "learning_rate": 0.0002862935170370116,
        "gradient_norm": 0.35943564772605896,
        "train_loss": 3.117478370666504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17054,
        "tokens": 8941207552,
        "learning_rate": 0.0002862652493143725,
        "gradient_norm": 0.3325837254524231,
        "train_loss": 3.140092372894287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17055,
        "tokens": 8941731840,
        "learning_rate": 0.00028623698208402265,
        "gradient_norm": 0.3383202850818634,
        "train_loss": 3.0933704376220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17056,
        "tokens": 8942256128,
        "learning_rate": 0.00028620871534627997,
        "gradient_norm": 0.32577410340309143,
        "train_loss": 3.0603978633880615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17057,
        "tokens": 8942780416,
        "learning_rate": 0.0002861804491014629,
        "gradient_norm": 0.31863659620285034,
        "train_loss": 3.077664852142334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17058,
        "tokens": 8943304704,
        "learning_rate": 0.00028615218334988944,
        "gradient_norm": 0.37030884623527527,
        "train_loss": 3.133481979370117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17059,
        "tokens": 8943828992,
        "learning_rate": 0.00028612391809187786,
        "gradient_norm": 0.3023729622364044,
        "train_loss": 3.048673391342163,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17060,
        "tokens": 8944353280,
        "learning_rate": 0.00028609565332774617,
        "gradient_norm": 0.3211832344532013,
        "train_loss": 3.0915303230285645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17061,
        "tokens": 8944877568,
        "learning_rate": 0.0002860673890578128,
        "gradient_norm": 0.28940320014953613,
        "train_loss": 3.1287598609924316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17062,
        "tokens": 8945401856,
        "learning_rate": 0.00028603912528239555,
        "gradient_norm": 0.31562313437461853,
        "train_loss": 3.1089682579040527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17063,
        "tokens": 8945926144,
        "learning_rate": 0.0002860108620018129,
        "gradient_norm": 0.3597928285598755,
        "train_loss": 3.0655789375305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17064,
        "tokens": 8946450432,
        "learning_rate": 0.00028598259921638273,
        "gradient_norm": 0.32209378480911255,
        "train_loss": 3.07743501663208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17065,
        "tokens": 8946974720,
        "learning_rate": 0.00028595433692642333,
        "gradient_norm": 0.31746187806129456,
        "train_loss": 3.082645893096924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17066,
        "tokens": 8947499008,
        "learning_rate": 0.0002859260751322528,
        "gradient_norm": 0.3221418559551239,
        "train_loss": 3.067378520965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17067,
        "tokens": 8948023296,
        "learning_rate": 0.0002858978138341891,
        "gradient_norm": 0.3121032416820526,
        "train_loss": 3.1016032695770264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17068,
        "tokens": 8948547584,
        "learning_rate": 0.00028586955303255054,
        "gradient_norm": 0.33908921480178833,
        "train_loss": 3.0719265937805176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17069,
        "tokens": 8949071872,
        "learning_rate": 0.00028584129272765527,
        "gradient_norm": 0.3104202151298523,
        "train_loss": 3.078150749206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17070,
        "tokens": 8949596160,
        "learning_rate": 0.00028581303291982116,
        "gradient_norm": 0.34448617696762085,
        "train_loss": 3.0904953479766846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17071,
        "tokens": 8950120448,
        "learning_rate": 0.00028578477360936654,
        "gradient_norm": 0.2981951832771301,
        "train_loss": 3.132314682006836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17072,
        "tokens": 8950644736,
        "learning_rate": 0.0002857565147966093,
        "gradient_norm": 0.3201236128807068,
        "train_loss": 3.0328941345214844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17073,
        "tokens": 8951169024,
        "learning_rate": 0.00028572825648186777,
        "gradient_norm": 0.3041312098503113,
        "train_loss": 3.1124372482299805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17074,
        "tokens": 8951693312,
        "learning_rate": 0.00028569999866545983,
        "gradient_norm": 0.3320733308792114,
        "train_loss": 3.128148078918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17075,
        "tokens": 8952217600,
        "learning_rate": 0.00028567174134770364,
        "gradient_norm": 0.30884233117103577,
        "train_loss": 3.0337305068969727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17076,
        "tokens": 8952741888,
        "learning_rate": 0.00028564348452891724,
        "gradient_norm": 0.3304752707481384,
        "train_loss": 3.117015838623047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17077,
        "tokens": 8953266176,
        "learning_rate": 0.0002856152282094188,
        "gradient_norm": 0.3248794674873352,
        "train_loss": 3.088571548461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17078,
        "tokens": 8953790464,
        "learning_rate": 0.0002855869723895261,
        "gradient_norm": 0.3229009509086609,
        "train_loss": 3.0419600009918213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17079,
        "tokens": 8954314752,
        "learning_rate": 0.0002855587170695576,
        "gradient_norm": 0.340619832277298,
        "train_loss": 3.148540496826172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17080,
        "tokens": 8954839040,
        "learning_rate": 0.00028553046224983095,
        "gradient_norm": 0.3485998213291168,
        "train_loss": 3.0600056648254395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17081,
        "tokens": 8955363328,
        "learning_rate": 0.0002855022079306646,
        "gradient_norm": 0.29241788387298584,
        "train_loss": 3.1073873043060303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17082,
        "tokens": 8955887616,
        "learning_rate": 0.0002854739541123762,
        "gradient_norm": 0.324285089969635,
        "train_loss": 3.050597667694092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17083,
        "tokens": 8956411904,
        "learning_rate": 0.00028544570079528395,
        "gradient_norm": 0.32995104789733887,
        "train_loss": 3.063459873199463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17084,
        "tokens": 8956936192,
        "learning_rate": 0.0002854174479797059,
        "gradient_norm": 0.3336656987667084,
        "train_loss": 3.0694193840026855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17085,
        "tokens": 8957460480,
        "learning_rate": 0.00028538919566596004,
        "gradient_norm": 0.3384675681591034,
        "train_loss": 3.106353759765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17086,
        "tokens": 8957984768,
        "learning_rate": 0.0002853609438543645,
        "gradient_norm": 0.3135794997215271,
        "train_loss": 3.0631046295166016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17087,
        "tokens": 8958509056,
        "learning_rate": 0.000285332692545237,
        "gradient_norm": 0.31819793581962585,
        "train_loss": 3.0319466590881348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17088,
        "tokens": 8959033344,
        "learning_rate": 0.0002853044417388959,
        "gradient_norm": 0.30819445848464966,
        "train_loss": 3.0661282539367676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17089,
        "tokens": 8959557632,
        "learning_rate": 0.0002852761914356589,
        "gradient_norm": 0.3321118950843811,
        "train_loss": 3.120547294616699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17090,
        "tokens": 8960081920,
        "learning_rate": 0.0002852479416358442,
        "gradient_norm": 0.31654617190361023,
        "train_loss": 3.1251230239868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17091,
        "tokens": 8960606208,
        "learning_rate": 0.00028521969233976963,
        "gradient_norm": 0.36534103751182556,
        "train_loss": 3.1026253700256348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17092,
        "tokens": 8961130496,
        "learning_rate": 0.00028519144354775323,
        "gradient_norm": 0.3295690715312958,
        "train_loss": 3.1054649353027344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17093,
        "tokens": 8961654784,
        "learning_rate": 0.00028516319526011304,
        "gradient_norm": 0.34441283345222473,
        "train_loss": 3.107355833053589,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17094,
        "tokens": 8962179072,
        "learning_rate": 0.00028513494747716697,
        "gradient_norm": 0.3406367003917694,
        "train_loss": 3.055851936340332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17095,
        "tokens": 8962703360,
        "learning_rate": 0.00028510670019923304,
        "gradient_norm": 0.33031517267227173,
        "train_loss": 3.1196341514587402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17096,
        "tokens": 8963227648,
        "learning_rate": 0.00028507845342662906,
        "gradient_norm": 0.30113938450813293,
        "train_loss": 3.0977671146392822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17097,
        "tokens": 8963751936,
        "learning_rate": 0.0002850502071596732,
        "gradient_norm": 0.32786422967910767,
        "train_loss": 3.0548787117004395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17098,
        "tokens": 8964276224,
        "learning_rate": 0.00028502196139868315,
        "gradient_norm": 0.33568274974823,
        "train_loss": 3.1003894805908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17099,
        "tokens": 8964800512,
        "learning_rate": 0.0002849937161439771,
        "gradient_norm": 0.3491170108318329,
        "train_loss": 3.0975561141967773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17100,
        "tokens": 8965324800,
        "learning_rate": 0.00028496547139587284,
        "gradient_norm": 0.35168108344078064,
        "train_loss": 3.098186492919922,
        "val_loss": 3.0529603958129883,
        "hellaswag_acc": 0.2815176248550415,
        "hellaswag_acc_norm": 0.2893846035003662
    },
    {
        "step": 17101,
        "tokens": 8965849088,
        "learning_rate": 0.00028493722715468837,
        "gradient_norm": 0.28929346799850464,
        "train_loss": 3.051628589630127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17102,
        "tokens": 8966373376,
        "learning_rate": 0.0002849089834207415,
        "gradient_norm": 0.34769460558891296,
        "train_loss": 3.107546806335449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17103,
        "tokens": 8966897664,
        "learning_rate": 0.00028488074019435025,
        "gradient_norm": 0.2904232442378998,
        "train_loss": 3.1183974742889404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17104,
        "tokens": 8967421952,
        "learning_rate": 0.0002848524974758326,
        "gradient_norm": 0.3051646053791046,
        "train_loss": 3.0891056060791016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17105,
        "tokens": 8967946240,
        "learning_rate": 0.00028482425526550625,
        "gradient_norm": 0.32485416531562805,
        "train_loss": 3.1140871047973633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17106,
        "tokens": 8968470528,
        "learning_rate": 0.00028479601356368937,
        "gradient_norm": 0.33658766746520996,
        "train_loss": 3.097545862197876,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17107,
        "tokens": 8968994816,
        "learning_rate": 0.0002847677723706995,
        "gradient_norm": 0.43616941571235657,
        "train_loss": 3.040227174758911,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17108,
        "tokens": 8969519104,
        "learning_rate": 0.0002847395316868549,
        "gradient_norm": 0.3390348255634308,
        "train_loss": 3.045802593231201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17109,
        "tokens": 8970043392,
        "learning_rate": 0.0002847112915124732,
        "gradient_norm": 0.3212408423423767,
        "train_loss": 3.115556478500366,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17110,
        "tokens": 8970567680,
        "learning_rate": 0.0002846830518478725,
        "gradient_norm": 0.3595651686191559,
        "train_loss": 3.0909924507141113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17111,
        "tokens": 8971091968,
        "learning_rate": 0.0002846548126933704,
        "gradient_norm": 0.2999407649040222,
        "train_loss": 3.1041886806488037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17112,
        "tokens": 8971616256,
        "learning_rate": 0.00028462657404928495,
        "gradient_norm": 0.3488982915878296,
        "train_loss": 3.103325366973877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17113,
        "tokens": 8972140544,
        "learning_rate": 0.00028459833591593396,
        "gradient_norm": 0.32081443071365356,
        "train_loss": 3.1255297660827637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17114,
        "tokens": 8972664832,
        "learning_rate": 0.0002845700982936353,
        "gradient_norm": 0.31249749660491943,
        "train_loss": 3.0514168739318848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17115,
        "tokens": 8973189120,
        "learning_rate": 0.0002845418611827069,
        "gradient_norm": 0.3238126337528229,
        "train_loss": 3.105438232421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17116,
        "tokens": 8973713408,
        "learning_rate": 0.0002845136245834664,
        "gradient_norm": 0.3154972791671753,
        "train_loss": 3.1222360134124756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17117,
        "tokens": 8974237696,
        "learning_rate": 0.0002844853884962318,
        "gradient_norm": 0.32841014862060547,
        "train_loss": 3.0574779510498047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17118,
        "tokens": 8974761984,
        "learning_rate": 0.00028445715292132085,
        "gradient_norm": 0.3581278324127197,
        "train_loss": 3.134389877319336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17119,
        "tokens": 8975286272,
        "learning_rate": 0.00028442891785905144,
        "gradient_norm": 0.3411025106906891,
        "train_loss": 3.10119891166687,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17120,
        "tokens": 8975810560,
        "learning_rate": 0.00028440068330974134,
        "gradient_norm": 0.35129114985466003,
        "train_loss": 3.1641836166381836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17121,
        "tokens": 8976334848,
        "learning_rate": 0.0002843724492737085,
        "gradient_norm": 0.3730916976928711,
        "train_loss": 3.12081241607666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17122,
        "tokens": 8976859136,
        "learning_rate": 0.0002843442157512705,
        "gradient_norm": 0.34004005789756775,
        "train_loss": 3.0995330810546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17123,
        "tokens": 8977383424,
        "learning_rate": 0.0002843159827427453,
        "gradient_norm": 0.36453554034233093,
        "train_loss": 3.0700039863586426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17124,
        "tokens": 8977907712,
        "learning_rate": 0.00028428775024845064,
        "gradient_norm": 0.35648250579833984,
        "train_loss": 3.122866153717041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17125,
        "tokens": 8978432000,
        "learning_rate": 0.00028425951826870435,
        "gradient_norm": 0.33235663175582886,
        "train_loss": 3.1044762134552,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17126,
        "tokens": 8978956288,
        "learning_rate": 0.00028423128680382426,
        "gradient_norm": 0.401116281747818,
        "train_loss": 3.119173765182495,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17127,
        "tokens": 8979480576,
        "learning_rate": 0.0002842030558541281,
        "gradient_norm": 0.2839549779891968,
        "train_loss": 3.095757484436035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17128,
        "tokens": 8980004864,
        "learning_rate": 0.00028417482541993346,
        "gradient_norm": 0.3511882722377777,
        "train_loss": 3.050374984741211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17129,
        "tokens": 8980529152,
        "learning_rate": 0.0002841465955015584,
        "gradient_norm": 0.30134880542755127,
        "train_loss": 3.108701705932617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17130,
        "tokens": 8981053440,
        "learning_rate": 0.0002841183660993206,
        "gradient_norm": 0.3176819384098053,
        "train_loss": 3.102935314178467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17131,
        "tokens": 8981577728,
        "learning_rate": 0.00028409013721353776,
        "gradient_norm": 0.315376877784729,
        "train_loss": 3.054912567138672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17132,
        "tokens": 8982102016,
        "learning_rate": 0.0002840619088445276,
        "gradient_norm": 0.3185349702835083,
        "train_loss": 3.1540064811706543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17133,
        "tokens": 8982626304,
        "learning_rate": 0.000284033680992608,
        "gradient_norm": 0.2929157614707947,
        "train_loss": 3.0489611625671387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17134,
        "tokens": 8983150592,
        "learning_rate": 0.0002840054536580965,
        "gradient_norm": 0.3011164367198944,
        "train_loss": 3.1406664848327637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17135,
        "tokens": 8983674880,
        "learning_rate": 0.00028397722684131107,
        "gradient_norm": 0.32331526279449463,
        "train_loss": 3.0758538246154785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17136,
        "tokens": 8984199168,
        "learning_rate": 0.0002839490005425693,
        "gradient_norm": 0.36197197437286377,
        "train_loss": 3.1253879070281982,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17137,
        "tokens": 8984723456,
        "learning_rate": 0.0002839207747621889,
        "gradient_norm": 0.30569934844970703,
        "train_loss": 3.0890603065490723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17138,
        "tokens": 8985247744,
        "learning_rate": 0.0002838925495004876,
        "gradient_norm": 0.3174026310443878,
        "train_loss": 3.1535141468048096,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17139,
        "tokens": 8985772032,
        "learning_rate": 0.0002838643247577832,
        "gradient_norm": 0.30218902230262756,
        "train_loss": 3.084890842437744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17140,
        "tokens": 8986296320,
        "learning_rate": 0.00028383610053439324,
        "gradient_norm": 0.3363952934741974,
        "train_loss": 3.095000743865967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17141,
        "tokens": 8986820608,
        "learning_rate": 0.0002838078768306356,
        "gradient_norm": 0.30618688464164734,
        "train_loss": 3.0526275634765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17142,
        "tokens": 8987344896,
        "learning_rate": 0.00028377965364682786,
        "gradient_norm": 0.30581793189048767,
        "train_loss": 3.078760862350464,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17143,
        "tokens": 8987869184,
        "learning_rate": 0.00028375143098328763,
        "gradient_norm": 0.29189229011535645,
        "train_loss": 3.116933822631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17144,
        "tokens": 8988393472,
        "learning_rate": 0.0002837232088403329,
        "gradient_norm": 0.2934575378894806,
        "train_loss": 3.088111400604248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17145,
        "tokens": 8988917760,
        "learning_rate": 0.000283694987218281,
        "gradient_norm": 0.28194835782051086,
        "train_loss": 3.1178488731384277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17146,
        "tokens": 8989442048,
        "learning_rate": 0.00028366676611744977,
        "gradient_norm": 0.3001991808414459,
        "train_loss": 3.0542640686035156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17147,
        "tokens": 8989966336,
        "learning_rate": 0.00028363854553815687,
        "gradient_norm": 0.3008933961391449,
        "train_loss": 3.11374831199646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17148,
        "tokens": 8990490624,
        "learning_rate": 0.0002836103254807199,
        "gradient_norm": 0.3042125701904297,
        "train_loss": 3.1225948333740234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17149,
        "tokens": 8991014912,
        "learning_rate": 0.0002835821059454565,
        "gradient_norm": 0.3015170693397522,
        "train_loss": 3.0657193660736084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17150,
        "tokens": 8991539200,
        "learning_rate": 0.0002835538869326845,
        "gradient_norm": 0.30834847688674927,
        "train_loss": 3.0859978199005127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17151,
        "tokens": 8992063488,
        "learning_rate": 0.0002835256684427212,
        "gradient_norm": 0.3524971306324005,
        "train_loss": 3.0805747509002686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17152,
        "tokens": 8992587776,
        "learning_rate": 0.0002834974504758845,
        "gradient_norm": 0.3268272578716278,
        "train_loss": 3.072227954864502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17153,
        "tokens": 8993112064,
        "learning_rate": 0.00028346923303249207,
        "gradient_norm": 0.29470717906951904,
        "train_loss": 3.087533950805664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17154,
        "tokens": 8993636352,
        "learning_rate": 0.0002834410161128613,
        "gradient_norm": 0.3244709372520447,
        "train_loss": 3.068032741546631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17155,
        "tokens": 8994160640,
        "learning_rate": 0.00028341279971731004,
        "gradient_norm": 0.3053039014339447,
        "train_loss": 3.0256223678588867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17156,
        "tokens": 8994684928,
        "learning_rate": 0.0002833845838461557,
        "gradient_norm": 0.2988288402557373,
        "train_loss": 3.0960683822631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17157,
        "tokens": 8995209216,
        "learning_rate": 0.0002833563684997161,
        "gradient_norm": 0.3081079423427582,
        "train_loss": 3.101254463195801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17158,
        "tokens": 8995733504,
        "learning_rate": 0.0002833281536783086,
        "gradient_norm": 0.3529735505580902,
        "train_loss": 3.091346263885498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17159,
        "tokens": 8996257792,
        "learning_rate": 0.00028329993938225095,
        "gradient_norm": 0.3157851994037628,
        "train_loss": 3.0754785537719727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17160,
        "tokens": 8996782080,
        "learning_rate": 0.0002832717256118606,
        "gradient_norm": 0.3317364454269409,
        "train_loss": 3.037360191345215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17161,
        "tokens": 8997306368,
        "learning_rate": 0.0002832435123674554,
        "gradient_norm": 0.3896389901638031,
        "train_loss": 3.0445518493652344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17162,
        "tokens": 8997830656,
        "learning_rate": 0.0002832152996493526,
        "gradient_norm": 0.30074542760849,
        "train_loss": 3.014366865158081,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17163,
        "tokens": 8998354944,
        "learning_rate": 0.0002831870874578699,
        "gradient_norm": 0.37721243500709534,
        "train_loss": 3.0878844261169434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17164,
        "tokens": 8998879232,
        "learning_rate": 0.00028315887579332506,
        "gradient_norm": 0.3047146797180176,
        "train_loss": 3.05073881149292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17165,
        "tokens": 8999403520,
        "learning_rate": 0.0002831306646560353,
        "gradient_norm": 0.3787637948989868,
        "train_loss": 2.998004913330078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17166,
        "tokens": 8999927808,
        "learning_rate": 0.0002831024540463185,
        "gradient_norm": 0.3182486295700073,
        "train_loss": 3.083728551864624,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17167,
        "tokens": 9000452096,
        "learning_rate": 0.00028307424396449186,
        "gradient_norm": 0.3281032145023346,
        "train_loss": 3.0915780067443848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17168,
        "tokens": 9000976384,
        "learning_rate": 0.00028304603441087325,
        "gradient_norm": 0.33592966198921204,
        "train_loss": 3.146397113800049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17169,
        "tokens": 9001500672,
        "learning_rate": 0.0002830178253857799,
        "gradient_norm": 0.32273730635643005,
        "train_loss": 3.037487030029297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17170,
        "tokens": 9002024960,
        "learning_rate": 0.0002829896168895297,
        "gradient_norm": 0.3155750036239624,
        "train_loss": 3.0513808727264404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17171,
        "tokens": 9002549248,
        "learning_rate": 0.0002829614089224398,
        "gradient_norm": 0.3192126452922821,
        "train_loss": 3.0697708129882812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17172,
        "tokens": 9003073536,
        "learning_rate": 0.0002829332014848279,
        "gradient_norm": 0.3528403341770172,
        "train_loss": 2.9975719451904297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17173,
        "tokens": 9003597824,
        "learning_rate": 0.0002829049945770115,
        "gradient_norm": 0.49287453293800354,
        "train_loss": 3.044243574142456,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17174,
        "tokens": 9004122112,
        "learning_rate": 0.00028287678819930806,
        "gradient_norm": 0.3392165005207062,
        "train_loss": 3.1525862216949463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17175,
        "tokens": 9004646400,
        "learning_rate": 0.0002828485823520351,
        "gradient_norm": 0.35285791754722595,
        "train_loss": 3.1014461517333984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17176,
        "tokens": 9005170688,
        "learning_rate": 0.0002828203770355102,
        "gradient_norm": 0.34053903818130493,
        "train_loss": 3.0927586555480957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17177,
        "tokens": 9005694976,
        "learning_rate": 0.00028279217225005073,
        "gradient_norm": 0.33822202682495117,
        "train_loss": 3.0816049575805664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17178,
        "tokens": 9006219264,
        "learning_rate": 0.00028276396799597423,
        "gradient_norm": 0.3262450098991394,
        "train_loss": 3.089840888977051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17179,
        "tokens": 9006743552,
        "learning_rate": 0.0002827357642735982,
        "gradient_norm": 0.3244237005710602,
        "train_loss": 3.0795035362243652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17180,
        "tokens": 9007267840,
        "learning_rate": 0.00028270756108323997,
        "gradient_norm": 0.3167504668235779,
        "train_loss": 3.108271598815918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17181,
        "tokens": 9007792128,
        "learning_rate": 0.0002826793584252171,
        "gradient_norm": 0.3028675317764282,
        "train_loss": 3.0793752670288086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17182,
        "tokens": 9008316416,
        "learning_rate": 0.00028265115629984706,
        "gradient_norm": 0.34733080863952637,
        "train_loss": 3.129361629486084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17183,
        "tokens": 9008840704,
        "learning_rate": 0.00028262295470744716,
        "gradient_norm": 0.3176110088825226,
        "train_loss": 3.1190314292907715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17184,
        "tokens": 9009364992,
        "learning_rate": 0.00028259475364833514,
        "gradient_norm": 0.3533976972103119,
        "train_loss": 3.103203058242798,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17185,
        "tokens": 9009889280,
        "learning_rate": 0.00028256655312282813,
        "gradient_norm": 0.4173080027103424,
        "train_loss": 3.093924045562744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17186,
        "tokens": 9010413568,
        "learning_rate": 0.00028253835313124385,
        "gradient_norm": 0.31733545660972595,
        "train_loss": 3.0925681591033936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17187,
        "tokens": 9010937856,
        "learning_rate": 0.0002825101536738994,
        "gradient_norm": 0.366883248090744,
        "train_loss": 3.135660171508789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17188,
        "tokens": 9011462144,
        "learning_rate": 0.0002824819547511125,
        "gradient_norm": 0.30742374062538147,
        "train_loss": 3.1454594135284424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17189,
        "tokens": 9011986432,
        "learning_rate": 0.00028245375636320026,
        "gradient_norm": 0.3557899594306946,
        "train_loss": 3.0940513610839844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17190,
        "tokens": 9012510720,
        "learning_rate": 0.0002824255585104805,
        "gradient_norm": 0.3264094591140747,
        "train_loss": 3.1060311794281006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17191,
        "tokens": 9013035008,
        "learning_rate": 0.00028239736119327016,
        "gradient_norm": 0.3349267244338989,
        "train_loss": 3.1728768348693848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17192,
        "tokens": 9013559296,
        "learning_rate": 0.00028236916441188686,
        "gradient_norm": 0.3256864845752716,
        "train_loss": 3.1226515769958496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17193,
        "tokens": 9014083584,
        "learning_rate": 0.00028234096816664815,
        "gradient_norm": 0.3941015303134918,
        "train_loss": 3.0078701972961426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17194,
        "tokens": 9014607872,
        "learning_rate": 0.00028231277245787116,
        "gradient_norm": 0.3513760268688202,
        "train_loss": 3.131002902984619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17195,
        "tokens": 9015132160,
        "learning_rate": 0.00028228457728587345,
        "gradient_norm": 0.36521434783935547,
        "train_loss": 3.1325745582580566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17196,
        "tokens": 9015656448,
        "learning_rate": 0.00028225638265097215,
        "gradient_norm": 0.364250123500824,
        "train_loss": 3.1724190711975098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17197,
        "tokens": 9016180736,
        "learning_rate": 0.00028222818855348493,
        "gradient_norm": 0.35617905855178833,
        "train_loss": 3.0656909942626953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17198,
        "tokens": 9016705024,
        "learning_rate": 0.00028219999499372886,
        "gradient_norm": 0.33777326345443726,
        "train_loss": 3.134241819381714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17199,
        "tokens": 9017229312,
        "learning_rate": 0.00028217180197202157,
        "gradient_norm": 0.3785002827644348,
        "train_loss": 3.0941596031188965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17200,
        "tokens": 9017753600,
        "learning_rate": 0.0002821436094886801,
        "gradient_norm": 0.3227328062057495,
        "train_loss": 3.0924601554870605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17201,
        "tokens": 9018277888,
        "learning_rate": 0.00028211541754402214,
        "gradient_norm": 0.3724176585674286,
        "train_loss": 3.0835180282592773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17202,
        "tokens": 9018802176,
        "learning_rate": 0.0002820872261383647,
        "gradient_norm": 0.35072940587997437,
        "train_loss": 3.059353828430176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17203,
        "tokens": 9019326464,
        "learning_rate": 0.00028205903527202524,
        "gradient_norm": 0.33700892329216003,
        "train_loss": 3.070373296737671,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17204,
        "tokens": 9019850752,
        "learning_rate": 0.00028203084494532124,
        "gradient_norm": 0.40825536847114563,
        "train_loss": 3.139831066131592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17205,
        "tokens": 9020375040,
        "learning_rate": 0.00028200265515856976,
        "gradient_norm": 0.40263068675994873,
        "train_loss": 3.087319850921631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17206,
        "tokens": 9020899328,
        "learning_rate": 0.00028197446591208836,
        "gradient_norm": 0.34031590819358826,
        "train_loss": 3.1302788257598877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17207,
        "tokens": 9021423616,
        "learning_rate": 0.000281946277206194,
        "gradient_norm": 0.510861873626709,
        "train_loss": 3.0746030807495117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17208,
        "tokens": 9021947904,
        "learning_rate": 0.0002819180890412044,
        "gradient_norm": 0.43012940883636475,
        "train_loss": 3.1712217330932617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17209,
        "tokens": 9022472192,
        "learning_rate": 0.0002818899014174365,
        "gradient_norm": 0.4061417579650879,
        "train_loss": 3.08656644821167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17210,
        "tokens": 9022996480,
        "learning_rate": 0.00028186171433520785,
        "gradient_norm": 0.3504176437854767,
        "train_loss": 3.0512866973876953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17211,
        "tokens": 9023520768,
        "learning_rate": 0.0002818335277948355,
        "gradient_norm": 0.36753764748573303,
        "train_loss": 3.0664114952087402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17212,
        "tokens": 9024045056,
        "learning_rate": 0.00028180534179663683,
        "gradient_norm": 0.3230569660663605,
        "train_loss": 3.08311128616333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17213,
        "tokens": 9024569344,
        "learning_rate": 0.0002817771563409292,
        "gradient_norm": 0.36625078320503235,
        "train_loss": 3.180323600769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17214,
        "tokens": 9025093632,
        "learning_rate": 0.0002817489714280298,
        "gradient_norm": 0.35820895433425903,
        "train_loss": 3.1089491844177246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17215,
        "tokens": 9025617920,
        "learning_rate": 0.0002817207870582558,
        "gradient_norm": 0.3314315974712372,
        "train_loss": 3.072847843170166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17216,
        "tokens": 9026142208,
        "learning_rate": 0.00028169260323192453,
        "gradient_norm": 0.3262566328048706,
        "train_loss": 3.1139214038848877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17217,
        "tokens": 9026666496,
        "learning_rate": 0.00028166441994935333,
        "gradient_norm": 0.3585026264190674,
        "train_loss": 3.062800645828247,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17218,
        "tokens": 9027190784,
        "learning_rate": 0.0002816362372108592,
        "gradient_norm": 0.33424660563468933,
        "train_loss": 3.12123966217041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17219,
        "tokens": 9027715072,
        "learning_rate": 0.0002816080550167596,
        "gradient_norm": 0.33458879590034485,
        "train_loss": 3.108968734741211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17220,
        "tokens": 9028239360,
        "learning_rate": 0.0002815798733673716,
        "gradient_norm": 0.33809658885002136,
        "train_loss": 3.140613555908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17221,
        "tokens": 9028763648,
        "learning_rate": 0.0002815516922630125,
        "gradient_norm": 0.33170944452285767,
        "train_loss": 3.068324327468872,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17222,
        "tokens": 9029287936,
        "learning_rate": 0.0002815235117039995,
        "gradient_norm": 0.3777252733707428,
        "train_loss": 3.1155388355255127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17223,
        "tokens": 9029812224,
        "learning_rate": 0.00028149533169064976,
        "gradient_norm": 0.3363555371761322,
        "train_loss": 3.070307493209839,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17224,
        "tokens": 9030336512,
        "learning_rate": 0.0002814671522232806,
        "gradient_norm": 0.3372214436531067,
        "train_loss": 3.0986266136169434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17225,
        "tokens": 9030860800,
        "learning_rate": 0.0002814389733022091,
        "gradient_norm": 0.35816362500190735,
        "train_loss": 3.0803401470184326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17226,
        "tokens": 9031385088,
        "learning_rate": 0.00028141079492775253,
        "gradient_norm": 0.34913280606269836,
        "train_loss": 3.0878915786743164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17227,
        "tokens": 9031909376,
        "learning_rate": 0.000281382617100228,
        "gradient_norm": 0.4597407877445221,
        "train_loss": 3.1058411598205566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17228,
        "tokens": 9032433664,
        "learning_rate": 0.00028135443981995275,
        "gradient_norm": 0.41395050287246704,
        "train_loss": 3.0960516929626465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17229,
        "tokens": 9032957952,
        "learning_rate": 0.00028132626308724387,
        "gradient_norm": 0.33390867710113525,
        "train_loss": 3.0796432495117188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17230,
        "tokens": 9033482240,
        "learning_rate": 0.00028129808690241856,
        "gradient_norm": 0.37675952911376953,
        "train_loss": 3.050886631011963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17231,
        "tokens": 9034006528,
        "learning_rate": 0.00028126991126579406,
        "gradient_norm": 0.3099467158317566,
        "train_loss": 3.0313315391540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17232,
        "tokens": 9034530816,
        "learning_rate": 0.00028124173617768733,
        "gradient_norm": 0.3101590871810913,
        "train_loss": 3.0536251068115234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17233,
        "tokens": 9035055104,
        "learning_rate": 0.0002812135616384158,
        "gradient_norm": 0.3275439143180847,
        "train_loss": 3.0877418518066406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17234,
        "tokens": 9035579392,
        "learning_rate": 0.00028118538764829626,
        "gradient_norm": 0.31640103459358215,
        "train_loss": 3.0721375942230225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17235,
        "tokens": 9036103680,
        "learning_rate": 0.00028115721420764623,
        "gradient_norm": 0.31439152359962463,
        "train_loss": 3.075749397277832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17236,
        "tokens": 9036627968,
        "learning_rate": 0.0002811290413167825,
        "gradient_norm": 0.294815331697464,
        "train_loss": 3.061641216278076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17237,
        "tokens": 9037152256,
        "learning_rate": 0.00028110086897602243,
        "gradient_norm": 0.32372650504112244,
        "train_loss": 3.1336774826049805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17238,
        "tokens": 9037676544,
        "learning_rate": 0.00028107269718568293,
        "gradient_norm": 0.3036012053489685,
        "train_loss": 3.161120891571045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17239,
        "tokens": 9038200832,
        "learning_rate": 0.0002810445259460813,
        "gradient_norm": 0.3111482858657837,
        "train_loss": 3.078805923461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17240,
        "tokens": 9038725120,
        "learning_rate": 0.00028101635525753447,
        "gradient_norm": 0.3384673297405243,
        "train_loss": 3.082793712615967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17241,
        "tokens": 9039249408,
        "learning_rate": 0.0002809881851203596,
        "gradient_norm": 0.33016568422317505,
        "train_loss": 3.0616369247436523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17242,
        "tokens": 9039773696,
        "learning_rate": 0.00028096001553487397,
        "gradient_norm": 0.31166884303092957,
        "train_loss": 3.081423282623291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17243,
        "tokens": 9040297984,
        "learning_rate": 0.00028093184650139437,
        "gradient_norm": 0.3168680667877197,
        "train_loss": 3.093374729156494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17244,
        "tokens": 9040822272,
        "learning_rate": 0.00028090367802023803,
        "gradient_norm": 0.3362930417060852,
        "train_loss": 3.0748114585876465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17245,
        "tokens": 9041346560,
        "learning_rate": 0.00028087551009172194,
        "gradient_norm": 0.35142451524734497,
        "train_loss": 3.0896363258361816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17246,
        "tokens": 9041870848,
        "learning_rate": 0.00028084734271616337,
        "gradient_norm": 0.3263457417488098,
        "train_loss": 3.1719844341278076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17247,
        "tokens": 9042395136,
        "learning_rate": 0.0002808191758938791,
        "gradient_norm": 0.3561819791793823,
        "train_loss": 3.0903215408325195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17248,
        "tokens": 9042919424,
        "learning_rate": 0.00028079100962518635,
        "gradient_norm": 0.2909240126609802,
        "train_loss": 3.0975852012634277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17249,
        "tokens": 9043443712,
        "learning_rate": 0.00028076284391040206,
        "gradient_norm": 0.34827500581741333,
        "train_loss": 3.0214688777923584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17250,
        "tokens": 9043968000,
        "learning_rate": 0.0002807346787498435,
        "gradient_norm": 0.3160523474216461,
        "train_loss": 3.114102363586426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17251,
        "tokens": 9044492288,
        "learning_rate": 0.00028070651414382737,
        "gradient_norm": 0.30292364954948425,
        "train_loss": 3.09778094291687,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17252,
        "tokens": 9045016576,
        "learning_rate": 0.00028067835009267086,
        "gradient_norm": 0.35177555680274963,
        "train_loss": 3.0599844455718994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17253,
        "tokens": 9045540864,
        "learning_rate": 0.00028065018659669113,
        "gradient_norm": 0.3742545545101166,
        "train_loss": 3.073765516281128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17254,
        "tokens": 9046065152,
        "learning_rate": 0.00028062202365620494,
        "gradient_norm": 0.3196881115436554,
        "train_loss": 3.1210336685180664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17255,
        "tokens": 9046589440,
        "learning_rate": 0.00028059386127152956,
        "gradient_norm": 0.39598459005355835,
        "train_loss": 3.0938501358032227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17256,
        "tokens": 9047113728,
        "learning_rate": 0.00028056569944298176,
        "gradient_norm": 0.33221226930618286,
        "train_loss": 3.081732749938965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17257,
        "tokens": 9047638016,
        "learning_rate": 0.0002805375381708787,
        "gradient_norm": 0.3089693784713745,
        "train_loss": 3.1017332077026367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17258,
        "tokens": 9048162304,
        "learning_rate": 0.0002805093774555372,
        "gradient_norm": 0.3257264494895935,
        "train_loss": 3.0789992809295654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17259,
        "tokens": 9048686592,
        "learning_rate": 0.00028048121729727453,
        "gradient_norm": 0.3015623390674591,
        "train_loss": 3.056870460510254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17260,
        "tokens": 9049210880,
        "learning_rate": 0.0002804530576964073,
        "gradient_norm": 0.33512330055236816,
        "train_loss": 3.0867233276367188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17261,
        "tokens": 9049735168,
        "learning_rate": 0.0002804248986532527,
        "gradient_norm": 0.3127741813659668,
        "train_loss": 3.069089412689209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17262,
        "tokens": 9050259456,
        "learning_rate": 0.0002803967401681278,
        "gradient_norm": 0.3044099807739258,
        "train_loss": 3.056004047393799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17263,
        "tokens": 9050783744,
        "learning_rate": 0.00028036858224134923,
        "gradient_norm": 0.3188914656639099,
        "train_loss": 3.105494499206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17264,
        "tokens": 9051308032,
        "learning_rate": 0.00028034042487323427,
        "gradient_norm": 0.33225497603416443,
        "train_loss": 3.1311473846435547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17265,
        "tokens": 9051832320,
        "learning_rate": 0.0002803122680640997,
        "gradient_norm": 0.32269561290740967,
        "train_loss": 3.1238272190093994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17266,
        "tokens": 9052356608,
        "learning_rate": 0.0002802841118142625,
        "gradient_norm": 0.3404262661933899,
        "train_loss": 3.072953701019287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17267,
        "tokens": 9052880896,
        "learning_rate": 0.00028025595612403957,
        "gradient_norm": 0.3125675618648529,
        "train_loss": 3.090407371520996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17268,
        "tokens": 9053405184,
        "learning_rate": 0.0002802278009937479,
        "gradient_norm": 0.32019445300102234,
        "train_loss": 3.074172019958496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17269,
        "tokens": 9053929472,
        "learning_rate": 0.00028019964642370424,
        "gradient_norm": 0.3462763726711273,
        "train_loss": 3.064601182937622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17270,
        "tokens": 9054453760,
        "learning_rate": 0.0002801714924142259,
        "gradient_norm": 0.31341224908828735,
        "train_loss": 3.0247607231140137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17271,
        "tokens": 9054978048,
        "learning_rate": 0.0002801433389656293,
        "gradient_norm": 0.31900307536125183,
        "train_loss": 3.0296387672424316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17272,
        "tokens": 9055502336,
        "learning_rate": 0.0002801151860782316,
        "gradient_norm": 0.32847827672958374,
        "train_loss": 3.0739541053771973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17273,
        "tokens": 9056026624,
        "learning_rate": 0.0002800870337523497,
        "gradient_norm": 0.3060983419418335,
        "train_loss": 3.054226875305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17274,
        "tokens": 9056550912,
        "learning_rate": 0.00028005888198830045,
        "gradient_norm": 0.32059064507484436,
        "train_loss": 3.105348587036133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17275,
        "tokens": 9057075200,
        "learning_rate": 0.00028003073078640075,
        "gradient_norm": 0.29182639718055725,
        "train_loss": 3.0752711296081543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17276,
        "tokens": 9057599488,
        "learning_rate": 0.0002800025801469675,
        "gradient_norm": 0.3286762535572052,
        "train_loss": 3.0880041122436523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17277,
        "tokens": 9058123776,
        "learning_rate": 0.00027997443007031747,
        "gradient_norm": 0.30971360206604004,
        "train_loss": 3.1125245094299316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17278,
        "tokens": 9058648064,
        "learning_rate": 0.0002799462805567676,
        "gradient_norm": 0.3175589144229889,
        "train_loss": 3.1371660232543945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17279,
        "tokens": 9059172352,
        "learning_rate": 0.00027991813160663476,
        "gradient_norm": 0.2976767420768738,
        "train_loss": 3.1094307899475098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17280,
        "tokens": 9059696640,
        "learning_rate": 0.00027988998322023566,
        "gradient_norm": 0.33488544821739197,
        "train_loss": 3.290830135345459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17281,
        "tokens": 9060220928,
        "learning_rate": 0.0002798618353978874,
        "gradient_norm": 0.35951364040374756,
        "train_loss": 3.1054306030273438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17282,
        "tokens": 9060745216,
        "learning_rate": 0.00027983368813990666,
        "gradient_norm": 0.3414975702762604,
        "train_loss": 3.122957706451416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17283,
        "tokens": 9061269504,
        "learning_rate": 0.00027980554144661025,
        "gradient_norm": 0.4151531159877777,
        "train_loss": 3.081512928009033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17284,
        "tokens": 9061793792,
        "learning_rate": 0.0002797773953183151,
        "gradient_norm": 0.33296114206314087,
        "train_loss": 3.0340075492858887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17285,
        "tokens": 9062318080,
        "learning_rate": 0.00027974924975533787,
        "gradient_norm": 0.35181137919425964,
        "train_loss": 3.0995936393737793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17286,
        "tokens": 9062842368,
        "learning_rate": 0.0002797211047579956,
        "gradient_norm": 0.34246131777763367,
        "train_loss": 3.0951290130615234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17287,
        "tokens": 9063366656,
        "learning_rate": 0.0002796929603266048,
        "gradient_norm": 0.34169358015060425,
        "train_loss": 3.062587261199951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17288,
        "tokens": 9063890944,
        "learning_rate": 0.0002796648164614826,
        "gradient_norm": 0.3708115220069885,
        "train_loss": 3.0536692142486572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17289,
        "tokens": 9064415232,
        "learning_rate": 0.00027963667316294557,
        "gradient_norm": 0.3100944459438324,
        "train_loss": 3.036557197570801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17290,
        "tokens": 9064939520,
        "learning_rate": 0.0002796085304313106,
        "gradient_norm": 0.3257445693016052,
        "train_loss": 3.120662212371826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17291,
        "tokens": 9065463808,
        "learning_rate": 0.0002795803882668944,
        "gradient_norm": 0.34085801243782043,
        "train_loss": 3.0723490715026855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17292,
        "tokens": 9065988096,
        "learning_rate": 0.0002795522466700137,
        "gradient_norm": 0.32304567098617554,
        "train_loss": 3.0505285263061523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17293,
        "tokens": 9066512384,
        "learning_rate": 0.0002795241056409855,
        "gradient_norm": 0.3376845121383667,
        "train_loss": 3.0889322757720947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17294,
        "tokens": 9067036672,
        "learning_rate": 0.00027949596518012635,
        "gradient_norm": 0.352438360452652,
        "train_loss": 3.057884931564331,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17295,
        "tokens": 9067560960,
        "learning_rate": 0.0002794678252877531,
        "gradient_norm": 0.3750024139881134,
        "train_loss": 3.1030731201171875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17296,
        "tokens": 9068085248,
        "learning_rate": 0.0002794396859641824,
        "gradient_norm": 0.30306509137153625,
        "train_loss": 3.060661792755127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17297,
        "tokens": 9068609536,
        "learning_rate": 0.0002794115472097311,
        "gradient_norm": 0.4066849946975708,
        "train_loss": 3.1971800327301025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17298,
        "tokens": 9069133824,
        "learning_rate": 0.00027938340902471586,
        "gradient_norm": 0.36774757504463196,
        "train_loss": 3.053906202316284,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17299,
        "tokens": 9069658112,
        "learning_rate": 0.0002793552714094535,
        "gradient_norm": 0.3573642671108246,
        "train_loss": 3.0742886066436768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17300,
        "tokens": 9070182400,
        "learning_rate": 0.00027932713436426066,
        "gradient_norm": 0.4253910481929779,
        "train_loss": 3.129091262817383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17301,
        "tokens": 9070706688,
        "learning_rate": 0.000279298997889454,
        "gradient_norm": 0.3186243176460266,
        "train_loss": 3.095050573348999,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17302,
        "tokens": 9071230976,
        "learning_rate": 0.0002792708619853505,
        "gradient_norm": 0.4078443944454193,
        "train_loss": 3.1003880500793457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17303,
        "tokens": 9071755264,
        "learning_rate": 0.00027924272665226654,
        "gradient_norm": 0.33700016140937805,
        "train_loss": 3.0597023963928223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17304,
        "tokens": 9072279552,
        "learning_rate": 0.0002792145918905191,
        "gradient_norm": 0.425066202878952,
        "train_loss": 3.1410651206970215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17305,
        "tokens": 9072803840,
        "learning_rate": 0.0002791864577004246,
        "gradient_norm": 0.3209054470062256,
        "train_loss": 3.0342466831207275,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17306,
        "tokens": 9073328128,
        "learning_rate": 0.00027915832408229995,
        "gradient_norm": 0.3733927607536316,
        "train_loss": 3.136559009552002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17307,
        "tokens": 9073852416,
        "learning_rate": 0.00027913019103646165,
        "gradient_norm": 0.3169073760509491,
        "train_loss": 3.1058645248413086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17308,
        "tokens": 9074376704,
        "learning_rate": 0.0002791020585632266,
        "gradient_norm": 0.38661983609199524,
        "train_loss": 3.067141532897949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17309,
        "tokens": 9074900992,
        "learning_rate": 0.00027907392666291113,
        "gradient_norm": 0.34078752994537354,
        "train_loss": 3.0844945907592773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17310,
        "tokens": 9075425280,
        "learning_rate": 0.0002790457953358323,
        "gradient_norm": 0.345479279756546,
        "train_loss": 3.084479331970215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17311,
        "tokens": 9075949568,
        "learning_rate": 0.0002790176645823064,
        "gradient_norm": 0.31776145100593567,
        "train_loss": 3.044344902038574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17312,
        "tokens": 9076473856,
        "learning_rate": 0.0002789895344026503,
        "gradient_norm": 0.3762049674987793,
        "train_loss": 3.036558151245117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17313,
        "tokens": 9076998144,
        "learning_rate": 0.00027896140479718057,
        "gradient_norm": 0.351641446352005,
        "train_loss": 3.154404640197754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17314,
        "tokens": 9077522432,
        "learning_rate": 0.0002789332757662138,
        "gradient_norm": 0.34844544529914856,
        "train_loss": 3.062710762023926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17315,
        "tokens": 9078046720,
        "learning_rate": 0.0002789051473100668,
        "gradient_norm": 0.32089728116989136,
        "train_loss": 3.028506278991699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17316,
        "tokens": 9078571008,
        "learning_rate": 0.00027887701942905593,
        "gradient_norm": 0.3244682550430298,
        "train_loss": 3.030940055847168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17317,
        "tokens": 9079095296,
        "learning_rate": 0.00027884889212349807,
        "gradient_norm": 0.3595001697540283,
        "train_loss": 3.0814921855926514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17318,
        "tokens": 9079619584,
        "learning_rate": 0.0002788207653937095,
        "gradient_norm": 0.38207700848579407,
        "train_loss": 3.125580310821533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17319,
        "tokens": 9080143872,
        "learning_rate": 0.0002787926392400072,
        "gradient_norm": 0.32993021607398987,
        "train_loss": 3.107156276702881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17320,
        "tokens": 9080668160,
        "learning_rate": 0.00027876451366270745,
        "gradient_norm": 0.35571110248565674,
        "train_loss": 3.161499500274658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17321,
        "tokens": 9081192448,
        "learning_rate": 0.00027873638866212703,
        "gradient_norm": 0.31888455152511597,
        "train_loss": 3.092264175415039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17322,
        "tokens": 9081716736,
        "learning_rate": 0.0002787082642385824,
        "gradient_norm": 0.34430110454559326,
        "train_loss": 3.078068971633911,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17323,
        "tokens": 9082241024,
        "learning_rate": 0.0002786801403923902,
        "gradient_norm": 0.2987874746322632,
        "train_loss": 3.1254191398620605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17324,
        "tokens": 9082765312,
        "learning_rate": 0.0002786520171238671,
        "gradient_norm": 0.33458346128463745,
        "train_loss": 3.026886463165283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17325,
        "tokens": 9083289600,
        "learning_rate": 0.0002786238944333294,
        "gradient_norm": 0.3038078546524048,
        "train_loss": 3.0710020065307617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17326,
        "tokens": 9083813888,
        "learning_rate": 0.000278595772321094,
        "gradient_norm": 0.3235127925872803,
        "train_loss": 3.0497069358825684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17327,
        "tokens": 9084338176,
        "learning_rate": 0.00027856765078747704,
        "gradient_norm": 0.3416953384876251,
        "train_loss": 3.1251134872436523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17328,
        "tokens": 9084862464,
        "learning_rate": 0.0002785395298327955,
        "gradient_norm": 0.2920648753643036,
        "train_loss": 3.0451109409332275,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17329,
        "tokens": 9085386752,
        "learning_rate": 0.00027851140945736553,
        "gradient_norm": 0.34829476475715637,
        "train_loss": 3.1022355556488037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17330,
        "tokens": 9085911040,
        "learning_rate": 0.0002784832896615039,
        "gradient_norm": 0.31206464767456055,
        "train_loss": 3.1411657333374023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17331,
        "tokens": 9086435328,
        "learning_rate": 0.00027845517044552704,
        "gradient_norm": 0.3337237536907196,
        "train_loss": 3.0620408058166504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17332,
        "tokens": 9086959616,
        "learning_rate": 0.0002784270518097515,
        "gradient_norm": 0.31796857714653015,
        "train_loss": 3.067324638366699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17333,
        "tokens": 9087483904,
        "learning_rate": 0.00027839893375449377,
        "gradient_norm": 0.35773342847824097,
        "train_loss": 3.1187498569488525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17334,
        "tokens": 9088008192,
        "learning_rate": 0.00027837081628007034,
        "gradient_norm": 0.3431536853313446,
        "train_loss": 3.026059150695801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17335,
        "tokens": 9088532480,
        "learning_rate": 0.0002783426993867978,
        "gradient_norm": 0.3207029402256012,
        "train_loss": 3.058675765991211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17336,
        "tokens": 9089056768,
        "learning_rate": 0.00027831458307499247,
        "gradient_norm": 0.3662060499191284,
        "train_loss": 3.1342530250549316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17337,
        "tokens": 9089581056,
        "learning_rate": 0.0002782864673449711,
        "gradient_norm": 0.3556489050388336,
        "train_loss": 3.057030439376831,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17338,
        "tokens": 9090105344,
        "learning_rate": 0.0002782583521970499,
        "gradient_norm": 0.32381516695022583,
        "train_loss": 3.086824893951416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17339,
        "tokens": 9090629632,
        "learning_rate": 0.0002782302376315454,
        "gradient_norm": 0.4163721799850464,
        "train_loss": 3.050467014312744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17340,
        "tokens": 9091153920,
        "learning_rate": 0.0002782021236487741,
        "gradient_norm": 0.3080970048904419,
        "train_loss": 3.104228973388672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17341,
        "tokens": 9091678208,
        "learning_rate": 0.00027817401024905254,
        "gradient_norm": 0.40013137459754944,
        "train_loss": 3.1026127338409424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17342,
        "tokens": 9092202496,
        "learning_rate": 0.0002781458974326971,
        "gradient_norm": 0.3224807381629944,
        "train_loss": 3.0703208446502686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17343,
        "tokens": 9092726784,
        "learning_rate": 0.0002781177852000242,
        "gradient_norm": 0.37339499592781067,
        "train_loss": 3.1208038330078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17344,
        "tokens": 9093251072,
        "learning_rate": 0.00027808967355135036,
        "gradient_norm": 0.3765017092227936,
        "train_loss": 3.103480339050293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17345,
        "tokens": 9093775360,
        "learning_rate": 0.0002780615624869918,
        "gradient_norm": 0.3199833035469055,
        "train_loss": 3.0289218425750732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17346,
        "tokens": 9094299648,
        "learning_rate": 0.0002780334520072653,
        "gradient_norm": 0.4119984805583954,
        "train_loss": 3.0589380264282227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17347,
        "tokens": 9094823936,
        "learning_rate": 0.0002780053421124869,
        "gradient_norm": 0.40667250752449036,
        "train_loss": 3.174064874649048,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17348,
        "tokens": 9095348224,
        "learning_rate": 0.00027797723280297324,
        "gradient_norm": 0.41794130206108093,
        "train_loss": 3.098378896713257,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17349,
        "tokens": 9095872512,
        "learning_rate": 0.00027794912407904065,
        "gradient_norm": 0.3375537097454071,
        "train_loss": 3.0496134757995605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17350,
        "tokens": 9096396800,
        "learning_rate": 0.00027792101594100566,
        "gradient_norm": 0.3624962568283081,
        "train_loss": 3.1151621341705322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17351,
        "tokens": 9096921088,
        "learning_rate": 0.00027789290838918436,
        "gradient_norm": 0.3645249307155609,
        "train_loss": 3.111175060272217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17352,
        "tokens": 9097445376,
        "learning_rate": 0.0002778648014238934,
        "gradient_norm": 0.35784193873405457,
        "train_loss": 3.040181875228882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17353,
        "tokens": 9097969664,
        "learning_rate": 0.0002778366950454492,
        "gradient_norm": 0.3570430278778076,
        "train_loss": 3.0794677734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17354,
        "tokens": 9098493952,
        "learning_rate": 0.00027780858925416797,
        "gradient_norm": 0.34794676303863525,
        "train_loss": 3.0518155097961426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17355,
        "tokens": 9099018240,
        "learning_rate": 0.00027778048405036613,
        "gradient_norm": 0.34392231702804565,
        "train_loss": 3.101219892501831,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17356,
        "tokens": 9099542528,
        "learning_rate": 0.00027775237943436,
        "gradient_norm": 0.4078715741634369,
        "train_loss": 3.1044492721557617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17357,
        "tokens": 9100066816,
        "learning_rate": 0.000277724275406466,
        "gradient_norm": 0.3838953673839569,
        "train_loss": 3.124206304550171,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17358,
        "tokens": 9100591104,
        "learning_rate": 0.0002776961719670004,
        "gradient_norm": 0.35058555006980896,
        "train_loss": 3.0635290145874023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17359,
        "tokens": 9101115392,
        "learning_rate": 0.00027766806911627966,
        "gradient_norm": 0.41518092155456543,
        "train_loss": 3.1025283336639404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17360,
        "tokens": 9101639680,
        "learning_rate": 0.0002776399668546199,
        "gradient_norm": 0.31508156657218933,
        "train_loss": 3.05123233795166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17361,
        "tokens": 9102163968,
        "learning_rate": 0.00027761186518233765,
        "gradient_norm": 0.32428228855133057,
        "train_loss": 3.082897186279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17362,
        "tokens": 9102688256,
        "learning_rate": 0.00027758376409974927,
        "gradient_norm": 0.3789202570915222,
        "train_loss": 3.1082184314727783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17363,
        "tokens": 9103212544,
        "learning_rate": 0.0002775556636071708,
        "gradient_norm": 0.32622694969177246,
        "train_loss": 3.0625362396240234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17364,
        "tokens": 9103736832,
        "learning_rate": 0.00027752756370491886,
        "gradient_norm": 0.3586577773094177,
        "train_loss": 3.1592204570770264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17365,
        "tokens": 9104261120,
        "learning_rate": 0.00027749946439330946,
        "gradient_norm": 0.330929160118103,
        "train_loss": 3.0225021839141846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17366,
        "tokens": 9104785408,
        "learning_rate": 0.00027747136567265915,
        "gradient_norm": 0.32510364055633545,
        "train_loss": 3.093790054321289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17367,
        "tokens": 9105309696,
        "learning_rate": 0.000277443267543284,
        "gradient_norm": 0.28836941719055176,
        "train_loss": 3.024998426437378,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17368,
        "tokens": 9105833984,
        "learning_rate": 0.0002774151700055005,
        "gradient_norm": 0.32743552327156067,
        "train_loss": 3.0842366218566895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17369,
        "tokens": 9106358272,
        "learning_rate": 0.0002773870730596247,
        "gradient_norm": 0.28743720054626465,
        "train_loss": 3.071798324584961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17370,
        "tokens": 9106882560,
        "learning_rate": 0.00027735897670597305,
        "gradient_norm": 0.3295760154724121,
        "train_loss": 3.091887950897217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17371,
        "tokens": 9107406848,
        "learning_rate": 0.00027733088094486166,
        "gradient_norm": 0.3069941997528076,
        "train_loss": 3.0737264156341553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17372,
        "tokens": 9107931136,
        "learning_rate": 0.0002773027857766068,
        "gradient_norm": 0.3477143347263336,
        "train_loss": 3.090580463409424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17373,
        "tokens": 9108455424,
        "learning_rate": 0.00027727469120152493,
        "gradient_norm": 0.3313530385494232,
        "train_loss": 3.042584180831909,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17374,
        "tokens": 9108979712,
        "learning_rate": 0.00027724659721993207,
        "gradient_norm": 0.3312361538410187,
        "train_loss": 3.0424647331237793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17375,
        "tokens": 9109504000,
        "learning_rate": 0.0002772185038321446,
        "gradient_norm": 0.32964009046554565,
        "train_loss": 3.0864546298980713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17376,
        "tokens": 9110028288,
        "learning_rate": 0.0002771904110384785,
        "gradient_norm": 0.30423158407211304,
        "train_loss": 3.1254870891571045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17377,
        "tokens": 9110552576,
        "learning_rate": 0.0002771623188392503,
        "gradient_norm": 0.39142662286758423,
        "train_loss": 3.107844591140747,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17378,
        "tokens": 9111076864,
        "learning_rate": 0.000277134227234776,
        "gradient_norm": 0.28096243739128113,
        "train_loss": 3.035738229751587,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17379,
        "tokens": 9111601152,
        "learning_rate": 0.0002771061362253719,
        "gradient_norm": 0.34735623002052307,
        "train_loss": 3.0750558376312256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17380,
        "tokens": 9112125440,
        "learning_rate": 0.0002770780458113541,
        "gradient_norm": 0.3132215738296509,
        "train_loss": 3.143460512161255,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17381,
        "tokens": 9112649728,
        "learning_rate": 0.00027704995599303893,
        "gradient_norm": 0.3186778128147125,
        "train_loss": 3.078993320465088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17382,
        "tokens": 9113174016,
        "learning_rate": 0.0002770218667707425,
        "gradient_norm": 0.3292187750339508,
        "train_loss": 3.062159776687622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17383,
        "tokens": 9113698304,
        "learning_rate": 0.000276993778144781,
        "gradient_norm": 0.3195815980434418,
        "train_loss": 3.081202268600464,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17384,
        "tokens": 9114222592,
        "learning_rate": 0.0002769656901154706,
        "gradient_norm": 0.3557187616825104,
        "train_loss": 3.074993848800659,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17385,
        "tokens": 9114746880,
        "learning_rate": 0.00027693760268312747,
        "gradient_norm": 0.30720940232276917,
        "train_loss": 3.103426218032837,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17386,
        "tokens": 9115271168,
        "learning_rate": 0.0002769095158480677,
        "gradient_norm": 0.39441388845443726,
        "train_loss": 3.0601437091827393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17387,
        "tokens": 9115795456,
        "learning_rate": 0.0002768814296106076,
        "gradient_norm": 0.3690473437309265,
        "train_loss": 3.136202096939087,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17388,
        "tokens": 9116319744,
        "learning_rate": 0.0002768533439710632,
        "gradient_norm": 0.327456533908844,
        "train_loss": 3.095301628112793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17389,
        "tokens": 9116844032,
        "learning_rate": 0.00027682525892975065,
        "gradient_norm": 0.4327039420604706,
        "train_loss": 3.1205408573150635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17390,
        "tokens": 9117368320,
        "learning_rate": 0.00027679717448698607,
        "gradient_norm": 0.31265172362327576,
        "train_loss": 3.11873197555542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17391,
        "tokens": 9117892608,
        "learning_rate": 0.00027676909064308565,
        "gradient_norm": 0.44253721833229065,
        "train_loss": 3.0719025135040283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17392,
        "tokens": 9118416896,
        "learning_rate": 0.0002767410073983654,
        "gradient_norm": 0.40418192744255066,
        "train_loss": 3.1070632934570312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17393,
        "tokens": 9118941184,
        "learning_rate": 0.0002767129247531416,
        "gradient_norm": 0.39169567823410034,
        "train_loss": 3.066318988800049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17394,
        "tokens": 9119465472,
        "learning_rate": 0.00027668484270773017,
        "gradient_norm": 0.3358966112136841,
        "train_loss": 3.1436705589294434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17395,
        "tokens": 9119989760,
        "learning_rate": 0.0002766567612624474,
        "gradient_norm": 0.3503003716468811,
        "train_loss": 3.0893001556396484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17396,
        "tokens": 9120514048,
        "learning_rate": 0.0002766286804176092,
        "gradient_norm": 0.3455455005168915,
        "train_loss": 3.0957541465759277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17397,
        "tokens": 9121038336,
        "learning_rate": 0.00027660060017353175,
        "gradient_norm": 0.3739255368709564,
        "train_loss": 3.1245694160461426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17398,
        "tokens": 9121562624,
        "learning_rate": 0.0002765725205305311,
        "gradient_norm": 0.370313823223114,
        "train_loss": 3.108330726623535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17399,
        "tokens": 9122086912,
        "learning_rate": 0.00027654444148892337,
        "gradient_norm": 0.3256852626800537,
        "train_loss": 3.010892868041992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17400,
        "tokens": 9122611200,
        "learning_rate": 0.00027651636304902447,
        "gradient_norm": 0.3419048488140106,
        "train_loss": 3.139739513397217,
        "val_loss": 3.0499701499938965,
        "hellaswag_acc": 0.2808205485343933,
        "hellaswag_acc_norm": 0.2936666011810303
    },
    {
        "step": 17401,
        "tokens": 9123135488,
        "learning_rate": 0.00027648828521115057,
        "gradient_norm": 0.2918992042541504,
        "train_loss": 3.0687718391418457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17402,
        "tokens": 9123659776,
        "learning_rate": 0.0002764602079756179,
        "gradient_norm": 0.3666897416114807,
        "train_loss": 3.0477797985076904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17403,
        "tokens": 9124184064,
        "learning_rate": 0.0002764321313427422,
        "gradient_norm": 0.307674765586853,
        "train_loss": 3.0623245239257812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17404,
        "tokens": 9124708352,
        "learning_rate": 0.0002764040553128397,
        "gradient_norm": 0.37867072224617004,
        "train_loss": 3.072018623352051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17405,
        "tokens": 9125232640,
        "learning_rate": 0.0002763759798862263,
        "gradient_norm": 0.3555293679237366,
        "train_loss": 3.0684423446655273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17406,
        "tokens": 9125756928,
        "learning_rate": 0.0002763479050632182,
        "gradient_norm": 0.3269670009613037,
        "train_loss": 3.0938751697540283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17407,
        "tokens": 9126281216,
        "learning_rate": 0.00027631983084413115,
        "gradient_norm": 0.3064958453178406,
        "train_loss": 3.080798625946045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17408,
        "tokens": 9126805504,
        "learning_rate": 0.00027629175722928146,
        "gradient_norm": 0.3178832232952118,
        "train_loss": 3.015030860900879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17409,
        "tokens": 9127329792,
        "learning_rate": 0.00027626368421898486,
        "gradient_norm": 0.2871592938899994,
        "train_loss": 3.0307180881500244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17410,
        "tokens": 9127854080,
        "learning_rate": 0.0002762356118135576,
        "gradient_norm": 0.3269289433956146,
        "train_loss": 3.0681612491607666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17411,
        "tokens": 9128378368,
        "learning_rate": 0.0002762075400133155,
        "gradient_norm": 0.31063246726989746,
        "train_loss": 3.1007485389709473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17412,
        "tokens": 9128902656,
        "learning_rate": 0.00027617946881857455,
        "gradient_norm": 0.33277782797813416,
        "train_loss": 3.106260299682617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17413,
        "tokens": 9129426944,
        "learning_rate": 0.00027615139822965084,
        "gradient_norm": 0.3161453604698181,
        "train_loss": 3.0828514099121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17414,
        "tokens": 9129951232,
        "learning_rate": 0.0002761233282468602,
        "gradient_norm": 0.3310461640357971,
        "train_loss": 3.030266761779785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17415,
        "tokens": 9130475520,
        "learning_rate": 0.00027609525887051874,
        "gradient_norm": 0.31181272864341736,
        "train_loss": 3.0926671028137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17416,
        "tokens": 9130999808,
        "learning_rate": 0.0002760671901009422,
        "gradient_norm": 0.36571022868156433,
        "train_loss": 3.1065807342529297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17417,
        "tokens": 9131524096,
        "learning_rate": 0.0002760391219384468,
        "gradient_norm": 0.3251595199108124,
        "train_loss": 3.1698615550994873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17418,
        "tokens": 9132048384,
        "learning_rate": 0.00027601105438334825,
        "gradient_norm": 0.42326855659484863,
        "train_loss": 3.1018967628479004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17419,
        "tokens": 9132572672,
        "learning_rate": 0.0002759829874359627,
        "gradient_norm": 0.33552810549736023,
        "train_loss": 3.0821988582611084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17420,
        "tokens": 9133096960,
        "learning_rate": 0.00027595492109660586,
        "gradient_norm": 0.3653973340988159,
        "train_loss": 3.052175998687744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17421,
        "tokens": 9133621248,
        "learning_rate": 0.0002759268553655937,
        "gradient_norm": 0.326077938079834,
        "train_loss": 3.1184566020965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17422,
        "tokens": 9134145536,
        "learning_rate": 0.0002758987902432424,
        "gradient_norm": 0.3508872985839844,
        "train_loss": 3.0970969200134277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17423,
        "tokens": 9134669824,
        "learning_rate": 0.0002758707257298674,
        "gradient_norm": 0.3334532082080841,
        "train_loss": 3.078192710876465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17424,
        "tokens": 9135194112,
        "learning_rate": 0.0002758426618257851,
        "gradient_norm": 0.33901843428611755,
        "train_loss": 3.117434501647949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17425,
        "tokens": 9135718400,
        "learning_rate": 0.000275814598531311,
        "gradient_norm": 0.34334760904312134,
        "train_loss": 3.0349931716918945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17426,
        "tokens": 9136242688,
        "learning_rate": 0.00027578653584676115,
        "gradient_norm": 0.3173961043357849,
        "train_loss": 3.073301076889038,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17427,
        "tokens": 9136766976,
        "learning_rate": 0.0002757584737724514,
        "gradient_norm": 0.34609732031822205,
        "train_loss": 3.1266891956329346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17428,
        "tokens": 9137291264,
        "learning_rate": 0.0002757304123086978,
        "gradient_norm": 0.32877641916275024,
        "train_loss": 3.107947587966919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17429,
        "tokens": 9137815552,
        "learning_rate": 0.00027570235145581585,
        "gradient_norm": 0.39596816897392273,
        "train_loss": 3.0455617904663086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17430,
        "tokens": 9138339840,
        "learning_rate": 0.0002756742912141218,
        "gradient_norm": 0.38188084959983826,
        "train_loss": 3.1158716678619385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17431,
        "tokens": 9138864128,
        "learning_rate": 0.0002756462315839311,
        "gradient_norm": 0.34935808181762695,
        "train_loss": 3.122072696685791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17432,
        "tokens": 9139388416,
        "learning_rate": 0.00027561817256556,
        "gradient_norm": 0.3680708408355713,
        "train_loss": 3.271758794784546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17433,
        "tokens": 9139912704,
        "learning_rate": 0.00027559011415932407,
        "gradient_norm": 0.3929155170917511,
        "train_loss": 3.1372926235198975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17434,
        "tokens": 9140436992,
        "learning_rate": 0.0002755620563655393,
        "gradient_norm": 0.3334084451198578,
        "train_loss": 3.0569374561309814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17435,
        "tokens": 9140961280,
        "learning_rate": 0.00027553399918452137,
        "gradient_norm": 0.3538331389427185,
        "train_loss": 2.991781234741211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17436,
        "tokens": 9141485568,
        "learning_rate": 0.00027550594261658624,
        "gradient_norm": 0.3559303283691406,
        "train_loss": 3.0326411724090576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17437,
        "tokens": 9142009856,
        "learning_rate": 0.0002754778866620496,
        "gradient_norm": 0.34342631697654724,
        "train_loss": 3.0287528038024902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17438,
        "tokens": 9142534144,
        "learning_rate": 0.00027544983132122734,
        "gradient_norm": 0.3608504831790924,
        "train_loss": 3.032914161682129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17439,
        "tokens": 9143058432,
        "learning_rate": 0.0002754217765944352,
        "gradient_norm": 0.31794285774230957,
        "train_loss": 3.125194549560547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17440,
        "tokens": 9143582720,
        "learning_rate": 0.00027539372248198903,
        "gradient_norm": 0.39200007915496826,
        "train_loss": 3.0843498706817627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17441,
        "tokens": 9144107008,
        "learning_rate": 0.0002753656689842045,
        "gradient_norm": 0.3198357820510864,
        "train_loss": 3.120840072631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17442,
        "tokens": 9144631296,
        "learning_rate": 0.0002753376161013976,
        "gradient_norm": 0.34714728593826294,
        "train_loss": 3.119112491607666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17443,
        "tokens": 9145155584,
        "learning_rate": 0.0002753095638338839,
        "gradient_norm": 0.31307345628738403,
        "train_loss": 3.1123054027557373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17444,
        "tokens": 9145679872,
        "learning_rate": 0.0002752815121819793,
        "gradient_norm": 0.31222793459892273,
        "train_loss": 3.1344594955444336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17445,
        "tokens": 9146204160,
        "learning_rate": 0.00027525346114599936,
        "gradient_norm": 0.3177550733089447,
        "train_loss": 3.0697145462036133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17446,
        "tokens": 9146728448,
        "learning_rate": 0.00027522541072626006,
        "gradient_norm": 0.29280081391334534,
        "train_loss": 3.083462715148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17447,
        "tokens": 9147252736,
        "learning_rate": 0.00027519736092307694,
        "gradient_norm": 0.28726428747177124,
        "train_loss": 3.075265645980835,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17448,
        "tokens": 9147777024,
        "learning_rate": 0.000275169311736766,
        "gradient_norm": 0.32874009013175964,
        "train_loss": 3.07682466506958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17449,
        "tokens": 9148301312,
        "learning_rate": 0.00027514126316764264,
        "gradient_norm": 0.32334548234939575,
        "train_loss": 3.0720648765563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17450,
        "tokens": 9148825600,
        "learning_rate": 0.00027511321521602285,
        "gradient_norm": 0.30639591813087463,
        "train_loss": 3.0651440620422363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17451,
        "tokens": 9149349888,
        "learning_rate": 0.0002750851678822221,
        "gradient_norm": 0.3297412693500519,
        "train_loss": 3.09171199798584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17452,
        "tokens": 9149874176,
        "learning_rate": 0.00027505712116655633,
        "gradient_norm": 0.29781338572502136,
        "train_loss": 3.0871989727020264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17453,
        "tokens": 9150398464,
        "learning_rate": 0.00027502907506934125,
        "gradient_norm": 0.3315318524837494,
        "train_loss": 3.127161979675293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17454,
        "tokens": 9150922752,
        "learning_rate": 0.0002750010295908923,
        "gradient_norm": 0.29803481698036194,
        "train_loss": 3.0340280532836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17455,
        "tokens": 9151447040,
        "learning_rate": 0.00027497298473152544,
        "gradient_norm": 0.31219446659088135,
        "train_loss": 3.0818347930908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17456,
        "tokens": 9151971328,
        "learning_rate": 0.0002749449404915561,
        "gradient_norm": 0.33954328298568726,
        "train_loss": 3.1189565658569336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17457,
        "tokens": 9152495616,
        "learning_rate": 0.00027491689687130026,
        "gradient_norm": 0.30945634841918945,
        "train_loss": 3.073303461074829,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17458,
        "tokens": 9153019904,
        "learning_rate": 0.00027488885387107323,
        "gradient_norm": 0.3126148581504822,
        "train_loss": 3.0775508880615234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17459,
        "tokens": 9153544192,
        "learning_rate": 0.000274860811491191,
        "gradient_norm": 0.3279929459095001,
        "train_loss": 3.111006021499634,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17460,
        "tokens": 9154068480,
        "learning_rate": 0.00027483276973196895,
        "gradient_norm": 0.3186212182044983,
        "train_loss": 3.065711498260498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17461,
        "tokens": 9154592768,
        "learning_rate": 0.0002748047285937228,
        "gradient_norm": 0.35385268926620483,
        "train_loss": 3.036625862121582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17462,
        "tokens": 9155117056,
        "learning_rate": 0.00027477668807676843,
        "gradient_norm": 0.396518737077713,
        "train_loss": 3.0981106758117676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17463,
        "tokens": 9155641344,
        "learning_rate": 0.0002747486481814211,
        "gradient_norm": 0.3283722698688507,
        "train_loss": 3.0441536903381348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17464,
        "tokens": 9156165632,
        "learning_rate": 0.0002747206089079967,
        "gradient_norm": 0.3996351659297943,
        "train_loss": 3.0770788192749023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17465,
        "tokens": 9156689920,
        "learning_rate": 0.0002746925702568107,
        "gradient_norm": 0.33560287952423096,
        "train_loss": 3.161442279815674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17466,
        "tokens": 9157214208,
        "learning_rate": 0.00027466453222817883,
        "gradient_norm": 0.3336930274963379,
        "train_loss": 3.09494686126709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17467,
        "tokens": 9157738496,
        "learning_rate": 0.0002746364948224165,
        "gradient_norm": 0.32064875960350037,
        "train_loss": 3.1073527336120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17468,
        "tokens": 9158262784,
        "learning_rate": 0.0002746084580398396,
        "gradient_norm": 0.3457365930080414,
        "train_loss": 3.0959365367889404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17469,
        "tokens": 9158787072,
        "learning_rate": 0.00027458042188076336,
        "gradient_norm": 0.32637766003608704,
        "train_loss": 3.0710620880126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17470,
        "tokens": 9159311360,
        "learning_rate": 0.0002745523863455038,
        "gradient_norm": 0.31625184416770935,
        "train_loss": 3.12976336479187,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17471,
        "tokens": 9159835648,
        "learning_rate": 0.000274524351434376,
        "gradient_norm": 0.3276086747646332,
        "train_loss": 3.064187526702881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17472,
        "tokens": 9160359936,
        "learning_rate": 0.00027449631714769585,
        "gradient_norm": 0.29631373286247253,
        "train_loss": 3.090503692626953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17473,
        "tokens": 9160884224,
        "learning_rate": 0.00027446828348577895,
        "gradient_norm": 0.32598990201950073,
        "train_loss": 3.090364456176758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17474,
        "tokens": 9161408512,
        "learning_rate": 0.0002744402504489406,
        "gradient_norm": 0.30536603927612305,
        "train_loss": 3.087796449661255,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17475,
        "tokens": 9161932800,
        "learning_rate": 0.0002744122180374966,
        "gradient_norm": 0.40283116698265076,
        "train_loss": 3.1168270111083984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17476,
        "tokens": 9162457088,
        "learning_rate": 0.00027438418625176235,
        "gradient_norm": 0.44946879148483276,
        "train_loss": 3.088998794555664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17477,
        "tokens": 9162981376,
        "learning_rate": 0.00027435615509205347,
        "gradient_norm": 0.31958645582199097,
        "train_loss": 3.0152878761291504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17478,
        "tokens": 9163505664,
        "learning_rate": 0.00027432812455868526,
        "gradient_norm": 0.5100035071372986,
        "train_loss": 3.0748515129089355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17479,
        "tokens": 9164029952,
        "learning_rate": 0.00027430009465197354,
        "gradient_norm": 0.32638657093048096,
        "train_loss": 3.0999863147735596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17480,
        "tokens": 9164554240,
        "learning_rate": 0.00027427206537223366,
        "gradient_norm": 0.4642833173274994,
        "train_loss": 3.0849199295043945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17481,
        "tokens": 9165078528,
        "learning_rate": 0.00027424403671978106,
        "gradient_norm": 0.3740190267562866,
        "train_loss": 3.053161144256592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17482,
        "tokens": 9165602816,
        "learning_rate": 0.00027421600869493147,
        "gradient_norm": 0.3720830976963043,
        "train_loss": 3.0457236766815186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17483,
        "tokens": 9166127104,
        "learning_rate": 0.00027418798129800017,
        "gradient_norm": 0.34740620851516724,
        "train_loss": 3.056607484817505,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17484,
        "tokens": 9166651392,
        "learning_rate": 0.0002741599545293027,
        "gradient_norm": 0.34837889671325684,
        "train_loss": 3.118169069290161,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17485,
        "tokens": 9167175680,
        "learning_rate": 0.00027413192838915456,
        "gradient_norm": 0.36721327900886536,
        "train_loss": 3.0441551208496094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17486,
        "tokens": 9167699968,
        "learning_rate": 0.0002741039028778712,
        "gradient_norm": 0.3195469379425049,
        "train_loss": 3.091275215148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17487,
        "tokens": 9168224256,
        "learning_rate": 0.00027407587799576814,
        "gradient_norm": 0.3680901825428009,
        "train_loss": 3.0761094093322754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17488,
        "tokens": 9168748544,
        "learning_rate": 0.0002740478537431607,
        "gradient_norm": 0.337268203496933,
        "train_loss": 3.099517583847046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17489,
        "tokens": 9169272832,
        "learning_rate": 0.0002740198301203645,
        "gradient_norm": 0.34027615189552307,
        "train_loss": 3.104261875152588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17490,
        "tokens": 9169797120,
        "learning_rate": 0.0002739918071276948,
        "gradient_norm": 0.3302149772644043,
        "train_loss": 3.041839599609375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17491,
        "tokens": 9170321408,
        "learning_rate": 0.0002739637847654672,
        "gradient_norm": 0.3177059590816498,
        "train_loss": 3.080749988555908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17492,
        "tokens": 9170845696,
        "learning_rate": 0.000273935763033997,
        "gradient_norm": 0.3402157127857208,
        "train_loss": 3.0692968368530273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17493,
        "tokens": 9171369984,
        "learning_rate": 0.0002739077419335997,
        "gradient_norm": 0.3056985139846802,
        "train_loss": 3.0756759643554688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17494,
        "tokens": 9171894272,
        "learning_rate": 0.00027387972146459064,
        "gradient_norm": 0.3482201397418976,
        "train_loss": 3.123683452606201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17495,
        "tokens": 9172418560,
        "learning_rate": 0.00027385170162728544,
        "gradient_norm": 0.43672528862953186,
        "train_loss": 3.051028251647949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17496,
        "tokens": 9172942848,
        "learning_rate": 0.0002738236824219991,
        "gradient_norm": 0.30851468443870544,
        "train_loss": 3.0992965698242188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17497,
        "tokens": 9173467136,
        "learning_rate": 0.0002737956638490475,
        "gradient_norm": 0.3455126881599426,
        "train_loss": 3.0469164848327637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17498,
        "tokens": 9173991424,
        "learning_rate": 0.0002737676459087455,
        "gradient_norm": 0.31897443532943726,
        "train_loss": 3.052846670150757,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17499,
        "tokens": 9174515712,
        "learning_rate": 0.00027373962860140883,
        "gradient_norm": 0.3199019134044647,
        "train_loss": 3.107206344604492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17500,
        "tokens": 9175040000,
        "learning_rate": 0.0002737116119273528,
        "gradient_norm": 0.3186012804508209,
        "train_loss": 3.092369318008423,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17501,
        "tokens": 9175564288,
        "learning_rate": 0.0002736835958868927,
        "gradient_norm": 0.3042379319667816,
        "train_loss": 3.0747833251953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17502,
        "tokens": 9176088576,
        "learning_rate": 0.00027365558048034406,
        "gradient_norm": 0.33084771037101746,
        "train_loss": 3.122107982635498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17503,
        "tokens": 9176612864,
        "learning_rate": 0.0002736275657080219,
        "gradient_norm": 0.2918591797351837,
        "train_loss": 3.1076197624206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17504,
        "tokens": 9177137152,
        "learning_rate": 0.0002735995515702419,
        "gradient_norm": 0.35855114459991455,
        "train_loss": 3.082442283630371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17505,
        "tokens": 9177661440,
        "learning_rate": 0.00027357153806731923,
        "gradient_norm": 0.3406654894351959,
        "train_loss": 3.058767318725586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17506,
        "tokens": 9178185728,
        "learning_rate": 0.0002735435251995692,
        "gradient_norm": 0.3165527582168579,
        "train_loss": 3.0944011211395264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17507,
        "tokens": 9178710016,
        "learning_rate": 0.0002735155129673072,
        "gradient_norm": 0.33470556139945984,
        "train_loss": 3.0676112174987793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17508,
        "tokens": 9179234304,
        "learning_rate": 0.0002734875013708486,
        "gradient_norm": 0.3500189483165741,
        "train_loss": 3.155055046081543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17509,
        "tokens": 9179758592,
        "learning_rate": 0.0002734594904105084,
        "gradient_norm": 0.3511422276496887,
        "train_loss": 3.0780599117279053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17510,
        "tokens": 9180282880,
        "learning_rate": 0.0002734314800866023,
        "gradient_norm": 0.33374595642089844,
        "train_loss": 3.081453800201416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17511,
        "tokens": 9180807168,
        "learning_rate": 0.0002734034703994453,
        "gradient_norm": 0.3363635838031769,
        "train_loss": 3.0946924686431885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17512,
        "tokens": 9181331456,
        "learning_rate": 0.0002733754613493528,
        "gradient_norm": 0.3423900306224823,
        "train_loss": 3.0811047554016113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17513,
        "tokens": 9181855744,
        "learning_rate": 0.0002733474529366401,
        "gradient_norm": 0.33601808547973633,
        "train_loss": 3.0859298706054688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17514,
        "tokens": 9182380032,
        "learning_rate": 0.00027331944516162236,
        "gradient_norm": 0.3535044193267822,
        "train_loss": 3.0968499183654785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17515,
        "tokens": 9182904320,
        "learning_rate": 0.0002732914380246151,
        "gradient_norm": 0.31663817167282104,
        "train_loss": 3.0835518836975098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17516,
        "tokens": 9183428608,
        "learning_rate": 0.0002732634315259332,
        "gradient_norm": 0.38278433680534363,
        "train_loss": 3.1079368591308594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17517,
        "tokens": 9183952896,
        "learning_rate": 0.0002732354256658922,
        "gradient_norm": 0.3959502577781677,
        "train_loss": 3.094722270965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17518,
        "tokens": 9184477184,
        "learning_rate": 0.00027320742044480725,
        "gradient_norm": 0.3342353105545044,
        "train_loss": 3.0903918743133545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17519,
        "tokens": 9185001472,
        "learning_rate": 0.0002731794158629936,
        "gradient_norm": 0.35004737973213196,
        "train_loss": 3.120086193084717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17520,
        "tokens": 9185525760,
        "learning_rate": 0.00027315141192076634,
        "gradient_norm": 0.34779593348503113,
        "train_loss": 3.1112279891967773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17521,
        "tokens": 9186050048,
        "learning_rate": 0.00027312340861844085,
        "gradient_norm": 0.3577553629875183,
        "train_loss": 3.0686583518981934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17522,
        "tokens": 9186574336,
        "learning_rate": 0.00027309540595633235,
        "gradient_norm": 0.3250472843647003,
        "train_loss": 3.0836331844329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17523,
        "tokens": 9187098624,
        "learning_rate": 0.00027306740393475586,
        "gradient_norm": 0.331536203622818,
        "train_loss": 3.1219334602355957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17524,
        "tokens": 9187622912,
        "learning_rate": 0.0002730394025540269,
        "gradient_norm": 0.33852618932724,
        "train_loss": 3.079230785369873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17525,
        "tokens": 9188147200,
        "learning_rate": 0.00027301140181446037,
        "gradient_norm": 0.3410322368144989,
        "train_loss": 3.072890520095825,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17526,
        "tokens": 9188671488,
        "learning_rate": 0.00027298340171637156,
        "gradient_norm": 0.33149853348731995,
        "train_loss": 3.1065893173217773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17527,
        "tokens": 9189195776,
        "learning_rate": 0.0002729554022600756,
        "gradient_norm": 0.4624788761138916,
        "train_loss": 3.0620274543762207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17528,
        "tokens": 9189720064,
        "learning_rate": 0.00027292740344588777,
        "gradient_norm": 0.3548886775970459,
        "train_loss": 3.048433780670166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17529,
        "tokens": 9190244352,
        "learning_rate": 0.000272899405274123,
        "gradient_norm": 0.3342781364917755,
        "train_loss": 3.081343650817871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17530,
        "tokens": 9190768640,
        "learning_rate": 0.00027287140774509685,
        "gradient_norm": 0.3160926401615143,
        "train_loss": 3.04046368598938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17531,
        "tokens": 9191292928,
        "learning_rate": 0.000272843410859124,
        "gradient_norm": 0.3507837951183319,
        "train_loss": 3.1177566051483154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17532,
        "tokens": 9191817216,
        "learning_rate": 0.0002728154146165198,
        "gradient_norm": 0.3231607675552368,
        "train_loss": 3.0829033851623535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17533,
        "tokens": 9192341504,
        "learning_rate": 0.0002727874190175996,
        "gradient_norm": 0.3591001033782959,
        "train_loss": 3.127800464630127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17534,
        "tokens": 9192865792,
        "learning_rate": 0.0002727594240626781,
        "gradient_norm": 0.367220401763916,
        "train_loss": 3.070676803588867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17535,
        "tokens": 9193390080,
        "learning_rate": 0.00027273142975207086,
        "gradient_norm": 0.32209452986717224,
        "train_loss": 3.098276138305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17536,
        "tokens": 9193914368,
        "learning_rate": 0.00027270343608609254,
        "gradient_norm": 0.3464600741863251,
        "train_loss": 3.0834429264068604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17537,
        "tokens": 9194438656,
        "learning_rate": 0.0002726754430650586,
        "gradient_norm": 0.33496686816215515,
        "train_loss": 3.066192150115967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17538,
        "tokens": 9194962944,
        "learning_rate": 0.00027264745068928395,
        "gradient_norm": 0.3563856780529022,
        "train_loss": 3.056643009185791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17539,
        "tokens": 9195487232,
        "learning_rate": 0.00027261945895908383,
        "gradient_norm": 0.3170090913772583,
        "train_loss": 3.1074705123901367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17540,
        "tokens": 9196011520,
        "learning_rate": 0.0002725914678747731,
        "gradient_norm": 0.34463033080101013,
        "train_loss": 3.053159713745117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17541,
        "tokens": 9196535808,
        "learning_rate": 0.000272563477436667,
        "gradient_norm": 0.3640986382961273,
        "train_loss": 3.090717077255249,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17542,
        "tokens": 9197060096,
        "learning_rate": 0.00027253548764508053,
        "gradient_norm": 0.2911781668663025,
        "train_loss": 3.12384033203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17543,
        "tokens": 9197584384,
        "learning_rate": 0.00027250749850032886,
        "gradient_norm": 0.3163580000400543,
        "train_loss": 3.114307403564453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17544,
        "tokens": 9198108672,
        "learning_rate": 0.0002724795100027269,
        "gradient_norm": 0.3059927523136139,
        "train_loss": 3.0573489665985107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17545,
        "tokens": 9198632960,
        "learning_rate": 0.00027245152215258977,
        "gradient_norm": 0.3374404013156891,
        "train_loss": 3.065192222595215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17546,
        "tokens": 9199157248,
        "learning_rate": 0.0002724235349502325,
        "gradient_norm": 0.27945083379745483,
        "train_loss": 3.0697803497314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17547,
        "tokens": 9199681536,
        "learning_rate": 0.00027239554839597017,
        "gradient_norm": 0.34813278913497925,
        "train_loss": 2.9903764724731445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17548,
        "tokens": 9200205824,
        "learning_rate": 0.00027236756249011766,
        "gradient_norm": 0.3100566864013672,
        "train_loss": 3.0925779342651367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17549,
        "tokens": 9200730112,
        "learning_rate": 0.0002723395772329901,
        "gradient_norm": 0.32971322536468506,
        "train_loss": 3.074889898300171,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17550,
        "tokens": 9201254400,
        "learning_rate": 0.0002723115926249025,
        "gradient_norm": 0.345397025346756,
        "train_loss": 3.1254189014434814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17551,
        "tokens": 9201778688,
        "learning_rate": 0.0002722836086661698,
        "gradient_norm": 0.2823886275291443,
        "train_loss": 3.074586868286133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17552,
        "tokens": 9202302976,
        "learning_rate": 0.00027225562535710703,
        "gradient_norm": 0.3004721999168396,
        "train_loss": 3.0760605335235596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17553,
        "tokens": 9202827264,
        "learning_rate": 0.00027222764269802923,
        "gradient_norm": 0.3566998839378357,
        "train_loss": 3.16203236579895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17554,
        "tokens": 9203351552,
        "learning_rate": 0.00027219966068925123,
        "gradient_norm": 0.3205973505973816,
        "train_loss": 3.118150234222412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17555,
        "tokens": 9203875840,
        "learning_rate": 0.0002721716793310882,
        "gradient_norm": 0.3406257629394531,
        "train_loss": 3.096951961517334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17556,
        "tokens": 9204400128,
        "learning_rate": 0.0002721436986238549,
        "gradient_norm": 0.3602932393550873,
        "train_loss": 3.045877695083618,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17557,
        "tokens": 9204924416,
        "learning_rate": 0.0002721157185678665,
        "gradient_norm": 0.36523544788360596,
        "train_loss": 3.079387664794922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17558,
        "tokens": 9205448704,
        "learning_rate": 0.00027208773916343777,
        "gradient_norm": 0.5863111615180969,
        "train_loss": 3.2959017753601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17559,
        "tokens": 9205972992,
        "learning_rate": 0.00027205976041088384,
        "gradient_norm": 0.5076643824577332,
        "train_loss": 3.0909016132354736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17560,
        "tokens": 9206497280,
        "learning_rate": 0.00027203178231051937,
        "gradient_norm": 0.39863675832748413,
        "train_loss": 3.120941162109375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17561,
        "tokens": 9207021568,
        "learning_rate": 0.0002720038048626595,
        "gradient_norm": 0.4855119287967682,
        "train_loss": 3.141353130340576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17562,
        "tokens": 9207545856,
        "learning_rate": 0.0002719758280676192,
        "gradient_norm": 0.36961716413497925,
        "train_loss": 3.0984129905700684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17563,
        "tokens": 9208070144,
        "learning_rate": 0.00027194785192571306,
        "gradient_norm": 0.43705058097839355,
        "train_loss": 3.0965709686279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17564,
        "tokens": 9208594432,
        "learning_rate": 0.00027191987643725645,
        "gradient_norm": 0.3519558012485504,
        "train_loss": 3.0903358459472656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17565,
        "tokens": 9209118720,
        "learning_rate": 0.0002718919016025639,
        "gradient_norm": 0.3965224623680115,
        "train_loss": 3.0875940322875977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17566,
        "tokens": 9209643008,
        "learning_rate": 0.0002718639274219505,
        "gradient_norm": 0.3660869300365448,
        "train_loss": 3.108354091644287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17567,
        "tokens": 9210167296,
        "learning_rate": 0.00027183595389573096,
        "gradient_norm": 0.3636005222797394,
        "train_loss": 3.127319097518921,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17568,
        "tokens": 9210691584,
        "learning_rate": 0.0002718079810242204,
        "gradient_norm": 0.36566397547721863,
        "train_loss": 3.0766539573669434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17569,
        "tokens": 9211215872,
        "learning_rate": 0.00027178000880773346,
        "gradient_norm": 0.36965620517730713,
        "train_loss": 3.1416563987731934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17570,
        "tokens": 9211740160,
        "learning_rate": 0.00027175203724658515,
        "gradient_norm": 0.353971928358078,
        "train_loss": 3.114987850189209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17571,
        "tokens": 9212264448,
        "learning_rate": 0.0002717240663410902,
        "gradient_norm": 0.34157097339630127,
        "train_loss": 3.0914478302001953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17572,
        "tokens": 9212788736,
        "learning_rate": 0.0002716960960915635,
        "gradient_norm": 0.3278915286064148,
        "train_loss": 3.0941123962402344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17573,
        "tokens": 9213313024,
        "learning_rate": 0.00027166812649832004,
        "gradient_norm": 0.3301357626914978,
        "train_loss": 3.0482664108276367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17574,
        "tokens": 9213837312,
        "learning_rate": 0.0002716401575616744,
        "gradient_norm": 0.3174961805343628,
        "train_loss": 3.0708303451538086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17575,
        "tokens": 9214361600,
        "learning_rate": 0.0002716121892819417,
        "gradient_norm": 0.33506518602371216,
        "train_loss": 3.095331907272339,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17576,
        "tokens": 9214885888,
        "learning_rate": 0.0002715842216594364,
        "gradient_norm": 0.3219912052154541,
        "train_loss": 3.129413604736328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17577,
        "tokens": 9215410176,
        "learning_rate": 0.0002715562546944737,
        "gradient_norm": 0.3307129442691803,
        "train_loss": 3.103881359100342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17578,
        "tokens": 9215934464,
        "learning_rate": 0.00027152828838736807,
        "gradient_norm": 0.33538341522216797,
        "train_loss": 3.0707175731658936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17579,
        "tokens": 9216458752,
        "learning_rate": 0.00027150032273843454,
        "gradient_norm": 0.34657639265060425,
        "train_loss": 3.126628875732422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17580,
        "tokens": 9216983040,
        "learning_rate": 0.0002714723577479877,
        "gradient_norm": 0.35136649012565613,
        "train_loss": 3.0455474853515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17581,
        "tokens": 9217507328,
        "learning_rate": 0.0002714443934163424,
        "gradient_norm": 0.3238176107406616,
        "train_loss": 3.099984884262085,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17582,
        "tokens": 9218031616,
        "learning_rate": 0.0002714164297438136,
        "gradient_norm": 0.3542105257511139,
        "train_loss": 3.0835702419281006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17583,
        "tokens": 9218555904,
        "learning_rate": 0.0002713884667307157,
        "gradient_norm": 0.3394491970539093,
        "train_loss": 3.0448622703552246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17584,
        "tokens": 9219080192,
        "learning_rate": 0.0002713605043773639,
        "gradient_norm": 0.32555556297302246,
        "train_loss": 3.100442886352539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17585,
        "tokens": 9219604480,
        "learning_rate": 0.0002713325426840725,
        "gradient_norm": 0.32615986466407776,
        "train_loss": 3.1149349212646484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17586,
        "tokens": 9220128768,
        "learning_rate": 0.00027130458165115665,
        "gradient_norm": 0.31675824522972107,
        "train_loss": 3.0790810585021973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17587,
        "tokens": 9220653056,
        "learning_rate": 0.00027127662127893074,
        "gradient_norm": 0.32580211758613586,
        "train_loss": 3.0808990001678467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17588,
        "tokens": 9221177344,
        "learning_rate": 0.0002712486615677098,
        "gradient_norm": 0.31348907947540283,
        "train_loss": 3.054684638977051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17589,
        "tokens": 9221701632,
        "learning_rate": 0.0002712207025178083,
        "gradient_norm": 0.3184341490268707,
        "train_loss": 3.112287998199463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17590,
        "tokens": 9222225920,
        "learning_rate": 0.00027119274412954115,
        "gradient_norm": 0.34722116589546204,
        "train_loss": 3.082453727722168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17591,
        "tokens": 9222750208,
        "learning_rate": 0.0002711647864032229,
        "gradient_norm": 0.29636919498443604,
        "train_loss": 3.050701141357422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17592,
        "tokens": 9223274496,
        "learning_rate": 0.00027113682933916836,
        "gradient_norm": 0.32872727513313293,
        "train_loss": 3.1058993339538574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17593,
        "tokens": 9223798784,
        "learning_rate": 0.0002711088729376921,
        "gradient_norm": 0.2910071909427643,
        "train_loss": 3.108020305633545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17594,
        "tokens": 9224323072,
        "learning_rate": 0.000271080917199109,
        "gradient_norm": 0.31230247020721436,
        "train_loss": 3.068922519683838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17595,
        "tokens": 9224847360,
        "learning_rate": 0.0002710529621237336,
        "gradient_norm": 0.28409481048583984,
        "train_loss": 3.020551919937134,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17596,
        "tokens": 9225371648,
        "learning_rate": 0.00027102500771188055,
        "gradient_norm": 0.3097632825374603,
        "train_loss": 3.082977771759033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17597,
        "tokens": 9225895936,
        "learning_rate": 0.00027099705396386455,
        "gradient_norm": 0.3343590199947357,
        "train_loss": 3.0681710243225098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17598,
        "tokens": 9226420224,
        "learning_rate": 0.00027096910088000034,
        "gradient_norm": 0.3053850829601288,
        "train_loss": 3.0144217014312744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17599,
        "tokens": 9226944512,
        "learning_rate": 0.0002709411484606024,
        "gradient_norm": 0.309834361076355,
        "train_loss": 3.045938014984131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17600,
        "tokens": 9227468800,
        "learning_rate": 0.0002709131967059855,
        "gradient_norm": 0.3323117792606354,
        "train_loss": 3.0639729499816895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17601,
        "tokens": 9227993088,
        "learning_rate": 0.00027088524561646413,
        "gradient_norm": 0.3116166293621063,
        "train_loss": 3.0733790397644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17602,
        "tokens": 9228517376,
        "learning_rate": 0.0002708572951923531,
        "gradient_norm": 0.30273476243019104,
        "train_loss": 3.067157745361328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17603,
        "tokens": 9229041664,
        "learning_rate": 0.0002708293454339669,
        "gradient_norm": 0.32290101051330566,
        "train_loss": 3.060624361038208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17604,
        "tokens": 9229565952,
        "learning_rate": 0.0002708013963416202,
        "gradient_norm": 0.3050599992275238,
        "train_loss": 3.043774127960205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17605,
        "tokens": 9230090240,
        "learning_rate": 0.0002707734479156275,
        "gradient_norm": 0.2997272312641144,
        "train_loss": 3.038053274154663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17606,
        "tokens": 9230614528,
        "learning_rate": 0.0002707455001563036,
        "gradient_norm": 0.3198436200618744,
        "train_loss": 3.146099328994751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17607,
        "tokens": 9231138816,
        "learning_rate": 0.00027071755306396286,
        "gradient_norm": 0.3380366861820221,
        "train_loss": 3.1322121620178223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17608,
        "tokens": 9231663104,
        "learning_rate": 0.00027068960663892004,
        "gradient_norm": 0.39040571451187134,
        "train_loss": 3.0773308277130127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17609,
        "tokens": 9232187392,
        "learning_rate": 0.00027066166088148956,
        "gradient_norm": 0.3094419240951538,
        "train_loss": 3.0600624084472656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17610,
        "tokens": 9232711680,
        "learning_rate": 0.000270633715791986,
        "gradient_norm": 0.35400286316871643,
        "train_loss": 3.1360340118408203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17611,
        "tokens": 9233235968,
        "learning_rate": 0.0002706057713707241,
        "gradient_norm": 0.4138754904270172,
        "train_loss": 3.078122615814209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17612,
        "tokens": 9233760256,
        "learning_rate": 0.0002705778276180182,
        "gradient_norm": 0.38601040840148926,
        "train_loss": 3.047724485397339,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17613,
        "tokens": 9234284544,
        "learning_rate": 0.000270549884534183,
        "gradient_norm": 0.3411259055137634,
        "train_loss": 3.0700931549072266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17614,
        "tokens": 9234808832,
        "learning_rate": 0.00027052194211953285,
        "gradient_norm": 0.3880986273288727,
        "train_loss": 3.1253721714019775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17615,
        "tokens": 9235333120,
        "learning_rate": 0.0002704940003743825,
        "gradient_norm": 0.3275741934776306,
        "train_loss": 3.0991382598876953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17616,
        "tokens": 9235857408,
        "learning_rate": 0.0002704660592990462,
        "gradient_norm": 0.43044063448905945,
        "train_loss": 3.0696682929992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17617,
        "tokens": 9236381696,
        "learning_rate": 0.0002704381188938388,
        "gradient_norm": 0.3889828622341156,
        "train_loss": 3.1656382083892822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17618,
        "tokens": 9236905984,
        "learning_rate": 0.00027041017915907447,
        "gradient_norm": 0.3935536742210388,
        "train_loss": 3.0871949195861816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17619,
        "tokens": 9237430272,
        "learning_rate": 0.00027038224009506796,
        "gradient_norm": 0.35683751106262207,
        "train_loss": 3.0538887977600098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17620,
        "tokens": 9237954560,
        "learning_rate": 0.00027035430170213354,
        "gradient_norm": 0.3520506024360657,
        "train_loss": 3.1045608520507812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17621,
        "tokens": 9238478848,
        "learning_rate": 0.0002703263639805858,
        "gradient_norm": 0.36727601289749146,
        "train_loss": 3.077521324157715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17622,
        "tokens": 9239003136,
        "learning_rate": 0.00027029842693073933,
        "gradient_norm": 0.34006941318511963,
        "train_loss": 3.0718703269958496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17623,
        "tokens": 9239527424,
        "learning_rate": 0.0002702704905529084,
        "gradient_norm": 0.34356406331062317,
        "train_loss": 3.036667823791504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17624,
        "tokens": 9240051712,
        "learning_rate": 0.0002702425548474077,
        "gradient_norm": 0.3355052173137665,
        "train_loss": 3.083789110183716,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17625,
        "tokens": 9240576000,
        "learning_rate": 0.0002702146198145513,
        "gradient_norm": 0.3060240149497986,
        "train_loss": 3.0895543098449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17626,
        "tokens": 9241100288,
        "learning_rate": 0.0002701866854546541,
        "gradient_norm": 0.3537999987602234,
        "train_loss": 2.9757652282714844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17627,
        "tokens": 9241624576,
        "learning_rate": 0.00027015875176803015,
        "gradient_norm": 0.33486491441726685,
        "train_loss": 3.1113717555999756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17628,
        "tokens": 9242148864,
        "learning_rate": 0.0002701308187549942,
        "gradient_norm": 0.31735002994537354,
        "train_loss": 3.0674617290496826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17629,
        "tokens": 9242673152,
        "learning_rate": 0.00027010288641586035,
        "gradient_norm": 0.7984666228294373,
        "train_loss": 3.120685577392578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17630,
        "tokens": 9243197440,
        "learning_rate": 0.00027007495475094316,
        "gradient_norm": 0.36625418066978455,
        "train_loss": 3.0711097717285156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17631,
        "tokens": 9243721728,
        "learning_rate": 0.0002700470237605572,
        "gradient_norm": 0.36159607768058777,
        "train_loss": 3.061249256134033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17632,
        "tokens": 9244246016,
        "learning_rate": 0.0002700190934450166,
        "gradient_norm": 0.3894832730293274,
        "train_loss": 3.0814037322998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17633,
        "tokens": 9244770304,
        "learning_rate": 0.000269991163804636,
        "gradient_norm": 0.32817766070365906,
        "train_loss": 3.109869956970215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17634,
        "tokens": 9245294592,
        "learning_rate": 0.00026996323483972955,
        "gradient_norm": 0.35005253553390503,
        "train_loss": 3.133497476577759,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17635,
        "tokens": 9245818880,
        "learning_rate": 0.00026993530655061184,
        "gradient_norm": 0.32369181513786316,
        "train_loss": 3.1111226081848145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17636,
        "tokens": 9246343168,
        "learning_rate": 0.000269907378937597,
        "gradient_norm": 0.3277883529663086,
        "train_loss": 3.068760871887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17637,
        "tokens": 9246867456,
        "learning_rate": 0.00026987945200099967,
        "gradient_norm": 0.2989622950553894,
        "train_loss": 3.087520122528076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17638,
        "tokens": 9247391744,
        "learning_rate": 0.0002698515257411339,
        "gradient_norm": 0.32473087310791016,
        "train_loss": 3.089118003845215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17639,
        "tokens": 9247916032,
        "learning_rate": 0.00026982360015831425,
        "gradient_norm": 0.28838738799095154,
        "train_loss": 3.091362476348877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17640,
        "tokens": 9248440320,
        "learning_rate": 0.0002697956752528549,
        "gradient_norm": 0.3349486291408539,
        "train_loss": 3.147371530532837,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17641,
        "tokens": 9248964608,
        "learning_rate": 0.00026976775102507033,
        "gradient_norm": 0.3021921217441559,
        "train_loss": 3.0378599166870117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17642,
        "tokens": 9249488896,
        "learning_rate": 0.0002697398274752749,
        "gradient_norm": 0.3235246241092682,
        "train_loss": 3.079721689224243,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17643,
        "tokens": 9250013184,
        "learning_rate": 0.0002697119046037828,
        "gradient_norm": 0.2979273796081543,
        "train_loss": 3.0775742530822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17644,
        "tokens": 9250537472,
        "learning_rate": 0.00026968398241090827,
        "gradient_norm": 0.3768460750579834,
        "train_loss": 3.1758031845092773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17645,
        "tokens": 9251061760,
        "learning_rate": 0.00026965606089696576,
        "gradient_norm": 0.3386240005493164,
        "train_loss": 3.10319185256958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17646,
        "tokens": 9251586048,
        "learning_rate": 0.0002696281400622695,
        "gradient_norm": 0.3780863583087921,
        "train_loss": 3.0701584815979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17647,
        "tokens": 9252110336,
        "learning_rate": 0.0002696002199071338,
        "gradient_norm": 0.35539963841438293,
        "train_loss": 3.0550589561462402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17648,
        "tokens": 9252634624,
        "learning_rate": 0.0002695723004318729,
        "gradient_norm": 0.3973742723464966,
        "train_loss": 3.0954084396362305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17649,
        "tokens": 9253158912,
        "learning_rate": 0.0002695443816368011,
        "gradient_norm": 0.32000595331192017,
        "train_loss": 3.081094264984131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17650,
        "tokens": 9253683200,
        "learning_rate": 0.00026951646352223256,
        "gradient_norm": 0.3181551396846771,
        "train_loss": 3.044160842895508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17651,
        "tokens": 9254207488,
        "learning_rate": 0.0002694885460884817,
        "gradient_norm": 0.30064502358436584,
        "train_loss": 3.0662999153137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17652,
        "tokens": 9254731776,
        "learning_rate": 0.0002694606293358626,
        "gradient_norm": 0.35509559512138367,
        "train_loss": 3.1257801055908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17653,
        "tokens": 9255256064,
        "learning_rate": 0.0002694327132646897,
        "gradient_norm": 0.3323461711406708,
        "train_loss": 3.120683193206787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17654,
        "tokens": 9255780352,
        "learning_rate": 0.000269404797875277,
        "gradient_norm": 0.35924649238586426,
        "train_loss": 3.0996856689453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17655,
        "tokens": 9256304640,
        "learning_rate": 0.00026937688316793894,
        "gradient_norm": 0.3066529929637909,
        "train_loss": 3.118675708770752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17656,
        "tokens": 9256828928,
        "learning_rate": 0.0002693489691429896,
        "gradient_norm": 0.3441862463951111,
        "train_loss": 3.083962917327881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17657,
        "tokens": 9257353216,
        "learning_rate": 0.0002693210558007432,
        "gradient_norm": 0.3011152744293213,
        "train_loss": 3.0791187286376953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17658,
        "tokens": 9257877504,
        "learning_rate": 0.00026929314314151387,
        "gradient_norm": 0.3477088510990143,
        "train_loss": 3.0640642642974854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17659,
        "tokens": 9258401792,
        "learning_rate": 0.00026926523116561603,
        "gradient_norm": 0.31776008009910583,
        "train_loss": 3.055860996246338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17660,
        "tokens": 9258926080,
        "learning_rate": 0.00026923731987336366,
        "gradient_norm": 0.34786221385002136,
        "train_loss": 3.0709211826324463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17661,
        "tokens": 9259450368,
        "learning_rate": 0.0002692094092650709,
        "gradient_norm": 0.35850536823272705,
        "train_loss": 3.081559181213379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17662,
        "tokens": 9259974656,
        "learning_rate": 0.0002691814993410522,
        "gradient_norm": 0.61575847864151,
        "train_loss": 3.1760504245758057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17663,
        "tokens": 9260498944,
        "learning_rate": 0.0002691535901016214,
        "gradient_norm": 0.37702620029449463,
        "train_loss": 3.058802366256714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17664,
        "tokens": 9261023232,
        "learning_rate": 0.00026912568154709285,
        "gradient_norm": 0.3990391194820404,
        "train_loss": 3.0820796489715576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17665,
        "tokens": 9261547520,
        "learning_rate": 0.0002690977736777806,
        "gradient_norm": 0.3671855032444,
        "train_loss": 3.0629758834838867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17666,
        "tokens": 9262071808,
        "learning_rate": 0.0002690698664939989,
        "gradient_norm": 0.39661285281181335,
        "train_loss": 3.1341500282287598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17667,
        "tokens": 9262596096,
        "learning_rate": 0.0002690419599960617,
        "gradient_norm": 0.38306039571762085,
        "train_loss": 3.077463150024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17668,
        "tokens": 9263120384,
        "learning_rate": 0.0002690140541842833,
        "gradient_norm": 0.37687644362449646,
        "train_loss": 3.103806972503662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17669,
        "tokens": 9263644672,
        "learning_rate": 0.00026898614905897765,
        "gradient_norm": 0.336196631193161,
        "train_loss": 3.0712954998016357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17670,
        "tokens": 9264168960,
        "learning_rate": 0.000268958244620459,
        "gradient_norm": 0.4037880301475525,
        "train_loss": 3.053609609603882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17671,
        "tokens": 9264693248,
        "learning_rate": 0.00026893034086904145,
        "gradient_norm": 0.3720970153808594,
        "train_loss": 3.1728782653808594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17672,
        "tokens": 9265217536,
        "learning_rate": 0.000268902437805039,
        "gradient_norm": 0.44566279649734497,
        "train_loss": 3.1269121170043945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17673,
        "tokens": 9265741824,
        "learning_rate": 0.0002688745354287658,
        "gradient_norm": 0.3849509060382843,
        "train_loss": 3.101199150085449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17674,
        "tokens": 9266266112,
        "learning_rate": 0.00026884663374053585,
        "gradient_norm": 0.40061214566230774,
        "train_loss": 3.0482852458953857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17675,
        "tokens": 9266790400,
        "learning_rate": 0.0002688187327406633,
        "gradient_norm": 0.3923492133617401,
        "train_loss": 3.067805528640747,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17676,
        "tokens": 9267314688,
        "learning_rate": 0.00026879083242946215,
        "gradient_norm": 0.4043639302253723,
        "train_loss": 3.075521945953369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17677,
        "tokens": 9267838976,
        "learning_rate": 0.00026876293280724657,
        "gradient_norm": 0.3754425048828125,
        "train_loss": 3.061208724975586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17678,
        "tokens": 9268363264,
        "learning_rate": 0.0002687350338743304,
        "gradient_norm": 0.3751881420612335,
        "train_loss": 3.0803864002227783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17679,
        "tokens": 9268887552,
        "learning_rate": 0.00026870713563102787,
        "gradient_norm": 0.32772186398506165,
        "train_loss": 3.0793001651763916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17680,
        "tokens": 9269411840,
        "learning_rate": 0.00026867923807765283,
        "gradient_norm": 0.3762754201889038,
        "train_loss": 3.0516905784606934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17681,
        "tokens": 9269936128,
        "learning_rate": 0.00026865134121451943,
        "gradient_norm": 0.3111658990383148,
        "train_loss": 3.0395169258117676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17682,
        "tokens": 9270460416,
        "learning_rate": 0.00026862344504194173,
        "gradient_norm": 0.340205579996109,
        "train_loss": 3.0757436752319336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17683,
        "tokens": 9270984704,
        "learning_rate": 0.00026859554956023364,
        "gradient_norm": 0.3779921233654022,
        "train_loss": 3.0937204360961914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17684,
        "tokens": 9271508992,
        "learning_rate": 0.0002685676547697092,
        "gradient_norm": 0.31191933155059814,
        "train_loss": 3.112334728240967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17685,
        "tokens": 9272033280,
        "learning_rate": 0.0002685397606706823,
        "gradient_norm": 0.3512398898601532,
        "train_loss": 3.073117256164551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17686,
        "tokens": 9272557568,
        "learning_rate": 0.00026851186726346713,
        "gradient_norm": 0.3416768014431,
        "train_loss": 3.0867857933044434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17687,
        "tokens": 9273081856,
        "learning_rate": 0.00026848397454837746,
        "gradient_norm": 0.35385966300964355,
        "train_loss": 3.0732438564300537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17688,
        "tokens": 9273606144,
        "learning_rate": 0.0002684560825257274,
        "gradient_norm": 0.29976433515548706,
        "train_loss": 3.0879979133605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17689,
        "tokens": 9274130432,
        "learning_rate": 0.0002684281911958308,
        "gradient_norm": 0.3316909074783325,
        "train_loss": 3.036916732788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17690,
        "tokens": 9274654720,
        "learning_rate": 0.00026840030055900164,
        "gradient_norm": 0.29547813534736633,
        "train_loss": 3.0501291751861572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17691,
        "tokens": 9275179008,
        "learning_rate": 0.0002683724106155539,
        "gradient_norm": 0.3281875252723694,
        "train_loss": 3.030801296234131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17692,
        "tokens": 9275703296,
        "learning_rate": 0.0002683445213658015,
        "gradient_norm": 0.3174183964729309,
        "train_loss": 3.0588886737823486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17693,
        "tokens": 9276227584,
        "learning_rate": 0.00026831663281005837,
        "gradient_norm": 0.3039737939834595,
        "train_loss": 3.075288772583008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17694,
        "tokens": 9276751872,
        "learning_rate": 0.0002682887449486384,
        "gradient_norm": 0.34330689907073975,
        "train_loss": 3.070474147796631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17695,
        "tokens": 9277276160,
        "learning_rate": 0.0002682608577818556,
        "gradient_norm": 0.2979540228843689,
        "train_loss": 3.0539398193359375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17696,
        "tokens": 9277800448,
        "learning_rate": 0.00026823297131002376,
        "gradient_norm": 0.37818577885627747,
        "train_loss": 3.1467347145080566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17697,
        "tokens": 9278324736,
        "learning_rate": 0.0002682050855334568,
        "gradient_norm": 0.3576209843158722,
        "train_loss": 3.084005832672119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17698,
        "tokens": 9278849024,
        "learning_rate": 0.00026817720045246873,
        "gradient_norm": 0.3272886276245117,
        "train_loss": 3.134934425354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17699,
        "tokens": 9279373312,
        "learning_rate": 0.00026814931606737325,
        "gradient_norm": 0.3600459396839142,
        "train_loss": 3.083507537841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17700,
        "tokens": 9279897600,
        "learning_rate": 0.0002681214323784843,
        "gradient_norm": 0.31236594915390015,
        "train_loss": 3.037015914916992,
        "val_loss": 3.0456881523132324,
        "hellaswag_acc": 0.28052181005477905,
        "hellaswag_acc_norm": 0.29316869378089905
    },
    {
        "step": 17701,
        "tokens": 9280421888,
        "learning_rate": 0.00026809354938611577,
        "gradient_norm": 0.3227687478065491,
        "train_loss": 3.00516939163208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17702,
        "tokens": 9280946176,
        "learning_rate": 0.0002680656670905816,
        "gradient_norm": 0.396019846200943,
        "train_loss": 3.0421018600463867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17703,
        "tokens": 9281470464,
        "learning_rate": 0.0002680377854921954,
        "gradient_norm": 0.3554965555667877,
        "train_loss": 3.07236385345459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17704,
        "tokens": 9281994752,
        "learning_rate": 0.0002680099045912713,
        "gradient_norm": 0.34671491384506226,
        "train_loss": 3.096266269683838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17705,
        "tokens": 9282519040,
        "learning_rate": 0.00026798202438812287,
        "gradient_norm": 0.3511008024215698,
        "train_loss": 3.0412416458129883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17706,
        "tokens": 9283043328,
        "learning_rate": 0.00026795414488306414,
        "gradient_norm": 0.33794429898262024,
        "train_loss": 3.092193365097046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17707,
        "tokens": 9283567616,
        "learning_rate": 0.0002679262660764089,
        "gradient_norm": 0.3584069609642029,
        "train_loss": 3.1324210166931152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17708,
        "tokens": 9284091904,
        "learning_rate": 0.00026789838796847086,
        "gradient_norm": 0.3037526309490204,
        "train_loss": 3.059722900390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17709,
        "tokens": 9284616192,
        "learning_rate": 0.00026787051055956383,
        "gradient_norm": 0.3203730583190918,
        "train_loss": 3.082702875137329,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17710,
        "tokens": 9285140480,
        "learning_rate": 0.0002678426338500017,
        "gradient_norm": 0.3407442569732666,
        "train_loss": 3.156907796859741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17711,
        "tokens": 9285664768,
        "learning_rate": 0.0002678147578400982,
        "gradient_norm": 0.3175346851348877,
        "train_loss": 3.0782313346862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17712,
        "tokens": 9286189056,
        "learning_rate": 0.0002677868825301671,
        "gradient_norm": 0.34403181076049805,
        "train_loss": 3.086949348449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17713,
        "tokens": 9286713344,
        "learning_rate": 0.0002677590079205222,
        "gradient_norm": 0.32996314764022827,
        "train_loss": 3.1081392765045166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17714,
        "tokens": 9287237632,
        "learning_rate": 0.00026773113401147726,
        "gradient_norm": 0.33872056007385254,
        "train_loss": 3.0266623497009277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17715,
        "tokens": 9287761920,
        "learning_rate": 0.0002677032608033461,
        "gradient_norm": 0.343536376953125,
        "train_loss": 3.043868064880371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17716,
        "tokens": 9288286208,
        "learning_rate": 0.00026767538829644224,
        "gradient_norm": 0.3555908799171448,
        "train_loss": 3.087439775466919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17717,
        "tokens": 9288810496,
        "learning_rate": 0.0002676475164910797,
        "gradient_norm": 0.31075695157051086,
        "train_loss": 3.0676424503326416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17718,
        "tokens": 9289334784,
        "learning_rate": 0.000267619645387572,
        "gradient_norm": 0.39917728304862976,
        "train_loss": 3.041118621826172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17719,
        "tokens": 9289859072,
        "learning_rate": 0.00026759177498623303,
        "gradient_norm": 0.3534177541732788,
        "train_loss": 3.086179494857788,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17720,
        "tokens": 9290383360,
        "learning_rate": 0.0002675639052873764,
        "gradient_norm": 0.3864029347896576,
        "train_loss": 3.060203790664673,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17721,
        "tokens": 9290907648,
        "learning_rate": 0.00026753603629131573,
        "gradient_norm": 0.3212894797325134,
        "train_loss": 3.079932928085327,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17722,
        "tokens": 9291431936,
        "learning_rate": 0.00026750816799836496,
        "gradient_norm": 0.3737391233444214,
        "train_loss": 3.0207858085632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17723,
        "tokens": 9291956224,
        "learning_rate": 0.0002674803004088376,
        "gradient_norm": 0.3509441018104553,
        "train_loss": 3.0964179039001465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17724,
        "tokens": 9292480512,
        "learning_rate": 0.0002674524335230475,
        "gradient_norm": 0.36867159605026245,
        "train_loss": 3.063934803009033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17725,
        "tokens": 9293004800,
        "learning_rate": 0.0002674245673413081,
        "gradient_norm": 0.36335355043411255,
        "train_loss": 3.077967643737793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17726,
        "tokens": 9293529088,
        "learning_rate": 0.00026739670186393333,
        "gradient_norm": 0.33631160855293274,
        "train_loss": 3.0265378952026367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17727,
        "tokens": 9294053376,
        "learning_rate": 0.00026736883709123653,
        "gradient_norm": 0.30688631534576416,
        "train_loss": 3.059772491455078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17728,
        "tokens": 9294577664,
        "learning_rate": 0.00026734097302353173,
        "gradient_norm": 0.312923789024353,
        "train_loss": 3.021557569503784,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17729,
        "tokens": 9295101952,
        "learning_rate": 0.0002673131096611322,
        "gradient_norm": 0.32533419132232666,
        "train_loss": 2.9905781745910645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17730,
        "tokens": 9295626240,
        "learning_rate": 0.0002672852470043519,
        "gradient_norm": 0.346662700176239,
        "train_loss": 3.035184383392334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17731,
        "tokens": 9296150528,
        "learning_rate": 0.0002672573850535043,
        "gradient_norm": 0.3141850233078003,
        "train_loss": 3.094001293182373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17732,
        "tokens": 9296674816,
        "learning_rate": 0.00026722952380890295,
        "gradient_norm": 0.35022568702697754,
        "train_loss": 3.0334362983703613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17733,
        "tokens": 9297199104,
        "learning_rate": 0.00026720166327086174,
        "gradient_norm": 0.3054630756378174,
        "train_loss": 3.025099754333496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17734,
        "tokens": 9297723392,
        "learning_rate": 0.0002671738034396939,
        "gradient_norm": 0.34380990266799927,
        "train_loss": 3.076443672180176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17735,
        "tokens": 9298247680,
        "learning_rate": 0.00026714594431571334,
        "gradient_norm": 0.34986183047294617,
        "train_loss": 3.1044559478759766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17736,
        "tokens": 9298771968,
        "learning_rate": 0.00026711808589923347,
        "gradient_norm": 0.3204980492591858,
        "train_loss": 3.0342512130737305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17737,
        "tokens": 9299296256,
        "learning_rate": 0.000267090228190568,
        "gradient_norm": 0.4450741410255432,
        "train_loss": 3.0425877571105957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17738,
        "tokens": 9299820544,
        "learning_rate": 0.0002670623711900303,
        "gradient_norm": 0.3388248383998871,
        "train_loss": 3.0673036575317383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17739,
        "tokens": 9300344832,
        "learning_rate": 0.00026703451489793416,
        "gradient_norm": 0.35399067401885986,
        "train_loss": 3.0367274284362793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17740,
        "tokens": 9300869120,
        "learning_rate": 0.000267006659314593,
        "gradient_norm": 0.32946404814720154,
        "train_loss": 3.0898423194885254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17741,
        "tokens": 9301393408,
        "learning_rate": 0.00026697880444032036,
        "gradient_norm": 0.3596034646034241,
        "train_loss": 2.949167490005493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17742,
        "tokens": 9301917696,
        "learning_rate": 0.00026695095027542997,
        "gradient_norm": 0.32471519708633423,
        "train_loss": 3.038698673248291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17743,
        "tokens": 9302441984,
        "learning_rate": 0.00026692309682023517,
        "gradient_norm": 0.3437425196170807,
        "train_loss": 3.0164103507995605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17744,
        "tokens": 9302966272,
        "learning_rate": 0.00026689524407504957,
        "gradient_norm": 0.3478721082210541,
        "train_loss": 3.066711187362671,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17745,
        "tokens": 9303490560,
        "learning_rate": 0.00026686739204018656,
        "gradient_norm": 0.3260633647441864,
        "train_loss": 3.054478645324707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17746,
        "tokens": 9304014848,
        "learning_rate": 0.0002668395407159599,
        "gradient_norm": 0.3497273027896881,
        "train_loss": 3.035396099090576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17747,
        "tokens": 9304539136,
        "learning_rate": 0.0002668116901026828,
        "gradient_norm": 0.34446826577186584,
        "train_loss": 3.060051441192627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17748,
        "tokens": 9305063424,
        "learning_rate": 0.000266783840200669,
        "gradient_norm": 0.31260475516319275,
        "train_loss": 3.0202717781066895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17749,
        "tokens": 9305587712,
        "learning_rate": 0.0002667559910102318,
        "gradient_norm": 0.3250143826007843,
        "train_loss": 3.0820460319519043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17750,
        "tokens": 9306112000,
        "learning_rate": 0.00026672814253168474,
        "gradient_norm": 0.33216822147369385,
        "train_loss": 3.050633430480957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17751,
        "tokens": 9306636288,
        "learning_rate": 0.0002667002947653414,
        "gradient_norm": 0.3568028211593628,
        "train_loss": 3.0586507320404053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17752,
        "tokens": 9307160576,
        "learning_rate": 0.00026667244771151513,
        "gradient_norm": 0.3758620619773865,
        "train_loss": 3.1232669353485107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17753,
        "tokens": 9307684864,
        "learning_rate": 0.00026664460137051937,
        "gradient_norm": 0.3544957935810089,
        "train_loss": 3.0137853622436523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17754,
        "tokens": 9308209152,
        "learning_rate": 0.00026661675574266757,
        "gradient_norm": 0.36182451248168945,
        "train_loss": 3.1356301307678223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17755,
        "tokens": 9308733440,
        "learning_rate": 0.00026658891082827327,
        "gradient_norm": 0.3751426935195923,
        "train_loss": 3.05961275100708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17756,
        "tokens": 9309257728,
        "learning_rate": 0.00026656106662764975,
        "gradient_norm": 0.3386431336402893,
        "train_loss": 3.0219597816467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17757,
        "tokens": 9309782016,
        "learning_rate": 0.0002665332231411105,
        "gradient_norm": 0.34810271859169006,
        "train_loss": 3.0243544578552246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17758,
        "tokens": 9310306304,
        "learning_rate": 0.00026650538036896907,
        "gradient_norm": 0.42030462622642517,
        "train_loss": 3.1068906784057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17759,
        "tokens": 9310830592,
        "learning_rate": 0.00026647753831153856,
        "gradient_norm": 0.3325388431549072,
        "train_loss": 3.0611300468444824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17760,
        "tokens": 9311354880,
        "learning_rate": 0.00026644969696913267,
        "gradient_norm": 0.38634759187698364,
        "train_loss": 3.010312080383301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17761,
        "tokens": 9311879168,
        "learning_rate": 0.0002664218563420645,
        "gradient_norm": 0.3063178062438965,
        "train_loss": 3.0621256828308105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17762,
        "tokens": 9312403456,
        "learning_rate": 0.00026639401643064773,
        "gradient_norm": 0.3400518298149109,
        "train_loss": 3.0352935791015625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17763,
        "tokens": 9312927744,
        "learning_rate": 0.0002663661772351955,
        "gradient_norm": 0.31531545519828796,
        "train_loss": 3.0626964569091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17764,
        "tokens": 9313452032,
        "learning_rate": 0.0002663383387560214,
        "gradient_norm": 0.3306848406791687,
        "train_loss": 3.053894519805908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17765,
        "tokens": 9313976320,
        "learning_rate": 0.00026631050099343854,
        "gradient_norm": 0.3802854120731354,
        "train_loss": 3.094705104827881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17766,
        "tokens": 9314500608,
        "learning_rate": 0.00026628266394776044,
        "gradient_norm": 0.32056066393852234,
        "train_loss": 3.0894062519073486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17767,
        "tokens": 9315024896,
        "learning_rate": 0.0002662548276193003,
        "gradient_norm": 0.32982558012008667,
        "train_loss": 2.9782819747924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17768,
        "tokens": 9315549184,
        "learning_rate": 0.00026622699200837166,
        "gradient_norm": 0.3492489457130432,
        "train_loss": 3.09635591506958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17769,
        "tokens": 9316073472,
        "learning_rate": 0.00026619915711528763,
        "gradient_norm": 0.3285617530345917,
        "train_loss": 3.0267789363861084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17770,
        "tokens": 9316597760,
        "learning_rate": 0.00026617132294036157,
        "gradient_norm": 0.42589670419692993,
        "train_loss": 3.0198283195495605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17771,
        "tokens": 9317122048,
        "learning_rate": 0.00026614348948390696,
        "gradient_norm": 0.3697454631328583,
        "train_loss": 3.0245461463928223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17772,
        "tokens": 9317646336,
        "learning_rate": 0.00026611565674623686,
        "gradient_norm": 0.36747124791145325,
        "train_loss": 3.037125587463379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17773,
        "tokens": 9318170624,
        "learning_rate": 0.00026608782472766477,
        "gradient_norm": 0.3595516085624695,
        "train_loss": 2.974388599395752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17774,
        "tokens": 9318694912,
        "learning_rate": 0.00026605999342850376,
        "gradient_norm": 0.3240709900856018,
        "train_loss": 3.1053829193115234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17775,
        "tokens": 9319219200,
        "learning_rate": 0.0002660321628490674,
        "gradient_norm": 0.33611050248146057,
        "train_loss": 3.021167755126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17776,
        "tokens": 9319743488,
        "learning_rate": 0.00026600433298966863,
        "gradient_norm": 0.35264134407043457,
        "train_loss": 3.1056466102600098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17777,
        "tokens": 9320267776,
        "learning_rate": 0.000265976503850621,
        "gradient_norm": 0.39111393690109253,
        "train_loss": 3.0978610515594482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17778,
        "tokens": 9320792064,
        "learning_rate": 0.0002659486754322375,
        "gradient_norm": 0.35142964124679565,
        "train_loss": 3.010829448699951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17779,
        "tokens": 9321316352,
        "learning_rate": 0.00026592084773483166,
        "gradient_norm": 0.3869604766368866,
        "train_loss": 3.0415167808532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17780,
        "tokens": 9321840640,
        "learning_rate": 0.00026589302075871637,
        "gradient_norm": 0.3630352318286896,
        "train_loss": 3.1063623428344727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17781,
        "tokens": 9322364928,
        "learning_rate": 0.00026586519450420506,
        "gradient_norm": 0.3148675858974457,
        "train_loss": 3.0620012283325195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17782,
        "tokens": 9322889216,
        "learning_rate": 0.0002658373689716111,
        "gradient_norm": 0.32664966583251953,
        "train_loss": 3.0660698413848877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17783,
        "tokens": 9323413504,
        "learning_rate": 0.00026580954416124736,
        "gradient_norm": 0.3380897045135498,
        "train_loss": 3.033000946044922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17784,
        "tokens": 9323937792,
        "learning_rate": 0.00026578172007342735,
        "gradient_norm": 0.322939395904541,
        "train_loss": 3.078341484069824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17785,
        "tokens": 9324462080,
        "learning_rate": 0.000265753896708464,
        "gradient_norm": 0.3303806781768799,
        "train_loss": 3.0608105659484863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17786,
        "tokens": 9324986368,
        "learning_rate": 0.00026572607406667075,
        "gradient_norm": 0.33541253209114075,
        "train_loss": 3.0619778633117676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17787,
        "tokens": 9325510656,
        "learning_rate": 0.00026569825214836054,
        "gradient_norm": 0.35130825638771057,
        "train_loss": 3.021118640899658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17788,
        "tokens": 9326034944,
        "learning_rate": 0.0002656704309538468,
        "gradient_norm": 0.3183271884918213,
        "train_loss": 3.0605416297912598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17789,
        "tokens": 9326559232,
        "learning_rate": 0.0002656426104834424,
        "gradient_norm": 0.37891629338264465,
        "train_loss": 3.098189115524292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17790,
        "tokens": 9327083520,
        "learning_rate": 0.00026561479073746065,
        "gradient_norm": 0.4132031798362732,
        "train_loss": 3.0929083824157715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17791,
        "tokens": 9327607808,
        "learning_rate": 0.0002655869717162148,
        "gradient_norm": 0.31734415888786316,
        "train_loss": 3.0465779304504395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17792,
        "tokens": 9328132096,
        "learning_rate": 0.00026555915342001786,
        "gradient_norm": 0.32504844665527344,
        "train_loss": 3.091111183166504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17793,
        "tokens": 9328656384,
        "learning_rate": 0.00026553133584918294,
        "gradient_norm": 0.3245278298854828,
        "train_loss": 3.0665812492370605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17794,
        "tokens": 9329180672,
        "learning_rate": 0.0002655035190040232,
        "gradient_norm": 0.34574684500694275,
        "train_loss": 3.058407783508301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17795,
        "tokens": 9329704960,
        "learning_rate": 0.00026547570288485176,
        "gradient_norm": 0.2844700515270233,
        "train_loss": 3.0824947357177734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17796,
        "tokens": 9330229248,
        "learning_rate": 0.00026544788749198163,
        "gradient_norm": 0.33366021513938904,
        "train_loss": 3.029015302658081,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17797,
        "tokens": 9330753536,
        "learning_rate": 0.0002654200728257261,
        "gradient_norm": 0.2914767265319824,
        "train_loss": 3.061781883239746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17798,
        "tokens": 9331277824,
        "learning_rate": 0.00026539225888639814,
        "gradient_norm": 0.35193827748298645,
        "train_loss": 3.1584768295288086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17799,
        "tokens": 9331802112,
        "learning_rate": 0.00026536444567431085,
        "gradient_norm": 0.3285404443740845,
        "train_loss": 3.1033217906951904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17800,
        "tokens": 9332326400,
        "learning_rate": 0.0002653366331897772,
        "gradient_norm": 0.33101189136505127,
        "train_loss": 3.064797878265381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17801,
        "tokens": 9332850688,
        "learning_rate": 0.00026530882143311046,
        "gradient_norm": 0.3452756702899933,
        "train_loss": 3.031712770462036,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17802,
        "tokens": 9333374976,
        "learning_rate": 0.0002652810104046235,
        "gradient_norm": 0.3093980848789215,
        "train_loss": 3.0528581142425537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17803,
        "tokens": 9333899264,
        "learning_rate": 0.0002652532001046295,
        "gradient_norm": 0.3389345705509186,
        "train_loss": 3.0253853797912598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17804,
        "tokens": 9334423552,
        "learning_rate": 0.00026522539053344137,
        "gradient_norm": 0.31559720635414124,
        "train_loss": 3.0849056243896484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17805,
        "tokens": 9334947840,
        "learning_rate": 0.00026519758169137226,
        "gradient_norm": 0.3588067889213562,
        "train_loss": 3.0949301719665527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17806,
        "tokens": 9335472128,
        "learning_rate": 0.00026516977357873514,
        "gradient_norm": 0.3430940806865692,
        "train_loss": 3.088038444519043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17807,
        "tokens": 9335996416,
        "learning_rate": 0.00026514196619584305,
        "gradient_norm": 0.301272451877594,
        "train_loss": 3.116807222366333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17808,
        "tokens": 9336520704,
        "learning_rate": 0.000265114159543009,
        "gradient_norm": 0.28999465703964233,
        "train_loss": 3.0119357109069824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17809,
        "tokens": 9337044992,
        "learning_rate": 0.0002650863536205459,
        "gradient_norm": 0.30138498544692993,
        "train_loss": 3.0149807929992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17810,
        "tokens": 9337569280,
        "learning_rate": 0.0002650585484287668,
        "gradient_norm": 0.333016574382782,
        "train_loss": 2.9906671047210693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17811,
        "tokens": 9338093568,
        "learning_rate": 0.00026503074396798474,
        "gradient_norm": 0.3250303566455841,
        "train_loss": 3.008401870727539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17812,
        "tokens": 9338617856,
        "learning_rate": 0.0002650029402385126,
        "gradient_norm": 0.30378448963165283,
        "train_loss": 3.0142951011657715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17813,
        "tokens": 9339142144,
        "learning_rate": 0.00026497513724066347,
        "gradient_norm": 0.32351547479629517,
        "train_loss": 2.9906423091888428,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17814,
        "tokens": 9339666432,
        "learning_rate": 0.0002649473349747501,
        "gradient_norm": 0.3272852599620819,
        "train_loss": 3.0006611347198486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17815,
        "tokens": 9340190720,
        "learning_rate": 0.00026491953344108575,
        "gradient_norm": 0.347459614276886,
        "train_loss": 3.0622823238372803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17816,
        "tokens": 9340715008,
        "learning_rate": 0.0002648917326399829,
        "gradient_norm": 0.3544314503669739,
        "train_loss": 3.0269198417663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17817,
        "tokens": 9341239296,
        "learning_rate": 0.000264863932571755,
        "gradient_norm": 0.3612515926361084,
        "train_loss": 3.047135591506958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17818,
        "tokens": 9341763584,
        "learning_rate": 0.00026483613323671464,
        "gradient_norm": 0.47312265634536743,
        "train_loss": 3.05045223236084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17819,
        "tokens": 9342287872,
        "learning_rate": 0.0002648083346351749,
        "gradient_norm": 0.4015176594257355,
        "train_loss": 3.0455727577209473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17820,
        "tokens": 9342812160,
        "learning_rate": 0.0002647805367674485,
        "gradient_norm": 0.3528907895088196,
        "train_loss": 3.068739652633667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17821,
        "tokens": 9343336448,
        "learning_rate": 0.00026475273963384846,
        "gradient_norm": 0.3440980017185211,
        "train_loss": 3.0377602577209473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17822,
        "tokens": 9343860736,
        "learning_rate": 0.00026472494323468777,
        "gradient_norm": 0.35433876514434814,
        "train_loss": 3.0225467681884766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17823,
        "tokens": 9344385024,
        "learning_rate": 0.0002646971475702792,
        "gradient_norm": 0.39988139271736145,
        "train_loss": 3.0362377166748047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17824,
        "tokens": 9344909312,
        "learning_rate": 0.0002646693526409356,
        "gradient_norm": 0.3313695192337036,
        "train_loss": 3.0000698566436768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17825,
        "tokens": 9345433600,
        "learning_rate": 0.00026464155844696985,
        "gradient_norm": 0.3796956539154053,
        "train_loss": 3.0481982231140137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17826,
        "tokens": 9345957888,
        "learning_rate": 0.0002646137649886949,
        "gradient_norm": 0.3009148836135864,
        "train_loss": 3.028050661087036,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17827,
        "tokens": 9346482176,
        "learning_rate": 0.0002645859722664234,
        "gradient_norm": 0.347100168466568,
        "train_loss": 3.0042495727539062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17828,
        "tokens": 9347006464,
        "learning_rate": 0.00026455818028046853,
        "gradient_norm": 0.3066881597042084,
        "train_loss": 3.064594268798828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17829,
        "tokens": 9347530752,
        "learning_rate": 0.0002645303890311427,
        "gradient_norm": 0.34401488304138184,
        "train_loss": 3.0192790031433105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17830,
        "tokens": 9348055040,
        "learning_rate": 0.000264502598518759,
        "gradient_norm": 0.36029717326164246,
        "train_loss": 3.0234522819519043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17831,
        "tokens": 9348579328,
        "learning_rate": 0.00026447480874363034,
        "gradient_norm": 0.3394845426082611,
        "train_loss": 3.031494140625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17832,
        "tokens": 9349103616,
        "learning_rate": 0.00026444701970606925,
        "gradient_norm": 0.33095476031303406,
        "train_loss": 3.037980556488037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17833,
        "tokens": 9349627904,
        "learning_rate": 0.00026441923140638874,
        "gradient_norm": 0.33951887488365173,
        "train_loss": 3.1546273231506348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17834,
        "tokens": 9350152192,
        "learning_rate": 0.0002643914438449015,
        "gradient_norm": 0.3696802258491516,
        "train_loss": 3.050241708755493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17835,
        "tokens": 9350676480,
        "learning_rate": 0.00026436365702192037,
        "gradient_norm": 0.31272080540657043,
        "train_loss": 3.072345733642578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17836,
        "tokens": 9351200768,
        "learning_rate": 0.000264335870937758,
        "gradient_norm": 0.39148378372192383,
        "train_loss": 3.064732551574707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17837,
        "tokens": 9351725056,
        "learning_rate": 0.0002643080855927274,
        "gradient_norm": 0.3407335877418518,
        "train_loss": 3.026848316192627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17838,
        "tokens": 9352249344,
        "learning_rate": 0.000264280300987141,
        "gradient_norm": 0.33821195363998413,
        "train_loss": 3.0890207290649414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17839,
        "tokens": 9352773632,
        "learning_rate": 0.00026425251712131195,
        "gradient_norm": 0.38848620653152466,
        "train_loss": 3.0237739086151123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17840,
        "tokens": 9353297920,
        "learning_rate": 0.0002642247339955526,
        "gradient_norm": 0.39764076471328735,
        "train_loss": 3.0979628562927246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17841,
        "tokens": 9353822208,
        "learning_rate": 0.00026419695161017593,
        "gradient_norm": 0.3493402302265167,
        "train_loss": 3.055382251739502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17842,
        "tokens": 9354346496,
        "learning_rate": 0.0002641691699654946,
        "gradient_norm": 0.3587523400783539,
        "train_loss": 3.024867534637451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17843,
        "tokens": 9354870784,
        "learning_rate": 0.00026414138906182124,
        "gradient_norm": 0.3484306335449219,
        "train_loss": 3.0610103607177734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17844,
        "tokens": 9355395072,
        "learning_rate": 0.0002641136088994688,
        "gradient_norm": 0.39629554748535156,
        "train_loss": 3.050722599029541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17845,
        "tokens": 9355919360,
        "learning_rate": 0.00026408582947874974,
        "gradient_norm": 0.3526192307472229,
        "train_loss": 3.042478084564209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17846,
        "tokens": 9356443648,
        "learning_rate": 0.0002640580507999768,
        "gradient_norm": 0.3419629633426666,
        "train_loss": 3.038884162902832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17847,
        "tokens": 9356967936,
        "learning_rate": 0.0002640302728634627,
        "gradient_norm": 0.3470613956451416,
        "train_loss": 3.0366830825805664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17848,
        "tokens": 9357492224,
        "learning_rate": 0.00026400249566952024,
        "gradient_norm": 0.3280717730522156,
        "train_loss": 3.021869659423828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17849,
        "tokens": 9358016512,
        "learning_rate": 0.0002639747192184618,
        "gradient_norm": 0.3654690980911255,
        "train_loss": 3.0931944847106934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17850,
        "tokens": 9358540800,
        "learning_rate": 0.00026394694351060025,
        "gradient_norm": 0.34957942366600037,
        "train_loss": 3.0769553184509277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17851,
        "tokens": 9359065088,
        "learning_rate": 0.0002639191685462482,
        "gradient_norm": 0.33880189061164856,
        "train_loss": 3.0686023235321045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17852,
        "tokens": 9359589376,
        "learning_rate": 0.0002638913943257183,
        "gradient_norm": 0.3443523645401001,
        "train_loss": 2.996352195739746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17853,
        "tokens": 9360113664,
        "learning_rate": 0.00026386362084932316,
        "gradient_norm": 0.3868267834186554,
        "train_loss": 3.072340488433838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17854,
        "tokens": 9360637952,
        "learning_rate": 0.0002638358481173754,
        "gradient_norm": 0.3425649106502533,
        "train_loss": 3.086709499359131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17855,
        "tokens": 9361162240,
        "learning_rate": 0.0002638080761301876,
        "gradient_norm": 0.40180355310440063,
        "train_loss": 3.0960693359375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17856,
        "tokens": 9361686528,
        "learning_rate": 0.0002637803048880725,
        "gradient_norm": 0.3778817653656006,
        "train_loss": 3.0619378089904785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17857,
        "tokens": 9362210816,
        "learning_rate": 0.0002637525343913425,
        "gradient_norm": 0.30693379044532776,
        "train_loss": 3.014925241470337,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17858,
        "tokens": 9362735104,
        "learning_rate": 0.0002637247646403104,
        "gradient_norm": 0.3468073904514313,
        "train_loss": 3.065436840057373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17859,
        "tokens": 9363259392,
        "learning_rate": 0.0002636969956352887,
        "gradient_norm": 0.31841328740119934,
        "train_loss": 3.146686553955078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17860,
        "tokens": 9363783680,
        "learning_rate": 0.0002636692273765899,
        "gradient_norm": 0.3647249937057495,
        "train_loss": 3.0567941665649414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17861,
        "tokens": 9364307968,
        "learning_rate": 0.00026364145986452656,
        "gradient_norm": 0.36115512251853943,
        "train_loss": 3.0308876037597656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17862,
        "tokens": 9364832256,
        "learning_rate": 0.00026361369309941147,
        "gradient_norm": 0.3346897065639496,
        "train_loss": 3.03641939163208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17863,
        "tokens": 9365356544,
        "learning_rate": 0.0002635859270815569,
        "gradient_norm": 0.36505603790283203,
        "train_loss": 3.0794153213500977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17864,
        "tokens": 9365880832,
        "learning_rate": 0.00026355816181127564,
        "gradient_norm": 0.32559317350387573,
        "train_loss": 3.051440954208374,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17865,
        "tokens": 9366405120,
        "learning_rate": 0.0002635303972888799,
        "gradient_norm": 0.3704794943332672,
        "train_loss": 2.9785327911376953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17866,
        "tokens": 9366929408,
        "learning_rate": 0.00026350263351468254,
        "gradient_norm": 0.3624016046524048,
        "train_loss": 3.0711827278137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17867,
        "tokens": 9367453696,
        "learning_rate": 0.00026347487048899586,
        "gradient_norm": 0.3262614905834198,
        "train_loss": 3.0096230506896973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17868,
        "tokens": 9367977984,
        "learning_rate": 0.0002634471082121325,
        "gradient_norm": 0.39274314045906067,
        "train_loss": 3.0104010105133057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17869,
        "tokens": 9368502272,
        "learning_rate": 0.0002634193466844048,
        "gradient_norm": 0.32882416248321533,
        "train_loss": 3.017225742340088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17870,
        "tokens": 9369026560,
        "learning_rate": 0.00026339158590612535,
        "gradient_norm": 0.31592971086502075,
        "train_loss": 3.041679859161377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17871,
        "tokens": 9369550848,
        "learning_rate": 0.00026336382587760683,
        "gradient_norm": 0.40723446011543274,
        "train_loss": 3.0446557998657227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17872,
        "tokens": 9370075136,
        "learning_rate": 0.00026333606659916127,
        "gradient_norm": 0.38356447219848633,
        "train_loss": 3.0420823097229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17873,
        "tokens": 9370599424,
        "learning_rate": 0.0002633083080711016,
        "gradient_norm": 0.32838618755340576,
        "train_loss": 3.007143974304199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17874,
        "tokens": 9371123712,
        "learning_rate": 0.00026328055029373984,
        "gradient_norm": 0.43427425622940063,
        "train_loss": 3.0628814697265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17875,
        "tokens": 9371648000,
        "learning_rate": 0.0002632527932673888,
        "gradient_norm": 0.3329586982727051,
        "train_loss": 3.047497272491455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17876,
        "tokens": 9372172288,
        "learning_rate": 0.0002632250369923607,
        "gradient_norm": 0.35451310873031616,
        "train_loss": 3.032491683959961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17877,
        "tokens": 9372696576,
        "learning_rate": 0.0002631972814689681,
        "gradient_norm": 0.3543378412723541,
        "train_loss": 3.083202362060547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17878,
        "tokens": 9373220864,
        "learning_rate": 0.0002631695266975233,
        "gradient_norm": 0.3341626226902008,
        "train_loss": 3.006923198699951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17879,
        "tokens": 9373745152,
        "learning_rate": 0.0002631417726783389,
        "gradient_norm": 0.3829229474067688,
        "train_loss": 3.0196943283081055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17880,
        "tokens": 9374269440,
        "learning_rate": 0.00026311401941172706,
        "gradient_norm": 0.38954150676727295,
        "train_loss": 3.0386407375335693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17881,
        "tokens": 9374793728,
        "learning_rate": 0.0002630862668980003,
        "gradient_norm": 0.34417465329170227,
        "train_loss": 3.073521852493286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17882,
        "tokens": 9375318016,
        "learning_rate": 0.00026305851513747113,
        "gradient_norm": 0.3528486490249634,
        "train_loss": 3.1134591102600098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17883,
        "tokens": 9375842304,
        "learning_rate": 0.00026303076413045177,
        "gradient_norm": 0.34614694118499756,
        "train_loss": 3.026153326034546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17884,
        "tokens": 9376366592,
        "learning_rate": 0.00026300301387725464,
        "gradient_norm": 0.3384731411933899,
        "train_loss": 3.0810437202453613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17885,
        "tokens": 9376890880,
        "learning_rate": 0.00026297526437819206,
        "gradient_norm": 0.3317687213420868,
        "train_loss": 3.018765449523926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17886,
        "tokens": 9377415168,
        "learning_rate": 0.0002629475156335765,
        "gradient_norm": 0.32728317379951477,
        "train_loss": 3.103987216949463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17887,
        "tokens": 9377939456,
        "learning_rate": 0.0002629197676437202,
        "gradient_norm": 0.326193630695343,
        "train_loss": 3.0795817375183105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17888,
        "tokens": 9378463744,
        "learning_rate": 0.00026289202040893553,
        "gradient_norm": 0.33315446972846985,
        "train_loss": 3.0159521102905273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17889,
        "tokens": 9378988032,
        "learning_rate": 0.0002628642739295348,
        "gradient_norm": 0.31407153606414795,
        "train_loss": 3.037261486053467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17890,
        "tokens": 9379512320,
        "learning_rate": 0.00026283652820583033,
        "gradient_norm": 0.3262138366699219,
        "train_loss": 3.0806431770324707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17891,
        "tokens": 9380036608,
        "learning_rate": 0.00026280878323813457,
        "gradient_norm": 0.31317558884620667,
        "train_loss": 3.082287311553955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17892,
        "tokens": 9380560896,
        "learning_rate": 0.0002627810390267596,
        "gradient_norm": 0.33313754200935364,
        "train_loss": 3.0324339866638184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17893,
        "tokens": 9381085184,
        "learning_rate": 0.00026275329557201793,
        "gradient_norm": 0.31876468658447266,
        "train_loss": 3.071326732635498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17894,
        "tokens": 9381609472,
        "learning_rate": 0.00026272555287422167,
        "gradient_norm": 0.32128244638442993,
        "train_loss": 3.0491297245025635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17895,
        "tokens": 9382133760,
        "learning_rate": 0.0002626978109336832,
        "gradient_norm": 0.3130093514919281,
        "train_loss": 3.0919957160949707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17896,
        "tokens": 9382658048,
        "learning_rate": 0.0002626700697507147,
        "gradient_norm": 0.34496408700942993,
        "train_loss": 3.042499542236328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17897,
        "tokens": 9383182336,
        "learning_rate": 0.0002626423293256286,
        "gradient_norm": 0.3460358679294586,
        "train_loss": 3.0449061393737793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17898,
        "tokens": 9383706624,
        "learning_rate": 0.000262614589658737,
        "gradient_norm": 0.33534762263298035,
        "train_loss": 3.018218994140625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17899,
        "tokens": 9384230912,
        "learning_rate": 0.0002625868507503522,
        "gradient_norm": 0.34318527579307556,
        "train_loss": 3.053288698196411,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17900,
        "tokens": 9384755200,
        "learning_rate": 0.0002625591126007863,
        "gradient_norm": 0.3105311393737793,
        "train_loss": 3.0470709800720215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17901,
        "tokens": 9385279488,
        "learning_rate": 0.0002625313752103518,
        "gradient_norm": 0.3648841679096222,
        "train_loss": 3.11295223236084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17902,
        "tokens": 9385803776,
        "learning_rate": 0.00026250363857936075,
        "gradient_norm": 0.3299870789051056,
        "train_loss": 3.070220708847046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17903,
        "tokens": 9386328064,
        "learning_rate": 0.0002624759027081254,
        "gradient_norm": 0.3609478175640106,
        "train_loss": 3.0598888397216797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17904,
        "tokens": 9386852352,
        "learning_rate": 0.0002624481675969579,
        "gradient_norm": 0.3054835796356201,
        "train_loss": 3.0350465774536133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17905,
        "tokens": 9387376640,
        "learning_rate": 0.00026242043324617046,
        "gradient_norm": 0.42507052421569824,
        "train_loss": 3.0429041385650635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17906,
        "tokens": 9387900928,
        "learning_rate": 0.00026239269965607534,
        "gradient_norm": 0.344472736120224,
        "train_loss": 3.0905568599700928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17907,
        "tokens": 9388425216,
        "learning_rate": 0.00026236496682698464,
        "gradient_norm": 0.345577597618103,
        "train_loss": 3.1007590293884277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17908,
        "tokens": 9388949504,
        "learning_rate": 0.0002623372347592105,
        "gradient_norm": 0.3306047320365906,
        "train_loss": 3.0547008514404297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17909,
        "tokens": 9389473792,
        "learning_rate": 0.0002623095034530652,
        "gradient_norm": 0.30737337470054626,
        "train_loss": 3.0515763759613037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17910,
        "tokens": 9389998080,
        "learning_rate": 0.0002622817729088607,
        "gradient_norm": 0.30254754424095154,
        "train_loss": 3.1043992042541504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17911,
        "tokens": 9390522368,
        "learning_rate": 0.00026225404312690945,
        "gradient_norm": 0.286396861076355,
        "train_loss": 3.051175594329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17912,
        "tokens": 9391046656,
        "learning_rate": 0.00026222631410752326,
        "gradient_norm": 0.2794162929058075,
        "train_loss": 3.106660842895508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17913,
        "tokens": 9391570944,
        "learning_rate": 0.00026219858585101435,
        "gradient_norm": 0.3073364198207855,
        "train_loss": 3.061941623687744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17914,
        "tokens": 9392095232,
        "learning_rate": 0.00026217085835769497,
        "gradient_norm": 0.3574214577674866,
        "train_loss": 3.0523605346679688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17915,
        "tokens": 9392619520,
        "learning_rate": 0.00026214313162787706,
        "gradient_norm": 0.3224187195301056,
        "train_loss": 3.054351568222046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17916,
        "tokens": 9393143808,
        "learning_rate": 0.0002621154056618729,
        "gradient_norm": 0.32251304388046265,
        "train_loss": 3.052593946456909,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17917,
        "tokens": 9393668096,
        "learning_rate": 0.0002620876804599944,
        "gradient_norm": 0.42750605940818787,
        "train_loss": 3.097405433654785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17918,
        "tokens": 9394192384,
        "learning_rate": 0.0002620599560225537,
        "gradient_norm": 0.34633803367614746,
        "train_loss": 3.1143932342529297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17919,
        "tokens": 9394716672,
        "learning_rate": 0.0002620322323498629,
        "gradient_norm": 0.3872743248939514,
        "train_loss": 3.119256019592285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17920,
        "tokens": 9395240960,
        "learning_rate": 0.00026200450944223404,
        "gradient_norm": 0.3394549787044525,
        "train_loss": 3.0322365760803223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17921,
        "tokens": 9395765248,
        "learning_rate": 0.00026197678729997914,
        "gradient_norm": 0.4054049551486969,
        "train_loss": 3.1080539226531982,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17922,
        "tokens": 9396289536,
        "learning_rate": 0.0002619490659234104,
        "gradient_norm": 0.393930047750473,
        "train_loss": 3.150916814804077,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17923,
        "tokens": 9396813824,
        "learning_rate": 0.0002619213453128396,
        "gradient_norm": 0.3635317385196686,
        "train_loss": 3.0632734298706055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17924,
        "tokens": 9397338112,
        "learning_rate": 0.0002618936254685791,
        "gradient_norm": 0.4257880449295044,
        "train_loss": 3.1076297760009766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17925,
        "tokens": 9397862400,
        "learning_rate": 0.0002618659063909406,
        "gradient_norm": 0.32091909646987915,
        "train_loss": 3.0750792026519775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17926,
        "tokens": 9398386688,
        "learning_rate": 0.00026183818808023636,
        "gradient_norm": 0.4112292528152466,
        "train_loss": 3.050753355026245,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17927,
        "tokens": 9398910976,
        "learning_rate": 0.0002618104705367781,
        "gradient_norm": 0.3438628017902374,
        "train_loss": 3.1258974075317383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17928,
        "tokens": 9399435264,
        "learning_rate": 0.00026178275376087827,
        "gradient_norm": 0.4371351897716522,
        "train_loss": 3.1288137435913086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17929,
        "tokens": 9399959552,
        "learning_rate": 0.0002617550377528483,
        "gradient_norm": 0.34625259041786194,
        "train_loss": 3.121399402618408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17930,
        "tokens": 9400483840,
        "learning_rate": 0.0002617273225130006,
        "gradient_norm": 0.4059770107269287,
        "train_loss": 3.08156156539917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17931,
        "tokens": 9401008128,
        "learning_rate": 0.000261699608041647,
        "gradient_norm": 0.33471062779426575,
        "train_loss": 3.0736889839172363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17932,
        "tokens": 9401532416,
        "learning_rate": 0.0002616718943390994,
        "gradient_norm": 0.3796252906322479,
        "train_loss": 3.129988670349121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17933,
        "tokens": 9402056704,
        "learning_rate": 0.00026164418140566984,
        "gradient_norm": 0.37875667214393616,
        "train_loss": 3.130377769470215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17934,
        "tokens": 9402580992,
        "learning_rate": 0.00026161646924167015,
        "gradient_norm": 0.39199692010879517,
        "train_loss": 3.0585851669311523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17935,
        "tokens": 9403105280,
        "learning_rate": 0.0002615887578474125,
        "gradient_norm": 0.3872866630554199,
        "train_loss": 3.101447582244873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17936,
        "tokens": 9403629568,
        "learning_rate": 0.00026156104722320847,
        "gradient_norm": 0.33667945861816406,
        "train_loss": 3.08821177482605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17937,
        "tokens": 9404153856,
        "learning_rate": 0.0002615333373693703,
        "gradient_norm": 0.3923015594482422,
        "train_loss": 3.0505099296569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17938,
        "tokens": 9404678144,
        "learning_rate": 0.0002615056282862097,
        "gradient_norm": 0.3672631084918976,
        "train_loss": 3.1006665229797363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17939,
        "tokens": 9405202432,
        "learning_rate": 0.00026147791997403866,
        "gradient_norm": 0.3712369203567505,
        "train_loss": 2.9944117069244385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17940,
        "tokens": 9405726720,
        "learning_rate": 0.000261450212433169,
        "gradient_norm": 0.3873651623725891,
        "train_loss": 3.1261935234069824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17941,
        "tokens": 9406251008,
        "learning_rate": 0.00026142250566391263,
        "gradient_norm": 0.40631890296936035,
        "train_loss": 3.101327419281006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17942,
        "tokens": 9406775296,
        "learning_rate": 0.00026139479966658157,
        "gradient_norm": 0.3782871961593628,
        "train_loss": 3.1147654056549072,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17943,
        "tokens": 9407299584,
        "learning_rate": 0.00026136709444148743,
        "gradient_norm": 0.3796398639678955,
        "train_loss": 3.1283035278320312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17944,
        "tokens": 9407823872,
        "learning_rate": 0.0002613393899889423,
        "gradient_norm": 0.36425092816352844,
        "train_loss": 3.1187846660614014,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17945,
        "tokens": 9408348160,
        "learning_rate": 0.0002613116863092578,
        "gradient_norm": 0.3858524560928345,
        "train_loss": 3.022921562194824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17946,
        "tokens": 9408872448,
        "learning_rate": 0.000261283983402746,
        "gradient_norm": 0.368705153465271,
        "train_loss": 3.056684970855713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17947,
        "tokens": 9409396736,
        "learning_rate": 0.0002612562812697186,
        "gradient_norm": 0.4000495374202728,
        "train_loss": 3.110567808151245,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17948,
        "tokens": 9409921024,
        "learning_rate": 0.0002612285799104875,
        "gradient_norm": 0.34466850757598877,
        "train_loss": 3.1147565841674805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17949,
        "tokens": 9410445312,
        "learning_rate": 0.0002612008793253643,
        "gradient_norm": 0.4003329575061798,
        "train_loss": 3.076491355895996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17950,
        "tokens": 9410969600,
        "learning_rate": 0.000261173179514661,
        "gradient_norm": 0.33922263979911804,
        "train_loss": 3.09454083442688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17951,
        "tokens": 9411493888,
        "learning_rate": 0.0002611454804786895,
        "gradient_norm": 0.3865620791912079,
        "train_loss": 3.0702338218688965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17952,
        "tokens": 9412018176,
        "learning_rate": 0.0002611177822177613,
        "gradient_norm": 0.35386839509010315,
        "train_loss": 3.092139720916748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17953,
        "tokens": 9412542464,
        "learning_rate": 0.00026109008473218845,
        "gradient_norm": 0.388901948928833,
        "train_loss": 3.0129661560058594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17954,
        "tokens": 9413066752,
        "learning_rate": 0.00026106238802228244,
        "gradient_norm": 0.35979747772216797,
        "train_loss": 3.058356761932373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17955,
        "tokens": 9413591040,
        "learning_rate": 0.0002610346920883554,
        "gradient_norm": 0.3769530951976776,
        "train_loss": 3.0881500244140625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17956,
        "tokens": 9414115328,
        "learning_rate": 0.0002610069969307187,
        "gradient_norm": 0.35356613993644714,
        "train_loss": 3.0855093002319336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17957,
        "tokens": 9414639616,
        "learning_rate": 0.00026097930254968436,
        "gradient_norm": 0.33686137199401855,
        "train_loss": 3.0952162742614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17958,
        "tokens": 9415163904,
        "learning_rate": 0.0002609516089455639,
        "gradient_norm": 0.33567845821380615,
        "train_loss": 3.130743980407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17959,
        "tokens": 9415688192,
        "learning_rate": 0.00026092391611866913,
        "gradient_norm": 0.3386746048927307,
        "train_loss": 3.045581340789795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17960,
        "tokens": 9416212480,
        "learning_rate": 0.0002608962240693119,
        "gradient_norm": 0.33254387974739075,
        "train_loss": 3.0662295818328857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17961,
        "tokens": 9416736768,
        "learning_rate": 0.0002608685327978038,
        "gradient_norm": 0.33016642928123474,
        "train_loss": 3.1087512969970703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17962,
        "tokens": 9417261056,
        "learning_rate": 0.00026084084230445647,
        "gradient_norm": 0.3469478189945221,
        "train_loss": 3.051729202270508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17963,
        "tokens": 9417785344,
        "learning_rate": 0.00026081315258958174,
        "gradient_norm": 0.32104501128196716,
        "train_loss": 3.053502082824707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17964,
        "tokens": 9418309632,
        "learning_rate": 0.0002607854636534912,
        "gradient_norm": 0.31781089305877686,
        "train_loss": 3.0608768463134766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17965,
        "tokens": 9418833920,
        "learning_rate": 0.00026075777549649647,
        "gradient_norm": 0.4245048463344574,
        "train_loss": 3.172999382019043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17966,
        "tokens": 9419358208,
        "learning_rate": 0.0002607300881189094,
        "gradient_norm": 0.4309495985507965,
        "train_loss": 3.079648971557617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17967,
        "tokens": 9419882496,
        "learning_rate": 0.0002607024015210415,
        "gradient_norm": 0.34980714321136475,
        "train_loss": 3.0878748893737793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17968,
        "tokens": 9420406784,
        "learning_rate": 0.0002606747157032044,
        "gradient_norm": 0.46339333057403564,
        "train_loss": 3.0996575355529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17969,
        "tokens": 9420931072,
        "learning_rate": 0.0002606470306657098,
        "gradient_norm": 0.41594013571739197,
        "train_loss": 3.0981740951538086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17970,
        "tokens": 9421455360,
        "learning_rate": 0.0002606193464088694,
        "gradient_norm": 0.3481917977333069,
        "train_loss": 3.0938072204589844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17971,
        "tokens": 9421979648,
        "learning_rate": 0.0002605916629329947,
        "gradient_norm": 0.38042813539505005,
        "train_loss": 3.0799400806427,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17972,
        "tokens": 9422503936,
        "learning_rate": 0.0002605639802383973,
        "gradient_norm": 0.3582376539707184,
        "train_loss": 3.0665712356567383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17973,
        "tokens": 9423028224,
        "learning_rate": 0.00026053629832538893,
        "gradient_norm": 0.3138374090194702,
        "train_loss": 3.1331543922424316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17974,
        "tokens": 9423552512,
        "learning_rate": 0.00026050861719428104,
        "gradient_norm": 0.3272159695625305,
        "train_loss": 3.073685646057129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17975,
        "tokens": 9424076800,
        "learning_rate": 0.0002604809368453854,
        "gradient_norm": 0.36639606952667236,
        "train_loss": 3.126633644104004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17976,
        "tokens": 9424601088,
        "learning_rate": 0.0002604532572790133,
        "gradient_norm": 0.3537086844444275,
        "train_loss": 3.0645601749420166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17977,
        "tokens": 9425125376,
        "learning_rate": 0.0002604255784954767,
        "gradient_norm": 0.45803505182266235,
        "train_loss": 3.3043642044067383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17978,
        "tokens": 9425649664,
        "learning_rate": 0.00026039790049508675,
        "gradient_norm": 0.3958653211593628,
        "train_loss": 3.093381881713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17979,
        "tokens": 9426173952,
        "learning_rate": 0.0002603702232781552,
        "gradient_norm": 0.381788045167923,
        "train_loss": 3.0934934616088867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17980,
        "tokens": 9426698240,
        "learning_rate": 0.0002603425468449937,
        "gradient_norm": 0.37256017327308655,
        "train_loss": 3.1132078170776367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17981,
        "tokens": 9427222528,
        "learning_rate": 0.0002603148711959136,
        "gradient_norm": 0.37544557452201843,
        "train_loss": 3.070249319076538,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17982,
        "tokens": 9427746816,
        "learning_rate": 0.00026028719633122656,
        "gradient_norm": 0.32959064841270447,
        "train_loss": 3.149102210998535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17983,
        "tokens": 9428271104,
        "learning_rate": 0.00026025952225124387,
        "gradient_norm": 0.3701730966567993,
        "train_loss": 3.0516819953918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17984,
        "tokens": 9428795392,
        "learning_rate": 0.00026023184895627733,
        "gradient_norm": 0.34015390276908875,
        "train_loss": 3.0607526302337646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17985,
        "tokens": 9429319680,
        "learning_rate": 0.0002602041764466382,
        "gradient_norm": 0.32984820008277893,
        "train_loss": 3.098644733428955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17986,
        "tokens": 9429843968,
        "learning_rate": 0.00026017650472263823,
        "gradient_norm": 0.3145376145839691,
        "train_loss": 3.0867671966552734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17987,
        "tokens": 9430368256,
        "learning_rate": 0.00026014883378458855,
        "gradient_norm": 0.327623575925827,
        "train_loss": 3.0706543922424316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17988,
        "tokens": 9430892544,
        "learning_rate": 0.000260121163632801,
        "gradient_norm": 0.33092594146728516,
        "train_loss": 3.10374116897583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17989,
        "tokens": 9431416832,
        "learning_rate": 0.0002600934942675867,
        "gradient_norm": 0.314609169960022,
        "train_loss": 3.065173625946045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17990,
        "tokens": 9431941120,
        "learning_rate": 0.0002600658256892572,
        "gradient_norm": 0.33620065450668335,
        "train_loss": 3.0564136505126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17991,
        "tokens": 9432465408,
        "learning_rate": 0.00026003815789812424,
        "gradient_norm": 0.33713990449905396,
        "train_loss": 3.1043925285339355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17992,
        "tokens": 9432989696,
        "learning_rate": 0.00026001049089449885,
        "gradient_norm": 0.3193104565143585,
        "train_loss": 3.0185179710388184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17993,
        "tokens": 9433513984,
        "learning_rate": 0.00025998282467869276,
        "gradient_norm": 0.34379926323890686,
        "train_loss": 3.053955554962158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17994,
        "tokens": 9434038272,
        "learning_rate": 0.0002599551592510171,
        "gradient_norm": 0.39496564865112305,
        "train_loss": 3.0732240676879883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17995,
        "tokens": 9434562560,
        "learning_rate": 0.0002599274946117836,
        "gradient_norm": 0.3469618260860443,
        "train_loss": 3.049867630004883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17996,
        "tokens": 9435086848,
        "learning_rate": 0.00025989983076130335,
        "gradient_norm": 0.3154664933681488,
        "train_loss": 3.0143322944641113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17997,
        "tokens": 9435611136,
        "learning_rate": 0.000259872167699888,
        "gradient_norm": 0.3532142639160156,
        "train_loss": 3.1338419914245605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17998,
        "tokens": 9436135424,
        "learning_rate": 0.00025984450542784873,
        "gradient_norm": 0.34280574321746826,
        "train_loss": 3.104743719100952,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17999,
        "tokens": 9436659712,
        "learning_rate": 0.000259816843945497,
        "gradient_norm": 0.3302885591983795,
        "train_loss": 3.0957911014556885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18000,
        "tokens": 9437184000,
        "learning_rate": 0.0002597891832531443,
        "gradient_norm": 0.37128469347953796,
        "train_loss": 3.0517678260803223,
        "val_loss": 3.040520191192627,
        "hellaswag_acc": 0.28121888637542725,
        "hellaswag_acc_norm": 0.28858792781829834
    },
    {
        "step": 18001,
        "tokens": 9437708288,
        "learning_rate": 0.0002597615233511017,
        "gradient_norm": 0.3447263538837433,
        "train_loss": 3.1003165245056152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18002,
        "tokens": 9438232576,
        "learning_rate": 0.00025973386423968085,
        "gradient_norm": 0.34064343571662903,
        "train_loss": 3.083773612976074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18003,
        "tokens": 9438756864,
        "learning_rate": 0.0002597062059191929,
        "gradient_norm": 0.3522875905036926,
        "train_loss": 3.107081890106201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18004,
        "tokens": 9439281152,
        "learning_rate": 0.00025967854838994923,
        "gradient_norm": 0.3307606875896454,
        "train_loss": 3.0861682891845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18005,
        "tokens": 9439805440,
        "learning_rate": 0.0002596508916522611,
        "gradient_norm": 0.32571327686309814,
        "train_loss": 3.0569169521331787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18006,
        "tokens": 9440329728,
        "learning_rate": 0.00025962323570644,
        "gradient_norm": 0.33860456943511963,
        "train_loss": 3.0556201934814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18007,
        "tokens": 9440854016,
        "learning_rate": 0.00025959558055279697,
        "gradient_norm": 0.3262825608253479,
        "train_loss": 3.1099939346313477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18008,
        "tokens": 9441378304,
        "learning_rate": 0.0002595679261916435,
        "gradient_norm": 0.38061457872390747,
        "train_loss": 3.0926971435546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18009,
        "tokens": 9441902592,
        "learning_rate": 0.00025954027262329086,
        "gradient_norm": 0.3801274001598358,
        "train_loss": 3.0199522972106934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18010,
        "tokens": 9442426880,
        "learning_rate": 0.0002595126198480502,
        "gradient_norm": 0.3695376515388489,
        "train_loss": 3.0714824199676514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18011,
        "tokens": 9442951168,
        "learning_rate": 0.00025948496786623294,
        "gradient_norm": 0.35760554671287537,
        "train_loss": 3.0807433128356934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18012,
        "tokens": 9443475456,
        "learning_rate": 0.0002594573166781502,
        "gradient_norm": 0.41846877336502075,
        "train_loss": 3.0869622230529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18013,
        "tokens": 9443999744,
        "learning_rate": 0.0002594296662841133,
        "gradient_norm": 0.3727530539035797,
        "train_loss": 3.0567712783813477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18014,
        "tokens": 9444524032,
        "learning_rate": 0.00025940201668443356,
        "gradient_norm": 0.33653783798217773,
        "train_loss": 3.0635151863098145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18015,
        "tokens": 9445048320,
        "learning_rate": 0.00025937436787942206,
        "gradient_norm": 0.3803379535675049,
        "train_loss": 3.0904784202575684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18016,
        "tokens": 9445572608,
        "learning_rate": 0.0002593467198693901,
        "gradient_norm": 0.29939860105514526,
        "train_loss": 3.0833206176757812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18017,
        "tokens": 9446096896,
        "learning_rate": 0.00025931907265464883,
        "gradient_norm": 0.3695926070213318,
        "train_loss": 3.0870230197906494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18018,
        "tokens": 9446621184,
        "learning_rate": 0.0002592914262355096,
        "gradient_norm": 0.3074624836444855,
        "train_loss": 3.0775656700134277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18019,
        "tokens": 9447145472,
        "learning_rate": 0.0002592637806122834,
        "gradient_norm": 0.38207629323005676,
        "train_loss": 3.1031603813171387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18020,
        "tokens": 9447669760,
        "learning_rate": 0.00025923613578528166,
        "gradient_norm": 0.3038111925125122,
        "train_loss": 3.0760011672973633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18021,
        "tokens": 9448194048,
        "learning_rate": 0.00025920849175481523,
        "gradient_norm": 0.32851237058639526,
        "train_loss": 3.0918755531311035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18022,
        "tokens": 9448718336,
        "learning_rate": 0.00025918084852119566,
        "gradient_norm": 0.39408183097839355,
        "train_loss": 3.125075101852417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18023,
        "tokens": 9449242624,
        "learning_rate": 0.00025915320608473384,
        "gradient_norm": 0.43977075815200806,
        "train_loss": 3.039074420928955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18024,
        "tokens": 9449766912,
        "learning_rate": 0.00025912556444574104,
        "gradient_norm": 0.3290596902370453,
        "train_loss": 3.091614246368408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18025,
        "tokens": 9450291200,
        "learning_rate": 0.00025909792360452827,
        "gradient_norm": 0.42515504360198975,
        "train_loss": 3.108461618423462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18026,
        "tokens": 9450815488,
        "learning_rate": 0.0002590702835614068,
        "gradient_norm": 0.35241609811782837,
        "train_loss": 3.088535785675049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18027,
        "tokens": 9451339776,
        "learning_rate": 0.0002590426443166877,
        "gradient_norm": 0.34200921654701233,
        "train_loss": 3.062775135040283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18028,
        "tokens": 9451864064,
        "learning_rate": 0.0002590150058706821,
        "gradient_norm": 0.3361821174621582,
        "train_loss": 3.073235034942627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18029,
        "tokens": 9452388352,
        "learning_rate": 0.00025898736822370106,
        "gradient_norm": 0.3595048189163208,
        "train_loss": 3.0873405933380127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18030,
        "tokens": 9452912640,
        "learning_rate": 0.00025895973137605565,
        "gradient_norm": 0.33673936128616333,
        "train_loss": 3.0593225955963135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18031,
        "tokens": 9453436928,
        "learning_rate": 0.0002589320953280572,
        "gradient_norm": 0.32699763774871826,
        "train_loss": 3.1082067489624023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18032,
        "tokens": 9453961216,
        "learning_rate": 0.0002589044600800164,
        "gradient_norm": 0.33094528317451477,
        "train_loss": 3.099853038787842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18033,
        "tokens": 9454485504,
        "learning_rate": 0.00025887682563224476,
        "gradient_norm": 0.3327834904193878,
        "train_loss": 3.0721237659454346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18034,
        "tokens": 9455009792,
        "learning_rate": 0.00025884919198505287,
        "gradient_norm": 0.32727813720703125,
        "train_loss": 3.113882541656494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18035,
        "tokens": 9455534080,
        "learning_rate": 0.00025882155913875223,
        "gradient_norm": 0.3539220690727234,
        "train_loss": 3.0799334049224854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18036,
        "tokens": 9456058368,
        "learning_rate": 0.00025879392709365353,
        "gradient_norm": 0.3040081262588501,
        "train_loss": 3.102876663208008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18037,
        "tokens": 9456582656,
        "learning_rate": 0.00025876629585006803,
        "gradient_norm": 0.37444978952407837,
        "train_loss": 3.0995235443115234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18038,
        "tokens": 9457106944,
        "learning_rate": 0.00025873866540830653,
        "gradient_norm": 0.7655528783798218,
        "train_loss": 2.964724540710449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18039,
        "tokens": 9457631232,
        "learning_rate": 0.0002587110357686802,
        "gradient_norm": 0.4195021092891693,
        "train_loss": 3.083735942840576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18040,
        "tokens": 9458155520,
        "learning_rate": 0.00025868340693150016,
        "gradient_norm": 0.39662882685661316,
        "train_loss": 3.0914740562438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18041,
        "tokens": 9458679808,
        "learning_rate": 0.00025865577889707715,
        "gradient_norm": 0.36708420515060425,
        "train_loss": 3.12001371383667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18042,
        "tokens": 9459204096,
        "learning_rate": 0.0002586281516657224,
        "gradient_norm": 0.3944169580936432,
        "train_loss": 3.095104932785034,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18043,
        "tokens": 9459728384,
        "learning_rate": 0.00025860052523774663,
        "gradient_norm": 0.5179060697555542,
        "train_loss": 3.1539852619171143,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18044,
        "tokens": 9460252672,
        "learning_rate": 0.0002585728996134611,
        "gradient_norm": 0.3959152102470398,
        "train_loss": 3.0746681690216064,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18045,
        "tokens": 9460776960,
        "learning_rate": 0.0002585452747931765,
        "gradient_norm": 0.3793018162250519,
        "train_loss": 3.132327079772949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18046,
        "tokens": 9461301248,
        "learning_rate": 0.000258517650777204,
        "gradient_norm": 0.33725547790527344,
        "train_loss": 3.1027722358703613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18047,
        "tokens": 9461825536,
        "learning_rate": 0.00025849002756585433,
        "gradient_norm": 0.3850157856941223,
        "train_loss": 3.101146697998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18048,
        "tokens": 9462349824,
        "learning_rate": 0.00025846240515943865,
        "gradient_norm": 0.36402976512908936,
        "train_loss": 3.0700783729553223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18049,
        "tokens": 9462874112,
        "learning_rate": 0.0002584347835582676,
        "gradient_norm": 0.4049549102783203,
        "train_loss": 3.1034860610961914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18050,
        "tokens": 9463398400,
        "learning_rate": 0.0002584071627626524,
        "gradient_norm": 0.3741692304611206,
        "train_loss": 3.0789682865142822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18051,
        "tokens": 9463922688,
        "learning_rate": 0.00025837954277290387,
        "gradient_norm": 0.3229074478149414,
        "train_loss": 3.08945369720459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18052,
        "tokens": 9464446976,
        "learning_rate": 0.00025835192358933276,
        "gradient_norm": 0.3942388594150543,
        "train_loss": 3.080235004425049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18053,
        "tokens": 9464971264,
        "learning_rate": 0.0002583243052122502,
        "gradient_norm": 0.34589359164237976,
        "train_loss": 3.104609489440918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18054,
        "tokens": 9465495552,
        "learning_rate": 0.0002582966876419668,
        "gradient_norm": 0.38184067606925964,
        "train_loss": 3.0920352935791016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18055,
        "tokens": 9466019840,
        "learning_rate": 0.0002582690708787936,
        "gradient_norm": 0.34406188130378723,
        "train_loss": 3.061910629272461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18056,
        "tokens": 9466544128,
        "learning_rate": 0.0002582414549230414,
        "gradient_norm": 0.42197880148887634,
        "train_loss": 3.060396194458008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18057,
        "tokens": 9467068416,
        "learning_rate": 0.0002582138397750212,
        "gradient_norm": 0.32404154539108276,
        "train_loss": 3.045804023742676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18058,
        "tokens": 9467592704,
        "learning_rate": 0.00025818622543504356,
        "gradient_norm": 0.35907649993896484,
        "train_loss": 3.0959091186523438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18059,
        "tokens": 9468116992,
        "learning_rate": 0.0002581586119034195,
        "gradient_norm": 0.36090365052223206,
        "train_loss": 3.056286334991455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18060,
        "tokens": 9468641280,
        "learning_rate": 0.0002581309991804599,
        "gradient_norm": 0.34340640902519226,
        "train_loss": 3.0843005180358887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18061,
        "tokens": 9469165568,
        "learning_rate": 0.00025810338726647543,
        "gradient_norm": 0.3950949013233185,
        "train_loss": 3.09611177444458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18062,
        "tokens": 9469689856,
        "learning_rate": 0.00025807577616177696,
        "gradient_norm": 0.3482772707939148,
        "train_loss": 3.0991556644439697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18063,
        "tokens": 9470214144,
        "learning_rate": 0.0002580481658666753,
        "gradient_norm": 0.3852179944515228,
        "train_loss": 3.054847240447998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18064,
        "tokens": 9470738432,
        "learning_rate": 0.0002580205563814812,
        "gradient_norm": 0.35116809606552124,
        "train_loss": 3.0842647552490234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18065,
        "tokens": 9471262720,
        "learning_rate": 0.00025799294770650547,
        "gradient_norm": 0.34272584319114685,
        "train_loss": 3.119439125061035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18066,
        "tokens": 9471787008,
        "learning_rate": 0.00025796533984205893,
        "gradient_norm": 0.302334725856781,
        "train_loss": 3.1027896404266357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18067,
        "tokens": 9472311296,
        "learning_rate": 0.0002579377327884522,
        "gradient_norm": 0.36392414569854736,
        "train_loss": 3.0780463218688965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18068,
        "tokens": 9472835584,
        "learning_rate": 0.0002579101265459962,
        "gradient_norm": 0.29982396960258484,
        "train_loss": 3.1032116413116455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18069,
        "tokens": 9473359872,
        "learning_rate": 0.0002578825211150015,
        "gradient_norm": 0.3766520321369171,
        "train_loss": 3.1594600677490234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18070,
        "tokens": 9473884160,
        "learning_rate": 0.0002578549164957789,
        "gradient_norm": 0.3071945905685425,
        "train_loss": 3.0511598587036133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18071,
        "tokens": 9474408448,
        "learning_rate": 0.0002578273126886393,
        "gradient_norm": 0.36293360590934753,
        "train_loss": 3.0384297370910645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18072,
        "tokens": 9474932736,
        "learning_rate": 0.00025779970969389313,
        "gradient_norm": 0.3199250400066376,
        "train_loss": 3.0536043643951416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18073,
        "tokens": 9475457024,
        "learning_rate": 0.0002577721075118513,
        "gradient_norm": 0.3247928321361542,
        "train_loss": 3.0493767261505127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18074,
        "tokens": 9475981312,
        "learning_rate": 0.00025774450614282434,
        "gradient_norm": 0.3104100227355957,
        "train_loss": 3.0734729766845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18075,
        "tokens": 9476505600,
        "learning_rate": 0.00025771690558712315,
        "gradient_norm": 0.3314211964607239,
        "train_loss": 3.124148368835449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18076,
        "tokens": 9477029888,
        "learning_rate": 0.0002576893058450582,
        "gradient_norm": 0.2987198233604431,
        "train_loss": 3.075061321258545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18077,
        "tokens": 9477554176,
        "learning_rate": 0.0002576617069169403,
        "gradient_norm": 0.3154730796813965,
        "train_loss": 3.0595192909240723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18078,
        "tokens": 9478078464,
        "learning_rate": 0.00025763410880308,
        "gradient_norm": 0.34731048345565796,
        "train_loss": 3.044524908065796,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18079,
        "tokens": 9478602752,
        "learning_rate": 0.00025760651150378796,
        "gradient_norm": 0.3176942467689514,
        "train_loss": 3.162092447280884,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18080,
        "tokens": 9479127040,
        "learning_rate": 0.0002575789150193751,
        "gradient_norm": 0.34725889563560486,
        "train_loss": 3.1270265579223633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18081,
        "tokens": 9479651328,
        "learning_rate": 0.0002575513193501516,
        "gradient_norm": 0.3244940936565399,
        "train_loss": 3.105436325073242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18082,
        "tokens": 9480175616,
        "learning_rate": 0.00025752372449642846,
        "gradient_norm": 0.34917697310447693,
        "train_loss": 3.040456533432007,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18083,
        "tokens": 9480699904,
        "learning_rate": 0.000257496130458516,
        "gradient_norm": 0.34229302406311035,
        "train_loss": 3.063978672027588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18084,
        "tokens": 9481224192,
        "learning_rate": 0.00025746853723672517,
        "gradient_norm": 0.3438918888568878,
        "train_loss": 3.087792158126831,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18085,
        "tokens": 9481748480,
        "learning_rate": 0.0002574409448313662,
        "gradient_norm": 0.3308762311935425,
        "train_loss": 3.1022119522094727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18086,
        "tokens": 9482272768,
        "learning_rate": 0.00025741335324275,
        "gradient_norm": 0.3236595392227173,
        "train_loss": 3.0541508197784424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18087,
        "tokens": 9482797056,
        "learning_rate": 0.0002573857624711868,
        "gradient_norm": 0.3142557740211487,
        "train_loss": 3.030155658721924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18088,
        "tokens": 9483321344,
        "learning_rate": 0.0002573581725169875,
        "gradient_norm": 0.33732300996780396,
        "train_loss": 3.0842208862304688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18089,
        "tokens": 9483845632,
        "learning_rate": 0.00025733058338046243,
        "gradient_norm": 0.409626305103302,
        "train_loss": 3.2605957984924316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18090,
        "tokens": 9484369920,
        "learning_rate": 0.00025730299506192223,
        "gradient_norm": 0.37700366973876953,
        "train_loss": 3.034362316131592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18091,
        "tokens": 9484894208,
        "learning_rate": 0.0002572754075616775,
        "gradient_norm": 0.34152594208717346,
        "train_loss": 3.071536064147949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18092,
        "tokens": 9485418496,
        "learning_rate": 0.00025724782088003864,
        "gradient_norm": 0.4297848641872406,
        "train_loss": 3.10626220703125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18093,
        "tokens": 9485942784,
        "learning_rate": 0.0002572202350173163,
        "gradient_norm": 0.40553155541419983,
        "train_loss": 3.0940752029418945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18094,
        "tokens": 9486467072,
        "learning_rate": 0.0002571926499738209,
        "gradient_norm": 0.43613675236701965,
        "train_loss": 3.12559175491333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18095,
        "tokens": 9486991360,
        "learning_rate": 0.0002571650657498631,
        "gradient_norm": 0.40957140922546387,
        "train_loss": 3.065861940383911,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18096,
        "tokens": 9487515648,
        "learning_rate": 0.00025713748234575313,
        "gradient_norm": 0.3696303069591522,
        "train_loss": 3.061692237854004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18097,
        "tokens": 9488039936,
        "learning_rate": 0.00025710989976180173,
        "gradient_norm": 0.3909032344818115,
        "train_loss": 3.03139066696167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18098,
        "tokens": 9488564224,
        "learning_rate": 0.0002570823179983192,
        "gradient_norm": 0.32533568143844604,
        "train_loss": 3.071384906768799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18099,
        "tokens": 9489088512,
        "learning_rate": 0.000257054737055616,
        "gradient_norm": 0.3885178864002228,
        "train_loss": 3.0761733055114746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18100,
        "tokens": 9489612800,
        "learning_rate": 0.00025702715693400285,
        "gradient_norm": 0.3404386043548584,
        "train_loss": 3.0220203399658203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18101,
        "tokens": 9490137088,
        "learning_rate": 0.0002569995776337898,
        "gradient_norm": 0.4153738021850586,
        "train_loss": 3.156425952911377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18102,
        "tokens": 9490661376,
        "learning_rate": 0.00025697199915528774,
        "gradient_norm": 0.3992140293121338,
        "train_loss": 3.099177360534668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18103,
        "tokens": 9491185664,
        "learning_rate": 0.00025694442149880667,
        "gradient_norm": 0.32808220386505127,
        "train_loss": 2.998809814453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18104,
        "tokens": 9491709952,
        "learning_rate": 0.00025691684466465733,
        "gradient_norm": 0.3458353877067566,
        "train_loss": 3.0788912773132324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18105,
        "tokens": 9492234240,
        "learning_rate": 0.0002568892686531499,
        "gradient_norm": 0.31583476066589355,
        "train_loss": 3.078357219696045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18106,
        "tokens": 9492758528,
        "learning_rate": 0.000256861693464595,
        "gradient_norm": 0.3719070851802826,
        "train_loss": 3.085798740386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18107,
        "tokens": 9493282816,
        "learning_rate": 0.0002568341190993028,
        "gradient_norm": 0.3490002751350403,
        "train_loss": 3.1110177040100098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18108,
        "tokens": 9493807104,
        "learning_rate": 0.00025680654555758386,
        "gradient_norm": 0.36614492535591125,
        "train_loss": 3.0930237770080566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18109,
        "tokens": 9494331392,
        "learning_rate": 0.0002567789728397484,
        "gradient_norm": 0.36028149724006653,
        "train_loss": 3.053694486618042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18110,
        "tokens": 9494855680,
        "learning_rate": 0.000256751400946107,
        "gradient_norm": 0.3645092248916626,
        "train_loss": 3.095400810241699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18111,
        "tokens": 9495379968,
        "learning_rate": 0.0002567238298769698,
        "gradient_norm": 0.3676161766052246,
        "train_loss": 3.1189017295837402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18112,
        "tokens": 9495904256,
        "learning_rate": 0.00025669625963264725,
        "gradient_norm": 0.3629384934902191,
        "train_loss": 3.1176648139953613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18113,
        "tokens": 9496428544,
        "learning_rate": 0.0002566686902134497,
        "gradient_norm": 0.3605892062187195,
        "train_loss": 3.0369210243225098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18114,
        "tokens": 9496952832,
        "learning_rate": 0.00025664112161968736,
        "gradient_norm": 0.36461693048477173,
        "train_loss": 3.1046934127807617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18115,
        "tokens": 9497477120,
        "learning_rate": 0.00025661355385167073,
        "gradient_norm": 0.36827149987220764,
        "train_loss": 3.1457457542419434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18116,
        "tokens": 9498001408,
        "learning_rate": 0.00025658598690971,
        "gradient_norm": 0.3482213020324707,
        "train_loss": 3.0745151042938232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18117,
        "tokens": 9498525696,
        "learning_rate": 0.0002565584207941156,
        "gradient_norm": 0.4142325818538666,
        "train_loss": 3.002826690673828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18118,
        "tokens": 9499049984,
        "learning_rate": 0.00025653085550519754,
        "gradient_norm": 0.33412155508995056,
        "train_loss": 3.0794169902801514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18119,
        "tokens": 9499574272,
        "learning_rate": 0.0002565032910432664,
        "gradient_norm": 0.397222101688385,
        "train_loss": 3.0824131965637207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18120,
        "tokens": 9500098560,
        "learning_rate": 0.00025647572740863234,
        "gradient_norm": 0.38106849789619446,
        "train_loss": 3.0998287200927734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18121,
        "tokens": 9500622848,
        "learning_rate": 0.0002564481646016056,
        "gradient_norm": 0.4291824400424957,
        "train_loss": 3.060492515563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18122,
        "tokens": 9501147136,
        "learning_rate": 0.00025642060262249643,
        "gradient_norm": 0.3524666726589203,
        "train_loss": 3.0579190254211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18123,
        "tokens": 9501671424,
        "learning_rate": 0.00025639304147161515,
        "gradient_norm": 0.37802648544311523,
        "train_loss": 3.0696771144866943,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18124,
        "tokens": 9502195712,
        "learning_rate": 0.0002563654811492719,
        "gradient_norm": 0.358021080493927,
        "train_loss": 3.0351758003234863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18125,
        "tokens": 9502720000,
        "learning_rate": 0.0002563379216557769,
        "gradient_norm": 0.3265177309513092,
        "train_loss": 3.108062267303467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18126,
        "tokens": 9503244288,
        "learning_rate": 0.00025631036299144055,
        "gradient_norm": 0.37795522809028625,
        "train_loss": 3.1018943786621094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18127,
        "tokens": 9503768576,
        "learning_rate": 0.00025628280515657275,
        "gradient_norm": 0.29562908411026,
        "train_loss": 3.0437958240509033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18128,
        "tokens": 9504292864,
        "learning_rate": 0.000256255248151484,
        "gradient_norm": 0.3871719241142273,
        "train_loss": 3.022645950317383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18129,
        "tokens": 9504817152,
        "learning_rate": 0.00025622769197648434,
        "gradient_norm": 0.30412718653678894,
        "train_loss": 3.0743911266326904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18130,
        "tokens": 9505341440,
        "learning_rate": 0.00025620013663188386,
        "gradient_norm": 0.352577269077301,
        "train_loss": 3.0835819244384766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18131,
        "tokens": 9505865728,
        "learning_rate": 0.000256172582117993,
        "gradient_norm": 0.3622322380542755,
        "train_loss": 2.995328426361084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18132,
        "tokens": 9506390016,
        "learning_rate": 0.0002561450284351216,
        "gradient_norm": 0.31538015604019165,
        "train_loss": 3.1131532192230225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18133,
        "tokens": 9506914304,
        "learning_rate": 0.0002561174755835801,
        "gradient_norm": 0.3338753879070282,
        "train_loss": 3.0752265453338623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18134,
        "tokens": 9507438592,
        "learning_rate": 0.00025608992356367837,
        "gradient_norm": 0.2986240088939667,
        "train_loss": 3.0002870559692383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18135,
        "tokens": 9507962880,
        "learning_rate": 0.00025606237237572687,
        "gradient_norm": 0.3482341468334198,
        "train_loss": 3.0967507362365723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18136,
        "tokens": 9508487168,
        "learning_rate": 0.00025603482202003536,
        "gradient_norm": 0.32138797640800476,
        "train_loss": 3.1333770751953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18137,
        "tokens": 9509011456,
        "learning_rate": 0.0002560072724969143,
        "gradient_norm": 0.4006468951702118,
        "train_loss": 3.0976428985595703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18138,
        "tokens": 9509535744,
        "learning_rate": 0.0002559797238066734,
        "gradient_norm": 0.34402063488960266,
        "train_loss": 3.1020007133483887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18139,
        "tokens": 9510060032,
        "learning_rate": 0.0002559521759496231,
        "gradient_norm": 0.3372669219970703,
        "train_loss": 3.072359800338745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18140,
        "tokens": 9510584320,
        "learning_rate": 0.00025592462892607337,
        "gradient_norm": 0.33025792241096497,
        "train_loss": 3.0906381607055664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18141,
        "tokens": 9511108608,
        "learning_rate": 0.0002558970827363342,
        "gradient_norm": 0.33536407351493835,
        "train_loss": 3.093078374862671,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18142,
        "tokens": 9511632896,
        "learning_rate": 0.0002558695373807158,
        "gradient_norm": 0.33054766058921814,
        "train_loss": 3.0330917835235596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18143,
        "tokens": 9512157184,
        "learning_rate": 0.00025584199285952813,
        "gradient_norm": 0.307496041059494,
        "train_loss": 3.0851526260375977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18144,
        "tokens": 9512681472,
        "learning_rate": 0.00025581444917308137,
        "gradient_norm": 0.3131212592124939,
        "train_loss": 3.070779800415039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18145,
        "tokens": 9513205760,
        "learning_rate": 0.0002557869063216854,
        "gradient_norm": 0.3265473246574402,
        "train_loss": 3.0707898139953613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18146,
        "tokens": 9513730048,
        "learning_rate": 0.00025575936430565036,
        "gradient_norm": 0.346680611371994,
        "train_loss": 3.0656864643096924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18147,
        "tokens": 9514254336,
        "learning_rate": 0.00025573182312528607,
        "gradient_norm": 0.3245358169078827,
        "train_loss": 3.0930700302124023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18148,
        "tokens": 9514778624,
        "learning_rate": 0.00025570428278090285,
        "gradient_norm": 0.4221701920032501,
        "train_loss": 3.0795412063598633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18149,
        "tokens": 9515302912,
        "learning_rate": 0.0002556767432728104,
        "gradient_norm": 0.37111419439315796,
        "train_loss": 3.0907578468322754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18150,
        "tokens": 9515827200,
        "learning_rate": 0.0002556492046013189,
        "gradient_norm": 0.33334487676620483,
        "train_loss": 3.1303060054779053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18151,
        "tokens": 9516351488,
        "learning_rate": 0.0002556216667667383,
        "gradient_norm": 0.4081341028213501,
        "train_loss": 3.0769824981689453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18152,
        "tokens": 9516875776,
        "learning_rate": 0.00025559412976937856,
        "gradient_norm": 0.36780989170074463,
        "train_loss": 3.088139533996582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18153,
        "tokens": 9517400064,
        "learning_rate": 0.0002555665936095497,
        "gradient_norm": 0.322793573141098,
        "train_loss": 3.104252338409424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18154,
        "tokens": 9517924352,
        "learning_rate": 0.00025553905828756146,
        "gradient_norm": 0.3677103817462921,
        "train_loss": 3.0510663986206055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18155,
        "tokens": 9518448640,
        "learning_rate": 0.00025551152380372407,
        "gradient_norm": 0.3263462483882904,
        "train_loss": 3.081794500350952,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18156,
        "tokens": 9518972928,
        "learning_rate": 0.0002554839901583473,
        "gradient_norm": 0.4038146734237671,
        "train_loss": 3.073314905166626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18157,
        "tokens": 9519497216,
        "learning_rate": 0.0002554564573517411,
        "gradient_norm": 0.33545705676078796,
        "train_loss": 3.056304454803467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18158,
        "tokens": 9520021504,
        "learning_rate": 0.00025542892538421536,
        "gradient_norm": 0.35042718052864075,
        "train_loss": 3.0256290435791016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18159,
        "tokens": 9520545792,
        "learning_rate": 0.00025540139425608,
        "gradient_norm": 0.3327075242996216,
        "train_loss": 3.1292152404785156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18160,
        "tokens": 9521070080,
        "learning_rate": 0.000255373863967645,
        "gradient_norm": 0.35220593214035034,
        "train_loss": 3.0432026386260986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18161,
        "tokens": 9521594368,
        "learning_rate": 0.00025534633451922015,
        "gradient_norm": 0.3652717173099518,
        "train_loss": 3.0735464096069336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18162,
        "tokens": 9522118656,
        "learning_rate": 0.00025531880591111544,
        "gradient_norm": 0.35266703367233276,
        "train_loss": 3.164463520050049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18163,
        "tokens": 9522642944,
        "learning_rate": 0.00025529127814364054,
        "gradient_norm": 0.35622406005859375,
        "train_loss": 3.0904104709625244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18164,
        "tokens": 9523167232,
        "learning_rate": 0.0002552637512171056,
        "gradient_norm": 0.33905425667762756,
        "train_loss": 3.081646203994751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18165,
        "tokens": 9523691520,
        "learning_rate": 0.00025523622513182014,
        "gradient_norm": 0.36196061968803406,
        "train_loss": 3.029064655303955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18166,
        "tokens": 9524215808,
        "learning_rate": 0.00025520869988809424,
        "gradient_norm": 0.3346433639526367,
        "train_loss": 3.0444633960723877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18167,
        "tokens": 9524740096,
        "learning_rate": 0.00025518117548623757,
        "gradient_norm": 0.36959710717201233,
        "train_loss": 3.025958776473999,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18168,
        "tokens": 9525264384,
        "learning_rate": 0.00025515365192656014,
        "gradient_norm": 0.35751304030418396,
        "train_loss": 3.033172607421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18169,
        "tokens": 9525788672,
        "learning_rate": 0.00025512612920937155,
        "gradient_norm": 0.34629639983177185,
        "train_loss": 3.073237895965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18170,
        "tokens": 9526312960,
        "learning_rate": 0.00025509860733498183,
        "gradient_norm": 0.37688639760017395,
        "train_loss": 3.0751163959503174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18171,
        "tokens": 9526837248,
        "learning_rate": 0.00025507108630370057,
        "gradient_norm": 0.35158950090408325,
        "train_loss": 3.0986828804016113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18172,
        "tokens": 9527361536,
        "learning_rate": 0.00025504356611583763,
        "gradient_norm": 0.3645872473716736,
        "train_loss": 3.0711565017700195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18173,
        "tokens": 9527885824,
        "learning_rate": 0.0002550160467717029,
        "gradient_norm": 0.3222593069076538,
        "train_loss": 3.072242021560669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18174,
        "tokens": 9528410112,
        "learning_rate": 0.00025498852827160587,
        "gradient_norm": 0.3612031042575836,
        "train_loss": 3.049686908721924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18175,
        "tokens": 9528934400,
        "learning_rate": 0.00025496101061585656,
        "gradient_norm": 0.37492406368255615,
        "train_loss": 3.050908088684082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18176,
        "tokens": 9529458688,
        "learning_rate": 0.0002549334938047646,
        "gradient_norm": 0.3347737193107605,
        "train_loss": 3.048692226409912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18177,
        "tokens": 9529982976,
        "learning_rate": 0.00025490597783863974,
        "gradient_norm": 0.41067183017730713,
        "train_loss": 3.0799155235290527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18178,
        "tokens": 9530507264,
        "learning_rate": 0.00025487846271779176,
        "gradient_norm": 0.3101222813129425,
        "train_loss": 3.066669464111328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18179,
        "tokens": 9531031552,
        "learning_rate": 0.0002548509484425302,
        "gradient_norm": 0.33148378133773804,
        "train_loss": 3.1229262351989746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18180,
        "tokens": 9531555840,
        "learning_rate": 0.00025482343501316497,
        "gradient_norm": 0.33069556951522827,
        "train_loss": 3.043818950653076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18181,
        "tokens": 9532080128,
        "learning_rate": 0.0002547959224300056,
        "gradient_norm": 0.30605435371398926,
        "train_loss": 3.0819036960601807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18182,
        "tokens": 9532604416,
        "learning_rate": 0.00025476841069336197,
        "gradient_norm": 0.3314276933670044,
        "train_loss": 3.1456079483032227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18183,
        "tokens": 9533128704,
        "learning_rate": 0.0002547408998035436,
        "gradient_norm": 0.3437857925891876,
        "train_loss": 3.0649514198303223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18184,
        "tokens": 9533652992,
        "learning_rate": 0.00025471338976086036,
        "gradient_norm": 0.3272598385810852,
        "train_loss": 3.1120638847351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18185,
        "tokens": 9534177280,
        "learning_rate": 0.00025468588056562155,
        "gradient_norm": 0.34382230043411255,
        "train_loss": 3.0364906787872314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18186,
        "tokens": 9534701568,
        "learning_rate": 0.0002546583722181372,
        "gradient_norm": 0.3413880169391632,
        "train_loss": 3.106609344482422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18187,
        "tokens": 9535225856,
        "learning_rate": 0.00025463086471871665,
        "gradient_norm": 0.41426733136177063,
        "train_loss": 3.1993818283081055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18188,
        "tokens": 9535750144,
        "learning_rate": 0.0002546033580676698,
        "gradient_norm": 0.4694553017616272,
        "train_loss": 3.0443735122680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18189,
        "tokens": 9536274432,
        "learning_rate": 0.000254575852265306,
        "gradient_norm": 0.37192943692207336,
        "train_loss": 3.1154110431671143,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18190,
        "tokens": 9536798720,
        "learning_rate": 0.000254548347311935,
        "gradient_norm": 0.38591378927230835,
        "train_loss": 3.0292270183563232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18191,
        "tokens": 9537323008,
        "learning_rate": 0.00025452084320786664,
        "gradient_norm": 0.39575088024139404,
        "train_loss": 3.037105083465576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18192,
        "tokens": 9537847296,
        "learning_rate": 0.00025449333995341004,
        "gradient_norm": 0.3800325095653534,
        "train_loss": 3.0908737182617188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18193,
        "tokens": 9538371584,
        "learning_rate": 0.00025446583754887514,
        "gradient_norm": 0.38606929779052734,
        "train_loss": 3.0783252716064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18194,
        "tokens": 9538895872,
        "learning_rate": 0.0002544383359945713,
        "gradient_norm": 0.34401124715805054,
        "train_loss": 3.0272445678710938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18195,
        "tokens": 9539420160,
        "learning_rate": 0.00025441083529080825,
        "gradient_norm": 0.37814509868621826,
        "train_loss": 3.0921952724456787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18196,
        "tokens": 9539944448,
        "learning_rate": 0.00025438333543789546,
        "gradient_norm": 0.37147971987724304,
        "train_loss": 3.0793404579162598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18197,
        "tokens": 9540468736,
        "learning_rate": 0.0002543558364361425,
        "gradient_norm": 0.3439999222755432,
        "train_loss": 3.050046920776367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18198,
        "tokens": 9540993024,
        "learning_rate": 0.00025432833828585886,
        "gradient_norm": 0.383044958114624,
        "train_loss": 3.093094825744629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18199,
        "tokens": 9541517312,
        "learning_rate": 0.0002543008409873541,
        "gradient_norm": 0.30304354429244995,
        "train_loss": 3.0873782634735107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18200,
        "tokens": 9542041600,
        "learning_rate": 0.00025427334454093773,
        "gradient_norm": 0.3429982662200928,
        "train_loss": 3.0744619369506836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18201,
        "tokens": 9542565888,
        "learning_rate": 0.0002542458489469193,
        "gradient_norm": 0.31931930780410767,
        "train_loss": 3.0545084476470947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18202,
        "tokens": 9543090176,
        "learning_rate": 0.00025421835420560827,
        "gradient_norm": 0.33924221992492676,
        "train_loss": 3.0318470001220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18203,
        "tokens": 9543614464,
        "learning_rate": 0.0002541908603173141,
        "gradient_norm": 0.3538973331451416,
        "train_loss": 3.110870838165283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18204,
        "tokens": 9544138752,
        "learning_rate": 0.0002541633672823463,
        "gradient_norm": 0.371643602848053,
        "train_loss": 3.0849180221557617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18205,
        "tokens": 9544663040,
        "learning_rate": 0.00025413587510101434,
        "gradient_norm": 0.3851982057094574,
        "train_loss": 3.044468879699707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18206,
        "tokens": 9545187328,
        "learning_rate": 0.00025410838377362775,
        "gradient_norm": 0.3352757692337036,
        "train_loss": 3.0501866340637207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18207,
        "tokens": 9545711616,
        "learning_rate": 0.00025408089330049576,
        "gradient_norm": 0.46870914101600647,
        "train_loss": 3.071822166442871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18208,
        "tokens": 9546235904,
        "learning_rate": 0.00025405340368192807,
        "gradient_norm": 0.40710213780403137,
        "train_loss": 3.075016498565674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18209,
        "tokens": 9546760192,
        "learning_rate": 0.0002540259149182339,
        "gradient_norm": 0.3812449872493744,
        "train_loss": 3.123526096343994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18210,
        "tokens": 9547284480,
        "learning_rate": 0.0002539984270097228,
        "gradient_norm": 0.5393475294113159,
        "train_loss": 3.0680627822875977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18211,
        "tokens": 9547808768,
        "learning_rate": 0.00025397093995670417,
        "gradient_norm": 0.4112485349178314,
        "train_loss": 3.1010332107543945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18212,
        "tokens": 9548333056,
        "learning_rate": 0.00025394345375948725,
        "gradient_norm": 0.38157710433006287,
        "train_loss": 3.1158690452575684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18213,
        "tokens": 9548857344,
        "learning_rate": 0.0002539159684183818,
        "gradient_norm": 0.3793756663799286,
        "train_loss": 3.108503818511963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18214,
        "tokens": 9549381632,
        "learning_rate": 0.0002538884839336968,
        "gradient_norm": 0.3606100082397461,
        "train_loss": 3.085664749145508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18215,
        "tokens": 9549905920,
        "learning_rate": 0.00025386100030574184,
        "gradient_norm": 0.31663578748703003,
        "train_loss": 3.0666728019714355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18216,
        "tokens": 9550430208,
        "learning_rate": 0.00025383351753482616,
        "gradient_norm": 0.33082136511802673,
        "train_loss": 3.078645706176758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18217,
        "tokens": 9550954496,
        "learning_rate": 0.0002538060356212593,
        "gradient_norm": 0.3125559985637665,
        "train_loss": 3.105518341064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18218,
        "tokens": 9551478784,
        "learning_rate": 0.0002537785545653504,
        "gradient_norm": 0.3598127067089081,
        "train_loss": 3.022307872772217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18219,
        "tokens": 9552003072,
        "learning_rate": 0.0002537510743674089,
        "gradient_norm": 0.3357763886451721,
        "train_loss": 3.110891342163086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18220,
        "tokens": 9552527360,
        "learning_rate": 0.00025372359502774417,
        "gradient_norm": 0.3556269705295563,
        "train_loss": 3.05256986618042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18221,
        "tokens": 9553051648,
        "learning_rate": 0.00025369611654666536,
        "gradient_norm": 0.3106653094291687,
        "train_loss": 3.0765695571899414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18222,
        "tokens": 9553575936,
        "learning_rate": 0.000253668638924482,
        "gradient_norm": 0.3109719157218933,
        "train_loss": 3.0918798446655273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18223,
        "tokens": 9554100224,
        "learning_rate": 0.0002536411621615031,
        "gradient_norm": 0.30867400765419006,
        "train_loss": 3.067948818206787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18224,
        "tokens": 9554624512,
        "learning_rate": 0.0002536136862580382,
        "gradient_norm": 0.32839709520339966,
        "train_loss": 3.0544276237487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18225,
        "tokens": 9555148800,
        "learning_rate": 0.00025358621121439643,
        "gradient_norm": 0.30031391978263855,
        "train_loss": 3.019946575164795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18226,
        "tokens": 9555673088,
        "learning_rate": 0.0002535587370308872,
        "gradient_norm": 0.3295719623565674,
        "train_loss": 3.1121504306793213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18227,
        "tokens": 9556197376,
        "learning_rate": 0.00025353126370781956,
        "gradient_norm": 0.32340097427368164,
        "train_loss": 3.054995059967041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18228,
        "tokens": 9556721664,
        "learning_rate": 0.00025350379124550296,
        "gradient_norm": 0.3164714276790619,
        "train_loss": 3.0571212768554688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18229,
        "tokens": 9557245952,
        "learning_rate": 0.0002534763196442465,
        "gradient_norm": 0.3116084039211273,
        "train_loss": 3.0790929794311523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18230,
        "tokens": 9557770240,
        "learning_rate": 0.00025344884890435944,
        "gradient_norm": 0.324690043926239,
        "train_loss": 3.13596248626709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18231,
        "tokens": 9558294528,
        "learning_rate": 0.00025342137902615105,
        "gradient_norm": 0.40718069672584534,
        "train_loss": 3.0359814167022705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18232,
        "tokens": 9558818816,
        "learning_rate": 0.0002533939100099304,
        "gradient_norm": 0.3710741102695465,
        "train_loss": 3.0758819580078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18233,
        "tokens": 9559343104,
        "learning_rate": 0.0002533664418560069,
        "gradient_norm": 0.40599924325942993,
        "train_loss": 3.0700154304504395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18234,
        "tokens": 9559867392,
        "learning_rate": 0.0002533389745646895,
        "gradient_norm": 0.6331913471221924,
        "train_loss": 3.0759634971618652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18235,
        "tokens": 9560391680,
        "learning_rate": 0.0002533115081362877,
        "gradient_norm": 0.3230257034301758,
        "train_loss": 3.0304763317108154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18236,
        "tokens": 9560915968,
        "learning_rate": 0.00025328404257111026,
        "gradient_norm": 0.4983929991722107,
        "train_loss": 3.0434207916259766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18237,
        "tokens": 9561440256,
        "learning_rate": 0.0002532565778694667,
        "gradient_norm": 0.4011085331439972,
        "train_loss": 3.0912957191467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18238,
        "tokens": 9561964544,
        "learning_rate": 0.00025322911403166594,
        "gradient_norm": 0.38126689195632935,
        "train_loss": 3.09250807762146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18239,
        "tokens": 9562488832,
        "learning_rate": 0.00025320165105801717,
        "gradient_norm": 0.3996598720550537,
        "train_loss": 3.0515241622924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18240,
        "tokens": 9563013120,
        "learning_rate": 0.0002531741889488296,
        "gradient_norm": 0.3654393255710602,
        "train_loss": 3.0308499336242676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18241,
        "tokens": 9563537408,
        "learning_rate": 0.00025314672770441224,
        "gradient_norm": 0.36418047547340393,
        "train_loss": 3.1084604263305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18242,
        "tokens": 9564061696,
        "learning_rate": 0.0002531192673250744,
        "gradient_norm": 0.3132185935974121,
        "train_loss": 3.0774197578430176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18243,
        "tokens": 9564585984,
        "learning_rate": 0.00025309180781112484,
        "gradient_norm": 0.3756246268749237,
        "train_loss": 3.1741886138916016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18244,
        "tokens": 9565110272,
        "learning_rate": 0.0002530643491628731,
        "gradient_norm": 0.35189205408096313,
        "train_loss": 3.005202293395996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18245,
        "tokens": 9565634560,
        "learning_rate": 0.0002530368913806278,
        "gradient_norm": 0.44629019498825073,
        "train_loss": 3.1409151554107666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18246,
        "tokens": 9566158848,
        "learning_rate": 0.0002530094344646984,
        "gradient_norm": 0.4177452027797699,
        "train_loss": 3.1478729248046875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18247,
        "tokens": 9566683136,
        "learning_rate": 0.0002529819784153936,
        "gradient_norm": 0.362348347902298,
        "train_loss": 3.031118392944336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18248,
        "tokens": 9567207424,
        "learning_rate": 0.0002529545232330228,
        "gradient_norm": 0.3866993188858032,
        "train_loss": 3.070124626159668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18249,
        "tokens": 9567731712,
        "learning_rate": 0.00025292706891789473,
        "gradient_norm": 0.3709588348865509,
        "train_loss": 3.0917649269104004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18250,
        "tokens": 9568256000,
        "learning_rate": 0.0002528996154703186,
        "gradient_norm": 0.4869191348552704,
        "train_loss": 3.080958843231201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18251,
        "tokens": 9568780288,
        "learning_rate": 0.0002528721628906035,
        "gradient_norm": 0.4136068522930145,
        "train_loss": 3.0199880599975586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18252,
        "tokens": 9569304576,
        "learning_rate": 0.00025284471117905825,
        "gradient_norm": 0.3435109257698059,
        "train_loss": 3.0232348442077637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18253,
        "tokens": 9569828864,
        "learning_rate": 0.00025281726033599215,
        "gradient_norm": 0.39327332377433777,
        "train_loss": 3.0556769371032715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18254,
        "tokens": 9570353152,
        "learning_rate": 0.0002527898103617137,
        "gradient_norm": 0.3564186990261078,
        "train_loss": 3.1202027797698975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18255,
        "tokens": 9570877440,
        "learning_rate": 0.00025276236125653246,
        "gradient_norm": 0.42800596356391907,
        "train_loss": 3.0162525177001953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18256,
        "tokens": 9571401728,
        "learning_rate": 0.00025273491302075694,
        "gradient_norm": 0.3299868404865265,
        "train_loss": 3.1060709953308105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18257,
        "tokens": 9571926016,
        "learning_rate": 0.00025270746565469635,
        "gradient_norm": 0.3573437035083771,
        "train_loss": 3.1023528575897217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18258,
        "tokens": 9572450304,
        "learning_rate": 0.0002526800191586596,
        "gradient_norm": 0.37503328919410706,
        "train_loss": 3.12572979927063,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18259,
        "tokens": 9572974592,
        "learning_rate": 0.0002526525735329555,
        "gradient_norm": 0.31963545083999634,
        "train_loss": 3.0383410453796387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18260,
        "tokens": 9573498880,
        "learning_rate": 0.00025262512877789327,
        "gradient_norm": 0.3576255142688751,
        "train_loss": 3.1526405811309814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18261,
        "tokens": 9574023168,
        "learning_rate": 0.0002525976848937816,
        "gradient_norm": 0.3412809669971466,
        "train_loss": 3.0742340087890625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18262,
        "tokens": 9574547456,
        "learning_rate": 0.0002525702418809295,
        "gradient_norm": 0.31708788871765137,
        "train_loss": 3.058215618133545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18263,
        "tokens": 9575071744,
        "learning_rate": 0.00025254279973964573,
        "gradient_norm": 0.3412930369377136,
        "train_loss": 3.0587103366851807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18264,
        "tokens": 9575596032,
        "learning_rate": 0.0002525153584702394,
        "gradient_norm": 0.31816282868385315,
        "train_loss": 3.0756030082702637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18265,
        "tokens": 9576120320,
        "learning_rate": 0.00025248791807301927,
        "gradient_norm": 0.34532034397125244,
        "train_loss": 3.107858657836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18266,
        "tokens": 9576644608,
        "learning_rate": 0.0002524604785482943,
        "gradient_norm": 0.3195398151874542,
        "train_loss": 3.0770480632781982,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18267,
        "tokens": 9577168896,
        "learning_rate": 0.0002524330398963732,
        "gradient_norm": 0.34734046459198,
        "train_loss": 3.101759433746338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18268,
        "tokens": 9577693184,
        "learning_rate": 0.00025240560211756504,
        "gradient_norm": 0.3282194137573242,
        "train_loss": 3.057560920715332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18269,
        "tokens": 9578217472,
        "learning_rate": 0.0002523781652121784,
        "gradient_norm": 0.3009839355945587,
        "train_loss": 3.0790328979492188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18270,
        "tokens": 9578741760,
        "learning_rate": 0.0002523507291805224,
        "gradient_norm": 0.3113451600074768,
        "train_loss": 3.071178674697876,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18271,
        "tokens": 9579266048,
        "learning_rate": 0.0002523232940229057,
        "gradient_norm": 0.29464608430862427,
        "train_loss": 3.0767464637756348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18272,
        "tokens": 9579790336,
        "learning_rate": 0.00025229585973963716,
        "gradient_norm": 0.3315170705318451,
        "train_loss": 3.0725502967834473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18273,
        "tokens": 9580314624,
        "learning_rate": 0.00025226842633102554,
        "gradient_norm": 0.33105504512786865,
        "train_loss": 3.091742515563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18274,
        "tokens": 9580838912,
        "learning_rate": 0.0002522409937973797,
        "gradient_norm": 0.32770398259162903,
        "train_loss": 3.08975887298584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18275,
        "tokens": 9581363200,
        "learning_rate": 0.0002522135621390084,
        "gradient_norm": 0.32919782400131226,
        "train_loss": 3.026182174682617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18276,
        "tokens": 9581887488,
        "learning_rate": 0.00025218613135622044,
        "gradient_norm": 0.37410447001457214,
        "train_loss": 3.0641322135925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18277,
        "tokens": 9582411776,
        "learning_rate": 0.00025215870144932456,
        "gradient_norm": 0.3498114347457886,
        "train_loss": 3.084764003753662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18278,
        "tokens": 9582936064,
        "learning_rate": 0.0002521312724186295,
        "gradient_norm": 0.34687936305999756,
        "train_loss": 3.0885210037231445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18279,
        "tokens": 9583460352,
        "learning_rate": 0.000252103844264444,
        "gradient_norm": 0.3415968120098114,
        "train_loss": 3.0300002098083496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18280,
        "tokens": 9583984640,
        "learning_rate": 0.000252076416987077,
        "gradient_norm": 0.3749460279941559,
        "train_loss": 3.1050236225128174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18281,
        "tokens": 9584508928,
        "learning_rate": 0.0002520489905868369,
        "gradient_norm": 0.38368549942970276,
        "train_loss": 3.089906930923462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18282,
        "tokens": 9585033216,
        "learning_rate": 0.0002520215650640327,
        "gradient_norm": 0.4013044536113739,
        "train_loss": 3.0972185134887695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18283,
        "tokens": 9585557504,
        "learning_rate": 0.00025199414041897285,
        "gradient_norm": 0.4058200716972351,
        "train_loss": 3.0751090049743652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18284,
        "tokens": 9586081792,
        "learning_rate": 0.0002519667166519663,
        "gradient_norm": 0.3541753888130188,
        "train_loss": 3.16269588470459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18285,
        "tokens": 9586606080,
        "learning_rate": 0.0002519392937633215,
        "gradient_norm": 0.3185825049877167,
        "train_loss": 3.0745351314544678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18286,
        "tokens": 9587130368,
        "learning_rate": 0.0002519118717533474,
        "gradient_norm": 0.32667553424835205,
        "train_loss": 3.0670077800750732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18287,
        "tokens": 9587654656,
        "learning_rate": 0.00025188445062235244,
        "gradient_norm": 0.35771554708480835,
        "train_loss": 3.0892062187194824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18288,
        "tokens": 9588178944,
        "learning_rate": 0.0002518570303706454,
        "gradient_norm": 0.34985318779945374,
        "train_loss": 3.0825204849243164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18289,
        "tokens": 9588703232,
        "learning_rate": 0.0002518296109985348,
        "gradient_norm": 0.38008198142051697,
        "train_loss": 3.04046630859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18290,
        "tokens": 9589227520,
        "learning_rate": 0.0002518021925063294,
        "gradient_norm": 0.3360954523086548,
        "train_loss": 3.1044039726257324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18291,
        "tokens": 9589751808,
        "learning_rate": 0.0002517747748943379,
        "gradient_norm": 0.3700745105743408,
        "train_loss": 3.068455219268799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18292,
        "tokens": 9590276096,
        "learning_rate": 0.00025174735816286875,
        "gradient_norm": 0.4361037611961365,
        "train_loss": 3.0963268280029297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18293,
        "tokens": 9590800384,
        "learning_rate": 0.0002517199423122307,
        "gradient_norm": 0.33920058608055115,
        "train_loss": 3.056802749633789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18294,
        "tokens": 9591324672,
        "learning_rate": 0.0002516925273427322,
        "gradient_norm": 0.44270026683807373,
        "train_loss": 3.099411725997925,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18295,
        "tokens": 9591848960,
        "learning_rate": 0.00025166511325468193,
        "gradient_norm": 0.34635496139526367,
        "train_loss": 3.132474899291992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18296,
        "tokens": 9592373248,
        "learning_rate": 0.0002516377000483884,
        "gradient_norm": 0.47821661829948425,
        "train_loss": 3.1012535095214844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18297,
        "tokens": 9592897536,
        "learning_rate": 0.00025161028772416035,
        "gradient_norm": 0.4408358037471771,
        "train_loss": 3.075310707092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18298,
        "tokens": 9593421824,
        "learning_rate": 0.00025158287628230613,
        "gradient_norm": 0.3297867476940155,
        "train_loss": 3.0393638610839844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18299,
        "tokens": 9593946112,
        "learning_rate": 0.00025155546572313436,
        "gradient_norm": 0.3413294553756714,
        "train_loss": 3.080784320831299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18300,
        "tokens": 9594470400,
        "learning_rate": 0.00025152805604695375,
        "gradient_norm": 0.3296523094177246,
        "train_loss": 3.080012559890747,
        "val_loss": 3.0378479957580566,
        "hellaswag_acc": 0.28181636333465576,
        "hellaswag_acc_norm": 0.29247161746025085
    },
    {
        "step": 18301,
        "tokens": 9594994688,
        "learning_rate": 0.0002515006472540726,
        "gradient_norm": 0.42775726318359375,
        "train_loss": 3.0493521690368652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18302,
        "tokens": 9595518976,
        "learning_rate": 0.00025147323934479956,
        "gradient_norm": 0.34851163625717163,
        "train_loss": 3.058851718902588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18303,
        "tokens": 9596043264,
        "learning_rate": 0.000251445832319443,
        "gradient_norm": 0.4845547676086426,
        "train_loss": 3.070735454559326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18304,
        "tokens": 9596567552,
        "learning_rate": 0.00025141842617831166,
        "gradient_norm": 0.4473912715911865,
        "train_loss": 3.129507064819336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18305,
        "tokens": 9597091840,
        "learning_rate": 0.00025139102092171375,
        "gradient_norm": 0.4688381254673004,
        "train_loss": 3.048795700073242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18306,
        "tokens": 9597616128,
        "learning_rate": 0.000251363616549958,
        "gradient_norm": 0.527738094329834,
        "train_loss": 3.1030566692352295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18307,
        "tokens": 9598140416,
        "learning_rate": 0.00025133621306335267,
        "gradient_norm": 0.393419086933136,
        "train_loss": 3.010030746459961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18308,
        "tokens": 9598664704,
        "learning_rate": 0.00025130881046220646,
        "gradient_norm": 0.43966159224510193,
        "train_loss": 3.072016716003418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18309,
        "tokens": 9599188992,
        "learning_rate": 0.0002512814087468275,
        "gradient_norm": 0.38270536065101624,
        "train_loss": 3.0448882579803467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18310,
        "tokens": 9599713280,
        "learning_rate": 0.0002512540079175245,
        "gradient_norm": 0.4286426305770874,
        "train_loss": 3.095179557800293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18311,
        "tokens": 9600237568,
        "learning_rate": 0.00025122660797460584,
        "gradient_norm": 0.3471476137638092,
        "train_loss": 3.0902700424194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18312,
        "tokens": 9600761856,
        "learning_rate": 0.0002511992089183798,
        "gradient_norm": 0.40092548727989197,
        "train_loss": 3.163733959197998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18313,
        "tokens": 9601286144,
        "learning_rate": 0.000251171810749155,
        "gradient_norm": 0.4362199604511261,
        "train_loss": 3.072772979736328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18314,
        "tokens": 9601810432,
        "learning_rate": 0.00025114441346723963,
        "gradient_norm": 0.4408193826675415,
        "train_loss": 3.123744010925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18315,
        "tokens": 9602334720,
        "learning_rate": 0.00025111701707294226,
        "gradient_norm": 0.38995853066444397,
        "train_loss": 3.0758578777313232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18316,
        "tokens": 9602859008,
        "learning_rate": 0.0002510896215665712,
        "gradient_norm": 0.3691696524620056,
        "train_loss": 3.0362534523010254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18317,
        "tokens": 9603383296,
        "learning_rate": 0.0002510622269484348,
        "gradient_norm": 0.3743050992488861,
        "train_loss": 3.058671236038208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18318,
        "tokens": 9603907584,
        "learning_rate": 0.0002510348332188414,
        "gradient_norm": 0.37408462166786194,
        "train_loss": 3.0945851802825928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18319,
        "tokens": 9604431872,
        "learning_rate": 0.00025100744037809925,
        "gradient_norm": 0.39487287402153015,
        "train_loss": 3.071317434310913,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18320,
        "tokens": 9604956160,
        "learning_rate": 0.00025098004842651707,
        "gradient_norm": 0.39187899231910706,
        "train_loss": 3.0893330574035645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18321,
        "tokens": 9605480448,
        "learning_rate": 0.00025095265736440285,
        "gradient_norm": 0.3679220378398895,
        "train_loss": 3.07187819480896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18322,
        "tokens": 9606004736,
        "learning_rate": 0.00025092526719206506,
        "gradient_norm": 0.34950217604637146,
        "train_loss": 3.091146945953369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18323,
        "tokens": 9606529024,
        "learning_rate": 0.00025089787790981183,
        "gradient_norm": 0.3320489823818207,
        "train_loss": 3.084078550338745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18324,
        "tokens": 9607053312,
        "learning_rate": 0.0002508704895179517,
        "gradient_norm": 0.35404855012893677,
        "train_loss": 3.1268744468688965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18325,
        "tokens": 9607577600,
        "learning_rate": 0.0002508431020167928,
        "gradient_norm": 0.3388941287994385,
        "train_loss": 3.1742238998413086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18326,
        "tokens": 9608101888,
        "learning_rate": 0.0002508157154066435,
        "gradient_norm": 0.40486419200897217,
        "train_loss": 3.1016502380371094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18327,
        "tokens": 9608626176,
        "learning_rate": 0.00025078832968781193,
        "gradient_norm": 0.3331799805164337,
        "train_loss": 3.050509452819824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18328,
        "tokens": 9609150464,
        "learning_rate": 0.00025076094486060663,
        "gradient_norm": 0.417294979095459,
        "train_loss": 3.142246961593628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18329,
        "tokens": 9609674752,
        "learning_rate": 0.00025073356092533553,
        "gradient_norm": 0.343765527009964,
        "train_loss": 3.082453727722168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18330,
        "tokens": 9610199040,
        "learning_rate": 0.00025070617788230704,
        "gradient_norm": 0.3494254946708679,
        "train_loss": 3.0230350494384766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18331,
        "tokens": 9610723328,
        "learning_rate": 0.00025067879573182933,
        "gradient_norm": 0.37484729290008545,
        "train_loss": 2.997292995452881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18332,
        "tokens": 9611247616,
        "learning_rate": 0.00025065141447421066,
        "gradient_norm": 0.3664586544036865,
        "train_loss": 3.0981647968292236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18333,
        "tokens": 9611771904,
        "learning_rate": 0.00025062403410975925,
        "gradient_norm": 0.35536691546440125,
        "train_loss": 3.0208568572998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18334,
        "tokens": 9612296192,
        "learning_rate": 0.0002505966546387833,
        "gradient_norm": 0.35837265849113464,
        "train_loss": 3.0860190391540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18335,
        "tokens": 9612820480,
        "learning_rate": 0.000250569276061591,
        "gradient_norm": 0.3484415113925934,
        "train_loss": 3.078967571258545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18336,
        "tokens": 9613344768,
        "learning_rate": 0.0002505418983784904,
        "gradient_norm": 0.3623342514038086,
        "train_loss": 3.122246265411377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18337,
        "tokens": 9613869056,
        "learning_rate": 0.0002505145215897899,
        "gradient_norm": 0.3838355243206024,
        "train_loss": 3.0955517292022705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18338,
        "tokens": 9614393344,
        "learning_rate": 0.0002504871456957975,
        "gradient_norm": 0.3353404104709625,
        "train_loss": 3.042187452316284,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18339,
        "tokens": 9614917632,
        "learning_rate": 0.0002504597706968213,
        "gradient_norm": 0.39015763998031616,
        "train_loss": 3.090273380279541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18340,
        "tokens": 9615441920,
        "learning_rate": 0.00025043239659316974,
        "gradient_norm": 0.34425315260887146,
        "train_loss": 3.045795440673828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18341,
        "tokens": 9615966208,
        "learning_rate": 0.00025040502338515057,
        "gradient_norm": 0.35755103826522827,
        "train_loss": 3.1219234466552734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18342,
        "tokens": 9616490496,
        "learning_rate": 0.00025037765107307217,
        "gradient_norm": 0.36294665932655334,
        "train_loss": 3.1022281646728516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18343,
        "tokens": 9617014784,
        "learning_rate": 0.00025035027965724245,
        "gradient_norm": 0.3553890585899353,
        "train_loss": 3.03784441947937,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18344,
        "tokens": 9617539072,
        "learning_rate": 0.00025032290913796975,
        "gradient_norm": 0.3787790536880493,
        "train_loss": 3.100616455078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18345,
        "tokens": 9618063360,
        "learning_rate": 0.0002502955395155619,
        "gradient_norm": 0.33492764830589294,
        "train_loss": 3.021812915802002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18346,
        "tokens": 9618587648,
        "learning_rate": 0.0002502681707903272,
        "gradient_norm": 0.38034161925315857,
        "train_loss": 3.076805353164673,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18347,
        "tokens": 9619111936,
        "learning_rate": 0.00025024080296257354,
        "gradient_norm": 0.31760987639427185,
        "train_loss": 3.132978916168213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18348,
        "tokens": 9619636224,
        "learning_rate": 0.0002502134360326091,
        "gradient_norm": 0.4150550961494446,
        "train_loss": 3.0224666595458984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18349,
        "tokens": 9620160512,
        "learning_rate": 0.0002501860700007419,
        "gradient_norm": 0.3261330723762512,
        "train_loss": 3.036792278289795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18350,
        "tokens": 9620684800,
        "learning_rate": 0.00025015870486728,
        "gradient_norm": 0.35967007279396057,
        "train_loss": 3.1021814346313477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18351,
        "tokens": 9621209088,
        "learning_rate": 0.0002501313406325314,
        "gradient_norm": 0.3895840644836426,
        "train_loss": 3.0308310985565186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18352,
        "tokens": 9621733376,
        "learning_rate": 0.0002501039772968041,
        "gradient_norm": 0.39689573645591736,
        "train_loss": 3.103914260864258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18353,
        "tokens": 9622257664,
        "learning_rate": 0.0002500766148604062,
        "gradient_norm": 0.33032262325286865,
        "train_loss": 3.053189277648926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18354,
        "tokens": 9622781952,
        "learning_rate": 0.0002500492533236455,
        "gradient_norm": 0.3781319558620453,
        "train_loss": 3.0563840866088867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18355,
        "tokens": 9623306240,
        "learning_rate": 0.0002500218926868302,
        "gradient_norm": 0.32557764649391174,
        "train_loss": 2.969381332397461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18356,
        "tokens": 9623830528,
        "learning_rate": 0.00024999453295026814,
        "gradient_norm": 0.3366051912307739,
        "train_loss": 3.0354814529418945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18357,
        "tokens": 9624354816,
        "learning_rate": 0.0002499671741142674,
        "gradient_norm": 0.5053380131721497,
        "train_loss": 3.165234088897705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18358,
        "tokens": 9624879104,
        "learning_rate": 0.0002499398161791358,
        "gradient_norm": 0.4077417254447937,
        "train_loss": 3.1150577068328857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18359,
        "tokens": 9625403392,
        "learning_rate": 0.0002499124591451814,
        "gradient_norm": 0.36908453702926636,
        "train_loss": 3.058523178100586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18360,
        "tokens": 9625927680,
        "learning_rate": 0.00024988510301271217,
        "gradient_norm": 0.43950173258781433,
        "train_loss": 3.078360080718994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18361,
        "tokens": 9626451968,
        "learning_rate": 0.00024985774778203587,
        "gradient_norm": 0.40829458832740784,
        "train_loss": 3.06461763381958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18362,
        "tokens": 9626976256,
        "learning_rate": 0.0002498303934534606,
        "gradient_norm": 0.31699520349502563,
        "train_loss": 3.0544674396514893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18363,
        "tokens": 9627500544,
        "learning_rate": 0.00024980304002729414,
        "gradient_norm": 0.37517601251602173,
        "train_loss": 3.0814666748046875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18364,
        "tokens": 9628024832,
        "learning_rate": 0.0002497756875038445,
        "gradient_norm": 0.332584410905838,
        "train_loss": 3.085217237472534,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18365,
        "tokens": 9628549120,
        "learning_rate": 0.0002497483358834194,
        "gradient_norm": 0.37227290868759155,
        "train_loss": 3.039522647857666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18366,
        "tokens": 9629073408,
        "learning_rate": 0.0002497209851663269,
        "gradient_norm": 0.3553503155708313,
        "train_loss": 3.1297245025634766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18367,
        "tokens": 9629597696,
        "learning_rate": 0.00024969363535287475,
        "gradient_norm": 0.33159711956977844,
        "train_loss": 3.0423879623413086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18368,
        "tokens": 9630121984,
        "learning_rate": 0.00024966628644337076,
        "gradient_norm": 0.39120250940322876,
        "train_loss": 3.1331863403320312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18369,
        "tokens": 9630646272,
        "learning_rate": 0.00024963893843812294,
        "gradient_norm": 0.34668129682540894,
        "train_loss": 3.092374086380005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18370,
        "tokens": 9631170560,
        "learning_rate": 0.00024961159133743904,
        "gradient_norm": 0.35468584299087524,
        "train_loss": 3.0972554683685303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18371,
        "tokens": 9631694848,
        "learning_rate": 0.0002495842451416269,
        "gradient_norm": 0.3256460726261139,
        "train_loss": 3.107663869857788,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18372,
        "tokens": 9632219136,
        "learning_rate": 0.00024955689985099424,
        "gradient_norm": 0.35002899169921875,
        "train_loss": 3.049342155456543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18373,
        "tokens": 9632743424,
        "learning_rate": 0.00024952955546584906,
        "gradient_norm": 0.33856111764907837,
        "train_loss": 2.9970076084136963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18374,
        "tokens": 9633267712,
        "learning_rate": 0.00024950221198649896,
        "gradient_norm": 0.37430062890052795,
        "train_loss": 3.084981918334961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18375,
        "tokens": 9633792000,
        "learning_rate": 0.0002494748694132519,
        "gradient_norm": 0.36373499035835266,
        "train_loss": 3.0357089042663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18376,
        "tokens": 9634316288,
        "learning_rate": 0.00024944752774641544,
        "gradient_norm": 0.3680523633956909,
        "train_loss": 3.080104351043701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18377,
        "tokens": 9634840576,
        "learning_rate": 0.0002494201869862976,
        "gradient_norm": 0.35096365213394165,
        "train_loss": 3.0482256412506104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18378,
        "tokens": 9635364864,
        "learning_rate": 0.0002493928471332058,
        "gradient_norm": 0.32747402787208557,
        "train_loss": 3.090503692626953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18379,
        "tokens": 9635889152,
        "learning_rate": 0.00024936550818744816,
        "gradient_norm": 0.41833066940307617,
        "train_loss": 3.1364307403564453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18380,
        "tokens": 9636413440,
        "learning_rate": 0.0002493381701493322,
        "gradient_norm": 0.3994986414909363,
        "train_loss": 3.1177988052368164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18381,
        "tokens": 9636937728,
        "learning_rate": 0.0002493108330191657,
        "gradient_norm": 0.33004817366600037,
        "train_loss": 3.073223114013672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18382,
        "tokens": 9637462016,
        "learning_rate": 0.00024928349679725627,
        "gradient_norm": 0.3644888997077942,
        "train_loss": 3.086906909942627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18383,
        "tokens": 9637986304,
        "learning_rate": 0.00024925616148391175,
        "gradient_norm": 0.34802812337875366,
        "train_loss": 3.086082935333252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18384,
        "tokens": 9638510592,
        "learning_rate": 0.00024922882707943987,
        "gradient_norm": 0.403830885887146,
        "train_loss": 3.108464241027832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18385,
        "tokens": 9639034880,
        "learning_rate": 0.0002492014935841481,
        "gradient_norm": 0.3429360091686249,
        "train_loss": 3.0651936531066895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18386,
        "tokens": 9639559168,
        "learning_rate": 0.0002491741609983442,
        "gradient_norm": 0.344317227602005,
        "train_loss": 3.093952178955078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18387,
        "tokens": 9640083456,
        "learning_rate": 0.00024914682932233607,
        "gradient_norm": 0.37761640548706055,
        "train_loss": 3.0214505195617676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18388,
        "tokens": 9640607744,
        "learning_rate": 0.00024911949855643096,
        "gradient_norm": 0.3352418839931488,
        "train_loss": 3.0926270484924316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18389,
        "tokens": 9641132032,
        "learning_rate": 0.00024909216870093687,
        "gradient_norm": 0.41926053166389465,
        "train_loss": 3.0374231338500977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18390,
        "tokens": 9641656320,
        "learning_rate": 0.00024906483975616116,
        "gradient_norm": 0.32058921456336975,
        "train_loss": 3.0658364295959473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18391,
        "tokens": 9642180608,
        "learning_rate": 0.00024903751172241164,
        "gradient_norm": 0.42473065853118896,
        "train_loss": 3.0665550231933594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18392,
        "tokens": 9642704896,
        "learning_rate": 0.0002490101845999958,
        "gradient_norm": 0.3612862527370453,
        "train_loss": 3.0806760787963867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18393,
        "tokens": 9643229184,
        "learning_rate": 0.0002489828583892213,
        "gradient_norm": 0.3302825689315796,
        "train_loss": 3.0622386932373047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18394,
        "tokens": 9643753472,
        "learning_rate": 0.0002489555330903957,
        "gradient_norm": 0.3354050815105438,
        "train_loss": 3.064971923828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18395,
        "tokens": 9644277760,
        "learning_rate": 0.0002489282087038267,
        "gradient_norm": 0.37449124455451965,
        "train_loss": 3.025867462158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18396,
        "tokens": 9644802048,
        "learning_rate": 0.00024890088522982166,
        "gradient_norm": 0.33991339802742004,
        "train_loss": 3.0641696453094482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18397,
        "tokens": 9645326336,
        "learning_rate": 0.0002488735626686883,
        "gradient_norm": 0.33363842964172363,
        "train_loss": 3.0080575942993164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18398,
        "tokens": 9645850624,
        "learning_rate": 0.0002488462410207341,
        "gradient_norm": 0.394481897354126,
        "train_loss": 3.0853166580200195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18399,
        "tokens": 9646374912,
        "learning_rate": 0.0002488189202862665,
        "gradient_norm": 0.35782694816589355,
        "train_loss": 3.1267502307891846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18400,
        "tokens": 9646899200,
        "learning_rate": 0.00024879160046559337,
        "gradient_norm": 0.3685814142227173,
        "train_loss": 3.0918664932250977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18401,
        "tokens": 9647423488,
        "learning_rate": 0.0002487642815590218,
        "gradient_norm": 0.3827560842037201,
        "train_loss": 3.087339162826538,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18402,
        "tokens": 9647947776,
        "learning_rate": 0.0002487369635668597,
        "gradient_norm": 0.40439942479133606,
        "train_loss": 3.1980559825897217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18403,
        "tokens": 9648472064,
        "learning_rate": 0.00024870964648941426,
        "gradient_norm": 0.3659612238407135,
        "train_loss": 3.0748724937438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18404,
        "tokens": 9648996352,
        "learning_rate": 0.00024868233032699315,
        "gradient_norm": 0.3283846974372864,
        "train_loss": 3.0418663024902344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18405,
        "tokens": 9649520640,
        "learning_rate": 0.00024865501507990366,
        "gradient_norm": 0.3467785120010376,
        "train_loss": 2.9898715019226074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18406,
        "tokens": 9650044928,
        "learning_rate": 0.0002486277007484535,
        "gradient_norm": 0.3319628834724426,
        "train_loss": 3.1005096435546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18407,
        "tokens": 9650569216,
        "learning_rate": 0.0002486003873329499,
        "gradient_norm": 0.3508394658565521,
        "train_loss": 3.0426173210144043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18408,
        "tokens": 9651093504,
        "learning_rate": 0.0002485730748337004,
        "gradient_norm": 0.3465418219566345,
        "train_loss": 3.0323147773742676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18409,
        "tokens": 9651617792,
        "learning_rate": 0.0002485457632510126,
        "gradient_norm": 0.3616715371608734,
        "train_loss": 3.1124987602233887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18410,
        "tokens": 9652142080,
        "learning_rate": 0.0002485184525851936,
        "gradient_norm": 0.31849613785743713,
        "train_loss": 3.113677978515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18411,
        "tokens": 9652666368,
        "learning_rate": 0.00024849114283655106,
        "gradient_norm": 0.35446420311927795,
        "train_loss": 3.097390651702881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18412,
        "tokens": 9653190656,
        "learning_rate": 0.0002484638340053923,
        "gradient_norm": 0.42900440096855164,
        "train_loss": 3.044914484024048,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18413,
        "tokens": 9653714944,
        "learning_rate": 0.00024843652609202475,
        "gradient_norm": 0.3620448410511017,
        "train_loss": 3.0839481353759766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18414,
        "tokens": 9654239232,
        "learning_rate": 0.0002484092190967557,
        "gradient_norm": 0.37344059348106384,
        "train_loss": 3.0332908630371094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18415,
        "tokens": 9654763520,
        "learning_rate": 0.00024838191301989276,
        "gradient_norm": 0.41031044721603394,
        "train_loss": 3.096430778503418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18416,
        "tokens": 9655287808,
        "learning_rate": 0.00024835460786174293,
        "gradient_norm": 0.39228129386901855,
        "train_loss": 3.0989370346069336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18417,
        "tokens": 9655812096,
        "learning_rate": 0.0002483273036226139,
        "gradient_norm": 0.4137657880783081,
        "train_loss": 3.035383701324463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18418,
        "tokens": 9656336384,
        "learning_rate": 0.00024830000030281275,
        "gradient_norm": 0.4343932271003723,
        "train_loss": 3.1100120544433594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18419,
        "tokens": 9656860672,
        "learning_rate": 0.0002482726979026469,
        "gradient_norm": 0.3597266674041748,
        "train_loss": 3.018620014190674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18420,
        "tokens": 9657384960,
        "learning_rate": 0.0002482453964224239,
        "gradient_norm": 0.4044143557548523,
        "train_loss": 3.0201618671417236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18421,
        "tokens": 9657909248,
        "learning_rate": 0.0002482180958624508,
        "gradient_norm": 0.3743758499622345,
        "train_loss": 3.038649559020996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18422,
        "tokens": 9658433536,
        "learning_rate": 0.000248190796223035,
        "gradient_norm": 0.4100069999694824,
        "train_loss": 3.0481038093566895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18423,
        "tokens": 9658957824,
        "learning_rate": 0.00024816349750448366,
        "gradient_norm": 0.3823443651199341,
        "train_loss": 3.049300193786621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18424,
        "tokens": 9659482112,
        "learning_rate": 0.0002481361997071043,
        "gradient_norm": 0.43402138352394104,
        "train_loss": 3.081338405609131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18425,
        "tokens": 9660006400,
        "learning_rate": 0.0002481089028312039,
        "gradient_norm": 0.3687567114830017,
        "train_loss": 3.0707106590270996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18426,
        "tokens": 9660530688,
        "learning_rate": 0.00024808160687709007,
        "gradient_norm": 0.38941726088523865,
        "train_loss": 3.0771431922912598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18427,
        "tokens": 9661054976,
        "learning_rate": 0.0002480543118450697,
        "gradient_norm": 0.3375985324382782,
        "train_loss": 3.1197972297668457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18428,
        "tokens": 9661579264,
        "learning_rate": 0.0002480270177354503,
        "gradient_norm": 0.4735852777957916,
        "train_loss": 3.1023192405700684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18429,
        "tokens": 9662103552,
        "learning_rate": 0.00024799972454853895,
        "gradient_norm": 0.3446575105190277,
        "train_loss": 3.113710403442383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18430,
        "tokens": 9662627840,
        "learning_rate": 0.000247972432284643,
        "gradient_norm": 0.42649513483047485,
        "train_loss": 3.1366372108459473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18431,
        "tokens": 9663152128,
        "learning_rate": 0.0002479451409440695,
        "gradient_norm": 0.34063994884490967,
        "train_loss": 3.145205497741699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18432,
        "tokens": 9663676416,
        "learning_rate": 0.00024791785052712573,
        "gradient_norm": 0.4648062288761139,
        "train_loss": 3.0693955421447754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18433,
        "tokens": 9664200704,
        "learning_rate": 0.00024789056103411886,
        "gradient_norm": 0.3264857232570648,
        "train_loss": 3.071101665496826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18434,
        "tokens": 9664724992,
        "learning_rate": 0.0002478632724653561,
        "gradient_norm": 0.38148030638694763,
        "train_loss": 3.076589584350586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18435,
        "tokens": 9665249280,
        "learning_rate": 0.0002478359848211446,
        "gradient_norm": 0.36312103271484375,
        "train_loss": 3.0753376483917236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18436,
        "tokens": 9665773568,
        "learning_rate": 0.0002478086981017915,
        "gradient_norm": 0.32780155539512634,
        "train_loss": 3.0701584815979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18437,
        "tokens": 9666297856,
        "learning_rate": 0.00024778141230760394,
        "gradient_norm": 0.3423387408256531,
        "train_loss": 3.0563604831695557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18438,
        "tokens": 9666822144,
        "learning_rate": 0.00024775412743888907,
        "gradient_norm": 0.3227589726448059,
        "train_loss": 3.0720443725585938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18439,
        "tokens": 9667346432,
        "learning_rate": 0.00024772684349595405,
        "gradient_norm": 0.33886227011680603,
        "train_loss": 3.063535690307617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18440,
        "tokens": 9667870720,
        "learning_rate": 0.00024769956047910593,
        "gradient_norm": 0.33167245984077454,
        "train_loss": 3.110647201538086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18441,
        "tokens": 9668395008,
        "learning_rate": 0.00024767227838865186,
        "gradient_norm": 0.32706162333488464,
        "train_loss": 3.0504491329193115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18442,
        "tokens": 9668919296,
        "learning_rate": 0.000247644997224899,
        "gradient_norm": 0.3333577513694763,
        "train_loss": 3.058328628540039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18443,
        "tokens": 9669443584,
        "learning_rate": 0.00024761771698815423,
        "gradient_norm": 0.3256770670413971,
        "train_loss": 3.0285110473632812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18444,
        "tokens": 9669967872,
        "learning_rate": 0.00024759043767872487,
        "gradient_norm": 0.31664830446243286,
        "train_loss": 3.085873603820801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18445,
        "tokens": 9670492160,
        "learning_rate": 0.0002475631592969177,
        "gradient_norm": 0.33796676993370056,
        "train_loss": 3.089578628540039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18446,
        "tokens": 9671016448,
        "learning_rate": 0.0002475358818430401,
        "gradient_norm": 0.3233964145183563,
        "train_loss": 3.0966575145721436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18447,
        "tokens": 9671540736,
        "learning_rate": 0.00024750860531739876,
        "gradient_norm": 0.31713443994522095,
        "train_loss": 3.0893311500549316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18448,
        "tokens": 9672065024,
        "learning_rate": 0.000247481329720301,
        "gradient_norm": 0.311784029006958,
        "train_loss": 3.1140027046203613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18449,
        "tokens": 9672589312,
        "learning_rate": 0.00024745405505205377,
        "gradient_norm": 0.342402845621109,
        "train_loss": 3.0917110443115234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18450,
        "tokens": 9673113600,
        "learning_rate": 0.00024742678131296395,
        "gradient_norm": 0.3606880009174347,
        "train_loss": 3.0561513900756836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18451,
        "tokens": 9673637888,
        "learning_rate": 0.00024739950850333875,
        "gradient_norm": 0.3355931043624878,
        "train_loss": 3.071807384490967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18452,
        "tokens": 9674162176,
        "learning_rate": 0.00024737223662348496,
        "gradient_norm": 0.32717642188072205,
        "train_loss": 3.0485167503356934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18453,
        "tokens": 9674686464,
        "learning_rate": 0.00024734496567370976,
        "gradient_norm": 0.35058772563934326,
        "train_loss": 3.018246650695801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18454,
        "tokens": 9675210752,
        "learning_rate": 0.0002473176956543199,
        "gradient_norm": 0.32652977108955383,
        "train_loss": 3.031043291091919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18455,
        "tokens": 9675735040,
        "learning_rate": 0.0002472904265656225,
        "gradient_norm": 0.4009196162223816,
        "train_loss": 3.1025502681732178,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18456,
        "tokens": 9676259328,
        "learning_rate": 0.0002472631584079243,
        "gradient_norm": 0.37366318702697754,
        "train_loss": 3.1159746646881104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18457,
        "tokens": 9676783616,
        "learning_rate": 0.0002472358911815326,
        "gradient_norm": 0.3718094527721405,
        "train_loss": 3.0060086250305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18458,
        "tokens": 9677307904,
        "learning_rate": 0.00024720862488675395,
        "gradient_norm": 0.42724671959877014,
        "train_loss": 3.0874009132385254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18459,
        "tokens": 9677832192,
        "learning_rate": 0.0002471813595238955,
        "gradient_norm": 0.33606475591659546,
        "train_loss": 3.1148595809936523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18460,
        "tokens": 9678356480,
        "learning_rate": 0.00024715409509326407,
        "gradient_norm": 0.3921254575252533,
        "train_loss": 3.105508327484131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18461,
        "tokens": 9678880768,
        "learning_rate": 0.00024712683159516655,
        "gradient_norm": 0.43499550223350525,
        "train_loss": 3.0742719173431396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18462,
        "tokens": 9679405056,
        "learning_rate": 0.00024709956902990997,
        "gradient_norm": 0.3431476652622223,
        "train_loss": 3.1229920387268066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18463,
        "tokens": 9679929344,
        "learning_rate": 0.0002470723073978009,
        "gradient_norm": 0.3885866701602936,
        "train_loss": 3.092297315597534,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18464,
        "tokens": 9680453632,
        "learning_rate": 0.0002470450466991465,
        "gradient_norm": 0.3529673218727112,
        "train_loss": 3.0609350204467773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18465,
        "tokens": 9680977920,
        "learning_rate": 0.0002470177869342534,
        "gradient_norm": 0.37774622440338135,
        "train_loss": 3.0873169898986816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18466,
        "tokens": 9681502208,
        "learning_rate": 0.0002469905281034287,
        "gradient_norm": 0.4306522607803345,
        "train_loss": 3.1072990894317627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18467,
        "tokens": 9682026496,
        "learning_rate": 0.0002469632702069789,
        "gradient_norm": 0.31793123483657837,
        "train_loss": 3.042379379272461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18468,
        "tokens": 9682550784,
        "learning_rate": 0.0002469360132452111,
        "gradient_norm": 0.3926134407520294,
        "train_loss": 3.0807344913482666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18469,
        "tokens": 9683075072,
        "learning_rate": 0.00024690875721843206,
        "gradient_norm": 0.33400896191596985,
        "train_loss": 3.050398826599121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18470,
        "tokens": 9683599360,
        "learning_rate": 0.00024688150212694843,
        "gradient_norm": 0.39810436964035034,
        "train_loss": 3.1130802631378174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18471,
        "tokens": 9684123648,
        "learning_rate": 0.0002468542479710672,
        "gradient_norm": 0.36236268281936646,
        "train_loss": 3.0394163131713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18472,
        "tokens": 9684647936,
        "learning_rate": 0.000246826994751095,
        "gradient_norm": 0.3589462339878082,
        "train_loss": 3.085028648376465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18473,
        "tokens": 9685172224,
        "learning_rate": 0.0002467997424673387,
        "gradient_norm": 0.39332300424575806,
        "train_loss": 3.0292611122131348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18474,
        "tokens": 9685696512,
        "learning_rate": 0.0002467724911201049,
        "gradient_norm": 0.34308522939682007,
        "train_loss": 3.052389621734619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18475,
        "tokens": 9686220800,
        "learning_rate": 0.0002467452407097006,
        "gradient_norm": 0.3905845284461975,
        "train_loss": 3.1057043075561523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18476,
        "tokens": 9686745088,
        "learning_rate": 0.00024671799123643227,
        "gradient_norm": 0.40925392508506775,
        "train_loss": 3.1083297729492188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18477,
        "tokens": 9687269376,
        "learning_rate": 0.0002466907427006069,
        "gradient_norm": 0.3745221793651581,
        "train_loss": 3.0763211250305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18478,
        "tokens": 9687793664,
        "learning_rate": 0.00024666349510253096,
        "gradient_norm": 0.3837689757347107,
        "train_loss": 3.086498737335205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18479,
        "tokens": 9688317952,
        "learning_rate": 0.00024663624844251125,
        "gradient_norm": 0.38154131174087524,
        "train_loss": 3.0497920513153076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18480,
        "tokens": 9688842240,
        "learning_rate": 0.00024660900272085453,
        "gradient_norm": 0.3153120279312134,
        "train_loss": 3.077679395675659,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18481,
        "tokens": 9689366528,
        "learning_rate": 0.0002465817579378675,
        "gradient_norm": 0.3792378008365631,
        "train_loss": 3.1299848556518555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18482,
        "tokens": 9689890816,
        "learning_rate": 0.00024655451409385663,
        "gradient_norm": 0.3369516432285309,
        "train_loss": 3.102029323577881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18483,
        "tokens": 9690415104,
        "learning_rate": 0.0002465272711891288,
        "gradient_norm": 0.3561263084411621,
        "train_loss": 3.0874404907226562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18484,
        "tokens": 9690939392,
        "learning_rate": 0.0002465000292239906,
        "gradient_norm": 0.36850088834762573,
        "train_loss": 3.098471164703369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18485,
        "tokens": 9691463680,
        "learning_rate": 0.00024647278819874864,
        "gradient_norm": 0.4007386267185211,
        "train_loss": 3.084519624710083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18486,
        "tokens": 9691987968,
        "learning_rate": 0.0002464455481137095,
        "gradient_norm": 0.45416584610939026,
        "train_loss": 3.018794059753418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18487,
        "tokens": 9692512256,
        "learning_rate": 0.00024641830896918,
        "gradient_norm": 0.33402523398399353,
        "train_loss": 3.0997142791748047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18488,
        "tokens": 9693036544,
        "learning_rate": 0.0002463910707654664,
        "gradient_norm": 0.4850136935710907,
        "train_loss": 3.042914867401123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18489,
        "tokens": 9693560832,
        "learning_rate": 0.00024636383350287575,
        "gradient_norm": 0.33591270446777344,
        "train_loss": 3.153474807739258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18490,
        "tokens": 9694085120,
        "learning_rate": 0.0002463365971817143,
        "gradient_norm": 0.4167915880680084,
        "train_loss": 3.0713753700256348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18491,
        "tokens": 9694609408,
        "learning_rate": 0.0002463093618022888,
        "gradient_norm": 0.33051663637161255,
        "train_loss": 3.1016640663146973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18492,
        "tokens": 9695133696,
        "learning_rate": 0.00024628212736490563,
        "gradient_norm": 0.456513911485672,
        "train_loss": 3.026884078979492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18493,
        "tokens": 9695657984,
        "learning_rate": 0.0002462548938698716,
        "gradient_norm": 0.3603276312351227,
        "train_loss": 3.0022873878479004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18494,
        "tokens": 9696182272,
        "learning_rate": 0.0002462276613174931,
        "gradient_norm": 0.36420610547065735,
        "train_loss": 3.095442295074463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18495,
        "tokens": 9696706560,
        "learning_rate": 0.00024620042970807665,
        "gradient_norm": 0.3337223529815674,
        "train_loss": 3.1426820755004883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18496,
        "tokens": 9697230848,
        "learning_rate": 0.0002461731990419289,
        "gradient_norm": 0.4058975875377655,
        "train_loss": 3.090986728668213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18497,
        "tokens": 9697755136,
        "learning_rate": 0.00024614596931935625,
        "gradient_norm": 0.37007611989974976,
        "train_loss": 3.090982675552368,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18498,
        "tokens": 9698279424,
        "learning_rate": 0.0002461187405406653,
        "gradient_norm": 0.3661127984523773,
        "train_loss": 3.0411503314971924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18499,
        "tokens": 9698803712,
        "learning_rate": 0.0002460915127061623,
        "gradient_norm": 0.33544668555259705,
        "train_loss": 3.036525249481201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18500,
        "tokens": 9699328000,
        "learning_rate": 0.0002460642858161541,
        "gradient_norm": 0.36122068762779236,
        "train_loss": 3.0857510566711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18501,
        "tokens": 9699852288,
        "learning_rate": 0.0002460370598709469,
        "gradient_norm": 0.30776628851890564,
        "train_loss": 3.0382285118103027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18502,
        "tokens": 9700376576,
        "learning_rate": 0.0002460098348708473,
        "gradient_norm": 0.33952537178993225,
        "train_loss": 3.0943896770477295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18503,
        "tokens": 9700900864,
        "learning_rate": 0.0002459826108161617,
        "gradient_norm": 0.3151912987232208,
        "train_loss": 3.0405964851379395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18504,
        "tokens": 9701425152,
        "learning_rate": 0.0002459553877071966,
        "gradient_norm": 0.3518812358379364,
        "train_loss": 3.0963499546051025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18505,
        "tokens": 9701949440,
        "learning_rate": 0.0002459281655442583,
        "gradient_norm": 0.31468069553375244,
        "train_loss": 3.068047523498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18506,
        "tokens": 9702473728,
        "learning_rate": 0.00024590094432765336,
        "gradient_norm": 0.35595718026161194,
        "train_loss": 3.0815718173980713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18507,
        "tokens": 9702998016,
        "learning_rate": 0.000245873724057688,
        "gradient_norm": 0.3232390284538269,
        "train_loss": 3.040266990661621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18508,
        "tokens": 9703522304,
        "learning_rate": 0.00024584650473466875,
        "gradient_norm": 0.3552388846874237,
        "train_loss": 3.053328514099121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18509,
        "tokens": 9704046592,
        "learning_rate": 0.0002458192863589021,
        "gradient_norm": 0.40129441022872925,
        "train_loss": 3.0783441066741943,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18510,
        "tokens": 9704570880,
        "learning_rate": 0.00024579206893069426,
        "gradient_norm": 0.3336411118507385,
        "train_loss": 3.056511878967285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18511,
        "tokens": 9705095168,
        "learning_rate": 0.00024576485245035167,
        "gradient_norm": 0.3590492010116577,
        "train_loss": 3.0603854656219482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18512,
        "tokens": 9705619456,
        "learning_rate": 0.0002457376369181806,
        "gradient_norm": 0.3624629080295563,
        "train_loss": 3.0994973182678223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18513,
        "tokens": 9706143744,
        "learning_rate": 0.0002457104223344876,
        "gradient_norm": 0.35662537813186646,
        "train_loss": 3.054560661315918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18514,
        "tokens": 9706668032,
        "learning_rate": 0.0002456832086995788,
        "gradient_norm": 0.40738987922668457,
        "train_loss": 3.0712432861328125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18515,
        "tokens": 9707192320,
        "learning_rate": 0.0002456559960137606,
        "gradient_norm": 0.3661944270133972,
        "train_loss": 3.122241258621216,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18516,
        "tokens": 9707716608,
        "learning_rate": 0.0002456287842773392,
        "gradient_norm": 0.40361759066581726,
        "train_loss": 3.0425643920898438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18517,
        "tokens": 9708240896,
        "learning_rate": 0.00024560157349062117,
        "gradient_norm": 0.33466291427612305,
        "train_loss": 3.0954623222351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18518,
        "tokens": 9708765184,
        "learning_rate": 0.0002455743636539125,
        "gradient_norm": 0.443097859621048,
        "train_loss": 3.1860411167144775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18519,
        "tokens": 9709289472,
        "learning_rate": 0.00024554715476751964,
        "gradient_norm": 0.3386476933956146,
        "train_loss": 3.0440726280212402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18520,
        "tokens": 9709813760,
        "learning_rate": 0.0002455199468317489,
        "gradient_norm": 0.42679405212402344,
        "train_loss": 3.075634241104126,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18521,
        "tokens": 9710338048,
        "learning_rate": 0.00024549273984690633,
        "gradient_norm": 0.44504740834236145,
        "train_loss": 3.073101043701172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18522,
        "tokens": 9710862336,
        "learning_rate": 0.00024546553381329846,
        "gradient_norm": 0.3554692268371582,
        "train_loss": 3.026075601577759,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18523,
        "tokens": 9711386624,
        "learning_rate": 0.00024543832873123126,
        "gradient_norm": 0.4160400927066803,
        "train_loss": 3.129887104034424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18524,
        "tokens": 9711910912,
        "learning_rate": 0.0002454111246010112,
        "gradient_norm": 0.3179265856742859,
        "train_loss": 3.072277069091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18525,
        "tokens": 9712435200,
        "learning_rate": 0.0002453839214229443,
        "gradient_norm": 0.40563830733299255,
        "train_loss": 3.0474982261657715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18526,
        "tokens": 9712959488,
        "learning_rate": 0.00024535671919733684,
        "gradient_norm": 0.3217547833919525,
        "train_loss": 3.072018623352051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18527,
        "tokens": 9713483776,
        "learning_rate": 0.00024532951792449503,
        "gradient_norm": 0.35719773173332214,
        "train_loss": 3.0807242393493652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18528,
        "tokens": 9714008064,
        "learning_rate": 0.00024530231760472494,
        "gradient_norm": 0.34362339973449707,
        "train_loss": 3.0903072357177734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18529,
        "tokens": 9714532352,
        "learning_rate": 0.00024527511823833306,
        "gradient_norm": 0.3841194808483124,
        "train_loss": 3.0608720779418945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18530,
        "tokens": 9715056640,
        "learning_rate": 0.00024524791982562515,
        "gradient_norm": 0.3341621458530426,
        "train_loss": 3.056633949279785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18531,
        "tokens": 9715580928,
        "learning_rate": 0.0002452207223669077,
        "gradient_norm": 0.3346787393093109,
        "train_loss": 3.064547300338745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18532,
        "tokens": 9716105216,
        "learning_rate": 0.0002451935258624865,
        "gradient_norm": 0.3518461585044861,
        "train_loss": 3.0902607440948486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18533,
        "tokens": 9716629504,
        "learning_rate": 0.0002451663303126681,
        "gradient_norm": 0.3059661388397217,
        "train_loss": 3.0233683586120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18534,
        "tokens": 9717153792,
        "learning_rate": 0.0002451391357177582,
        "gradient_norm": 0.3356594741344452,
        "train_loss": 3.096433162689209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18535,
        "tokens": 9717678080,
        "learning_rate": 0.0002451119420780633,
        "gradient_norm": 0.3395631015300751,
        "train_loss": 3.087583541870117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18536,
        "tokens": 9718202368,
        "learning_rate": 0.0002450847493938892,
        "gradient_norm": 0.33017203211784363,
        "train_loss": 3.0797438621520996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18537,
        "tokens": 9718726656,
        "learning_rate": 0.00024505755766554213,
        "gradient_norm": 0.3368363082408905,
        "train_loss": 3.064638137817383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18538,
        "tokens": 9719250944,
        "learning_rate": 0.00024503036689332803,
        "gradient_norm": 0.3205086290836334,
        "train_loss": 3.110874652862549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18539,
        "tokens": 9719775232,
        "learning_rate": 0.0002450031770775532,
        "gradient_norm": 0.31834179162979126,
        "train_loss": 3.0698554515838623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18540,
        "tokens": 9720299520,
        "learning_rate": 0.00024497598821852354,
        "gradient_norm": 0.3212135136127472,
        "train_loss": 3.0404181480407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18541,
        "tokens": 9720823808,
        "learning_rate": 0.00024494880031654506,
        "gradient_norm": 0.34430360794067383,
        "train_loss": 3.0407376289367676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18542,
        "tokens": 9721348096,
        "learning_rate": 0.0002449216133719239,
        "gradient_norm": 0.35748085379600525,
        "train_loss": 3.0602872371673584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18543,
        "tokens": 9721872384,
        "learning_rate": 0.000244894427384966,
        "gradient_norm": 0.3381797969341278,
        "train_loss": 3.090543508529663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18544,
        "tokens": 9722396672,
        "learning_rate": 0.0002448672423559775,
        "gradient_norm": 0.34149491786956787,
        "train_loss": 3.1186304092407227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18545,
        "tokens": 9722920960,
        "learning_rate": 0.00024484005828526417,
        "gradient_norm": 0.35682934522628784,
        "train_loss": 3.04841685295105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18546,
        "tokens": 9723445248,
        "learning_rate": 0.0002448128751731322,
        "gradient_norm": 0.3117596507072449,
        "train_loss": 3.0729238986968994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18547,
        "tokens": 9723969536,
        "learning_rate": 0.00024478569301988754,
        "gradient_norm": 0.34850946068763733,
        "train_loss": 3.0336294174194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18548,
        "tokens": 9724493824,
        "learning_rate": 0.00024475851182583603,
        "gradient_norm": 0.30970796942710876,
        "train_loss": 3.105921745300293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18549,
        "tokens": 9725018112,
        "learning_rate": 0.0002447313315912838,
        "gradient_norm": 0.39579516649246216,
        "train_loss": 3.041388511657715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18550,
        "tokens": 9725542400,
        "learning_rate": 0.0002447041523165367,
        "gradient_norm": 0.3374006152153015,
        "train_loss": 3.0588908195495605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18551,
        "tokens": 9726066688,
        "learning_rate": 0.00024467697400190077,
        "gradient_norm": 0.39303064346313477,
        "train_loss": 3.100306510925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18552,
        "tokens": 9726590976,
        "learning_rate": 0.00024464979664768174,
        "gradient_norm": 0.36491039395332336,
        "train_loss": 3.0447349548339844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18553,
        "tokens": 9727115264,
        "learning_rate": 0.0002446226202541858,
        "gradient_norm": 0.3603571653366089,
        "train_loss": 3.0566811561584473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18554,
        "tokens": 9727639552,
        "learning_rate": 0.00024459544482171853,
        "gradient_norm": 0.3474772274494171,
        "train_loss": 3.0691189765930176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18555,
        "tokens": 9728163840,
        "learning_rate": 0.0002445682703505861,
        "gradient_norm": 0.325557142496109,
        "train_loss": 3.031923294067383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18556,
        "tokens": 9728688128,
        "learning_rate": 0.00024454109684109415,
        "gradient_norm": 0.338521808385849,
        "train_loss": 3.123508930206299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18557,
        "tokens": 9729212416,
        "learning_rate": 0.00024451392429354884,
        "gradient_norm": 0.346316933631897,
        "train_loss": 3.0075457096099854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18558,
        "tokens": 9729736704,
        "learning_rate": 0.00024448675270825567,
        "gradient_norm": 0.47405800223350525,
        "train_loss": 3.0966198444366455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18559,
        "tokens": 9730260992,
        "learning_rate": 0.00024445958208552083,
        "gradient_norm": 0.40564092993736267,
        "train_loss": 3.0454349517822266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18560,
        "tokens": 9730785280,
        "learning_rate": 0.00024443241242565005,
        "gradient_norm": 0.34038498997688293,
        "train_loss": 3.0862886905670166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18561,
        "tokens": 9731309568,
        "learning_rate": 0.00024440524372894897,
        "gradient_norm": 0.42530205845832825,
        "train_loss": 3.0805070400238037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18562,
        "tokens": 9731833856,
        "learning_rate": 0.0002443780759957238,
        "gradient_norm": 0.3641981780529022,
        "train_loss": 3.0905442237854004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18563,
        "tokens": 9732358144,
        "learning_rate": 0.00024435090922627994,
        "gradient_norm": 0.3734542727470398,
        "train_loss": 3.127138376235962,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18564,
        "tokens": 9732882432,
        "learning_rate": 0.0002443237434209235,
        "gradient_norm": 0.4219558537006378,
        "train_loss": 3.0997323989868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18565,
        "tokens": 9733406720,
        "learning_rate": 0.00024429657857995995,
        "gradient_norm": 0.324124276638031,
        "train_loss": 3.0854172706604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18566,
        "tokens": 9733931008,
        "learning_rate": 0.0002442694147036954,
        "gradient_norm": 0.3592335879802704,
        "train_loss": 3.064026355743408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18567,
        "tokens": 9734455296,
        "learning_rate": 0.00024424225179243536,
        "gradient_norm": 0.4307613968849182,
        "train_loss": 3.0727462768554688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18568,
        "tokens": 9734979584,
        "learning_rate": 0.0002442150898464857,
        "gradient_norm": 0.37360379099845886,
        "train_loss": 3.0620296001434326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18569,
        "tokens": 9735503872,
        "learning_rate": 0.00024418792886615217,
        "gradient_norm": 0.3774462938308716,
        "train_loss": 3.096858024597168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18570,
        "tokens": 9736028160,
        "learning_rate": 0.0002441607688517404,
        "gradient_norm": 0.39640817046165466,
        "train_loss": 3.061906099319458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18571,
        "tokens": 9736552448,
        "learning_rate": 0.00024413360980355629,
        "gradient_norm": 0.3521392345428467,
        "train_loss": 3.061603546142578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18572,
        "tokens": 9737076736,
        "learning_rate": 0.00024410645172190533,
        "gradient_norm": 0.3991047441959381,
        "train_loss": 3.075319766998291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18573,
        "tokens": 9737601024,
        "learning_rate": 0.0002440792946070934,
        "gradient_norm": 0.4173876941204071,
        "train_loss": 3.0905489921569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18574,
        "tokens": 9738125312,
        "learning_rate": 0.00024405213845942603,
        "gradient_norm": 0.42940229177474976,
        "train_loss": 3.1205129623413086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18575,
        "tokens": 9738649600,
        "learning_rate": 0.00024402498327920908,
        "gradient_norm": 0.37415769696235657,
        "train_loss": 3.038656711578369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18576,
        "tokens": 9739173888,
        "learning_rate": 0.000243997829066748,
        "gradient_norm": 0.38522616028785706,
        "train_loss": 3.1111669540405273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18577,
        "tokens": 9739698176,
        "learning_rate": 0.0002439706758223487,
        "gradient_norm": 0.36219653487205505,
        "train_loss": 3.0730395317077637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18578,
        "tokens": 9740222464,
        "learning_rate": 0.00024394352354631653,
        "gradient_norm": 0.34970542788505554,
        "train_loss": 3.0457162857055664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18579,
        "tokens": 9740746752,
        "learning_rate": 0.00024391637223895727,
        "gradient_norm": 0.34755924344062805,
        "train_loss": 3.0600900650024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18580,
        "tokens": 9741271040,
        "learning_rate": 0.0002438892219005767,
        "gradient_norm": 0.3243798613548279,
        "train_loss": 3.020613193511963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18581,
        "tokens": 9741795328,
        "learning_rate": 0.00024386207253148013,
        "gradient_norm": 0.3582068383693695,
        "train_loss": 3.1534013748168945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18582,
        "tokens": 9742319616,
        "learning_rate": 0.00024383492413197343,
        "gradient_norm": 0.4764438271522522,
        "train_loss": 3.282686471939087,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18583,
        "tokens": 9742843904,
        "learning_rate": 0.00024380777670236198,
        "gradient_norm": 0.39431294798851013,
        "train_loss": 3.097522258758545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18584,
        "tokens": 9743368192,
        "learning_rate": 0.00024378063024295152,
        "gradient_norm": 0.4114193618297577,
        "train_loss": 3.0782265663146973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18585,
        "tokens": 9743892480,
        "learning_rate": 0.00024375348475404746,
        "gradient_norm": 0.3241559565067291,
        "train_loss": 3.1005358695983887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18586,
        "tokens": 9744416768,
        "learning_rate": 0.00024372634023595553,
        "gradient_norm": 0.42381036281585693,
        "train_loss": 3.1870479583740234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18587,
        "tokens": 9744941056,
        "learning_rate": 0.00024369919668898107,
        "gradient_norm": 0.36689284443855286,
        "train_loss": 3.0466697216033936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18588,
        "tokens": 9745465344,
        "learning_rate": 0.0002436720541134298,
        "gradient_norm": 0.3178523778915405,
        "train_loss": 3.0353755950927734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18589,
        "tokens": 9745989632,
        "learning_rate": 0.00024364491250960716,
        "gradient_norm": 0.36146166920661926,
        "train_loss": 3.0373919010162354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18590,
        "tokens": 9746513920,
        "learning_rate": 0.0002436177718778187,
        "gradient_norm": 0.40226125717163086,
        "train_loss": 3.0815000534057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18591,
        "tokens": 9747038208,
        "learning_rate": 0.00024359063221836988,
        "gradient_norm": 0.4438854455947876,
        "train_loss": 3.064202308654785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18592,
        "tokens": 9747562496,
        "learning_rate": 0.00024356349353156617,
        "gradient_norm": 0.3612729609012604,
        "train_loss": 3.052511215209961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18593,
        "tokens": 9748086784,
        "learning_rate": 0.00024353635581771314,
        "gradient_norm": 0.37889108061790466,
        "train_loss": 3.0610673427581787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18594,
        "tokens": 9748611072,
        "learning_rate": 0.00024350921907711616,
        "gradient_norm": 0.46317675709724426,
        "train_loss": 3.0259172916412354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18595,
        "tokens": 9749135360,
        "learning_rate": 0.00024348208331008076,
        "gradient_norm": 0.4106244742870331,
        "train_loss": 3.1263952255249023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18596,
        "tokens": 9749659648,
        "learning_rate": 0.00024345494851691236,
        "gradient_norm": 0.37982842326164246,
        "train_loss": 3.1209142208099365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18597,
        "tokens": 9750183936,
        "learning_rate": 0.00024342781469791636,
        "gradient_norm": 0.41992583870887756,
        "train_loss": 3.1551153659820557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18598,
        "tokens": 9750708224,
        "learning_rate": 0.00024340068185339827,
        "gradient_norm": 0.38511109352111816,
        "train_loss": 3.1886682510375977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18599,
        "tokens": 9751232512,
        "learning_rate": 0.0002433735499836634,
        "gradient_norm": 0.42897680401802063,
        "train_loss": 3.101391077041626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18600,
        "tokens": 9751756800,
        "learning_rate": 0.00024334641908901726,
        "gradient_norm": 0.3647916913032532,
        "train_loss": 3.006014347076416,
        "val_loss": 3.0372085571289062,
        "hellaswag_acc": 0.28131845593452454,
        "hellaswag_acc_norm": 0.2881895899772644
    },
    {
        "step": 18601,
        "tokens": 9752281088,
        "learning_rate": 0.00024331928916976512,
        "gradient_norm": 0.33676382899284363,
        "train_loss": 3.085653781890869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18602,
        "tokens": 9752805376,
        "learning_rate": 0.00024329216022621257,
        "gradient_norm": 0.43800368905067444,
        "train_loss": 3.1614341735839844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18603,
        "tokens": 9753329664,
        "learning_rate": 0.00024326503225866468,
        "gradient_norm": 0.3545021414756775,
        "train_loss": 3.081707000732422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18604,
        "tokens": 9753853952,
        "learning_rate": 0.0002432379052674271,
        "gradient_norm": 0.36437225341796875,
        "train_loss": 3.071610450744629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18605,
        "tokens": 9754378240,
        "learning_rate": 0.0002432107792528049,
        "gradient_norm": 0.35961291193962097,
        "train_loss": 3.113870143890381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18606,
        "tokens": 9754902528,
        "learning_rate": 0.00024318365421510373,
        "gradient_norm": 0.3675415813922882,
        "train_loss": 3.052412986755371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18607,
        "tokens": 9755426816,
        "learning_rate": 0.0002431565301546286,
        "gradient_norm": 0.33429405093193054,
        "train_loss": 3.078357219696045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18608,
        "tokens": 9755951104,
        "learning_rate": 0.00024312940707168503,
        "gradient_norm": 0.38806334137916565,
        "train_loss": 3.0587105751037598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18609,
        "tokens": 9756475392,
        "learning_rate": 0.00024310228496657836,
        "gradient_norm": 0.34205108880996704,
        "train_loss": 3.0637941360473633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18610,
        "tokens": 9756999680,
        "learning_rate": 0.00024307516383961366,
        "gradient_norm": 0.3781355917453766,
        "train_loss": 3.067074775695801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18611,
        "tokens": 9757523968,
        "learning_rate": 0.00024304804369109647,
        "gradient_norm": 0.3599775433540344,
        "train_loss": 3.039092779159546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18612,
        "tokens": 9758048256,
        "learning_rate": 0.00024302092452133182,
        "gradient_norm": 0.3462640047073364,
        "train_loss": 3.097985029220581,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18613,
        "tokens": 9758572544,
        "learning_rate": 0.0002429938063306252,
        "gradient_norm": 0.3616216480731964,
        "train_loss": 3.0390262603759766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18614,
        "tokens": 9759096832,
        "learning_rate": 0.00024296668911928164,
        "gradient_norm": 0.3248087465763092,
        "train_loss": 3.0705771446228027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18615,
        "tokens": 9759621120,
        "learning_rate": 0.00024293957288760656,
        "gradient_norm": 0.3536742925643921,
        "train_loss": 3.0335888862609863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18616,
        "tokens": 9760145408,
        "learning_rate": 0.00024291245763590508,
        "gradient_norm": 0.3291724920272827,
        "train_loss": 3.116894245147705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18617,
        "tokens": 9760669696,
        "learning_rate": 0.0002428853433644825,
        "gradient_norm": 0.35029345750808716,
        "train_loss": 3.0589599609375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18618,
        "tokens": 9761193984,
        "learning_rate": 0.00024285823007364385,
        "gradient_norm": 0.37163978815078735,
        "train_loss": 3.061436653137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18619,
        "tokens": 9761718272,
        "learning_rate": 0.00024283111776369446,
        "gradient_norm": 0.33553701639175415,
        "train_loss": 3.0673046112060547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18620,
        "tokens": 9762242560,
        "learning_rate": 0.00024280400643493963,
        "gradient_norm": 0.34809044003486633,
        "train_loss": 3.007932186126709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18621,
        "tokens": 9762766848,
        "learning_rate": 0.00024277689608768427,
        "gradient_norm": 0.3716298043727875,
        "train_loss": 3.077277183532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18622,
        "tokens": 9763291136,
        "learning_rate": 0.0002427497867222338,
        "gradient_norm": 0.3472541570663452,
        "train_loss": 3.0223276615142822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18623,
        "tokens": 9763815424,
        "learning_rate": 0.0002427226783388931,
        "gradient_norm": 0.3362014591693878,
        "train_loss": 3.058051586151123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18624,
        "tokens": 9764339712,
        "learning_rate": 0.00024269557093796758,
        "gradient_norm": 0.38305947184562683,
        "train_loss": 3.080165147781372,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18625,
        "tokens": 9764864000,
        "learning_rate": 0.00024266846451976212,
        "gradient_norm": 0.3478688895702362,
        "train_loss": 3.0946624279022217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18626,
        "tokens": 9765388288,
        "learning_rate": 0.00024264135908458207,
        "gradient_norm": 0.36984026432037354,
        "train_loss": 3.1506686210632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18627,
        "tokens": 9765912576,
        "learning_rate": 0.0002426142546327323,
        "gradient_norm": 0.35092195868492126,
        "train_loss": 3.0072576999664307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18628,
        "tokens": 9766436864,
        "learning_rate": 0.00024258715116451805,
        "gradient_norm": 0.35215139389038086,
        "train_loss": 3.115805149078369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18629,
        "tokens": 9766961152,
        "learning_rate": 0.00024256004868024447,
        "gradient_norm": 0.35707351565361023,
        "train_loss": 3.102212905883789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18630,
        "tokens": 9767485440,
        "learning_rate": 0.0002425329471802164,
        "gradient_norm": 0.3233890235424042,
        "train_loss": 3.0625412464141846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18631,
        "tokens": 9768009728,
        "learning_rate": 0.00024250584666473917,
        "gradient_norm": 0.34209585189819336,
        "train_loss": 3.0969815254211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18632,
        "tokens": 9768534016,
        "learning_rate": 0.0002424787471341176,
        "gradient_norm": 0.3735348880290985,
        "train_loss": 3.0421528816223145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18633,
        "tokens": 9769058304,
        "learning_rate": 0.00024245164858865693,
        "gradient_norm": 0.3526131212711334,
        "train_loss": 3.04313325881958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18634,
        "tokens": 9769582592,
        "learning_rate": 0.000242424551028662,
        "gradient_norm": 0.3179565370082855,
        "train_loss": 3.051966905593872,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18635,
        "tokens": 9770106880,
        "learning_rate": 0.000242397454454438,
        "gradient_norm": 0.3825254440307617,
        "train_loss": 3.0946431159973145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18636,
        "tokens": 9770631168,
        "learning_rate": 0.00024237035886628974,
        "gradient_norm": 0.4167262017726898,
        "train_loss": 3.0174365043640137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18637,
        "tokens": 9771155456,
        "learning_rate": 0.0002423432642645224,
        "gradient_norm": 0.3783073127269745,
        "train_loss": 3.0930891036987305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18638,
        "tokens": 9771679744,
        "learning_rate": 0.00024231617064944086,
        "gradient_norm": 0.3749505579471588,
        "train_loss": 3.0779995918273926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18639,
        "tokens": 9772204032,
        "learning_rate": 0.0002422890780213501,
        "gradient_norm": 0.4113708734512329,
        "train_loss": 3.01519775390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18640,
        "tokens": 9772728320,
        "learning_rate": 0.00024226198638055516,
        "gradient_norm": 0.3545714318752289,
        "train_loss": 3.09594988822937,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18641,
        "tokens": 9773252608,
        "learning_rate": 0.00024223489572736088,
        "gradient_norm": 0.4176449477672577,
        "train_loss": 3.0404815673828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18642,
        "tokens": 9773776896,
        "learning_rate": 0.00024220780606207227,
        "gradient_norm": 0.3644026815891266,
        "train_loss": 3.0268096923828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18643,
        "tokens": 9774301184,
        "learning_rate": 0.00024218071738499425,
        "gradient_norm": 0.38743162155151367,
        "train_loss": 3.069880247116089,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18644,
        "tokens": 9774825472,
        "learning_rate": 0.0002421536296964317,
        "gradient_norm": 0.3932967483997345,
        "train_loss": 3.072082757949829,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18645,
        "tokens": 9775349760,
        "learning_rate": 0.00024212654299668958,
        "gradient_norm": 0.4530969560146332,
        "train_loss": 3.080843448638916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18646,
        "tokens": 9775874048,
        "learning_rate": 0.00024209945728607274,
        "gradient_norm": 0.42180657386779785,
        "train_loss": 3.0392985343933105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18647,
        "tokens": 9776398336,
        "learning_rate": 0.0002420723725648861,
        "gradient_norm": 0.372920423746109,
        "train_loss": 3.090325355529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18648,
        "tokens": 9776922624,
        "learning_rate": 0.00024204528883343441,
        "gradient_norm": 0.3979431092739105,
        "train_loss": 3.0874485969543457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18649,
        "tokens": 9777446912,
        "learning_rate": 0.00024201820609202283,
        "gradient_norm": 0.35485124588012695,
        "train_loss": 3.076516628265381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18650,
        "tokens": 9777971200,
        "learning_rate": 0.0002419911243409558,
        "gradient_norm": 0.35902127623558044,
        "train_loss": 3.079627513885498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18651,
        "tokens": 9778495488,
        "learning_rate": 0.00024196404358053854,
        "gradient_norm": 0.3235524594783783,
        "train_loss": 3.0459375381469727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18652,
        "tokens": 9779019776,
        "learning_rate": 0.0002419369638110756,
        "gradient_norm": 0.3688810467720032,
        "train_loss": 3.0241200923919678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18653,
        "tokens": 9779544064,
        "learning_rate": 0.000241909885032872,
        "gradient_norm": 0.3345991373062134,
        "train_loss": 3.0812530517578125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18654,
        "tokens": 9780068352,
        "learning_rate": 0.00024188280724623233,
        "gradient_norm": 0.3674469292163849,
        "train_loss": 3.032933235168457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18655,
        "tokens": 9780592640,
        "learning_rate": 0.00024185573045146163,
        "gradient_norm": 0.381004273891449,
        "train_loss": 3.085023880004883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18656,
        "tokens": 9781116928,
        "learning_rate": 0.00024182865464886444,
        "gradient_norm": 0.335606187582016,
        "train_loss": 3.061074733734131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18657,
        "tokens": 9781641216,
        "learning_rate": 0.0002418015798387458,
        "gradient_norm": 0.3523808717727661,
        "train_loss": 3.086677312850952,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18658,
        "tokens": 9782165504,
        "learning_rate": 0.00024177450602141015,
        "gradient_norm": 0.32667627930641174,
        "train_loss": 3.046562910079956,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18659,
        "tokens": 9782689792,
        "learning_rate": 0.00024174743319716244,
        "gradient_norm": 0.32461684942245483,
        "train_loss": 3.0597620010375977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18660,
        "tokens": 9783214080,
        "learning_rate": 0.0002417203613663075,
        "gradient_norm": 0.30533185601234436,
        "train_loss": 3.0468783378601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18661,
        "tokens": 9783738368,
        "learning_rate": 0.0002416932905291498,
        "gradient_norm": 0.3170647919178009,
        "train_loss": 3.1040053367614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18662,
        "tokens": 9784262656,
        "learning_rate": 0.00024166622068599433,
        "gradient_norm": 0.3816673457622528,
        "train_loss": 3.0838499069213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18663,
        "tokens": 9784786944,
        "learning_rate": 0.0002416391518371455,
        "gradient_norm": 0.37343457341194153,
        "train_loss": 3.0654263496398926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18664,
        "tokens": 9785311232,
        "learning_rate": 0.00024161208398290832,
        "gradient_norm": 0.3566160202026367,
        "train_loss": 3.074350118637085,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18665,
        "tokens": 9785835520,
        "learning_rate": 0.0002415850171235872,
        "gradient_norm": 0.3974250853061676,
        "train_loss": 3.0584073066711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18666,
        "tokens": 9786359808,
        "learning_rate": 0.00024155795125948703,
        "gradient_norm": 0.3626258969306946,
        "train_loss": 3.01483154296875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18667,
        "tokens": 9786884096,
        "learning_rate": 0.00024153088639091225,
        "gradient_norm": 0.40369096398353577,
        "train_loss": 3.083178997039795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18668,
        "tokens": 9787408384,
        "learning_rate": 0.0002415038225181676,
        "gradient_norm": 0.40958189964294434,
        "train_loss": 3.0655760765075684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18669,
        "tokens": 9787932672,
        "learning_rate": 0.00024147675964155787,
        "gradient_norm": 0.3530191481113434,
        "train_loss": 3.0614991188049316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18670,
        "tokens": 9788456960,
        "learning_rate": 0.00024144969776138746,
        "gradient_norm": 0.46042600274086,
        "train_loss": 3.0651111602783203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18671,
        "tokens": 9788981248,
        "learning_rate": 0.00024142263687796118,
        "gradient_norm": 0.34593865275382996,
        "train_loss": 3.0789732933044434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18672,
        "tokens": 9789505536,
        "learning_rate": 0.0002413955769915834,
        "gradient_norm": 0.3759842813014984,
        "train_loss": 3.0621719360351562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18673,
        "tokens": 9790029824,
        "learning_rate": 0.000241368518102559,
        "gradient_norm": 0.3324151039123535,
        "train_loss": 3.0659661293029785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18674,
        "tokens": 9790554112,
        "learning_rate": 0.0002413414602111923,
        "gradient_norm": 0.3766380846500397,
        "train_loss": 3.1140708923339844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18675,
        "tokens": 9791078400,
        "learning_rate": 0.00024131440331778806,
        "gradient_norm": 0.389295369386673,
        "train_loss": 3.0883307456970215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18676,
        "tokens": 9791602688,
        "learning_rate": 0.0002412873474226507,
        "gradient_norm": 0.36444059014320374,
        "train_loss": 3.0862386226654053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18677,
        "tokens": 9792126976,
        "learning_rate": 0.0002412602925260849,
        "gradient_norm": 0.325662225484848,
        "train_loss": 3.068868637084961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18678,
        "tokens": 9792651264,
        "learning_rate": 0.000241233238628395,
        "gradient_norm": 0.3515402674674988,
        "train_loss": 3.093038558959961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18679,
        "tokens": 9793175552,
        "learning_rate": 0.00024120618572988568,
        "gradient_norm": 0.3311459720134735,
        "train_loss": 3.094507932662964,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18680,
        "tokens": 9793699840,
        "learning_rate": 0.00024117913383086152,
        "gradient_norm": 0.38611117005348206,
        "train_loss": 3.1374783515930176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18681,
        "tokens": 9794224128,
        "learning_rate": 0.00024115208293162683,
        "gradient_norm": 0.34974947571754456,
        "train_loss": 3.072289228439331,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18682,
        "tokens": 9794748416,
        "learning_rate": 0.00024112503303248633,
        "gradient_norm": 0.3692757785320282,
        "train_loss": 3.0716099739074707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18683,
        "tokens": 9795272704,
        "learning_rate": 0.0002410979841337442,
        "gradient_norm": 0.35911041498184204,
        "train_loss": 3.0689451694488525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18684,
        "tokens": 9795796992,
        "learning_rate": 0.00024107093623570522,
        "gradient_norm": 0.4073772132396698,
        "train_loss": 3.051046371459961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18685,
        "tokens": 9796321280,
        "learning_rate": 0.0002410438893386736,
        "gradient_norm": 0.3633100390434265,
        "train_loss": 3.135129928588867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18686,
        "tokens": 9796845568,
        "learning_rate": 0.000241016843442954,
        "gradient_norm": 0.345917671918869,
        "train_loss": 3.0622310638427734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18687,
        "tokens": 9797369856,
        "learning_rate": 0.00024098979854885063,
        "gradient_norm": 0.3625392019748688,
        "train_loss": 3.0714008808135986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18688,
        "tokens": 9797894144,
        "learning_rate": 0.00024096275465666808,
        "gradient_norm": 0.3550734519958496,
        "train_loss": 3.055898904800415,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18689,
        "tokens": 9798418432,
        "learning_rate": 0.00024093571176671074,
        "gradient_norm": 0.3612557351589203,
        "train_loss": 3.1146042346954346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18690,
        "tokens": 9798942720,
        "learning_rate": 0.00024090866987928295,
        "gradient_norm": 0.348861426115036,
        "train_loss": 3.0562691688537598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18691,
        "tokens": 9799467008,
        "learning_rate": 0.00024088162899468915,
        "gradient_norm": 0.38154998421669006,
        "train_loss": 3.0735814571380615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18692,
        "tokens": 9799991296,
        "learning_rate": 0.00024085458911323374,
        "gradient_norm": 0.38229820132255554,
        "train_loss": 3.097550392150879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18693,
        "tokens": 9800515584,
        "learning_rate": 0.000240827550235221,
        "gradient_norm": 0.417967289686203,
        "train_loss": 3.0652735233306885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18694,
        "tokens": 9801039872,
        "learning_rate": 0.00024080051236095534,
        "gradient_norm": 0.3447597324848175,
        "train_loss": 3.0746536254882812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18695,
        "tokens": 9801564160,
        "learning_rate": 0.00024077347549074116,
        "gradient_norm": 0.3687881529331207,
        "train_loss": 3.06484317779541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18696,
        "tokens": 9802088448,
        "learning_rate": 0.00024074643962488268,
        "gradient_norm": 0.4791344702243805,
        "train_loss": 3.116842269897461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18697,
        "tokens": 9802612736,
        "learning_rate": 0.0002407194047636843,
        "gradient_norm": 0.406727135181427,
        "train_loss": 3.0127766132354736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18698,
        "tokens": 9803137024,
        "learning_rate": 0.00024069237090745032,
        "gradient_norm": 0.3709842562675476,
        "train_loss": 3.062516689300537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18699,
        "tokens": 9803661312,
        "learning_rate": 0.00024066533805648495,
        "gradient_norm": 0.3601633310317993,
        "train_loss": 3.0860278606414795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18700,
        "tokens": 9804185600,
        "learning_rate": 0.00024063830621109264,
        "gradient_norm": 0.3419966399669647,
        "train_loss": 3.059596061706543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18701,
        "tokens": 9804709888,
        "learning_rate": 0.00024061127537157757,
        "gradient_norm": 0.35092663764953613,
        "train_loss": 3.06473970413208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18702,
        "tokens": 9805234176,
        "learning_rate": 0.00024058424553824402,
        "gradient_norm": 0.31904637813568115,
        "train_loss": 3.0961687564849854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18703,
        "tokens": 9805758464,
        "learning_rate": 0.00024055721671139627,
        "gradient_norm": 0.34169629216194153,
        "train_loss": 3.103816032409668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18704,
        "tokens": 9806282752,
        "learning_rate": 0.0002405301888913385,
        "gradient_norm": 0.31849777698516846,
        "train_loss": 3.042412757873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18705,
        "tokens": 9806807040,
        "learning_rate": 0.000240503162078375,
        "gradient_norm": 0.3525465428829193,
        "train_loss": 3.1365697383880615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18706,
        "tokens": 9807331328,
        "learning_rate": 0.00024047613627281,
        "gradient_norm": 0.3419075310230255,
        "train_loss": 3.053976535797119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18707,
        "tokens": 9807855616,
        "learning_rate": 0.00024044911147494763,
        "gradient_norm": 0.36384129524230957,
        "train_loss": 3.0719337463378906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18708,
        "tokens": 9808379904,
        "learning_rate": 0.00024042208768509213,
        "gradient_norm": 0.33740562200546265,
        "train_loss": 3.101583957672119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18709,
        "tokens": 9808904192,
        "learning_rate": 0.0002403950649035478,
        "gradient_norm": 0.3657046854496002,
        "train_loss": 3.0108275413513184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18710,
        "tokens": 9809428480,
        "learning_rate": 0.00024036804313061854,
        "gradient_norm": 0.35785844922065735,
        "train_loss": 3.0935046672821045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18711,
        "tokens": 9809952768,
        "learning_rate": 0.00024034102236660887,
        "gradient_norm": 0.36106443405151367,
        "train_loss": 3.178770065307617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18712,
        "tokens": 9810477056,
        "learning_rate": 0.0002403140026118226,
        "gradient_norm": 0.4500015676021576,
        "train_loss": 3.080902576446533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18713,
        "tokens": 9811001344,
        "learning_rate": 0.00024028698386656416,
        "gradient_norm": 0.4760071635246277,
        "train_loss": 3.09122896194458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18714,
        "tokens": 9811525632,
        "learning_rate": 0.00024025996613113743,
        "gradient_norm": 0.3343307077884674,
        "train_loss": 3.062901496887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18715,
        "tokens": 9812049920,
        "learning_rate": 0.00024023294940584675,
        "gradient_norm": 0.41106322407722473,
        "train_loss": 3.06539249420166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18716,
        "tokens": 9812574208,
        "learning_rate": 0.00024020593369099603,
        "gradient_norm": 0.34577345848083496,
        "train_loss": 3.1069254875183105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18717,
        "tokens": 9813098496,
        "learning_rate": 0.00024017891898688942,
        "gradient_norm": 0.43191537261009216,
        "train_loss": 3.0515499114990234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18718,
        "tokens": 9813622784,
        "learning_rate": 0.00024015190529383122,
        "gradient_norm": 0.33181071281433105,
        "train_loss": 3.053107261657715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18719,
        "tokens": 9814147072,
        "learning_rate": 0.00024012489261212512,
        "gradient_norm": 0.4129558801651001,
        "train_loss": 3.102294921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18720,
        "tokens": 9814671360,
        "learning_rate": 0.00024009788094207554,
        "gradient_norm": 0.34379345178604126,
        "train_loss": 3.047532081604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18721,
        "tokens": 9815195648,
        "learning_rate": 0.00024007087028398628,
        "gradient_norm": 0.36775505542755127,
        "train_loss": 3.1437337398529053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18722,
        "tokens": 9815719936,
        "learning_rate": 0.00024004386063816157,
        "gradient_norm": 0.38618016242980957,
        "train_loss": 3.1112782955169678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18723,
        "tokens": 9816244224,
        "learning_rate": 0.00024001685200490523,
        "gradient_norm": 0.34222444891929626,
        "train_loss": 3.0905795097351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18724,
        "tokens": 9816768512,
        "learning_rate": 0.0002399898443845215,
        "gradient_norm": 0.3845880925655365,
        "train_loss": 3.0717928409576416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18725,
        "tokens": 9817292800,
        "learning_rate": 0.0002399628377773142,
        "gradient_norm": 0.35606807470321655,
        "train_loss": 3.0872530937194824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18726,
        "tokens": 9817817088,
        "learning_rate": 0.0002399358321835875,
        "gradient_norm": 0.37456539273262024,
        "train_loss": 3.061246633529663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18727,
        "tokens": 9818341376,
        "learning_rate": 0.00023990882760364511,
        "gradient_norm": 0.317143052816391,
        "train_loss": 3.0286619663238525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18728,
        "tokens": 9818865664,
        "learning_rate": 0.00023988182403779118,
        "gradient_norm": 0.35851386189460754,
        "train_loss": 3.062333583831787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18729,
        "tokens": 9819389952,
        "learning_rate": 0.0002398548214863298,
        "gradient_norm": 0.30747997760772705,
        "train_loss": 3.0634493827819824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18730,
        "tokens": 9819914240,
        "learning_rate": 0.00023982781994956465,
        "gradient_norm": 0.3408101499080658,
        "train_loss": 3.0520009994506836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18731,
        "tokens": 9820438528,
        "learning_rate": 0.00023980081942779987,
        "gradient_norm": 0.3410536050796509,
        "train_loss": 3.1115095615386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18732,
        "tokens": 9820962816,
        "learning_rate": 0.00023977381992133925,
        "gradient_norm": 0.3187641501426697,
        "train_loss": 3.0610127449035645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18733,
        "tokens": 9821487104,
        "learning_rate": 0.00023974682143048683,
        "gradient_norm": 0.32859674096107483,
        "train_loss": 3.050464153289795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18734,
        "tokens": 9822011392,
        "learning_rate": 0.0002397198239555463,
        "gradient_norm": 0.3333124816417694,
        "train_loss": 3.040041923522949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18735,
        "tokens": 9822535680,
        "learning_rate": 0.00023969282749682183,
        "gradient_norm": 0.340412974357605,
        "train_loss": 3.0769057273864746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18736,
        "tokens": 9823059968,
        "learning_rate": 0.00023966583205461706,
        "gradient_norm": 0.3984537720680237,
        "train_loss": 3.064807891845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18737,
        "tokens": 9823584256,
        "learning_rate": 0.0002396388376292359,
        "gradient_norm": 0.34407302737236023,
        "train_loss": 3.125713586807251,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18738,
        "tokens": 9824108544,
        "learning_rate": 0.00023961184422098246,
        "gradient_norm": 0.3997989594936371,
        "train_loss": 3.0853636264801025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18739,
        "tokens": 9824632832,
        "learning_rate": 0.00023958485183016024,
        "gradient_norm": 0.3140539228916168,
        "train_loss": 3.137338399887085,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18740,
        "tokens": 9825157120,
        "learning_rate": 0.00023955786045707332,
        "gradient_norm": 0.3776406943798065,
        "train_loss": 3.086366891860962,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18741,
        "tokens": 9825681408,
        "learning_rate": 0.00023953087010202527,
        "gradient_norm": 0.35559791326522827,
        "train_loss": 3.101015329360962,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18742,
        "tokens": 9826205696,
        "learning_rate": 0.0002395038807653202,
        "gradient_norm": 0.41128626465797424,
        "train_loss": 3.0607810020446777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18743,
        "tokens": 9826729984,
        "learning_rate": 0.00023947689244726165,
        "gradient_norm": 0.5034490823745728,
        "train_loss": 2.9800891876220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18744,
        "tokens": 9827254272,
        "learning_rate": 0.00023944990514815364,
        "gradient_norm": 0.35705435276031494,
        "train_loss": 3.109654188156128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18745,
        "tokens": 9827778560,
        "learning_rate": 0.00023942291886829968,
        "gradient_norm": 0.3705013692378998,
        "train_loss": 3.060030460357666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18746,
        "tokens": 9828302848,
        "learning_rate": 0.00023939593360800378,
        "gradient_norm": 0.33205193281173706,
        "train_loss": 3.0455756187438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18747,
        "tokens": 9828827136,
        "learning_rate": 0.0002393689493675695,
        "gradient_norm": 0.4181959629058838,
        "train_loss": 2.947237491607666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18748,
        "tokens": 9829351424,
        "learning_rate": 0.0002393419661473007,
        "gradient_norm": 0.33086103200912476,
        "train_loss": 3.0394835472106934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18749,
        "tokens": 9829875712,
        "learning_rate": 0.00023931498394750113,
        "gradient_norm": 0.32368412613868713,
        "train_loss": 3.0778708457946777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18750,
        "tokens": 9830400000,
        "learning_rate": 0.0002392880027684744,
        "gradient_norm": 0.34059494733810425,
        "train_loss": 3.0996103286743164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18751,
        "tokens": 9830924288,
        "learning_rate": 0.00023926102261052432,
        "gradient_norm": 0.33064165711402893,
        "train_loss": 3.0530643463134766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18752,
        "tokens": 9831448576,
        "learning_rate": 0.0002392340434739545,
        "gradient_norm": 0.33845990896224976,
        "train_loss": 3.117185592651367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18753,
        "tokens": 9831972864,
        "learning_rate": 0.00023920706535906873,
        "gradient_norm": 0.3669763207435608,
        "train_loss": 3.0940332412719727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18754,
        "tokens": 9832497152,
        "learning_rate": 0.00023918008826617055,
        "gradient_norm": 0.3662845194339752,
        "train_loss": 3.121772289276123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18755,
        "tokens": 9833021440,
        "learning_rate": 0.0002391531121955637,
        "gradient_norm": 0.39197301864624023,
        "train_loss": 3.066570281982422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18756,
        "tokens": 9833545728,
        "learning_rate": 0.00023912613714755182,
        "gradient_norm": 0.3812675178050995,
        "train_loss": 3.072913646697998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18757,
        "tokens": 9834070016,
        "learning_rate": 0.00023909916312243849,
        "gradient_norm": 0.4591308832168579,
        "train_loss": 3.0602316856384277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18758,
        "tokens": 9834594304,
        "learning_rate": 0.0002390721901205275,
        "gradient_norm": 0.44414329528808594,
        "train_loss": 3.085050582885742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18759,
        "tokens": 9835118592,
        "learning_rate": 0.00023904521814212224,
        "gradient_norm": 0.4203210771083832,
        "train_loss": 3.041064500808716,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18760,
        "tokens": 9835642880,
        "learning_rate": 0.00023901824718752652,
        "gradient_norm": 0.47688281536102295,
        "train_loss": 3.181783437728882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18761,
        "tokens": 9836167168,
        "learning_rate": 0.00023899127725704377,
        "gradient_norm": 0.3579617738723755,
        "train_loss": 2.997040271759033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18762,
        "tokens": 9836691456,
        "learning_rate": 0.00023896430835097774,
        "gradient_norm": 0.47101062536239624,
        "train_loss": 3.137007713317871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18763,
        "tokens": 9837215744,
        "learning_rate": 0.00023893734046963178,
        "gradient_norm": 0.37084007263183594,
        "train_loss": 3.107733726501465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18764,
        "tokens": 9837740032,
        "learning_rate": 0.00023891037361330967,
        "gradient_norm": 0.44318288564682007,
        "train_loss": 3.070622205734253,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18765,
        "tokens": 9838264320,
        "learning_rate": 0.00023888340778231473,
        "gradient_norm": 0.3875236511230469,
        "train_loss": 3.040132522583008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18766,
        "tokens": 9838788608,
        "learning_rate": 0.00023885644297695074,
        "gradient_norm": 0.33584973216056824,
        "train_loss": 3.026237964630127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18767,
        "tokens": 9839312896,
        "learning_rate": 0.000238829479197521,
        "gradient_norm": 0.35372859239578247,
        "train_loss": 3.0809717178344727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18768,
        "tokens": 9839837184,
        "learning_rate": 0.0002388025164443291,
        "gradient_norm": 0.32368481159210205,
        "train_loss": 3.096677780151367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18769,
        "tokens": 9840361472,
        "learning_rate": 0.00023877555471767868,
        "gradient_norm": 0.3402674198150635,
        "train_loss": 3.0681090354919434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18770,
        "tokens": 9840885760,
        "learning_rate": 0.000238748594017873,
        "gradient_norm": 0.3696993291378021,
        "train_loss": 3.0620064735412598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18771,
        "tokens": 9841410048,
        "learning_rate": 0.00023872163434521574,
        "gradient_norm": 0.31067705154418945,
        "train_loss": 3.086808443069458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18772,
        "tokens": 9841934336,
        "learning_rate": 0.00023869467570001017,
        "gradient_norm": 0.36100277304649353,
        "train_loss": 3.073856830596924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18773,
        "tokens": 9842458624,
        "learning_rate": 0.00023866771808255996,
        "gradient_norm": 0.3532632291316986,
        "train_loss": 3.0768165588378906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18774,
        "tokens": 9842982912,
        "learning_rate": 0.00023864076149316828,
        "gradient_norm": 0.4408210515975952,
        "train_loss": 3.09911847114563,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18775,
        "tokens": 9843507200,
        "learning_rate": 0.00023861380593213883,
        "gradient_norm": 0.40846261382102966,
        "train_loss": 3.05975341796875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18776,
        "tokens": 9844031488,
        "learning_rate": 0.00023858685139977484,
        "gradient_norm": 0.3395616114139557,
        "train_loss": 3.08074951171875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18777,
        "tokens": 9844555776,
        "learning_rate": 0.00023855989789637976,
        "gradient_norm": 0.3661714494228363,
        "train_loss": 3.0663414001464844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18778,
        "tokens": 9845080064,
        "learning_rate": 0.00023853294542225715,
        "gradient_norm": 0.3635765016078949,
        "train_loss": 3.04815673828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18779,
        "tokens": 9845604352,
        "learning_rate": 0.00023850599397771008,
        "gradient_norm": 0.33105072379112244,
        "train_loss": 3.0560519695281982,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18780,
        "tokens": 9846128640,
        "learning_rate": 0.00023847904356304224,
        "gradient_norm": 0.33765891194343567,
        "train_loss": 3.052004814147949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18781,
        "tokens": 9846652928,
        "learning_rate": 0.00023845209417855674,
        "gradient_norm": 0.3475368022918701,
        "train_loss": 3.1070556640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18782,
        "tokens": 9847177216,
        "learning_rate": 0.0002384251458245572,
        "gradient_norm": 0.3935528099536896,
        "train_loss": 3.0759124755859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18783,
        "tokens": 9847701504,
        "learning_rate": 0.00023839819850134662,
        "gradient_norm": 0.33612245321273804,
        "train_loss": 3.0451369285583496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18784,
        "tokens": 9848225792,
        "learning_rate": 0.00023837125220922865,
        "gradient_norm": 0.3234438896179199,
        "train_loss": 3.009965419769287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18785,
        "tokens": 9848750080,
        "learning_rate": 0.0002383443069485063,
        "gradient_norm": 0.3284043073654175,
        "train_loss": 3.1242945194244385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18786,
        "tokens": 9849274368,
        "learning_rate": 0.00023831736271948318,
        "gradient_norm": 0.34766313433647156,
        "train_loss": 3.064225196838379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18787,
        "tokens": 9849798656,
        "learning_rate": 0.00023829041952246229,
        "gradient_norm": 0.36395591497421265,
        "train_loss": 3.063948392868042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18788,
        "tokens": 9850322944,
        "learning_rate": 0.00023826347735774703,
        "gradient_norm": 0.3435247540473938,
        "train_loss": 3.072019338607788,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18789,
        "tokens": 9850847232,
        "learning_rate": 0.00023823653622564084,
        "gradient_norm": 0.3592357039451599,
        "train_loss": 3.057051658630371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18790,
        "tokens": 9851371520,
        "learning_rate": 0.00023820959612644668,
        "gradient_norm": 0.33308860659599304,
        "train_loss": 3.0508804321289062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18791,
        "tokens": 9851895808,
        "learning_rate": 0.00023818265706046808,
        "gradient_norm": 0.388264000415802,
        "train_loss": 3.1116342544555664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18792,
        "tokens": 9852420096,
        "learning_rate": 0.000238155719028008,
        "gradient_norm": 0.4179782271385193,
        "train_loss": 3.0676231384277344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18793,
        "tokens": 9852944384,
        "learning_rate": 0.00023812878202936986,
        "gradient_norm": 0.3816560208797455,
        "train_loss": 3.070046901702881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18794,
        "tokens": 9853468672,
        "learning_rate": 0.00023810184606485677,
        "gradient_norm": 0.380991131067276,
        "train_loss": 3.0071990489959717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18795,
        "tokens": 9853992960,
        "learning_rate": 0.00023807491113477197,
        "gradient_norm": 0.40241920948028564,
        "train_loss": 3.05379581451416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18796,
        "tokens": 9854517248,
        "learning_rate": 0.00023804797723941858,
        "gradient_norm": 0.36464327573776245,
        "train_loss": 3.112769842147827,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18797,
        "tokens": 9855041536,
        "learning_rate": 0.00023802104437909989,
        "gradient_norm": 0.4011014401912689,
        "train_loss": 3.0812137126922607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18798,
        "tokens": 9855565824,
        "learning_rate": 0.000237994112554119,
        "gradient_norm": 0.4246842563152313,
        "train_loss": 3.0855109691619873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18799,
        "tokens": 9856090112,
        "learning_rate": 0.00023796718176477904,
        "gradient_norm": 0.3698772192001343,
        "train_loss": 3.1281280517578125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18800,
        "tokens": 9856614400,
        "learning_rate": 0.00023794025201138319,
        "gradient_norm": 0.3874843716621399,
        "train_loss": 3.0662429332733154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18801,
        "tokens": 9857138688,
        "learning_rate": 0.00023791332329423453,
        "gradient_norm": 0.3295057713985443,
        "train_loss": 3.1033458709716797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18802,
        "tokens": 9857662976,
        "learning_rate": 0.00023788639561363623,
        "gradient_norm": 0.35901954770088196,
        "train_loss": 3.0767595767974854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18803,
        "tokens": 9858187264,
        "learning_rate": 0.00023785946896989136,
        "gradient_norm": 0.3517131209373474,
        "train_loss": 3.074507474899292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18804,
        "tokens": 9858711552,
        "learning_rate": 0.00023783254336330305,
        "gradient_norm": 0.33453676104545593,
        "train_loss": 3.067559003829956,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18805,
        "tokens": 9859235840,
        "learning_rate": 0.0002378056187941743,
        "gradient_norm": 0.33514633774757385,
        "train_loss": 3.060542106628418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18806,
        "tokens": 9859760128,
        "learning_rate": 0.00023777869526280828,
        "gradient_norm": 0.36135461926460266,
        "train_loss": 3.1005167961120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18807,
        "tokens": 9860284416,
        "learning_rate": 0.00023775177276950796,
        "gradient_norm": 0.3535459041595459,
        "train_loss": 3.0855484008789062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18808,
        "tokens": 9860808704,
        "learning_rate": 0.00023772485131457643,
        "gradient_norm": 0.39293596148490906,
        "train_loss": 3.048360824584961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18809,
        "tokens": 9861332992,
        "learning_rate": 0.00023769793089831678,
        "gradient_norm": 0.3369051218032837,
        "train_loss": 3.0461082458496094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18810,
        "tokens": 9861857280,
        "learning_rate": 0.0002376710115210319,
        "gradient_norm": 0.36274635791778564,
        "train_loss": 3.085827112197876,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18811,
        "tokens": 9862381568,
        "learning_rate": 0.00023764409318302495,
        "gradient_norm": 0.32204583287239075,
        "train_loss": 3.0330822467803955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18812,
        "tokens": 9862905856,
        "learning_rate": 0.0002376171758845988,
        "gradient_norm": 0.39769798517227173,
        "train_loss": 3.0597386360168457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18813,
        "tokens": 9863430144,
        "learning_rate": 0.00023759025962605658,
        "gradient_norm": 0.3696053624153137,
        "train_loss": 3.06003475189209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18814,
        "tokens": 9863954432,
        "learning_rate": 0.00023756334440770102,
        "gradient_norm": 0.34578579664230347,
        "train_loss": 3.041577100753784,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18815,
        "tokens": 9864478720,
        "learning_rate": 0.00023753643022983542,
        "gradient_norm": 0.36650142073631287,
        "train_loss": 3.1082077026367188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18816,
        "tokens": 9865003008,
        "learning_rate": 0.0002375095170927624,
        "gradient_norm": 0.39116156101226807,
        "train_loss": 3.166877269744873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18817,
        "tokens": 9865527296,
        "learning_rate": 0.0002374826049967851,
        "gradient_norm": 0.4048120677471161,
        "train_loss": 3.0754854679107666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18818,
        "tokens": 9866051584,
        "learning_rate": 0.00023745569394220648,
        "gradient_norm": 0.3423769176006317,
        "train_loss": 3.0483269691467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18819,
        "tokens": 9866575872,
        "learning_rate": 0.00023742878392932928,
        "gradient_norm": 0.3611748516559601,
        "train_loss": 3.0967400074005127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18820,
        "tokens": 9867100160,
        "learning_rate": 0.00023740187495845667,
        "gradient_norm": 0.33306047320365906,
        "train_loss": 3.0967612266540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18821,
        "tokens": 9867624448,
        "learning_rate": 0.00023737496702989122,
        "gradient_norm": 0.3455798327922821,
        "train_loss": 3.044513702392578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18822,
        "tokens": 9868148736,
        "learning_rate": 0.00023734806014393607,
        "gradient_norm": 0.3195917010307312,
        "train_loss": 3.054931163787842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18823,
        "tokens": 9868673024,
        "learning_rate": 0.00023732115430089395,
        "gradient_norm": 0.39293503761291504,
        "train_loss": 3.089163303375244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18824,
        "tokens": 9869197312,
        "learning_rate": 0.00023729424950106782,
        "gradient_norm": 0.33969247341156006,
        "train_loss": 3.094045877456665,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18825,
        "tokens": 9869721600,
        "learning_rate": 0.0002372673457447604,
        "gradient_norm": 0.391593873500824,
        "train_loss": 3.0846152305603027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18826,
        "tokens": 9870245888,
        "learning_rate": 0.0002372404430322747,
        "gradient_norm": 0.3538510799407959,
        "train_loss": 3.1281023025512695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18827,
        "tokens": 9870770176,
        "learning_rate": 0.0002372135413639133,
        "gradient_norm": 0.3462288975715637,
        "train_loss": 3.064718723297119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18828,
        "tokens": 9871294464,
        "learning_rate": 0.00023718664073997918,
        "gradient_norm": 0.4047272801399231,
        "train_loss": 3.0810766220092773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18829,
        "tokens": 9871818752,
        "learning_rate": 0.00023715974116077525,
        "gradient_norm": 0.36864399909973145,
        "train_loss": 3.147839307785034,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18830,
        "tokens": 9872343040,
        "learning_rate": 0.00023713284262660402,
        "gradient_norm": 0.35842886567115784,
        "train_loss": 3.063472270965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18831,
        "tokens": 9872867328,
        "learning_rate": 0.00023710594513776852,
        "gradient_norm": 0.37684065103530884,
        "train_loss": 3.053201913833618,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18832,
        "tokens": 9873391616,
        "learning_rate": 0.00023707904869457128,
        "gradient_norm": 0.34969615936279297,
        "train_loss": 3.062432289123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18833,
        "tokens": 9873915904,
        "learning_rate": 0.00023705215329731532,
        "gradient_norm": 0.3892672657966614,
        "train_loss": 3.067251205444336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18834,
        "tokens": 9874440192,
        "learning_rate": 0.00023702525894630312,
        "gradient_norm": 0.44037511944770813,
        "train_loss": 3.0432653427124023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18835,
        "tokens": 9874964480,
        "learning_rate": 0.00023699836564183762,
        "gradient_norm": 0.3744860887527466,
        "train_loss": 3.0927505493164062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18836,
        "tokens": 9875488768,
        "learning_rate": 0.00023697147338422135,
        "gradient_norm": 0.3309893012046814,
        "train_loss": 3.0583577156066895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18837,
        "tokens": 9876013056,
        "learning_rate": 0.0002369445821737571,
        "gradient_norm": 0.36813926696777344,
        "train_loss": 3.084404230117798,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18838,
        "tokens": 9876537344,
        "learning_rate": 0.00023691769201074765,
        "gradient_norm": 0.3485267162322998,
        "train_loss": 3.0567774772644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18839,
        "tokens": 9877061632,
        "learning_rate": 0.00023689080289549555,
        "gradient_norm": 0.3950558304786682,
        "train_loss": 2.983598232269287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18840,
        "tokens": 9877585920,
        "learning_rate": 0.00023686391482830363,
        "gradient_norm": 0.40569326281547546,
        "train_loss": 3.140603542327881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18841,
        "tokens": 9878110208,
        "learning_rate": 0.0002368370278094743,
        "gradient_norm": 0.41502171754837036,
        "train_loss": 3.1340177059173584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18842,
        "tokens": 9878634496,
        "learning_rate": 0.00023681014183931048,
        "gradient_norm": 0.41304221749305725,
        "train_loss": 3.0597033500671387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18843,
        "tokens": 9879158784,
        "learning_rate": 0.0002367832569181146,
        "gradient_norm": 0.389877587556839,
        "train_loss": 3.0881807804107666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18844,
        "tokens": 9879683072,
        "learning_rate": 0.00023675637304618942,
        "gradient_norm": 0.3751063048839569,
        "train_loss": 3.053046226501465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18845,
        "tokens": 9880207360,
        "learning_rate": 0.0002367294902238374,
        "gradient_norm": 0.40924370288848877,
        "train_loss": 3.0535995960235596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18846,
        "tokens": 9880731648,
        "learning_rate": 0.00023670260845136135,
        "gradient_norm": 0.3736256957054138,
        "train_loss": 3.0828890800476074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18847,
        "tokens": 9881255936,
        "learning_rate": 0.00023667572772906366,
        "gradient_norm": 0.41092386841773987,
        "train_loss": 3.0637831687927246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18848,
        "tokens": 9881780224,
        "learning_rate": 0.000236648848057247,
        "gradient_norm": 0.4171464145183563,
        "train_loss": 3.0167226791381836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18849,
        "tokens": 9882304512,
        "learning_rate": 0.00023662196943621393,
        "gradient_norm": 0.3553813695907593,
        "train_loss": 3.0661349296569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18850,
        "tokens": 9882828800,
        "learning_rate": 0.000236595091866267,
        "gradient_norm": 0.4784516394138336,
        "train_loss": 3.034985065460205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18851,
        "tokens": 9883353088,
        "learning_rate": 0.0002365682153477087,
        "gradient_norm": 0.3815895617008209,
        "train_loss": 3.1537067890167236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18852,
        "tokens": 9883877376,
        "learning_rate": 0.00023654133988084165,
        "gradient_norm": 0.4119257628917694,
        "train_loss": 3.113863229751587,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18853,
        "tokens": 9884401664,
        "learning_rate": 0.0002365144654659683,
        "gradient_norm": 0.3685007691383362,
        "train_loss": 3.085458755493164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18854,
        "tokens": 9884925952,
        "learning_rate": 0.00023648759210339118,
        "gradient_norm": 0.4019426703453064,
        "train_loss": 3.0259156227111816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18855,
        "tokens": 9885450240,
        "learning_rate": 0.00023646071979341278,
        "gradient_norm": 0.3701569139957428,
        "train_loss": 3.0873169898986816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18856,
        "tokens": 9885974528,
        "learning_rate": 0.0002364338485363356,
        "gradient_norm": 0.3346632719039917,
        "train_loss": 3.0645596981048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18857,
        "tokens": 9886498816,
        "learning_rate": 0.000236406978332462,
        "gradient_norm": 0.5322721004486084,
        "train_loss": 3.14133358001709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18858,
        "tokens": 9887023104,
        "learning_rate": 0.00023638010918209466,
        "gradient_norm": 0.36764371395111084,
        "train_loss": 3.053314208984375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18859,
        "tokens": 9887547392,
        "learning_rate": 0.00023635324108553575,
        "gradient_norm": 0.4129333198070526,
        "train_loss": 3.1012649536132812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18860,
        "tokens": 9888071680,
        "learning_rate": 0.00023632637404308798,
        "gradient_norm": 0.3635031580924988,
        "train_loss": 3.0329060554504395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18861,
        "tokens": 9888595968,
        "learning_rate": 0.0002362995080550535,
        "gradient_norm": 0.3815747797489166,
        "train_loss": 3.055143117904663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18862,
        "tokens": 9889120256,
        "learning_rate": 0.000236272643121735,
        "gradient_norm": 0.3773345947265625,
        "train_loss": 3.0616297721862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18863,
        "tokens": 9889644544,
        "learning_rate": 0.00023624577924343464,
        "gradient_norm": 0.33254122734069824,
        "train_loss": 3.0831334590911865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18864,
        "tokens": 9890168832,
        "learning_rate": 0.000236218916420455,
        "gradient_norm": 0.3880573809146881,
        "train_loss": 3.1336379051208496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18865,
        "tokens": 9890693120,
        "learning_rate": 0.00023619205465309821,
        "gradient_norm": 0.33722084760665894,
        "train_loss": 3.008530616760254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18866,
        "tokens": 9891217408,
        "learning_rate": 0.0002361651939416669,
        "gradient_norm": 0.368612140417099,
        "train_loss": 3.0545430183410645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18867,
        "tokens": 9891741696,
        "learning_rate": 0.0002361383342864632,
        "gradient_norm": 0.3438138961791992,
        "train_loss": 3.0237016677856445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18868,
        "tokens": 9892265984,
        "learning_rate": 0.00023611147568778956,
        "gradient_norm": 0.3956110179424286,
        "train_loss": 3.1159517765045166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18869,
        "tokens": 9892790272,
        "learning_rate": 0.00023608461814594837,
        "gradient_norm": 0.3750138580799103,
        "train_loss": 3.131594657897949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18870,
        "tokens": 9893314560,
        "learning_rate": 0.00023605776166124183,
        "gradient_norm": 0.32295843958854675,
        "train_loss": 3.123152256011963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18871,
        "tokens": 9893838848,
        "learning_rate": 0.00023603090623397233,
        "gradient_norm": 0.3677166998386383,
        "train_loss": 3.0743348598480225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18872,
        "tokens": 9894363136,
        "learning_rate": 0.00023600405186444202,
        "gradient_norm": 0.34654802083969116,
        "train_loss": 3.04217267036438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18873,
        "tokens": 9894887424,
        "learning_rate": 0.0002359771985529534,
        "gradient_norm": 0.33954477310180664,
        "train_loss": 3.0671839714050293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18874,
        "tokens": 9895411712,
        "learning_rate": 0.0002359503462998085,
        "gradient_norm": 0.3453110158443451,
        "train_loss": 3.0430874824523926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18875,
        "tokens": 9895936000,
        "learning_rate": 0.0002359234951053098,
        "gradient_norm": 0.32900020480155945,
        "train_loss": 3.0149073600769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18876,
        "tokens": 9896460288,
        "learning_rate": 0.0002358966449697593,
        "gradient_norm": 0.34465909004211426,
        "train_loss": 3.0735208988189697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18877,
        "tokens": 9896984576,
        "learning_rate": 0.0002358697958934594,
        "gradient_norm": 0.3976016044616699,
        "train_loss": 3.100975513458252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18878,
        "tokens": 9897508864,
        "learning_rate": 0.0002358429478767124,
        "gradient_norm": 0.3708235025405884,
        "train_loss": 3.096087694168091,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18879,
        "tokens": 9898033152,
        "learning_rate": 0.00023581610091982024,
        "gradient_norm": 0.3449072539806366,
        "train_loss": 3.0486860275268555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18880,
        "tokens": 9898557440,
        "learning_rate": 0.00023578925502308541,
        "gradient_norm": 0.4077480435371399,
        "train_loss": 3.0418577194213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18881,
        "tokens": 9899081728,
        "learning_rate": 0.00023576241018680982,
        "gradient_norm": 0.3278960585594177,
        "train_loss": 3.0311596393585205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18882,
        "tokens": 9899606016,
        "learning_rate": 0.0002357355664112959,
        "gradient_norm": 0.36637425422668457,
        "train_loss": 3.0800909996032715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18883,
        "tokens": 9900130304,
        "learning_rate": 0.00023570872369684553,
        "gradient_norm": 0.3466293513774872,
        "train_loss": 3.0904273986816406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18884,
        "tokens": 9900654592,
        "learning_rate": 0.00023568188204376115,
        "gradient_norm": 0.35282883048057556,
        "train_loss": 3.0796828269958496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18885,
        "tokens": 9901178880,
        "learning_rate": 0.00023565504145234468,
        "gradient_norm": 0.3752489387989044,
        "train_loss": 3.0681376457214355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18886,
        "tokens": 9901703168,
        "learning_rate": 0.00023562820192289842,
        "gradient_norm": 0.3526657521724701,
        "train_loss": 3.083047866821289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18887,
        "tokens": 9902227456,
        "learning_rate": 0.00023560136345572425,
        "gradient_norm": 0.3583223521709442,
        "train_loss": 3.0853686332702637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18888,
        "tokens": 9902751744,
        "learning_rate": 0.0002355745260511244,
        "gradient_norm": 0.37238484621047974,
        "train_loss": 3.0762195587158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18889,
        "tokens": 9903276032,
        "learning_rate": 0.0002355476897094011,
        "gradient_norm": 0.3367042541503906,
        "train_loss": 3.1101021766662598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18890,
        "tokens": 9903800320,
        "learning_rate": 0.00023552085443085617,
        "gradient_norm": 0.36797571182250977,
        "train_loss": 3.0849547386169434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18891,
        "tokens": 9904324608,
        "learning_rate": 0.00023549402021579192,
        "gradient_norm": 0.4050462245941162,
        "train_loss": 3.0893068313598633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18892,
        "tokens": 9904848896,
        "learning_rate": 0.00023546718706451012,
        "gradient_norm": 0.3499630093574524,
        "train_loss": 3.0430197715759277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18893,
        "tokens": 9905373184,
        "learning_rate": 0.00023544035497731315,
        "gradient_norm": 0.32508042454719543,
        "train_loss": 3.0562291145324707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18894,
        "tokens": 9905897472,
        "learning_rate": 0.00023541352395450266,
        "gradient_norm": 0.3275814354419708,
        "train_loss": 3.0650510787963867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18895,
        "tokens": 9906421760,
        "learning_rate": 0.00023538669399638103,
        "gradient_norm": 0.3287624418735504,
        "train_loss": 3.097306728363037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18896,
        "tokens": 9906946048,
        "learning_rate": 0.00023535986510325,
        "gradient_norm": 0.35503432154655457,
        "train_loss": 3.0933613777160645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18897,
        "tokens": 9907470336,
        "learning_rate": 0.0002353330372754117,
        "gradient_norm": 0.3443032503128052,
        "train_loss": 3.0880346298217773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18898,
        "tokens": 9907994624,
        "learning_rate": 0.00023530621051316805,
        "gradient_norm": 0.3147852122783661,
        "train_loss": 3.028484344482422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18899,
        "tokens": 9908518912,
        "learning_rate": 0.00023527938481682104,
        "gradient_norm": 0.3378327190876007,
        "train_loss": 3.0435967445373535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18900,
        "tokens": 9909043200,
        "learning_rate": 0.00023525256018667266,
        "gradient_norm": 0.3256639540195465,
        "train_loss": 3.056372880935669,
        "val_loss": 3.031282901763916,
        "hellaswag_acc": 0.28111928701400757,
        "hellaswag_acc_norm": 0.2926707863807678
    },
    {
        "step": 18901,
        "tokens": 9909567488,
        "learning_rate": 0.0002352257366230248,
        "gradient_norm": 0.356995165348053,
        "train_loss": 3.069916248321533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18902,
        "tokens": 9910091776,
        "learning_rate": 0.00023519891412617942,
        "gradient_norm": 0.3290383517742157,
        "train_loss": 3.0701823234558105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18903,
        "tokens": 9910616064,
        "learning_rate": 0.00023517209269643843,
        "gradient_norm": 0.3462356925010681,
        "train_loss": 3.072628974914551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18904,
        "tokens": 9911140352,
        "learning_rate": 0.00023514527233410373,
        "gradient_norm": 0.3301336169242859,
        "train_loss": 3.1302971839904785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18905,
        "tokens": 9911664640,
        "learning_rate": 0.0002351184530394772,
        "gradient_norm": 0.3306332528591156,
        "train_loss": 3.0769898891448975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18906,
        "tokens": 9912188928,
        "learning_rate": 0.00023509163481286082,
        "gradient_norm": 0.30644771456718445,
        "train_loss": 3.1009833812713623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18907,
        "tokens": 9912713216,
        "learning_rate": 0.00023506481765455634,
        "gradient_norm": 0.3306960463523865,
        "train_loss": 3.093738079071045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18908,
        "tokens": 9913237504,
        "learning_rate": 0.0002350380015648657,
        "gradient_norm": 0.371322900056839,
        "train_loss": 3.138082504272461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18909,
        "tokens": 9913761792,
        "learning_rate": 0.0002350111865440907,
        "gradient_norm": 0.3653642237186432,
        "train_loss": 3.0905232429504395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18910,
        "tokens": 9914286080,
        "learning_rate": 0.00023498437259253325,
        "gradient_norm": 0.3482056260108948,
        "train_loss": 3.013831615447998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18911,
        "tokens": 9914810368,
        "learning_rate": 0.00023495755971049512,
        "gradient_norm": 0.4222399890422821,
        "train_loss": 3.051809310913086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18912,
        "tokens": 9915334656,
        "learning_rate": 0.00023493074789827811,
        "gradient_norm": 0.3835129141807556,
        "train_loss": 3.0633254051208496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18913,
        "tokens": 9915858944,
        "learning_rate": 0.00023490393715618405,
        "gradient_norm": 0.36691296100616455,
        "train_loss": 3.040984630584717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18914,
        "tokens": 9916383232,
        "learning_rate": 0.00023487712748451473,
        "gradient_norm": 0.36194342374801636,
        "train_loss": 3.0496773719787598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18915,
        "tokens": 9916907520,
        "learning_rate": 0.00023485031888357188,
        "gradient_norm": 0.3222522735595703,
        "train_loss": 3.107006549835205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18916,
        "tokens": 9917431808,
        "learning_rate": 0.00023482351135365736,
        "gradient_norm": 0.34547460079193115,
        "train_loss": 3.13561749458313,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18917,
        "tokens": 9917956096,
        "learning_rate": 0.00023479670489507274,
        "gradient_norm": 0.35537469387054443,
        "train_loss": 3.078166961669922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18918,
        "tokens": 9918480384,
        "learning_rate": 0.00023476989950812002,
        "gradient_norm": 0.34204190969467163,
        "train_loss": 3.096666097640991,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18919,
        "tokens": 9919004672,
        "learning_rate": 0.0002347430951931007,
        "gradient_norm": 0.336397260427475,
        "train_loss": 3.038548469543457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18920,
        "tokens": 9919528960,
        "learning_rate": 0.00023471629195031664,
        "gradient_norm": 0.33378931879997253,
        "train_loss": 3.0846991539001465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18921,
        "tokens": 9920053248,
        "learning_rate": 0.00023468948978006942,
        "gradient_norm": 0.3575534522533417,
        "train_loss": 3.0687806606292725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18922,
        "tokens": 9920577536,
        "learning_rate": 0.0002346626886826609,
        "gradient_norm": 0.35983192920684814,
        "train_loss": 3.0632004737854004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18923,
        "tokens": 9921101824,
        "learning_rate": 0.00023463588865839255,
        "gradient_norm": 0.3777262568473816,
        "train_loss": 3.1064610481262207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18924,
        "tokens": 9921626112,
        "learning_rate": 0.00023460908970756623,
        "gradient_norm": 0.3865455090999603,
        "train_loss": 3.045684337615967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18925,
        "tokens": 9922150400,
        "learning_rate": 0.00023458229183048344,
        "gradient_norm": 0.3385397791862488,
        "train_loss": 3.0893712043762207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18926,
        "tokens": 9922674688,
        "learning_rate": 0.000234555495027446,
        "gradient_norm": 0.3533744215965271,
        "train_loss": 3.0950918197631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18927,
        "tokens": 9923198976,
        "learning_rate": 0.00023452869929875534,
        "gradient_norm": 0.36725765466690063,
        "train_loss": 3.0808210372924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18928,
        "tokens": 9923723264,
        "learning_rate": 0.00023450190464471314,
        "gradient_norm": 0.35115835070610046,
        "train_loss": 3.0261850357055664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18929,
        "tokens": 9924247552,
        "learning_rate": 0.00023447511106562118,
        "gradient_norm": 0.3942197263240814,
        "train_loss": 3.0587430000305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18930,
        "tokens": 9924771840,
        "learning_rate": 0.0002344483185617808,
        "gradient_norm": 0.3993262052536011,
        "train_loss": 3.0894107818603516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18931,
        "tokens": 9925296128,
        "learning_rate": 0.0002344215271334938,
        "gradient_norm": 0.3732317388057709,
        "train_loss": 3.081545114517212,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18932,
        "tokens": 9925820416,
        "learning_rate": 0.00023439473678106155,
        "gradient_norm": 0.3276364505290985,
        "train_loss": 3.0557403564453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18933,
        "tokens": 9926344704,
        "learning_rate": 0.00023436794750478587,
        "gradient_norm": 0.3970986306667328,
        "train_loss": 3.1527743339538574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18934,
        "tokens": 9926868992,
        "learning_rate": 0.000234341159304968,
        "gradient_norm": 0.3597257733345032,
        "train_loss": 3.0636816024780273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18935,
        "tokens": 9927393280,
        "learning_rate": 0.00023431437218190976,
        "gradient_norm": 0.3468749225139618,
        "train_loss": 3.0497617721557617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18936,
        "tokens": 9927917568,
        "learning_rate": 0.00023428758613591236,
        "gradient_norm": 0.34470677375793457,
        "train_loss": 3.006559371948242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18937,
        "tokens": 9928441856,
        "learning_rate": 0.00023426080116727756,
        "gradient_norm": 0.38104870915412903,
        "train_loss": 3.0854384899139404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18938,
        "tokens": 9928966144,
        "learning_rate": 0.00023423401727630687,
        "gradient_norm": 0.38045960664749146,
        "train_loss": 3.067835807800293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18939,
        "tokens": 9929490432,
        "learning_rate": 0.0002342072344633016,
        "gradient_norm": 0.3915503919124603,
        "train_loss": 3.068312883377075,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18940,
        "tokens": 9930014720,
        "learning_rate": 0.00023418045272856336,
        "gradient_norm": 0.4305697977542877,
        "train_loss": 3.035994052886963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18941,
        "tokens": 9930539008,
        "learning_rate": 0.00023415367207239347,
        "gradient_norm": 0.3390134572982788,
        "train_loss": 3.0411534309387207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18942,
        "tokens": 9931063296,
        "learning_rate": 0.00023412689249509365,
        "gradient_norm": 0.3787112832069397,
        "train_loss": 3.0707573890686035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18943,
        "tokens": 9931587584,
        "learning_rate": 0.000234100113996965,
        "gradient_norm": 0.3331090211868286,
        "train_loss": 3.0123353004455566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18944,
        "tokens": 9932111872,
        "learning_rate": 0.00023407333657830926,
        "gradient_norm": 0.3728020489215851,
        "train_loss": 2.987908124923706,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18945,
        "tokens": 9932636160,
        "learning_rate": 0.00023404656023942754,
        "gradient_norm": 0.36284855008125305,
        "train_loss": 3.0853161811828613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18946,
        "tokens": 9933160448,
        "learning_rate": 0.00023401978498062154,
        "gradient_norm": 0.3523842692375183,
        "train_loss": 3.025517463684082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18947,
        "tokens": 9933684736,
        "learning_rate": 0.00023399301080219236,
        "gradient_norm": 0.3864331543445587,
        "train_loss": 3.042985439300537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18948,
        "tokens": 9934209024,
        "learning_rate": 0.00023396623770444158,
        "gradient_norm": 0.3626300096511841,
        "train_loss": 3.0614073276519775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18949,
        "tokens": 9934733312,
        "learning_rate": 0.00023393946568767054,
        "gradient_norm": 0.32576969265937805,
        "train_loss": 3.0594334602355957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18950,
        "tokens": 9935257600,
        "learning_rate": 0.00023391269475218047,
        "gradient_norm": 0.34770622849464417,
        "train_loss": 3.0325217247009277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18951,
        "tokens": 9935781888,
        "learning_rate": 0.0002338859248982729,
        "gradient_norm": 0.33999958634376526,
        "train_loss": 3.036600351333618,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18952,
        "tokens": 9936306176,
        "learning_rate": 0.000233859156126249,
        "gradient_norm": 0.32672032713890076,
        "train_loss": 3.057840347290039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18953,
        "tokens": 9936830464,
        "learning_rate": 0.0002338323884364102,
        "gradient_norm": 0.3803209662437439,
        "train_loss": 3.0558860301971436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18954,
        "tokens": 9937354752,
        "learning_rate": 0.0002338056218290576,
        "gradient_norm": 0.33019721508026123,
        "train_loss": 3.061084747314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18955,
        "tokens": 9937879040,
        "learning_rate": 0.0002337788563044928,
        "gradient_norm": 0.3540339767932892,
        "train_loss": 3.1688976287841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18956,
        "tokens": 9938403328,
        "learning_rate": 0.0002337520918630168,
        "gradient_norm": 0.3496917188167572,
        "train_loss": 3.037093162536621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18957,
        "tokens": 9938927616,
        "learning_rate": 0.00023372532850493102,
        "gradient_norm": 0.4030010998249054,
        "train_loss": 3.062203884124756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18958,
        "tokens": 9939451904,
        "learning_rate": 0.00023369856623053673,
        "gradient_norm": 0.4278534948825836,
        "train_loss": 3.109104871749878,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18959,
        "tokens": 9939976192,
        "learning_rate": 0.00023367180504013505,
        "gradient_norm": 0.3373458981513977,
        "train_loss": 3.076857566833496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18960,
        "tokens": 9940500480,
        "learning_rate": 0.0002336450449340273,
        "gradient_norm": 0.49081388115882874,
        "train_loss": 3.0225250720977783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18961,
        "tokens": 9941024768,
        "learning_rate": 0.0002336182859125147,
        "gradient_norm": 0.45725467801094055,
        "train_loss": 3.0271027088165283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18962,
        "tokens": 9941549056,
        "learning_rate": 0.00023359152797589841,
        "gradient_norm": 0.3757099211215973,
        "train_loss": 3.0664377212524414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18963,
        "tokens": 9942073344,
        "learning_rate": 0.00023356477112447966,
        "gradient_norm": 0.595961332321167,
        "train_loss": 3.0590217113494873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18964,
        "tokens": 9942597632,
        "learning_rate": 0.00023353801535855965,
        "gradient_norm": 0.4703819453716278,
        "train_loss": 3.0676279067993164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18965,
        "tokens": 9943121920,
        "learning_rate": 0.00023351126067843947,
        "gradient_norm": 0.41071730852127075,
        "train_loss": 3.056373119354248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18966,
        "tokens": 9943646208,
        "learning_rate": 0.00023348450708442035,
        "gradient_norm": 0.43444299697875977,
        "train_loss": 3.0486207008361816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18967,
        "tokens": 9944170496,
        "learning_rate": 0.00023345775457680342,
        "gradient_norm": 0.4416765570640564,
        "train_loss": 3.0743281841278076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18968,
        "tokens": 9944694784,
        "learning_rate": 0.00023343100315588973,
        "gradient_norm": 0.39777448773384094,
        "train_loss": 3.0920190811157227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18969,
        "tokens": 9945219072,
        "learning_rate": 0.0002334042528219806,
        "gradient_norm": 0.48022928833961487,
        "train_loss": 3.0815181732177734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18970,
        "tokens": 9945743360,
        "learning_rate": 0.00023337750357537693,
        "gradient_norm": 0.36454081535339355,
        "train_loss": 2.992563486099243,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18971,
        "tokens": 9946267648,
        "learning_rate": 0.00023335075541637996,
        "gradient_norm": 0.4668257236480713,
        "train_loss": 3.0292768478393555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18972,
        "tokens": 9946791936,
        "learning_rate": 0.00023332400834529064,
        "gradient_norm": 0.3926982283592224,
        "train_loss": 3.042468786239624,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18973,
        "tokens": 9947316224,
        "learning_rate": 0.00023329726236241018,
        "gradient_norm": 0.3625298738479614,
        "train_loss": 3.060157060623169,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18974,
        "tokens": 9947840512,
        "learning_rate": 0.0002332705174680395,
        "gradient_norm": 0.3987773060798645,
        "train_loss": 3.115682601928711,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18975,
        "tokens": 9948364800,
        "learning_rate": 0.00023324377366247984,
        "gradient_norm": 0.37915846705436707,
        "train_loss": 3.0586471557617188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18976,
        "tokens": 9948889088,
        "learning_rate": 0.000233217030946032,
        "gradient_norm": 0.378528356552124,
        "train_loss": 3.0822837352752686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18977,
        "tokens": 9949413376,
        "learning_rate": 0.0002331902893189971,
        "gradient_norm": 0.35712212324142456,
        "train_loss": 3.0667896270751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18978,
        "tokens": 9949937664,
        "learning_rate": 0.00023316354878167631,
        "gradient_norm": 0.34118491411209106,
        "train_loss": 3.1030337810516357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18979,
        "tokens": 9950461952,
        "learning_rate": 0.00023313680933437035,
        "gradient_norm": 0.4003538489341736,
        "train_loss": 3.1061758995056152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18980,
        "tokens": 9950986240,
        "learning_rate": 0.0002331100709773805,
        "gradient_norm": 0.33821403980255127,
        "train_loss": 3.0759167671203613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18981,
        "tokens": 9951510528,
        "learning_rate": 0.0002330833337110074,
        "gradient_norm": 0.40071025490760803,
        "train_loss": 3.0589966773986816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18982,
        "tokens": 9952034816,
        "learning_rate": 0.00023305659753555238,
        "gradient_norm": 0.3244057893753052,
        "train_loss": 3.090085029602051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18983,
        "tokens": 9952559104,
        "learning_rate": 0.00023302986245131603,
        "gradient_norm": 0.3789568245410919,
        "train_loss": 3.0756936073303223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18984,
        "tokens": 9953083392,
        "learning_rate": 0.00023300312845859954,
        "gradient_norm": 0.351115345954895,
        "train_loss": 3.0709803104400635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18985,
        "tokens": 9953607680,
        "learning_rate": 0.00023297639555770373,
        "gradient_norm": 0.3594987690448761,
        "train_loss": 3.021697998046875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18986,
        "tokens": 9954131968,
        "learning_rate": 0.00023294966374892958,
        "gradient_norm": 0.36594080924987793,
        "train_loss": 3.093169927597046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18987,
        "tokens": 9954656256,
        "learning_rate": 0.0002329229330325778,
        "gradient_norm": 0.39284592866897583,
        "train_loss": 3.1082205772399902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18988,
        "tokens": 9955180544,
        "learning_rate": 0.00023289620340894947,
        "gradient_norm": 0.36726197600364685,
        "train_loss": 3.0678796768188477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18989,
        "tokens": 9955704832,
        "learning_rate": 0.0002328694748783455,
        "gradient_norm": 0.36746418476104736,
        "train_loss": 3.022106170654297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18990,
        "tokens": 9956229120,
        "learning_rate": 0.0002328427474410666,
        "gradient_norm": 0.3396303057670593,
        "train_loss": 2.988409996032715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18991,
        "tokens": 9956753408,
        "learning_rate": 0.00023281602109741375,
        "gradient_norm": 0.3716607987880707,
        "train_loss": 3.027371883392334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18992,
        "tokens": 9957277696,
        "learning_rate": 0.0002327892958476876,
        "gradient_norm": 0.3097570836544037,
        "train_loss": 3.071223735809326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18993,
        "tokens": 9957801984,
        "learning_rate": 0.00023276257169218927,
        "gradient_norm": 0.3552517592906952,
        "train_loss": 3.087406635284424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18994,
        "tokens": 9958326272,
        "learning_rate": 0.00023273584863121925,
        "gradient_norm": 0.3724193871021271,
        "train_loss": 3.1029911041259766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18995,
        "tokens": 9958850560,
        "learning_rate": 0.00023270912666507865,
        "gradient_norm": 0.4254814684391022,
        "train_loss": 3.1079540252685547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18996,
        "tokens": 9959374848,
        "learning_rate": 0.00023268240579406795,
        "gradient_norm": 0.44908636808395386,
        "train_loss": 3.0961966514587402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18997,
        "tokens": 9959899136,
        "learning_rate": 0.00023265568601848812,
        "gradient_norm": 0.35506126284599304,
        "train_loss": 3.04903507232666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18998,
        "tokens": 9960423424,
        "learning_rate": 0.00023262896733863996,
        "gradient_norm": 0.42456960678100586,
        "train_loss": 3.1448419094085693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18999,
        "tokens": 9960947712,
        "learning_rate": 0.00023260224975482407,
        "gradient_norm": 0.38739603757858276,
        "train_loss": 3.0607872009277344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19000,
        "tokens": 9961472000,
        "learning_rate": 0.0002325755332673414,
        "gradient_norm": 0.3780297338962555,
        "train_loss": 3.0353751182556152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19001,
        "tokens": 9961996288,
        "learning_rate": 0.00023254881787649237,
        "gradient_norm": 0.475495308637619,
        "train_loss": 3.118669033050537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19002,
        "tokens": 9962520576,
        "learning_rate": 0.00023252210358257802,
        "gradient_norm": 0.39682459831237793,
        "train_loss": 3.0593950748443604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19003,
        "tokens": 9963044864,
        "learning_rate": 0.00023249539038589875,
        "gradient_norm": 0.40327319502830505,
        "train_loss": 3.056915283203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19004,
        "tokens": 9963569152,
        "learning_rate": 0.00023246867828675556,
        "gradient_norm": 0.39125362038612366,
        "train_loss": 3.070091485977173,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19005,
        "tokens": 9964093440,
        "learning_rate": 0.00023244196728544887,
        "gradient_norm": 0.375357061624527,
        "train_loss": 3.102994918823242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19006,
        "tokens": 9964617728,
        "learning_rate": 0.00023241525738227956,
        "gradient_norm": 0.36069270968437195,
        "train_loss": 3.014117956161499,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19007,
        "tokens": 9965142016,
        "learning_rate": 0.000232388548577548,
        "gradient_norm": 0.34781384468078613,
        "train_loss": 3.0833160877227783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19008,
        "tokens": 9965666304,
        "learning_rate": 0.00023236184087155513,
        "gradient_norm": 0.38308316469192505,
        "train_loss": 3.1237571239471436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19009,
        "tokens": 9966190592,
        "learning_rate": 0.0002323351342646014,
        "gradient_norm": 0.35191774368286133,
        "train_loss": 3.0623159408569336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19010,
        "tokens": 9966714880,
        "learning_rate": 0.0002323084287569875,
        "gradient_norm": 0.3673005700111389,
        "train_loss": 3.082984209060669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19011,
        "tokens": 9967239168,
        "learning_rate": 0.000232281724349014,
        "gradient_norm": 0.34098440408706665,
        "train_loss": 3.0557613372802734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19012,
        "tokens": 9967763456,
        "learning_rate": 0.0002322550210409815,
        "gradient_norm": 0.3838120698928833,
        "train_loss": 3.0620412826538086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19013,
        "tokens": 9968287744,
        "learning_rate": 0.00023222831883319058,
        "gradient_norm": 0.3300670087337494,
        "train_loss": 3.0762670040130615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19014,
        "tokens": 9968812032,
        "learning_rate": 0.00023220161772594182,
        "gradient_norm": 0.3610887825489044,
        "train_loss": 3.0983800888061523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19015,
        "tokens": 9969336320,
        "learning_rate": 0.00023217491771953573,
        "gradient_norm": 0.3661322593688965,
        "train_loss": 3.056940793991089,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19016,
        "tokens": 9969860608,
        "learning_rate": 0.00023214821881427294,
        "gradient_norm": 0.41225630044937134,
        "train_loss": 3.082261562347412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19017,
        "tokens": 9970384896,
        "learning_rate": 0.00023212152101045384,
        "gradient_norm": 0.41737353801727295,
        "train_loss": 3.072317600250244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19018,
        "tokens": 9970909184,
        "learning_rate": 0.00023209482430837911,
        "gradient_norm": 0.37060996890068054,
        "train_loss": 3.1041061878204346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19019,
        "tokens": 9971433472,
        "learning_rate": 0.00023206812870834912,
        "gradient_norm": 0.5245808362960815,
        "train_loss": 3.090473175048828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19020,
        "tokens": 9971957760,
        "learning_rate": 0.00023204143421066446,
        "gradient_norm": 0.3818672001361847,
        "train_loss": 3.121048927307129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19021,
        "tokens": 9972482048,
        "learning_rate": 0.0002320147408156255,
        "gradient_norm": 0.38608723878860474,
        "train_loss": 3.0525271892547607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19022,
        "tokens": 9973006336,
        "learning_rate": 0.0002319880485235329,
        "gradient_norm": 0.37953290343284607,
        "train_loss": 3.04428768157959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19023,
        "tokens": 9973530624,
        "learning_rate": 0.00023196135733468683,
        "gradient_norm": 0.36395493149757385,
        "train_loss": 3.073841094970703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19024,
        "tokens": 9974054912,
        "learning_rate": 0.00023193466724938803,
        "gradient_norm": 0.36181432008743286,
        "train_loss": 3.0710089206695557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19025,
        "tokens": 9974579200,
        "learning_rate": 0.00023190797826793668,
        "gradient_norm": 0.3876437246799469,
        "train_loss": 3.1162285804748535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19026,
        "tokens": 9975103488,
        "learning_rate": 0.0002318812903906334,
        "gradient_norm": 0.41955482959747314,
        "train_loss": 3.1313672065734863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19027,
        "tokens": 9975627776,
        "learning_rate": 0.00023185460361777846,
        "gradient_norm": 0.3555412292480469,
        "train_loss": 3.0764400959014893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19028,
        "tokens": 9976152064,
        "learning_rate": 0.0002318279179496722,
        "gradient_norm": 0.3795951008796692,
        "train_loss": 3.0570735931396484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19029,
        "tokens": 9976676352,
        "learning_rate": 0.00023180123338661528,
        "gradient_norm": 0.3693414032459259,
        "train_loss": 3.153059244155884,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19030,
        "tokens": 9977200640,
        "learning_rate": 0.00023177454992890777,
        "gradient_norm": 0.44966596364974976,
        "train_loss": 3.1161556243896484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19031,
        "tokens": 9977724928,
        "learning_rate": 0.00023174786757685023,
        "gradient_norm": 0.3855755031108856,
        "train_loss": 3.096713066101074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19032,
        "tokens": 9978249216,
        "learning_rate": 0.00023172118633074283,
        "gradient_norm": 0.36318397521972656,
        "train_loss": 3.1306686401367188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19033,
        "tokens": 9978773504,
        "learning_rate": 0.00023169450619088606,
        "gradient_norm": 0.3807127773761749,
        "train_loss": 3.086085796356201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19034,
        "tokens": 9979297792,
        "learning_rate": 0.00023166782715758008,
        "gradient_norm": 0.3631913363933563,
        "train_loss": 3.0973644256591797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19035,
        "tokens": 9979822080,
        "learning_rate": 0.00023164114923112538,
        "gradient_norm": 0.36085042357444763,
        "train_loss": 3.120474338531494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19036,
        "tokens": 9980346368,
        "learning_rate": 0.00023161447241182203,
        "gradient_norm": 0.3586377799510956,
        "train_loss": 3.043853759765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19037,
        "tokens": 9980870656,
        "learning_rate": 0.00023158779669997043,
        "gradient_norm": 0.40531179308891296,
        "train_loss": 3.0496270656585693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19038,
        "tokens": 9981394944,
        "learning_rate": 0.00023156112209587099,
        "gradient_norm": 0.34664344787597656,
        "train_loss": 3.108717203140259,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19039,
        "tokens": 9981919232,
        "learning_rate": 0.00023153444859982372,
        "gradient_norm": 0.3785228431224823,
        "train_loss": 3.0753796100616455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19040,
        "tokens": 9982443520,
        "learning_rate": 0.00023150777621212907,
        "gradient_norm": 0.364773154258728,
        "train_loss": 3.0742249488830566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19041,
        "tokens": 9982967808,
        "learning_rate": 0.00023148110493308706,
        "gradient_norm": 0.4274665117263794,
        "train_loss": 3.049913167953491,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19042,
        "tokens": 9983492096,
        "learning_rate": 0.00023145443476299814,
        "gradient_norm": 0.3377346992492676,
        "train_loss": 3.08384108543396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19043,
        "tokens": 9984016384,
        "learning_rate": 0.00023142776570216227,
        "gradient_norm": 0.37117037177085876,
        "train_loss": 3.1435112953186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19044,
        "tokens": 9984540672,
        "learning_rate": 0.00023140109775087988,
        "gradient_norm": 0.38322287797927856,
        "train_loss": 3.077706813812256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19045,
        "tokens": 9985064960,
        "learning_rate": 0.00023137443090945095,
        "gradient_norm": 0.33323800563812256,
        "train_loss": 3.08886981010437,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19046,
        "tokens": 9985589248,
        "learning_rate": 0.00023134776517817586,
        "gradient_norm": 0.5537301301956177,
        "train_loss": 3.0733494758605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19047,
        "tokens": 9986113536,
        "learning_rate": 0.0002313211005573545,
        "gradient_norm": 0.3773999512195587,
        "train_loss": 3.0580008029937744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19048,
        "tokens": 9986637824,
        "learning_rate": 0.00023129443704728717,
        "gradient_norm": 0.40201422572135925,
        "train_loss": 3.0625405311584473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19049,
        "tokens": 9987162112,
        "learning_rate": 0.00023126777464827414,
        "gradient_norm": 0.32816699147224426,
        "train_loss": 3.0782341957092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19050,
        "tokens": 9987686400,
        "learning_rate": 0.00023124111336061522,
        "gradient_norm": 0.47713303565979004,
        "train_loss": 3.0427405834198,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19051,
        "tokens": 9988210688,
        "learning_rate": 0.0002312144531846108,
        "gradient_norm": 0.318531334400177,
        "train_loss": 3.020824909210205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19052,
        "tokens": 9988734976,
        "learning_rate": 0.00023118779412056075,
        "gradient_norm": 0.3818073868751526,
        "train_loss": 3.0101065635681152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19053,
        "tokens": 9989259264,
        "learning_rate": 0.00023116113616876533,
        "gradient_norm": 0.3146857023239136,
        "train_loss": 3.1279211044311523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19054,
        "tokens": 9989783552,
        "learning_rate": 0.00023113447932952445,
        "gradient_norm": 0.373778373003006,
        "train_loss": 3.0887486934661865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19055,
        "tokens": 9990307840,
        "learning_rate": 0.00023110782360313833,
        "gradient_norm": 0.3277274966239929,
        "train_loss": 3.0659642219543457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19056,
        "tokens": 9990832128,
        "learning_rate": 0.00023108116898990684,
        "gradient_norm": 0.3241901993751526,
        "train_loss": 3.053861141204834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19057,
        "tokens": 9991356416,
        "learning_rate": 0.00023105451549013014,
        "gradient_norm": 0.35317671298980713,
        "train_loss": 3.0791163444519043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19058,
        "tokens": 9991880704,
        "learning_rate": 0.00023102786310410823,
        "gradient_norm": 0.36685702204704285,
        "train_loss": 3.081845283508301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19059,
        "tokens": 9992404992,
        "learning_rate": 0.00023100121183214104,
        "gradient_norm": 0.37533560395240784,
        "train_loss": 3.0708837509155273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19060,
        "tokens": 9992929280,
        "learning_rate": 0.0002309745616745287,
        "gradient_norm": 0.3430239260196686,
        "train_loss": 3.032078742980957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19061,
        "tokens": 9993453568,
        "learning_rate": 0.00023094791263157105,
        "gradient_norm": 0.32237282395362854,
        "train_loss": 3.087556838989258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19062,
        "tokens": 9993977856,
        "learning_rate": 0.0002309212647035681,
        "gradient_norm": 0.37191757559776306,
        "train_loss": 3.0660691261291504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19063,
        "tokens": 9994502144,
        "learning_rate": 0.00023089461789081988,
        "gradient_norm": 0.36327293515205383,
        "train_loss": 3.1104977130889893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19064,
        "tokens": 9995026432,
        "learning_rate": 0.00023086797219362622,
        "gradient_norm": 0.35340312123298645,
        "train_loss": 3.0019967555999756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19065,
        "tokens": 9995550720,
        "learning_rate": 0.00023084132761228712,
        "gradient_norm": 0.34501293301582336,
        "train_loss": 3.106236696243286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19066,
        "tokens": 9996075008,
        "learning_rate": 0.00023081468414710247,
        "gradient_norm": 0.3296135365962982,
        "train_loss": 3.0673060417175293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19067,
        "tokens": 9996599296,
        "learning_rate": 0.00023078804179837222,
        "gradient_norm": 0.3352328836917877,
        "train_loss": 3.1093921661376953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19068,
        "tokens": 9997123584,
        "learning_rate": 0.00023076140056639617,
        "gradient_norm": 0.3635079562664032,
        "train_loss": 3.120584011077881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19069,
        "tokens": 9997647872,
        "learning_rate": 0.00023073476045147432,
        "gradient_norm": 0.35700568556785583,
        "train_loss": 3.118098497390747,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19070,
        "tokens": 9998172160,
        "learning_rate": 0.0002307081214539064,
        "gradient_norm": 0.35946905612945557,
        "train_loss": 3.0371627807617188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19071,
        "tokens": 9998696448,
        "learning_rate": 0.0002306814835739925,
        "gradient_norm": 0.3367388844490051,
        "train_loss": 3.119446039199829,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19072,
        "tokens": 9999220736,
        "learning_rate": 0.00023065484681203215,
        "gradient_norm": 0.3808913826942444,
        "train_loss": 3.1316566467285156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19073,
        "tokens": 9999745024,
        "learning_rate": 0.00023062821116832542,
        "gradient_norm": 0.3461400270462036,
        "train_loss": 3.0941948890686035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19074,
        "tokens": 10000269312,
        "learning_rate": 0.00023060157664317197,
        "gradient_norm": 0.3624468147754669,
        "train_loss": 3.1045408248901367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19075,
        "tokens": 10000793600,
        "learning_rate": 0.0002305749432368718,
        "gradient_norm": 0.3773992657661438,
        "train_loss": 3.022087574005127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19076,
        "tokens": 10001317888,
        "learning_rate": 0.00023054831094972445,
        "gradient_norm": 0.41185420751571655,
        "train_loss": 3.0953516960144043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19077,
        "tokens": 10001842176,
        "learning_rate": 0.00023052167978202987,
        "gradient_norm": 0.3669281303882599,
        "train_loss": 3.062657117843628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19078,
        "tokens": 10002366464,
        "learning_rate": 0.0002304950497340878,
        "gradient_norm": 0.43534085154533386,
        "train_loss": 3.066202402114868,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19079,
        "tokens": 10002890752,
        "learning_rate": 0.00023046842080619794,
        "gradient_norm": 0.3911648690700531,
        "train_loss": 3.1205649375915527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19080,
        "tokens": 10003415040,
        "learning_rate": 0.00023044179299866018,
        "gradient_norm": 0.47188931703567505,
        "train_loss": 3.1203763484954834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19081,
        "tokens": 10003939328,
        "learning_rate": 0.00023041516631177404,
        "gradient_norm": 0.38027966022491455,
        "train_loss": 3.038184881210327,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19082,
        "tokens": 10004463616,
        "learning_rate": 0.00023038854074583943,
        "gradient_norm": 0.520912766456604,
        "train_loss": 3.06691837310791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19083,
        "tokens": 10004987904,
        "learning_rate": 0.00023036191630115588,
        "gradient_norm": 0.373982697725296,
        "train_loss": 3.0320024490356445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19084,
        "tokens": 10005512192,
        "learning_rate": 0.00023033529297802327,
        "gradient_norm": 0.4597023129463196,
        "train_loss": 3.105329990386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19085,
        "tokens": 10006036480,
        "learning_rate": 0.00023030867077674104,
        "gradient_norm": 0.41645073890686035,
        "train_loss": 3.0913753509521484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19086,
        "tokens": 10006560768,
        "learning_rate": 0.00023028204969760899,
        "gradient_norm": 0.4779241979122162,
        "train_loss": 3.0918195247650146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19087,
        "tokens": 10007085056,
        "learning_rate": 0.00023025542974092688,
        "gradient_norm": 0.4143175780773163,
        "train_loss": 3.091068983078003,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19088,
        "tokens": 10007609344,
        "learning_rate": 0.00023022881090699413,
        "gradient_norm": 0.3881402909755707,
        "train_loss": 3.0691001415252686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19089,
        "tokens": 10008133632,
        "learning_rate": 0.00023020219319611063,
        "gradient_norm": 0.3960302472114563,
        "train_loss": 3.0768778324127197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19090,
        "tokens": 10008657920,
        "learning_rate": 0.00023017557660857572,
        "gradient_norm": 0.3917197287082672,
        "train_loss": 3.101050853729248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19091,
        "tokens": 10009182208,
        "learning_rate": 0.00023014896114468918,
        "gradient_norm": 0.35517334938049316,
        "train_loss": 3.065035820007324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19092,
        "tokens": 10009706496,
        "learning_rate": 0.00023012234680475053,
        "gradient_norm": 0.3784443736076355,
        "train_loss": 3.079057216644287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19093,
        "tokens": 10010230784,
        "learning_rate": 0.00023009573358905944,
        "gradient_norm": 0.4045852720737457,
        "train_loss": 3.102626323699951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19094,
        "tokens": 10010755072,
        "learning_rate": 0.00023006912149791528,
        "gradient_norm": 0.37649568915367126,
        "train_loss": 3.025629997253418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19095,
        "tokens": 10011279360,
        "learning_rate": 0.0002300425105316178,
        "gradient_norm": 0.37279996275901794,
        "train_loss": 3.072208881378174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19096,
        "tokens": 10011803648,
        "learning_rate": 0.00023001590069046644,
        "gradient_norm": 0.37326687574386597,
        "train_loss": 3.0496888160705566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19097,
        "tokens": 10012327936,
        "learning_rate": 0.00022998929197476072,
        "gradient_norm": 0.3951651155948639,
        "train_loss": 3.1240763664245605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19098,
        "tokens": 10012852224,
        "learning_rate": 0.00022996268438480027,
        "gradient_norm": 0.3442813754081726,
        "train_loss": 3.029766798019409,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19099,
        "tokens": 10013376512,
        "learning_rate": 0.0002299360779208844,
        "gradient_norm": 0.3400111496448517,
        "train_loss": 3.0213727951049805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19100,
        "tokens": 10013900800,
        "learning_rate": 0.00022990947258331285,
        "gradient_norm": 0.35882678627967834,
        "train_loss": 3.0513710975646973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19101,
        "tokens": 10014425088,
        "learning_rate": 0.00022988286837238481,
        "gradient_norm": 0.39997243881225586,
        "train_loss": 3.0738871097564697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19102,
        "tokens": 10014949376,
        "learning_rate": 0.00022985626528840002,
        "gradient_norm": 0.3032709062099457,
        "train_loss": 3.075364828109741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19103,
        "tokens": 10015473664,
        "learning_rate": 0.00022982966333165767,
        "gradient_norm": 0.34925463795661926,
        "train_loss": 3.0671465396881104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19104,
        "tokens": 10015997952,
        "learning_rate": 0.00022980306250245741,
        "gradient_norm": 0.3515016436576843,
        "train_loss": 3.1073622703552246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19105,
        "tokens": 10016522240,
        "learning_rate": 0.0002297764628010985,
        "gradient_norm": 0.33821800351142883,
        "train_loss": 3.1004910469055176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19106,
        "tokens": 10017046528,
        "learning_rate": 0.00022974986422788052,
        "gradient_norm": 0.36251965165138245,
        "train_loss": 3.1045734882354736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19107,
        "tokens": 10017570816,
        "learning_rate": 0.00022972326678310273,
        "gradient_norm": 0.3838757574558258,
        "train_loss": 3.0949277877807617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19108,
        "tokens": 10018095104,
        "learning_rate": 0.00022969667046706456,
        "gradient_norm": 0.40963223576545715,
        "train_loss": 3.052762746810913,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19109,
        "tokens": 10018619392,
        "learning_rate": 0.00022967007528006545,
        "gradient_norm": 0.3646849989891052,
        "train_loss": 3.102086305618286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19110,
        "tokens": 10019143680,
        "learning_rate": 0.0002296434812224046,
        "gradient_norm": 0.37900257110595703,
        "train_loss": 3.061396598815918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19111,
        "tokens": 10019667968,
        "learning_rate": 0.00022961688829438163,
        "gradient_norm": 0.389169842004776,
        "train_loss": 3.070728302001953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19112,
        "tokens": 10020192256,
        "learning_rate": 0.0002295902964962956,
        "gradient_norm": 0.3402177691459656,
        "train_loss": 3.0768351554870605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19113,
        "tokens": 10020716544,
        "learning_rate": 0.000229563705828446,
        "gradient_norm": 0.362565815448761,
        "train_loss": 3.0742926597595215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19114,
        "tokens": 10021240832,
        "learning_rate": 0.000229537116291132,
        "gradient_norm": 0.34926891326904297,
        "train_loss": 3.05904221534729,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19115,
        "tokens": 10021765120,
        "learning_rate": 0.0002295105278846531,
        "gradient_norm": 0.34964504837989807,
        "train_loss": 3.0634665489196777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19116,
        "tokens": 10022289408,
        "learning_rate": 0.0002294839406093084,
        "gradient_norm": 0.33791685104370117,
        "train_loss": 3.0786828994750977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19117,
        "tokens": 10022813696,
        "learning_rate": 0.00022945735446539727,
        "gradient_norm": 0.36004820466041565,
        "train_loss": 3.0418858528137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19118,
        "tokens": 10023337984,
        "learning_rate": 0.00022943076945321892,
        "gradient_norm": 0.3302551209926605,
        "train_loss": 3.049788475036621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19119,
        "tokens": 10023862272,
        "learning_rate": 0.00022940418557307267,
        "gradient_norm": 0.3387688398361206,
        "train_loss": 3.080714464187622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19120,
        "tokens": 10024386560,
        "learning_rate": 0.00022937760282525766,
        "gradient_norm": 0.32752883434295654,
        "train_loss": 3.0918498039245605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19121,
        "tokens": 10024910848,
        "learning_rate": 0.00022935102121007323,
        "gradient_norm": 0.3455091118812561,
        "train_loss": 3.079021692276001,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19122,
        "tokens": 10025435136,
        "learning_rate": 0.00022932444072781846,
        "gradient_norm": 0.3766799569129944,
        "train_loss": 3.061150550842285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19123,
        "tokens": 10025959424,
        "learning_rate": 0.00022929786137879262,
        "gradient_norm": 0.32881924510002136,
        "train_loss": 3.07342267036438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19124,
        "tokens": 10026483712,
        "learning_rate": 0.00022927128316329486,
        "gradient_norm": 0.3861485421657562,
        "train_loss": 3.0799760818481445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19125,
        "tokens": 10027008000,
        "learning_rate": 0.00022924470608162438,
        "gradient_norm": 0.356189489364624,
        "train_loss": 3.06805419921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19126,
        "tokens": 10027532288,
        "learning_rate": 0.0002292181301340803,
        "gradient_norm": 0.39544618129730225,
        "train_loss": 3.0954089164733887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19127,
        "tokens": 10028056576,
        "learning_rate": 0.00022919155532096186,
        "gradient_norm": 0.32423505187034607,
        "train_loss": 3.0411248207092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19128,
        "tokens": 10028580864,
        "learning_rate": 0.00022916498164256806,
        "gradient_norm": 0.37735480070114136,
        "train_loss": 3.0846831798553467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19129,
        "tokens": 10029105152,
        "learning_rate": 0.00022913840909919816,
        "gradient_norm": 0.3709733188152313,
        "train_loss": 3.1067428588867188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19130,
        "tokens": 10029629440,
        "learning_rate": 0.00022911183769115111,
        "gradient_norm": 0.31491485238075256,
        "train_loss": 3.113842248916626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19131,
        "tokens": 10030153728,
        "learning_rate": 0.00022908526741872618,
        "gradient_norm": 0.34340259432792664,
        "train_loss": 3.012247085571289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19132,
        "tokens": 10030678016,
        "learning_rate": 0.00022905869828222222,
        "gradient_norm": 0.3293040692806244,
        "train_loss": 3.0495448112487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19133,
        "tokens": 10031202304,
        "learning_rate": 0.0002290321302819386,
        "gradient_norm": 0.3688095510005951,
        "train_loss": 3.1017348766326904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19134,
        "tokens": 10031726592,
        "learning_rate": 0.0002290055634181741,
        "gradient_norm": 0.3376101851463318,
        "train_loss": 3.081547260284424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19135,
        "tokens": 10032250880,
        "learning_rate": 0.00022897899769122796,
        "gradient_norm": 0.3781132698059082,
        "train_loss": 3.0690441131591797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19136,
        "tokens": 10032775168,
        "learning_rate": 0.00022895243310139902,
        "gradient_norm": 0.3571763336658478,
        "train_loss": 3.0013790130615234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19137,
        "tokens": 10033299456,
        "learning_rate": 0.00022892586964898644,
        "gradient_norm": 0.36657586693763733,
        "train_loss": 3.0713694095611572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19138,
        "tokens": 10033823744,
        "learning_rate": 0.00022889930733428925,
        "gradient_norm": 0.350841224193573,
        "train_loss": 3.037442207336426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19139,
        "tokens": 10034348032,
        "learning_rate": 0.0002288727461576063,
        "gradient_norm": 0.3606164753437042,
        "train_loss": 3.037461280822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19140,
        "tokens": 10034872320,
        "learning_rate": 0.00022884618611923675,
        "gradient_norm": 0.3585048317909241,
        "train_loss": 3.051919460296631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19141,
        "tokens": 10035396608,
        "learning_rate": 0.00022881962721947935,
        "gradient_norm": 0.3701927959918976,
        "train_loss": 3.0771636962890625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19142,
        "tokens": 10035920896,
        "learning_rate": 0.00022879306945863327,
        "gradient_norm": 0.352591335773468,
        "train_loss": 3.078651189804077,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19143,
        "tokens": 10036445184,
        "learning_rate": 0.0002287665128369973,
        "gradient_norm": 0.34491172432899475,
        "train_loss": 3.0557198524475098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19144,
        "tokens": 10036969472,
        "learning_rate": 0.00022873995735487048,
        "gradient_norm": 0.3575454652309418,
        "train_loss": 3.064601421356201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19145,
        "tokens": 10037493760,
        "learning_rate": 0.00022871340301255157,
        "gradient_norm": 0.3960360288619995,
        "train_loss": 3.094566822052002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19146,
        "tokens": 10038018048,
        "learning_rate": 0.00022868684981033953,
        "gradient_norm": 0.29787585139274597,
        "train_loss": 3.067291259765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19147,
        "tokens": 10038542336,
        "learning_rate": 0.00022866029774853343,
        "gradient_norm": 0.38354137539863586,
        "train_loss": 2.998579978942871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19148,
        "tokens": 10039066624,
        "learning_rate": 0.0002286337468274319,
        "gradient_norm": 0.3526975214481354,
        "train_loss": 3.0706329345703125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19149,
        "tokens": 10039590912,
        "learning_rate": 0.00022860719704733402,
        "gradient_norm": 0.3513607382774353,
        "train_loss": 3.091045379638672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19150,
        "tokens": 10040115200,
        "learning_rate": 0.00022858064840853838,
        "gradient_norm": 0.369595468044281,
        "train_loss": 3.054227828979492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19151,
        "tokens": 10040639488,
        "learning_rate": 0.00022855410091134407,
        "gradient_norm": 0.30562183260917664,
        "train_loss": 3.056391716003418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19152,
        "tokens": 10041163776,
        "learning_rate": 0.00022852755455604975,
        "gradient_norm": 0.329878032207489,
        "train_loss": 3.1151652336120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19153,
        "tokens": 10041688064,
        "learning_rate": 0.00022850100934295437,
        "gradient_norm": 0.3501656651496887,
        "train_loss": 3.0572197437286377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19154,
        "tokens": 10042212352,
        "learning_rate": 0.00022847446527235655,
        "gradient_norm": 0.3113660514354706,
        "train_loss": 3.0874900817871094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19155,
        "tokens": 10042736640,
        "learning_rate": 0.00022844792234455528,
        "gradient_norm": 0.38071689009666443,
        "train_loss": 3.11618709564209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19156,
        "tokens": 10043260928,
        "learning_rate": 0.00022842138055984915,
        "gradient_norm": 0.33920368552207947,
        "train_loss": 3.0574264526367188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19157,
        "tokens": 10043785216,
        "learning_rate": 0.00022839483991853697,
        "gradient_norm": 0.3680352568626404,
        "train_loss": 3.054598331451416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19158,
        "tokens": 10044309504,
        "learning_rate": 0.00022836830042091764,
        "gradient_norm": 0.35016506910324097,
        "train_loss": 3.082265853881836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19159,
        "tokens": 10044833792,
        "learning_rate": 0.00022834176206728966,
        "gradient_norm": 0.455970823764801,
        "train_loss": 3.0397732257843018,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19160,
        "tokens": 10045358080,
        "learning_rate": 0.00022831522485795199,
        "gradient_norm": 0.38799914717674255,
        "train_loss": 3.0169453620910645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19161,
        "tokens": 10045882368,
        "learning_rate": 0.00022828868879320308,
        "gradient_norm": 0.4050547480583191,
        "train_loss": 3.088134765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19162,
        "tokens": 10046406656,
        "learning_rate": 0.00022826215387334193,
        "gradient_norm": 0.38527026772499084,
        "train_loss": 3.089864730834961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19163,
        "tokens": 10046930944,
        "learning_rate": 0.0002282356200986669,
        "gradient_norm": 0.34864363074302673,
        "train_loss": 3.079047441482544,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19164,
        "tokens": 10047455232,
        "learning_rate": 0.00022820908746947697,
        "gradient_norm": 0.45368361473083496,
        "train_loss": 3.0633044242858887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19165,
        "tokens": 10047979520,
        "learning_rate": 0.00022818255598607047,
        "gradient_norm": 0.3429411053657532,
        "train_loss": 3.036281108856201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19166,
        "tokens": 10048503808,
        "learning_rate": 0.00022815602564874634,
        "gradient_norm": 0.44068658351898193,
        "train_loss": 3.1160852909088135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19167,
        "tokens": 10049028096,
        "learning_rate": 0.00022812949645780307,
        "gradient_norm": 0.3455331027507782,
        "train_loss": 3.0530881881713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19168,
        "tokens": 10049552384,
        "learning_rate": 0.0002281029684135393,
        "gradient_norm": 0.3348730504512787,
        "train_loss": 3.021892547607422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19169,
        "tokens": 10050076672,
        "learning_rate": 0.00022807644151625367,
        "gradient_norm": 0.34033969044685364,
        "train_loss": 3.092560291290283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19170,
        "tokens": 10050600960,
        "learning_rate": 0.0002280499157662447,
        "gradient_norm": 0.3619184195995331,
        "train_loss": 3.0536136627197266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19171,
        "tokens": 10051125248,
        "learning_rate": 0.00022802339116381103,
        "gradient_norm": 0.3199317455291748,
        "train_loss": 3.0405449867248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19172,
        "tokens": 10051649536,
        "learning_rate": 0.00022799686770925116,
        "gradient_norm": 0.35566505789756775,
        "train_loss": 3.0825366973876953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19173,
        "tokens": 10052173824,
        "learning_rate": 0.00022797034540286378,
        "gradient_norm": 0.34261655807495117,
        "train_loss": 3.0037760734558105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19174,
        "tokens": 10052698112,
        "learning_rate": 0.0002279438242449473,
        "gradient_norm": 0.42908021807670593,
        "train_loss": 3.1636853218078613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19175,
        "tokens": 10053222400,
        "learning_rate": 0.0002279173042358003,
        "gradient_norm": 0.36498308181762695,
        "train_loss": 3.014777183532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19176,
        "tokens": 10053746688,
        "learning_rate": 0.00022789078537572126,
        "gradient_norm": 0.3707195818424225,
        "train_loss": 3.0497426986694336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19177,
        "tokens": 10054270976,
        "learning_rate": 0.0002278642676650087,
        "gradient_norm": 0.38340437412261963,
        "train_loss": 3.088834524154663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19178,
        "tokens": 10054795264,
        "learning_rate": 0.00022783775110396122,
        "gradient_norm": 0.39096683263778687,
        "train_loss": 3.140460729598999,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19179,
        "tokens": 10055319552,
        "learning_rate": 0.0002278112356928771,
        "gradient_norm": 0.3779905140399933,
        "train_loss": 3.0520849227905273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19180,
        "tokens": 10055843840,
        "learning_rate": 0.00022778472143205502,
        "gradient_norm": 0.36767521500587463,
        "train_loss": 3.0887932777404785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19181,
        "tokens": 10056368128,
        "learning_rate": 0.00022775820832179316,
        "gradient_norm": 0.41414573788642883,
        "train_loss": 3.106480598449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19182,
        "tokens": 10056892416,
        "learning_rate": 0.00022773169636239023,
        "gradient_norm": 0.3680882751941681,
        "train_loss": 3.0969676971435547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19183,
        "tokens": 10057416704,
        "learning_rate": 0.00022770518555414448,
        "gradient_norm": 0.4390726089477539,
        "train_loss": 3.0284013748168945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19184,
        "tokens": 10057940992,
        "learning_rate": 0.00022767867589735443,
        "gradient_norm": 0.3817482590675354,
        "train_loss": 3.0447983741760254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19185,
        "tokens": 10058465280,
        "learning_rate": 0.00022765216739231836,
        "gradient_norm": 0.4321582019329071,
        "train_loss": 3.13364315032959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19186,
        "tokens": 10058989568,
        "learning_rate": 0.00022762566003933473,
        "gradient_norm": 0.4026336669921875,
        "train_loss": 3.054241180419922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19187,
        "tokens": 10059513856,
        "learning_rate": 0.000227599153838702,
        "gradient_norm": 0.38672590255737305,
        "train_loss": 3.086357593536377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19188,
        "tokens": 10060038144,
        "learning_rate": 0.00022757264879071836,
        "gradient_norm": 0.3801077902317047,
        "train_loss": 3.10170316696167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19189,
        "tokens": 10060562432,
        "learning_rate": 0.0002275461448956823,
        "gradient_norm": 0.3966352343559265,
        "train_loss": 3.1136507987976074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19190,
        "tokens": 10061086720,
        "learning_rate": 0.000227519642153892,
        "gradient_norm": 0.3906959295272827,
        "train_loss": 3.0230584144592285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19191,
        "tokens": 10061611008,
        "learning_rate": 0.00022749314056564598,
        "gradient_norm": 0.38478830456733704,
        "train_loss": 3.0504183769226074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19192,
        "tokens": 10062135296,
        "learning_rate": 0.00022746664013124235,
        "gradient_norm": 0.35468313097953796,
        "train_loss": 3.090958595275879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19193,
        "tokens": 10062659584,
        "learning_rate": 0.0002274401408509796,
        "gradient_norm": 0.3934658467769623,
        "train_loss": 3.043884754180908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19194,
        "tokens": 10063183872,
        "learning_rate": 0.00022741364272515577,
        "gradient_norm": 0.381000280380249,
        "train_loss": 3.019089698791504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19195,
        "tokens": 10063708160,
        "learning_rate": 0.0002273871457540694,
        "gradient_norm": 0.42573022842407227,
        "train_loss": 3.067011833190918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19196,
        "tokens": 10064232448,
        "learning_rate": 0.0002273606499380185,
        "gradient_norm": 0.38350215554237366,
        "train_loss": 3.061944007873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19197,
        "tokens": 10064756736,
        "learning_rate": 0.00022733415527730145,
        "gradient_norm": 0.3855660855770111,
        "train_loss": 3.0844736099243164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19198,
        "tokens": 10065281024,
        "learning_rate": 0.00022730766177221656,
        "gradient_norm": 0.3188220262527466,
        "train_loss": 3.035916805267334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19199,
        "tokens": 10065805312,
        "learning_rate": 0.0002272811694230618,
        "gradient_norm": 0.351462721824646,
        "train_loss": 3.0108699798583984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19200,
        "tokens": 10066329600,
        "learning_rate": 0.00022725467823013566,
        "gradient_norm": 0.3400159478187561,
        "train_loss": 3.0613481998443604,
        "val_loss": 3.029355525970459,
        "hellaswag_acc": 0.2824138402938843,
        "hellaswag_acc_norm": 0.29506075382232666
    },
    {
        "step": 19201,
        "tokens": 10066853888,
        "learning_rate": 0.00022722818819373607,
        "gradient_norm": 0.3878224492073059,
        "train_loss": 3.0377631187438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19202,
        "tokens": 10067378176,
        "learning_rate": 0.00022720169931416146,
        "gradient_norm": 0.3371162414550781,
        "train_loss": 3.0679969787597656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19203,
        "tokens": 10067902464,
        "learning_rate": 0.00022717521159170976,
        "gradient_norm": 0.3856886923313141,
        "train_loss": 3.0924229621887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19204,
        "tokens": 10068426752,
        "learning_rate": 0.0002271487250266793,
        "gradient_norm": 0.3250900208950043,
        "train_loss": 3.1058037281036377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19205,
        "tokens": 10068951040,
        "learning_rate": 0.0002271222396193681,
        "gradient_norm": 0.36161455512046814,
        "train_loss": 3.093069553375244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19206,
        "tokens": 10069475328,
        "learning_rate": 0.0002270957553700743,
        "gradient_norm": 0.41086435317993164,
        "train_loss": 3.0538783073425293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19207,
        "tokens": 10069999616,
        "learning_rate": 0.00022706927227909612,
        "gradient_norm": 0.3310409486293793,
        "train_loss": 3.079319953918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19208,
        "tokens": 10070523904,
        "learning_rate": 0.00022704279034673153,
        "gradient_norm": 0.3717111051082611,
        "train_loss": 3.0611777305603027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19209,
        "tokens": 10071048192,
        "learning_rate": 0.00022701630957327876,
        "gradient_norm": 0.3249801695346832,
        "train_loss": 3.0807182788848877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19210,
        "tokens": 10071572480,
        "learning_rate": 0.0002269898299590357,
        "gradient_norm": 0.43988722562789917,
        "train_loss": 3.091705322265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19211,
        "tokens": 10072096768,
        "learning_rate": 0.0002269633515043006,
        "gradient_norm": 0.3686732351779938,
        "train_loss": 3.0545389652252197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19212,
        "tokens": 10072621056,
        "learning_rate": 0.00022693687420937133,
        "gradient_norm": 0.37671196460723877,
        "train_loss": 3.044410228729248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19213,
        "tokens": 10073145344,
        "learning_rate": 0.0002269103980745461,
        "gradient_norm": 0.3646068871021271,
        "train_loss": 3.0751595497131348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19214,
        "tokens": 10073669632,
        "learning_rate": 0.00022688392310012275,
        "gradient_norm": 0.33613038063049316,
        "train_loss": 3.095945358276367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19215,
        "tokens": 10074193920,
        "learning_rate": 0.0002268574492863995,
        "gradient_norm": 0.3588472008705139,
        "train_loss": 3.0624806880950928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19216,
        "tokens": 10074718208,
        "learning_rate": 0.0002268309766336741,
        "gradient_norm": 0.39046669006347656,
        "train_loss": 3.1231729984283447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19217,
        "tokens": 10075242496,
        "learning_rate": 0.00022680450514224473,
        "gradient_norm": 0.3500382900238037,
        "train_loss": 3.1054439544677734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19218,
        "tokens": 10075766784,
        "learning_rate": 0.0002267780348124093,
        "gradient_norm": 0.3623901903629303,
        "train_loss": 3.0745444297790527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19219,
        "tokens": 10076291072,
        "learning_rate": 0.00022675156564446573,
        "gradient_norm": 0.3452896177768707,
        "train_loss": 3.0780043601989746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19220,
        "tokens": 10076815360,
        "learning_rate": 0.00022672509763871197,
        "gradient_norm": 0.3591442108154297,
        "train_loss": 3.1106104850769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19221,
        "tokens": 10077339648,
        "learning_rate": 0.00022669863079544602,
        "gradient_norm": 0.4120958149433136,
        "train_loss": 3.070427417755127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19222,
        "tokens": 10077863936,
        "learning_rate": 0.00022667216511496573,
        "gradient_norm": 0.3947271406650543,
        "train_loss": 3.044565200805664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19223,
        "tokens": 10078388224,
        "learning_rate": 0.000226645700597569,
        "gradient_norm": 0.3974933922290802,
        "train_loss": 3.0428884029388428,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19224,
        "tokens": 10078912512,
        "learning_rate": 0.0002266192372435538,
        "gradient_norm": 0.3991338610649109,
        "train_loss": 3.1225719451904297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19225,
        "tokens": 10079436800,
        "learning_rate": 0.00022659277505321794,
        "gradient_norm": 0.3587513864040375,
        "train_loss": 3.079414129257202,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19226,
        "tokens": 10079961088,
        "learning_rate": 0.00022656631402685924,
        "gradient_norm": 0.3567548394203186,
        "train_loss": 3.049152374267578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19227,
        "tokens": 10080485376,
        "learning_rate": 0.0002265398541647757,
        "gradient_norm": 0.3291909694671631,
        "train_loss": 3.0633740425109863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19228,
        "tokens": 10081009664,
        "learning_rate": 0.00022651339546726494,
        "gradient_norm": 0.4004215896129608,
        "train_loss": 3.071838140487671,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19229,
        "tokens": 10081533952,
        "learning_rate": 0.00022648693793462507,
        "gradient_norm": 0.3612689673900604,
        "train_loss": 3.097665309906006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19230,
        "tokens": 10082058240,
        "learning_rate": 0.00022646048156715358,
        "gradient_norm": 0.362643837928772,
        "train_loss": 3.044908046722412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19231,
        "tokens": 10082582528,
        "learning_rate": 0.0002264340263651486,
        "gradient_norm": 0.344918817281723,
        "train_loss": 3.097910165786743,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19232,
        "tokens": 10083106816,
        "learning_rate": 0.00022640757232890763,
        "gradient_norm": 0.4041232466697693,
        "train_loss": 3.052849531173706,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19233,
        "tokens": 10083631104,
        "learning_rate": 0.00022638111945872866,
        "gradient_norm": 0.37376633286476135,
        "train_loss": 3.08693265914917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19234,
        "tokens": 10084155392,
        "learning_rate": 0.00022635466775490924,
        "gradient_norm": 0.39485278725624084,
        "train_loss": 3.074324607849121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19235,
        "tokens": 10084679680,
        "learning_rate": 0.00022632821721774732,
        "gradient_norm": 0.39694204926490784,
        "train_loss": 3.08418607711792,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19236,
        "tokens": 10085203968,
        "learning_rate": 0.0002263017678475405,
        "gradient_norm": 0.3940146565437317,
        "train_loss": 3.1187052726745605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19237,
        "tokens": 10085728256,
        "learning_rate": 0.00022627531964458653,
        "gradient_norm": 0.37449678778648376,
        "train_loss": 3.0502567291259766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19238,
        "tokens": 10086252544,
        "learning_rate": 0.0002262488726091832,
        "gradient_norm": 0.3668305575847626,
        "train_loss": 3.102372646331787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19239,
        "tokens": 10086776832,
        "learning_rate": 0.00022622242674162805,
        "gradient_norm": 0.3861941695213318,
        "train_loss": 3.0730643272399902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19240,
        "tokens": 10087301120,
        "learning_rate": 0.00022619598204221897,
        "gradient_norm": 0.38646289706230164,
        "train_loss": 3.0847835540771484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19241,
        "tokens": 10087825408,
        "learning_rate": 0.00022616953851125338,
        "gradient_norm": 0.36295247077941895,
        "train_loss": 3.0238537788391113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19242,
        "tokens": 10088349696,
        "learning_rate": 0.00022614309614902922,
        "gradient_norm": 0.43423500657081604,
        "train_loss": 3.1780154705047607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19243,
        "tokens": 10088873984,
        "learning_rate": 0.0002261166549558438,
        "gradient_norm": 0.4555307924747467,
        "train_loss": 3.045579433441162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19244,
        "tokens": 10089398272,
        "learning_rate": 0.00022609021493199505,
        "gradient_norm": 0.3596494495868683,
        "train_loss": 3.0450496673583984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19245,
        "tokens": 10089922560,
        "learning_rate": 0.0002260637760777804,
        "gradient_norm": 0.424106240272522,
        "train_loss": 3.0162100791931152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19246,
        "tokens": 10090446848,
        "learning_rate": 0.00022603733839349742,
        "gradient_norm": 0.362516850233078,
        "train_loss": 3.1631317138671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19247,
        "tokens": 10090971136,
        "learning_rate": 0.00022601090187944394,
        "gradient_norm": 0.4935161769390106,
        "train_loss": 3.0689663887023926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19248,
        "tokens": 10091495424,
        "learning_rate": 0.0002259844665359173,
        "gradient_norm": 0.3897019624710083,
        "train_loss": 3.0705151557922363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19249,
        "tokens": 10092019712,
        "learning_rate": 0.00022595803236321522,
        "gradient_norm": 0.4117691218852997,
        "train_loss": 3.1601390838623047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19250,
        "tokens": 10092544000,
        "learning_rate": 0.0002259315993616351,
        "gradient_norm": 0.39263343811035156,
        "train_loss": 3.0698986053466797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19251,
        "tokens": 10093068288,
        "learning_rate": 0.00022590516753147465,
        "gradient_norm": 0.38108155131340027,
        "train_loss": 3.181002616882324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19252,
        "tokens": 10093592576,
        "learning_rate": 0.0002258787368730312,
        "gradient_norm": 0.413318395614624,
        "train_loss": 3.0618178844451904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19253,
        "tokens": 10094116864,
        "learning_rate": 0.00022585230738660246,
        "gradient_norm": 0.3502894639968872,
        "train_loss": 3.0586893558502197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19254,
        "tokens": 10094641152,
        "learning_rate": 0.0002258258790724857,
        "gradient_norm": 0.3802541494369507,
        "train_loss": 3.1056177616119385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19255,
        "tokens": 10095165440,
        "learning_rate": 0.00022579945193097864,
        "gradient_norm": 0.35580191016197205,
        "train_loss": 3.065850257873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19256,
        "tokens": 10095689728,
        "learning_rate": 0.00022577302596237854,
        "gradient_norm": 0.3385917544364929,
        "train_loss": 3.1342110633850098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19257,
        "tokens": 10096214016,
        "learning_rate": 0.00022574660116698295,
        "gradient_norm": 0.36102208495140076,
        "train_loss": 3.0837860107421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19258,
        "tokens": 10096738304,
        "learning_rate": 0.00022572017754508942,
        "gradient_norm": 0.35535964369773865,
        "train_loss": 3.1211795806884766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19259,
        "tokens": 10097262592,
        "learning_rate": 0.00022569375509699517,
        "gradient_norm": 0.4148699939250946,
        "train_loss": 3.0608983039855957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19260,
        "tokens": 10097786880,
        "learning_rate": 0.00022566733382299784,
        "gradient_norm": 0.3915184438228607,
        "train_loss": 3.0668535232543945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19261,
        "tokens": 10098311168,
        "learning_rate": 0.00022564091372339465,
        "gradient_norm": 0.40459901094436646,
        "train_loss": 3.125699520111084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19262,
        "tokens": 10098835456,
        "learning_rate": 0.00022561449479848312,
        "gradient_norm": 0.4869583249092102,
        "train_loss": 3.048069477081299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19263,
        "tokens": 10099359744,
        "learning_rate": 0.0002255880770485605,
        "gradient_norm": 0.3449634611606598,
        "train_loss": 3.049990177154541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19264,
        "tokens": 10099884032,
        "learning_rate": 0.0002255616604739243,
        "gradient_norm": 0.3658529818058014,
        "train_loss": 3.0511975288391113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19265,
        "tokens": 10100408320,
        "learning_rate": 0.00022553524507487173,
        "gradient_norm": 0.3954901099205017,
        "train_loss": 3.095191717147827,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19266,
        "tokens": 10100932608,
        "learning_rate": 0.0002255088308517002,
        "gradient_norm": 0.4090552031993866,
        "train_loss": 3.0843138694763184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19267,
        "tokens": 10101456896,
        "learning_rate": 0.00022548241780470706,
        "gradient_norm": 0.3223061263561249,
        "train_loss": 3.0155725479125977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19268,
        "tokens": 10101981184,
        "learning_rate": 0.0002254560059341896,
        "gradient_norm": 0.37334463000297546,
        "train_loss": 3.1157708168029785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19269,
        "tokens": 10102505472,
        "learning_rate": 0.0002254295952404451,
        "gradient_norm": 0.3711826503276825,
        "train_loss": 3.1236019134521484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19270,
        "tokens": 10103029760,
        "learning_rate": 0.00022540318572377083,
        "gradient_norm": 0.36262497305870056,
        "train_loss": 3.0670390129089355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19271,
        "tokens": 10103554048,
        "learning_rate": 0.00022537677738446413,
        "gradient_norm": 0.3625500202178955,
        "train_loss": 3.068427562713623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19272,
        "tokens": 10104078336,
        "learning_rate": 0.00022535037022282218,
        "gradient_norm": 0.3514903485774994,
        "train_loss": 3.101957321166992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19273,
        "tokens": 10104602624,
        "learning_rate": 0.00022532396423914232,
        "gradient_norm": 0.33386221528053284,
        "train_loss": 3.045701742172241,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19274,
        "tokens": 10105126912,
        "learning_rate": 0.00022529755943372166,
        "gradient_norm": 0.3337665796279907,
        "train_loss": 3.035658359527588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19275,
        "tokens": 10105651200,
        "learning_rate": 0.00022527115580685752,
        "gradient_norm": 0.3423473536968231,
        "train_loss": 3.0574283599853516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19276,
        "tokens": 10106175488,
        "learning_rate": 0.00022524475335884705,
        "gradient_norm": 0.3384664058685303,
        "train_loss": 3.1150245666503906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19277,
        "tokens": 10106699776,
        "learning_rate": 0.00022521835208998744,
        "gradient_norm": 0.3965986967086792,
        "train_loss": 3.081190586090088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19278,
        "tokens": 10107224064,
        "learning_rate": 0.00022519195200057594,
        "gradient_norm": 0.3681313693523407,
        "train_loss": 3.084257125854492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19279,
        "tokens": 10107748352,
        "learning_rate": 0.0002251655530909096,
        "gradient_norm": 0.3797270357608795,
        "train_loss": 3.066002368927002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19280,
        "tokens": 10108272640,
        "learning_rate": 0.00022513915536128575,
        "gradient_norm": 0.3303581476211548,
        "train_loss": 3.0631208419799805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19281,
        "tokens": 10108796928,
        "learning_rate": 0.0002251127588120013,
        "gradient_norm": 0.3599163889884949,
        "train_loss": 3.0674986839294434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19282,
        "tokens": 10109321216,
        "learning_rate": 0.0002250863634433536,
        "gradient_norm": 0.3463813066482544,
        "train_loss": 3.0577893257141113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19283,
        "tokens": 10109845504,
        "learning_rate": 0.00022505996925563956,
        "gradient_norm": 0.3704577684402466,
        "train_loss": 3.0909929275512695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19284,
        "tokens": 10110369792,
        "learning_rate": 0.00022503357624915646,
        "gradient_norm": 0.33941417932510376,
        "train_loss": 3.0402286052703857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19285,
        "tokens": 10110894080,
        "learning_rate": 0.00022500718442420125,
        "gradient_norm": 0.3492646813392639,
        "train_loss": 3.0666613578796387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19286,
        "tokens": 10111418368,
        "learning_rate": 0.00022498079378107102,
        "gradient_norm": 0.32874855399131775,
        "train_loss": 3.0858073234558105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19287,
        "tokens": 10111942656,
        "learning_rate": 0.00022495440432006295,
        "gradient_norm": 0.3502384424209595,
        "train_loss": 3.099971055984497,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19288,
        "tokens": 10112466944,
        "learning_rate": 0.00022492801604147392,
        "gradient_norm": 0.36064302921295166,
        "train_loss": 3.076453685760498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19289,
        "tokens": 10112991232,
        "learning_rate": 0.0002249016289456012,
        "gradient_norm": 0.386247843503952,
        "train_loss": 3.132875442504883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19290,
        "tokens": 10113515520,
        "learning_rate": 0.00022487524303274145,
        "gradient_norm": 0.38602229952812195,
        "train_loss": 3.07565975189209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19291,
        "tokens": 10114039808,
        "learning_rate": 0.00022484885830319207,
        "gradient_norm": 0.345304012298584,
        "train_loss": 3.0790939331054688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19292,
        "tokens": 10114564096,
        "learning_rate": 0.00022482247475724972,
        "gradient_norm": 0.35710474848747253,
        "train_loss": 3.0357351303100586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19293,
        "tokens": 10115088384,
        "learning_rate": 0.00022479609239521163,
        "gradient_norm": 0.3988705277442932,
        "train_loss": 3.068816900253296,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19294,
        "tokens": 10115612672,
        "learning_rate": 0.0002247697112173746,
        "gradient_norm": 0.34845203161239624,
        "train_loss": 3.0640785694122314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19295,
        "tokens": 10116136960,
        "learning_rate": 0.00022474333122403565,
        "gradient_norm": 0.3804723620414734,
        "train_loss": 3.007744789123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19296,
        "tokens": 10116661248,
        "learning_rate": 0.00022471695241549166,
        "gradient_norm": 0.39682725071907043,
        "train_loss": 3.1233725547790527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19297,
        "tokens": 10117185536,
        "learning_rate": 0.00022469057479203964,
        "gradient_norm": 0.38818004727363586,
        "train_loss": 3.031195640563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19298,
        "tokens": 10117709824,
        "learning_rate": 0.00022466419835397654,
        "gradient_norm": 0.35981202125549316,
        "train_loss": 3.0415737628936768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19299,
        "tokens": 10118234112,
        "learning_rate": 0.00022463782310159908,
        "gradient_norm": 0.35428422689437866,
        "train_loss": 3.058412790298462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19300,
        "tokens": 10118758400,
        "learning_rate": 0.0002246114490352044,
        "gradient_norm": 0.3543645143508911,
        "train_loss": 3.068479537963867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19301,
        "tokens": 10119282688,
        "learning_rate": 0.00022458507615508912,
        "gradient_norm": 0.34747710824012756,
        "train_loss": 3.0562877655029297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19302,
        "tokens": 10119806976,
        "learning_rate": 0.00022455870446155035,
        "gradient_norm": 0.3408537805080414,
        "train_loss": 3.032827854156494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19303,
        "tokens": 10120331264,
        "learning_rate": 0.0002245323339548846,
        "gradient_norm": 0.3346738815307617,
        "train_loss": 3.0841479301452637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19304,
        "tokens": 10120855552,
        "learning_rate": 0.00022450596463538907,
        "gradient_norm": 0.36005356907844543,
        "train_loss": 3.0375170707702637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19305,
        "tokens": 10121379840,
        "learning_rate": 0.0002244795965033603,
        "gradient_norm": 0.4111931622028351,
        "train_loss": 3.084280490875244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19306,
        "tokens": 10121904128,
        "learning_rate": 0.00022445322955909518,
        "gradient_norm": 0.33450600504875183,
        "train_loss": 3.056255578994751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19307,
        "tokens": 10122428416,
        "learning_rate": 0.00022442686380289066,
        "gradient_norm": 0.43453314900398254,
        "train_loss": 3.037755012512207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19308,
        "tokens": 10122952704,
        "learning_rate": 0.00022440049923504326,
        "gradient_norm": 0.37122178077697754,
        "train_loss": 3.1118552684783936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19309,
        "tokens": 10123476992,
        "learning_rate": 0.00022437413585584998,
        "gradient_norm": 0.4161624014377594,
        "train_loss": 3.078464984893799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19310,
        "tokens": 10124001280,
        "learning_rate": 0.00022434777366560737,
        "gradient_norm": 0.36128056049346924,
        "train_loss": 3.062807559967041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19311,
        "tokens": 10124525568,
        "learning_rate": 0.0002243214126646124,
        "gradient_norm": 0.43559530377388,
        "train_loss": 3.0143022537231445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19312,
        "tokens": 10125049856,
        "learning_rate": 0.00022429505285316155,
        "gradient_norm": 0.3226648271083832,
        "train_loss": 3.036644697189331,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19313,
        "tokens": 10125574144,
        "learning_rate": 0.00022426869423155174,
        "gradient_norm": 0.41579991579055786,
        "train_loss": 3.067317485809326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19314,
        "tokens": 10126098432,
        "learning_rate": 0.0002242423368000794,
        "gradient_norm": 0.33949151635169983,
        "train_loss": 3.0370430946350098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19315,
        "tokens": 10126622720,
        "learning_rate": 0.0002242159805590416,
        "gradient_norm": 0.45048943161964417,
        "train_loss": 3.0798423290252686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19316,
        "tokens": 10127147008,
        "learning_rate": 0.00022418962550873464,
        "gradient_norm": 0.3365076780319214,
        "train_loss": 3.0151586532592773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19317,
        "tokens": 10127671296,
        "learning_rate": 0.00022416327164945533,
        "gradient_norm": 0.38686737418174744,
        "train_loss": 2.9841885566711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19318,
        "tokens": 10128195584,
        "learning_rate": 0.00022413691898150049,
        "gradient_norm": 0.41191917657852173,
        "train_loss": 3.0840234756469727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19319,
        "tokens": 10128719872,
        "learning_rate": 0.00022411056750516644,
        "gradient_norm": 0.37134161591529846,
        "train_loss": 3.0498931407928467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19320,
        "tokens": 10129244160,
        "learning_rate": 0.00022408421722075006,
        "gradient_norm": 0.34110772609710693,
        "train_loss": 3.0842843055725098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19321,
        "tokens": 10129768448,
        "learning_rate": 0.00022405786812854773,
        "gradient_norm": 0.3354310989379883,
        "train_loss": 3.0404319763183594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19322,
        "tokens": 10130292736,
        "learning_rate": 0.00022403152022885627,
        "gradient_norm": 0.3497488498687744,
        "train_loss": 3.0361764430999756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19323,
        "tokens": 10130817024,
        "learning_rate": 0.000224005173521972,
        "gradient_norm": 0.3381616473197937,
        "train_loss": 3.086946964263916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19324,
        "tokens": 10131341312,
        "learning_rate": 0.00022397882800819183,
        "gradient_norm": 0.3880951404571533,
        "train_loss": 3.0227549076080322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19325,
        "tokens": 10131865600,
        "learning_rate": 0.00022395248368781192,
        "gradient_norm": 0.33293846249580383,
        "train_loss": 3.050934314727783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19326,
        "tokens": 10132389888,
        "learning_rate": 0.00022392614056112909,
        "gradient_norm": 0.3615208566188812,
        "train_loss": 3.026078701019287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19327,
        "tokens": 10132914176,
        "learning_rate": 0.00022389979862843973,
        "gradient_norm": 0.3243531286716461,
        "train_loss": 3.1508078575134277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19328,
        "tokens": 10133438464,
        "learning_rate": 0.00022387345789004042,
        "gradient_norm": 0.34503623843193054,
        "train_loss": 3.010976791381836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19329,
        "tokens": 10133962752,
        "learning_rate": 0.00022384711834622765,
        "gradient_norm": 0.36779916286468506,
        "train_loss": 3.0264177322387695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19330,
        "tokens": 10134487040,
        "learning_rate": 0.00022382077999729785,
        "gradient_norm": 0.35076281428337097,
        "train_loss": 3.0572288036346436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19331,
        "tokens": 10135011328,
        "learning_rate": 0.00022379444284354754,
        "gradient_norm": 0.3815653920173645,
        "train_loss": 3.1016287803649902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19332,
        "tokens": 10135535616,
        "learning_rate": 0.00022376810688527318,
        "gradient_norm": 0.3803902566432953,
        "train_loss": 3.0846614837646484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19333,
        "tokens": 10136059904,
        "learning_rate": 0.0002237417721227712,
        "gradient_norm": 0.4098372161388397,
        "train_loss": 3.0690228939056396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19334,
        "tokens": 10136584192,
        "learning_rate": 0.000223715438556338,
        "gradient_norm": 0.3463176190853119,
        "train_loss": 3.03206205368042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19335,
        "tokens": 10137108480,
        "learning_rate": 0.00022368910618627007,
        "gradient_norm": 0.3608172833919525,
        "train_loss": 3.0721142292022705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19336,
        "tokens": 10137632768,
        "learning_rate": 0.00022366277501286374,
        "gradient_norm": 0.3577113151550293,
        "train_loss": 3.016627311706543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19337,
        "tokens": 10138157056,
        "learning_rate": 0.00022363644503641536,
        "gradient_norm": 0.47718778252601624,
        "train_loss": 2.9515256881713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19338,
        "tokens": 10138681344,
        "learning_rate": 0.00022361011625722152,
        "gradient_norm": 0.44705212116241455,
        "train_loss": 3.045567274093628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19339,
        "tokens": 10139205632,
        "learning_rate": 0.0002235837886755783,
        "gradient_norm": 0.35580557584762573,
        "train_loss": 3.067960262298584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19340,
        "tokens": 10139729920,
        "learning_rate": 0.00022355746229178232,
        "gradient_norm": 0.4168286919593811,
        "train_loss": 3.047698497772217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19341,
        "tokens": 10140254208,
        "learning_rate": 0.00022353113710612968,
        "gradient_norm": 0.37174591422080994,
        "train_loss": 3.081826686859131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19342,
        "tokens": 10140778496,
        "learning_rate": 0.00022350481311891692,
        "gradient_norm": 0.39270058274269104,
        "train_loss": 3.0558223724365234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19343,
        "tokens": 10141302784,
        "learning_rate": 0.0002234784903304401,
        "gradient_norm": 0.39128541946411133,
        "train_loss": 3.084193706512451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19344,
        "tokens": 10141827072,
        "learning_rate": 0.0002234521687409958,
        "gradient_norm": 0.3945678472518921,
        "train_loss": 3.106426954269409,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19345,
        "tokens": 10142351360,
        "learning_rate": 0.00022342584835088,
        "gradient_norm": 0.3791842758655548,
        "train_loss": 3.0648365020751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19346,
        "tokens": 10142875648,
        "learning_rate": 0.00022339952916038914,
        "gradient_norm": 0.3763614296913147,
        "train_loss": 3.003793239593506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19347,
        "tokens": 10143399936,
        "learning_rate": 0.00022337321116981963,
        "gradient_norm": 0.35145875811576843,
        "train_loss": 3.0779917240142822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19348,
        "tokens": 10143924224,
        "learning_rate": 0.00022334689437946738,
        "gradient_norm": 0.37896713614463806,
        "train_loss": 3.0780954360961914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19349,
        "tokens": 10144448512,
        "learning_rate": 0.00022332057878962888,
        "gradient_norm": 0.4504448473453522,
        "train_loss": 3.037752866744995,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19350,
        "tokens": 10144972800,
        "learning_rate": 0.00022329426440060015,
        "gradient_norm": 0.35611146688461304,
        "train_loss": 3.0738911628723145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19351,
        "tokens": 10145497088,
        "learning_rate": 0.00022326795121267758,
        "gradient_norm": 0.37440773844718933,
        "train_loss": 3.0919783115386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19352,
        "tokens": 10146021376,
        "learning_rate": 0.00022324163922615717,
        "gradient_norm": 0.3576674461364746,
        "train_loss": 3.0427517890930176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19353,
        "tokens": 10146545664,
        "learning_rate": 0.0002232153284413353,
        "gradient_norm": 0.36621302366256714,
        "train_loss": 3.1075422763824463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19354,
        "tokens": 10147069952,
        "learning_rate": 0.00022318901885850793,
        "gradient_norm": 0.3712514340877533,
        "train_loss": 3.1978909969329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19355,
        "tokens": 10147594240,
        "learning_rate": 0.00022316271047797138,
        "gradient_norm": 0.3883437216281891,
        "train_loss": 3.08712100982666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19356,
        "tokens": 10148118528,
        "learning_rate": 0.0002231364033000216,
        "gradient_norm": 0.3434949815273285,
        "train_loss": 3.0131664276123047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19357,
        "tokens": 10148642816,
        "learning_rate": 0.00022311009732495481,
        "gradient_norm": 0.34476444125175476,
        "train_loss": 3.065483570098877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19358,
        "tokens": 10149167104,
        "learning_rate": 0.0002230837925530672,
        "gradient_norm": 0.5246759653091431,
        "train_loss": 3.0923914909362793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19359,
        "tokens": 10149691392,
        "learning_rate": 0.0002230574889846547,
        "gradient_norm": 0.6674810647964478,
        "train_loss": 2.991908550262451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19360,
        "tokens": 10150215680,
        "learning_rate": 0.00022303118662001358,
        "gradient_norm": 0.4721234440803528,
        "train_loss": 3.078758716583252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19361,
        "tokens": 10150739968,
        "learning_rate": 0.00022300488545943967,
        "gradient_norm": 0.43872904777526855,
        "train_loss": 3.1409103870391846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19362,
        "tokens": 10151264256,
        "learning_rate": 0.00022297858550322924,
        "gradient_norm": 0.3960123360157013,
        "train_loss": 3.0749757289886475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19363,
        "tokens": 10151788544,
        "learning_rate": 0.00022295228675167815,
        "gradient_norm": 0.4527522027492523,
        "train_loss": 3.049689769744873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19364,
        "tokens": 10152312832,
        "learning_rate": 0.00022292598920508263,
        "gradient_norm": 0.3776179850101471,
        "train_loss": 3.088900089263916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19365,
        "tokens": 10152837120,
        "learning_rate": 0.00022289969286373845,
        "gradient_norm": 0.3856840431690216,
        "train_loss": 3.088559150695801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19366,
        "tokens": 10153361408,
        "learning_rate": 0.00022287339772794173,
        "gradient_norm": 0.36425498127937317,
        "train_loss": 3.021592855453491,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19367,
        "tokens": 10153885696,
        "learning_rate": 0.0002228471037979886,
        "gradient_norm": 0.416124165058136,
        "train_loss": 3.1246519088745117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19368,
        "tokens": 10154409984,
        "learning_rate": 0.0002228208110741747,
        "gradient_norm": 0.3679841458797455,
        "train_loss": 3.059195041656494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19369,
        "tokens": 10154934272,
        "learning_rate": 0.00022279451955679633,
        "gradient_norm": 0.39927512407302856,
        "train_loss": 3.0538344383239746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19370,
        "tokens": 10155458560,
        "learning_rate": 0.00022276822924614917,
        "gradient_norm": 0.3564268946647644,
        "train_loss": 3.1018600463867188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19371,
        "tokens": 10155982848,
        "learning_rate": 0.00022274194014252935,
        "gradient_norm": 0.40774551033973694,
        "train_loss": 3.0681982040405273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19372,
        "tokens": 10156507136,
        "learning_rate": 0.00022271565224623262,
        "gradient_norm": 0.36107563972473145,
        "train_loss": 3.131927967071533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19373,
        "tokens": 10157031424,
        "learning_rate": 0.00022268936555755505,
        "gradient_norm": 0.4040170907974243,
        "train_loss": 3.080077648162842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19374,
        "tokens": 10157555712,
        "learning_rate": 0.00022266308007679232,
        "gradient_norm": 0.40821385383605957,
        "train_loss": 3.0442259311676025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19375,
        "tokens": 10158080000,
        "learning_rate": 0.0002226367958042405,
        "gradient_norm": 0.3646999001502991,
        "train_loss": 3.0691914558410645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19376,
        "tokens": 10158604288,
        "learning_rate": 0.00022261051274019534,
        "gradient_norm": 0.38263463973999023,
        "train_loss": 3.1279664039611816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19377,
        "tokens": 10159128576,
        "learning_rate": 0.0002225842308849527,
        "gradient_norm": 0.34842491149902344,
        "train_loss": 3.052874803543091,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19378,
        "tokens": 10159652864,
        "learning_rate": 0.0002225579502388085,
        "gradient_norm": 0.4011516869068146,
        "train_loss": 3.1320996284484863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19379,
        "tokens": 10160177152,
        "learning_rate": 0.00022253167080205847,
        "gradient_norm": 0.34571218490600586,
        "train_loss": 3.0419328212738037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19380,
        "tokens": 10160701440,
        "learning_rate": 0.00022250539257499843,
        "gradient_norm": 0.35593387484550476,
        "train_loss": 3.0443265438079834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19381,
        "tokens": 10161225728,
        "learning_rate": 0.00022247911555792424,
        "gradient_norm": 0.33770790696144104,
        "train_loss": 3.0664095878601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19382,
        "tokens": 10161750016,
        "learning_rate": 0.0002224528397511316,
        "gradient_norm": 0.3844901919364929,
        "train_loss": 3.116671562194824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19383,
        "tokens": 10162274304,
        "learning_rate": 0.00022242656515491632,
        "gradient_norm": 0.34348198771476746,
        "train_loss": 3.0601108074188232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19384,
        "tokens": 10162798592,
        "learning_rate": 0.00022240029176957414,
        "gradient_norm": 0.3897930681705475,
        "train_loss": 3.114145278930664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19385,
        "tokens": 10163322880,
        "learning_rate": 0.00022237401959540083,
        "gradient_norm": 0.3752838969230652,
        "train_loss": 3.085336208343506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19386,
        "tokens": 10163847168,
        "learning_rate": 0.000222347748632692,
        "gradient_norm": 0.38331568241119385,
        "train_loss": 3.0414085388183594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19387,
        "tokens": 10164371456,
        "learning_rate": 0.00022232147888174357,
        "gradient_norm": 0.3288806676864624,
        "train_loss": 3.0654640197753906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19388,
        "tokens": 10164895744,
        "learning_rate": 0.00022229521034285098,
        "gradient_norm": 0.39418789744377136,
        "train_loss": 3.0691473484039307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19389,
        "tokens": 10165420032,
        "learning_rate": 0.00022226894301631022,
        "gradient_norm": 0.3063613772392273,
        "train_loss": 3.082176446914673,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19390,
        "tokens": 10165944320,
        "learning_rate": 0.00022224267690241662,
        "gradient_norm": 0.37560799717903137,
        "train_loss": 3.136765718460083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19391,
        "tokens": 10166468608,
        "learning_rate": 0.0002222164120014662,
        "gradient_norm": 0.3566780984401703,
        "train_loss": 3.092613697052002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19392,
        "tokens": 10166992896,
        "learning_rate": 0.00022219014831375428,
        "gradient_norm": 0.33658382296562195,
        "train_loss": 3.0577521324157715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19393,
        "tokens": 10167517184,
        "learning_rate": 0.0002221638858395767,
        "gradient_norm": 0.34516021609306335,
        "train_loss": 3.037569999694824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19394,
        "tokens": 10168041472,
        "learning_rate": 0.00022213762457922893,
        "gradient_norm": 0.35954612493515015,
        "train_loss": 3.0566511154174805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19395,
        "tokens": 10168565760,
        "learning_rate": 0.00022211136453300677,
        "gradient_norm": 0.3545181155204773,
        "train_loss": 3.0576696395874023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19396,
        "tokens": 10169090048,
        "learning_rate": 0.00022208510570120559,
        "gradient_norm": 0.360099196434021,
        "train_loss": 3.068009376525879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19397,
        "tokens": 10169614336,
        "learning_rate": 0.00022205884808412102,
        "gradient_norm": 0.3271369934082031,
        "train_loss": 3.0452709197998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19398,
        "tokens": 10170138624,
        "learning_rate": 0.0002220325916820488,
        "gradient_norm": 0.39786121249198914,
        "train_loss": 3.069932222366333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19399,
        "tokens": 10170662912,
        "learning_rate": 0.00022200633649528423,
        "gradient_norm": 0.365876704454422,
        "train_loss": 3.08351469039917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19400,
        "tokens": 10171187200,
        "learning_rate": 0.00022198008252412307,
        "gradient_norm": 0.35722342133522034,
        "train_loss": 3.0989785194396973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19401,
        "tokens": 10171711488,
        "learning_rate": 0.00022195382976886063,
        "gradient_norm": 0.3871552050113678,
        "train_loss": 3.0050418376922607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19402,
        "tokens": 10172235776,
        "learning_rate": 0.00022192757822979262,
        "gradient_norm": 0.3993208706378937,
        "train_loss": 3.0802254676818848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19403,
        "tokens": 10172760064,
        "learning_rate": 0.00022190132790721436,
        "gradient_norm": 0.37726452946662903,
        "train_loss": 3.002025842666626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19404,
        "tokens": 10173284352,
        "learning_rate": 0.00022187507880142146,
        "gradient_norm": 0.33648422360420227,
        "train_loss": 3.0512521266937256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19405,
        "tokens": 10173808640,
        "learning_rate": 0.00022184883091270924,
        "gradient_norm": 0.36649802327156067,
        "train_loss": 3.0663833618164062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19406,
        "tokens": 10174332928,
        "learning_rate": 0.00022182258424137324,
        "gradient_norm": 0.4067493677139282,
        "train_loss": 3.209322929382324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19407,
        "tokens": 10174857216,
        "learning_rate": 0.000221796338787709,
        "gradient_norm": 0.34577301144599915,
        "train_loss": 3.0322160720825195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19408,
        "tokens": 10175381504,
        "learning_rate": 0.00022177009455201177,
        "gradient_norm": 0.3664873540401459,
        "train_loss": 3.0662336349487305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19409,
        "tokens": 10175905792,
        "learning_rate": 0.0002217438515345771,
        "gradient_norm": 0.3597390055656433,
        "train_loss": 3.0753350257873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19410,
        "tokens": 10176430080,
        "learning_rate": 0.00022171760973570026,
        "gradient_norm": 0.3821263313293457,
        "train_loss": 3.0553178787231445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19411,
        "tokens": 10176954368,
        "learning_rate": 0.0002216913691556768,
        "gradient_norm": 0.3857748210430145,
        "train_loss": 3.0459418296813965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19412,
        "tokens": 10177478656,
        "learning_rate": 0.00022166512979480187,
        "gradient_norm": 0.3603546917438507,
        "train_loss": 3.0719759464263916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19413,
        "tokens": 10178002944,
        "learning_rate": 0.00022163889165337106,
        "gradient_norm": 0.39939218759536743,
        "train_loss": 3.044544219970703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19414,
        "tokens": 10178527232,
        "learning_rate": 0.0002216126547316795,
        "gradient_norm": 0.43816348910331726,
        "train_loss": 3.073765277862549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19415,
        "tokens": 10179051520,
        "learning_rate": 0.00022158641903002272,
        "gradient_norm": 0.40607598423957825,
        "train_loss": 3.0558271408081055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19416,
        "tokens": 10179575808,
        "learning_rate": 0.00022156018454869584,
        "gradient_norm": 0.34040284156799316,
        "train_loss": 3.0672507286071777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19417,
        "tokens": 10180100096,
        "learning_rate": 0.00022153395128799423,
        "gradient_norm": 0.37370264530181885,
        "train_loss": 3.065880298614502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19418,
        "tokens": 10180624384,
        "learning_rate": 0.00022150771924821333,
        "gradient_norm": 0.3752368688583374,
        "train_loss": 3.07889986038208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19419,
        "tokens": 10181148672,
        "learning_rate": 0.00022148148842964814,
        "gradient_norm": 0.38418737053871155,
        "train_loss": 3.1432158946990967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19420,
        "tokens": 10181672960,
        "learning_rate": 0.00022145525883259423,
        "gradient_norm": 0.41089892387390137,
        "train_loss": 3.0805039405822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19421,
        "tokens": 10182197248,
        "learning_rate": 0.0002214290304573466,
        "gradient_norm": 0.36034417152404785,
        "train_loss": 3.0856456756591797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19422,
        "tokens": 10182721536,
        "learning_rate": 0.0002214028033042006,
        "gradient_norm": 0.4358579218387604,
        "train_loss": 3.028564929962158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19423,
        "tokens": 10183245824,
        "learning_rate": 0.00022137657737345137,
        "gradient_norm": 0.3616434633731842,
        "train_loss": 3.0839452743530273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19424,
        "tokens": 10183770112,
        "learning_rate": 0.00022135035266539427,
        "gradient_norm": 0.35651397705078125,
        "train_loss": 3.0905539989471436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19425,
        "tokens": 10184294400,
        "learning_rate": 0.00022132412918032424,
        "gradient_norm": 0.3810248076915741,
        "train_loss": 3.145742893218994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19426,
        "tokens": 10184818688,
        "learning_rate": 0.00022129790691853668,
        "gradient_norm": 0.39624524116516113,
        "train_loss": 3.0921630859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19427,
        "tokens": 10185342976,
        "learning_rate": 0.00022127168588032667,
        "gradient_norm": 0.3510283827781677,
        "train_loss": 3.0658037662506104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19428,
        "tokens": 10185867264,
        "learning_rate": 0.0002212454660659894,
        "gradient_norm": 0.40812617540359497,
        "train_loss": 3.0817298889160156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19429,
        "tokens": 10186391552,
        "learning_rate": 0.00022121924747581993,
        "gradient_norm": 0.3655896484851837,
        "train_loss": 3.054454803466797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19430,
        "tokens": 10186915840,
        "learning_rate": 0.00022119303011011344,
        "gradient_norm": 0.3490849435329437,
        "train_loss": 3.0220389366149902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19431,
        "tokens": 10187440128,
        "learning_rate": 0.00022116681396916506,
        "gradient_norm": 0.355885773897171,
        "train_loss": 3.066688060760498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19432,
        "tokens": 10187964416,
        "learning_rate": 0.0002211405990532698,
        "gradient_norm": 0.35215115547180176,
        "train_loss": 3.0834085941314697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19433,
        "tokens": 10188488704,
        "learning_rate": 0.00022111438536272286,
        "gradient_norm": 0.3614806830883026,
        "train_loss": 3.0468204021453857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19434,
        "tokens": 10189012992,
        "learning_rate": 0.0002210881728978192,
        "gradient_norm": 0.3124745190143585,
        "train_loss": 2.9919731616973877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19435,
        "tokens": 10189537280,
        "learning_rate": 0.0002210619616588539,
        "gradient_norm": 0.38290566205978394,
        "train_loss": 3.0741493701934814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19436,
        "tokens": 10190061568,
        "learning_rate": 0.00022103575164612207,
        "gradient_norm": 0.3212343454360962,
        "train_loss": 3.0773723125457764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19437,
        "tokens": 10190585856,
        "learning_rate": 0.0002210095428599186,
        "gradient_norm": 0.3354993760585785,
        "train_loss": 3.080200672149658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19438,
        "tokens": 10191110144,
        "learning_rate": 0.0002209833353005387,
        "gradient_norm": 0.3394422233104706,
        "train_loss": 3.091498374938965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19439,
        "tokens": 10191634432,
        "learning_rate": 0.00022095712896827714,
        "gradient_norm": 0.3851729929447174,
        "train_loss": 3.1137921810150146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19440,
        "tokens": 10192158720,
        "learning_rate": 0.00022093092386342913,
        "gradient_norm": 0.408602237701416,
        "train_loss": 3.0737102031707764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19441,
        "tokens": 10192683008,
        "learning_rate": 0.0002209047199862894,
        "gradient_norm": 0.36966174840927124,
        "train_loss": 3.033022403717041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19442,
        "tokens": 10193207296,
        "learning_rate": 0.00022087851733715316,
        "gradient_norm": 0.36834704875946045,
        "train_loss": 3.0642662048339844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19443,
        "tokens": 10193731584,
        "learning_rate": 0.00022085231591631514,
        "gradient_norm": 0.3422478437423706,
        "train_loss": 3.0574936866760254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19444,
        "tokens": 10194255872,
        "learning_rate": 0.00022082611572407047,
        "gradient_norm": 0.4075455963611603,
        "train_loss": 3.0234997272491455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19445,
        "tokens": 10194780160,
        "learning_rate": 0.0002207999167607138,
        "gradient_norm": 0.36547067761421204,
        "train_loss": 3.0449628829956055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19446,
        "tokens": 10195304448,
        "learning_rate": 0.00022077371902654022,
        "gradient_norm": 0.39299631118774414,
        "train_loss": 3.0544514656066895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19447,
        "tokens": 10195828736,
        "learning_rate": 0.00022074752252184473,
        "gradient_norm": 0.38829633593559265,
        "train_loss": 3.075584888458252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19448,
        "tokens": 10196353024,
        "learning_rate": 0.0002207213272469219,
        "gradient_norm": 0.3757418692111969,
        "train_loss": 3.061798572540283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19449,
        "tokens": 10196877312,
        "learning_rate": 0.00022069513320206684,
        "gradient_norm": 0.3387692868709564,
        "train_loss": 3.151003360748291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19450,
        "tokens": 10197401600,
        "learning_rate": 0.0002206689403875743,
        "gradient_norm": 0.3864433765411377,
        "train_loss": 3.1638336181640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19451,
        "tokens": 10197925888,
        "learning_rate": 0.00022064274880373913,
        "gradient_norm": 0.3829962909221649,
        "train_loss": 3.0791079998016357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19452,
        "tokens": 10198450176,
        "learning_rate": 0.00022061655845085606,
        "gradient_norm": 0.3673354387283325,
        "train_loss": 3.083188533782959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19453,
        "tokens": 10198974464,
        "learning_rate": 0.00022059036932922012,
        "gradient_norm": 0.37796270847320557,
        "train_loss": 3.0354247093200684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19454,
        "tokens": 10199498752,
        "learning_rate": 0.0002205641814391258,
        "gradient_norm": 0.3679247498512268,
        "train_loss": 3.0878875255584717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19455,
        "tokens": 10200023040,
        "learning_rate": 0.00022053799478086815,
        "gradient_norm": 0.4171048402786255,
        "train_loss": 3.0942697525024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19456,
        "tokens": 10200547328,
        "learning_rate": 0.00022051180935474173,
        "gradient_norm": 0.3243867754936218,
        "train_loss": 3.04154896736145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19457,
        "tokens": 10201071616,
        "learning_rate": 0.00022048562516104137,
        "gradient_norm": 0.4136269688606262,
        "train_loss": 3.0679447650909424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19458,
        "tokens": 10201595904,
        "learning_rate": 0.0002204594422000619,
        "gradient_norm": 0.3623410165309906,
        "train_loss": 3.089317560195923,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19459,
        "tokens": 10202120192,
        "learning_rate": 0.00022043326047209785,
        "gradient_norm": 0.387938529253006,
        "train_loss": 3.0740742683410645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19460,
        "tokens": 10202644480,
        "learning_rate": 0.00022040707997744417,
        "gradient_norm": 0.3874319791793823,
        "train_loss": 3.0746774673461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19461,
        "tokens": 10203168768,
        "learning_rate": 0.0002203809007163953,
        "gradient_norm": 0.35385560989379883,
        "train_loss": 3.010624885559082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19462,
        "tokens": 10203693056,
        "learning_rate": 0.00022035472268924612,
        "gradient_norm": 0.37036797404289246,
        "train_loss": 3.0895938873291016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19463,
        "tokens": 10204217344,
        "learning_rate": 0.00022032854589629108,
        "gradient_norm": 0.3806328773498535,
        "train_loss": 3.04860782623291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19464,
        "tokens": 10204741632,
        "learning_rate": 0.00022030237033782515,
        "gradient_norm": 0.36229249835014343,
        "train_loss": 3.063425064086914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19465,
        "tokens": 10205265920,
        "learning_rate": 0.00022027619601414262,
        "gradient_norm": 0.35714831948280334,
        "train_loss": 3.0807034969329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19466,
        "tokens": 10205790208,
        "learning_rate": 0.00022025002292553833,
        "gradient_norm": 0.38159534335136414,
        "train_loss": 3.123213768005371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19467,
        "tokens": 10206314496,
        "learning_rate": 0.0002202238510723069,
        "gradient_norm": 0.3533029854297638,
        "train_loss": 3.0434367656707764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19468,
        "tokens": 10206838784,
        "learning_rate": 0.00022019768045474273,
        "gradient_norm": 0.39036792516708374,
        "train_loss": 3.046886920928955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19469,
        "tokens": 10207363072,
        "learning_rate": 0.00022017151107314072,
        "gradient_norm": 0.3622734248638153,
        "train_loss": 3.072572708129883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19470,
        "tokens": 10207887360,
        "learning_rate": 0.00022014534292779512,
        "gradient_norm": 0.3464871346950531,
        "train_loss": 3.0530381202697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19471,
        "tokens": 10208411648,
        "learning_rate": 0.0002201191760190007,
        "gradient_norm": 0.3592834770679474,
        "train_loss": 3.04176664352417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19472,
        "tokens": 10208935936,
        "learning_rate": 0.00022009301034705184,
        "gradient_norm": 0.3856600224971771,
        "train_loss": 3.0577073097229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19473,
        "tokens": 10209460224,
        "learning_rate": 0.0002200668459122433,
        "gradient_norm": 0.4112251400947571,
        "train_loss": 3.0777645111083984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19474,
        "tokens": 10209984512,
        "learning_rate": 0.00022004068271486927,
        "gradient_norm": 0.3463159501552582,
        "train_loss": 3.0450572967529297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19475,
        "tokens": 10210508800,
        "learning_rate": 0.0002200145207552245,
        "gradient_norm": 0.3557538390159607,
        "train_loss": 3.0466575622558594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19476,
        "tokens": 10211033088,
        "learning_rate": 0.00021998836003360342,
        "gradient_norm": 0.33793383836746216,
        "train_loss": 3.0549545288085938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19477,
        "tokens": 10211557376,
        "learning_rate": 0.00021996220055030047,
        "gradient_norm": 0.37257224321365356,
        "train_loss": 3.141111373901367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19478,
        "tokens": 10212081664,
        "learning_rate": 0.0002199360423056101,
        "gradient_norm": 0.3543189465999603,
        "train_loss": 3.049630880355835,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19479,
        "tokens": 10212605952,
        "learning_rate": 0.00021990988529982679,
        "gradient_norm": 0.35925108194351196,
        "train_loss": 3.084475517272949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19480,
        "tokens": 10213130240,
        "learning_rate": 0.0002198837295332449,
        "gradient_norm": 0.3468208312988281,
        "train_loss": 3.0863759517669678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19481,
        "tokens": 10213654528,
        "learning_rate": 0.000219857575006159,
        "gradient_norm": 0.3883565664291382,
        "train_loss": 3.0680179595947266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19482,
        "tokens": 10214178816,
        "learning_rate": 0.00021983142171886334,
        "gradient_norm": 0.3586418926715851,
        "train_loss": 3.120954990386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19483,
        "tokens": 10214703104,
        "learning_rate": 0.00021980526967165236,
        "gradient_norm": 0.3219946622848511,
        "train_loss": 3.1061551570892334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19484,
        "tokens": 10215227392,
        "learning_rate": 0.00021977911886482038,
        "gradient_norm": 0.3586927652359009,
        "train_loss": 3.016493797302246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19485,
        "tokens": 10215751680,
        "learning_rate": 0.00021975296929866188,
        "gradient_norm": 0.3218345046043396,
        "train_loss": 3.0487546920776367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19486,
        "tokens": 10216275968,
        "learning_rate": 0.00021972682097347107,
        "gradient_norm": 0.34417784214019775,
        "train_loss": 3.001828193664551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19487,
        "tokens": 10216800256,
        "learning_rate": 0.00021970067388954242,
        "gradient_norm": 0.3449520468711853,
        "train_loss": 3.1057982444763184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19488,
        "tokens": 10217324544,
        "learning_rate": 0.00021967452804717012,
        "gradient_norm": 0.32272782921791077,
        "train_loss": 3.096529722213745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19489,
        "tokens": 10217848832,
        "learning_rate": 0.0002196483834466486,
        "gradient_norm": 0.3335300087928772,
        "train_loss": 3.063730001449585,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19490,
        "tokens": 10218373120,
        "learning_rate": 0.00021962224008827196,
        "gradient_norm": 0.3332999348640442,
        "train_loss": 3.0980732440948486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19491,
        "tokens": 10218897408,
        "learning_rate": 0.0002195960979723347,
        "gradient_norm": 0.37481406331062317,
        "train_loss": 3.1571993827819824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19492,
        "tokens": 10219421696,
        "learning_rate": 0.00021956995709913093,
        "gradient_norm": 0.39641109108924866,
        "train_loss": 3.0998411178588867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19493,
        "tokens": 10219945984,
        "learning_rate": 0.00021954381746895502,
        "gradient_norm": 0.3702254295349121,
        "train_loss": 3.006324291229248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19494,
        "tokens": 10220470272,
        "learning_rate": 0.00021951767908210106,
        "gradient_norm": 0.36122336983680725,
        "train_loss": 3.032926559448242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19495,
        "tokens": 10220994560,
        "learning_rate": 0.00021949154193886332,
        "gradient_norm": 0.33408045768737793,
        "train_loss": 3.0581183433532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19496,
        "tokens": 10221518848,
        "learning_rate": 0.00021946540603953613,
        "gradient_norm": 0.38675668835639954,
        "train_loss": 2.993947982788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19497,
        "tokens": 10222043136,
        "learning_rate": 0.00021943927138441346,
        "gradient_norm": 0.34603744745254517,
        "train_loss": 3.0590929985046387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19498,
        "tokens": 10222567424,
        "learning_rate": 0.0002194131379737897,
        "gradient_norm": 0.3615310788154602,
        "train_loss": 3.082188606262207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19499,
        "tokens": 10223091712,
        "learning_rate": 0.00021938700580795888,
        "gradient_norm": 0.4021329879760742,
        "train_loss": 3.055152416229248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19500,
        "tokens": 10223616000,
        "learning_rate": 0.0002193608748872153,
        "gradient_norm": 0.35679537057876587,
        "train_loss": 3.089660167694092,
        "val_loss": 3.0260558128356934,
        "hellaswag_acc": 0.2834096848964691,
        "hellaswag_acc_norm": 0.2927703559398651
    },
    {
        "step": 19501,
        "tokens": 10224140288,
        "learning_rate": 0.00021933474521185282,
        "gradient_norm": 0.3396839499473572,
        "train_loss": 2.980930805206299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19502,
        "tokens": 10224664576,
        "learning_rate": 0.00021930861678216585,
        "gradient_norm": 0.34448105096817017,
        "train_loss": 3.022263526916504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19503,
        "tokens": 10225188864,
        "learning_rate": 0.0002192824895984483,
        "gradient_norm": 0.3696082830429077,
        "train_loss": 3.132962703704834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19504,
        "tokens": 10225713152,
        "learning_rate": 0.00021925636366099441,
        "gradient_norm": 0.36672544479370117,
        "train_loss": 3.071690559387207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19505,
        "tokens": 10226237440,
        "learning_rate": 0.0002192302389700981,
        "gradient_norm": 0.36241427063941956,
        "train_loss": 3.0454416275024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19506,
        "tokens": 10226761728,
        "learning_rate": 0.0002192041155260535,
        "gradient_norm": 0.34112268686294556,
        "train_loss": 3.031606674194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19507,
        "tokens": 10227286016,
        "learning_rate": 0.00021917799332915486,
        "gradient_norm": 0.37084320187568665,
        "train_loss": 3.031007766723633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19508,
        "tokens": 10227810304,
        "learning_rate": 0.00021915187237969596,
        "gradient_norm": 0.3325514495372772,
        "train_loss": 3.029937267303467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19509,
        "tokens": 10228334592,
        "learning_rate": 0.00021912575267797095,
        "gradient_norm": 0.37749049067497253,
        "train_loss": 3.0301389694213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19510,
        "tokens": 10228858880,
        "learning_rate": 0.0002190996342242737,
        "gradient_norm": 0.37473171949386597,
        "train_loss": 3.130474090576172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19511,
        "tokens": 10229383168,
        "learning_rate": 0.00021907351701889845,
        "gradient_norm": 0.40166372060775757,
        "train_loss": 3.0941147804260254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19512,
        "tokens": 10229907456,
        "learning_rate": 0.00021904740106213892,
        "gradient_norm": 0.3371489942073822,
        "train_loss": 3.0868749618530273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19513,
        "tokens": 10230431744,
        "learning_rate": 0.0002190212863542893,
        "gradient_norm": 0.4199845790863037,
        "train_loss": 3.105917453765869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19514,
        "tokens": 10230956032,
        "learning_rate": 0.00021899517289564334,
        "gradient_norm": 0.3691868782043457,
        "train_loss": 3.056077003479004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19515,
        "tokens": 10231480320,
        "learning_rate": 0.00021896906068649504,
        "gradient_norm": 0.37424859404563904,
        "train_loss": 3.0694024562835693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19516,
        "tokens": 10232004608,
        "learning_rate": 0.0002189429497271385,
        "gradient_norm": 0.4176952540874481,
        "train_loss": 3.0247175693511963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19517,
        "tokens": 10232528896,
        "learning_rate": 0.00021891684001786743,
        "gradient_norm": 0.3766559958457947,
        "train_loss": 3.010911464691162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19518,
        "tokens": 10233053184,
        "learning_rate": 0.00021889073155897587,
        "gradient_norm": 0.32781827449798584,
        "train_loss": 3.0538573265075684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19519,
        "tokens": 10233577472,
        "learning_rate": 0.00021886462435075752,
        "gradient_norm": 0.34903478622436523,
        "train_loss": 3.0617189407348633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19520,
        "tokens": 10234101760,
        "learning_rate": 0.00021883851839350646,
        "gradient_norm": 0.3768727779388428,
        "train_loss": 3.067967414855957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19521,
        "tokens": 10234626048,
        "learning_rate": 0.00021881241368751632,
        "gradient_norm": 0.32988497614860535,
        "train_loss": 3.0841917991638184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19522,
        "tokens": 10235150336,
        "learning_rate": 0.00021878631023308122,
        "gradient_norm": 0.44233348965644836,
        "train_loss": 3.085935592651367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19523,
        "tokens": 10235674624,
        "learning_rate": 0.00021876020803049466,
        "gradient_norm": 0.4226472079753876,
        "train_loss": 3.0517702102661133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19524,
        "tokens": 10236198912,
        "learning_rate": 0.00021873410708005077,
        "gradient_norm": 0.34425342082977295,
        "train_loss": 3.0454750061035156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19525,
        "tokens": 10236723200,
        "learning_rate": 0.0002187080073820431,
        "gradient_norm": 0.37378811836242676,
        "train_loss": 3.169437885284424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19526,
        "tokens": 10237247488,
        "learning_rate": 0.0002186819089367655,
        "gradient_norm": 0.3801722526550293,
        "train_loss": 3.104858160018921,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19527,
        "tokens": 10237771776,
        "learning_rate": 0.0002186558117445119,
        "gradient_norm": 0.39092791080474854,
        "train_loss": 3.094221353530884,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19528,
        "tokens": 10238296064,
        "learning_rate": 0.00021862971580557586,
        "gradient_norm": 0.42566466331481934,
        "train_loss": 3.079850435256958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19529,
        "tokens": 10238820352,
        "learning_rate": 0.00021860362112025125,
        "gradient_norm": 0.38846975564956665,
        "train_loss": 3.027315139770508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19530,
        "tokens": 10239344640,
        "learning_rate": 0.00021857752768883167,
        "gradient_norm": 0.3565308451652527,
        "train_loss": 3.0761771202087402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19531,
        "tokens": 10239868928,
        "learning_rate": 0.000218551435511611,
        "gradient_norm": 0.3754156529903412,
        "train_loss": 3.053281784057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19532,
        "tokens": 10240393216,
        "learning_rate": 0.00021852534458888275,
        "gradient_norm": 0.3779430389404297,
        "train_loss": 3.087068557739258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19533,
        "tokens": 10240917504,
        "learning_rate": 0.0002184992549209408,
        "gradient_norm": 0.39331305027008057,
        "train_loss": 3.065354347229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19534,
        "tokens": 10241441792,
        "learning_rate": 0.0002184731665080786,
        "gradient_norm": 0.34960705041885376,
        "train_loss": 3.083303213119507,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19535,
        "tokens": 10241966080,
        "learning_rate": 0.00021844707935059001,
        "gradient_norm": 0.3913128972053528,
        "train_loss": 3.082289218902588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19536,
        "tokens": 10242490368,
        "learning_rate": 0.00021842099344876863,
        "gradient_norm": 0.3978990316390991,
        "train_loss": 3.020972490310669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19537,
        "tokens": 10243014656,
        "learning_rate": 0.000218394908802908,
        "gradient_norm": 0.36023208498954773,
        "train_loss": 3.078554630279541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19538,
        "tokens": 10243538944,
        "learning_rate": 0.00021836882541330182,
        "gradient_norm": 0.3758627474308014,
        "train_loss": 3.0363104343414307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19539,
        "tokens": 10244063232,
        "learning_rate": 0.00021834274328024365,
        "gradient_norm": 0.36481648683547974,
        "train_loss": 3.0554938316345215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19540,
        "tokens": 10244587520,
        "learning_rate": 0.00021831666240402708,
        "gradient_norm": 0.3684571087360382,
        "train_loss": 3.057589292526245,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19541,
        "tokens": 10245111808,
        "learning_rate": 0.00021829058278494573,
        "gradient_norm": 0.37489432096481323,
        "train_loss": 3.094670295715332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19542,
        "tokens": 10245636096,
        "learning_rate": 0.0002182645044232931,
        "gradient_norm": 0.36490657925605774,
        "train_loss": 3.0193793773651123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19543,
        "tokens": 10246160384,
        "learning_rate": 0.00021823842731936275,
        "gradient_norm": 0.3807842433452606,
        "train_loss": 3.075164794921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19544,
        "tokens": 10246684672,
        "learning_rate": 0.0002182123514734482,
        "gradient_norm": 0.3373214602470398,
        "train_loss": 3.0288617610931396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19545,
        "tokens": 10247208960,
        "learning_rate": 0.000218186276885843,
        "gradient_norm": 0.44598495960235596,
        "train_loss": 3.0516576766967773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19546,
        "tokens": 10247733248,
        "learning_rate": 0.00021816020355684053,
        "gradient_norm": 0.4230234920978546,
        "train_loss": 3.092735767364502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19547,
        "tokens": 10248257536,
        "learning_rate": 0.0002181341314867346,
        "gradient_norm": 0.3880116641521454,
        "train_loss": 3.0236263275146484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19548,
        "tokens": 10248781824,
        "learning_rate": 0.00021810806067581824,
        "gradient_norm": 0.40709051489830017,
        "train_loss": 3.02823805809021,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19549,
        "tokens": 10249306112,
        "learning_rate": 0.0002180819911243853,
        "gradient_norm": 0.3460208773612976,
        "train_loss": 3.064133882522583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19550,
        "tokens": 10249830400,
        "learning_rate": 0.00021805592283272895,
        "gradient_norm": 0.364367812871933,
        "train_loss": 3.074902057647705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19551,
        "tokens": 10250354688,
        "learning_rate": 0.0002180298558011428,
        "gradient_norm": 0.3707810640335083,
        "train_loss": 3.043980598449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19552,
        "tokens": 10250878976,
        "learning_rate": 0.00021800379002992018,
        "gradient_norm": 0.38287603855133057,
        "train_loss": 3.0629005432128906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19553,
        "tokens": 10251403264,
        "learning_rate": 0.00021797772551935453,
        "gradient_norm": 0.3484443128108978,
        "train_loss": 3.061636209487915,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19554,
        "tokens": 10251927552,
        "learning_rate": 0.00021795166226973913,
        "gradient_norm": 0.4130265712738037,
        "train_loss": 3.0897634029388428,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19555,
        "tokens": 10252451840,
        "learning_rate": 0.00021792560028136744,
        "gradient_norm": 0.3532051146030426,
        "train_loss": 3.057915687561035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19556,
        "tokens": 10252976128,
        "learning_rate": 0.00021789953955453296,
        "gradient_norm": 0.3438895046710968,
        "train_loss": 3.0013175010681152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19557,
        "tokens": 10253500416,
        "learning_rate": 0.00021787348008952878,
        "gradient_norm": 0.34023618698120117,
        "train_loss": 3.058037757873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19558,
        "tokens": 10254024704,
        "learning_rate": 0.00021784742188664846,
        "gradient_norm": 0.3704361617565155,
        "train_loss": 3.09237003326416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19559,
        "tokens": 10254548992,
        "learning_rate": 0.0002178213649461851,
        "gradient_norm": 0.39576658606529236,
        "train_loss": 3.005368709564209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19560,
        "tokens": 10255073280,
        "learning_rate": 0.0002177953092684322,
        "gradient_norm": 0.37691783905029297,
        "train_loss": 3.059696674346924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19561,
        "tokens": 10255597568,
        "learning_rate": 0.00021776925485368287,
        "gradient_norm": 0.3812999725341797,
        "train_loss": 3.0852527618408203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19562,
        "tokens": 10256121856,
        "learning_rate": 0.00021774320170223058,
        "gradient_norm": 0.3500722646713257,
        "train_loss": 3.027872085571289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19563,
        "tokens": 10256646144,
        "learning_rate": 0.00021771714981436838,
        "gradient_norm": 0.3601602017879486,
        "train_loss": 3.0481438636779785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19564,
        "tokens": 10257170432,
        "learning_rate": 0.00021769109919038973,
        "gradient_norm": 0.39287862181663513,
        "train_loss": 3.0815987586975098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19565,
        "tokens": 10257694720,
        "learning_rate": 0.00021766504983058765,
        "gradient_norm": 0.3575427830219269,
        "train_loss": 3.079003095626831,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19566,
        "tokens": 10258219008,
        "learning_rate": 0.0002176390017352555,
        "gradient_norm": 0.37877726554870605,
        "train_loss": 3.0346055030822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19567,
        "tokens": 10258743296,
        "learning_rate": 0.00021761295490468652,
        "gradient_norm": 0.37963002920150757,
        "train_loss": 3.080012798309326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19568,
        "tokens": 10259267584,
        "learning_rate": 0.0002175869093391737,
        "gradient_norm": 0.34868699312210083,
        "train_loss": 3.0674185752868652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19569,
        "tokens": 10259791872,
        "learning_rate": 0.0002175608650390105,
        "gradient_norm": 0.38477736711502075,
        "train_loss": 3.064815044403076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19570,
        "tokens": 10260316160,
        "learning_rate": 0.00021753482200448975,
        "gradient_norm": 0.36055195331573486,
        "train_loss": 3.115516424179077,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19571,
        "tokens": 10260840448,
        "learning_rate": 0.00021750878023590493,
        "gradient_norm": 0.3708362281322479,
        "train_loss": 3.0367698669433594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19572,
        "tokens": 10261364736,
        "learning_rate": 0.0002174827397335489,
        "gradient_norm": 0.4293825924396515,
        "train_loss": 3.055227756500244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19573,
        "tokens": 10261889024,
        "learning_rate": 0.000217456700497715,
        "gradient_norm": 0.3688204288482666,
        "train_loss": 3.0489706993103027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19574,
        "tokens": 10262413312,
        "learning_rate": 0.00021743066252869606,
        "gradient_norm": 0.3667786717414856,
        "train_loss": 3.079418182373047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19575,
        "tokens": 10262937600,
        "learning_rate": 0.0002174046258267854,
        "gradient_norm": 0.357185959815979,
        "train_loss": 3.057011604309082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19576,
        "tokens": 10263461888,
        "learning_rate": 0.00021737859039227612,
        "gradient_norm": 0.37133508920669556,
        "train_loss": 3.087686061859131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19577,
        "tokens": 10263986176,
        "learning_rate": 0.00021735255622546106,
        "gradient_norm": 0.3401853144168854,
        "train_loss": 3.0795979499816895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19578,
        "tokens": 10264510464,
        "learning_rate": 0.0002173265233266335,
        "gradient_norm": 0.3638274371623993,
        "train_loss": 3.0342607498168945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19579,
        "tokens": 10265034752,
        "learning_rate": 0.0002173004916960863,
        "gradient_norm": 0.3694882392883301,
        "train_loss": 3.0802016258239746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19580,
        "tokens": 10265559040,
        "learning_rate": 0.00021727446133411262,
        "gradient_norm": 0.3217816948890686,
        "train_loss": 3.0562944412231445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19581,
        "tokens": 10266083328,
        "learning_rate": 0.00021724843224100535,
        "gradient_norm": 0.41091907024383545,
        "train_loss": 3.0756309032440186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19582,
        "tokens": 10266607616,
        "learning_rate": 0.00021722240441705756,
        "gradient_norm": 0.369131475687027,
        "train_loss": 3.069985866546631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19583,
        "tokens": 10267131904,
        "learning_rate": 0.0002171963778625621,
        "gradient_norm": 0.3874494731426239,
        "train_loss": 3.059983730316162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19584,
        "tokens": 10267656192,
        "learning_rate": 0.00021717035257781214,
        "gradient_norm": 0.3405357003211975,
        "train_loss": 3.061007022857666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19585,
        "tokens": 10268180480,
        "learning_rate": 0.0002171443285631004,
        "gradient_norm": 0.33528241515159607,
        "train_loss": 3.0531232357025146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19586,
        "tokens": 10268704768,
        "learning_rate": 0.00021711830581871993,
        "gradient_norm": 0.3431144058704376,
        "train_loss": 3.0739102363586426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19587,
        "tokens": 10269229056,
        "learning_rate": 0.00021709228434496373,
        "gradient_norm": 0.3628726303577423,
        "train_loss": 3.0453672409057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19588,
        "tokens": 10269753344,
        "learning_rate": 0.00021706626414212454,
        "gradient_norm": 0.3748117685317993,
        "train_loss": 3.06282901763916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19589,
        "tokens": 10270277632,
        "learning_rate": 0.00021704024521049538,
        "gradient_norm": 0.34367212653160095,
        "train_loss": 3.017190456390381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19590,
        "tokens": 10270801920,
        "learning_rate": 0.00021701422755036898,
        "gradient_norm": 0.3671259582042694,
        "train_loss": 3.111764907836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19591,
        "tokens": 10271326208,
        "learning_rate": 0.0002169882111620384,
        "gradient_norm": 0.3798155188560486,
        "train_loss": 3.0617332458496094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19592,
        "tokens": 10271850496,
        "learning_rate": 0.00021696219604579628,
        "gradient_norm": 0.3347613215446472,
        "train_loss": 3.103982925415039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19593,
        "tokens": 10272374784,
        "learning_rate": 0.0002169361822019356,
        "gradient_norm": 0.3517346680164337,
        "train_loss": 3.1107070446014404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19594,
        "tokens": 10272899072,
        "learning_rate": 0.00021691016963074907,
        "gradient_norm": 0.33309102058410645,
        "train_loss": 3.019473075866699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19595,
        "tokens": 10273423360,
        "learning_rate": 0.00021688415833252957,
        "gradient_norm": 0.3187512159347534,
        "train_loss": 3.0609242916107178,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19596,
        "tokens": 10273947648,
        "learning_rate": 0.00021685814830756995,
        "gradient_norm": 0.33099377155303955,
        "train_loss": 3.1111531257629395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19597,
        "tokens": 10274471936,
        "learning_rate": 0.00021683213955616282,
        "gradient_norm": 0.37071409821510315,
        "train_loss": 3.0324807167053223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19598,
        "tokens": 10274996224,
        "learning_rate": 0.0002168061320786011,
        "gradient_norm": 0.3550885319709778,
        "train_loss": 3.012803077697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19599,
        "tokens": 10275520512,
        "learning_rate": 0.00021678012587517736,
        "gradient_norm": 0.33241555094718933,
        "train_loss": 3.1065573692321777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19600,
        "tokens": 10276044800,
        "learning_rate": 0.00021675412094618456,
        "gradient_norm": 0.3593306839466095,
        "train_loss": 3.0509438514709473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19601,
        "tokens": 10276569088,
        "learning_rate": 0.00021672811729191518,
        "gradient_norm": 0.3575516939163208,
        "train_loss": 3.0445914268493652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19602,
        "tokens": 10277093376,
        "learning_rate": 0.00021670211491266214,
        "gradient_norm": 0.3352676331996918,
        "train_loss": 3.0937085151672363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19603,
        "tokens": 10277617664,
        "learning_rate": 0.00021667611380871794,
        "gradient_norm": 0.35677069425582886,
        "train_loss": 3.0724809169769287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19604,
        "tokens": 10278141952,
        "learning_rate": 0.00021665011398037538,
        "gradient_norm": 0.34162434935569763,
        "train_loss": 3.045198440551758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19605,
        "tokens": 10278666240,
        "learning_rate": 0.00021662411542792704,
        "gradient_norm": 0.37134745717048645,
        "train_loss": 3.0452213287353516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19606,
        "tokens": 10279190528,
        "learning_rate": 0.00021659811815166562,
        "gradient_norm": 0.3686831295490265,
        "train_loss": 3.13016676902771,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19607,
        "tokens": 10279714816,
        "learning_rate": 0.0002165721221518838,
        "gradient_norm": 0.42495670914649963,
        "train_loss": 3.075579881668091,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19608,
        "tokens": 10280239104,
        "learning_rate": 0.00021654612742887406,
        "gradient_norm": 0.37279027700424194,
        "train_loss": 3.0585360527038574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19609,
        "tokens": 10280763392,
        "learning_rate": 0.00021652013398292918,
        "gradient_norm": 0.46551820635795593,
        "train_loss": 3.0915257930755615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19610,
        "tokens": 10281287680,
        "learning_rate": 0.00021649414181434154,
        "gradient_norm": 0.38341769576072693,
        "train_loss": 3.0658047199249268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19611,
        "tokens": 10281811968,
        "learning_rate": 0.00021646815092340394,
        "gradient_norm": 0.3885166347026825,
        "train_loss": 3.0614259243011475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19612,
        "tokens": 10282336256,
        "learning_rate": 0.00021644216131040867,
        "gradient_norm": 0.3686254322528839,
        "train_loss": 3.1759819984436035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19613,
        "tokens": 10282860544,
        "learning_rate": 0.00021641617297564857,
        "gradient_norm": 0.41464415192604065,
        "train_loss": 3.030938148498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19614,
        "tokens": 10283384832,
        "learning_rate": 0.0002163901859194159,
        "gradient_norm": 0.3968750238418579,
        "train_loss": 3.049302816390991,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19615,
        "tokens": 10283909120,
        "learning_rate": 0.00021636420014200337,
        "gradient_norm": 0.38402867317199707,
        "train_loss": 3.0917110443115234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19616,
        "tokens": 10284433408,
        "learning_rate": 0.00021633821564370347,
        "gradient_norm": 0.35514914989471436,
        "train_loss": 3.076427459716797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19617,
        "tokens": 10284957696,
        "learning_rate": 0.0002163122324248085,
        "gradient_norm": 0.36838993430137634,
        "train_loss": 3.0316314697265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19618,
        "tokens": 10285481984,
        "learning_rate": 0.00021628625048561125,
        "gradient_norm": 0.3563048243522644,
        "train_loss": 3.0684080123901367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19619,
        "tokens": 10286006272,
        "learning_rate": 0.00021626026982640383,
        "gradient_norm": 0.47616976499557495,
        "train_loss": 3.140069007873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19620,
        "tokens": 10286530560,
        "learning_rate": 0.000216234290447479,
        "gradient_norm": 0.3825839161872864,
        "train_loss": 3.0202770233154297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19621,
        "tokens": 10287054848,
        "learning_rate": 0.00021620831234912892,
        "gradient_norm": 0.4529602825641632,
        "train_loss": 3.12764835357666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19622,
        "tokens": 10287579136,
        "learning_rate": 0.00021618233553164626,
        "gradient_norm": 0.47918373346328735,
        "train_loss": 3.032815933227539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19623,
        "tokens": 10288103424,
        "learning_rate": 0.00021615635999532314,
        "gradient_norm": 0.4013892114162445,
        "train_loss": 3.0714309215545654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19624,
        "tokens": 10288627712,
        "learning_rate": 0.00021613038574045225,
        "gradient_norm": 0.45343294739723206,
        "train_loss": 3.1140482425689697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19625,
        "tokens": 10289152000,
        "learning_rate": 0.00021610441276732567,
        "gradient_norm": 0.46570807695388794,
        "train_loss": 3.048394203186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19626,
        "tokens": 10289676288,
        "learning_rate": 0.00021607844107623595,
        "gradient_norm": 0.48496612906455994,
        "train_loss": 3.1600351333618164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19627,
        "tokens": 10290200576,
        "learning_rate": 0.00021605247066747545,
        "gradient_norm": 0.4262526035308838,
        "train_loss": 3.0620577335357666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19628,
        "tokens": 10290724864,
        "learning_rate": 0.00021602650154133632,
        "gradient_norm": 0.4053066670894623,
        "train_loss": 3.1465673446655273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19629,
        "tokens": 10291249152,
        "learning_rate": 0.0002160005336981111,
        "gradient_norm": 0.44431072473526,
        "train_loss": 3.0445809364318848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19630,
        "tokens": 10291773440,
        "learning_rate": 0.00021597456713809185,
        "gradient_norm": 0.3787325322628021,
        "train_loss": 3.0864555835723877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19631,
        "tokens": 10292297728,
        "learning_rate": 0.00021594860186157112,
        "gradient_norm": 0.4273996651172638,
        "train_loss": 3.1150736808776855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19632,
        "tokens": 10292822016,
        "learning_rate": 0.00021592263786884096,
        "gradient_norm": 0.4268328547477722,
        "train_loss": 3.0860440731048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19633,
        "tokens": 10293346304,
        "learning_rate": 0.00021589667516019374,
        "gradient_norm": 0.5049390196800232,
        "train_loss": 3.1735308170318604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19634,
        "tokens": 10293870592,
        "learning_rate": 0.00021587071373592163,
        "gradient_norm": 0.42456474900245667,
        "train_loss": 3.0248825550079346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19635,
        "tokens": 10294394880,
        "learning_rate": 0.00021584475359631692,
        "gradient_norm": 0.4253670573234558,
        "train_loss": 3.1023082733154297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19636,
        "tokens": 10294919168,
        "learning_rate": 0.00021581879474167186,
        "gradient_norm": 0.4192952513694763,
        "train_loss": 3.053795576095581,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19637,
        "tokens": 10295443456,
        "learning_rate": 0.00021579283717227852,
        "gradient_norm": 0.3896031379699707,
        "train_loss": 3.052062511444092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19638,
        "tokens": 10295967744,
        "learning_rate": 0.00021576688088842925,
        "gradient_norm": 0.383253276348114,
        "train_loss": 3.0765891075134277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19639,
        "tokens": 10296492032,
        "learning_rate": 0.00021574092589041603,
        "gradient_norm": 0.3698490858078003,
        "train_loss": 3.074000358581543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19640,
        "tokens": 10297016320,
        "learning_rate": 0.00021571497217853122,
        "gradient_norm": 0.3588266372680664,
        "train_loss": 3.1105611324310303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19641,
        "tokens": 10297540608,
        "learning_rate": 0.00021568901975306675,
        "gradient_norm": 0.38798338174819946,
        "train_loss": 3.0279502868652344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19642,
        "tokens": 10298064896,
        "learning_rate": 0.000215663068614315,
        "gradient_norm": 0.3390350043773651,
        "train_loss": 3.0581295490264893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19643,
        "tokens": 10298589184,
        "learning_rate": 0.00021563711876256778,
        "gradient_norm": 0.3679232895374298,
        "train_loss": 3.094376564025879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19644,
        "tokens": 10299113472,
        "learning_rate": 0.00021561117019811747,
        "gradient_norm": 0.3899324834346771,
        "train_loss": 3.1152312755584717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19645,
        "tokens": 10299637760,
        "learning_rate": 0.00021558522292125593,
        "gradient_norm": 0.3551417589187622,
        "train_loss": 3.010746955871582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19646,
        "tokens": 10300162048,
        "learning_rate": 0.0002155592769322753,
        "gradient_norm": 0.39174601435661316,
        "train_loss": 3.1094930171966553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19647,
        "tokens": 10300686336,
        "learning_rate": 0.00021553333223146783,
        "gradient_norm": 0.3626243770122528,
        "train_loss": 2.998548746109009,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19648,
        "tokens": 10301210624,
        "learning_rate": 0.00021550738881912523,
        "gradient_norm": 0.3499249517917633,
        "train_loss": 3.0600881576538086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19649,
        "tokens": 10301734912,
        "learning_rate": 0.0002154814466955398,
        "gradient_norm": 0.3343212902545929,
        "train_loss": 3.0444798469543457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19650,
        "tokens": 10302259200,
        "learning_rate": 0.00021545550586100334,
        "gradient_norm": 0.35289305448532104,
        "train_loss": 3.079627752304077,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19651,
        "tokens": 10302783488,
        "learning_rate": 0.00021542956631580805,
        "gradient_norm": 0.34435155987739563,
        "train_loss": 3.0639028549194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19652,
        "tokens": 10303307776,
        "learning_rate": 0.00021540362806024574,
        "gradient_norm": 0.33663907647132874,
        "train_loss": 3.0493979454040527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19653,
        "tokens": 10303832064,
        "learning_rate": 0.0002153776910946085,
        "gradient_norm": 0.3578505516052246,
        "train_loss": 3.089735984802246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19654,
        "tokens": 10304356352,
        "learning_rate": 0.00021535175541918816,
        "gradient_norm": 0.3546982407569885,
        "train_loss": 3.0267112255096436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19655,
        "tokens": 10304880640,
        "learning_rate": 0.0002153258210342767,
        "gradient_norm": 0.345643013715744,
        "train_loss": 3.057732105255127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19656,
        "tokens": 10305404928,
        "learning_rate": 0.00021529988794016615,
        "gradient_norm": 0.335335910320282,
        "train_loss": 3.0772223472595215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19657,
        "tokens": 10305929216,
        "learning_rate": 0.00021527395613714828,
        "gradient_norm": 0.33782535791397095,
        "train_loss": 3.0191874504089355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19658,
        "tokens": 10306453504,
        "learning_rate": 0.00021524802562551513,
        "gradient_norm": 0.3167567849159241,
        "train_loss": 3.018571615219116,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19659,
        "tokens": 10306977792,
        "learning_rate": 0.0002152220964055584,
        "gradient_norm": 0.3121873140335083,
        "train_loss": 3.080693483352661,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19660,
        "tokens": 10307502080,
        "learning_rate": 0.00021519616847757013,
        "gradient_norm": 0.35862094163894653,
        "train_loss": 3.040764093399048,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19661,
        "tokens": 10308026368,
        "learning_rate": 0.00021517024184184198,
        "gradient_norm": 0.3072669208049774,
        "train_loss": 3.043246269226074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19662,
        "tokens": 10308550656,
        "learning_rate": 0.00021514431649866605,
        "gradient_norm": 0.38648101687431335,
        "train_loss": 3.1887834072113037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19663,
        "tokens": 10309074944,
        "learning_rate": 0.00021511839244833385,
        "gradient_norm": 0.3723226487636566,
        "train_loss": 3.068331241607666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19664,
        "tokens": 10309599232,
        "learning_rate": 0.00021509246969113747,
        "gradient_norm": 0.43628737330436707,
        "train_loss": 3.0474209785461426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19665,
        "tokens": 10310123520,
        "learning_rate": 0.0002150665482273685,
        "gradient_norm": 0.3537112772464752,
        "train_loss": 3.029125213623047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19666,
        "tokens": 10310647808,
        "learning_rate": 0.00021504062805731888,
        "gradient_norm": 0.36065149307250977,
        "train_loss": 3.035222053527832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19667,
        "tokens": 10311172096,
        "learning_rate": 0.00021501470918128016,
        "gradient_norm": 0.3442822992801666,
        "train_loss": 3.053131341934204,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19668,
        "tokens": 10311696384,
        "learning_rate": 0.00021498879159954437,
        "gradient_norm": 0.33495691418647766,
        "train_loss": 3.0817699432373047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19669,
        "tokens": 10312220672,
        "learning_rate": 0.00021496287531240298,
        "gradient_norm": 0.39206787943840027,
        "train_loss": 3.033137083053589,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19670,
        "tokens": 10312744960,
        "learning_rate": 0.00021493696032014794,
        "gradient_norm": 0.3103586435317993,
        "train_loss": 3.0415639877319336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19671,
        "tokens": 10313269248,
        "learning_rate": 0.00021491104662307072,
        "gradient_norm": 0.3665805160999298,
        "train_loss": 3.0321662425994873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19672,
        "tokens": 10313793536,
        "learning_rate": 0.00021488513422146326,
        "gradient_norm": 0.32017719745635986,
        "train_loss": 3.0066418647766113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19673,
        "tokens": 10314317824,
        "learning_rate": 0.000214859223115617,
        "gradient_norm": 0.3773067891597748,
        "train_loss": 3.0736680030822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19674,
        "tokens": 10314842112,
        "learning_rate": 0.00021483331330582377,
        "gradient_norm": 0.34915193915367126,
        "train_loss": 3.061899185180664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19675,
        "tokens": 10315366400,
        "learning_rate": 0.0002148074047923751,
        "gradient_norm": 0.36388084292411804,
        "train_loss": 3.0254855155944824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19676,
        "tokens": 10315890688,
        "learning_rate": 0.00021478149757556275,
        "gradient_norm": 0.34845519065856934,
        "train_loss": 3.033600330352783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19677,
        "tokens": 10316414976,
        "learning_rate": 0.00021475559165567819,
        "gradient_norm": 0.35447660088539124,
        "train_loss": 3.065264940261841,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19678,
        "tokens": 10316939264,
        "learning_rate": 0.00021472968703301323,
        "gradient_norm": 0.3634510040283203,
        "train_loss": 3.077674150466919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19679,
        "tokens": 10317463552,
        "learning_rate": 0.00021470378370785917,
        "gradient_norm": 0.3453119993209839,
        "train_loss": 3.061183452606201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19680,
        "tokens": 10317987840,
        "learning_rate": 0.00021467788168050788,
        "gradient_norm": 0.43188679218292236,
        "train_loss": 3.176791191101074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19681,
        "tokens": 10318512128,
        "learning_rate": 0.00021465198095125068,
        "gradient_norm": 0.39162999391555786,
        "train_loss": 3.07041597366333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19682,
        "tokens": 10319036416,
        "learning_rate": 0.0002146260815203793,
        "gradient_norm": 0.340625137090683,
        "train_loss": 3.062671184539795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19683,
        "tokens": 10319560704,
        "learning_rate": 0.0002146001833881851,
        "gradient_norm": 0.3457881510257721,
        "train_loss": 3.0848886966705322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19684,
        "tokens": 10320084992,
        "learning_rate": 0.0002145742865549598,
        "gradient_norm": 0.3657052516937256,
        "train_loss": 3.0268659591674805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19685,
        "tokens": 10320609280,
        "learning_rate": 0.00021454839102099467,
        "gradient_norm": 0.3224833607673645,
        "train_loss": 2.975325584411621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19686,
        "tokens": 10321133568,
        "learning_rate": 0.0002145224967865813,
        "gradient_norm": 0.379269540309906,
        "train_loss": 3.0491786003112793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19687,
        "tokens": 10321657856,
        "learning_rate": 0.00021449660385201134,
        "gradient_norm": 0.3281981945037842,
        "train_loss": 3.039280891418457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19688,
        "tokens": 10322182144,
        "learning_rate": 0.00021447071221757593,
        "gradient_norm": 0.36216750741004944,
        "train_loss": 3.0725996494293213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19689,
        "tokens": 10322706432,
        "learning_rate": 0.0002144448218835668,
        "gradient_norm": 0.35040736198425293,
        "train_loss": 3.1513752937316895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19690,
        "tokens": 10323230720,
        "learning_rate": 0.0002144189328502751,
        "gradient_norm": 0.3909429907798767,
        "train_loss": 3.1213016510009766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19691,
        "tokens": 10323755008,
        "learning_rate": 0.0002143930451179925,
        "gradient_norm": 0.3400033116340637,
        "train_loss": 3.0575459003448486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19692,
        "tokens": 10324279296,
        "learning_rate": 0.00021436715868701018,
        "gradient_norm": 0.3845345377922058,
        "train_loss": 3.063542604446411,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19693,
        "tokens": 10324803584,
        "learning_rate": 0.00021434127355761975,
        "gradient_norm": 0.33265164494514465,
        "train_loss": 3.0596399307250977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19694,
        "tokens": 10325327872,
        "learning_rate": 0.00021431538973011236,
        "gradient_norm": 0.34846368432044983,
        "train_loss": 3.055482864379883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19695,
        "tokens": 10325852160,
        "learning_rate": 0.00021428950720477942,
        "gradient_norm": 0.3489623963832855,
        "train_loss": 3.0877459049224854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19696,
        "tokens": 10326376448,
        "learning_rate": 0.00021426362598191246,
        "gradient_norm": 0.33349886536598206,
        "train_loss": 3.0783939361572266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19697,
        "tokens": 10326900736,
        "learning_rate": 0.00021423774606180252,
        "gradient_norm": 0.33939313888549805,
        "train_loss": 3.0535364151000977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19698,
        "tokens": 10327425024,
        "learning_rate": 0.00021421186744474119,
        "gradient_norm": 0.3792433440685272,
        "train_loss": 3.0855963230133057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19699,
        "tokens": 10327949312,
        "learning_rate": 0.0002141859901310195,
        "gradient_norm": 0.38676759600639343,
        "train_loss": 3.1142196655273438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19700,
        "tokens": 10328473600,
        "learning_rate": 0.00021416011412092896,
        "gradient_norm": 0.38726502656936646,
        "train_loss": 3.0887832641601562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19701,
        "tokens": 10328997888,
        "learning_rate": 0.00021413423941476066,
        "gradient_norm": 0.36179274320602417,
        "train_loss": 3.0500102043151855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19702,
        "tokens": 10329522176,
        "learning_rate": 0.00021410836601280596,
        "gradient_norm": 0.373592734336853,
        "train_loss": 3.0356860160827637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19703,
        "tokens": 10330046464,
        "learning_rate": 0.00021408249391535603,
        "gradient_norm": 0.3639802634716034,
        "train_loss": 3.0007572174072266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19704,
        "tokens": 10330570752,
        "learning_rate": 0.0002140566231227022,
        "gradient_norm": 0.3834437131881714,
        "train_loss": 3.069096803665161,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19705,
        "tokens": 10331095040,
        "learning_rate": 0.00021403075363513553,
        "gradient_norm": 0.38449642062187195,
        "train_loss": 3.0803918838500977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19706,
        "tokens": 10331619328,
        "learning_rate": 0.00021400488545294724,
        "gradient_norm": 0.331738144159317,
        "train_loss": 3.0668206214904785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19707,
        "tokens": 10332143616,
        "learning_rate": 0.0002139790185764287,
        "gradient_norm": 0.3315257132053375,
        "train_loss": 3.07655668258667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19708,
        "tokens": 10332667904,
        "learning_rate": 0.0002139531530058708,
        "gradient_norm": 0.3288407623767853,
        "train_loss": 3.1114821434020996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19709,
        "tokens": 10333192192,
        "learning_rate": 0.00021392728874156493,
        "gradient_norm": 0.33972179889678955,
        "train_loss": 3.033247947692871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19710,
        "tokens": 10333716480,
        "learning_rate": 0.000213901425783802,
        "gradient_norm": 0.3389926552772522,
        "train_loss": 3.1028265953063965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19711,
        "tokens": 10334240768,
        "learning_rate": 0.00021387556413287334,
        "gradient_norm": 0.3386576771736145,
        "train_loss": 3.035341262817383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19712,
        "tokens": 10334765056,
        "learning_rate": 0.0002138497037890699,
        "gradient_norm": 0.35944563150405884,
        "train_loss": 3.066091537475586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19713,
        "tokens": 10335289344,
        "learning_rate": 0.00021382384475268293,
        "gradient_norm": 0.3688124716281891,
        "train_loss": 3.024099349975586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19714,
        "tokens": 10335813632,
        "learning_rate": 0.00021379798702400325,
        "gradient_norm": 0.33391866087913513,
        "train_loss": 3.0343031883239746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19715,
        "tokens": 10336337920,
        "learning_rate": 0.00021377213060332212,
        "gradient_norm": 0.4062696695327759,
        "train_loss": 3.030059814453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19716,
        "tokens": 10336862208,
        "learning_rate": 0.00021374627549093061,
        "gradient_norm": 0.39190730452537537,
        "train_loss": 3.058255910873413,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19717,
        "tokens": 10337386496,
        "learning_rate": 0.0002137204216871196,
        "gradient_norm": 0.37445464730262756,
        "train_loss": 3.0395772457122803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19718,
        "tokens": 10337910784,
        "learning_rate": 0.0002136945691921803,
        "gradient_norm": 0.3551706075668335,
        "train_loss": 3.0876569747924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19719,
        "tokens": 10338435072,
        "learning_rate": 0.0002136687180064035,
        "gradient_norm": 0.3848712742328644,
        "train_loss": 2.9674086570739746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19720,
        "tokens": 10338959360,
        "learning_rate": 0.00021364286813008038,
        "gradient_norm": 0.33468034863471985,
        "train_loss": 3.0780627727508545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19721,
        "tokens": 10339483648,
        "learning_rate": 0.00021361701956350174,
        "gradient_norm": 0.33663058280944824,
        "train_loss": 3.063645362854004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19722,
        "tokens": 10340007936,
        "learning_rate": 0.00021359117230695867,
        "gradient_norm": 0.3837180435657501,
        "train_loss": 3.0893280506134033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19723,
        "tokens": 10340532224,
        "learning_rate": 0.00021356532636074199,
        "gradient_norm": 0.3562794327735901,
        "train_loss": 3.0461206436157227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19724,
        "tokens": 10341056512,
        "learning_rate": 0.00021353948172514282,
        "gradient_norm": 0.3561042845249176,
        "train_loss": 3.0541958808898926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19725,
        "tokens": 10341580800,
        "learning_rate": 0.00021351363840045183,
        "gradient_norm": 0.3474085032939911,
        "train_loss": 3.0447444915771484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19726,
        "tokens": 10342105088,
        "learning_rate": 0.00021348779638696006,
        "gradient_norm": 0.3618547022342682,
        "train_loss": 3.0460028648376465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19727,
        "tokens": 10342629376,
        "learning_rate": 0.0002134619556849585,
        "gradient_norm": 0.37016168236732483,
        "train_loss": 3.081477165222168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19728,
        "tokens": 10343153664,
        "learning_rate": 0.00021343611629473774,
        "gradient_norm": 0.4501255452632904,
        "train_loss": 3.1404659748077393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19729,
        "tokens": 10343677952,
        "learning_rate": 0.0002134102782165889,
        "gradient_norm": 0.36981067061424255,
        "train_loss": 3.0929017066955566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19730,
        "tokens": 10344202240,
        "learning_rate": 0.00021338444145080267,
        "gradient_norm": 0.3903898596763611,
        "train_loss": 3.0142736434936523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19731,
        "tokens": 10344726528,
        "learning_rate": 0.00021335860599766999,
        "gradient_norm": 0.334648996591568,
        "train_loss": 3.0687828063964844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19732,
        "tokens": 10345250816,
        "learning_rate": 0.00021333277185748146,
        "gradient_norm": 0.4096159040927887,
        "train_loss": 3.0229074954986572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19733,
        "tokens": 10345775104,
        "learning_rate": 0.00021330693903052816,
        "gradient_norm": 0.379422664642334,
        "train_loss": 3.1045918464660645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19734,
        "tokens": 10346299392,
        "learning_rate": 0.00021328110751710062,
        "gradient_norm": 0.34767892956733704,
        "train_loss": 3.0617780685424805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19735,
        "tokens": 10346823680,
        "learning_rate": 0.0002132552773174897,
        "gradient_norm": 0.4433031976222992,
        "train_loss": 3.093845844268799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19736,
        "tokens": 10347347968,
        "learning_rate": 0.00021322944843198623,
        "gradient_norm": 0.33012160658836365,
        "train_loss": 3.060621738433838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19737,
        "tokens": 10347872256,
        "learning_rate": 0.00021320362086088077,
        "gradient_norm": 0.3640398383140564,
        "train_loss": 3.038038492202759,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19738,
        "tokens": 10348396544,
        "learning_rate": 0.00021317779460446428,
        "gradient_norm": 0.32517310976982117,
        "train_loss": 3.0360894203186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19739,
        "tokens": 10348920832,
        "learning_rate": 0.00021315196966302725,
        "gradient_norm": 0.35839858651161194,
        "train_loss": 3.080796718597412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19740,
        "tokens": 10349445120,
        "learning_rate": 0.00021312614603686053,
        "gradient_norm": 0.3533896207809448,
        "train_loss": 3.0585992336273193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19741,
        "tokens": 10349969408,
        "learning_rate": 0.00021310032372625465,
        "gradient_norm": 0.3256903290748596,
        "train_loss": 3.0700106620788574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19742,
        "tokens": 10350493696,
        "learning_rate": 0.00021307450273150044,
        "gradient_norm": 0.3725150227546692,
        "train_loss": 3.092526912689209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19743,
        "tokens": 10351017984,
        "learning_rate": 0.00021304868305288834,
        "gradient_norm": 0.36788931488990784,
        "train_loss": 3.062354564666748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19744,
        "tokens": 10351542272,
        "learning_rate": 0.0002130228646907092,
        "gradient_norm": 0.3735169768333435,
        "train_loss": 3.0667295455932617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19745,
        "tokens": 10352066560,
        "learning_rate": 0.00021299704764525342,
        "gradient_norm": 0.32567283511161804,
        "train_loss": 3.0632224082946777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19746,
        "tokens": 10352590848,
        "learning_rate": 0.00021297123191681171,
        "gradient_norm": 0.3435477018356323,
        "train_loss": 3.0594067573547363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19747,
        "tokens": 10353115136,
        "learning_rate": 0.00021294541750567478,
        "gradient_norm": 0.36080726981163025,
        "train_loss": 3.0773019790649414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19748,
        "tokens": 10353639424,
        "learning_rate": 0.00021291960441213303,
        "gradient_norm": 0.3873114287853241,
        "train_loss": 3.0078132152557373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19749,
        "tokens": 10354163712,
        "learning_rate": 0.0002128937926364771,
        "gradient_norm": 0.3738466501235962,
        "train_loss": 3.0636096000671387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19750,
        "tokens": 10354688000,
        "learning_rate": 0.00021286798217899744,
        "gradient_norm": 0.42813271284103394,
        "train_loss": 3.093432903289795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19751,
        "tokens": 10355212288,
        "learning_rate": 0.00021284217303998477,
        "gradient_norm": 0.39628148078918457,
        "train_loss": 3.06052303314209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19752,
        "tokens": 10355736576,
        "learning_rate": 0.00021281636521972935,
        "gradient_norm": 0.4020683169364929,
        "train_loss": 3.0600738525390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19753,
        "tokens": 10356260864,
        "learning_rate": 0.00021279055871852197,
        "gradient_norm": 0.3814682364463806,
        "train_loss": 3.1053524017333984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19754,
        "tokens": 10356785152,
        "learning_rate": 0.00021276475353665278,
        "gradient_norm": 0.42218175530433655,
        "train_loss": 3.1364669799804688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19755,
        "tokens": 10357309440,
        "learning_rate": 0.00021273894967441248,
        "gradient_norm": 0.3818250000476837,
        "train_loss": 3.014610767364502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19756,
        "tokens": 10357833728,
        "learning_rate": 0.00021271314713209154,
        "gradient_norm": 0.422985315322876,
        "train_loss": 3.074833631515503,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19757,
        "tokens": 10358358016,
        "learning_rate": 0.00021268734590998024,
        "gradient_norm": 0.4311399459838867,
        "train_loss": 3.001608371734619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19758,
        "tokens": 10358882304,
        "learning_rate": 0.00021266154600836924,
        "gradient_norm": 0.3963668644428253,
        "train_loss": 3.0838677883148193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19759,
        "tokens": 10359406592,
        "learning_rate": 0.00021263574742754867,
        "gradient_norm": 0.34905320405960083,
        "train_loss": 3.043210506439209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19760,
        "tokens": 10359930880,
        "learning_rate": 0.00021260995016780918,
        "gradient_norm": 0.3600867986679077,
        "train_loss": 3.089263916015625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19761,
        "tokens": 10360455168,
        "learning_rate": 0.00021258415422944086,
        "gradient_norm": 0.36963218450546265,
        "train_loss": 3.0246100425720215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19762,
        "tokens": 10360979456,
        "learning_rate": 0.00021255835961273443,
        "gradient_norm": 0.37281906604766846,
        "train_loss": 3.044414520263672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19763,
        "tokens": 10361503744,
        "learning_rate": 0.0002125325663179799,
        "gradient_norm": 0.3810194730758667,
        "train_loss": 3.1272284984588623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19764,
        "tokens": 10362028032,
        "learning_rate": 0.00021250677434546793,
        "gradient_norm": 0.3737187087535858,
        "train_loss": 3.0868911743164062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19765,
        "tokens": 10362552320,
        "learning_rate": 0.0002124809836954885,
        "gradient_norm": 0.3527149260044098,
        "train_loss": 3.0693366527557373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19766,
        "tokens": 10363076608,
        "learning_rate": 0.00021245519436833226,
        "gradient_norm": 0.3490486145019531,
        "train_loss": 3.076531410217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19767,
        "tokens": 10363600896,
        "learning_rate": 0.0002124294063642892,
        "gradient_norm": 0.3543156087398529,
        "train_loss": 2.999330520629883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19768,
        "tokens": 10364125184,
        "learning_rate": 0.00021240361968364978,
        "gradient_norm": 0.3280751407146454,
        "train_loss": 3.0398478507995605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19769,
        "tokens": 10364649472,
        "learning_rate": 0.0002123778343267042,
        "gradient_norm": 0.35285118222236633,
        "train_loss": 3.060333251953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19770,
        "tokens": 10365173760,
        "learning_rate": 0.00021235205029374274,
        "gradient_norm": 0.3268531262874603,
        "train_loss": 3.011026620864868,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19771,
        "tokens": 10365698048,
        "learning_rate": 0.00021232626758505553,
        "gradient_norm": 0.3426834046840668,
        "train_loss": 3.0807912349700928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19772,
        "tokens": 10366222336,
        "learning_rate": 0.00021230048620093296,
        "gradient_norm": 0.35137584805488586,
        "train_loss": 3.1003570556640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19773,
        "tokens": 10366746624,
        "learning_rate": 0.00021227470614166503,
        "gradient_norm": 0.3738415837287903,
        "train_loss": 3.0605533123016357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19774,
        "tokens": 10367270912,
        "learning_rate": 0.00021224892740754215,
        "gradient_norm": 0.4050499498844147,
        "train_loss": 3.0524449348449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19775,
        "tokens": 10367795200,
        "learning_rate": 0.00021222314999885426,
        "gradient_norm": 0.389607310295105,
        "train_loss": 3.087860107421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19776,
        "tokens": 10368319488,
        "learning_rate": 0.0002121973739158917,
        "gradient_norm": 0.37039798498153687,
        "train_loss": 3.084672689437866,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19777,
        "tokens": 10368843776,
        "learning_rate": 0.0002121715991589445,
        "gradient_norm": 0.3939429819583893,
        "train_loss": 3.047849655151367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19778,
        "tokens": 10369368064,
        "learning_rate": 0.0002121458257283029,
        "gradient_norm": 0.3772520422935486,
        "train_loss": 3.0602030754089355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19779,
        "tokens": 10369892352,
        "learning_rate": 0.00021212005362425686,
        "gradient_norm": 0.37369275093078613,
        "train_loss": 3.0601887702941895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19780,
        "tokens": 10370416640,
        "learning_rate": 0.00021209428284709662,
        "gradient_norm": 0.40334853529930115,
        "train_loss": 3.090945243835449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19781,
        "tokens": 10370940928,
        "learning_rate": 0.0002120685133971121,
        "gradient_norm": 0.37158188223838806,
        "train_loss": 3.075336456298828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19782,
        "tokens": 10371465216,
        "learning_rate": 0.0002120427452745935,
        "gradient_norm": 0.35452958941459656,
        "train_loss": 3.0847132205963135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19783,
        "tokens": 10371989504,
        "learning_rate": 0.00021201697847983092,
        "gradient_norm": 0.38158050179481506,
        "train_loss": 3.04494571685791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19784,
        "tokens": 10372513792,
        "learning_rate": 0.00021199121301311422,
        "gradient_norm": 0.3694806396961212,
        "train_loss": 3.0610570907592773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19785,
        "tokens": 10373038080,
        "learning_rate": 0.00021196544887473363,
        "gradient_norm": 0.3623523414134979,
        "train_loss": 3.0646958351135254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19786,
        "tokens": 10373562368,
        "learning_rate": 0.0002119396860649789,
        "gradient_norm": 0.3631397783756256,
        "train_loss": 3.0556883811950684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19787,
        "tokens": 10374086656,
        "learning_rate": 0.00021191392458414033,
        "gradient_norm": 0.40877681970596313,
        "train_loss": 3.087709903717041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19788,
        "tokens": 10374610944,
        "learning_rate": 0.0002118881644325076,
        "gradient_norm": 0.36043912172317505,
        "train_loss": 3.060377597808838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19789,
        "tokens": 10375135232,
        "learning_rate": 0.00021186240561037095,
        "gradient_norm": 0.45335134863853455,
        "train_loss": 3.1371610164642334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19790,
        "tokens": 10375659520,
        "learning_rate": 0.00021183664811802005,
        "gradient_norm": 0.4049668312072754,
        "train_loss": 3.0762298107147217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19791,
        "tokens": 10376183808,
        "learning_rate": 0.00021181089195574507,
        "gradient_norm": 0.37169674038887024,
        "train_loss": 3.0681777000427246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19792,
        "tokens": 10376708096,
        "learning_rate": 0.00021178513712383573,
        "gradient_norm": 0.4076027274131775,
        "train_loss": 3.078491449356079,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19793,
        "tokens": 10377232384,
        "learning_rate": 0.00021175938362258214,
        "gradient_norm": 0.33056607842445374,
        "train_loss": 3.1032729148864746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19794,
        "tokens": 10377756672,
        "learning_rate": 0.00021173363145227401,
        "gradient_norm": 0.42766356468200684,
        "train_loss": 3.0588908195495605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19795,
        "tokens": 10378280960,
        "learning_rate": 0.00021170788061320123,
        "gradient_norm": 0.3738912045955658,
        "train_loss": 3.0688343048095703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19796,
        "tokens": 10378805248,
        "learning_rate": 0.00021168213110565382,
        "gradient_norm": 0.37550288438796997,
        "train_loss": 3.087468147277832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19797,
        "tokens": 10379329536,
        "learning_rate": 0.0002116563829299214,
        "gradient_norm": 0.3864436149597168,
        "train_loss": 3.082427501678467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19798,
        "tokens": 10379853824,
        "learning_rate": 0.00021163063608629405,
        "gradient_norm": 0.38247430324554443,
        "train_loss": 3.1011109352111816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19799,
        "tokens": 10380378112,
        "learning_rate": 0.00021160489057506132,
        "gradient_norm": 0.36711612343788147,
        "train_loss": 3.049226760864258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19800,
        "tokens": 10380902400,
        "learning_rate": 0.00021157914639651323,
        "gradient_norm": 0.3868016302585602,
        "train_loss": 3.099231243133545,
        "val_loss": 3.02343487739563,
        "hellaswag_acc": 0.2841067612171173,
        "hellaswag_acc_norm": 0.2966540455818176
    },
    {
        "step": 19801,
        "tokens": 10381426688,
        "learning_rate": 0.00021155340355093934,
        "gradient_norm": 0.33892661333084106,
        "train_loss": 3.013491630554199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19802,
        "tokens": 10381950976,
        "learning_rate": 0.00021152766203862968,
        "gradient_norm": 0.36081641912460327,
        "train_loss": 3.0691819190979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19803,
        "tokens": 10382475264,
        "learning_rate": 0.00021150192185987374,
        "gradient_norm": 0.362215518951416,
        "train_loss": 3.115703582763672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19804,
        "tokens": 10382999552,
        "learning_rate": 0.00021147618301496147,
        "gradient_norm": 0.4183829128742218,
        "train_loss": 3.0519542694091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19805,
        "tokens": 10383523840,
        "learning_rate": 0.00021145044550418242,
        "gradient_norm": 0.3598170578479767,
        "train_loss": 3.0585739612579346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19806,
        "tokens": 10384048128,
        "learning_rate": 0.0002114247093278264,
        "gradient_norm": 0.40804263949394226,
        "train_loss": 3.08829402923584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19807,
        "tokens": 10384572416,
        "learning_rate": 0.00021139897448618316,
        "gradient_norm": 0.395575612783432,
        "train_loss": 3.1035594940185547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19808,
        "tokens": 10385096704,
        "learning_rate": 0.00021137324097954223,
        "gradient_norm": 0.3861888647079468,
        "train_loss": 3.048764228820801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19809,
        "tokens": 10385620992,
        "learning_rate": 0.0002113475088081934,
        "gradient_norm": 0.36419999599456787,
        "train_loss": 3.054692268371582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19810,
        "tokens": 10386145280,
        "learning_rate": 0.00021132177797242616,
        "gradient_norm": 0.34370413422584534,
        "train_loss": 3.0255956649780273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19811,
        "tokens": 10386669568,
        "learning_rate": 0.0002112960484725304,
        "gradient_norm": 0.37383994460105896,
        "train_loss": 3.043720245361328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19812,
        "tokens": 10387193856,
        "learning_rate": 0.00021127032030879547,
        "gradient_norm": 0.35857200622558594,
        "train_loss": 3.0242526531219482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19813,
        "tokens": 10387718144,
        "learning_rate": 0.0002112445934815112,
        "gradient_norm": 0.31163290143013,
        "train_loss": 3.0310521125793457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19814,
        "tokens": 10388242432,
        "learning_rate": 0.00021121886799096689,
        "gradient_norm": 0.3517923057079315,
        "train_loss": 3.0290133953094482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19815,
        "tokens": 10388766720,
        "learning_rate": 0.00021119314383745232,
        "gradient_norm": 0.35661324858665466,
        "train_loss": 3.0365939140319824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19816,
        "tokens": 10389291008,
        "learning_rate": 0.00021116742102125714,
        "gradient_norm": 0.34229984879493713,
        "train_loss": 2.9896140098571777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19817,
        "tokens": 10389815296,
        "learning_rate": 0.00021114169954267065,
        "gradient_norm": 0.3517824113368988,
        "train_loss": 3.0372118949890137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19818,
        "tokens": 10390339584,
        "learning_rate": 0.00021111597940198256,
        "gradient_norm": 0.38439252972602844,
        "train_loss": 3.0523695945739746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19819,
        "tokens": 10390863872,
        "learning_rate": 0.00021109026059948227,
        "gradient_norm": 0.4261191785335541,
        "train_loss": 3.010197639465332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19820,
        "tokens": 10391388160,
        "learning_rate": 0.0002110645431354594,
        "gradient_norm": 0.36532238125801086,
        "train_loss": 3.035804510116577,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19821,
        "tokens": 10391912448,
        "learning_rate": 0.00021103882701020322,
        "gradient_norm": 0.3430560529232025,
        "train_loss": 2.999967098236084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19822,
        "tokens": 10392436736,
        "learning_rate": 0.0002110131122240035,
        "gradient_norm": 0.3433595597743988,
        "train_loss": 3.0301122665405273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19823,
        "tokens": 10392961024,
        "learning_rate": 0.00021098739877714937,
        "gradient_norm": 0.36344829201698303,
        "train_loss": 2.9892778396606445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19824,
        "tokens": 10393485312,
        "learning_rate": 0.00021096168666993054,
        "gradient_norm": 0.35195448994636536,
        "train_loss": 2.9700260162353516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19825,
        "tokens": 10394009600,
        "learning_rate": 0.0002109359759026362,
        "gradient_norm": 0.40630042552948,
        "train_loss": 3.037606716156006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19826,
        "tokens": 10394533888,
        "learning_rate": 0.00021091026647555587,
        "gradient_norm": 0.3775840103626251,
        "train_loss": 3.0072622299194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19827,
        "tokens": 10395058176,
        "learning_rate": 0.00021088455838897904,
        "gradient_norm": 0.37328997254371643,
        "train_loss": 2.9943675994873047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19828,
        "tokens": 10395582464,
        "learning_rate": 0.0002108588516431949,
        "gradient_norm": 0.36104512214660645,
        "train_loss": 3.0137133598327637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19829,
        "tokens": 10396106752,
        "learning_rate": 0.00021083314623849295,
        "gradient_norm": 0.38581517338752747,
        "train_loss": 3.0659942626953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19830,
        "tokens": 10396631040,
        "learning_rate": 0.00021080744217516243,
        "gradient_norm": 0.37475085258483887,
        "train_loss": 2.9581029415130615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19831,
        "tokens": 10397155328,
        "learning_rate": 0.00021078173945349282,
        "gradient_norm": 0.39005425572395325,
        "train_loss": 3.079714775085449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19832,
        "tokens": 10397679616,
        "learning_rate": 0.00021075603807377323,
        "gradient_norm": 0.32042983174324036,
        "train_loss": 3.0059406757354736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19833,
        "tokens": 10398203904,
        "learning_rate": 0.00021073033803629322,
        "gradient_norm": 0.37259402871131897,
        "train_loss": 3.0276594161987305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19834,
        "tokens": 10398728192,
        "learning_rate": 0.00021070463934134178,
        "gradient_norm": 0.3561563789844513,
        "train_loss": 2.9895665645599365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19835,
        "tokens": 10399252480,
        "learning_rate": 0.00021067894198920832,
        "gradient_norm": 0.3354426622390747,
        "train_loss": 3.006702423095703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19836,
        "tokens": 10399776768,
        "learning_rate": 0.0002106532459801822,
        "gradient_norm": 0.3872273862361908,
        "train_loss": 3.0196194648742676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19837,
        "tokens": 10400301056,
        "learning_rate": 0.0002106275513145525,
        "gradient_norm": 0.36888810992240906,
        "train_loss": 3.0368313789367676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19838,
        "tokens": 10400825344,
        "learning_rate": 0.00021060185799260867,
        "gradient_norm": 0.3324413299560547,
        "train_loss": 3.0599822998046875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19839,
        "tokens": 10401349632,
        "learning_rate": 0.00021057616601463953,
        "gradient_norm": 0.34389182925224304,
        "train_loss": 3.0354435443878174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19840,
        "tokens": 10401873920,
        "learning_rate": 0.0002105504753809347,
        "gradient_norm": 0.3603781461715698,
        "train_loss": 2.9885706901550293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19841,
        "tokens": 10402398208,
        "learning_rate": 0.00021052478609178305,
        "gradient_norm": 0.3307359218597412,
        "train_loss": 3.0765609741210938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19842,
        "tokens": 10402922496,
        "learning_rate": 0.00021049909814747396,
        "gradient_norm": 0.3805099129676819,
        "train_loss": 3.0112557411193848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19843,
        "tokens": 10403446784,
        "learning_rate": 0.00021047341154829637,
        "gradient_norm": 0.3266385793685913,
        "train_loss": 3.0196542739868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19844,
        "tokens": 10403971072,
        "learning_rate": 0.0002104477262945395,
        "gradient_norm": 0.35560232400894165,
        "train_loss": 3.0599637031555176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19845,
        "tokens": 10404495360,
        "learning_rate": 0.00021042204238649263,
        "gradient_norm": 0.38201606273651123,
        "train_loss": 3.026621103286743,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19846,
        "tokens": 10405019648,
        "learning_rate": 0.00021039635982444466,
        "gradient_norm": 0.3521098792552948,
        "train_loss": 3.051833391189575,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19847,
        "tokens": 10405543936,
        "learning_rate": 0.0002103706786086848,
        "gradient_norm": 0.34277892112731934,
        "train_loss": 2.9778223037719727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19848,
        "tokens": 10406068224,
        "learning_rate": 0.00021034499873950202,
        "gradient_norm": 0.39905545115470886,
        "train_loss": 3.0027151107788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19849,
        "tokens": 10406592512,
        "learning_rate": 0.00021031932021718552,
        "gradient_norm": 0.3850601613521576,
        "train_loss": 2.967972993850708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19850,
        "tokens": 10407116800,
        "learning_rate": 0.0002102936430420241,
        "gradient_norm": 0.34714460372924805,
        "train_loss": 2.982008934020996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19851,
        "tokens": 10407641088,
        "learning_rate": 0.0002102679672143071,
        "gradient_norm": 0.3303937315940857,
        "train_loss": 3.0211386680603027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19852,
        "tokens": 10408165376,
        "learning_rate": 0.00021024229273432327,
        "gradient_norm": 0.36687198281288147,
        "train_loss": 3.0424275398254395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19853,
        "tokens": 10408689664,
        "learning_rate": 0.00021021661960236182,
        "gradient_norm": 0.3311343789100647,
        "train_loss": 3.0908799171447754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19854,
        "tokens": 10409213952,
        "learning_rate": 0.00021019094781871153,
        "gradient_norm": 0.347275048494339,
        "train_loss": 3.078606605529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19855,
        "tokens": 10409738240,
        "learning_rate": 0.00021016527738366148,
        "gradient_norm": 0.32854074239730835,
        "train_loss": 3.013671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19856,
        "tokens": 10410262528,
        "learning_rate": 0.00021013960829750067,
        "gradient_norm": 0.3139125108718872,
        "train_loss": 2.9950764179229736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19857,
        "tokens": 10410786816,
        "learning_rate": 0.00021011394056051792,
        "gradient_norm": 0.33452481031417847,
        "train_loss": 3.051933765411377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19858,
        "tokens": 10411311104,
        "learning_rate": 0.0002100882741730023,
        "gradient_norm": 0.3164173662662506,
        "train_loss": 3.0181422233581543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19859,
        "tokens": 10411835392,
        "learning_rate": 0.0002100626091352425,
        "gradient_norm": 0.3841192424297333,
        "train_loss": 3.0436935424804688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19860,
        "tokens": 10412359680,
        "learning_rate": 0.00021003694544752765,
        "gradient_norm": 0.32384249567985535,
        "train_loss": 3.0931596755981445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19861,
        "tokens": 10412883968,
        "learning_rate": 0.00021001128311014643,
        "gradient_norm": 0.37110549211502075,
        "train_loss": 3.093825340270996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19862,
        "tokens": 10413408256,
        "learning_rate": 0.00020998562212338792,
        "gradient_norm": 0.36292558908462524,
        "train_loss": 3.0721874237060547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19863,
        "tokens": 10413932544,
        "learning_rate": 0.00020995996248754066,
        "gradient_norm": 0.34825822710990906,
        "train_loss": 3.0332093238830566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19864,
        "tokens": 10414456832,
        "learning_rate": 0.00020993430420289372,
        "gradient_norm": 0.3243494927883148,
        "train_loss": 2.9754714965820312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19865,
        "tokens": 10414981120,
        "learning_rate": 0.00020990864726973593,
        "gradient_norm": 0.36139729619026184,
        "train_loss": 3.069870948791504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19866,
        "tokens": 10415505408,
        "learning_rate": 0.00020988299168835588,
        "gradient_norm": 0.33289316296577454,
        "train_loss": 3.044456720352173,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19867,
        "tokens": 10416029696,
        "learning_rate": 0.00020985733745904268,
        "gradient_norm": 0.36086800694465637,
        "train_loss": 3.00886869430542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19868,
        "tokens": 10416553984,
        "learning_rate": 0.0002098316845820847,
        "gradient_norm": 0.33719462156295776,
        "train_loss": 2.999582529067993,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19869,
        "tokens": 10417078272,
        "learning_rate": 0.00020980603305777108,
        "gradient_norm": 0.3297029733657837,
        "train_loss": 3.0398995876312256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19870,
        "tokens": 10417602560,
        "learning_rate": 0.00020978038288639025,
        "gradient_norm": 0.31515464186668396,
        "train_loss": 3.0353565216064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19871,
        "tokens": 10418126848,
        "learning_rate": 0.00020975473406823115,
        "gradient_norm": 0.3054678738117218,
        "train_loss": 3.0449013710021973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19872,
        "tokens": 10418651136,
        "learning_rate": 0.00020972908660358235,
        "gradient_norm": 0.3507659435272217,
        "train_loss": 3.048893451690674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19873,
        "tokens": 10419175424,
        "learning_rate": 0.0002097034404927327,
        "gradient_norm": 0.371133416891098,
        "train_loss": 3.022641658782959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19874,
        "tokens": 10419699712,
        "learning_rate": 0.00020967779573597065,
        "gradient_norm": 0.37925055623054504,
        "train_loss": 3.0054430961608887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19875,
        "tokens": 10420224000,
        "learning_rate": 0.00020965215233358512,
        "gradient_norm": 0.37895846366882324,
        "train_loss": 3.0386223793029785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19876,
        "tokens": 10420748288,
        "learning_rate": 0.00020962651028586454,
        "gradient_norm": 0.3852890133857727,
        "train_loss": 3.020230293273926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19877,
        "tokens": 10421272576,
        "learning_rate": 0.00020960086959309772,
        "gradient_norm": 0.34268367290496826,
        "train_loss": 3.045562505722046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19878,
        "tokens": 10421796864,
        "learning_rate": 0.00020957523025557308,
        "gradient_norm": 0.3874877393245697,
        "train_loss": 3.007770299911499,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19879,
        "tokens": 10422321152,
        "learning_rate": 0.00020954959227357947,
        "gradient_norm": 0.34257417917251587,
        "train_loss": 2.949481964111328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19880,
        "tokens": 10422845440,
        "learning_rate": 0.0002095239556474052,
        "gradient_norm": 0.3941609859466553,
        "train_loss": 3.0052897930145264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19881,
        "tokens": 10423369728,
        "learning_rate": 0.00020949832037733915,
        "gradient_norm": 0.41646450757980347,
        "train_loss": 3.007704734802246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19882,
        "tokens": 10423894016,
        "learning_rate": 0.00020947268646366956,
        "gradient_norm": 0.3759516775608063,
        "train_loss": 3.053501844406128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19883,
        "tokens": 10424418304,
        "learning_rate": 0.00020944705390668522,
        "gradient_norm": 0.36998221278190613,
        "train_loss": 3.114838123321533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19884,
        "tokens": 10424942592,
        "learning_rate": 0.0002094214227066745,
        "gradient_norm": 0.37213069200515747,
        "train_loss": 3.0219976902008057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19885,
        "tokens": 10425466880,
        "learning_rate": 0.00020939579286392607,
        "gradient_norm": 0.34960126876831055,
        "train_loss": 3.0634560585021973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19886,
        "tokens": 10425991168,
        "learning_rate": 0.0002093701643787282,
        "gradient_norm": 0.36691638827323914,
        "train_loss": 3.0199337005615234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19887,
        "tokens": 10426515456,
        "learning_rate": 0.00020934453725136962,
        "gradient_norm": 0.4016661047935486,
        "train_loss": 3.068142890930176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19888,
        "tokens": 10427039744,
        "learning_rate": 0.00020931891148213855,
        "gradient_norm": 0.41322290897369385,
        "train_loss": 2.9974985122680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19889,
        "tokens": 10427564032,
        "learning_rate": 0.00020929328707132368,
        "gradient_norm": 0.36636337637901306,
        "train_loss": 3.0649375915527344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19890,
        "tokens": 10428088320,
        "learning_rate": 0.00020926766401921325,
        "gradient_norm": 0.45502543449401855,
        "train_loss": 3.0419669151306152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19891,
        "tokens": 10428612608,
        "learning_rate": 0.0002092420423260958,
        "gradient_norm": 0.34794536232948303,
        "train_loss": 3.049365282058716,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19892,
        "tokens": 10429136896,
        "learning_rate": 0.00020921642199225963,
        "gradient_norm": 0.3743942081928253,
        "train_loss": 3.055722236633301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19893,
        "tokens": 10429661184,
        "learning_rate": 0.0002091908030179933,
        "gradient_norm": 0.3887791037559509,
        "train_loss": 3.020871877670288,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19894,
        "tokens": 10430185472,
        "learning_rate": 0.00020916518540358496,
        "gradient_norm": 0.42928534746170044,
        "train_loss": 3.0546483993530273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19895,
        "tokens": 10430709760,
        "learning_rate": 0.00020913956914932308,
        "gradient_norm": 0.3589250147342682,
        "train_loss": 3.0232858657836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19896,
        "tokens": 10431234048,
        "learning_rate": 0.00020911395425549613,
        "gradient_norm": 0.3838960528373718,
        "train_loss": 3.0238380432128906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19897,
        "tokens": 10431758336,
        "learning_rate": 0.0002090883407223922,
        "gradient_norm": 0.34840551018714905,
        "train_loss": 3.0407276153564453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19898,
        "tokens": 10432282624,
        "learning_rate": 0.0002090627285502998,
        "gradient_norm": 0.3781454265117645,
        "train_loss": 3.0257372856140137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19899,
        "tokens": 10432806912,
        "learning_rate": 0.00020903711773950705,
        "gradient_norm": 0.3536163866519928,
        "train_loss": 3.018197774887085,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19900,
        "tokens": 10433331200,
        "learning_rate": 0.00020901150829030245,
        "gradient_norm": 0.3866965174674988,
        "train_loss": 3.049903392791748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19901,
        "tokens": 10433855488,
        "learning_rate": 0.000208985900202974,
        "gradient_norm": 0.3421213626861572,
        "train_loss": 3.0390572547912598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19902,
        "tokens": 10434379776,
        "learning_rate": 0.00020896029347781026,
        "gradient_norm": 0.37349098920822144,
        "train_loss": 3.0179429054260254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19903,
        "tokens": 10434904064,
        "learning_rate": 0.0002089346881150991,
        "gradient_norm": 0.3650780916213989,
        "train_loss": 2.983912467956543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19904,
        "tokens": 10435428352,
        "learning_rate": 0.000208909084115129,
        "gradient_norm": 0.34270551800727844,
        "train_loss": 3.073187828063965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19905,
        "tokens": 10435952640,
        "learning_rate": 0.0002088834814781882,
        "gradient_norm": 0.6471090316772461,
        "train_loss": 3.092787265777588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19906,
        "tokens": 10436476928,
        "learning_rate": 0.00020885788020456465,
        "gradient_norm": 0.39476051926612854,
        "train_loss": 3.0796027183532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19907,
        "tokens": 10437001216,
        "learning_rate": 0.00020883228029454682,
        "gradient_norm": 0.36917737126350403,
        "train_loss": 3.0339832305908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19908,
        "tokens": 10437525504,
        "learning_rate": 0.00020880668174842257,
        "gradient_norm": 0.3713444173336029,
        "train_loss": 3.0924506187438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19909,
        "tokens": 10438049792,
        "learning_rate": 0.00020878108456648032,
        "gradient_norm": 0.36535733938217163,
        "train_loss": 3.0747780799865723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19910,
        "tokens": 10438574080,
        "learning_rate": 0.00020875548874900796,
        "gradient_norm": 0.4125036597251892,
        "train_loss": 3.0569722652435303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19911,
        "tokens": 10439098368,
        "learning_rate": 0.00020872989429629378,
        "gradient_norm": 0.3818581700325012,
        "train_loss": 3.024646759033203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19912,
        "tokens": 10439622656,
        "learning_rate": 0.00020870430120862576,
        "gradient_norm": 0.3766945004463196,
        "train_loss": 3.028287410736084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19913,
        "tokens": 10440146944,
        "learning_rate": 0.0002086787094862921,
        "gradient_norm": 0.38726744055747986,
        "train_loss": 3.0100674629211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19914,
        "tokens": 10440671232,
        "learning_rate": 0.00020865311912958068,
        "gradient_norm": 0.34974077343940735,
        "train_loss": 3.050344228744507,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19915,
        "tokens": 10441195520,
        "learning_rate": 0.00020862753013877968,
        "gradient_norm": 0.36421525478363037,
        "train_loss": 2.9964170455932617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19916,
        "tokens": 10441719808,
        "learning_rate": 0.00020860194251417724,
        "gradient_norm": 0.3470269739627838,
        "train_loss": 2.991124153137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19917,
        "tokens": 10442244096,
        "learning_rate": 0.00020857635625606114,
        "gradient_norm": 0.32141563296318054,
        "train_loss": 2.981977701187134,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19918,
        "tokens": 10442768384,
        "learning_rate": 0.0002085507713647196,
        "gradient_norm": 0.4056413173675537,
        "train_loss": 3.0422511100769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19919,
        "tokens": 10443292672,
        "learning_rate": 0.00020852518784044045,
        "gradient_norm": 0.36405447125434875,
        "train_loss": 3.0773086547851562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19920,
        "tokens": 10443816960,
        "learning_rate": 0.00020849960568351185,
        "gradient_norm": 0.3986366093158722,
        "train_loss": 3.011889696121216,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19921,
        "tokens": 10444341248,
        "learning_rate": 0.00020847402489422147,
        "gradient_norm": 0.39052820205688477,
        "train_loss": 3.0459251403808594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19922,
        "tokens": 10444865536,
        "learning_rate": 0.0002084484454728576,
        "gradient_norm": 0.3605612516403198,
        "train_loss": 3.02146053314209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19923,
        "tokens": 10445389824,
        "learning_rate": 0.00020842286741970783,
        "gradient_norm": 0.38443753123283386,
        "train_loss": 3.0261402130126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19924,
        "tokens": 10445914112,
        "learning_rate": 0.0002083972907350603,
        "gradient_norm": 0.3625442385673523,
        "train_loss": 3.0279173851013184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19925,
        "tokens": 10446438400,
        "learning_rate": 0.00020837171541920288,
        "gradient_norm": 0.36729156970977783,
        "train_loss": 3.0051350593566895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19926,
        "tokens": 10446962688,
        "learning_rate": 0.00020834614147242336,
        "gradient_norm": 0.3711634576320648,
        "train_loss": 3.0477402210235596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19927,
        "tokens": 10447486976,
        "learning_rate": 0.00020832056889500975,
        "gradient_norm": 0.4146459102630615,
        "train_loss": 3.002856969833374,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19928,
        "tokens": 10448011264,
        "learning_rate": 0.0002082949976872497,
        "gradient_norm": 0.3309757709503174,
        "train_loss": 2.9984803199768066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19929,
        "tokens": 10448535552,
        "learning_rate": 0.00020826942784943128,
        "gradient_norm": 0.40071210265159607,
        "train_loss": 3.011261463165283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19930,
        "tokens": 10449059840,
        "learning_rate": 0.00020824385938184213,
        "gradient_norm": 0.37013110518455505,
        "train_loss": 3.0129785537719727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19931,
        "tokens": 10449584128,
        "learning_rate": 0.00020821829228477015,
        "gradient_norm": 0.4338957369327545,
        "train_loss": 3.126997947692871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19932,
        "tokens": 10450108416,
        "learning_rate": 0.00020819272655850303,
        "gradient_norm": 0.37824299931526184,
        "train_loss": 3.1091203689575195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19933,
        "tokens": 10450632704,
        "learning_rate": 0.0002081671622033287,
        "gradient_norm": 0.4005596935749054,
        "train_loss": 3.0080466270446777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19934,
        "tokens": 10451156992,
        "learning_rate": 0.00020814159921953473,
        "gradient_norm": 0.36716699600219727,
        "train_loss": 3.057745933532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19935,
        "tokens": 10451681280,
        "learning_rate": 0.00020811603760740894,
        "gradient_norm": 0.4333464801311493,
        "train_loss": 3.029877185821533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19936,
        "tokens": 10452205568,
        "learning_rate": 0.00020809047736723918,
        "gradient_norm": 0.3420107960700989,
        "train_loss": 3.061605453491211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19937,
        "tokens": 10452729856,
        "learning_rate": 0.00020806491849931298,
        "gradient_norm": 0.36062154173851013,
        "train_loss": 3.034245252609253,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19938,
        "tokens": 10453254144,
        "learning_rate": 0.00020803936100391825,
        "gradient_norm": 0.37830406427383423,
        "train_loss": 3.065042495727539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19939,
        "tokens": 10453778432,
        "learning_rate": 0.0002080138048813424,
        "gradient_norm": 0.3599027991294861,
        "train_loss": 3.0066776275634766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19940,
        "tokens": 10454302720,
        "learning_rate": 0.00020798825013187332,
        "gradient_norm": 0.38429078459739685,
        "train_loss": 3.034287452697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19941,
        "tokens": 10454827008,
        "learning_rate": 0.00020796269675579852,
        "gradient_norm": 0.35708707571029663,
        "train_loss": 3.0572328567504883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19942,
        "tokens": 10455351296,
        "learning_rate": 0.00020793714475340574,
        "gradient_norm": 0.39353910088539124,
        "train_loss": 2.991593837738037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19943,
        "tokens": 10455875584,
        "learning_rate": 0.0002079115941249825,
        "gradient_norm": 0.3577999472618103,
        "train_loss": 2.9843006134033203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19944,
        "tokens": 10456399872,
        "learning_rate": 0.00020788604487081646,
        "gradient_norm": 0.36322784423828125,
        "train_loss": 3.0925958156585693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19945,
        "tokens": 10456924160,
        "learning_rate": 0.00020786049699119527,
        "gradient_norm": 0.36187079548835754,
        "train_loss": 3.0124661922454834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19946,
        "tokens": 10457448448,
        "learning_rate": 0.00020783495048640633,
        "gradient_norm": 0.3556267023086548,
        "train_loss": 2.9850735664367676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19947,
        "tokens": 10457972736,
        "learning_rate": 0.00020780940535673745,
        "gradient_norm": 0.3731836676597595,
        "train_loss": 3.033447027206421,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19948,
        "tokens": 10458497024,
        "learning_rate": 0.00020778386160247587,
        "gradient_norm": 0.3494696021080017,
        "train_loss": 2.931918144226074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19949,
        "tokens": 10459021312,
        "learning_rate": 0.00020775831922390943,
        "gradient_norm": 0.33349114656448364,
        "train_loss": 3.0004122257232666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19950,
        "tokens": 10459545600,
        "learning_rate": 0.00020773277822132535,
        "gradient_norm": 0.39456844329833984,
        "train_loss": 2.9912025928497314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19951,
        "tokens": 10460069888,
        "learning_rate": 0.00020770723859501138,
        "gradient_norm": 0.35808560252189636,
        "train_loss": 2.9974617958068848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19952,
        "tokens": 10460594176,
        "learning_rate": 0.00020768170034525478,
        "gradient_norm": 0.3550175428390503,
        "train_loss": 3.011735439300537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19953,
        "tokens": 10461118464,
        "learning_rate": 0.00020765616347234318,
        "gradient_norm": 0.3784661293029785,
        "train_loss": 3.056032657623291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19954,
        "tokens": 10461642752,
        "learning_rate": 0.0002076306279765639,
        "gradient_norm": 0.3821088671684265,
        "train_loss": 3.096367835998535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19955,
        "tokens": 10462167040,
        "learning_rate": 0.00020760509385820447,
        "gradient_norm": 0.38634324073791504,
        "train_loss": 3.1165287494659424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19956,
        "tokens": 10462691328,
        "learning_rate": 0.0002075795611175523,
        "gradient_norm": 0.39974352717399597,
        "train_loss": 3.0378365516662598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19957,
        "tokens": 10463215616,
        "learning_rate": 0.00020755402975489474,
        "gradient_norm": 0.3813309073448181,
        "train_loss": 3.006572723388672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19958,
        "tokens": 10463739904,
        "learning_rate": 0.00020752849977051925,
        "gradient_norm": 0.37614014744758606,
        "train_loss": 3.0271573066711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19959,
        "tokens": 10464264192,
        "learning_rate": 0.00020750297116471314,
        "gradient_norm": 0.3625074625015259,
        "train_loss": 2.997401237487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19960,
        "tokens": 10464788480,
        "learning_rate": 0.00020747744393776382,
        "gradient_norm": 0.41684791445732117,
        "train_loss": 3.035733222961426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19961,
        "tokens": 10465312768,
        "learning_rate": 0.0002074519180899585,
        "gradient_norm": 0.4694901704788208,
        "train_loss": 2.974013328552246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19962,
        "tokens": 10465837056,
        "learning_rate": 0.0002074263936215847,
        "gradient_norm": 0.40955740213394165,
        "train_loss": 3.081017017364502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19963,
        "tokens": 10466361344,
        "learning_rate": 0.00020740087053292954,
        "gradient_norm": 0.4288850724697113,
        "train_loss": 3.054053783416748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19964,
        "tokens": 10466885632,
        "learning_rate": 0.00020737534882428043,
        "gradient_norm": 0.378703773021698,
        "train_loss": 2.9895341396331787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19965,
        "tokens": 10467409920,
        "learning_rate": 0.0002073498284959247,
        "gradient_norm": 0.4436904191970825,
        "train_loss": 3.162602186203003,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19966,
        "tokens": 10467934208,
        "learning_rate": 0.00020732430954814948,
        "gradient_norm": 0.4214952886104584,
        "train_loss": 3.08194899559021,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19967,
        "tokens": 10468458496,
        "learning_rate": 0.0002072987919812421,
        "gradient_norm": 0.4149312973022461,
        "train_loss": 3.010854959487915,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19968,
        "tokens": 10468982784,
        "learning_rate": 0.00020727327579548972,
        "gradient_norm": 0.3777896463871002,
        "train_loss": 3.013577938079834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19969,
        "tokens": 10469507072,
        "learning_rate": 0.00020724776099117972,
        "gradient_norm": 0.37371906638145447,
        "train_loss": 3.0241785049438477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19970,
        "tokens": 10470031360,
        "learning_rate": 0.00020722224756859902,
        "gradient_norm": 0.3863329291343689,
        "train_loss": 3.043393611907959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19971,
        "tokens": 10470555648,
        "learning_rate": 0.00020719673552803514,
        "gradient_norm": 0.3919425904750824,
        "train_loss": 3.035930633544922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19972,
        "tokens": 10471079936,
        "learning_rate": 0.00020717122486977493,
        "gradient_norm": 0.38896918296813965,
        "train_loss": 3.0470118522644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19973,
        "tokens": 10471604224,
        "learning_rate": 0.00020714571559410583,
        "gradient_norm": 0.36212119460105896,
        "train_loss": 3.0705771446228027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19974,
        "tokens": 10472128512,
        "learning_rate": 0.0002071202077013147,
        "gradient_norm": 0.39774736762046814,
        "train_loss": 3.0272483825683594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19975,
        "tokens": 10472652800,
        "learning_rate": 0.00020709470119168895,
        "gradient_norm": 0.34198427200317383,
        "train_loss": 3.0506160259246826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19976,
        "tokens": 10473177088,
        "learning_rate": 0.0002070691960655154,
        "gradient_norm": 0.42533135414123535,
        "train_loss": 3.022402286529541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19977,
        "tokens": 10473701376,
        "learning_rate": 0.00020704369232308142,
        "gradient_norm": 0.33939284086227417,
        "train_loss": 3.0302841663360596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19978,
        "tokens": 10474225664,
        "learning_rate": 0.00020701818996467385,
        "gradient_norm": 0.39674150943756104,
        "train_loss": 3.0316944122314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19979,
        "tokens": 10474749952,
        "learning_rate": 0.00020699268899057995,
        "gradient_norm": 0.35601091384887695,
        "train_loss": 3.024507999420166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19980,
        "tokens": 10475274240,
        "learning_rate": 0.00020696718940108654,
        "gradient_norm": 0.399050235748291,
        "train_loss": 3.0473246574401855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19981,
        "tokens": 10475798528,
        "learning_rate": 0.00020694169119648092,
        "gradient_norm": 0.3495370149612427,
        "train_loss": 3.0658679008483887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19982,
        "tokens": 10476322816,
        "learning_rate": 0.00020691619437704985,
        "gradient_norm": 0.34376510977745056,
        "train_loss": 2.977548837661743,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19983,
        "tokens": 10476847104,
        "learning_rate": 0.00020689069894308054,
        "gradient_norm": 0.39902353286743164,
        "train_loss": 3.083846092224121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19984,
        "tokens": 10477371392,
        "learning_rate": 0.00020686520489485977,
        "gradient_norm": 0.3520791828632355,
        "train_loss": 3.0273802280426025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19985,
        "tokens": 10477895680,
        "learning_rate": 0.00020683971223267467,
        "gradient_norm": 0.36139896512031555,
        "train_loss": 3.0315823554992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19986,
        "tokens": 10478419968,
        "learning_rate": 0.00020681422095681208,
        "gradient_norm": 0.3439512848854065,
        "train_loss": 3.0578866004943848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19987,
        "tokens": 10478944256,
        "learning_rate": 0.0002067887310675591,
        "gradient_norm": 0.35254359245300293,
        "train_loss": 3.0361952781677246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19988,
        "tokens": 10479468544,
        "learning_rate": 0.00020676324256520238,
        "gradient_norm": 0.3647474944591522,
        "train_loss": 3.017817735671997,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19989,
        "tokens": 10479992832,
        "learning_rate": 0.00020673775545002903,
        "gradient_norm": 0.3462539613246918,
        "train_loss": 3.0301401615142822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19990,
        "tokens": 10480517120,
        "learning_rate": 0.000206712269722326,
        "gradient_norm": 0.3923162519931793,
        "train_loss": 2.99471378326416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19991,
        "tokens": 10481041408,
        "learning_rate": 0.0002066867853823799,
        "gradient_norm": 0.4112354516983032,
        "train_loss": 3.023207187652588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19992,
        "tokens": 10481565696,
        "learning_rate": 0.00020666130243047787,
        "gradient_norm": 0.36059895157814026,
        "train_loss": 3.013826847076416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19993,
        "tokens": 10482089984,
        "learning_rate": 0.00020663582086690658,
        "gradient_norm": 0.3789546489715576,
        "train_loss": 3.019277572631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19994,
        "tokens": 10482614272,
        "learning_rate": 0.00020661034069195295,
        "gradient_norm": 0.34017857909202576,
        "train_loss": 2.995546579360962,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19995,
        "tokens": 10483138560,
        "learning_rate": 0.00020658486190590364,
        "gradient_norm": 0.3924652338027954,
        "train_loss": 3.1391353607177734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19996,
        "tokens": 10483662848,
        "learning_rate": 0.0002065593845090457,
        "gradient_norm": 0.35668864846229553,
        "train_loss": 3.0147364139556885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19997,
        "tokens": 10484187136,
        "learning_rate": 0.00020653390850166562,
        "gradient_norm": 0.34778285026550293,
        "train_loss": 2.976938009262085,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19998,
        "tokens": 10484711424,
        "learning_rate": 0.0002065084338840504,
        "gradient_norm": 0.3476108908653259,
        "train_loss": 2.997659206390381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19999,
        "tokens": 10485235712,
        "learning_rate": 0.00020648296065648662,
        "gradient_norm": 0.34668052196502686,
        "train_loss": 3.020853042602539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20000,
        "tokens": 10485760000,
        "learning_rate": 0.00020645748881926114,
        "gradient_norm": 0.34484580159187317,
        "train_loss": 3.006884813308716,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20001,
        "tokens": 10486284288,
        "learning_rate": 0.00020643201837266056,
        "gradient_norm": 0.34757882356643677,
        "train_loss": 3.010129690170288,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20002,
        "tokens": 10486808576,
        "learning_rate": 0.00020640654931697175,
        "gradient_norm": 0.3461344242095947,
        "train_loss": 3.05362606048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20003,
        "tokens": 10487332864,
        "learning_rate": 0.00020638108165248116,
        "gradient_norm": 0.34889519214630127,
        "train_loss": 3.0379509925842285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20004,
        "tokens": 10487857152,
        "learning_rate": 0.00020635561537947562,
        "gradient_norm": 0.3591824471950531,
        "train_loss": 3.100663661956787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20005,
        "tokens": 10488381440,
        "learning_rate": 0.00020633015049824186,
        "gradient_norm": 0.36767226457595825,
        "train_loss": 3.0480732917785645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20006,
        "tokens": 10488905728,
        "learning_rate": 0.0002063046870090663,
        "gradient_norm": 0.35442882776260376,
        "train_loss": 3.0264573097229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20007,
        "tokens": 10489430016,
        "learning_rate": 0.00020627922491223578,
        "gradient_norm": 0.3626779615879059,
        "train_loss": 3.0764498710632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20008,
        "tokens": 10489954304,
        "learning_rate": 0.0002062537642080367,
        "gradient_norm": 0.3948586583137512,
        "train_loss": 3.05999755859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20009,
        "tokens": 10490478592,
        "learning_rate": 0.00020622830489675588,
        "gradient_norm": 0.31848815083503723,
        "train_loss": 3.0143003463745117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20010,
        "tokens": 10491002880,
        "learning_rate": 0.00020620284697867963,
        "gradient_norm": 0.4156312644481659,
        "train_loss": 3.008401393890381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20011,
        "tokens": 10491527168,
        "learning_rate": 0.0002061773904540948,
        "gradient_norm": 0.3280363976955414,
        "train_loss": 3.0916099548339844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20012,
        "tokens": 10492051456,
        "learning_rate": 0.00020615193532328764,
        "gradient_norm": 0.36560359597206116,
        "train_loss": 3.0914316177368164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20013,
        "tokens": 10492575744,
        "learning_rate": 0.00020612648158654495,
        "gradient_norm": 0.38583481311798096,
        "train_loss": 3.0827131271362305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20014,
        "tokens": 10493100032,
        "learning_rate": 0.00020610102924415306,
        "gradient_norm": 0.3512824475765228,
        "train_loss": 3.0753188133239746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20015,
        "tokens": 10493624320,
        "learning_rate": 0.0002060755782963985,
        "gradient_norm": 0.33933785557746887,
        "train_loss": 3.0571789741516113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20016,
        "tokens": 10494148608,
        "learning_rate": 0.00020605012874356788,
        "gradient_norm": 0.35160863399505615,
        "train_loss": 3.1248464584350586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20017,
        "tokens": 10494672896,
        "learning_rate": 0.00020602468058594745,
        "gradient_norm": 0.37593334913253784,
        "train_loss": 3.0695271492004395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20018,
        "tokens": 10495197184,
        "learning_rate": 0.00020599923382382391,
        "gradient_norm": 0.3295590281486511,
        "train_loss": 3.054456949234009,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20019,
        "tokens": 10495721472,
        "learning_rate": 0.00020597378845748347,
        "gradient_norm": 0.35788270831108093,
        "train_loss": 3.086717128753662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20020,
        "tokens": 10496245760,
        "learning_rate": 0.00020594834448721272,
        "gradient_norm": 0.36669713258743286,
        "train_loss": 3.101677417755127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20021,
        "tokens": 10496770048,
        "learning_rate": 0.00020592290191329788,
        "gradient_norm": 0.4287121295928955,
        "train_loss": 3.0904619693756104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20022,
        "tokens": 10497294336,
        "learning_rate": 0.00020589746073602558,
        "gradient_norm": 0.41290146112442017,
        "train_loss": 3.046142816543579,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20023,
        "tokens": 10497818624,
        "learning_rate": 0.00020587202095568192,
        "gradient_norm": 0.3955894112586975,
        "train_loss": 3.0713183879852295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20024,
        "tokens": 10498342912,
        "learning_rate": 0.00020584658257255344,
        "gradient_norm": 0.4900203347206116,
        "train_loss": 3.024890422821045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20025,
        "tokens": 10498867200,
        "learning_rate": 0.0002058211455869265,
        "gradient_norm": 0.3893544673919678,
        "train_loss": 3.0905771255493164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20026,
        "tokens": 10499391488,
        "learning_rate": 0.00020579570999908726,
        "gradient_norm": 0.4469265639781952,
        "train_loss": 3.0794272422790527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20027,
        "tokens": 10499915776,
        "learning_rate": 0.00020577027580932224,
        "gradient_norm": 0.37407535314559937,
        "train_loss": 3.0051217079162598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20028,
        "tokens": 10500440064,
        "learning_rate": 0.0002057448430179175,
        "gradient_norm": 0.3871913552284241,
        "train_loss": 3.019892692565918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20029,
        "tokens": 10500964352,
        "learning_rate": 0.0002057194116251596,
        "gradient_norm": 0.3507048189640045,
        "train_loss": 3.0252954959869385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20030,
        "tokens": 10501488640,
        "learning_rate": 0.00020569398163133444,
        "gradient_norm": 0.3783590495586395,
        "train_loss": 3.0267486572265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20031,
        "tokens": 10502012928,
        "learning_rate": 0.00020566855303672866,
        "gradient_norm": 0.34363895654678345,
        "train_loss": 3.0152547359466553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20032,
        "tokens": 10502537216,
        "learning_rate": 0.00020564312584162814,
        "gradient_norm": 0.3864390254020691,
        "train_loss": 3.067627429962158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20033,
        "tokens": 10503061504,
        "learning_rate": 0.00020561770004631942,
        "gradient_norm": 0.38829368352890015,
        "train_loss": 3.051971435546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20034,
        "tokens": 10503585792,
        "learning_rate": 0.00020559227565108835,
        "gradient_norm": 0.36640533804893494,
        "train_loss": 3.0918195247650146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20035,
        "tokens": 10504110080,
        "learning_rate": 0.00020556685265622133,
        "gradient_norm": 0.36506131291389465,
        "train_loss": 3.1172947883605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20036,
        "tokens": 10504634368,
        "learning_rate": 0.00020554143106200464,
        "gradient_norm": 0.34690019488334656,
        "train_loss": 3.078547954559326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20037,
        "tokens": 10505158656,
        "learning_rate": 0.00020551601086872412,
        "gradient_norm": 0.4796335995197296,
        "train_loss": 3.0902810096740723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20038,
        "tokens": 10505682944,
        "learning_rate": 0.0002054905920766662,
        "gradient_norm": 0.44869253039360046,
        "train_loss": 3.0628833770751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20039,
        "tokens": 10506207232,
        "learning_rate": 0.00020546517468611675,
        "gradient_norm": 0.34312620759010315,
        "train_loss": 3.0604822635650635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20040,
        "tokens": 10506731520,
        "learning_rate": 0.00020543975869736212,
        "gradient_norm": 0.4095273017883301,
        "train_loss": 3.0590996742248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20041,
        "tokens": 10507255808,
        "learning_rate": 0.00020541434411068817,
        "gradient_norm": 0.3678300678730011,
        "train_loss": 3.0592403411865234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20042,
        "tokens": 10507780096,
        "learning_rate": 0.0002053889309263812,
        "gradient_norm": 0.36750105023384094,
        "train_loss": 3.04325008392334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20043,
        "tokens": 10508304384,
        "learning_rate": 0.000205363519144727,
        "gradient_norm": 0.3653196394443512,
        "train_loss": 3.0808334350585938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20044,
        "tokens": 10508828672,
        "learning_rate": 0.00020533810876601177,
        "gradient_norm": 0.39737874269485474,
        "train_loss": 3.0530271530151367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20045,
        "tokens": 10509352960,
        "learning_rate": 0.00020531269979052165,
        "gradient_norm": 0.37726590037345886,
        "train_loss": 3.104581356048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20046,
        "tokens": 10509877248,
        "learning_rate": 0.00020528729221854237,
        "gradient_norm": 0.37665730714797974,
        "train_loss": 2.990302085876465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20047,
        "tokens": 10510401536,
        "learning_rate": 0.00020526188605036024,
        "gradient_norm": 0.46475812792778015,
        "train_loss": 3.098008155822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20048,
        "tokens": 10510925824,
        "learning_rate": 0.0002052364812862609,
        "gradient_norm": 0.36989155411720276,
        "train_loss": 3.0519251823425293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20049,
        "tokens": 10511450112,
        "learning_rate": 0.00020521107792653064,
        "gradient_norm": 0.373874694108963,
        "train_loss": 3.0670628547668457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20050,
        "tokens": 10511974400,
        "learning_rate": 0.00020518567597145512,
        "gradient_norm": 0.35269367694854736,
        "train_loss": 3.051722288131714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20051,
        "tokens": 10512498688,
        "learning_rate": 0.00020516027542132048,
        "gradient_norm": 0.3480546474456787,
        "train_loss": 3.0557491779327393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20052,
        "tokens": 10513022976,
        "learning_rate": 0.0002051348762764125,
        "gradient_norm": 0.3328231871128082,
        "train_loss": 3.049473285675049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20053,
        "tokens": 10513547264,
        "learning_rate": 0.00020510947853701723,
        "gradient_norm": 0.3584510385990143,
        "train_loss": 3.058276653289795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20054,
        "tokens": 10514071552,
        "learning_rate": 0.00020508408220342038,
        "gradient_norm": 0.36547985672950745,
        "train_loss": 3.090186595916748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20055,
        "tokens": 10514595840,
        "learning_rate": 0.00020505868727590786,
        "gradient_norm": 0.37290695309638977,
        "train_loss": 3.054464817047119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20056,
        "tokens": 10515120128,
        "learning_rate": 0.00020503329375476566,
        "gradient_norm": 0.3538477420806885,
        "train_loss": 3.0748775005340576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20057,
        "tokens": 10515644416,
        "learning_rate": 0.0002050079016402794,
        "gradient_norm": 0.35448208451271057,
        "train_loss": 3.096219539642334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20058,
        "tokens": 10516168704,
        "learning_rate": 0.00020498251093273515,
        "gradient_norm": 0.3444080948829651,
        "train_loss": 3.0472488403320312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20059,
        "tokens": 10516692992,
        "learning_rate": 0.0002049571216324185,
        "gradient_norm": 0.363701194524765,
        "train_loss": 3.082207679748535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20060,
        "tokens": 10517217280,
        "learning_rate": 0.00020493173373961536,
        "gradient_norm": 0.35493695735931396,
        "train_loss": 3.035693883895874,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20061,
        "tokens": 10517741568,
        "learning_rate": 0.00020490634725461138,
        "gradient_norm": 0.3607635200023651,
        "train_loss": 3.0687179565429688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20062,
        "tokens": 10518265856,
        "learning_rate": 0.00020488096217769248,
        "gradient_norm": 0.414203405380249,
        "train_loss": 3.0225255489349365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20063,
        "tokens": 10518790144,
        "learning_rate": 0.00020485557850914422,
        "gradient_norm": 0.47354912757873535,
        "train_loss": 3.0654184818267822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20064,
        "tokens": 10519314432,
        "learning_rate": 0.00020483019624925242,
        "gradient_norm": 0.3590593934059143,
        "train_loss": 3.017045497894287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20065,
        "tokens": 10519838720,
        "learning_rate": 0.00020480481539830291,
        "gradient_norm": 0.4073062837123871,
        "train_loss": 3.0627853870391846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20066,
        "tokens": 10520363008,
        "learning_rate": 0.00020477943595658115,
        "gradient_norm": 0.34388962388038635,
        "train_loss": 3.0346810817718506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20067,
        "tokens": 10520887296,
        "learning_rate": 0.00020475405792437303,
        "gradient_norm": 0.4088703989982605,
        "train_loss": 3.1374993324279785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20068,
        "tokens": 10521411584,
        "learning_rate": 0.000204728681301964,
        "gradient_norm": 0.3909846246242523,
        "train_loss": 3.1163206100463867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20069,
        "tokens": 10521935872,
        "learning_rate": 0.00020470330608963994,
        "gradient_norm": 0.36063963174819946,
        "train_loss": 3.0709774494171143,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20070,
        "tokens": 10522460160,
        "learning_rate": 0.00020467793228768624,
        "gradient_norm": 0.3477613031864166,
        "train_loss": 3.022338628768921,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20071,
        "tokens": 10522984448,
        "learning_rate": 0.00020465255989638877,
        "gradient_norm": 0.3842507004737854,
        "train_loss": 3.070283889770508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20072,
        "tokens": 10523508736,
        "learning_rate": 0.00020462718891603283,
        "gradient_norm": 0.35119470953941345,
        "train_loss": 3.0214593410491943,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20073,
        "tokens": 10524033024,
        "learning_rate": 0.0002046018193469043,
        "gradient_norm": 0.37386375665664673,
        "train_loss": 3.052887201309204,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20074,
        "tokens": 10524557312,
        "learning_rate": 0.00020457645118928847,
        "gradient_norm": 0.34526771306991577,
        "train_loss": 3.0217859745025635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20075,
        "tokens": 10525081600,
        "learning_rate": 0.00020455108444347104,
        "gradient_norm": 0.3662945330142975,
        "train_loss": 3.131519317626953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20076,
        "tokens": 10525605888,
        "learning_rate": 0.00020452571910973763,
        "gradient_norm": 0.37282413244247437,
        "train_loss": 3.07828426361084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20077,
        "tokens": 10526130176,
        "learning_rate": 0.0002045003551883736,
        "gradient_norm": 0.36080577969551086,
        "train_loss": 3.0615437030792236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20078,
        "tokens": 10526654464,
        "learning_rate": 0.00020447499267966455,
        "gradient_norm": 0.35636404156684875,
        "train_loss": 3.098083972930908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20079,
        "tokens": 10527178752,
        "learning_rate": 0.00020444963158389588,
        "gradient_norm": 0.34057143330574036,
        "train_loss": 3.0464367866516113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20080,
        "tokens": 10527703040,
        "learning_rate": 0.0002044242719013532,
        "gradient_norm": 0.4177171289920807,
        "train_loss": 3.153578281402588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20081,
        "tokens": 10528227328,
        "learning_rate": 0.0002043989136323217,
        "gradient_norm": 0.35780754685401917,
        "train_loss": 3.017348051071167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20082,
        "tokens": 10528751616,
        "learning_rate": 0.0002043735567770872,
        "gradient_norm": 0.42265933752059937,
        "train_loss": 3.1033987998962402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20083,
        "tokens": 10529275904,
        "learning_rate": 0.00020434820133593477,
        "gradient_norm": 0.3898909091949463,
        "train_loss": 3.20589017868042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20084,
        "tokens": 10529800192,
        "learning_rate": 0.00020432284730915006,
        "gradient_norm": 0.42988452315330505,
        "train_loss": 3.0506250858306885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20085,
        "tokens": 10530324480,
        "learning_rate": 0.00020429749469701825,
        "gradient_norm": 0.3891924321651459,
        "train_loss": 3.03485369682312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20086,
        "tokens": 10530848768,
        "learning_rate": 0.00020427214349982498,
        "gradient_norm": 0.4088483154773712,
        "train_loss": 3.1087839603424072,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20087,
        "tokens": 10531373056,
        "learning_rate": 0.0002042467937178553,
        "gradient_norm": 0.45333781838417053,
        "train_loss": 3.0293006896972656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20088,
        "tokens": 10531897344,
        "learning_rate": 0.00020422144535139482,
        "gradient_norm": 0.5733054280281067,
        "train_loss": 3.142061710357666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20089,
        "tokens": 10532421632,
        "learning_rate": 0.0002041960984007287,
        "gradient_norm": 0.47238507866859436,
        "train_loss": 3.0386404991149902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20090,
        "tokens": 10532945920,
        "learning_rate": 0.00020417075286614239,
        "gradient_norm": 0.4827936887741089,
        "train_loss": 3.093626022338867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20091,
        "tokens": 10533470208,
        "learning_rate": 0.000204145408747921,
        "gradient_norm": 0.4656135141849518,
        "train_loss": 3.055264711380005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20092,
        "tokens": 10533994496,
        "learning_rate": 0.00020412006604635002,
        "gradient_norm": 0.4032822847366333,
        "train_loss": 3.108555793762207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20093,
        "tokens": 10534518784,
        "learning_rate": 0.0002040947247617145,
        "gradient_norm": 0.4064827859401703,
        "train_loss": 3.0721898078918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20094,
        "tokens": 10535043072,
        "learning_rate": 0.00020406938489429992,
        "gradient_norm": 0.38189777731895447,
        "train_loss": 3.0418245792388916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20095,
        "tokens": 10535567360,
        "learning_rate": 0.0002040440464443913,
        "gradient_norm": 0.3761948347091675,
        "train_loss": 3.063690185546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20096,
        "tokens": 10536091648,
        "learning_rate": 0.000204018709412274,
        "gradient_norm": 0.3801841735839844,
        "train_loss": 3.0917391777038574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20097,
        "tokens": 10536615936,
        "learning_rate": 0.00020399337379823309,
        "gradient_norm": 0.3559471368789673,
        "train_loss": 3.0588715076446533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20098,
        "tokens": 10537140224,
        "learning_rate": 0.00020396803960255394,
        "gradient_norm": 0.3482406735420227,
        "train_loss": 3.0781612396240234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20099,
        "tokens": 10537664512,
        "learning_rate": 0.00020394270682552146,
        "gradient_norm": 0.3351566791534424,
        "train_loss": 3.1235404014587402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20100,
        "tokens": 10538188800,
        "learning_rate": 0.00020391737546742112,
        "gradient_norm": 0.40131059288978577,
        "train_loss": 3.0301289558410645,
        "val_loss": 3.020932674407959,
        "hellaswag_acc": 0.2834096848964691,
        "hellaswag_acc_norm": 0.2942640781402588
    },
    {
        "step": 20101,
        "tokens": 10538713088,
        "learning_rate": 0.00020389204552853773,
        "gradient_norm": 0.40819811820983887,
        "train_loss": 3.1035122871398926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20102,
        "tokens": 10539237376,
        "learning_rate": 0.0002038667170091567,
        "gradient_norm": 0.36517322063446045,
        "train_loss": 3.055387020111084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20103,
        "tokens": 10539761664,
        "learning_rate": 0.00020384138990956288,
        "gradient_norm": 0.37934955954551697,
        "train_loss": 3.108379364013672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20104,
        "tokens": 10540285952,
        "learning_rate": 0.00020381606423004148,
        "gradient_norm": 0.3544059097766876,
        "train_loss": 3.016587257385254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20105,
        "tokens": 10540810240,
        "learning_rate": 0.00020379073997087768,
        "gradient_norm": 0.40648970007896423,
        "train_loss": 3.0618984699249268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20106,
        "tokens": 10541334528,
        "learning_rate": 0.00020376541713235628,
        "gradient_norm": 0.33625903725624084,
        "train_loss": 3.075310707092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20107,
        "tokens": 10541858816,
        "learning_rate": 0.00020374009571476264,
        "gradient_norm": 0.3612114489078522,
        "train_loss": 3.064047336578369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20108,
        "tokens": 10542383104,
        "learning_rate": 0.00020371477571838145,
        "gradient_norm": 0.35119104385375977,
        "train_loss": 3.1197474002838135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20109,
        "tokens": 10542907392,
        "learning_rate": 0.000203689457143498,
        "gradient_norm": 0.3802410066127777,
        "train_loss": 3.098494052886963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20110,
        "tokens": 10543431680,
        "learning_rate": 0.0002036641399903971,
        "gradient_norm": 0.4060882329940796,
        "train_loss": 3.070751905441284,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20111,
        "tokens": 10543955968,
        "learning_rate": 0.00020363882425936385,
        "gradient_norm": 0.4135667085647583,
        "train_loss": 3.0649006366729736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20112,
        "tokens": 10544480256,
        "learning_rate": 0.000203613509950683,
        "gradient_norm": 0.34363853931427,
        "train_loss": 3.0107779502868652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20113,
        "tokens": 10545004544,
        "learning_rate": 0.0002035881970646398,
        "gradient_norm": 0.438974529504776,
        "train_loss": 3.0802323818206787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20114,
        "tokens": 10545528832,
        "learning_rate": 0.0002035628856015189,
        "gradient_norm": 0.3500705063343048,
        "train_loss": 3.141167402267456,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20115,
        "tokens": 10546053120,
        "learning_rate": 0.00020353757556160532,
        "gradient_norm": 0.45523354411125183,
        "train_loss": 3.028031587600708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20116,
        "tokens": 10546577408,
        "learning_rate": 0.00020351226694518412,
        "gradient_norm": 0.38662248849868774,
        "train_loss": 3.0615739822387695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20117,
        "tokens": 10547101696,
        "learning_rate": 0.00020348695975253985,
        "gradient_norm": 0.364721417427063,
        "train_loss": 3.0107245445251465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20118,
        "tokens": 10547625984,
        "learning_rate": 0.00020346165398395772,
        "gradient_norm": 0.33750268816947937,
        "train_loss": 3.092621326446533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20119,
        "tokens": 10548150272,
        "learning_rate": 0.00020343634963972224,
        "gradient_norm": 0.3977682590484619,
        "train_loss": 3.0746216773986816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20120,
        "tokens": 10548674560,
        "learning_rate": 0.00020341104672011855,
        "gradient_norm": 0.3583545684814453,
        "train_loss": 3.0371336936950684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20121,
        "tokens": 10549198848,
        "learning_rate": 0.00020338574522543124,
        "gradient_norm": 0.36723610758781433,
        "train_loss": 3.037801742553711,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20122,
        "tokens": 10549723136,
        "learning_rate": 0.00020336044515594529,
        "gradient_norm": 0.3598414659500122,
        "train_loss": 3.0868053436279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20123,
        "tokens": 10550247424,
        "learning_rate": 0.00020333514651194525,
        "gradient_norm": 0.39463865756988525,
        "train_loss": 3.045982837677002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20124,
        "tokens": 10550771712,
        "learning_rate": 0.00020330984929371604,
        "gradient_norm": 0.3631785809993744,
        "train_loss": 3.08715558052063,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20125,
        "tokens": 10551296000,
        "learning_rate": 0.00020328455350154253,
        "gradient_norm": 0.38015347719192505,
        "train_loss": 3.0281455516815186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20126,
        "tokens": 10551820288,
        "learning_rate": 0.00020325925913570921,
        "gradient_norm": 0.35944974422454834,
        "train_loss": 3.0568454265594482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20127,
        "tokens": 10552344576,
        "learning_rate": 0.00020323396619650102,
        "gradient_norm": 0.4038812816143036,
        "train_loss": 3.002171516418457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20128,
        "tokens": 10552868864,
        "learning_rate": 0.00020320867468420246,
        "gradient_norm": 0.374625027179718,
        "train_loss": 3.098768472671509,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20129,
        "tokens": 10553393152,
        "learning_rate": 0.0002031833845990984,
        "gradient_norm": 0.3763216435909271,
        "train_loss": 2.9893131256103516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20130,
        "tokens": 10553917440,
        "learning_rate": 0.00020315809594147335,
        "gradient_norm": 0.34836575388908386,
        "train_loss": 3.068302869796753,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20131,
        "tokens": 10554441728,
        "learning_rate": 0.00020313280871161213,
        "gradient_norm": 0.3664296269416809,
        "train_loss": 3.1172571182250977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20132,
        "tokens": 10554966016,
        "learning_rate": 0.00020310752290979918,
        "gradient_norm": 0.37714293599128723,
        "train_loss": 3.064385414123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20133,
        "tokens": 10555490304,
        "learning_rate": 0.00020308223853631935,
        "gradient_norm": 0.3894024193286896,
        "train_loss": 3.072678565979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20134,
        "tokens": 10556014592,
        "learning_rate": 0.00020305695559145705,
        "gradient_norm": 0.3543907403945923,
        "train_loss": 3.069655418395996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20135,
        "tokens": 10556538880,
        "learning_rate": 0.0002030316740754969,
        "gradient_norm": 0.3835683763027191,
        "train_loss": 3.0851478576660156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20136,
        "tokens": 10557063168,
        "learning_rate": 0.00020300639398872369,
        "gradient_norm": 0.39606472849845886,
        "train_loss": 3.0486109256744385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20137,
        "tokens": 10557587456,
        "learning_rate": 0.00020298111533142169,
        "gradient_norm": 0.33864259719848633,
        "train_loss": 3.0444540977478027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20138,
        "tokens": 10558111744,
        "learning_rate": 0.00020295583810387569,
        "gradient_norm": 0.3963087797164917,
        "train_loss": 3.082005023956299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20139,
        "tokens": 10558636032,
        "learning_rate": 0.00020293056230636996,
        "gradient_norm": 0.44553497433662415,
        "train_loss": 3.1156716346740723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20140,
        "tokens": 10559160320,
        "learning_rate": 0.00020290528793918925,
        "gradient_norm": 0.4258688986301422,
        "train_loss": 3.1093671321868896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20141,
        "tokens": 10559684608,
        "learning_rate": 0.0002028800150026179,
        "gradient_norm": 0.41473516821861267,
        "train_loss": 3.1265792846679688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20142,
        "tokens": 10560208896,
        "learning_rate": 0.00020285474349694045,
        "gradient_norm": 0.45507797598838806,
        "train_loss": 3.0672287940979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20143,
        "tokens": 10560733184,
        "learning_rate": 0.00020282947342244132,
        "gradient_norm": 0.36395925283432007,
        "train_loss": 3.0661418437957764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20144,
        "tokens": 10561257472,
        "learning_rate": 0.00020280420477940497,
        "gradient_norm": 0.4045526385307312,
        "train_loss": 3.0921640396118164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20145,
        "tokens": 10561781760,
        "learning_rate": 0.00020277893756811597,
        "gradient_norm": 0.3821313679218292,
        "train_loss": 3.097377300262451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20146,
        "tokens": 10562306048,
        "learning_rate": 0.0002027536717888585,
        "gradient_norm": 0.3776462972164154,
        "train_loss": 3.1094212532043457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20147,
        "tokens": 10562830336,
        "learning_rate": 0.00020272840744191717,
        "gradient_norm": 0.432971715927124,
        "train_loss": 3.05765700340271,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20148,
        "tokens": 10563354624,
        "learning_rate": 0.00020270314452757617,
        "gradient_norm": 0.38283655047416687,
        "train_loss": 3.0525009632110596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20149,
        "tokens": 10563878912,
        "learning_rate": 0.00020267788304612007,
        "gradient_norm": 0.4673682451248169,
        "train_loss": 3.074432849884033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20150,
        "tokens": 10564403200,
        "learning_rate": 0.00020265262299783298,
        "gradient_norm": 0.3865368366241455,
        "train_loss": 3.0882883071899414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20151,
        "tokens": 10564927488,
        "learning_rate": 0.00020262736438299945,
        "gradient_norm": 0.3612258732318878,
        "train_loss": 3.0591492652893066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20152,
        "tokens": 10565451776,
        "learning_rate": 0.00020260210720190363,
        "gradient_norm": 0.42374399304389954,
        "train_loss": 3.103259801864624,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20153,
        "tokens": 10565976064,
        "learning_rate": 0.00020257685145483,
        "gradient_norm": 0.417906254529953,
        "train_loss": 3.0423264503479004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20154,
        "tokens": 10566500352,
        "learning_rate": 0.00020255159714206264,
        "gradient_norm": 0.4240078926086426,
        "train_loss": 3.065885543823242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20155,
        "tokens": 10567024640,
        "learning_rate": 0.00020252634426388592,
        "gradient_norm": 0.3421579599380493,
        "train_loss": 3.065168857574463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20156,
        "tokens": 10567548928,
        "learning_rate": 0.00020250109282058418,
        "gradient_norm": 0.3579462170600891,
        "train_loss": 3.0035853385925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20157,
        "tokens": 10568073216,
        "learning_rate": 0.0002024758428124415,
        "gradient_norm": 0.33976611495018005,
        "train_loss": 3.0360851287841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20158,
        "tokens": 10568597504,
        "learning_rate": 0.00020245059423974228,
        "gradient_norm": 0.3561958074569702,
        "train_loss": 3.0570740699768066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20159,
        "tokens": 10569121792,
        "learning_rate": 0.0002024253471027705,
        "gradient_norm": 0.3652421832084656,
        "train_loss": 3.0752675533294678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20160,
        "tokens": 10569646080,
        "learning_rate": 0.00020240010140181055,
        "gradient_norm": 0.3608878552913666,
        "train_loss": 3.0163609981536865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20161,
        "tokens": 10570170368,
        "learning_rate": 0.00020237485713714645,
        "gradient_norm": 0.41640791296958923,
        "train_loss": 3.132052421569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20162,
        "tokens": 10570694656,
        "learning_rate": 0.0002023496143090625,
        "gradient_norm": 0.37921491265296936,
        "train_loss": 3.0331153869628906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20163,
        "tokens": 10571218944,
        "learning_rate": 0.00020232437291784267,
        "gradient_norm": 0.3583618104457855,
        "train_loss": 3.091858386993408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20164,
        "tokens": 10571743232,
        "learning_rate": 0.00020229913296377115,
        "gradient_norm": 0.3799669146537781,
        "train_loss": 3.025434970855713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20165,
        "tokens": 10572267520,
        "learning_rate": 0.00020227389444713218,
        "gradient_norm": 0.35654497146606445,
        "train_loss": 3.0825393199920654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20166,
        "tokens": 10572791808,
        "learning_rate": 0.00020224865736820962,
        "gradient_norm": 0.4043024480342865,
        "train_loss": 3.0966098308563232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20167,
        "tokens": 10573316096,
        "learning_rate": 0.00020222342172728785,
        "gradient_norm": 0.39897680282592773,
        "train_loss": 3.081146478652954,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20168,
        "tokens": 10573840384,
        "learning_rate": 0.0002021981875246506,
        "gradient_norm": 0.38140779733657837,
        "train_loss": 3.018425941467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20169,
        "tokens": 10574364672,
        "learning_rate": 0.00020217295476058212,
        "gradient_norm": 0.40685373544692993,
        "train_loss": 3.065708637237549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20170,
        "tokens": 10574888960,
        "learning_rate": 0.00020214772343536634,
        "gradient_norm": 0.3897615373134613,
        "train_loss": 3.092689275741577,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20171,
        "tokens": 10575413248,
        "learning_rate": 0.00020212249354928735,
        "gradient_norm": 0.352809339761734,
        "train_loss": 3.050950050354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20172,
        "tokens": 10575937536,
        "learning_rate": 0.00020209726510262904,
        "gradient_norm": 0.35817858576774597,
        "train_loss": 3.105320453643799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20173,
        "tokens": 10576461824,
        "learning_rate": 0.00020207203809567554,
        "gradient_norm": 0.35282042622566223,
        "train_loss": 3.0332775115966797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20174,
        "tokens": 10576986112,
        "learning_rate": 0.0002020468125287106,
        "gradient_norm": 0.3586057126522064,
        "train_loss": 3.0525412559509277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20175,
        "tokens": 10577510400,
        "learning_rate": 0.00020202158840201828,
        "gradient_norm": 0.3869030475616455,
        "train_loss": 3.151488780975342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20176,
        "tokens": 10578034688,
        "learning_rate": 0.0002019963657158826,
        "gradient_norm": 0.32796069979667664,
        "train_loss": 3.0800485610961914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20177,
        "tokens": 10578558976,
        "learning_rate": 0.00020197114447058733,
        "gradient_norm": 0.3914817273616791,
        "train_loss": 2.9890377521514893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20178,
        "tokens": 10579083264,
        "learning_rate": 0.0002019459246664165,
        "gradient_norm": 0.3572460412979126,
        "train_loss": 3.10013747215271,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20179,
        "tokens": 10579607552,
        "learning_rate": 0.0002019207063036538,
        "gradient_norm": 0.3771851062774658,
        "train_loss": 3.0935654640197754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20180,
        "tokens": 10580131840,
        "learning_rate": 0.0002018954893825833,
        "gradient_norm": 0.4186815321445465,
        "train_loss": 3.019824743270874,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20181,
        "tokens": 10580656128,
        "learning_rate": 0.0002018702739034887,
        "gradient_norm": 0.3351947069168091,
        "train_loss": 3.049748659133911,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20182,
        "tokens": 10581180416,
        "learning_rate": 0.00020184505986665393,
        "gradient_norm": 0.34816476702690125,
        "train_loss": 3.0292012691497803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20183,
        "tokens": 10581704704,
        "learning_rate": 0.00020181984727236268,
        "gradient_norm": 0.3922405540943146,
        "train_loss": 3.1264688968658447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20184,
        "tokens": 10582228992,
        "learning_rate": 0.00020179463612089894,
        "gradient_norm": 0.3634330630302429,
        "train_loss": 3.128232002258301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20185,
        "tokens": 10582753280,
        "learning_rate": 0.00020176942641254625,
        "gradient_norm": 0.354562371969223,
        "train_loss": 3.046814203262329,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20186,
        "tokens": 10583277568,
        "learning_rate": 0.00020174421814758863,
        "gradient_norm": 0.387363463640213,
        "train_loss": 3.0959558486938477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20187,
        "tokens": 10583801856,
        "learning_rate": 0.00020171901132630965,
        "gradient_norm": 0.3848511576652527,
        "train_loss": 3.066070079803467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20188,
        "tokens": 10584326144,
        "learning_rate": 0.00020169380594899317,
        "gradient_norm": 0.35233092308044434,
        "train_loss": 3.093550682067871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20189,
        "tokens": 10584850432,
        "learning_rate": 0.00020166860201592272,
        "gradient_norm": 0.3914946913719177,
        "train_loss": 3.04325532913208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20190,
        "tokens": 10585374720,
        "learning_rate": 0.00020164339952738223,
        "gradient_norm": 0.36336421966552734,
        "train_loss": 3.054847002029419,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20191,
        "tokens": 10585899008,
        "learning_rate": 0.0002016181984836552,
        "gradient_norm": 0.33730971813201904,
        "train_loss": 3.034050226211548,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20192,
        "tokens": 10586423296,
        "learning_rate": 0.0002015929988850255,
        "gradient_norm": 0.36139118671417236,
        "train_loss": 3.073881149291992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20193,
        "tokens": 10586947584,
        "learning_rate": 0.0002015678007317765,
        "gradient_norm": 0.3494487404823303,
        "train_loss": 3.1156768798828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20194,
        "tokens": 10587471872,
        "learning_rate": 0.00020154260402419202,
        "gradient_norm": 0.3484087288379669,
        "train_loss": 3.1245172023773193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20195,
        "tokens": 10587996160,
        "learning_rate": 0.0002015174087625558,
        "gradient_norm": 0.37641987204551697,
        "train_loss": 3.0231289863586426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20196,
        "tokens": 10588520448,
        "learning_rate": 0.00020149221494715117,
        "gradient_norm": 0.3428724706172943,
        "train_loss": 3.0358400344848633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20197,
        "tokens": 10589044736,
        "learning_rate": 0.00020146702257826195,
        "gradient_norm": 0.37101733684539795,
        "train_loss": 3.0608057975769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20198,
        "tokens": 10589569024,
        "learning_rate": 0.00020144183165617149,
        "gradient_norm": 0.36517858505249023,
        "train_loss": 3.071665048599243,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20199,
        "tokens": 10590093312,
        "learning_rate": 0.0002014166421811636,
        "gradient_norm": 0.3393898606300354,
        "train_loss": 3.071469783782959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20200,
        "tokens": 10590617600,
        "learning_rate": 0.00020139145415352155,
        "gradient_norm": 0.3880695104598999,
        "train_loss": 3.022413730621338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20201,
        "tokens": 10591141888,
        "learning_rate": 0.00020136626757352917,
        "gradient_norm": 0.36417487263679504,
        "train_loss": 3.091926336288452,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20202,
        "tokens": 10591666176,
        "learning_rate": 0.00020134108244146962,
        "gradient_norm": 0.3958137035369873,
        "train_loss": 3.0389463901519775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20203,
        "tokens": 10592190464,
        "learning_rate": 0.00020131589875762668,
        "gradient_norm": 0.35219287872314453,
        "train_loss": 3.1027112007141113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20204,
        "tokens": 10592714752,
        "learning_rate": 0.0002012907165222836,
        "gradient_norm": 0.35517051815986633,
        "train_loss": 3.0760605335235596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20205,
        "tokens": 10593239040,
        "learning_rate": 0.0002012655357357241,
        "gradient_norm": 0.39207544922828674,
        "train_loss": 3.0685648918151855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20206,
        "tokens": 10593763328,
        "learning_rate": 0.0002012403563982313,
        "gradient_norm": 0.39151009917259216,
        "train_loss": 3.0669643878936768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20207,
        "tokens": 10594287616,
        "learning_rate": 0.00020121517851008896,
        "gradient_norm": 0.3428646922111511,
        "train_loss": 3.07867431640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20208,
        "tokens": 10594811904,
        "learning_rate": 0.00020119000207158017,
        "gradient_norm": 0.39827024936676025,
        "train_loss": 3.0419936180114746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20209,
        "tokens": 10595336192,
        "learning_rate": 0.0002011648270829886,
        "gradient_norm": 0.3918312191963196,
        "train_loss": 3.0721044540405273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20210,
        "tokens": 10595860480,
        "learning_rate": 0.00020113965354459737,
        "gradient_norm": 0.3867076635360718,
        "train_loss": 3.0304219722747803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20211,
        "tokens": 10596384768,
        "learning_rate": 0.00020111448145669012,
        "gradient_norm": 0.36357781291007996,
        "train_loss": 3.049326181411743,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20212,
        "tokens": 10596909056,
        "learning_rate": 0.00020108931081954987,
        "gradient_norm": 0.36760973930358887,
        "train_loss": 3.05226993560791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20213,
        "tokens": 10597433344,
        "learning_rate": 0.00020106414163346018,
        "gradient_norm": 0.3566422462463379,
        "train_loss": 3.0491552352905273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20214,
        "tokens": 10597957632,
        "learning_rate": 0.00020103897389870434,
        "gradient_norm": 0.399501234292984,
        "train_loss": 3.095252513885498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20215,
        "tokens": 10598481920,
        "learning_rate": 0.00020101380761556554,
        "gradient_norm": 0.3670816421508789,
        "train_loss": 3.0893170833587646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20216,
        "tokens": 10599006208,
        "learning_rate": 0.0002009886427843272,
        "gradient_norm": 0.33566367626190186,
        "train_loss": 3.025209665298462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20217,
        "tokens": 10599530496,
        "learning_rate": 0.00020096347940527244,
        "gradient_norm": 0.38492289185523987,
        "train_loss": 3.0764451026916504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20218,
        "tokens": 10600054784,
        "learning_rate": 0.00020093831747868462,
        "gradient_norm": 0.344901978969574,
        "train_loss": 3.0705718994140625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20219,
        "tokens": 10600579072,
        "learning_rate": 0.00020091315700484683,
        "gradient_norm": 0.3484625220298767,
        "train_loss": 3.0229554176330566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20220,
        "tokens": 10601103360,
        "learning_rate": 0.0002008879979840425,
        "gradient_norm": 0.3355274796485901,
        "train_loss": 3.0580222606658936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20221,
        "tokens": 10601627648,
        "learning_rate": 0.00020086284041655457,
        "gradient_norm": 0.34091588854789734,
        "train_loss": 3.073697566986084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20222,
        "tokens": 10602151936,
        "learning_rate": 0.00020083768430266647,
        "gradient_norm": 0.4786936342716217,
        "train_loss": 3.154834270477295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20223,
        "tokens": 10602676224,
        "learning_rate": 0.0002008125296426611,
        "gradient_norm": 0.42615750432014465,
        "train_loss": 3.061445713043213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20224,
        "tokens": 10603200512,
        "learning_rate": 0.00020078737643682178,
        "gradient_norm": 0.37680885195732117,
        "train_loss": 3.075361728668213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20225,
        "tokens": 10603724800,
        "learning_rate": 0.00020076222468543166,
        "gradient_norm": 0.36862337589263916,
        "train_loss": 3.073768138885498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20226,
        "tokens": 10604249088,
        "learning_rate": 0.00020073707438877375,
        "gradient_norm": 0.34972766041755676,
        "train_loss": 3.0710537433624268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20227,
        "tokens": 10604773376,
        "learning_rate": 0.0002007119255471313,
        "gradient_norm": 0.379822313785553,
        "train_loss": 3.0596446990966797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20228,
        "tokens": 10605297664,
        "learning_rate": 0.00020068677816078716,
        "gradient_norm": 0.34950435161590576,
        "train_loss": 3.0932846069335938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20229,
        "tokens": 10605821952,
        "learning_rate": 0.0002006616322300246,
        "gradient_norm": 0.44160082936286926,
        "train_loss": 3.2127604484558105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20230,
        "tokens": 10606346240,
        "learning_rate": 0.00020063648775512654,
        "gradient_norm": 0.474742591381073,
        "train_loss": 3.0566205978393555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20231,
        "tokens": 10606870528,
        "learning_rate": 0.00020061134473637617,
        "gradient_norm": 0.3836672604084015,
        "train_loss": 3.0911240577697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20232,
        "tokens": 10607394816,
        "learning_rate": 0.00020058620317405624,
        "gradient_norm": 0.42471379041671753,
        "train_loss": 3.0763792991638184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20233,
        "tokens": 10607919104,
        "learning_rate": 0.00020056106306845,
        "gradient_norm": 0.3920557200908661,
        "train_loss": 3.0631537437438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20234,
        "tokens": 10608443392,
        "learning_rate": 0.00020053592441984038,
        "gradient_norm": 0.4066503345966339,
        "train_loss": 3.0949695110321045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20235,
        "tokens": 10608967680,
        "learning_rate": 0.00020051078722851026,
        "gradient_norm": 0.4287206828594208,
        "train_loss": 3.009212017059326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20236,
        "tokens": 10609491968,
        "learning_rate": 0.00020048565149474268,
        "gradient_norm": 0.38818198442459106,
        "train_loss": 3.0690078735351562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20237,
        "tokens": 10610016256,
        "learning_rate": 0.0002004605172188205,
        "gradient_norm": 0.4373916685581207,
        "train_loss": 3.1395998001098633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20238,
        "tokens": 10610540544,
        "learning_rate": 0.00020043538440102674,
        "gradient_norm": 0.4437594413757324,
        "train_loss": 3.1267056465148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20239,
        "tokens": 10611064832,
        "learning_rate": 0.00020041025304164413,
        "gradient_norm": 0.4199993312358856,
        "train_loss": 3.048496723175049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20240,
        "tokens": 10611589120,
        "learning_rate": 0.00020038512314095577,
        "gradient_norm": 0.44130030274391174,
        "train_loss": 3.065824508666992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20241,
        "tokens": 10612113408,
        "learning_rate": 0.00020035999469924433,
        "gradient_norm": 0.37731972336769104,
        "train_loss": 3.0635111331939697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20242,
        "tokens": 10612637696,
        "learning_rate": 0.00020033486771679285,
        "gradient_norm": 0.42167356610298157,
        "train_loss": 3.0459024906158447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20243,
        "tokens": 10613161984,
        "learning_rate": 0.00020030974219388393,
        "gradient_norm": 0.36994174122810364,
        "train_loss": 3.034313440322876,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20244,
        "tokens": 10613686272,
        "learning_rate": 0.00020028461813080054,
        "gradient_norm": 0.3739207983016968,
        "train_loss": 3.042511224746704,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20245,
        "tokens": 10614210560,
        "learning_rate": 0.0002002594955278256,
        "gradient_norm": 0.34254634380340576,
        "train_loss": 3.0607969760894775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20246,
        "tokens": 10614734848,
        "learning_rate": 0.00020023437438524162,
        "gradient_norm": 0.40088075399398804,
        "train_loss": 3.0426764488220215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20247,
        "tokens": 10615259136,
        "learning_rate": 0.00020020925470333166,
        "gradient_norm": 0.356906533241272,
        "train_loss": 3.0989837646484375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20248,
        "tokens": 10615783424,
        "learning_rate": 0.0002001841364823782,
        "gradient_norm": 0.3465806841850281,
        "train_loss": 3.057764768600464,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20249,
        "tokens": 10616307712,
        "learning_rate": 0.00020015901972266417,
        "gradient_norm": 0.3770541250705719,
        "train_loss": 3.0239052772521973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20250,
        "tokens": 10616832000,
        "learning_rate": 0.00020013390442447218,
        "gradient_norm": 0.3569108545780182,
        "train_loss": 3.115401268005371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20251,
        "tokens": 10617356288,
        "learning_rate": 0.00020010879058808504,
        "gradient_norm": 0.3830646276473999,
        "train_loss": 3.034506320953369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20252,
        "tokens": 10617880576,
        "learning_rate": 0.0002000836782137853,
        "gradient_norm": 0.38595154881477356,
        "train_loss": 3.0729000568389893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20253,
        "tokens": 10618404864,
        "learning_rate": 0.0002000585673018557,
        "gradient_norm": 0.3922249376773834,
        "train_loss": 3.1154985427856445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20254,
        "tokens": 10618929152,
        "learning_rate": 0.000200033457852579,
        "gradient_norm": 0.37725016474723816,
        "train_loss": 3.087430238723755,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20255,
        "tokens": 10619453440,
        "learning_rate": 0.00020000834986623763,
        "gradient_norm": 0.406141072511673,
        "train_loss": 3.090542793273926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20256,
        "tokens": 10619977728,
        "learning_rate": 0.00019998324334311444,
        "gradient_norm": 0.34283116459846497,
        "train_loss": 3.0403308868408203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20257,
        "tokens": 10620502016,
        "learning_rate": 0.00019995813828349178,
        "gradient_norm": 0.38635578751564026,
        "train_loss": 3.0530757904052734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20258,
        "tokens": 10621026304,
        "learning_rate": 0.00019993303468765253,
        "gradient_norm": 0.3458768427371979,
        "train_loss": 3.045747756958008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20259,
        "tokens": 10621550592,
        "learning_rate": 0.000199907932555879,
        "gradient_norm": 0.37494948506355286,
        "train_loss": 3.041161060333252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20260,
        "tokens": 10622074880,
        "learning_rate": 0.0001998828318884539,
        "gradient_norm": 0.3516821563243866,
        "train_loss": 3.026538372039795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20261,
        "tokens": 10622599168,
        "learning_rate": 0.00019985773268565968,
        "gradient_norm": 0.3604566752910614,
        "train_loss": 3.0610857009887695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20262,
        "tokens": 10623123456,
        "learning_rate": 0.00019983263494777897,
        "gradient_norm": 0.3484675884246826,
        "train_loss": 3.028562068939209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20263,
        "tokens": 10623647744,
        "learning_rate": 0.00019980753867509415,
        "gradient_norm": 0.35359910130500793,
        "train_loss": 3.0682005882263184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20264,
        "tokens": 10624172032,
        "learning_rate": 0.00019978244386788772,
        "gradient_norm": 0.3730498254299164,
        "train_loss": 3.078953266143799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20265,
        "tokens": 10624696320,
        "learning_rate": 0.00019975735052644232,
        "gradient_norm": 0.40691104531288147,
        "train_loss": 3.0705060958862305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20266,
        "tokens": 10625220608,
        "learning_rate": 0.0001997322586510402,
        "gradient_norm": 0.3764660060405731,
        "train_loss": 2.979811191558838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20267,
        "tokens": 10625744896,
        "learning_rate": 0.000199707168241964,
        "gradient_norm": 0.3699245750904083,
        "train_loss": 3.0242486000061035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20268,
        "tokens": 10626269184,
        "learning_rate": 0.00019968207929949591,
        "gradient_norm": 0.3621784448623657,
        "train_loss": 3.0961456298828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20269,
        "tokens": 10626793472,
        "learning_rate": 0.00019965699182391858,
        "gradient_norm": 0.36560243368148804,
        "train_loss": 3.059493064880371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20270,
        "tokens": 10627317760,
        "learning_rate": 0.00019963190581551418,
        "gradient_norm": 0.3781253695487976,
        "train_loss": 3.0655012130737305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20271,
        "tokens": 10627842048,
        "learning_rate": 0.0001996068212745653,
        "gradient_norm": 0.376296728849411,
        "train_loss": 3.01770281791687,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20272,
        "tokens": 10628366336,
        "learning_rate": 0.00019958173820135407,
        "gradient_norm": 0.37481889128685,
        "train_loss": 3.0595855712890625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20273,
        "tokens": 10628890624,
        "learning_rate": 0.00019955665659616298,
        "gradient_norm": 0.3357158899307251,
        "train_loss": 3.0530214309692383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20274,
        "tokens": 10629414912,
        "learning_rate": 0.00019953157645927438,
        "gradient_norm": 0.3381960690021515,
        "train_loss": 3.023709297180176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20275,
        "tokens": 10629939200,
        "learning_rate": 0.00019950649779097043,
        "gradient_norm": 0.3571634590625763,
        "train_loss": 3.0641422271728516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20276,
        "tokens": 10630463488,
        "learning_rate": 0.0001994814205915336,
        "gradient_norm": 0.3363882005214691,
        "train_loss": 3.0336756706237793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20277,
        "tokens": 10630987776,
        "learning_rate": 0.00019945634486124601,
        "gradient_norm": 0.3549391031265259,
        "train_loss": 3.0317373275756836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20278,
        "tokens": 10631512064,
        "learning_rate": 0.00019943127060039007,
        "gradient_norm": 0.3194608688354492,
        "train_loss": 3.012002944946289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20279,
        "tokens": 10632036352,
        "learning_rate": 0.00019940619780924783,
        "gradient_norm": 0.37541458010673523,
        "train_loss": 3.0848162174224854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20280,
        "tokens": 10632560640,
        "learning_rate": 0.00019938112648810175,
        "gradient_norm": 0.3699477016925812,
        "train_loss": 2.9904277324676514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20281,
        "tokens": 10633084928,
        "learning_rate": 0.00019935605663723378,
        "gradient_norm": 0.3299559950828552,
        "train_loss": 3.0408942699432373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20282,
        "tokens": 10633609216,
        "learning_rate": 0.00019933098825692638,
        "gradient_norm": 0.34802502393722534,
        "train_loss": 3.0618295669555664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20283,
        "tokens": 10634133504,
        "learning_rate": 0.00019930592134746148,
        "gradient_norm": 0.33596518635749817,
        "train_loss": 3.1022276878356934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20284,
        "tokens": 10634657792,
        "learning_rate": 0.0001992808559091213,
        "gradient_norm": 0.3785504102706909,
        "train_loss": 3.0504424571990967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20285,
        "tokens": 10635182080,
        "learning_rate": 0.00019925579194218822,
        "gradient_norm": 0.37305811047554016,
        "train_loss": 3.099012851715088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20286,
        "tokens": 10635706368,
        "learning_rate": 0.000199230729446944,
        "gradient_norm": 0.41418346762657166,
        "train_loss": 3.2014410495758057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20287,
        "tokens": 10636230656,
        "learning_rate": 0.00019920566842367108,
        "gradient_norm": 0.49676257371902466,
        "train_loss": 3.0454483032226562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20288,
        "tokens": 10636754944,
        "learning_rate": 0.00019918060887265127,
        "gradient_norm": 0.5209616422653198,
        "train_loss": 2.907614231109619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20289,
        "tokens": 10637279232,
        "learning_rate": 0.00019915555079416688,
        "gradient_norm": 0.4456278681755066,
        "train_loss": 3.0616297721862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20290,
        "tokens": 10637803520,
        "learning_rate": 0.00019913049418849975,
        "gradient_norm": 0.42671045660972595,
        "train_loss": 3.0410568714141846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20291,
        "tokens": 10638327808,
        "learning_rate": 0.0001991054390559322,
        "gradient_norm": 0.49212250113487244,
        "train_loss": 3.1306354999542236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20292,
        "tokens": 10638852096,
        "learning_rate": 0.00019908038539674593,
        "gradient_norm": 0.42441388964653015,
        "train_loss": 3.0792489051818848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20293,
        "tokens": 10639376384,
        "learning_rate": 0.0001990553332112233,
        "gradient_norm": 0.465762197971344,
        "train_loss": 3.0333261489868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20294,
        "tokens": 10639900672,
        "learning_rate": 0.00019903028249964593,
        "gradient_norm": 0.4527877867221832,
        "train_loss": 3.040503978729248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20295,
        "tokens": 10640424960,
        "learning_rate": 0.00019900523326229613,
        "gradient_norm": 0.4269656836986542,
        "train_loss": 3.055002450942993,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20296,
        "tokens": 10640949248,
        "learning_rate": 0.00019898018549945564,
        "gradient_norm": 0.39200201630592346,
        "train_loss": 3.0666487216949463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20297,
        "tokens": 10641473536,
        "learning_rate": 0.00019895513921140654,
        "gradient_norm": 0.458639919757843,
        "train_loss": 3.089254140853882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20298,
        "tokens": 10641997824,
        "learning_rate": 0.00019893009439843064,
        "gradient_norm": 0.38516533374786377,
        "train_loss": 3.0008187294006348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20299,
        "tokens": 10642522112,
        "learning_rate": 0.00019890505106081,
        "gradient_norm": 0.4120883047580719,
        "train_loss": 3.0278971195220947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20300,
        "tokens": 10643046400,
        "learning_rate": 0.00019888000919882632,
        "gradient_norm": 0.4124012589454651,
        "train_loss": 3.0670933723449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20301,
        "tokens": 10643570688,
        "learning_rate": 0.00019885496881276167,
        "gradient_norm": 0.3737305700778961,
        "train_loss": 3.0029854774475098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20302,
        "tokens": 10644094976,
        "learning_rate": 0.00019882992990289774,
        "gradient_norm": 0.41516977548599243,
        "train_loss": 3.057394504547119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20303,
        "tokens": 10644619264,
        "learning_rate": 0.00019880489246951655,
        "gradient_norm": 0.3599044382572174,
        "train_loss": 3.0758395195007324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20304,
        "tokens": 10645143552,
        "learning_rate": 0.00019877985651289972,
        "gradient_norm": 0.4107096195220947,
        "train_loss": 3.034433364868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20305,
        "tokens": 10645667840,
        "learning_rate": 0.00019875482203332928,
        "gradient_norm": 0.3366740643978119,
        "train_loss": 3.0792689323425293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20306,
        "tokens": 10646192128,
        "learning_rate": 0.00019872978903108683,
        "gradient_norm": 0.38592952489852905,
        "train_loss": 3.0814876556396484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20307,
        "tokens": 10646716416,
        "learning_rate": 0.00019870475750645436,
        "gradient_norm": 0.373145192861557,
        "train_loss": 3.0349910259246826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20308,
        "tokens": 10647240704,
        "learning_rate": 0.00019867972745971337,
        "gradient_norm": 0.3617187440395355,
        "train_loss": 3.0910396575927734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20309,
        "tokens": 10647764992,
        "learning_rate": 0.00019865469889114584,
        "gradient_norm": 0.3448333442211151,
        "train_loss": 3.0782408714294434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20310,
        "tokens": 10648289280,
        "learning_rate": 0.0001986296718010333,
        "gradient_norm": 0.4153343439102173,
        "train_loss": 3.000568389892578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20311,
        "tokens": 10648813568,
        "learning_rate": 0.00019860464618965768,
        "gradient_norm": 0.39896687865257263,
        "train_loss": 3.0874829292297363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20312,
        "tokens": 10649337856,
        "learning_rate": 0.0001985796220573005,
        "gradient_norm": 0.36343643069267273,
        "train_loss": 2.9877753257751465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20313,
        "tokens": 10649862144,
        "learning_rate": 0.0001985545994042434,
        "gradient_norm": 0.3553246557712555,
        "train_loss": 3.0003652572631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20314,
        "tokens": 10650386432,
        "learning_rate": 0.0001985295782307683,
        "gradient_norm": 0.33990973234176636,
        "train_loss": 3.1144750118255615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20315,
        "tokens": 10650910720,
        "learning_rate": 0.00019850455853715656,
        "gradient_norm": 0.42534342408180237,
        "train_loss": 3.061626434326172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20316,
        "tokens": 10651435008,
        "learning_rate": 0.00019847954032369,
        "gradient_norm": 0.38128215074539185,
        "train_loss": 3.0379858016967773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20317,
        "tokens": 10651959296,
        "learning_rate": 0.0001984545235906501,
        "gradient_norm": 0.4436831474304199,
        "train_loss": 2.976411819458008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20318,
        "tokens": 10652483584,
        "learning_rate": 0.0001984295083383186,
        "gradient_norm": 0.4045165181159973,
        "train_loss": 3.060335159301758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20319,
        "tokens": 10653007872,
        "learning_rate": 0.0001984044945669769,
        "gradient_norm": 0.3689384460449219,
        "train_loss": 3.024301052093506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20320,
        "tokens": 10653532160,
        "learning_rate": 0.00019837948227690674,
        "gradient_norm": 0.3910978436470032,
        "train_loss": 3.0631086826324463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20321,
        "tokens": 10654056448,
        "learning_rate": 0.00019835447146838948,
        "gradient_norm": 0.35554617643356323,
        "train_loss": 3.113780975341797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20322,
        "tokens": 10654580736,
        "learning_rate": 0.00019832946214170684,
        "gradient_norm": 0.37693139910697937,
        "train_loss": 3.1375091075897217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20323,
        "tokens": 10655105024,
        "learning_rate": 0.00019830445429714014,
        "gradient_norm": 0.352234810590744,
        "train_loss": 3.0681676864624023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20324,
        "tokens": 10655629312,
        "learning_rate": 0.00019827944793497095,
        "gradient_norm": 0.3566948175430298,
        "train_loss": 3.063138961791992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20325,
        "tokens": 10656153600,
        "learning_rate": 0.00019825444305548087,
        "gradient_norm": 0.3927781581878662,
        "train_loss": 3.0531005859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20326,
        "tokens": 10656677888,
        "learning_rate": 0.0001982294396589512,
        "gradient_norm": 0.41077250242233276,
        "train_loss": 3.0875418186187744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20327,
        "tokens": 10657202176,
        "learning_rate": 0.0001982044377456635,
        "gradient_norm": 0.3735547661781311,
        "train_loss": 3.084278106689453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20328,
        "tokens": 10657726464,
        "learning_rate": 0.00019817943731589906,
        "gradient_norm": 0.37081989645957947,
        "train_loss": 3.090792179107666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20329,
        "tokens": 10658250752,
        "learning_rate": 0.00019815443836993944,
        "gradient_norm": 0.349942684173584,
        "train_loss": 3.0706279277801514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20330,
        "tokens": 10658775040,
        "learning_rate": 0.0001981294409080659,
        "gradient_norm": 0.4120185077190399,
        "train_loss": 3.0619144439697266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20331,
        "tokens": 10659299328,
        "learning_rate": 0.00019810444493056,
        "gradient_norm": 0.3314417004585266,
        "train_loss": 3.013422966003418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20332,
        "tokens": 10659823616,
        "learning_rate": 0.00019807945043770286,
        "gradient_norm": 0.36992281675338745,
        "train_loss": 3.0952396392822266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20333,
        "tokens": 10660347904,
        "learning_rate": 0.00019805445742977594,
        "gradient_norm": 0.33718401193618774,
        "train_loss": 3.0001144409179688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20334,
        "tokens": 10660872192,
        "learning_rate": 0.0001980294659070607,
        "gradient_norm": 0.3420032262802124,
        "train_loss": 3.073873996734619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20335,
        "tokens": 10661396480,
        "learning_rate": 0.0001980044758698382,
        "gradient_norm": 0.3605358600616455,
        "train_loss": 3.0513126850128174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20336,
        "tokens": 10661920768,
        "learning_rate": 0.00019797948731838997,
        "gradient_norm": 0.3588115870952606,
        "train_loss": 3.094594717025757,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20337,
        "tokens": 10662445056,
        "learning_rate": 0.00019795450025299706,
        "gradient_norm": 0.3605455756187439,
        "train_loss": 3.0558128356933594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20338,
        "tokens": 10662969344,
        "learning_rate": 0.000197929514673941,
        "gradient_norm": 0.34598714113235474,
        "train_loss": 3.056302070617676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20339,
        "tokens": 10663493632,
        "learning_rate": 0.00019790453058150272,
        "gradient_norm": 0.42325839400291443,
        "train_loss": 3.1305413246154785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20340,
        "tokens": 10664017920,
        "learning_rate": 0.00019787954797596374,
        "gradient_norm": 0.44402727484703064,
        "train_loss": 3.1001625061035156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20341,
        "tokens": 10664542208,
        "learning_rate": 0.00019785456685760507,
        "gradient_norm": 0.3727792203426361,
        "train_loss": 3.014469623565674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20342,
        "tokens": 10665066496,
        "learning_rate": 0.00019782958722670805,
        "gradient_norm": 0.4122748374938965,
        "train_loss": 3.0477514266967773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20343,
        "tokens": 10665590784,
        "learning_rate": 0.00019780460908355366,
        "gradient_norm": 0.34118950366973877,
        "train_loss": 3.0694403648376465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20344,
        "tokens": 10666115072,
        "learning_rate": 0.0001977796324284232,
        "gradient_norm": 0.3989526331424713,
        "train_loss": 3.0920395851135254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20345,
        "tokens": 10666639360,
        "learning_rate": 0.00019775465726159787,
        "gradient_norm": 0.4206828773021698,
        "train_loss": 3.043684959411621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20346,
        "tokens": 10667163648,
        "learning_rate": 0.00019772968358335865,
        "gradient_norm": 0.3393087685108185,
        "train_loss": 3.0305240154266357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20347,
        "tokens": 10667687936,
        "learning_rate": 0.00019770471139398679,
        "gradient_norm": 0.37618157267570496,
        "train_loss": 3.031480312347412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20348,
        "tokens": 10668212224,
        "learning_rate": 0.00019767974069376327,
        "gradient_norm": 0.3346441686153412,
        "train_loss": 3.0728163719177246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20349,
        "tokens": 10668736512,
        "learning_rate": 0.00019765477148296927,
        "gradient_norm": 0.3830694556236267,
        "train_loss": 3.0069384574890137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20350,
        "tokens": 10669260800,
        "learning_rate": 0.00019762980376188566,
        "gradient_norm": 0.36921873688697815,
        "train_loss": 3.0581202507019043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20351,
        "tokens": 10669785088,
        "learning_rate": 0.00019760483753079376,
        "gradient_norm": 0.36480170488357544,
        "train_loss": 3.0296630859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20352,
        "tokens": 10670309376,
        "learning_rate": 0.00019757987278997435,
        "gradient_norm": 0.367487370967865,
        "train_loss": 3.0955617427825928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20353,
        "tokens": 10670833664,
        "learning_rate": 0.00019755490953970854,
        "gradient_norm": 0.3720064163208008,
        "train_loss": 3.0657570362091064,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20354,
        "tokens": 10671357952,
        "learning_rate": 0.00019752994778027738,
        "gradient_norm": 0.36341628432273865,
        "train_loss": 3.039090156555176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20355,
        "tokens": 10671882240,
        "learning_rate": 0.00019750498751196173,
        "gradient_norm": 0.4740486145019531,
        "train_loss": 3.08628249168396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20356,
        "tokens": 10672406528,
        "learning_rate": 0.0001974800287350427,
        "gradient_norm": 0.36346322298049927,
        "train_loss": 3.0794920921325684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20357,
        "tokens": 10672930816,
        "learning_rate": 0.000197455071449801,
        "gradient_norm": 0.3401082456111908,
        "train_loss": 3.03419828414917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20358,
        "tokens": 10673455104,
        "learning_rate": 0.00019743011565651782,
        "gradient_norm": 0.3377268612384796,
        "train_loss": 3.0418167114257812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20359,
        "tokens": 10673979392,
        "learning_rate": 0.00019740516135547382,
        "gradient_norm": 0.33458802103996277,
        "train_loss": 3.087723970413208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20360,
        "tokens": 10674503680,
        "learning_rate": 0.00019738020854695015,
        "gradient_norm": 0.39994490146636963,
        "train_loss": 3.0610127449035645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20361,
        "tokens": 10675027968,
        "learning_rate": 0.0001973552572312274,
        "gradient_norm": 0.35539352893829346,
        "train_loss": 3.12442946434021,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20362,
        "tokens": 10675552256,
        "learning_rate": 0.00019733030740858671,
        "gradient_norm": 0.4053468704223633,
        "train_loss": 3.0956106185913086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20363,
        "tokens": 10676076544,
        "learning_rate": 0.00019730535907930868,
        "gradient_norm": 0.3669095039367676,
        "train_loss": 3.050893783569336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20364,
        "tokens": 10676600832,
        "learning_rate": 0.00019728041224367426,
        "gradient_norm": 0.40435636043548584,
        "train_loss": 3.0783181190490723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20365,
        "tokens": 10677125120,
        "learning_rate": 0.0001972554669019643,
        "gradient_norm": 0.3245404362678528,
        "train_loss": 3.074826240539551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20366,
        "tokens": 10677649408,
        "learning_rate": 0.00019723052305445945,
        "gradient_norm": 0.38628292083740234,
        "train_loss": 3.0465240478515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20367,
        "tokens": 10678173696,
        "learning_rate": 0.00019720558070144068,
        "gradient_norm": 0.3710435926914215,
        "train_loss": 3.0824904441833496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20368,
        "tokens": 10678697984,
        "learning_rate": 0.0001971806398431885,
        "gradient_norm": 0.3865177035331726,
        "train_loss": 3.041491746902466,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20369,
        "tokens": 10679222272,
        "learning_rate": 0.0001971557004799839,
        "gradient_norm": 0.3921155333518982,
        "train_loss": 2.998291254043579,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20370,
        "tokens": 10679746560,
        "learning_rate": 0.0001971307626121074,
        "gradient_norm": 0.3482498228549957,
        "train_loss": 3.1074941158294678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20371,
        "tokens": 10680270848,
        "learning_rate": 0.00019710582623983986,
        "gradient_norm": 0.4060535728931427,
        "train_loss": 3.0710959434509277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20372,
        "tokens": 10680795136,
        "learning_rate": 0.0001970808913634618,
        "gradient_norm": 0.3820129632949829,
        "train_loss": 3.0648365020751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20373,
        "tokens": 10681319424,
        "learning_rate": 0.00019705595798325402,
        "gradient_norm": 0.3800382614135742,
        "train_loss": 3.0355491638183594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20374,
        "tokens": 10681843712,
        "learning_rate": 0.00019703102609949726,
        "gradient_norm": 0.3784787058830261,
        "train_loss": 3.0673816204071045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20375,
        "tokens": 10682368000,
        "learning_rate": 0.00019700609571247194,
        "gradient_norm": 0.41898417472839355,
        "train_loss": 3.082681179046631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20376,
        "tokens": 10682892288,
        "learning_rate": 0.00019698116682245889,
        "gradient_norm": 0.41713500022888184,
        "train_loss": 3.090890884399414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20377,
        "tokens": 10683416576,
        "learning_rate": 0.00019695623942973852,
        "gradient_norm": 0.4006582796573639,
        "train_loss": 3.027320384979248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20378,
        "tokens": 10683940864,
        "learning_rate": 0.00019693131353459162,
        "gradient_norm": 0.397305965423584,
        "train_loss": 3.0174713134765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20379,
        "tokens": 10684465152,
        "learning_rate": 0.00019690638913729858,
        "gradient_norm": 0.3780585825443268,
        "train_loss": 3.0358569622039795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20380,
        "tokens": 10684989440,
        "learning_rate": 0.0001968814662381401,
        "gradient_norm": 0.3470664322376251,
        "train_loss": 2.976569652557373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20381,
        "tokens": 10685513728,
        "learning_rate": 0.0001968565448373966,
        "gradient_norm": 0.3572303354740143,
        "train_loss": 3.030104160308838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20382,
        "tokens": 10686038016,
        "learning_rate": 0.0001968316249353487,
        "gradient_norm": 0.36702805757522583,
        "train_loss": 3.0374317169189453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20383,
        "tokens": 10686562304,
        "learning_rate": 0.0001968067065322768,
        "gradient_norm": 0.3820042610168457,
        "train_loss": 3.1001150608062744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20384,
        "tokens": 10687086592,
        "learning_rate": 0.00019678178962846145,
        "gradient_norm": 0.32543641328811646,
        "train_loss": 3.0782406330108643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20385,
        "tokens": 10687610880,
        "learning_rate": 0.0001967568742241832,
        "gradient_norm": 0.3515692949295044,
        "train_loss": 3.045271873474121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20386,
        "tokens": 10688135168,
        "learning_rate": 0.0001967319603197223,
        "gradient_norm": 0.34981122612953186,
        "train_loss": 3.047395706176758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20387,
        "tokens": 10688659456,
        "learning_rate": 0.00019670704791535946,
        "gradient_norm": 0.38406893610954285,
        "train_loss": 3.0291006565093994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20388,
        "tokens": 10689183744,
        "learning_rate": 0.00019668213701137482,
        "gradient_norm": 0.3401039242744446,
        "train_loss": 3.049046039581299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20389,
        "tokens": 10689708032,
        "learning_rate": 0.000196657227608049,
        "gradient_norm": 0.3986847996711731,
        "train_loss": 2.993279218673706,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20390,
        "tokens": 10690232320,
        "learning_rate": 0.00019663231970566222,
        "gradient_norm": 0.3831937909126282,
        "train_loss": 3.0153956413269043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20391,
        "tokens": 10690756608,
        "learning_rate": 0.00019660741330449505,
        "gradient_norm": 0.39039915800094604,
        "train_loss": 3.0061841011047363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20392,
        "tokens": 10691280896,
        "learning_rate": 0.0001965825084048276,
        "gradient_norm": 0.3918251097202301,
        "train_loss": 3.036287784576416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20393,
        "tokens": 10691805184,
        "learning_rate": 0.00019655760500694042,
        "gradient_norm": 0.35106414556503296,
        "train_loss": 3.0366244316101074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20394,
        "tokens": 10692329472,
        "learning_rate": 0.00019653270311111362,
        "gradient_norm": 0.38956916332244873,
        "train_loss": 3.10196852684021,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20395,
        "tokens": 10692853760,
        "learning_rate": 0.00019650780271762775,
        "gradient_norm": 0.3515680432319641,
        "train_loss": 3.0806102752685547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20396,
        "tokens": 10693378048,
        "learning_rate": 0.00019648290382676288,
        "gradient_norm": 0.3738621175289154,
        "train_loss": 3.0430212020874023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20397,
        "tokens": 10693902336,
        "learning_rate": 0.0001964580064387994,
        "gradient_norm": 0.3413967490196228,
        "train_loss": 3.0655813217163086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20398,
        "tokens": 10694426624,
        "learning_rate": 0.00019643311055401747,
        "gradient_norm": 0.3961518108844757,
        "train_loss": 3.1051101684570312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20399,
        "tokens": 10694950912,
        "learning_rate": 0.00019640821617269733,
        "gradient_norm": 0.3552224934101105,
        "train_loss": 3.0844497680664062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20400,
        "tokens": 10695475200,
        "learning_rate": 0.00019638332329511941,
        "gradient_norm": 0.3568849265575409,
        "train_loss": 3.0822768211364746,
        "val_loss": 3.017007350921631,
        "hellaswag_acc": 0.2835092544555664,
        "hellaswag_acc_norm": 0.29784902930259705
    },
    {
        "step": 20401,
        "tokens": 10695999488,
        "learning_rate": 0.0001963584319215636,
        "gradient_norm": 0.3656340539455414,
        "train_loss": 3.045098304748535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20402,
        "tokens": 10696523776,
        "learning_rate": 0.00019633354205231032,
        "gradient_norm": 0.36134251952171326,
        "train_loss": 3.100598096847534,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20403,
        "tokens": 10697048064,
        "learning_rate": 0.00019630865368763957,
        "gradient_norm": 0.40262094140052795,
        "train_loss": 3.014791250228882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20404,
        "tokens": 10697572352,
        "learning_rate": 0.00019628376682783165,
        "gradient_norm": 0.4327126443386078,
        "train_loss": 3.0693113803863525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20405,
        "tokens": 10698096640,
        "learning_rate": 0.00019625888147316656,
        "gradient_norm": 0.40152955055236816,
        "train_loss": 3.0412142276763916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20406,
        "tokens": 10698620928,
        "learning_rate": 0.00019623399762392453,
        "gradient_norm": 0.40198636054992676,
        "train_loss": 3.0413379669189453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20407,
        "tokens": 10699145216,
        "learning_rate": 0.00019620911528038553,
        "gradient_norm": 0.38126882910728455,
        "train_loss": 3.0712428092956543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20408,
        "tokens": 10699669504,
        "learning_rate": 0.00019618423444282975,
        "gradient_norm": 0.4072902202606201,
        "train_loss": 3.073427200317383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20409,
        "tokens": 10700193792,
        "learning_rate": 0.00019615935511153718,
        "gradient_norm": 0.3999358117580414,
        "train_loss": 3.098449230194092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20410,
        "tokens": 10700718080,
        "learning_rate": 0.00019613447728678802,
        "gradient_norm": 0.32932502031326294,
        "train_loss": 3.079496145248413,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20411,
        "tokens": 10701242368,
        "learning_rate": 0.00019610960096886202,
        "gradient_norm": 0.4103134274482727,
        "train_loss": 3.038455009460449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20412,
        "tokens": 10701766656,
        "learning_rate": 0.0001960847261580395,
        "gradient_norm": 0.3886003792285919,
        "train_loss": 3.0667166709899902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20413,
        "tokens": 10702290944,
        "learning_rate": 0.0001960598528546002,
        "gradient_norm": 0.4238399267196655,
        "train_loss": 3.098118305206299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20414,
        "tokens": 10702815232,
        "learning_rate": 0.00019603498105882433,
        "gradient_norm": 0.37100011110305786,
        "train_loss": 3.0609121322631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20415,
        "tokens": 10703339520,
        "learning_rate": 0.00019601011077099165,
        "gradient_norm": 0.4315408766269684,
        "train_loss": 3.082270622253418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20416,
        "tokens": 10703863808,
        "learning_rate": 0.00019598524199138226,
        "gradient_norm": 0.40839236974716187,
        "train_loss": 3.130840301513672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20417,
        "tokens": 10704388096,
        "learning_rate": 0.00019596037472027593,
        "gradient_norm": 0.39031851291656494,
        "train_loss": 3.052886724472046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20418,
        "tokens": 10704912384,
        "learning_rate": 0.00019593550895795282,
        "gradient_norm": 0.4748634696006775,
        "train_loss": 3.120718002319336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20419,
        "tokens": 10705436672,
        "learning_rate": 0.0001959106447046925,
        "gradient_norm": 0.44465088844299316,
        "train_loss": 3.0657799243927,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20420,
        "tokens": 10705960960,
        "learning_rate": 0.0001958857819607752,
        "gradient_norm": 0.411251425743103,
        "train_loss": 3.062093734741211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20421,
        "tokens": 10706485248,
        "learning_rate": 0.00019586092072648045,
        "gradient_norm": 0.3840489089488983,
        "train_loss": 3.0076792240142822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20422,
        "tokens": 10707009536,
        "learning_rate": 0.00019583606100208835,
        "gradient_norm": 0.40469956398010254,
        "train_loss": 3.037982702255249,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20423,
        "tokens": 10707533824,
        "learning_rate": 0.00019581120278787853,
        "gradient_norm": 0.38851359486579895,
        "train_loss": 3.037299156188965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20424,
        "tokens": 10708058112,
        "learning_rate": 0.00019578634608413088,
        "gradient_norm": 0.4187900722026825,
        "train_loss": 3.021150588989258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20425,
        "tokens": 10708582400,
        "learning_rate": 0.0001957614908911253,
        "gradient_norm": 0.4683305025100708,
        "train_loss": 3.1646056175231934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20426,
        "tokens": 10709106688,
        "learning_rate": 0.0001957366372091414,
        "gradient_norm": 0.4840836822986603,
        "train_loss": 3.0853819847106934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20427,
        "tokens": 10709630976,
        "learning_rate": 0.00019571178503845912,
        "gradient_norm": 0.3939325213432312,
        "train_loss": 3.1245083808898926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20428,
        "tokens": 10710155264,
        "learning_rate": 0.00019568693437935797,
        "gradient_norm": 0.44030696153640747,
        "train_loss": 3.0511574745178223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20429,
        "tokens": 10710679552,
        "learning_rate": 0.0001956620852321179,
        "gradient_norm": 0.39554479718208313,
        "train_loss": 3.0670790672302246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20430,
        "tokens": 10711203840,
        "learning_rate": 0.00019563723759701842,
        "gradient_norm": 0.3942047357559204,
        "train_loss": 3.0431294441223145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20431,
        "tokens": 10711728128,
        "learning_rate": 0.00019561239147433942,
        "gradient_norm": 0.3965963125228882,
        "train_loss": 3.034527063369751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20432,
        "tokens": 10712252416,
        "learning_rate": 0.0001955875468643604,
        "gradient_norm": 0.39026108384132385,
        "train_loss": 3.0353329181671143,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20433,
        "tokens": 10712776704,
        "learning_rate": 0.00019556270376736105,
        "gradient_norm": 0.3777766227722168,
        "train_loss": 3.07357120513916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20434,
        "tokens": 10713300992,
        "learning_rate": 0.00019553786218362118,
        "gradient_norm": 0.37405797839164734,
        "train_loss": 3.0309886932373047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20435,
        "tokens": 10713825280,
        "learning_rate": 0.00019551302211342014,
        "gradient_norm": 0.3637436330318451,
        "train_loss": 3.031040906906128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20436,
        "tokens": 10714349568,
        "learning_rate": 0.0001954881835570378,
        "gradient_norm": 0.3715701103210449,
        "train_loss": 3.0837604999542236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20437,
        "tokens": 10714873856,
        "learning_rate": 0.00019546334651475355,
        "gradient_norm": 0.3695719838142395,
        "train_loss": 3.035709857940674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20438,
        "tokens": 10715398144,
        "learning_rate": 0.0001954385109868471,
        "gradient_norm": 0.3457021117210388,
        "train_loss": 3.0608363151550293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20439,
        "tokens": 10715922432,
        "learning_rate": 0.00019541367697359786,
        "gradient_norm": 0.3757123053073883,
        "train_loss": 3.0350518226623535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20440,
        "tokens": 10716446720,
        "learning_rate": 0.00019538884447528558,
        "gradient_norm": 0.35143518447875977,
        "train_loss": 3.0641846656799316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20441,
        "tokens": 10716971008,
        "learning_rate": 0.0001953640134921895,
        "gradient_norm": 0.3921037018299103,
        "train_loss": 3.034489631652832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20442,
        "tokens": 10717495296,
        "learning_rate": 0.00019533918402458943,
        "gradient_norm": 0.39118722081184387,
        "train_loss": 3.022968292236328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20443,
        "tokens": 10718019584,
        "learning_rate": 0.00019531435607276457,
        "gradient_norm": 0.3273581862449646,
        "train_loss": 3.013153314590454,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20444,
        "tokens": 10718543872,
        "learning_rate": 0.00019528952963699455,
        "gradient_norm": 0.3895418345928192,
        "train_loss": 3.1111602783203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20445,
        "tokens": 10719068160,
        "learning_rate": 0.00019526470471755886,
        "gradient_norm": 0.38136351108551025,
        "train_loss": 3.049649238586426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20446,
        "tokens": 10719592448,
        "learning_rate": 0.00019523988131473678,
        "gradient_norm": 0.3982680141925812,
        "train_loss": 3.0674211978912354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20447,
        "tokens": 10720116736,
        "learning_rate": 0.00019521505942880792,
        "gradient_norm": 0.33295944333076477,
        "train_loss": 3.0672078132629395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20448,
        "tokens": 10720641024,
        "learning_rate": 0.00019519023906005152,
        "gradient_norm": 0.37845584750175476,
        "train_loss": 3.050319194793701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20449,
        "tokens": 10721165312,
        "learning_rate": 0.00019516542020874705,
        "gradient_norm": 0.34951475262641907,
        "train_loss": 3.031114101409912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20450,
        "tokens": 10721689600,
        "learning_rate": 0.00019514060287517378,
        "gradient_norm": 0.3916488289833069,
        "train_loss": 3.046036720275879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20451,
        "tokens": 10722213888,
        "learning_rate": 0.0001951157870596113,
        "gradient_norm": 0.3416755497455597,
        "train_loss": 3.034907341003418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20452,
        "tokens": 10722738176,
        "learning_rate": 0.0001950909727623386,
        "gradient_norm": 0.34326064586639404,
        "train_loss": 2.986624240875244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20453,
        "tokens": 10723262464,
        "learning_rate": 0.00019506615998363515,
        "gradient_norm": 0.35974061489105225,
        "train_loss": 3.045046806335449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20454,
        "tokens": 10723786752,
        "learning_rate": 0.00019504134872378042,
        "gradient_norm": 0.32943588495254517,
        "train_loss": 3.026212215423584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20455,
        "tokens": 10724311040,
        "learning_rate": 0.00019501653898305342,
        "gradient_norm": 0.3607916533946991,
        "train_loss": 3.0021512508392334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20456,
        "tokens": 10724835328,
        "learning_rate": 0.00019499173076173364,
        "gradient_norm": 0.3716210722923279,
        "train_loss": 3.032850742340088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20457,
        "tokens": 10725359616,
        "learning_rate": 0.00019496692406010012,
        "gradient_norm": 0.3747090697288513,
        "train_loss": 3.0519955158233643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20458,
        "tokens": 10725883904,
        "learning_rate": 0.0001949421188784323,
        "gradient_norm": 0.4087980091571808,
        "train_loss": 3.099203586578369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20459,
        "tokens": 10726408192,
        "learning_rate": 0.0001949173152170092,
        "gradient_norm": 0.44241252541542053,
        "train_loss": 3.0228657722473145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20460,
        "tokens": 10726932480,
        "learning_rate": 0.00019489251307611017,
        "gradient_norm": 0.41714784502983093,
        "train_loss": 3.2039761543273926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20461,
        "tokens": 10727456768,
        "learning_rate": 0.00019486771245601423,
        "gradient_norm": 0.40439900755882263,
        "train_loss": 3.045708656311035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20462,
        "tokens": 10727981056,
        "learning_rate": 0.00019484291335700074,
        "gradient_norm": 0.42780470848083496,
        "train_loss": 3.0379509925842285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20463,
        "tokens": 10728505344,
        "learning_rate": 0.00019481811577934865,
        "gradient_norm": 0.34937554597854614,
        "train_loss": 3.06605863571167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20464,
        "tokens": 10729029632,
        "learning_rate": 0.00019479331972333715,
        "gradient_norm": 0.4181915819644928,
        "train_loss": 2.9850597381591797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20465,
        "tokens": 10729553920,
        "learning_rate": 0.0001947685251892455,
        "gradient_norm": 0.3490765690803528,
        "train_loss": 3.0523533821105957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20466,
        "tokens": 10730078208,
        "learning_rate": 0.00019474373217735254,
        "gradient_norm": 0.3955332338809967,
        "train_loss": 3.069458246231079,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20467,
        "tokens": 10730602496,
        "learning_rate": 0.0001947189406879376,
        "gradient_norm": 0.34266841411590576,
        "train_loss": 3.0790982246398926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20468,
        "tokens": 10731126784,
        "learning_rate": 0.0001946941507212795,
        "gradient_norm": 0.39703235030174255,
        "train_loss": 3.0775856971740723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20469,
        "tokens": 10731651072,
        "learning_rate": 0.00019466936227765751,
        "gradient_norm": 0.3805479109287262,
        "train_loss": 3.0314064025878906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20470,
        "tokens": 10732175360,
        "learning_rate": 0.00019464457535735042,
        "gradient_norm": 0.38745731115341187,
        "train_loss": 3.10438871383667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20471,
        "tokens": 10732699648,
        "learning_rate": 0.0001946197899606375,
        "gradient_norm": 0.4849160611629486,
        "train_loss": 3.139484405517578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20472,
        "tokens": 10733223936,
        "learning_rate": 0.00019459500608779746,
        "gradient_norm": 0.4649971127510071,
        "train_loss": 3.0409367084503174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20473,
        "tokens": 10733748224,
        "learning_rate": 0.00019457022373910944,
        "gradient_norm": 0.47623950242996216,
        "train_loss": 3.0663559436798096,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20474,
        "tokens": 10734272512,
        "learning_rate": 0.00019454544291485246,
        "gradient_norm": 0.41790303587913513,
        "train_loss": 3.011780023574829,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20475,
        "tokens": 10734796800,
        "learning_rate": 0.00019452066361530526,
        "gradient_norm": 0.4863818883895874,
        "train_loss": 3.1247758865356445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20476,
        "tokens": 10735321088,
        "learning_rate": 0.00019449588584074696,
        "gradient_norm": 0.4454393982887268,
        "train_loss": 3.0839598178863525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20477,
        "tokens": 10735845376,
        "learning_rate": 0.00019447110959145631,
        "gradient_norm": 0.43193474411964417,
        "train_loss": 3.0236878395080566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20478,
        "tokens": 10736369664,
        "learning_rate": 0.00019444633486771236,
        "gradient_norm": 0.43083617091178894,
        "train_loss": 3.0646471977233887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20479,
        "tokens": 10736893952,
        "learning_rate": 0.00019442156166979375,
        "gradient_norm": 0.43131282925605774,
        "train_loss": 3.0428478717803955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20480,
        "tokens": 10737418240,
        "learning_rate": 0.00019439678999797958,
        "gradient_norm": 0.38652265071868896,
        "train_loss": 3.0585811138153076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20481,
        "tokens": 10737942528,
        "learning_rate": 0.00019437201985254848,
        "gradient_norm": 0.48513972759246826,
        "train_loss": 3.059947967529297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20482,
        "tokens": 10738466816,
        "learning_rate": 0.00019434725123377945,
        "gradient_norm": 0.3787139356136322,
        "train_loss": 3.0029497146606445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20483,
        "tokens": 10738991104,
        "learning_rate": 0.0001943224841419511,
        "gradient_norm": 0.3759975731372833,
        "train_loss": 3.070791721343994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20484,
        "tokens": 10739515392,
        "learning_rate": 0.00019429771857734234,
        "gradient_norm": 0.43890154361724854,
        "train_loss": 3.1360321044921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20485,
        "tokens": 10740039680,
        "learning_rate": 0.000194272954540232,
        "gradient_norm": 0.38821202516555786,
        "train_loss": 3.010862350463867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20486,
        "tokens": 10740563968,
        "learning_rate": 0.00019424819203089867,
        "gradient_norm": 0.3844466805458069,
        "train_loss": 3.0475387573242188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20487,
        "tokens": 10741088256,
        "learning_rate": 0.00019422343104962122,
        "gradient_norm": 0.3748547434806824,
        "train_loss": 3.078805685043335,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20488,
        "tokens": 10741612544,
        "learning_rate": 0.00019419867159667823,
        "gradient_norm": 0.3772190511226654,
        "train_loss": 3.0803089141845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20489,
        "tokens": 10742136832,
        "learning_rate": 0.00019417391367234857,
        "gradient_norm": 0.40340960025787354,
        "train_loss": 3.0956435203552246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20490,
        "tokens": 10742661120,
        "learning_rate": 0.0001941491572769107,
        "gradient_norm": 0.3765042722225189,
        "train_loss": 3.0428390502929688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20491,
        "tokens": 10743185408,
        "learning_rate": 0.00019412440241064354,
        "gradient_norm": 0.38065671920776367,
        "train_loss": 3.06796932220459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20492,
        "tokens": 10743709696,
        "learning_rate": 0.00019409964907382546,
        "gradient_norm": 0.3734372854232788,
        "train_loss": 3.082479953765869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20493,
        "tokens": 10744233984,
        "learning_rate": 0.00019407489726673525,
        "gradient_norm": 0.4030891954898834,
        "train_loss": 3.0759801864624023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20494,
        "tokens": 10744758272,
        "learning_rate": 0.00019405014698965162,
        "gradient_norm": 0.36241066455841064,
        "train_loss": 3.05527663230896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20495,
        "tokens": 10745282560,
        "learning_rate": 0.00019402539824285296,
        "gradient_norm": 0.4017631411552429,
        "train_loss": 3.0499322414398193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20496,
        "tokens": 10745806848,
        "learning_rate": 0.00019400065102661803,
        "gradient_norm": 0.3662957549095154,
        "train_loss": 3.0392303466796875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20497,
        "tokens": 10746331136,
        "learning_rate": 0.0001939759053412252,
        "gradient_norm": 0.3550378680229187,
        "train_loss": 3.073854923248291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20498,
        "tokens": 10746855424,
        "learning_rate": 0.0001939511611869532,
        "gradient_norm": 0.39420247077941895,
        "train_loss": 3.034754753112793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20499,
        "tokens": 10747379712,
        "learning_rate": 0.0001939264185640804,
        "gradient_norm": 0.3723088502883911,
        "train_loss": 3.1048779487609863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20500,
        "tokens": 10747904000,
        "learning_rate": 0.00019390167747288545,
        "gradient_norm": 0.3721301555633545,
        "train_loss": 3.1396899223327637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20501,
        "tokens": 10748428288,
        "learning_rate": 0.00019387693791364668,
        "gradient_norm": 0.3847985565662384,
        "train_loss": 3.0502376556396484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20502,
        "tokens": 10748952576,
        "learning_rate": 0.00019385219988664277,
        "gradient_norm": 0.3637617528438568,
        "train_loss": 3.0452992916107178,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20503,
        "tokens": 10749476864,
        "learning_rate": 0.00019382746339215195,
        "gradient_norm": 0.3933908939361572,
        "train_loss": 3.044620990753174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20504,
        "tokens": 10750001152,
        "learning_rate": 0.00019380272843045286,
        "gradient_norm": 0.37471818923950195,
        "train_loss": 3.0744407176971436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20505,
        "tokens": 10750525440,
        "learning_rate": 0.00019377799500182376,
        "gradient_norm": 0.38920462131500244,
        "train_loss": 2.985365867614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20506,
        "tokens": 10751049728,
        "learning_rate": 0.0001937532631065432,
        "gradient_norm": 0.3845204710960388,
        "train_loss": 3.090193033218384,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20507,
        "tokens": 10751574016,
        "learning_rate": 0.00019372853274488944,
        "gradient_norm": 0.39536941051483154,
        "train_loss": 2.989745616912842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20508,
        "tokens": 10752098304,
        "learning_rate": 0.00019370380391714099,
        "gradient_norm": 0.3885642886161804,
        "train_loss": 3.0055551528930664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20509,
        "tokens": 10752622592,
        "learning_rate": 0.00019367907662357601,
        "gradient_norm": 0.37687069177627563,
        "train_loss": 3.029423236846924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20510,
        "tokens": 10753146880,
        "learning_rate": 0.00019365435086447308,
        "gradient_norm": 0.38189879059791565,
        "train_loss": 3.034270763397217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20511,
        "tokens": 10753671168,
        "learning_rate": 0.00019362962664011028,
        "gradient_norm": 0.38035547733306885,
        "train_loss": 2.9977338314056396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20512,
        "tokens": 10754195456,
        "learning_rate": 0.00019360490395076613,
        "gradient_norm": 0.3868679702281952,
        "train_loss": 3.116885185241699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20513,
        "tokens": 10754719744,
        "learning_rate": 0.00019358018279671868,
        "gradient_norm": 0.39023691415786743,
        "train_loss": 3.0932743549346924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20514,
        "tokens": 10755244032,
        "learning_rate": 0.00019355546317824645,
        "gradient_norm": 0.43724218010902405,
        "train_loss": 3.142866373062134,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20515,
        "tokens": 10755768320,
        "learning_rate": 0.00019353074509562748,
        "gradient_norm": 0.39623329043388367,
        "train_loss": 3.0477890968322754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20516,
        "tokens": 10756292608,
        "learning_rate": 0.00019350602854914016,
        "gradient_norm": 0.4221312403678894,
        "train_loss": 3.012089729309082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20517,
        "tokens": 10756816896,
        "learning_rate": 0.0001934813135390625,
        "gradient_norm": 0.4437370300292969,
        "train_loss": 3.0630791187286377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20518,
        "tokens": 10757341184,
        "learning_rate": 0.00019345660006567299,
        "gradient_norm": 0.4073965549468994,
        "train_loss": 3.0398402214050293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20519,
        "tokens": 10757865472,
        "learning_rate": 0.00019343188812924954,
        "gradient_norm": 0.3839259743690491,
        "train_loss": 3.0658326148986816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20520,
        "tokens": 10758389760,
        "learning_rate": 0.00019340717773007047,
        "gradient_norm": 0.3752216398715973,
        "train_loss": 2.9958271980285645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20521,
        "tokens": 10758914048,
        "learning_rate": 0.00019338246886841387,
        "gradient_norm": 0.41221654415130615,
        "train_loss": 3.01310396194458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20522,
        "tokens": 10759438336,
        "learning_rate": 0.00019335776154455792,
        "gradient_norm": 0.4012649953365326,
        "train_loss": 3.0795295238494873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20523,
        "tokens": 10759962624,
        "learning_rate": 0.00019333305575878064,
        "gradient_norm": 0.393680602312088,
        "train_loss": 3.0824475288391113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20524,
        "tokens": 10760486912,
        "learning_rate": 0.0001933083515113601,
        "gradient_norm": 0.38497012853622437,
        "train_loss": 3.090470314025879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20525,
        "tokens": 10761011200,
        "learning_rate": 0.00019328364880257464,
        "gradient_norm": 0.3483392894268036,
        "train_loss": 3.0330638885498047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20526,
        "tokens": 10761535488,
        "learning_rate": 0.000193258947632702,
        "gradient_norm": 0.3782500922679901,
        "train_loss": 3.064957618713379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20527,
        "tokens": 10762059776,
        "learning_rate": 0.00019323424800202042,
        "gradient_norm": 0.3648805618286133,
        "train_loss": 3.081167221069336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20528,
        "tokens": 10762584064,
        "learning_rate": 0.0001932095499108078,
        "gradient_norm": 0.4316026270389557,
        "train_loss": 3.1150779724121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20529,
        "tokens": 10763108352,
        "learning_rate": 0.0001931848533593423,
        "gradient_norm": 0.3809334635734558,
        "train_loss": 2.9763898849487305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20530,
        "tokens": 10763632640,
        "learning_rate": 0.00019316015834790174,
        "gradient_norm": 0.3375336527824402,
        "train_loss": 3.0316996574401855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20531,
        "tokens": 10764156928,
        "learning_rate": 0.00019313546487676427,
        "gradient_norm": 0.42693576216697693,
        "train_loss": 3.0882303714752197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20532,
        "tokens": 10764681216,
        "learning_rate": 0.00019311077294620764,
        "gradient_norm": 0.3774352967739105,
        "train_loss": 3.0308632850646973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20533,
        "tokens": 10765205504,
        "learning_rate": 0.0001930860825565099,
        "gradient_norm": 0.3894879221916199,
        "train_loss": 3.0215423107147217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20534,
        "tokens": 10765729792,
        "learning_rate": 0.00019306139370794904,
        "gradient_norm": 0.39646705985069275,
        "train_loss": 3.0086727142333984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20535,
        "tokens": 10766254080,
        "learning_rate": 0.00019303670640080282,
        "gradient_norm": 0.40445858240127563,
        "train_loss": 3.086265802383423,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20536,
        "tokens": 10766778368,
        "learning_rate": 0.0001930120206353493,
        "gradient_norm": 0.3684167265892029,
        "train_loss": 3.0774359703063965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20537,
        "tokens": 10767302656,
        "learning_rate": 0.00019298733641186612,
        "gradient_norm": 0.3793562054634094,
        "train_loss": 3.0097856521606445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20538,
        "tokens": 10767826944,
        "learning_rate": 0.0001929626537306314,
        "gradient_norm": 0.37806692719459534,
        "train_loss": 3.0230278968811035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20539,
        "tokens": 10768351232,
        "learning_rate": 0.0001929379725919227,
        "gradient_norm": 0.3750697672367096,
        "train_loss": 2.9938418865203857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20540,
        "tokens": 10768875520,
        "learning_rate": 0.0001929132929960181,
        "gradient_norm": 0.42410528659820557,
        "train_loss": 3.115185260772705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20541,
        "tokens": 10769399808,
        "learning_rate": 0.00019288861494319513,
        "gradient_norm": 0.3684006929397583,
        "train_loss": 3.0602285861968994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20542,
        "tokens": 10769924096,
        "learning_rate": 0.00019286393843373183,
        "gradient_norm": 0.38486865162849426,
        "train_loss": 2.997892141342163,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20543,
        "tokens": 10770448384,
        "learning_rate": 0.0001928392634679058,
        "gradient_norm": 0.3593808114528656,
        "train_loss": 3.0676729679107666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20544,
        "tokens": 10770972672,
        "learning_rate": 0.00019281459004599476,
        "gradient_norm": 0.40054136514663696,
        "train_loss": 3.075629711151123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20545,
        "tokens": 10771496960,
        "learning_rate": 0.00019278991816827667,
        "gradient_norm": 0.3650045394897461,
        "train_loss": 3.0714120864868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20546,
        "tokens": 10772021248,
        "learning_rate": 0.00019276524783502894,
        "gradient_norm": 0.3774529993534088,
        "train_loss": 3.041107654571533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20547,
        "tokens": 10772545536,
        "learning_rate": 0.00019274057904652953,
        "gradient_norm": 0.43538782000541687,
        "train_loss": 3.107685089111328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20548,
        "tokens": 10773069824,
        "learning_rate": 0.00019271591180305592,
        "gradient_norm": 0.434369832277298,
        "train_loss": 3.1231846809387207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20549,
        "tokens": 10773594112,
        "learning_rate": 0.00019269124610488594,
        "gradient_norm": 0.3847768008708954,
        "train_loss": 3.0803062915802,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20550,
        "tokens": 10774118400,
        "learning_rate": 0.00019266658195229704,
        "gradient_norm": 0.3842701017856598,
        "train_loss": 3.0082201957702637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20551,
        "tokens": 10774642688,
        "learning_rate": 0.00019264191934556706,
        "gradient_norm": 0.37249162793159485,
        "train_loss": 3.024383544921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20552,
        "tokens": 10775166976,
        "learning_rate": 0.0001926172582849734,
        "gradient_norm": 0.4597567319869995,
        "train_loss": 3.083874464035034,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20553,
        "tokens": 10775691264,
        "learning_rate": 0.00019259259877079375,
        "gradient_norm": 0.3696369230747223,
        "train_loss": 3.0484743118286133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20554,
        "tokens": 10776215552,
        "learning_rate": 0.00019256794080330574,
        "gradient_norm": 0.38613349199295044,
        "train_loss": 3.0944626331329346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20555,
        "tokens": 10776739840,
        "learning_rate": 0.00019254328438278684,
        "gradient_norm": 0.38567647337913513,
        "train_loss": 3.0577967166900635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20556,
        "tokens": 10777264128,
        "learning_rate": 0.0001925186295095147,
        "gradient_norm": 0.3572138547897339,
        "train_loss": 3.0763678550720215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20557,
        "tokens": 10777788416,
        "learning_rate": 0.00019249397618376662,
        "gradient_norm": 0.37831294536590576,
        "train_loss": 2.9907851219177246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20558,
        "tokens": 10778312704,
        "learning_rate": 0.0001924693244058204,
        "gradient_norm": 0.3276410400867462,
        "train_loss": 3.0489046573638916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20559,
        "tokens": 10778836992,
        "learning_rate": 0.0001924446741759532,
        "gradient_norm": 0.35395464301109314,
        "train_loss": 3.0537099838256836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20560,
        "tokens": 10779361280,
        "learning_rate": 0.00019242002549444282,
        "gradient_norm": 0.36751750111579895,
        "train_loss": 3.101093292236328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20561,
        "tokens": 10779885568,
        "learning_rate": 0.00019239537836156643,
        "gradient_norm": 0.3583928942680359,
        "train_loss": 3.0729804039001465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20562,
        "tokens": 10780409856,
        "learning_rate": 0.00019237073277760168,
        "gradient_norm": 0.3818759024143219,
        "train_loss": 3.01290225982666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20563,
        "tokens": 10780934144,
        "learning_rate": 0.0001923460887428258,
        "gradient_norm": 0.3645526170730591,
        "train_loss": 3.109017848968506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20564,
        "tokens": 10781458432,
        "learning_rate": 0.00019232144625751628,
        "gradient_norm": 0.4310552775859833,
        "train_loss": 3.036367416381836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20565,
        "tokens": 10781982720,
        "learning_rate": 0.0001922968053219506,
        "gradient_norm": 0.35800623893737793,
        "train_loss": 3.061317205429077,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20566,
        "tokens": 10782507008,
        "learning_rate": 0.00019227216593640592,
        "gradient_norm": 0.36919575929641724,
        "train_loss": 2.9990639686584473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20567,
        "tokens": 10783031296,
        "learning_rate": 0.00019224752810115983,
        "gradient_norm": 0.39353200793266296,
        "train_loss": 3.081775665283203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20568,
        "tokens": 10783555584,
        "learning_rate": 0.0001922228918164894,
        "gradient_norm": 0.39772477746009827,
        "train_loss": 2.992894172668457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20569,
        "tokens": 10784079872,
        "learning_rate": 0.00019219825708267216,
        "gradient_norm": 0.3968011438846588,
        "train_loss": 3.0431525707244873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20570,
        "tokens": 10784604160,
        "learning_rate": 0.0001921736238999852,
        "gradient_norm": 0.3716781437397003,
        "train_loss": 3.059615135192871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20571,
        "tokens": 10785128448,
        "learning_rate": 0.00019214899226870603,
        "gradient_norm": 0.386203408241272,
        "train_loss": 3.0859508514404297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20572,
        "tokens": 10785652736,
        "learning_rate": 0.0001921243621891117,
        "gradient_norm": 0.3837426006793976,
        "train_loss": 3.0439188480377197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20573,
        "tokens": 10786177024,
        "learning_rate": 0.0001920997336614795,
        "gradient_norm": 0.4793040454387665,
        "train_loss": 3.0419914722442627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20574,
        "tokens": 10786701312,
        "learning_rate": 0.00019207510668608682,
        "gradient_norm": 0.48639848828315735,
        "train_loss": 3.029341697692871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20575,
        "tokens": 10787225600,
        "learning_rate": 0.00019205048126321066,
        "gradient_norm": 0.4384997487068176,
        "train_loss": 3.120311975479126,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20576,
        "tokens": 10787749888,
        "learning_rate": 0.00019202585739312836,
        "gradient_norm": 0.5599898099899292,
        "train_loss": 3.015388011932373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20577,
        "tokens": 10788274176,
        "learning_rate": 0.00019200123507611693,
        "gradient_norm": 0.4128475785255432,
        "train_loss": 3.0297226905822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20578,
        "tokens": 10788798464,
        "learning_rate": 0.00019197661431245375,
        "gradient_norm": 0.4129497706890106,
        "train_loss": 3.020136594772339,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20579,
        "tokens": 10789322752,
        "learning_rate": 0.0001919519951024157,
        "gradient_norm": 0.43564024567604065,
        "train_loss": 3.0608410835266113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20580,
        "tokens": 10789847040,
        "learning_rate": 0.0001919273774462801,
        "gradient_norm": 0.3988622725009918,
        "train_loss": 3.0539708137512207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20581,
        "tokens": 10790371328,
        "learning_rate": 0.0001919027613443239,
        "gradient_norm": 0.3768084943294525,
        "train_loss": 3.0362467765808105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20582,
        "tokens": 10790895616,
        "learning_rate": 0.00019187814679682427,
        "gradient_norm": 0.33971765637397766,
        "train_loss": 3.0291740894317627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20583,
        "tokens": 10791419904,
        "learning_rate": 0.00019185353380405838,
        "gradient_norm": 0.3785316050052643,
        "train_loss": 3.072787046432495,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20584,
        "tokens": 10791944192,
        "learning_rate": 0.00019182892236630308,
        "gradient_norm": 0.34222695231437683,
        "train_loss": 3.0831422805786133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20585,
        "tokens": 10792468480,
        "learning_rate": 0.00019180431248383556,
        "gradient_norm": 0.34154725074768066,
        "train_loss": 3.0366387367248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20586,
        "tokens": 10792992768,
        "learning_rate": 0.00019177970415693268,
        "gradient_norm": 0.3460105359554291,
        "train_loss": 3.0637354850769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20587,
        "tokens": 10793517056,
        "learning_rate": 0.00019175509738587163,
        "gradient_norm": 0.41005823016166687,
        "train_loss": 2.9952430725097656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20588,
        "tokens": 10794041344,
        "learning_rate": 0.00019173049217092918,
        "gradient_norm": 0.36333146691322327,
        "train_loss": 3.0082406997680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20589,
        "tokens": 10794565632,
        "learning_rate": 0.00019170588851238253,
        "gradient_norm": 0.36617252230644226,
        "train_loss": 3.098752498626709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20590,
        "tokens": 10795089920,
        "learning_rate": 0.00019168128641050837,
        "gradient_norm": 0.3508254289627075,
        "train_loss": 3.031691074371338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20591,
        "tokens": 10795614208,
        "learning_rate": 0.00019165668586558385,
        "gradient_norm": 0.3909962475299835,
        "train_loss": 3.0029468536376953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20592,
        "tokens": 10796138496,
        "learning_rate": 0.00019163208687788567,
        "gradient_norm": 0.4165562391281128,
        "train_loss": 3.0590620040893555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20593,
        "tokens": 10796662784,
        "learning_rate": 0.00019160748944769084,
        "gradient_norm": 0.37382301688194275,
        "train_loss": 3.056507110595703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20594,
        "tokens": 10797187072,
        "learning_rate": 0.00019158289357527634,
        "gradient_norm": 0.44639360904693604,
        "train_loss": 3.0424864292144775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20595,
        "tokens": 10797711360,
        "learning_rate": 0.0001915582992609188,
        "gradient_norm": 0.3797960579395294,
        "train_loss": 3.0073368549346924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20596,
        "tokens": 10798235648,
        "learning_rate": 0.00019153370650489525,
        "gradient_norm": 0.3721259832382202,
        "train_loss": 3.0508642196655273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20597,
        "tokens": 10798759936,
        "learning_rate": 0.00019150911530748237,
        "gradient_norm": 0.3792569935321808,
        "train_loss": 2.9941513538360596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20598,
        "tokens": 10799284224,
        "learning_rate": 0.00019148452566895713,
        "gradient_norm": 0.38997209072113037,
        "train_loss": 3.030642032623291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20599,
        "tokens": 10799808512,
        "learning_rate": 0.0001914599375895961,
        "gradient_norm": 0.38385528326034546,
        "train_loss": 3.099667549133301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20600,
        "tokens": 10800332800,
        "learning_rate": 0.00019143535106967629,
        "gradient_norm": 0.35413220524787903,
        "train_loss": 3.0377495288848877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20601,
        "tokens": 10800857088,
        "learning_rate": 0.00019141076610947418,
        "gradient_norm": 0.43083930015563965,
        "train_loss": 3.064798355102539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20602,
        "tokens": 10801381376,
        "learning_rate": 0.0001913861827092668,
        "gradient_norm": 0.3719881474971771,
        "train_loss": 3.043776035308838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20603,
        "tokens": 10801905664,
        "learning_rate": 0.0001913616008693306,
        "gradient_norm": 0.4015897810459137,
        "train_loss": 3.0772669315338135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20604,
        "tokens": 10802429952,
        "learning_rate": 0.00019133702058994243,
        "gradient_norm": 0.37788960337638855,
        "train_loss": 3.079272747039795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20605,
        "tokens": 10802954240,
        "learning_rate": 0.00019131244187137902,
        "gradient_norm": 0.42118969559669495,
        "train_loss": 3.082252264022827,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20606,
        "tokens": 10803478528,
        "learning_rate": 0.00019128786471391684,
        "gradient_norm": 0.38158345222473145,
        "train_loss": 3.0711851119995117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20607,
        "tokens": 10804002816,
        "learning_rate": 0.00019126328911783278,
        "gradient_norm": 0.36830446124076843,
        "train_loss": 3.0497097969055176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20608,
        "tokens": 10804527104,
        "learning_rate": 0.00019123871508340323,
        "gradient_norm": 0.3668029010295868,
        "train_loss": 3.052579879760742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20609,
        "tokens": 10805051392,
        "learning_rate": 0.000191214142610905,
        "gradient_norm": 0.42572084069252014,
        "train_loss": 3.031324625015259,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20610,
        "tokens": 10805575680,
        "learning_rate": 0.0001911895717006145,
        "gradient_norm": 0.36661195755004883,
        "train_loss": 3.0823371410369873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20611,
        "tokens": 10806099968,
        "learning_rate": 0.00019116500235280852,
        "gradient_norm": 0.3798021376132965,
        "train_loss": 3.028884172439575,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20612,
        "tokens": 10806624256,
        "learning_rate": 0.0001911404345677634,
        "gradient_norm": 0.4078519940376282,
        "train_loss": 3.0375468730926514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20613,
        "tokens": 10807148544,
        "learning_rate": 0.00019111586834575587,
        "gradient_norm": 0.39532172679901123,
        "train_loss": 3.077334403991699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20614,
        "tokens": 10807672832,
        "learning_rate": 0.00019109130368706226,
        "gradient_norm": 0.4091796278953552,
        "train_loss": 3.095362901687622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20615,
        "tokens": 10808197120,
        "learning_rate": 0.0001910667405919593,
        "gradient_norm": 0.3824273645877838,
        "train_loss": 3.0353336334228516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20616,
        "tokens": 10808721408,
        "learning_rate": 0.00019104217906072324,
        "gradient_norm": 0.40199607610702515,
        "train_loss": 3.091212749481201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20617,
        "tokens": 10809245696,
        "learning_rate": 0.00019101761909363078,
        "gradient_norm": 0.3742571771144867,
        "train_loss": 3.022418975830078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20618,
        "tokens": 10809769984,
        "learning_rate": 0.00019099306069095815,
        "gradient_norm": 0.37408092617988586,
        "train_loss": 3.076950788497925,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20619,
        "tokens": 10810294272,
        "learning_rate": 0.00019096850385298203,
        "gradient_norm": 0.37161168456077576,
        "train_loss": 3.0413169860839844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20620,
        "tokens": 10810818560,
        "learning_rate": 0.0001909439485799786,
        "gradient_norm": 0.33748409152030945,
        "train_loss": 2.9677610397338867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20621,
        "tokens": 10811342848,
        "learning_rate": 0.00019091939487222444,
        "gradient_norm": 0.3922306001186371,
        "train_loss": 3.083893060684204,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20622,
        "tokens": 10811867136,
        "learning_rate": 0.00019089484272999578,
        "gradient_norm": 0.3654687702655792,
        "train_loss": 3.082730293273926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20623,
        "tokens": 10812391424,
        "learning_rate": 0.00019087029215356915,
        "gradient_norm": 0.41736239194869995,
        "train_loss": 3.070326089859009,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20624,
        "tokens": 10812915712,
        "learning_rate": 0.0001908457431432207,
        "gradient_norm": 0.403754323720932,
        "train_loss": 3.0612611770629883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20625,
        "tokens": 10813440000,
        "learning_rate": 0.00019082119569922701,
        "gradient_norm": 0.4608452618122101,
        "train_loss": 3.0537912845611572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20626,
        "tokens": 10813964288,
        "learning_rate": 0.00019079664982186412,
        "gradient_norm": 0.4333483576774597,
        "train_loss": 3.115391254425049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20627,
        "tokens": 10814488576,
        "learning_rate": 0.00019077210551140855,
        "gradient_norm": 0.49337372183799744,
        "train_loss": 3.0179619789123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20628,
        "tokens": 10815012864,
        "learning_rate": 0.0001907475627681364,
        "gradient_norm": 0.4119376838207245,
        "train_loss": 3.0736217498779297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20629,
        "tokens": 10815537152,
        "learning_rate": 0.00019072302159232413,
        "gradient_norm": 0.45769184827804565,
        "train_loss": 3.067699432373047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20630,
        "tokens": 10816061440,
        "learning_rate": 0.00019069848198424776,
        "gradient_norm": 0.39440256357192993,
        "train_loss": 3.096653461456299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20631,
        "tokens": 10816585728,
        "learning_rate": 0.00019067394394418373,
        "gradient_norm": 0.37535130977630615,
        "train_loss": 3.056210517883301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20632,
        "tokens": 10817110016,
        "learning_rate": 0.00019064940747240798,
        "gradient_norm": 0.3579971492290497,
        "train_loss": 3.0597610473632812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20633,
        "tokens": 10817634304,
        "learning_rate": 0.0001906248725691969,
        "gradient_norm": 0.43048861622810364,
        "train_loss": 3.0425500869750977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20634,
        "tokens": 10818158592,
        "learning_rate": 0.00019060033923482672,
        "gradient_norm": 0.37301120162010193,
        "train_loss": 3.0451600551605225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20635,
        "tokens": 10818682880,
        "learning_rate": 0.00019057580746957337,
        "gradient_norm": 0.3814076781272888,
        "train_loss": 3.031831741333008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20636,
        "tokens": 10819207168,
        "learning_rate": 0.00019055127727371323,
        "gradient_norm": 0.3951074481010437,
        "train_loss": 3.0503196716308594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20637,
        "tokens": 10819731456,
        "learning_rate": 0.00019052674864752215,
        "gradient_norm": 0.3823406398296356,
        "train_loss": 3.0597829818725586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20638,
        "tokens": 10820255744,
        "learning_rate": 0.0001905022215912765,
        "gradient_norm": 0.3840109705924988,
        "train_loss": 3.067258596420288,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20639,
        "tokens": 10820780032,
        "learning_rate": 0.00019047769610525212,
        "gradient_norm": 0.3714103698730469,
        "train_loss": 3.0245580673217773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20640,
        "tokens": 10821304320,
        "learning_rate": 0.00019045317218972527,
        "gradient_norm": 0.3821951448917389,
        "train_loss": 3.019761800765991,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20641,
        "tokens": 10821828608,
        "learning_rate": 0.00019042864984497186,
        "gradient_norm": 0.37432825565338135,
        "train_loss": 3.054569721221924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20642,
        "tokens": 10822352896,
        "learning_rate": 0.00019040412907126797,
        "gradient_norm": 0.4155128598213196,
        "train_loss": 3.0075225830078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20643,
        "tokens": 10822877184,
        "learning_rate": 0.0001903796098688897,
        "gradient_norm": 0.3917686641216278,
        "train_loss": 3.0445728302001953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20644,
        "tokens": 10823401472,
        "learning_rate": 0.00019035509223811286,
        "gradient_norm": 0.39110633730888367,
        "train_loss": 3.1117587089538574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20645,
        "tokens": 10823925760,
        "learning_rate": 0.00019033057617921366,
        "gradient_norm": 0.42210716009140015,
        "train_loss": 3.0722899436950684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20646,
        "tokens": 10824450048,
        "learning_rate": 0.0001903060616924678,
        "gradient_norm": 0.37520644068717957,
        "train_loss": 3.0510995388031006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20647,
        "tokens": 10824974336,
        "learning_rate": 0.00019028154877815146,
        "gradient_norm": 0.3598247766494751,
        "train_loss": 3.090493679046631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20648,
        "tokens": 10825498624,
        "learning_rate": 0.00019025703743654035,
        "gradient_norm": 0.3443825840950012,
        "train_loss": 3.053746223449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20649,
        "tokens": 10826022912,
        "learning_rate": 0.00019023252766791056,
        "gradient_norm": 0.37497320771217346,
        "train_loss": 3.0588676929473877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20650,
        "tokens": 10826547200,
        "learning_rate": 0.00019020801947253782,
        "gradient_norm": 0.3476034700870514,
        "train_loss": 3.0666568279266357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20651,
        "tokens": 10827071488,
        "learning_rate": 0.00019018351285069818,
        "gradient_norm": 0.3743893802165985,
        "train_loss": 3.0228848457336426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20652,
        "tokens": 10827595776,
        "learning_rate": 0.00019015900780266725,
        "gradient_norm": 0.31080517172813416,
        "train_loss": 3.1067819595336914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20653,
        "tokens": 10828120064,
        "learning_rate": 0.00019013450432872104,
        "gradient_norm": 0.3280005156993866,
        "train_loss": 3.052090883255005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20654,
        "tokens": 10828644352,
        "learning_rate": 0.00019011000242913543,
        "gradient_norm": 0.31880030035972595,
        "train_loss": 3.0732388496398926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20655,
        "tokens": 10829168640,
        "learning_rate": 0.000190085502104186,
        "gradient_norm": 0.3961915671825409,
        "train_loss": 3.086088180541992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20656,
        "tokens": 10829692928,
        "learning_rate": 0.00019006100335414877,
        "gradient_norm": 0.4108525812625885,
        "train_loss": 3.108783721923828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20657,
        "tokens": 10830217216,
        "learning_rate": 0.00019003650617929925,
        "gradient_norm": 0.3776984214782715,
        "train_loss": 2.995478868484497,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20658,
        "tokens": 10830741504,
        "learning_rate": 0.00019001201057991347,
        "gradient_norm": 0.3856455683708191,
        "train_loss": 3.0701212882995605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20659,
        "tokens": 10831265792,
        "learning_rate": 0.00018998751655626689,
        "gradient_norm": 0.3523799479007721,
        "train_loss": 3.109520435333252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20660,
        "tokens": 10831790080,
        "learning_rate": 0.00018996302410863544,
        "gradient_norm": 0.3659134805202484,
        "train_loss": 3.040194034576416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20661,
        "tokens": 10832314368,
        "learning_rate": 0.00018993853323729463,
        "gradient_norm": 0.34631064534187317,
        "train_loss": 3.039951801300049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20662,
        "tokens": 10832838656,
        "learning_rate": 0.0001899140439425202,
        "gradient_norm": 0.3654012382030487,
        "train_loss": 3.07692551612854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20663,
        "tokens": 10833362944,
        "learning_rate": 0.00018988955622458792,
        "gradient_norm": 0.37606850266456604,
        "train_loss": 3.0354795455932617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20664,
        "tokens": 10833887232,
        "learning_rate": 0.00018986507008377323,
        "gradient_norm": 0.37514618039131165,
        "train_loss": 3.044844627380371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20665,
        "tokens": 10834411520,
        "learning_rate": 0.000189840585520352,
        "gradient_norm": 0.363028883934021,
        "train_loss": 3.0500481128692627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20666,
        "tokens": 10834935808,
        "learning_rate": 0.00018981610253459959,
        "gradient_norm": 0.3920775353908539,
        "train_loss": 3.032339096069336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20667,
        "tokens": 10835460096,
        "learning_rate": 0.00018979162112679176,
        "gradient_norm": 0.36574456095695496,
        "train_loss": 3.046206474304199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20668,
        "tokens": 10835984384,
        "learning_rate": 0.00018976714129720392,
        "gradient_norm": 0.37797465920448303,
        "train_loss": 2.9990181922912598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20669,
        "tokens": 10836508672,
        "learning_rate": 0.00018974266304611182,
        "gradient_norm": 0.37621238827705383,
        "train_loss": 3.08284592628479,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20670,
        "tokens": 10837032960,
        "learning_rate": 0.00018971818637379076,
        "gradient_norm": 0.40326371788978577,
        "train_loss": 3.104703426361084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20671,
        "tokens": 10837557248,
        "learning_rate": 0.0001896937112805165,
        "gradient_norm": 0.36567533016204834,
        "train_loss": 3.005657196044922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20672,
        "tokens": 10838081536,
        "learning_rate": 0.0001896692377665643,
        "gradient_norm": 0.35156628489494324,
        "train_loss": 3.0459799766540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20673,
        "tokens": 10838605824,
        "learning_rate": 0.00018964476583220976,
        "gradient_norm": 0.3731822371482849,
        "train_loss": 3.0743207931518555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20674,
        "tokens": 10839130112,
        "learning_rate": 0.00018962029547772843,
        "gradient_norm": 0.33851683139801025,
        "train_loss": 3.082367181777954,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20675,
        "tokens": 10839654400,
        "learning_rate": 0.00018959582670339558,
        "gradient_norm": 0.3885135054588318,
        "train_loss": 3.0782382488250732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20676,
        "tokens": 10840178688,
        "learning_rate": 0.0001895713595094868,
        "gradient_norm": 0.3478577136993408,
        "train_loss": 3.0484602451324463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20677,
        "tokens": 10840702976,
        "learning_rate": 0.00018954689389627736,
        "gradient_norm": 0.3858751952648163,
        "train_loss": 3.0071158409118652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20678,
        "tokens": 10841227264,
        "learning_rate": 0.00018952242986404276,
        "gradient_norm": 0.3548831641674042,
        "train_loss": 3.06472110748291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20679,
        "tokens": 10841751552,
        "learning_rate": 0.00018949796741305822,
        "gradient_norm": 0.37034228444099426,
        "train_loss": 3.0697884559631348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20680,
        "tokens": 10842275840,
        "learning_rate": 0.0001894735065435993,
        "gradient_norm": 0.4148303270339966,
        "train_loss": 3.0378806591033936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20681,
        "tokens": 10842800128,
        "learning_rate": 0.00018944904725594117,
        "gradient_norm": 0.3667011559009552,
        "train_loss": 3.0664024353027344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20682,
        "tokens": 10843324416,
        "learning_rate": 0.00018942458955035918,
        "gradient_norm": 0.3500547707080841,
        "train_loss": 3.0465502738952637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20683,
        "tokens": 10843848704,
        "learning_rate": 0.00018940013342712882,
        "gradient_norm": 0.4135054051876068,
        "train_loss": 3.046283721923828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20684,
        "tokens": 10844372992,
        "learning_rate": 0.00018937567888652508,
        "gradient_norm": 0.33378440141677856,
        "train_loss": 3.073550224304199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20685,
        "tokens": 10844897280,
        "learning_rate": 0.00018935122592882348,
        "gradient_norm": 0.3941743075847626,
        "train_loss": 3.1078078746795654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20686,
        "tokens": 10845421568,
        "learning_rate": 0.00018932677455429903,
        "gradient_norm": 0.3534221649169922,
        "train_loss": 3.0834174156188965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20687,
        "tokens": 10845945856,
        "learning_rate": 0.00018930232476322719,
        "gradient_norm": 0.35927391052246094,
        "train_loss": 3.0512969493865967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20688,
        "tokens": 10846470144,
        "learning_rate": 0.00018927787655588298,
        "gradient_norm": 0.3848949670791626,
        "train_loss": 3.1153290271759033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20689,
        "tokens": 10846994432,
        "learning_rate": 0.00018925342993254178,
        "gradient_norm": 0.390527606010437,
        "train_loss": 3.0492076873779297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20690,
        "tokens": 10847518720,
        "learning_rate": 0.0001892289848934786,
        "gradient_norm": 0.37427714467048645,
        "train_loss": 3.129948616027832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20691,
        "tokens": 10848043008,
        "learning_rate": 0.00018920454143896872,
        "gradient_norm": 0.416412889957428,
        "train_loss": 3.0575153827667236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20692,
        "tokens": 10848567296,
        "learning_rate": 0.00018918009956928717,
        "gradient_norm": 0.41385042667388916,
        "train_loss": 3.0838911533355713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20693,
        "tokens": 10849091584,
        "learning_rate": 0.00018915565928470912,
        "gradient_norm": 0.3870561420917511,
        "train_loss": 3.0696332454681396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20694,
        "tokens": 10849615872,
        "learning_rate": 0.0001891312205855098,
        "gradient_norm": 0.44496452808380127,
        "train_loss": 3.0540904998779297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20695,
        "tokens": 10850140160,
        "learning_rate": 0.00018910678347196406,
        "gradient_norm": 0.39497530460357666,
        "train_loss": 3.0362460613250732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20696,
        "tokens": 10850664448,
        "learning_rate": 0.00018908234794434725,
        "gradient_norm": 0.43946313858032227,
        "train_loss": 3.0368266105651855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20697,
        "tokens": 10851188736,
        "learning_rate": 0.00018905791400293415,
        "gradient_norm": 0.35403597354888916,
        "train_loss": 3.082611083984375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20698,
        "tokens": 10851713024,
        "learning_rate": 0.000189033481648,
        "gradient_norm": 0.4264318645000458,
        "train_loss": 3.036173105239868,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20699,
        "tokens": 10852237312,
        "learning_rate": 0.00018900905087981966,
        "gradient_norm": 0.39516085386276245,
        "train_loss": 3.073843479156494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20700,
        "tokens": 10852761600,
        "learning_rate": 0.0001889846216986683,
        "gradient_norm": 0.4051114320755005,
        "train_loss": 3.047018051147461,
        "val_loss": 3.014561891555786,
        "hellaswag_acc": 0.2835092544555664,
        "hellaswag_acc_norm": 0.29306912422180176
    },
    {
        "step": 20701,
        "tokens": 10853285888,
        "learning_rate": 0.00018896019410482068,
        "gradient_norm": 0.3666626513004303,
        "train_loss": 3.131298065185547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20702,
        "tokens": 10853810176,
        "learning_rate": 0.0001889357680985519,
        "gradient_norm": 0.40819892287254333,
        "train_loss": 3.081587553024292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20703,
        "tokens": 10854334464,
        "learning_rate": 0.000188911343680137,
        "gradient_norm": 0.3794553577899933,
        "train_loss": 3.076930046081543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20704,
        "tokens": 10854858752,
        "learning_rate": 0.00018888692084985067,
        "gradient_norm": 0.41254591941833496,
        "train_loss": 3.0404019355773926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20705,
        "tokens": 10855383040,
        "learning_rate": 0.0001888624996079681,
        "gradient_norm": 0.3988543450832367,
        "train_loss": 3.0200400352478027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20706,
        "tokens": 10855907328,
        "learning_rate": 0.00018883807995476388,
        "gradient_norm": 0.41168659925460815,
        "train_loss": 3.0587387084960938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20707,
        "tokens": 10856431616,
        "learning_rate": 0.00018881366189051315,
        "gradient_norm": 0.43129071593284607,
        "train_loss": 3.064537763595581,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20708,
        "tokens": 10856955904,
        "learning_rate": 0.00018878924541549055,
        "gradient_norm": 0.39102762937545776,
        "train_loss": 3.0616159439086914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20709,
        "tokens": 10857480192,
        "learning_rate": 0.00018876483052997111,
        "gradient_norm": 0.4201745390892029,
        "train_loss": 3.0167319774627686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20710,
        "tokens": 10858004480,
        "learning_rate": 0.0001887404172342295,
        "gradient_norm": 0.4325115382671356,
        "train_loss": 3.100092887878418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20711,
        "tokens": 10858528768,
        "learning_rate": 0.0001887160055285406,
        "gradient_norm": 0.3994418680667877,
        "train_loss": 3.020845890045166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20712,
        "tokens": 10859053056,
        "learning_rate": 0.00018869159541317913,
        "gradient_norm": 0.47919705510139465,
        "train_loss": 3.053225517272949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20713,
        "tokens": 10859577344,
        "learning_rate": 0.00018866718688842,
        "gradient_norm": 0.36983969807624817,
        "train_loss": 3.0472331047058105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20714,
        "tokens": 10860101632,
        "learning_rate": 0.0001886427799545377,
        "gradient_norm": 0.44801294803619385,
        "train_loss": 3.1031107902526855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20715,
        "tokens": 10860625920,
        "learning_rate": 0.0001886183746118073,
        "gradient_norm": 0.36949557065963745,
        "train_loss": 3.0402746200561523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20716,
        "tokens": 10861150208,
        "learning_rate": 0.00018859397086050316,
        "gradient_norm": 0.3833785355091095,
        "train_loss": 3.063582420349121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20717,
        "tokens": 10861674496,
        "learning_rate": 0.00018856956870090029,
        "gradient_norm": 0.3418440520763397,
        "train_loss": 3.060145378112793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20718,
        "tokens": 10862198784,
        "learning_rate": 0.0001885451681332731,
        "gradient_norm": 0.4196452796459198,
        "train_loss": 3.0375800132751465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20719,
        "tokens": 10862723072,
        "learning_rate": 0.0001885207691578965,
        "gradient_norm": 0.3943886458873749,
        "train_loss": 3.0313854217529297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20720,
        "tokens": 10863247360,
        "learning_rate": 0.00018849637177504488,
        "gradient_norm": 0.3392307758331299,
        "train_loss": 3.0682380199432373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20721,
        "tokens": 10863771648,
        "learning_rate": 0.00018847197598499308,
        "gradient_norm": 0.3872065246105194,
        "train_loss": 3.0369884967803955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20722,
        "tokens": 10864295936,
        "learning_rate": 0.0001884475817880155,
        "gradient_norm": 0.3674469292163849,
        "train_loss": 3.0261311531066895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20723,
        "tokens": 10864820224,
        "learning_rate": 0.00018842318918438694,
        "gradient_norm": 0.4303343892097473,
        "train_loss": 3.064033031463623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20724,
        "tokens": 10865344512,
        "learning_rate": 0.00018839879817438178,
        "gradient_norm": 0.3466756045818329,
        "train_loss": 3.0760254859924316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20725,
        "tokens": 10865868800,
        "learning_rate": 0.00018837440875827476,
        "gradient_norm": 0.400944322347641,
        "train_loss": 2.9898841381073,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20726,
        "tokens": 10866393088,
        "learning_rate": 0.00018835002093634017,
        "gradient_norm": 0.3633004128932953,
        "train_loss": 3.056253671646118,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20727,
        "tokens": 10866917376,
        "learning_rate": 0.00018832563470885281,
        "gradient_norm": 0.41207340359687805,
        "train_loss": 3.0284500122070312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20728,
        "tokens": 10867441664,
        "learning_rate": 0.00018830125007608694,
        "gradient_norm": 0.37136340141296387,
        "train_loss": 3.0478553771972656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20729,
        "tokens": 10867965952,
        "learning_rate": 0.0001882768670383172,
        "gradient_norm": 0.38077452778816223,
        "train_loss": 3.0373897552490234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20730,
        "tokens": 10868490240,
        "learning_rate": 0.00018825248559581792,
        "gradient_norm": 0.40065130591392517,
        "train_loss": 3.0189390182495117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20731,
        "tokens": 10869014528,
        "learning_rate": 0.00018822810574886366,
        "gradient_norm": 0.3648858964443207,
        "train_loss": 3.1010384559631348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20732,
        "tokens": 10869538816,
        "learning_rate": 0.00018820372749772874,
        "gradient_norm": 0.38844767212867737,
        "train_loss": 3.061326026916504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20733,
        "tokens": 10870063104,
        "learning_rate": 0.00018817935084268757,
        "gradient_norm": 0.3866651952266693,
        "train_loss": 3.0734920501708984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20734,
        "tokens": 10870587392,
        "learning_rate": 0.00018815497578401476,
        "gradient_norm": 0.38736608624458313,
        "train_loss": 3.078070640563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20735,
        "tokens": 10871111680,
        "learning_rate": 0.00018813060232198437,
        "gradient_norm": 0.35708820819854736,
        "train_loss": 3.0372941493988037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20736,
        "tokens": 10871635968,
        "learning_rate": 0.00018810623045687096,
        "gradient_norm": 0.37001246213912964,
        "train_loss": 3.032011032104492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20737,
        "tokens": 10872160256,
        "learning_rate": 0.00018808186018894873,
        "gradient_norm": 0.3511631488800049,
        "train_loss": 3.0334854125976562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20738,
        "tokens": 10872684544,
        "learning_rate": 0.0001880574915184922,
        "gradient_norm": 0.3921375572681427,
        "train_loss": 3.0391643047332764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20739,
        "tokens": 10873208832,
        "learning_rate": 0.00018803312444577543,
        "gradient_norm": 0.3579784631729126,
        "train_loss": 3.058701992034912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20740,
        "tokens": 10873733120,
        "learning_rate": 0.0001880087589710729,
        "gradient_norm": 0.37597864866256714,
        "train_loss": 3.0680761337280273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20741,
        "tokens": 10874257408,
        "learning_rate": 0.00018798439509465866,
        "gradient_norm": 0.3581067621707916,
        "train_loss": 3.0595173835754395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20742,
        "tokens": 10874781696,
        "learning_rate": 0.00018796003281680712,
        "gradient_norm": 0.3579419255256653,
        "train_loss": 3.057323455810547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20743,
        "tokens": 10875305984,
        "learning_rate": 0.00018793567213779255,
        "gradient_norm": 0.35329464077949524,
        "train_loss": 3.043034553527832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20744,
        "tokens": 10875830272,
        "learning_rate": 0.00018791131305788896,
        "gradient_norm": 0.3420054018497467,
        "train_loss": 3.0750253200531006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20745,
        "tokens": 10876354560,
        "learning_rate": 0.0001878869555773708,
        "gradient_norm": 0.40950289368629456,
        "train_loss": 3.0512328147888184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20746,
        "tokens": 10876878848,
        "learning_rate": 0.00018786259969651197,
        "gradient_norm": 0.35505858063697815,
        "train_loss": 3.0678699016571045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20747,
        "tokens": 10877403136,
        "learning_rate": 0.00018783824541558687,
        "gradient_norm": 0.37952664494514465,
        "train_loss": 3.029963731765747,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20748,
        "tokens": 10877927424,
        "learning_rate": 0.00018781389273486943,
        "gradient_norm": 0.3413408398628235,
        "train_loss": 3.032464027404785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20749,
        "tokens": 10878451712,
        "learning_rate": 0.00018778954165463396,
        "gradient_norm": 0.35635390877723694,
        "train_loss": 3.071089267730713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20750,
        "tokens": 10878976000,
        "learning_rate": 0.00018776519217515437,
        "gradient_norm": 0.34170711040496826,
        "train_loss": 3.0950779914855957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20751,
        "tokens": 10879500288,
        "learning_rate": 0.00018774084429670497,
        "gradient_norm": 0.3535139560699463,
        "train_loss": 3.039060115814209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20752,
        "tokens": 10880024576,
        "learning_rate": 0.00018771649801955955,
        "gradient_norm": 0.35530319809913635,
        "train_loss": 3.050658702850342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20753,
        "tokens": 10880548864,
        "learning_rate": 0.00018769215334399236,
        "gradient_norm": 0.3431137800216675,
        "train_loss": 3.072815179824829,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20754,
        "tokens": 10881073152,
        "learning_rate": 0.00018766781027027742,
        "gradient_norm": 0.337981253862381,
        "train_loss": 3.073072910308838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20755,
        "tokens": 10881597440,
        "learning_rate": 0.00018764346879868865,
        "gradient_norm": 0.39009279012680054,
        "train_loss": 3.0914647579193115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20756,
        "tokens": 10882121728,
        "learning_rate": 0.00018761912892950014,
        "gradient_norm": 0.3331851065158844,
        "train_loss": 3.0587563514709473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20757,
        "tokens": 10882646016,
        "learning_rate": 0.00018759479066298576,
        "gradient_norm": 0.4185568392276764,
        "train_loss": 3.016643524169922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20758,
        "tokens": 10883170304,
        "learning_rate": 0.0001875704539994196,
        "gradient_norm": 0.33741700649261475,
        "train_loss": 3.017134666442871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20759,
        "tokens": 10883694592,
        "learning_rate": 0.00018754611893907544,
        "gradient_norm": 0.3755112886428833,
        "train_loss": 3.073946475982666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20760,
        "tokens": 10884218880,
        "learning_rate": 0.00018752178548222737,
        "gradient_norm": 0.39397600293159485,
        "train_loss": 3.1235008239746094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20761,
        "tokens": 10884743168,
        "learning_rate": 0.0001874974536291491,
        "gradient_norm": 0.39611536264419556,
        "train_loss": 3.033129930496216,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20762,
        "tokens": 10885267456,
        "learning_rate": 0.00018747312338011462,
        "gradient_norm": 0.40586456656455994,
        "train_loss": 3.024810314178467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20763,
        "tokens": 10885791744,
        "learning_rate": 0.0001874487947353979,
        "gradient_norm": 0.40929749608039856,
        "train_loss": 3.0937695503234863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20764,
        "tokens": 10886316032,
        "learning_rate": 0.00018742446769527262,
        "gradient_norm": 0.38024961948394775,
        "train_loss": 3.0348801612854004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20765,
        "tokens": 10886840320,
        "learning_rate": 0.00018740014226001277,
        "gradient_norm": 0.3772948384284973,
        "train_loss": 3.0060369968414307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20766,
        "tokens": 10887364608,
        "learning_rate": 0.00018737581842989196,
        "gradient_norm": 0.36374524235725403,
        "train_loss": 3.043194532394409,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20767,
        "tokens": 10887888896,
        "learning_rate": 0.00018735149620518424,
        "gradient_norm": 0.4061718285083771,
        "train_loss": 3.071906566619873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20768,
        "tokens": 10888413184,
        "learning_rate": 0.00018732717558616309,
        "gradient_norm": 0.3598102033138275,
        "train_loss": 3.063358783721924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20769,
        "tokens": 10888937472,
        "learning_rate": 0.00018730285657310254,
        "gradient_norm": 0.3973287343978882,
        "train_loss": 3.0417284965515137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20770,
        "tokens": 10889461760,
        "learning_rate": 0.00018727853916627614,
        "gradient_norm": 0.38980716466903687,
        "train_loss": 3.0906333923339844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20771,
        "tokens": 10889986048,
        "learning_rate": 0.0001872542233659578,
        "gradient_norm": 0.4337838590145111,
        "train_loss": 3.0137031078338623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20772,
        "tokens": 10890510336,
        "learning_rate": 0.00018722990917242096,
        "gradient_norm": 0.3705240488052368,
        "train_loss": 3.042806625366211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20773,
        "tokens": 10891034624,
        "learning_rate": 0.00018720559658593947,
        "gradient_norm": 0.3968972861766815,
        "train_loss": 3.032057285308838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20774,
        "tokens": 10891558912,
        "learning_rate": 0.00018718128560678713,
        "gradient_norm": 0.379447877407074,
        "train_loss": 3.0875020027160645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20775,
        "tokens": 10892083200,
        "learning_rate": 0.00018715697623523732,
        "gradient_norm": 0.35340142250061035,
        "train_loss": 3.043118715286255,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20776,
        "tokens": 10892607488,
        "learning_rate": 0.0001871326684715639,
        "gradient_norm": 0.4163969159126282,
        "train_loss": 3.088705062866211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20777,
        "tokens": 10893131776,
        "learning_rate": 0.0001871083623160403,
        "gradient_norm": 0.33800074458122253,
        "train_loss": 3.0871381759643555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20778,
        "tokens": 10893656064,
        "learning_rate": 0.0001870840577689403,
        "gradient_norm": 0.37810471653938293,
        "train_loss": 3.048741102218628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20779,
        "tokens": 10894180352,
        "learning_rate": 0.00018705975483053727,
        "gradient_norm": 0.3886645436286926,
        "train_loss": 3.078005313873291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20780,
        "tokens": 10894704640,
        "learning_rate": 0.00018703545350110497,
        "gradient_norm": 0.37515074014663696,
        "train_loss": 3.0942482948303223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20781,
        "tokens": 10895228928,
        "learning_rate": 0.00018701115378091677,
        "gradient_norm": 0.3882633149623871,
        "train_loss": 3.065812110900879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20782,
        "tokens": 10895753216,
        "learning_rate": 0.00018698685567024626,
        "gradient_norm": 0.3512916564941406,
        "train_loss": 3.0312602519989014,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20783,
        "tokens": 10896277504,
        "learning_rate": 0.00018696255916936708,
        "gradient_norm": 0.37276437878608704,
        "train_loss": 3.0511457920074463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20784,
        "tokens": 10896801792,
        "learning_rate": 0.00018693826427855248,
        "gradient_norm": 0.3734837770462036,
        "train_loss": 3.0475754737854004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20785,
        "tokens": 10897326080,
        "learning_rate": 0.00018691397099807614,
        "gradient_norm": 0.39627453684806824,
        "train_loss": 3.034837245941162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20786,
        "tokens": 10897850368,
        "learning_rate": 0.0001868896793282113,
        "gradient_norm": 0.37985798716545105,
        "train_loss": 3.0855965614318848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20787,
        "tokens": 10898374656,
        "learning_rate": 0.00018686538926923168,
        "gradient_norm": 0.3939492106437683,
        "train_loss": 3.028102397918701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20788,
        "tokens": 10898898944,
        "learning_rate": 0.00018684110082141037,
        "gradient_norm": 0.4124046266078949,
        "train_loss": 3.045261859893799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20789,
        "tokens": 10899423232,
        "learning_rate": 0.00018681681398502104,
        "gradient_norm": 0.3761307895183563,
        "train_loss": 3.0100882053375244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20790,
        "tokens": 10899947520,
        "learning_rate": 0.00018679252876033684,
        "gradient_norm": 0.4064180850982666,
        "train_loss": 2.997823715209961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20791,
        "tokens": 10900471808,
        "learning_rate": 0.00018676824514763133,
        "gradient_norm": 0.4035968780517578,
        "train_loss": 3.052180767059326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20792,
        "tokens": 10900996096,
        "learning_rate": 0.0001867439631471777,
        "gradient_norm": 0.42125821113586426,
        "train_loss": 3.100343704223633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20793,
        "tokens": 10901520384,
        "learning_rate": 0.00018671968275924932,
        "gradient_norm": 0.42479413747787476,
        "train_loss": 3.0814685821533203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20794,
        "tokens": 10902044672,
        "learning_rate": 0.00018669540398411964,
        "gradient_norm": 0.3824167847633362,
        "train_loss": 3.0578179359436035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20795,
        "tokens": 10902568960,
        "learning_rate": 0.00018667112682206168,
        "gradient_norm": 0.36573925614356995,
        "train_loss": 3.1070644855499268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20796,
        "tokens": 10903093248,
        "learning_rate": 0.000186646851273349,
        "gradient_norm": 0.4002324342727661,
        "train_loss": 3.0936455726623535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20797,
        "tokens": 10903617536,
        "learning_rate": 0.00018662257733825455,
        "gradient_norm": 0.39127984642982483,
        "train_loss": 3.0551745891571045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20798,
        "tokens": 10904141824,
        "learning_rate": 0.00018659830501705185,
        "gradient_norm": 0.3756120204925537,
        "train_loss": 3.0827548503875732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20799,
        "tokens": 10904666112,
        "learning_rate": 0.00018657403431001385,
        "gradient_norm": 0.3880859315395355,
        "train_loss": 2.993098497390747,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20800,
        "tokens": 10905190400,
        "learning_rate": 0.000186549765217414,
        "gradient_norm": 0.41868385672569275,
        "train_loss": 3.063443660736084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20801,
        "tokens": 10905714688,
        "learning_rate": 0.00018652549773952526,
        "gradient_norm": 0.3497168719768524,
        "train_loss": 3.024959087371826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20802,
        "tokens": 10906238976,
        "learning_rate": 0.00018650123187662087,
        "gradient_norm": 0.3856845200061798,
        "train_loss": 3.0487070083618164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20803,
        "tokens": 10906763264,
        "learning_rate": 0.00018647696762897413,
        "gradient_norm": 0.3561154305934906,
        "train_loss": 3.0865867137908936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20804,
        "tokens": 10907287552,
        "learning_rate": 0.0001864527049968579,
        "gradient_norm": 0.35485580563545227,
        "train_loss": 3.0396533012390137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20805,
        "tokens": 10907811840,
        "learning_rate": 0.0001864284439805455,
        "gradient_norm": 0.34769442677497864,
        "train_loss": 3.081279754638672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20806,
        "tokens": 10908336128,
        "learning_rate": 0.00018640418458030987,
        "gradient_norm": 0.39949914813041687,
        "train_loss": 3.042656421661377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20807,
        "tokens": 10908860416,
        "learning_rate": 0.00018637992679642422,
        "gradient_norm": 0.3864201307296753,
        "train_loss": 3.0933446884155273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20808,
        "tokens": 10909384704,
        "learning_rate": 0.00018635567062916142,
        "gradient_norm": 0.3578437566757202,
        "train_loss": 3.046311140060425,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20809,
        "tokens": 10909908992,
        "learning_rate": 0.00018633141607879468,
        "gradient_norm": 0.3350110650062561,
        "train_loss": 3.0614871978759766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20810,
        "tokens": 10910433280,
        "learning_rate": 0.00018630716314559686,
        "gradient_norm": 0.3624894917011261,
        "train_loss": 3.078923225402832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20811,
        "tokens": 10910957568,
        "learning_rate": 0.00018628291182984114,
        "gradient_norm": 0.38411659002304077,
        "train_loss": 2.987617254257202,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20812,
        "tokens": 10911481856,
        "learning_rate": 0.0001862586621318003,
        "gradient_norm": 0.3592122793197632,
        "train_loss": 3.028449058532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20813,
        "tokens": 10912006144,
        "learning_rate": 0.00018623441405174736,
        "gradient_norm": 0.3906586468219757,
        "train_loss": 3.0509252548217773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20814,
        "tokens": 10912530432,
        "learning_rate": 0.00018621016758995544,
        "gradient_norm": 0.3745388686656952,
        "train_loss": 3.082282543182373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20815,
        "tokens": 10913054720,
        "learning_rate": 0.00018618592274669723,
        "gradient_norm": 0.3616143763065338,
        "train_loss": 3.0437843799591064,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20816,
        "tokens": 10913579008,
        "learning_rate": 0.0001861616795222458,
        "gradient_norm": 0.38867953419685364,
        "train_loss": 3.087221622467041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20817,
        "tokens": 10914103296,
        "learning_rate": 0.00018613743791687386,
        "gradient_norm": 0.37316396832466125,
        "train_loss": 3.0555546283721924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20818,
        "tokens": 10914627584,
        "learning_rate": 0.0001861131979308545,
        "gradient_norm": 0.3793046474456787,
        "train_loss": 3.067798614501953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20819,
        "tokens": 10915151872,
        "learning_rate": 0.00018608895956446036,
        "gradient_norm": 0.39061522483825684,
        "train_loss": 3.0534873008728027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20820,
        "tokens": 10915676160,
        "learning_rate": 0.00018606472281796444,
        "gradient_norm": 0.3803558051586151,
        "train_loss": 3.063500165939331,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20821,
        "tokens": 10916200448,
        "learning_rate": 0.0001860404876916394,
        "gradient_norm": 0.40371763706207275,
        "train_loss": 3.1219825744628906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20822,
        "tokens": 10916724736,
        "learning_rate": 0.00018601625418575825,
        "gradient_norm": 0.4384041130542755,
        "train_loss": 3.0364160537719727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20823,
        "tokens": 10917249024,
        "learning_rate": 0.00018599202230059353,
        "gradient_norm": 0.386707067489624,
        "train_loss": 3.0292439460754395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20824,
        "tokens": 10917773312,
        "learning_rate": 0.00018596779203641818,
        "gradient_norm": 0.3723975718021393,
        "train_loss": 3.133183002471924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20825,
        "tokens": 10918297600,
        "learning_rate": 0.00018594356339350483,
        "gradient_norm": 0.37876540422439575,
        "train_loss": 3.044567108154297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20826,
        "tokens": 10918821888,
        "learning_rate": 0.00018591933637212627,
        "gradient_norm": 0.39102834463119507,
        "train_loss": 3.0472912788391113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20827,
        "tokens": 10919346176,
        "learning_rate": 0.00018589511097255514,
        "gradient_norm": 0.34711992740631104,
        "train_loss": 3.041027069091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20828,
        "tokens": 10919870464,
        "learning_rate": 0.00018587088719506425,
        "gradient_norm": 0.35871121287345886,
        "train_loss": 3.0133442878723145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20829,
        "tokens": 10920394752,
        "learning_rate": 0.00018584666503992608,
        "gradient_norm": 0.37946873903274536,
        "train_loss": 3.075439214706421,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20830,
        "tokens": 10920919040,
        "learning_rate": 0.0001858224445074135,
        "gradient_norm": 0.3745748996734619,
        "train_loss": 3.0388851165771484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20831,
        "tokens": 10921443328,
        "learning_rate": 0.00018579822559779892,
        "gradient_norm": 0.37610170245170593,
        "train_loss": 3.0319929122924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20832,
        "tokens": 10921967616,
        "learning_rate": 0.00018577400831135514,
        "gradient_norm": 0.3626938760280609,
        "train_loss": 3.079969882965088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20833,
        "tokens": 10922491904,
        "learning_rate": 0.00018574979264835459,
        "gradient_norm": 0.40539249777793884,
        "train_loss": 3.0084705352783203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20834,
        "tokens": 10923016192,
        "learning_rate": 0.00018572557860907005,
        "gradient_norm": 0.36264336109161377,
        "train_loss": 3.0254626274108887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20835,
        "tokens": 10923540480,
        "learning_rate": 0.00018570136619377387,
        "gradient_norm": 0.4001953899860382,
        "train_loss": 3.0637006759643555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20836,
        "tokens": 10924064768,
        "learning_rate": 0.00018567715540273878,
        "gradient_norm": 0.3757091760635376,
        "train_loss": 3.069382667541504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20837,
        "tokens": 10924589056,
        "learning_rate": 0.00018565294623623711,
        "gradient_norm": 0.3817332983016968,
        "train_loss": 3.0923705101013184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20838,
        "tokens": 10925113344,
        "learning_rate": 0.00018562873869454154,
        "gradient_norm": 0.35968926548957825,
        "train_loss": 3.1058907508850098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20839,
        "tokens": 10925637632,
        "learning_rate": 0.0001856045327779244,
        "gradient_norm": 0.37538599967956543,
        "train_loss": 3.0065760612487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20840,
        "tokens": 10926161920,
        "learning_rate": 0.00018558032848665836,
        "gradient_norm": 0.3694784641265869,
        "train_loss": 3.0304617881774902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20841,
        "tokens": 10926686208,
        "learning_rate": 0.0001855561258210156,
        "gradient_norm": 0.3655271828174591,
        "train_loss": 3.0601367950439453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20842,
        "tokens": 10927210496,
        "learning_rate": 0.00018553192478126874,
        "gradient_norm": 0.35625022649765015,
        "train_loss": 2.9849934577941895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20843,
        "tokens": 10927734784,
        "learning_rate": 0.00018550772536769021,
        "gradient_norm": 0.3605201840400696,
        "train_loss": 3.039361000061035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20844,
        "tokens": 10928259072,
        "learning_rate": 0.00018548352758055228,
        "gradient_norm": 0.34320497512817383,
        "train_loss": 3.028292179107666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20845,
        "tokens": 10928783360,
        "learning_rate": 0.00018545933142012747,
        "gradient_norm": 0.3843920826911926,
        "train_loss": 3.0236916542053223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20846,
        "tokens": 10929307648,
        "learning_rate": 0.00018543513688668798,
        "gradient_norm": 0.3810439705848694,
        "train_loss": 3.0753722190856934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20847,
        "tokens": 10929831936,
        "learning_rate": 0.0001854109439805063,
        "gradient_norm": 0.3701707720756531,
        "train_loss": 3.037217617034912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20848,
        "tokens": 10930356224,
        "learning_rate": 0.0001853867527018546,
        "gradient_norm": 0.3412534296512604,
        "train_loss": 3.057644844055176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20849,
        "tokens": 10930880512,
        "learning_rate": 0.0001853625630510054,
        "gradient_norm": 0.38252222537994385,
        "train_loss": 3.0205111503601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20850,
        "tokens": 10931404800,
        "learning_rate": 0.00018533837502823067,
        "gradient_norm": 0.3667980432510376,
        "train_loss": 3.080280303955078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20851,
        "tokens": 10931929088,
        "learning_rate": 0.00018531418863380303,
        "gradient_norm": 0.42808061838150024,
        "train_loss": 3.0392956733703613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20852,
        "tokens": 10932453376,
        "learning_rate": 0.00018529000386799442,
        "gradient_norm": 0.38886457681655884,
        "train_loss": 3.06620717048645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20853,
        "tokens": 10932977664,
        "learning_rate": 0.00018526582073107717,
        "gradient_norm": 0.3828108012676239,
        "train_loss": 3.0883870124816895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20854,
        "tokens": 10933501952,
        "learning_rate": 0.00018524163922332366,
        "gradient_norm": 0.3810318410396576,
        "train_loss": 3.0193638801574707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20855,
        "tokens": 10934026240,
        "learning_rate": 0.00018521745934500585,
        "gradient_norm": 0.36902570724487305,
        "train_loss": 3.0378713607788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20856,
        "tokens": 10934550528,
        "learning_rate": 0.00018519328109639608,
        "gradient_norm": 0.3416098952293396,
        "train_loss": 3.0249269008636475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20857,
        "tokens": 10935074816,
        "learning_rate": 0.00018516910447776637,
        "gradient_norm": 0.368903249502182,
        "train_loss": 3.06776762008667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20858,
        "tokens": 10935599104,
        "learning_rate": 0.000185144929489389,
        "gradient_norm": 0.35202786326408386,
        "train_loss": 3.037583827972412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20859,
        "tokens": 10936123392,
        "learning_rate": 0.00018512075613153593,
        "gradient_norm": 0.36783114075660706,
        "train_loss": 3.033991813659668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20860,
        "tokens": 10936647680,
        "learning_rate": 0.00018509658440447944,
        "gradient_norm": 0.3931276500225067,
        "train_loss": 3.0844645500183105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20861,
        "tokens": 10937171968,
        "learning_rate": 0.00018507241430849145,
        "gradient_norm": 0.38621243834495544,
        "train_loss": 3.046050786972046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20862,
        "tokens": 10937696256,
        "learning_rate": 0.00018504824584384406,
        "gradient_norm": 0.5227908492088318,
        "train_loss": 3.0215911865234375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20863,
        "tokens": 10938220544,
        "learning_rate": 0.00018502407901080947,
        "gradient_norm": 0.4755288064479828,
        "train_loss": 3.0748696327209473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20864,
        "tokens": 10938744832,
        "learning_rate": 0.00018499991380965946,
        "gradient_norm": 0.4552978575229645,
        "train_loss": 3.0379765033721924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20865,
        "tokens": 10939269120,
        "learning_rate": 0.0001849757502406663,
        "gradient_norm": 0.4709787964820862,
        "train_loss": 3.0896122455596924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20866,
        "tokens": 10939793408,
        "learning_rate": 0.00018495158830410173,
        "gradient_norm": 0.4328457713127136,
        "train_loss": 3.063544750213623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20867,
        "tokens": 10940317696,
        "learning_rate": 0.00018492742800023794,
        "gradient_norm": 0.4190692603588104,
        "train_loss": 3.0530333518981934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20868,
        "tokens": 10940841984,
        "learning_rate": 0.0001849032693293467,
        "gradient_norm": 0.44458672404289246,
        "train_loss": 3.065802574157715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20869,
        "tokens": 10941366272,
        "learning_rate": 0.0001848791122917001,
        "gradient_norm": 0.39032578468322754,
        "train_loss": 3.038191318511963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20870,
        "tokens": 10941890560,
        "learning_rate": 0.00018485495688756994,
        "gradient_norm": 0.44116804003715515,
        "train_loss": 2.974699020385742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20871,
        "tokens": 10942414848,
        "learning_rate": 0.00018483080311722822,
        "gradient_norm": 0.3583955764770508,
        "train_loss": 3.0633020401000977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20872,
        "tokens": 10942939136,
        "learning_rate": 0.00018480665098094667,
        "gradient_norm": 0.4193194508552551,
        "train_loss": 3.0494537353515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20873,
        "tokens": 10943463424,
        "learning_rate": 0.00018478250047899728,
        "gradient_norm": 0.3548995554447174,
        "train_loss": 3.0423192977905273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20874,
        "tokens": 10943987712,
        "learning_rate": 0.00018475835161165197,
        "gradient_norm": 0.3377193808555603,
        "train_loss": 3.033809185028076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20875,
        "tokens": 10944512000,
        "learning_rate": 0.00018473420437918234,
        "gradient_norm": 0.40113916993141174,
        "train_loss": 3.0763473510742188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20876,
        "tokens": 10945036288,
        "learning_rate": 0.0001847100587818604,
        "gradient_norm": 0.35529300570487976,
        "train_loss": 3.0335536003112793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20877,
        "tokens": 10945560576,
        "learning_rate": 0.0001846859148199578,
        "gradient_norm": 0.36189138889312744,
        "train_loss": 3.0542407035827637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20878,
        "tokens": 10946084864,
        "learning_rate": 0.00018466177249374646,
        "gradient_norm": 0.3835557997226715,
        "train_loss": 2.9928078651428223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20879,
        "tokens": 10946609152,
        "learning_rate": 0.0001846376318034979,
        "gradient_norm": 0.38305625319480896,
        "train_loss": 3.083317279815674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20880,
        "tokens": 10947133440,
        "learning_rate": 0.00018461349274948412,
        "gradient_norm": 0.38653597235679626,
        "train_loss": 3.0148539543151855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20881,
        "tokens": 10947657728,
        "learning_rate": 0.0001845893553319766,
        "gradient_norm": 0.3683691620826721,
        "train_loss": 3.0644302368164062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20882,
        "tokens": 10948182016,
        "learning_rate": 0.00018456521955124717,
        "gradient_norm": 0.33407196402549744,
        "train_loss": 3.0704197883605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20883,
        "tokens": 10948706304,
        "learning_rate": 0.00018454108540756755,
        "gradient_norm": 0.36955761909484863,
        "train_loss": 3.0488357543945312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20884,
        "tokens": 10949230592,
        "learning_rate": 0.00018451695290120927,
        "gradient_norm": 0.36264821887016296,
        "train_loss": 3.0383217334747314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20885,
        "tokens": 10949754880,
        "learning_rate": 0.00018449282203244412,
        "gradient_norm": 0.3913184404373169,
        "train_loss": 3.070167064666748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20886,
        "tokens": 10950279168,
        "learning_rate": 0.0001844686928015435,
        "gradient_norm": 0.3779570162296295,
        "train_loss": 3.0418219566345215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20887,
        "tokens": 10950803456,
        "learning_rate": 0.00018444456520877933,
        "gradient_norm": 0.36646515130996704,
        "train_loss": 3.015371799468994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20888,
        "tokens": 10951327744,
        "learning_rate": 0.00018442043925442285,
        "gradient_norm": 0.3721472918987274,
        "train_loss": 3.1320393085479736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20889,
        "tokens": 10951852032,
        "learning_rate": 0.00018439631493874593,
        "gradient_norm": 0.3681966960430145,
        "train_loss": 3.0488476753234863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20890,
        "tokens": 10952376320,
        "learning_rate": 0.00018437219226201987,
        "gradient_norm": 0.33751797676086426,
        "train_loss": 3.01228404045105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20891,
        "tokens": 10952900608,
        "learning_rate": 0.00018434807122451641,
        "gradient_norm": 0.39795300364494324,
        "train_loss": 3.0599558353424072,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20892,
        "tokens": 10953424896,
        "learning_rate": 0.00018432395182650687,
        "gradient_norm": 0.3514261841773987,
        "train_loss": 3.072606086730957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20893,
        "tokens": 10953949184,
        "learning_rate": 0.00018429983406826285,
        "gradient_norm": 0.38445812463760376,
        "train_loss": 3.0842947959899902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20894,
        "tokens": 10954473472,
        "learning_rate": 0.00018427571795005593,
        "gradient_norm": 0.4003446102142334,
        "train_loss": 3.072192430496216,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20895,
        "tokens": 10954997760,
        "learning_rate": 0.00018425160347215733,
        "gradient_norm": 0.3848686218261719,
        "train_loss": 3.0919885635375977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20896,
        "tokens": 10955522048,
        "learning_rate": 0.00018422749063483872,
        "gradient_norm": 0.3408954441547394,
        "train_loss": 3.047422409057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20897,
        "tokens": 10956046336,
        "learning_rate": 0.00018420337943837135,
        "gradient_norm": 0.373543381690979,
        "train_loss": 3.120363235473633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20898,
        "tokens": 10956570624,
        "learning_rate": 0.00018417926988302673,
        "gradient_norm": 0.36284562945365906,
        "train_loss": 3.0982890129089355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20899,
        "tokens": 10957094912,
        "learning_rate": 0.00018415516196907612,
        "gradient_norm": 0.34617140889167786,
        "train_loss": 2.9950966835021973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20900,
        "tokens": 10957619200,
        "learning_rate": 0.00018413105569679104,
        "gradient_norm": 0.412000834941864,
        "train_loss": 3.058821201324463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20901,
        "tokens": 10958143488,
        "learning_rate": 0.00018410695106644268,
        "gradient_norm": 0.346181720495224,
        "train_loss": 3.078904867172241,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20902,
        "tokens": 10958667776,
        "learning_rate": 0.00018408284807830245,
        "gradient_norm": 0.432438462972641,
        "train_loss": 3.110135555267334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20903,
        "tokens": 10959192064,
        "learning_rate": 0.00018405874673264178,
        "gradient_norm": 0.4261280298233032,
        "train_loss": 3.179262161254883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20904,
        "tokens": 10959716352,
        "learning_rate": 0.0001840346470297317,
        "gradient_norm": 0.38652297854423523,
        "train_loss": 3.0701332092285156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20905,
        "tokens": 10960240640,
        "learning_rate": 0.00018401054896984373,
        "gradient_norm": 0.3851519227027893,
        "train_loss": 2.98077130317688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20906,
        "tokens": 10960764928,
        "learning_rate": 0.0001839864525532489,
        "gradient_norm": 0.341660737991333,
        "train_loss": 3.040048122406006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20907,
        "tokens": 10961289216,
        "learning_rate": 0.00018396235778021867,
        "gradient_norm": 0.36306139826774597,
        "train_loss": 3.067401647567749,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20908,
        "tokens": 10961813504,
        "learning_rate": 0.00018393826465102405,
        "gradient_norm": 0.3744141161441803,
        "train_loss": 3.0151877403259277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20909,
        "tokens": 10962337792,
        "learning_rate": 0.0001839141731659364,
        "gradient_norm": 0.37642550468444824,
        "train_loss": 3.00612735748291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20910,
        "tokens": 10962862080,
        "learning_rate": 0.00018389008332522677,
        "gradient_norm": 0.3816460072994232,
        "train_loss": 3.0313193798065186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20911,
        "tokens": 10963386368,
        "learning_rate": 0.00018386599512916648,
        "gradient_norm": 0.4420834183692932,
        "train_loss": 3.042365312576294,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20912,
        "tokens": 10963910656,
        "learning_rate": 0.00018384190857802644,
        "gradient_norm": 0.38470664620399475,
        "train_loss": 3.0726675987243652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20913,
        "tokens": 10964434944,
        "learning_rate": 0.00018381782367207794,
        "gradient_norm": 0.39327117800712585,
        "train_loss": 3.1031575202941895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20914,
        "tokens": 10964959232,
        "learning_rate": 0.00018379374041159214,
        "gradient_norm": 0.3719427287578583,
        "train_loss": 3.066751480102539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20915,
        "tokens": 10965483520,
        "learning_rate": 0.00018376965879683997,
        "gradient_norm": 0.3549697697162628,
        "train_loss": 3.0340683460235596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20916,
        "tokens": 10966007808,
        "learning_rate": 0.00018374557882809263,
        "gradient_norm": 0.4033195674419403,
        "train_loss": 3.0333211421966553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20917,
        "tokens": 10966532096,
        "learning_rate": 0.00018372150050562102,
        "gradient_norm": 0.3742925226688385,
        "train_loss": 3.059152126312256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20918,
        "tokens": 10967056384,
        "learning_rate": 0.00018369742382969638,
        "gradient_norm": 0.3900408148765564,
        "train_loss": 3.0410208702087402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20919,
        "tokens": 10967580672,
        "learning_rate": 0.00018367334880058951,
        "gradient_norm": 0.3908281624317169,
        "train_loss": 3.0765082836151123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20920,
        "tokens": 10968104960,
        "learning_rate": 0.0001836492754185716,
        "gradient_norm": 0.40466952323913574,
        "train_loss": 3.0916638374328613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20921,
        "tokens": 10968629248,
        "learning_rate": 0.0001836252036839134,
        "gradient_norm": 0.3906598389148712,
        "train_loss": 3.045194149017334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20922,
        "tokens": 10969153536,
        "learning_rate": 0.0001836011335968861,
        "gradient_norm": 0.4049821197986603,
        "train_loss": 3.012601375579834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20923,
        "tokens": 10969677824,
        "learning_rate": 0.00018357706515776046,
        "gradient_norm": 0.4097641408443451,
        "train_loss": 3.069300651550293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20924,
        "tokens": 10970202112,
        "learning_rate": 0.00018355299836680754,
        "gradient_norm": 0.42321550846099854,
        "train_loss": 3.052359104156494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20925,
        "tokens": 10970726400,
        "learning_rate": 0.0001835289332242981,
        "gradient_norm": 0.36974507570266724,
        "train_loss": 3.0405614376068115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20926,
        "tokens": 10971250688,
        "learning_rate": 0.0001835048697305032,
        "gradient_norm": 0.4070459306240082,
        "train_loss": 3.0740456581115723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20927,
        "tokens": 10971774976,
        "learning_rate": 0.00018348080788569348,
        "gradient_norm": 0.3648047149181366,
        "train_loss": 3.081592082977295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20928,
        "tokens": 10972299264,
        "learning_rate": 0.00018345674769014003,
        "gradient_norm": 0.39321622252464294,
        "train_loss": 3.062234878540039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20929,
        "tokens": 10972823552,
        "learning_rate": 0.00018343268914411344,
        "gradient_norm": 0.34394654631614685,
        "train_loss": 3.0328712463378906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20930,
        "tokens": 10973347840,
        "learning_rate": 0.00018340863224788475,
        "gradient_norm": 0.3513779640197754,
        "train_loss": 3.0505590438842773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20931,
        "tokens": 10973872128,
        "learning_rate": 0.00018338457700172454,
        "gradient_norm": 0.37122195959091187,
        "train_loss": 3.0940847396850586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20932,
        "tokens": 10974396416,
        "learning_rate": 0.00018336052340590375,
        "gradient_norm": 0.33651238679885864,
        "train_loss": 3.061056613922119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20933,
        "tokens": 10974920704,
        "learning_rate": 0.00018333647146069298,
        "gradient_norm": 0.3630013167858124,
        "train_loss": 3.053555965423584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20934,
        "tokens": 10975444992,
        "learning_rate": 0.0001833124211663631,
        "gradient_norm": 0.3686903417110443,
        "train_loss": 3.0300755500793457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20935,
        "tokens": 10975969280,
        "learning_rate": 0.0001832883725231847,
        "gradient_norm": 0.3625729978084564,
        "train_loss": 3.0763940811157227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20936,
        "tokens": 10976493568,
        "learning_rate": 0.00018326432553142868,
        "gradient_norm": 0.3478814959526062,
        "train_loss": 3.108513832092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20937,
        "tokens": 10977017856,
        "learning_rate": 0.00018324028019136546,
        "gradient_norm": 0.3827451467514038,
        "train_loss": 3.0107386112213135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20938,
        "tokens": 10977542144,
        "learning_rate": 0.0001832162365032659,
        "gradient_norm": 0.3649038076400757,
        "train_loss": 3.076063871383667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20939,
        "tokens": 10978066432,
        "learning_rate": 0.0001831921944674005,
        "gradient_norm": 0.3928182125091553,
        "train_loss": 3.043844699859619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20940,
        "tokens": 10978590720,
        "learning_rate": 0.00018316815408404006,
        "gradient_norm": 0.3748432993888855,
        "train_loss": 2.979679822921753,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20941,
        "tokens": 10979115008,
        "learning_rate": 0.00018314411535345494,
        "gradient_norm": 0.36887142062187195,
        "train_loss": 3.0233168601989746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20942,
        "tokens": 10979639296,
        "learning_rate": 0.0001831200782759159,
        "gradient_norm": 0.3860693573951721,
        "train_loss": 3.0706686973571777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20943,
        "tokens": 10980163584,
        "learning_rate": 0.00018309604285169357,
        "gradient_norm": 0.41304945945739746,
        "train_loss": 3.057954788208008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20944,
        "tokens": 10980687872,
        "learning_rate": 0.00018307200908105828,
        "gradient_norm": 0.37788963317871094,
        "train_loss": 3.0031089782714844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20945,
        "tokens": 10981212160,
        "learning_rate": 0.0001830479769642808,
        "gradient_norm": 0.42519357800483704,
        "train_loss": 3.0809683799743652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20946,
        "tokens": 10981736448,
        "learning_rate": 0.0001830239465016314,
        "gradient_norm": 0.383421927690506,
        "train_loss": 3.0213043689727783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20947,
        "tokens": 10982260736,
        "learning_rate": 0.0001829999176933808,
        "gradient_norm": 0.3948720693588257,
        "train_loss": 3.018889904022217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20948,
        "tokens": 10982785024,
        "learning_rate": 0.00018297589053979925,
        "gradient_norm": 0.38444313406944275,
        "train_loss": 3.0102219581604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20949,
        "tokens": 10983309312,
        "learning_rate": 0.00018295186504115743,
        "gradient_norm": 0.3335590660572052,
        "train_loss": 3.0597426891326904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20950,
        "tokens": 10983833600,
        "learning_rate": 0.0001829278411977256,
        "gradient_norm": 0.3611401915550232,
        "train_loss": 3.0514354705810547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20951,
        "tokens": 10984357888,
        "learning_rate": 0.0001829038190097743,
        "gradient_norm": 0.36861154437065125,
        "train_loss": 3.0139546394348145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20952,
        "tokens": 10984882176,
        "learning_rate": 0.0001828797984775738,
        "gradient_norm": 0.3762265741825104,
        "train_loss": 3.0192010402679443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20953,
        "tokens": 10985406464,
        "learning_rate": 0.00018285577960139456,
        "gradient_norm": 0.3928760290145874,
        "train_loss": 3.058164119720459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20954,
        "tokens": 10985930752,
        "learning_rate": 0.00018283176238150704,
        "gradient_norm": 0.33267316222190857,
        "train_loss": 3.015767812728882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20955,
        "tokens": 10986455040,
        "learning_rate": 0.00018280774681818138,
        "gradient_norm": 0.39943641424179077,
        "train_loss": 3.010145425796509,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20956,
        "tokens": 10986979328,
        "learning_rate": 0.0001827837329116881,
        "gradient_norm": 0.3786998987197876,
        "train_loss": 3.034186601638794,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20957,
        "tokens": 10987503616,
        "learning_rate": 0.00018275972066229734,
        "gradient_norm": 0.3792782127857208,
        "train_loss": 3.0197229385375977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20958,
        "tokens": 10988027904,
        "learning_rate": 0.00018273571007027954,
        "gradient_norm": 0.40148431062698364,
        "train_loss": 3.114887237548828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20959,
        "tokens": 10988552192,
        "learning_rate": 0.00018271170113590482,
        "gradient_norm": 0.4442225992679596,
        "train_loss": 3.0189294815063477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20960,
        "tokens": 10989076480,
        "learning_rate": 0.00018268769385944357,
        "gradient_norm": 0.4034268856048584,
        "train_loss": 3.0019218921661377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20961,
        "tokens": 10989600768,
        "learning_rate": 0.00018266368824116586,
        "gradient_norm": 0.4549086391925812,
        "train_loss": 3.038703441619873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20962,
        "tokens": 10990125056,
        "learning_rate": 0.00018263968428134205,
        "gradient_norm": 0.3789832293987274,
        "train_loss": 3.051793336868286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20963,
        "tokens": 10990649344,
        "learning_rate": 0.0001826156819802423,
        "gradient_norm": 0.41543370485305786,
        "train_loss": 3.0855774879455566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20964,
        "tokens": 10991173632,
        "learning_rate": 0.00018259168133813675,
        "gradient_norm": 0.36849796772003174,
        "train_loss": 3.0839529037475586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20965,
        "tokens": 10991697920,
        "learning_rate": 0.00018256768235529563,
        "gradient_norm": 0.4000582695007324,
        "train_loss": 3.0890588760375977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20966,
        "tokens": 10992222208,
        "learning_rate": 0.00018254368503198892,
        "gradient_norm": 0.3713984489440918,
        "train_loss": 3.058946132659912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20967,
        "tokens": 10992746496,
        "learning_rate": 0.00018251968936848696,
        "gradient_norm": 0.37823960185050964,
        "train_loss": 3.0814056396484375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20968,
        "tokens": 10993270784,
        "learning_rate": 0.00018249569536505963,
        "gradient_norm": 0.39217036962509155,
        "train_loss": 3.031691312789917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20969,
        "tokens": 10993795072,
        "learning_rate": 0.00018247170302197722,
        "gradient_norm": 0.37991681694984436,
        "train_loss": 3.0532195568084717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20970,
        "tokens": 10994319360,
        "learning_rate": 0.0001824477123395096,
        "gradient_norm": 0.3913674056529999,
        "train_loss": 3.0574138164520264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20971,
        "tokens": 10994843648,
        "learning_rate": 0.00018242372331792687,
        "gradient_norm": 0.4318310022354126,
        "train_loss": 3.065504789352417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20972,
        "tokens": 10995367936,
        "learning_rate": 0.00018239973595749923,
        "gradient_norm": 0.4064905345439911,
        "train_loss": 3.0679092407226562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20973,
        "tokens": 10995892224,
        "learning_rate": 0.00018237575025849644,
        "gradient_norm": 0.4152369201183319,
        "train_loss": 2.981808662414551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20974,
        "tokens": 10996416512,
        "learning_rate": 0.00018235176622118871,
        "gradient_norm": 0.42101621627807617,
        "train_loss": 3.0913500785827637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20975,
        "tokens": 10996940800,
        "learning_rate": 0.0001823277838458458,
        "gradient_norm": 0.4789622724056244,
        "train_loss": 3.0955896377563477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20976,
        "tokens": 10997465088,
        "learning_rate": 0.00018230380313273786,
        "gradient_norm": 0.4476158022880554,
        "train_loss": 3.0300562381744385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20977,
        "tokens": 10997989376,
        "learning_rate": 0.0001822798240821346,
        "gradient_norm": 0.39481666684150696,
        "train_loss": 3.015740394592285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20978,
        "tokens": 10998513664,
        "learning_rate": 0.00018225584669430617,
        "gradient_norm": 0.4804531931877136,
        "train_loss": 3.0966081619262695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20979,
        "tokens": 10999037952,
        "learning_rate": 0.00018223187096952226,
        "gradient_norm": 0.3537308871746063,
        "train_loss": 3.015138864517212,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20980,
        "tokens": 10999562240,
        "learning_rate": 0.00018220789690805294,
        "gradient_norm": 0.47433629631996155,
        "train_loss": 3.011585235595703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20981,
        "tokens": 11000086528,
        "learning_rate": 0.00018218392451016787,
        "gradient_norm": 0.3900447487831116,
        "train_loss": 3.055238723754883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20982,
        "tokens": 11000610816,
        "learning_rate": 0.00018215995377613697,
        "gradient_norm": 0.4178012013435364,
        "train_loss": 3.0267038345336914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20983,
        "tokens": 11001135104,
        "learning_rate": 0.0001821359847062302,
        "gradient_norm": 0.4064595699310303,
        "train_loss": 3.0304980278015137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20984,
        "tokens": 11001659392,
        "learning_rate": 0.00018211201730071713,
        "gradient_norm": 0.40112248063087463,
        "train_loss": 2.9954237937927246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20985,
        "tokens": 11002183680,
        "learning_rate": 0.00018208805155986774,
        "gradient_norm": 0.41663551330566406,
        "train_loss": 3.0614023208618164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20986,
        "tokens": 11002707968,
        "learning_rate": 0.00018206408748395163,
        "gradient_norm": 0.4008527100086212,
        "train_loss": 3.0906076431274414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20987,
        "tokens": 11003232256,
        "learning_rate": 0.0001820401250732387,
        "gradient_norm": 0.3935929238796234,
        "train_loss": 3.0178632736206055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20988,
        "tokens": 11003756544,
        "learning_rate": 0.0001820161643279985,
        "gradient_norm": 0.40255388617515564,
        "train_loss": 3.0883164405822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20989,
        "tokens": 11004280832,
        "learning_rate": 0.00018199220524850094,
        "gradient_norm": 0.461343377828598,
        "train_loss": 3.1356265544891357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20990,
        "tokens": 11004805120,
        "learning_rate": 0.00018196824783501555,
        "gradient_norm": 0.4245833158493042,
        "train_loss": 3.024277687072754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20991,
        "tokens": 11005329408,
        "learning_rate": 0.000181944292087812,
        "gradient_norm": 0.3567922115325928,
        "train_loss": 3.048283576965332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20992,
        "tokens": 11005853696,
        "learning_rate": 0.0001819203380071601,
        "gradient_norm": 0.3700733482837677,
        "train_loss": 3.0517659187316895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20993,
        "tokens": 11006377984,
        "learning_rate": 0.00018189638559332931,
        "gradient_norm": 0.38169777393341064,
        "train_loss": 3.066152572631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20994,
        "tokens": 11006902272,
        "learning_rate": 0.00018187243484658942,
        "gradient_norm": 0.4022639989852905,
        "train_loss": 3.066358804702759,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20995,
        "tokens": 11007426560,
        "learning_rate": 0.0001818484857672098,
        "gradient_norm": 0.3863024413585663,
        "train_loss": 3.11236834526062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20996,
        "tokens": 11007950848,
        "learning_rate": 0.00018182453835546028,
        "gradient_norm": 0.3847954273223877,
        "train_loss": 3.093931198120117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20997,
        "tokens": 11008475136,
        "learning_rate": 0.00018180059261161015,
        "gradient_norm": 0.4368853271007538,
        "train_loss": 2.9436755180358887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20998,
        "tokens": 11008999424,
        "learning_rate": 0.0001817766485359292,
        "gradient_norm": 0.3648843765258789,
        "train_loss": 3.067880153656006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20999,
        "tokens": 11009523712,
        "learning_rate": 0.0001817527061286867,
        "gradient_norm": 0.3614259958267212,
        "train_loss": 3.0872802734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21000,
        "tokens": 11010048000,
        "learning_rate": 0.00018172876539015247,
        "gradient_norm": 0.3547315001487732,
        "train_loss": 3.0326085090637207,
        "val_loss": 3.0123162269592285,
        "hellaswag_acc": 0.2822147011756897,
        "hellaswag_acc_norm": 0.2969527840614319
    },
    {
        "step": 21001,
        "tokens": 11010572288,
        "learning_rate": 0.00018170482632059564,
        "gradient_norm": 0.38227128982543945,
        "train_loss": 2.999089241027832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21002,
        "tokens": 11011096576,
        "learning_rate": 0.00018168088892028589,
        "gradient_norm": 0.376477986574173,
        "train_loss": 3.025491237640381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21003,
        "tokens": 11011620864,
        "learning_rate": 0.00018165695318949268,
        "gradient_norm": 0.37136346101760864,
        "train_loss": 3.0550336837768555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21004,
        "tokens": 11012145152,
        "learning_rate": 0.0001816330191284853,
        "gradient_norm": 0.4362485706806183,
        "train_loss": 3.099877119064331,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21005,
        "tokens": 11012669440,
        "learning_rate": 0.00018160908673753334,
        "gradient_norm": 0.3460516929626465,
        "train_loss": 3.0461957454681396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21006,
        "tokens": 11013193728,
        "learning_rate": 0.00018158515601690594,
        "gradient_norm": 0.4406769871711731,
        "train_loss": 3.082871675491333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21007,
        "tokens": 11013718016,
        "learning_rate": 0.00018156122696687274,
        "gradient_norm": 0.36404016613960266,
        "train_loss": 2.9891366958618164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21008,
        "tokens": 11014242304,
        "learning_rate": 0.00018153729958770285,
        "gradient_norm": 0.39329788088798523,
        "train_loss": 3.0100789070129395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21009,
        "tokens": 11014766592,
        "learning_rate": 0.00018151337387966587,
        "gradient_norm": 0.3981068730354309,
        "train_loss": 3.0701394081115723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21010,
        "tokens": 11015290880,
        "learning_rate": 0.0001814894498430308,
        "gradient_norm": 0.3644830286502838,
        "train_loss": 3.0592877864837646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21011,
        "tokens": 11015815168,
        "learning_rate": 0.00018146552747806715,
        "gradient_norm": 0.3744867444038391,
        "train_loss": 3.0455269813537598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21012,
        "tokens": 11016339456,
        "learning_rate": 0.0001814416067850442,
        "gradient_norm": 0.384848952293396,
        "train_loss": 3.1054773330688477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21013,
        "tokens": 11016863744,
        "learning_rate": 0.00018141768776423105,
        "gradient_norm": 0.4311119318008423,
        "train_loss": 3.017850875854492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21014,
        "tokens": 11017388032,
        "learning_rate": 0.00018139377041589716,
        "gradient_norm": 0.3759427070617676,
        "train_loss": 3.0031583309173584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21015,
        "tokens": 11017912320,
        "learning_rate": 0.00018136985474031153,
        "gradient_norm": 0.4155278503894806,
        "train_loss": 3.0112321376800537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21016,
        "tokens": 11018436608,
        "learning_rate": 0.0001813459407377435,
        "gradient_norm": 0.35097530484199524,
        "train_loss": 3.0348987579345703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21017,
        "tokens": 11018960896,
        "learning_rate": 0.00018132202840846217,
        "gradient_norm": 0.3926028311252594,
        "train_loss": 3.046473503112793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21018,
        "tokens": 11019485184,
        "learning_rate": 0.00018129811775273683,
        "gradient_norm": 0.366401731967926,
        "train_loss": 3.0265092849731445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21019,
        "tokens": 11020009472,
        "learning_rate": 0.0001812742087708364,
        "gradient_norm": 0.3811716139316559,
        "train_loss": 3.0367000102996826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21020,
        "tokens": 11020533760,
        "learning_rate": 0.00018125030146303028,
        "gradient_norm": 0.37935832142829895,
        "train_loss": 3.030212163925171,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21021,
        "tokens": 11021058048,
        "learning_rate": 0.00018122639582958733,
        "gradient_norm": 0.41859620809555054,
        "train_loss": 3.0671510696411133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21022,
        "tokens": 11021582336,
        "learning_rate": 0.00018120249187077674,
        "gradient_norm": 0.44464364647865295,
        "train_loss": 3.035566806793213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21023,
        "tokens": 11022106624,
        "learning_rate": 0.0001811785895868677,
        "gradient_norm": 0.35110732913017273,
        "train_loss": 2.991879940032959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21024,
        "tokens": 11022630912,
        "learning_rate": 0.00018115468897812905,
        "gradient_norm": 0.3746334910392761,
        "train_loss": 3.0382773876190186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21025,
        "tokens": 11023155200,
        "learning_rate": 0.00018113079004483,
        "gradient_norm": 0.35525429248809814,
        "train_loss": 3.0778591632843018,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21026,
        "tokens": 11023679488,
        "learning_rate": 0.00018110689278723937,
        "gradient_norm": 0.3713285028934479,
        "train_loss": 3.099630832672119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21027,
        "tokens": 11024203776,
        "learning_rate": 0.00018108299720562637,
        "gradient_norm": 0.38436588644981384,
        "train_loss": 3.022963285446167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21028,
        "tokens": 11024728064,
        "learning_rate": 0.00018105910330025975,
        "gradient_norm": 0.36156582832336426,
        "train_loss": 3.0373404026031494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21029,
        "tokens": 11025252352,
        "learning_rate": 0.00018103521107140871,
        "gradient_norm": 0.36017563939094543,
        "train_loss": 3.111363410949707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21030,
        "tokens": 11025776640,
        "learning_rate": 0.00018101132051934194,
        "gradient_norm": 0.38197004795074463,
        "train_loss": 3.092501163482666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21031,
        "tokens": 11026300928,
        "learning_rate": 0.0001809874316443286,
        "gradient_norm": 0.38049811124801636,
        "train_loss": 3.0700418949127197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21032,
        "tokens": 11026825216,
        "learning_rate": 0.00018096354444663737,
        "gradient_norm": 0.33498382568359375,
        "train_loss": 3.020261287689209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21033,
        "tokens": 11027349504,
        "learning_rate": 0.00018093965892653727,
        "gradient_norm": 0.34989070892333984,
        "train_loss": 3.0349998474121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21034,
        "tokens": 11027873792,
        "learning_rate": 0.00018091577508429706,
        "gradient_norm": 0.3532232344150543,
        "train_loss": 3.1035871505737305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21035,
        "tokens": 11028398080,
        "learning_rate": 0.00018089189292018573,
        "gradient_norm": 0.3630701005458832,
        "train_loss": 3.0782532691955566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21036,
        "tokens": 11028922368,
        "learning_rate": 0.00018086801243447195,
        "gradient_norm": 0.36892378330230713,
        "train_loss": 3.0079147815704346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21037,
        "tokens": 11029446656,
        "learning_rate": 0.00018084413362742466,
        "gradient_norm": 0.38593268394470215,
        "train_loss": 3.093907594680786,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21038,
        "tokens": 11029970944,
        "learning_rate": 0.00018082025649931245,
        "gradient_norm": 0.3443840742111206,
        "train_loss": 3.0076372623443604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21039,
        "tokens": 11030495232,
        "learning_rate": 0.0001807963810504043,
        "gradient_norm": 0.3873356580734253,
        "train_loss": 3.0201542377471924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21040,
        "tokens": 11031019520,
        "learning_rate": 0.0001807725072809688,
        "gradient_norm": 0.34889811277389526,
        "train_loss": 3.1109771728515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21041,
        "tokens": 11031543808,
        "learning_rate": 0.00018074863519127485,
        "gradient_norm": 0.4104903042316437,
        "train_loss": 3.043951988220215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21042,
        "tokens": 11032068096,
        "learning_rate": 0.00018072476478159097,
        "gradient_norm": 0.3511766791343689,
        "train_loss": 3.0906574726104736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21043,
        "tokens": 11032592384,
        "learning_rate": 0.000180700896052186,
        "gradient_norm": 0.34092384576797485,
        "train_loss": 2.998976230621338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21044,
        "tokens": 11033116672,
        "learning_rate": 0.0001806770290033285,
        "gradient_norm": 0.37552517652511597,
        "train_loss": 3.035585880279541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21045,
        "tokens": 11033640960,
        "learning_rate": 0.00018065316363528725,
        "gradient_norm": 0.36618486046791077,
        "train_loss": 3.050405263900757,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21046,
        "tokens": 11034165248,
        "learning_rate": 0.0001806292999483307,
        "gradient_norm": 0.3689703941345215,
        "train_loss": 2.998154640197754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21047,
        "tokens": 11034689536,
        "learning_rate": 0.00018060543794272768,
        "gradient_norm": 0.36630985140800476,
        "train_loss": 3.076295852661133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21048,
        "tokens": 11035213824,
        "learning_rate": 0.0001805815776187466,
        "gradient_norm": 0.36367693543434143,
        "train_loss": 3.0946669578552246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21049,
        "tokens": 11035738112,
        "learning_rate": 0.00018055771897665618,
        "gradient_norm": 0.40735331177711487,
        "train_loss": 3.075225830078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21050,
        "tokens": 11036262400,
        "learning_rate": 0.00018053386201672485,
        "gradient_norm": 0.414688378572464,
        "train_loss": 3.0032548904418945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21051,
        "tokens": 11036786688,
        "learning_rate": 0.0001805100067392212,
        "gradient_norm": 0.4042361080646515,
        "train_loss": 3.0579984188079834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21052,
        "tokens": 11037310976,
        "learning_rate": 0.00018048615314441386,
        "gradient_norm": 0.395280122756958,
        "train_loss": 3.0732593536376953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21053,
        "tokens": 11037835264,
        "learning_rate": 0.00018046230123257116,
        "gradient_norm": 0.45393890142440796,
        "train_loss": 3.0359256267547607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21054,
        "tokens": 11038359552,
        "learning_rate": 0.00018043845100396177,
        "gradient_norm": 0.4273599684238434,
        "train_loss": 3.013328790664673,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21055,
        "tokens": 11038883840,
        "learning_rate": 0.00018041460245885393,
        "gradient_norm": 0.42805221676826477,
        "train_loss": 3.056614875793457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21056,
        "tokens": 11039408128,
        "learning_rate": 0.0001803907555975163,
        "gradient_norm": 0.4096897840499878,
        "train_loss": 3.02305269241333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21057,
        "tokens": 11039932416,
        "learning_rate": 0.0001803669104202171,
        "gradient_norm": 0.3933645188808441,
        "train_loss": 3.0393288135528564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21058,
        "tokens": 11040456704,
        "learning_rate": 0.00018034306692722498,
        "gradient_norm": 0.369259238243103,
        "train_loss": 3.043844223022461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21059,
        "tokens": 11040980992,
        "learning_rate": 0.0001803192251188081,
        "gradient_norm": 0.3987271189689636,
        "train_loss": 3.064215898513794,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21060,
        "tokens": 11041505280,
        "learning_rate": 0.00018029538499523499,
        "gradient_norm": 0.37043410539627075,
        "train_loss": 3.0379750728607178,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21061,
        "tokens": 11042029568,
        "learning_rate": 0.00018027154655677382,
        "gradient_norm": 0.3468732237815857,
        "train_loss": 3.0378682613372803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21062,
        "tokens": 11042553856,
        "learning_rate": 0.00018024770980369306,
        "gradient_norm": 0.3633439838886261,
        "train_loss": 3.0990588665008545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21063,
        "tokens": 11043078144,
        "learning_rate": 0.0001802238747362611,
        "gradient_norm": 0.3841426372528076,
        "train_loss": 3.0835533142089844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21064,
        "tokens": 11043602432,
        "learning_rate": 0.00018020004135474603,
        "gradient_norm": 0.3954845070838928,
        "train_loss": 3.10048770904541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21065,
        "tokens": 11044126720,
        "learning_rate": 0.0001801762096594163,
        "gradient_norm": 0.39196011424064636,
        "train_loss": 3.0414743423461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21066,
        "tokens": 11044651008,
        "learning_rate": 0.00018015237965054,
        "gradient_norm": 0.4724687337875366,
        "train_loss": 3.0546579360961914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21067,
        "tokens": 11045175296,
        "learning_rate": 0.0001801285513283856,
        "gradient_norm": 0.3359921872615814,
        "train_loss": 3.0303523540496826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21068,
        "tokens": 11045699584,
        "learning_rate": 0.00018010472469322104,
        "gradient_norm": 0.4309428036212921,
        "train_loss": 3.0257413387298584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21069,
        "tokens": 11046223872,
        "learning_rate": 0.00018008089974531476,
        "gradient_norm": 0.3535805642604828,
        "train_loss": 3.0718464851379395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21070,
        "tokens": 11046748160,
        "learning_rate": 0.00018005707648493472,
        "gradient_norm": 0.44848933815956116,
        "train_loss": 3.0587284564971924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21071,
        "tokens": 11047272448,
        "learning_rate": 0.00018003325491234922,
        "gradient_norm": 0.35343366861343384,
        "train_loss": 3.096816301345825,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21072,
        "tokens": 11047796736,
        "learning_rate": 0.00018000943502782644,
        "gradient_norm": 0.4578150510787964,
        "train_loss": 3.031449556350708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21073,
        "tokens": 11048321024,
        "learning_rate": 0.00017998561683163435,
        "gradient_norm": 0.37051528692245483,
        "train_loss": 3.0156197547912598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21074,
        "tokens": 11048845312,
        "learning_rate": 0.00017996180032404127,
        "gradient_norm": 0.37413209676742554,
        "train_loss": 3.0603890419006348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21075,
        "tokens": 11049369600,
        "learning_rate": 0.000179937985505315,
        "gradient_norm": 0.3812173306941986,
        "train_loss": 3.0233397483825684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21076,
        "tokens": 11049893888,
        "learning_rate": 0.00017991417237572387,
        "gradient_norm": 0.3657238483428955,
        "train_loss": 3.036400556564331,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21077,
        "tokens": 11050418176,
        "learning_rate": 0.00017989036093553576,
        "gradient_norm": 0.37037762999534607,
        "train_loss": 3.091334342956543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21078,
        "tokens": 11050942464,
        "learning_rate": 0.00017986655118501884,
        "gradient_norm": 0.44536063075065613,
        "train_loss": 3.057471752166748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21079,
        "tokens": 11051466752,
        "learning_rate": 0.0001798427431244409,
        "gradient_norm": 0.3764681816101074,
        "train_loss": 3.085388660430908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21080,
        "tokens": 11051991040,
        "learning_rate": 0.0001798189367540702,
        "gradient_norm": 0.36926591396331787,
        "train_loss": 3.0017566680908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21081,
        "tokens": 11052515328,
        "learning_rate": 0.00017979513207417447,
        "gradient_norm": 0.3837774991989136,
        "train_loss": 3.0115160942077637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21082,
        "tokens": 11053039616,
        "learning_rate": 0.00017977132908502172,
        "gradient_norm": 0.36324402689933777,
        "train_loss": 3.0752675533294678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21083,
        "tokens": 11053563904,
        "learning_rate": 0.00017974752778688008,
        "gradient_norm": 0.3760124146938324,
        "train_loss": 3.0367980003356934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21084,
        "tokens": 11054088192,
        "learning_rate": 0.00017972372818001717,
        "gradient_norm": 0.3509804308414459,
        "train_loss": 3.0208468437194824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21085,
        "tokens": 11054612480,
        "learning_rate": 0.00017969993026470112,
        "gradient_norm": 0.3840210437774658,
        "train_loss": 3.012423515319824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21086,
        "tokens": 11055136768,
        "learning_rate": 0.00017967613404119964,
        "gradient_norm": 0.3778916299343109,
        "train_loss": 3.0773158073425293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21087,
        "tokens": 11055661056,
        "learning_rate": 0.00017965233950978076,
        "gradient_norm": 0.3431122899055481,
        "train_loss": 3.052786350250244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21088,
        "tokens": 11056185344,
        "learning_rate": 0.0001796285466707121,
        "gradient_norm": 0.40559640526771545,
        "train_loss": 3.0746660232543945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21089,
        "tokens": 11056709632,
        "learning_rate": 0.00017960475552426168,
        "gradient_norm": 0.3425638973712921,
        "train_loss": 3.0176548957824707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21090,
        "tokens": 11057233920,
        "learning_rate": 0.0001795809660706971,
        "gradient_norm": 0.35517776012420654,
        "train_loss": 3.0218658447265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21091,
        "tokens": 11057758208,
        "learning_rate": 0.0001795571783102863,
        "gradient_norm": 0.3848741352558136,
        "train_loss": 3.0242738723754883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21092,
        "tokens": 11058282496,
        "learning_rate": 0.000179533392243297,
        "gradient_norm": 0.37010255455970764,
        "train_loss": 3.0744943618774414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21093,
        "tokens": 11058806784,
        "learning_rate": 0.0001795096078699969,
        "gradient_norm": 0.4216764271259308,
        "train_loss": 3.086024522781372,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21094,
        "tokens": 11059331072,
        "learning_rate": 0.00017948582519065383,
        "gradient_norm": 0.35948196053504944,
        "train_loss": 3.099703311920166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21095,
        "tokens": 11059855360,
        "learning_rate": 0.00017946204420553536,
        "gradient_norm": 0.4051800072193146,
        "train_loss": 3.1218624114990234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21096,
        "tokens": 11060379648,
        "learning_rate": 0.00017943826491490932,
        "gradient_norm": 0.3715616464614868,
        "train_loss": 3.075080394744873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21097,
        "tokens": 11060903936,
        "learning_rate": 0.00017941448731904314,
        "gradient_norm": 0.42597368359565735,
        "train_loss": 3.0251147747039795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21098,
        "tokens": 11061428224,
        "learning_rate": 0.00017939071141820476,
        "gradient_norm": 0.3682590126991272,
        "train_loss": 3.0475029945373535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21099,
        "tokens": 11061952512,
        "learning_rate": 0.0001793669372126615,
        "gradient_norm": 0.37199822068214417,
        "train_loss": 3.079819679260254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21100,
        "tokens": 11062476800,
        "learning_rate": 0.00017934316470268128,
        "gradient_norm": 0.3786919116973877,
        "train_loss": 3.080937385559082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21101,
        "tokens": 11063001088,
        "learning_rate": 0.00017931939388853143,
        "gradient_norm": 0.4201723337173462,
        "train_loss": 3.1517953872680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21102,
        "tokens": 11063525376,
        "learning_rate": 0.00017929562477047968,
        "gradient_norm": 0.4079110622406006,
        "train_loss": 3.0752358436584473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21103,
        "tokens": 11064049664,
        "learning_rate": 0.00017927185734879357,
        "gradient_norm": 0.3747541308403015,
        "train_loss": 3.0316004753112793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21104,
        "tokens": 11064573952,
        "learning_rate": 0.0001792480916237405,
        "gradient_norm": 0.3691170811653137,
        "train_loss": 3.046755313873291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21105,
        "tokens": 11065098240,
        "learning_rate": 0.0001792243275955882,
        "gradient_norm": 0.419974684715271,
        "train_loss": 3.0855977535247803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21106,
        "tokens": 11065622528,
        "learning_rate": 0.00017920056526460392,
        "gradient_norm": 0.37809690833091736,
        "train_loss": 2.993317127227783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21107,
        "tokens": 11066146816,
        "learning_rate": 0.00017917680463105538,
        "gradient_norm": 0.39264100790023804,
        "train_loss": 3.0243239402770996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21108,
        "tokens": 11066671104,
        "learning_rate": 0.0001791530456952098,
        "gradient_norm": 0.40202248096466064,
        "train_loss": 3.062025547027588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21109,
        "tokens": 11067195392,
        "learning_rate": 0.00017912928845733483,
        "gradient_norm": 0.4102884829044342,
        "train_loss": 3.017505407333374,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21110,
        "tokens": 11067719680,
        "learning_rate": 0.00017910553291769764,
        "gradient_norm": 0.41649824380874634,
        "train_loss": 3.0210988521575928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21111,
        "tokens": 11068243968,
        "learning_rate": 0.0001790817790765658,
        "gradient_norm": 0.39831167459487915,
        "train_loss": 3.094167709350586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21112,
        "tokens": 11068768256,
        "learning_rate": 0.00017905802693420677,
        "gradient_norm": 0.41576701402664185,
        "train_loss": 3.092092514038086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21113,
        "tokens": 11069292544,
        "learning_rate": 0.0001790342764908877,
        "gradient_norm": 0.3611721694469452,
        "train_loss": 3.0637571811676025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21114,
        "tokens": 11069816832,
        "learning_rate": 0.00017901052774687616,
        "gradient_norm": 0.40510857105255127,
        "train_loss": 3.0798208713531494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21115,
        "tokens": 11070341120,
        "learning_rate": 0.00017898678070243918,
        "gradient_norm": 0.3681493401527405,
        "train_loss": 3.0945239067077637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21116,
        "tokens": 11070865408,
        "learning_rate": 0.00017896303535784434,
        "gradient_norm": 0.36772283911705017,
        "train_loss": 3.0487866401672363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21117,
        "tokens": 11071389696,
        "learning_rate": 0.00017893929171335874,
        "gradient_norm": 0.3778974115848541,
        "train_loss": 3.039778232574463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21118,
        "tokens": 11071913984,
        "learning_rate": 0.0001789155497692498,
        "gradient_norm": 0.3621281683444977,
        "train_loss": 3.027047634124756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21119,
        "tokens": 11072438272,
        "learning_rate": 0.0001788918095257846,
        "gradient_norm": 0.3961271047592163,
        "train_loss": 3.0478038787841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21120,
        "tokens": 11072962560,
        "learning_rate": 0.00017886807098323052,
        "gradient_norm": 0.34926024079322815,
        "train_loss": 3.015960693359375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21121,
        "tokens": 11073486848,
        "learning_rate": 0.0001788443341418546,
        "gradient_norm": 0.3688581585884094,
        "train_loss": 3.0752995014190674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21122,
        "tokens": 11074011136,
        "learning_rate": 0.00017882059900192412,
        "gradient_norm": 0.37346896529197693,
        "train_loss": 3.043412446975708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21123,
        "tokens": 11074535424,
        "learning_rate": 0.00017879686556370632,
        "gradient_norm": 0.35854509472846985,
        "train_loss": 3.0766055583953857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21124,
        "tokens": 11075059712,
        "learning_rate": 0.00017877313382746822,
        "gradient_norm": 0.36316394805908203,
        "train_loss": 3.0648152828216553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21125,
        "tokens": 11075584000,
        "learning_rate": 0.00017874940379347708,
        "gradient_norm": 0.39861205220222473,
        "train_loss": 3.0631117820739746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21126,
        "tokens": 11076108288,
        "learning_rate": 0.00017872567546199988,
        "gradient_norm": 0.35865318775177,
        "train_loss": 3.0009090900421143,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21127,
        "tokens": 11076632576,
        "learning_rate": 0.0001787019488333038,
        "gradient_norm": 0.3646904528141022,
        "train_loss": 3.0340685844421387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21128,
        "tokens": 11077156864,
        "learning_rate": 0.00017867822390765586,
        "gradient_norm": 0.40252169966697693,
        "train_loss": 3.075429916381836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21129,
        "tokens": 11077681152,
        "learning_rate": 0.00017865450068532319,
        "gradient_norm": 0.38263005018234253,
        "train_loss": 2.993227958679199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21130,
        "tokens": 11078205440,
        "learning_rate": 0.00017863077916657267,
        "gradient_norm": 0.4113234579563141,
        "train_loss": 3.047161102294922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21131,
        "tokens": 11078729728,
        "learning_rate": 0.00017860705935167153,
        "gradient_norm": 0.36993342638015747,
        "train_loss": 3.0210719108581543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21132,
        "tokens": 11079254016,
        "learning_rate": 0.00017858334124088658,
        "gradient_norm": 0.403113454580307,
        "train_loss": 3.051410675048828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21133,
        "tokens": 11079778304,
        "learning_rate": 0.00017855962483448494,
        "gradient_norm": 0.3748434782028198,
        "train_loss": 3.0595285892486572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21134,
        "tokens": 11080302592,
        "learning_rate": 0.0001785359101327334,
        "gradient_norm": 0.3705926537513733,
        "train_loss": 3.019618511199951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21135,
        "tokens": 11080826880,
        "learning_rate": 0.0001785121971358991,
        "gradient_norm": 0.41418153047561646,
        "train_loss": 3.1039648056030273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21136,
        "tokens": 11081351168,
        "learning_rate": 0.00017848848584424876,
        "gradient_norm": 0.34345194697380066,
        "train_loss": 3.047611713409424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21137,
        "tokens": 11081875456,
        "learning_rate": 0.00017846477625804946,
        "gradient_norm": 0.33010220527648926,
        "train_loss": 3.0540566444396973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21138,
        "tokens": 11082399744,
        "learning_rate": 0.0001784410683775679,
        "gradient_norm": 0.3484698235988617,
        "train_loss": 3.02626633644104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21139,
        "tokens": 11082924032,
        "learning_rate": 0.00017841736220307113,
        "gradient_norm": 0.3643970191478729,
        "train_loss": 3.0434346199035645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21140,
        "tokens": 11083448320,
        "learning_rate": 0.00017839365773482586,
        "gradient_norm": 0.44500216841697693,
        "train_loss": 3.079796552658081,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21141,
        "tokens": 11083972608,
        "learning_rate": 0.000178369954973099,
        "gradient_norm": 0.4733061194419861,
        "train_loss": 3.044712543487549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21142,
        "tokens": 11084496896,
        "learning_rate": 0.0001783462539181572,
        "gradient_norm": 0.3525422513484955,
        "train_loss": 3.0602593421936035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21143,
        "tokens": 11085021184,
        "learning_rate": 0.00017832255457026747,
        "gradient_norm": 0.45278483629226685,
        "train_loss": 3.0522146224975586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21144,
        "tokens": 11085545472,
        "learning_rate": 0.00017829885692969638,
        "gradient_norm": 0.3753471076488495,
        "train_loss": 3.0731210708618164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21145,
        "tokens": 11086069760,
        "learning_rate": 0.00017827516099671085,
        "gradient_norm": 0.405796617269516,
        "train_loss": 3.1888294219970703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21146,
        "tokens": 11086594048,
        "learning_rate": 0.00017825146677157737,
        "gradient_norm": 0.43069031834602356,
        "train_loss": 3.0641942024230957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21147,
        "tokens": 11087118336,
        "learning_rate": 0.00017822777425456293,
        "gradient_norm": 0.39026761054992676,
        "train_loss": 3.0456838607788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21148,
        "tokens": 11087642624,
        "learning_rate": 0.00017820408344593398,
        "gradient_norm": 0.41495710611343384,
        "train_loss": 3.0371861457824707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21149,
        "tokens": 11088166912,
        "learning_rate": 0.0001781803943459574,
        "gradient_norm": 0.38320618867874146,
        "train_loss": 3.082777500152588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21150,
        "tokens": 11088691200,
        "learning_rate": 0.00017815670695489958,
        "gradient_norm": 0.3631332218647003,
        "train_loss": 3.054079532623291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21151,
        "tokens": 11089215488,
        "learning_rate": 0.00017813302127302736,
        "gradient_norm": 0.35839536786079407,
        "train_loss": 3.0659875869750977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21152,
        "tokens": 11089739776,
        "learning_rate": 0.00017810933730060734,
        "gradient_norm": 0.36533668637275696,
        "train_loss": 3.006585121154785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21153,
        "tokens": 11090264064,
        "learning_rate": 0.000178085655037906,
        "gradient_norm": 0.37726160883903503,
        "train_loss": 3.044675827026367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21154,
        "tokens": 11090788352,
        "learning_rate": 0.00017806197448519008,
        "gradient_norm": 0.3856396973133087,
        "train_loss": 3.0343170166015625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21155,
        "tokens": 11091312640,
        "learning_rate": 0.0001780382956427259,
        "gradient_norm": 0.42139068245887756,
        "train_loss": 3.0158228874206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21156,
        "tokens": 11091836928,
        "learning_rate": 0.00017801461851078024,
        "gradient_norm": 0.39232346415519714,
        "train_loss": 3.1275134086608887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21157,
        "tokens": 11092361216,
        "learning_rate": 0.00017799094308961941,
        "gradient_norm": 0.37969470024108887,
        "train_loss": 3.033536434173584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21158,
        "tokens": 11092885504,
        "learning_rate": 0.00017796726937951014,
        "gradient_norm": 0.3841356635093689,
        "train_loss": 3.0698037147521973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21159,
        "tokens": 11093409792,
        "learning_rate": 0.00017794359738071864,
        "gradient_norm": 0.3996489644050598,
        "train_loss": 3.0400171279907227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21160,
        "tokens": 11093934080,
        "learning_rate": 0.00017791992709351157,
        "gradient_norm": 0.39486390352249146,
        "train_loss": 3.0172858238220215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21161,
        "tokens": 11094458368,
        "learning_rate": 0.0001778962585181552,
        "gradient_norm": 0.3658866584300995,
        "train_loss": 3.0227203369140625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21162,
        "tokens": 11094982656,
        "learning_rate": 0.00017787259165491604,
        "gradient_norm": 0.40027162432670593,
        "train_loss": 3.0732662677764893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21163,
        "tokens": 11095506944,
        "learning_rate": 0.00017784892650406063,
        "gradient_norm": 0.3945932984352112,
        "train_loss": 3.09421706199646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21164,
        "tokens": 11096031232,
        "learning_rate": 0.00017782526306585507,
        "gradient_norm": 0.3783246576786041,
        "train_loss": 3.041548728942871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21165,
        "tokens": 11096555520,
        "learning_rate": 0.000177801601340566,
        "gradient_norm": 0.39354848861694336,
        "train_loss": 3.034573793411255,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21166,
        "tokens": 11097079808,
        "learning_rate": 0.00017777794132845946,
        "gradient_norm": 0.36862173676490784,
        "train_loss": 3.071394920349121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21167,
        "tokens": 11097604096,
        "learning_rate": 0.0001777542830298021,
        "gradient_norm": 0.3804987370967865,
        "train_loss": 3.076517343521118,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21168,
        "tokens": 11098128384,
        "learning_rate": 0.00017773062644485998,
        "gradient_norm": 0.4286390542984009,
        "train_loss": 3.0354270935058594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21169,
        "tokens": 11098652672,
        "learning_rate": 0.00017770697157389954,
        "gradient_norm": 0.39966103434562683,
        "train_loss": 3.038545608520508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21170,
        "tokens": 11099176960,
        "learning_rate": 0.00017768331841718686,
        "gradient_norm": 0.5174418091773987,
        "train_loss": 3.060725212097168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21171,
        "tokens": 11099701248,
        "learning_rate": 0.0001776596669749883,
        "gradient_norm": 0.463138222694397,
        "train_loss": 3.0573980808258057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21172,
        "tokens": 11100225536,
        "learning_rate": 0.00017763601724757024,
        "gradient_norm": 0.43985509872436523,
        "train_loss": 3.0174813270568848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21173,
        "tokens": 11100749824,
        "learning_rate": 0.00017761236923519858,
        "gradient_norm": 0.4291251301765442,
        "train_loss": 3.0204248428344727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21174,
        "tokens": 11101274112,
        "learning_rate": 0.00017758872293813975,
        "gradient_norm": 0.4717113971710205,
        "train_loss": 3.054774284362793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21175,
        "tokens": 11101798400,
        "learning_rate": 0.00017756507835665978,
        "gradient_norm": 0.40610605478286743,
        "train_loss": 3.041810989379883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21176,
        "tokens": 11102322688,
        "learning_rate": 0.00017754143549102494,
        "gradient_norm": 0.428204745054245,
        "train_loss": 3.0292348861694336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21177,
        "tokens": 11102846976,
        "learning_rate": 0.00017751779434150116,
        "gradient_norm": 0.3638863265514374,
        "train_loss": 3.018038272857666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21178,
        "tokens": 11103371264,
        "learning_rate": 0.00017749415490835483,
        "gradient_norm": 0.3826102018356323,
        "train_loss": 3.074397087097168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21179,
        "tokens": 11103895552,
        "learning_rate": 0.00017747051719185176,
        "gradient_norm": 0.37412646412849426,
        "train_loss": 3.107053279876709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21180,
        "tokens": 11104419840,
        "learning_rate": 0.00017744688119225826,
        "gradient_norm": 0.37635478377342224,
        "train_loss": 3.0220718383789062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21181,
        "tokens": 11104944128,
        "learning_rate": 0.00017742324690984013,
        "gradient_norm": 0.3750704526901245,
        "train_loss": 3.060098171234131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21182,
        "tokens": 11105468416,
        "learning_rate": 0.00017739961434486362,
        "gradient_norm": 0.402291476726532,
        "train_loss": 3.0241222381591797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21183,
        "tokens": 11105992704,
        "learning_rate": 0.00017737598349759474,
        "gradient_norm": 0.36452528834342957,
        "train_loss": 3.067246913909912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21184,
        "tokens": 11106516992,
        "learning_rate": 0.00017735235436829933,
        "gradient_norm": 0.36897578835487366,
        "train_loss": 3.0883965492248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21185,
        "tokens": 11107041280,
        "learning_rate": 0.00017732872695724351,
        "gradient_norm": 0.3799077272415161,
        "train_loss": 3.069610595703125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21186,
        "tokens": 11107565568,
        "learning_rate": 0.00017730510126469313,
        "gradient_norm": 0.3950774669647217,
        "train_loss": 3.0802927017211914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21187,
        "tokens": 11108089856,
        "learning_rate": 0.00017728147729091426,
        "gradient_norm": 0.38385072350502014,
        "train_loss": 3.028144121170044,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21188,
        "tokens": 11108614144,
        "learning_rate": 0.00017725785503617262,
        "gradient_norm": 0.41309475898742676,
        "train_loss": 3.0761728286743164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21189,
        "tokens": 11109138432,
        "learning_rate": 0.0001772342345007343,
        "gradient_norm": 0.3856376111507416,
        "train_loss": 3.0518887042999268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21190,
        "tokens": 11109662720,
        "learning_rate": 0.00017721061568486504,
        "gradient_norm": 0.40277454257011414,
        "train_loss": 3.033097743988037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21191,
        "tokens": 11110187008,
        "learning_rate": 0.00017718699858883073,
        "gradient_norm": 0.37781962752342224,
        "train_loss": 3.0172462463378906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21192,
        "tokens": 11110711296,
        "learning_rate": 0.00017716338321289735,
        "gradient_norm": 0.45010048151016235,
        "train_loss": 3.123295783996582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21193,
        "tokens": 11111235584,
        "learning_rate": 0.0001771397695573305,
        "gradient_norm": 0.39864233136177063,
        "train_loss": 3.0476036071777344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21194,
        "tokens": 11111759872,
        "learning_rate": 0.0001771161576223962,
        "gradient_norm": 0.47129204869270325,
        "train_loss": 3.0266597270965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21195,
        "tokens": 11112284160,
        "learning_rate": 0.00017709254740836002,
        "gradient_norm": 0.3893941640853882,
        "train_loss": 3.0421533584594727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21196,
        "tokens": 11112808448,
        "learning_rate": 0.0001770689389154879,
        "gradient_norm": 0.4101611077785492,
        "train_loss": 3.046823501586914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21197,
        "tokens": 11113332736,
        "learning_rate": 0.00017704533214404545,
        "gradient_norm": 0.39224952459335327,
        "train_loss": 3.080630302429199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21198,
        "tokens": 11113857024,
        "learning_rate": 0.00017702172709429848,
        "gradient_norm": 0.376680850982666,
        "train_loss": 3.0280094146728516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21199,
        "tokens": 11114381312,
        "learning_rate": 0.00017699812376651265,
        "gradient_norm": 0.38464295864105225,
        "train_loss": 3.0296058654785156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21200,
        "tokens": 11114905600,
        "learning_rate": 0.0001769745221609537,
        "gradient_norm": 0.444233238697052,
        "train_loss": 3.1422057151794434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21201,
        "tokens": 11115429888,
        "learning_rate": 0.00017695092227788716,
        "gradient_norm": 0.4077620804309845,
        "train_loss": 3.0347137451171875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21202,
        "tokens": 11115954176,
        "learning_rate": 0.0001769273241175788,
        "gradient_norm": 0.36827191710472107,
        "train_loss": 3.0156376361846924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21203,
        "tokens": 11116478464,
        "learning_rate": 0.0001769037276802943,
        "gradient_norm": 0.3883614242076874,
        "train_loss": 3.048252582550049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21204,
        "tokens": 11117002752,
        "learning_rate": 0.00017688013296629908,
        "gradient_norm": 0.48731666803359985,
        "train_loss": 3.2214033603668213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21205,
        "tokens": 11117527040,
        "learning_rate": 0.00017685653997585892,
        "gradient_norm": 0.38223740458488464,
        "train_loss": 2.9955263137817383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21206,
        "tokens": 11118051328,
        "learning_rate": 0.0001768329487092392,
        "gradient_norm": 0.41699716448783875,
        "train_loss": 3.0132510662078857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21207,
        "tokens": 11118575616,
        "learning_rate": 0.0001768093591667057,
        "gradient_norm": 0.37351861596107483,
        "train_loss": 3.0112123489379883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21208,
        "tokens": 11119099904,
        "learning_rate": 0.00017678577134852373,
        "gradient_norm": 0.5030208230018616,
        "train_loss": 3.070035934448242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21209,
        "tokens": 11119624192,
        "learning_rate": 0.00017676218525495896,
        "gradient_norm": 0.413277804851532,
        "train_loss": 3.0668396949768066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21210,
        "tokens": 11120148480,
        "learning_rate": 0.00017673860088627668,
        "gradient_norm": 0.49328935146331787,
        "train_loss": 3.0469565391540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21211,
        "tokens": 11120672768,
        "learning_rate": 0.00017671501824274253,
        "gradient_norm": 0.39855316281318665,
        "train_loss": 3.088510513305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21212,
        "tokens": 11121197056,
        "learning_rate": 0.00017669143732462205,
        "gradient_norm": 0.4539324939250946,
        "train_loss": 3.036201000213623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21213,
        "tokens": 11121721344,
        "learning_rate": 0.00017666785813218042,
        "gradient_norm": 0.41739892959594727,
        "train_loss": 3.102268695831299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21214,
        "tokens": 11122245632,
        "learning_rate": 0.0001766442806656833,
        "gradient_norm": 0.4783768057823181,
        "train_loss": 3.091273784637451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21215,
        "tokens": 11122769920,
        "learning_rate": 0.00017662070492539583,
        "gradient_norm": 0.3874492347240448,
        "train_loss": 3.048717975616455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21216,
        "tokens": 11123294208,
        "learning_rate": 0.00017659713091158362,
        "gradient_norm": 0.3981628715991974,
        "train_loss": 3.0405335426330566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21217,
        "tokens": 11123818496,
        "learning_rate": 0.00017657355862451185,
        "gradient_norm": 0.41198328137397766,
        "train_loss": 3.0563387870788574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21218,
        "tokens": 11124342784,
        "learning_rate": 0.000176549988064446,
        "gradient_norm": 0.41056710481643677,
        "train_loss": 3.0988306999206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21219,
        "tokens": 11124867072,
        "learning_rate": 0.00017652641923165122,
        "gradient_norm": 0.40947285294532776,
        "train_loss": 3.0406672954559326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21220,
        "tokens": 11125391360,
        "learning_rate": 0.00017650285212639303,
        "gradient_norm": 0.4481815695762634,
        "train_loss": 3.0480480194091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21221,
        "tokens": 11125915648,
        "learning_rate": 0.00017647928674893645,
        "gradient_norm": 0.35333895683288574,
        "train_loss": 3.050906181335449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21222,
        "tokens": 11126439936,
        "learning_rate": 0.00017645572309954688,
        "gradient_norm": 0.4319118857383728,
        "train_loss": 3.0424249172210693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21223,
        "tokens": 11126964224,
        "learning_rate": 0.00017643216117848963,
        "gradient_norm": 0.40152448415756226,
        "train_loss": 3.124622344970703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21224,
        "tokens": 11127488512,
        "learning_rate": 0.00017640860098602976,
        "gradient_norm": 0.44787874817848206,
        "train_loss": 2.9926443099975586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21225,
        "tokens": 11128012800,
        "learning_rate": 0.0001763850425224326,
        "gradient_norm": 0.3969692885875702,
        "train_loss": 3.0580124855041504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21226,
        "tokens": 11128537088,
        "learning_rate": 0.00017636148578796323,
        "gradient_norm": 0.38898247480392456,
        "train_loss": 3.0707859992980957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21227,
        "tokens": 11129061376,
        "learning_rate": 0.0001763379307828869,
        "gradient_norm": 0.36488884687423706,
        "train_loss": 3.030226230621338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21228,
        "tokens": 11129585664,
        "learning_rate": 0.00017631437750746862,
        "gradient_norm": 0.3716769218444824,
        "train_loss": 3.0408668518066406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21229,
        "tokens": 11130109952,
        "learning_rate": 0.0001762908259619737,
        "gradient_norm": 0.348775178194046,
        "train_loss": 3.121718406677246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21230,
        "tokens": 11130634240,
        "learning_rate": 0.00017626727614666708,
        "gradient_norm": 0.44318991899490356,
        "train_loss": 3.122467041015625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21231,
        "tokens": 11131158528,
        "learning_rate": 0.00017624372806181383,
        "gradient_norm": 0.447375625371933,
        "train_loss": 3.0728538036346436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21232,
        "tokens": 11131682816,
        "learning_rate": 0.00017622018170767922,
        "gradient_norm": 0.37077903747558594,
        "train_loss": 3.049434185028076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21233,
        "tokens": 11132207104,
        "learning_rate": 0.00017619663708452803,
        "gradient_norm": 0.3984823524951935,
        "train_loss": 3.055532455444336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21234,
        "tokens": 11132731392,
        "learning_rate": 0.00017617309419262552,
        "gradient_norm": 0.37425944209098816,
        "train_loss": 3.009091377258301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21235,
        "tokens": 11133255680,
        "learning_rate": 0.0001761495530322365,
        "gradient_norm": 0.395927757024765,
        "train_loss": 3.022953987121582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21236,
        "tokens": 11133779968,
        "learning_rate": 0.00017612601360362612,
        "gradient_norm": 0.3596579134464264,
        "train_loss": 3.0465087890625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21237,
        "tokens": 11134304256,
        "learning_rate": 0.00017610247590705918,
        "gradient_norm": 0.33715444803237915,
        "train_loss": 3.039022922515869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21238,
        "tokens": 11134828544,
        "learning_rate": 0.00017607893994280084,
        "gradient_norm": 0.4133009612560272,
        "train_loss": 3.0520288944244385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21239,
        "tokens": 11135352832,
        "learning_rate": 0.00017605540571111574,
        "gradient_norm": 0.3734707236289978,
        "train_loss": 3.056879997253418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21240,
        "tokens": 11135877120,
        "learning_rate": 0.0001760318732122691,
        "gradient_norm": 0.430991530418396,
        "train_loss": 3.0692152976989746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21241,
        "tokens": 11136401408,
        "learning_rate": 0.00017600834244652552,
        "gradient_norm": 0.39979079365730286,
        "train_loss": 3.045557975769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21242,
        "tokens": 11136925696,
        "learning_rate": 0.0001759848134141501,
        "gradient_norm": 0.37497252225875854,
        "train_loss": 3.0151262283325195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21243,
        "tokens": 11137449984,
        "learning_rate": 0.00017596128611540752,
        "gradient_norm": 0.39498838782310486,
        "train_loss": 3.0329651832580566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21244,
        "tokens": 11137974272,
        "learning_rate": 0.00017593776055056275,
        "gradient_norm": 0.4244903326034546,
        "train_loss": 3.0304579734802246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21245,
        "tokens": 11138498560,
        "learning_rate": 0.00017591423671988043,
        "gradient_norm": 0.41990384459495544,
        "train_loss": 3.034444808959961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21246,
        "tokens": 11139022848,
        "learning_rate": 0.00017589071462362557,
        "gradient_norm": 0.3813832998275757,
        "train_loss": 3.008220672607422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21247,
        "tokens": 11139547136,
        "learning_rate": 0.00017586719426206272,
        "gradient_norm": 0.4164848029613495,
        "train_loss": 3.0384840965270996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21248,
        "tokens": 11140071424,
        "learning_rate": 0.00017584367563545683,
        "gradient_norm": 0.3939509093761444,
        "train_loss": 3.0590763092041016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21249,
        "tokens": 11140595712,
        "learning_rate": 0.0001758201587440724,
        "gradient_norm": 0.44629064202308655,
        "train_loss": 3.064953327178955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21250,
        "tokens": 11141120000,
        "learning_rate": 0.00017579664358817438,
        "gradient_norm": 0.3835866451263428,
        "train_loss": 3.0782432556152344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21251,
        "tokens": 11141644288,
        "learning_rate": 0.00017577313016802726,
        "gradient_norm": 0.42199617624282837,
        "train_loss": 3.0638649463653564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21252,
        "tokens": 11142168576,
        "learning_rate": 0.00017574961848389593,
        "gradient_norm": 0.3661019206047058,
        "train_loss": 3.029815912246704,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21253,
        "tokens": 11142692864,
        "learning_rate": 0.0001757261085360448,
        "gradient_norm": 0.40134677290916443,
        "train_loss": 3.039358377456665,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21254,
        "tokens": 11143217152,
        "learning_rate": 0.00017570260032473872,
        "gradient_norm": 0.44443953037261963,
        "train_loss": 3.06581711769104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21255,
        "tokens": 11143741440,
        "learning_rate": 0.00017567909385024212,
        "gradient_norm": 0.4154807925224304,
        "train_loss": 3.092794418334961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21256,
        "tokens": 11144265728,
        "learning_rate": 0.0001756555891128198,
        "gradient_norm": 0.40473195910453796,
        "train_loss": 3.0653131008148193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21257,
        "tokens": 11144790016,
        "learning_rate": 0.00017563208611273614,
        "gradient_norm": 0.4019259214401245,
        "train_loss": 3.044450283050537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21258,
        "tokens": 11145314304,
        "learning_rate": 0.00017560858485025582,
        "gradient_norm": 0.34609609842300415,
        "train_loss": 3.0137457847595215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21259,
        "tokens": 11145838592,
        "learning_rate": 0.00017558508532564325,
        "gradient_norm": 0.3724893033504486,
        "train_loss": 3.0891921520233154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21260,
        "tokens": 11146362880,
        "learning_rate": 0.00017556158753916312,
        "gradient_norm": 0.35660886764526367,
        "train_loss": 3.0357093811035156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21261,
        "tokens": 11146887168,
        "learning_rate": 0.00017553809149107973,
        "gradient_norm": 0.37493282556533813,
        "train_loss": 3.0465285778045654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21262,
        "tokens": 11147411456,
        "learning_rate": 0.00017551459718165768,
        "gradient_norm": 0.35555499792099,
        "train_loss": 3.057602882385254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21263,
        "tokens": 11147935744,
        "learning_rate": 0.00017549110461116153,
        "gradient_norm": 0.3557453453540802,
        "train_loss": 3.019033432006836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21264,
        "tokens": 11148460032,
        "learning_rate": 0.0001754676137798555,
        "gradient_norm": 0.3449248671531677,
        "train_loss": 3.034825086593628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21265,
        "tokens": 11148984320,
        "learning_rate": 0.0001754441246880042,
        "gradient_norm": 0.40278735756874084,
        "train_loss": 3.03701114654541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21266,
        "tokens": 11149508608,
        "learning_rate": 0.0001754206373358718,
        "gradient_norm": 0.362922340631485,
        "train_loss": 3.0314173698425293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21267,
        "tokens": 11150032896,
        "learning_rate": 0.00017539715172372293,
        "gradient_norm": 0.3983696401119232,
        "train_loss": 3.024810314178467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21268,
        "tokens": 11150557184,
        "learning_rate": 0.00017537366785182174,
        "gradient_norm": 0.40142592787742615,
        "train_loss": 3.0201220512390137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21269,
        "tokens": 11151081472,
        "learning_rate": 0.00017535018572043275,
        "gradient_norm": 0.35750073194503784,
        "train_loss": 3.0427799224853516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21270,
        "tokens": 11151605760,
        "learning_rate": 0.0001753267053298201,
        "gradient_norm": 0.3891916573047638,
        "train_loss": 3.042065143585205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21271,
        "tokens": 11152130048,
        "learning_rate": 0.00017530322668024822,
        "gradient_norm": 0.36010488867759705,
        "train_loss": 3.130441188812256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21272,
        "tokens": 11152654336,
        "learning_rate": 0.00017527974977198145,
        "gradient_norm": 0.4032363295555115,
        "train_loss": 3.036149501800537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21273,
        "tokens": 11153178624,
        "learning_rate": 0.00017525627460528381,
        "gradient_norm": 0.3624407947063446,
        "train_loss": 3.061903953552246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21274,
        "tokens": 11153702912,
        "learning_rate": 0.00017523280118041985,
        "gradient_norm": 0.3764231503009796,
        "train_loss": 2.9669504165649414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21275,
        "tokens": 11154227200,
        "learning_rate": 0.0001752093294976535,
        "gradient_norm": 0.38354015350341797,
        "train_loss": 3.109250783920288,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21276,
        "tokens": 11154751488,
        "learning_rate": 0.00017518585955724923,
        "gradient_norm": 0.3970974385738373,
        "train_loss": 3.0105717182159424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21277,
        "tokens": 11155275776,
        "learning_rate": 0.00017516239135947098,
        "gradient_norm": 0.3465740382671356,
        "train_loss": 3.055044174194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21278,
        "tokens": 11155800064,
        "learning_rate": 0.0001751389249045831,
        "gradient_norm": 0.37831050157546997,
        "train_loss": 3.1183786392211914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21279,
        "tokens": 11156324352,
        "learning_rate": 0.00017511546019284956,
        "gradient_norm": 0.40431690216064453,
        "train_loss": 3.0751700401306152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21280,
        "tokens": 11156848640,
        "learning_rate": 0.00017509199722453471,
        "gradient_norm": 0.37053534388542175,
        "train_loss": 3.0237951278686523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21281,
        "tokens": 11157372928,
        "learning_rate": 0.00017506853599990246,
        "gradient_norm": 0.3981584906578064,
        "train_loss": 3.0702171325683594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21282,
        "tokens": 11157897216,
        "learning_rate": 0.0001750450765192169,
        "gradient_norm": 0.40916693210601807,
        "train_loss": 3.063833236694336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21283,
        "tokens": 11158421504,
        "learning_rate": 0.0001750216187827423,
        "gradient_norm": 0.3648844063282013,
        "train_loss": 2.994530200958252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21284,
        "tokens": 11158945792,
        "learning_rate": 0.00017499816279074244,
        "gradient_norm": 0.38235828280448914,
        "train_loss": 3.0727107524871826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21285,
        "tokens": 11159470080,
        "learning_rate": 0.00017497470854348159,
        "gradient_norm": 0.3394175171852112,
        "train_loss": 3.0713000297546387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21286,
        "tokens": 11159994368,
        "learning_rate": 0.00017495125604122355,
        "gradient_norm": 0.37541595101356506,
        "train_loss": 3.0795435905456543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21287,
        "tokens": 11160518656,
        "learning_rate": 0.00017492780528423246,
        "gradient_norm": 0.3852100670337677,
        "train_loss": 3.0481948852539062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21288,
        "tokens": 11161042944,
        "learning_rate": 0.00017490435627277214,
        "gradient_norm": 0.36225777864456177,
        "train_loss": 2.9750523567199707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21289,
        "tokens": 11161567232,
        "learning_rate": 0.0001748809090071067,
        "gradient_norm": 0.4295850694179535,
        "train_loss": 3.069767951965332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21290,
        "tokens": 11162091520,
        "learning_rate": 0.00017485746348749995,
        "gradient_norm": 0.3689030408859253,
        "train_loss": 3.02827525138855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21291,
        "tokens": 11162615808,
        "learning_rate": 0.0001748340197142158,
        "gradient_norm": 0.3948800563812256,
        "train_loss": 3.073054075241089,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21292,
        "tokens": 11163140096,
        "learning_rate": 0.00017481057768751828,
        "gradient_norm": 0.38780465722084045,
        "train_loss": 3.0503640174865723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21293,
        "tokens": 11163664384,
        "learning_rate": 0.00017478713740767108,
        "gradient_norm": 0.3483295142650604,
        "train_loss": 3.0500125885009766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21294,
        "tokens": 11164188672,
        "learning_rate": 0.0001747636988749382,
        "gradient_norm": 0.44791778922080994,
        "train_loss": 3.036564350128174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21295,
        "tokens": 11164712960,
        "learning_rate": 0.0001747402620895833,
        "gradient_norm": 0.32923758029937744,
        "train_loss": 3.040623426437378,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21296,
        "tokens": 11165237248,
        "learning_rate": 0.0001747168270518704,
        "gradient_norm": 0.4472233057022095,
        "train_loss": 3.008366584777832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21297,
        "tokens": 11165761536,
        "learning_rate": 0.00017469339376206304,
        "gradient_norm": 0.3479878902435303,
        "train_loss": 3.0469307899475098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21298,
        "tokens": 11166285824,
        "learning_rate": 0.00017466996222042526,
        "gradient_norm": 0.4776836633682251,
        "train_loss": 2.9933884143829346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21299,
        "tokens": 11166810112,
        "learning_rate": 0.00017464653242722057,
        "gradient_norm": 0.38919028639793396,
        "train_loss": 3.0813379287719727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21300,
        "tokens": 11167334400,
        "learning_rate": 0.00017462310438271292,
        "gradient_norm": 0.4063173234462738,
        "train_loss": 3.0300045013427734,
        "val_loss": 3.0089728832244873,
        "hellaswag_acc": 0.28211510181427,
        "hellaswag_acc_norm": 0.2948615849018097
    },
    {
        "step": 21301,
        "tokens": 11167858688,
        "learning_rate": 0.0001745996780871658,
        "gradient_norm": 0.37321728467941284,
        "train_loss": 3.0396814346313477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21302,
        "tokens": 11168382976,
        "learning_rate": 0.00017457625354084301,
        "gradient_norm": 0.4009194076061249,
        "train_loss": 3.0416407585144043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21303,
        "tokens": 11168907264,
        "learning_rate": 0.00017455283074400833,
        "gradient_norm": 0.36347082257270813,
        "train_loss": 3.0386929512023926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21304,
        "tokens": 11169431552,
        "learning_rate": 0.00017452940969692524,
        "gradient_norm": 0.3832450807094574,
        "train_loss": 3.0419907569885254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21305,
        "tokens": 11169955840,
        "learning_rate": 0.00017450599039985751,
        "gradient_norm": 0.3742790222167969,
        "train_loss": 3.0311827659606934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21306,
        "tokens": 11170480128,
        "learning_rate": 0.00017448257285306864,
        "gradient_norm": 0.38801392912864685,
        "train_loss": 3.1258199214935303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21307,
        "tokens": 11171004416,
        "learning_rate": 0.00017445915705682232,
        "gradient_norm": 0.3929060101509094,
        "train_loss": 3.0921707153320312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21308,
        "tokens": 11171528704,
        "learning_rate": 0.000174435743011382,
        "gradient_norm": 0.36056631803512573,
        "train_loss": 3.0851032733917236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21309,
        "tokens": 11172052992,
        "learning_rate": 0.00017441233071701135,
        "gradient_norm": 0.39446887373924255,
        "train_loss": 3.072099447250366,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21310,
        "tokens": 11172577280,
        "learning_rate": 0.0001743889201739738,
        "gradient_norm": 0.3823193609714508,
        "train_loss": 3.101853132247925,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21311,
        "tokens": 11173101568,
        "learning_rate": 0.00017436551138253295,
        "gradient_norm": 0.41227978467941284,
        "train_loss": 3.082015037536621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21312,
        "tokens": 11173625856,
        "learning_rate": 0.00017434210434295235,
        "gradient_norm": 0.4129640758037567,
        "train_loss": 3.0722403526306152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21313,
        "tokens": 11174150144,
        "learning_rate": 0.0001743186990554953,
        "gradient_norm": 0.4167959988117218,
        "train_loss": 3.0701704025268555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21314,
        "tokens": 11174674432,
        "learning_rate": 0.00017429529552042544,
        "gradient_norm": 0.395902544260025,
        "train_loss": 3.013047695159912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21315,
        "tokens": 11175198720,
        "learning_rate": 0.00017427189373800606,
        "gradient_norm": 0.37355080246925354,
        "train_loss": 3.028183937072754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21316,
        "tokens": 11175723008,
        "learning_rate": 0.0001742484937085007,
        "gradient_norm": 0.44438984990119934,
        "train_loss": 3.0451292991638184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21317,
        "tokens": 11176247296,
        "learning_rate": 0.0001742250954321726,
        "gradient_norm": 0.44156673550605774,
        "train_loss": 3.1570329666137695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21318,
        "tokens": 11176771584,
        "learning_rate": 0.00017420169890928534,
        "gradient_norm": 0.4310908317565918,
        "train_loss": 3.0327441692352295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21319,
        "tokens": 11177295872,
        "learning_rate": 0.00017417830414010209,
        "gradient_norm": 0.43640223145484924,
        "train_loss": 3.1182494163513184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21320,
        "tokens": 11177820160,
        "learning_rate": 0.0001741549111248863,
        "gradient_norm": 0.413237065076828,
        "train_loss": 3.0027451515197754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21321,
        "tokens": 11178344448,
        "learning_rate": 0.0001741315198639012,
        "gradient_norm": 0.371649831533432,
        "train_loss": 3.0762040615081787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21322,
        "tokens": 11178868736,
        "learning_rate": 0.0001741081303574101,
        "gradient_norm": 0.4565005898475647,
        "train_loss": 3.057158946990967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21323,
        "tokens": 11179393024,
        "learning_rate": 0.00017408474260567646,
        "gradient_norm": 0.3601946532726288,
        "train_loss": 3.0616464614868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21324,
        "tokens": 11179917312,
        "learning_rate": 0.0001740613566089633,
        "gradient_norm": 0.43752187490463257,
        "train_loss": 3.101008892059326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21325,
        "tokens": 11180441600,
        "learning_rate": 0.00017403797236753403,
        "gradient_norm": 0.3644102215766907,
        "train_loss": 3.0214247703552246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21326,
        "tokens": 11180965888,
        "learning_rate": 0.00017401458988165167,
        "gradient_norm": 0.3984476923942566,
        "train_loss": 3.0568408966064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21327,
        "tokens": 11181490176,
        "learning_rate": 0.00017399120915157968,
        "gradient_norm": 0.4211967885494232,
        "train_loss": 3.103170871734619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21328,
        "tokens": 11182014464,
        "learning_rate": 0.00017396783017758095,
        "gradient_norm": 0.39323797821998596,
        "train_loss": 3.0917367935180664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21329,
        "tokens": 11182538752,
        "learning_rate": 0.00017394445295991896,
        "gradient_norm": 0.4176851809024811,
        "train_loss": 3.026426076889038,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21330,
        "tokens": 11183063040,
        "learning_rate": 0.00017392107749885654,
        "gradient_norm": 0.40304479002952576,
        "train_loss": 2.9838240146636963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21331,
        "tokens": 11183587328,
        "learning_rate": 0.00017389770379465694,
        "gradient_norm": 0.4164362847805023,
        "train_loss": 2.9993185997009277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21332,
        "tokens": 11184111616,
        "learning_rate": 0.0001738743318475834,
        "gradient_norm": 0.39063817262649536,
        "train_loss": 2.987863779067993,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21333,
        "tokens": 11184635904,
        "learning_rate": 0.0001738509616578988,
        "gradient_norm": 0.44056567549705505,
        "train_loss": 3.0372366905212402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21334,
        "tokens": 11185160192,
        "learning_rate": 0.00017382759322586629,
        "gradient_norm": 0.43002039194107056,
        "train_loss": 3.0240156650543213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21335,
        "tokens": 11185684480,
        "learning_rate": 0.00017380422655174883,
        "gradient_norm": 0.37487637996673584,
        "train_loss": 2.982637643814087,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21336,
        "tokens": 11186208768,
        "learning_rate": 0.00017378086163580964,
        "gradient_norm": 0.39572110772132874,
        "train_loss": 3.0865116119384766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21337,
        "tokens": 11186733056,
        "learning_rate": 0.00017375749847831144,
        "gradient_norm": 0.39498013257980347,
        "train_loss": 3.0798444747924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21338,
        "tokens": 11187257344,
        "learning_rate": 0.00017373413707951743,
        "gradient_norm": 0.37483322620391846,
        "train_loss": 3.059291124343872,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21339,
        "tokens": 11187781632,
        "learning_rate": 0.00017371077743969047,
        "gradient_norm": 0.40229201316833496,
        "train_loss": 3.027527332305908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21340,
        "tokens": 11188305920,
        "learning_rate": 0.00017368741955909358,
        "gradient_norm": 0.37171515822410583,
        "train_loss": 3.019845724105835,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21341,
        "tokens": 11188830208,
        "learning_rate": 0.00017366406343798953,
        "gradient_norm": 0.34610575437545776,
        "train_loss": 3.0310428142547607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21342,
        "tokens": 11189354496,
        "learning_rate": 0.00017364070907664145,
        "gradient_norm": 0.3721250891685486,
        "train_loss": 2.9925332069396973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21343,
        "tokens": 11189878784,
        "learning_rate": 0.00017361735647531198,
        "gradient_norm": 0.3517826795578003,
        "train_loss": 3.0874221324920654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21344,
        "tokens": 11190403072,
        "learning_rate": 0.00017359400563426422,
        "gradient_norm": 0.3600524663925171,
        "train_loss": 3.048125982284546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21345,
        "tokens": 11190927360,
        "learning_rate": 0.0001735706565537608,
        "gradient_norm": 0.3575616478919983,
        "train_loss": 2.9851553440093994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21346,
        "tokens": 11191451648,
        "learning_rate": 0.0001735473092340647,
        "gradient_norm": 0.3619026243686676,
        "train_loss": 3.07696270942688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21347,
        "tokens": 11191975936,
        "learning_rate": 0.00017352396367543857,
        "gradient_norm": 0.3821169435977936,
        "train_loss": 3.044034004211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21348,
        "tokens": 11192500224,
        "learning_rate": 0.00017350061987814536,
        "gradient_norm": 0.3856114149093628,
        "train_loss": 3.1749777793884277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21349,
        "tokens": 11193024512,
        "learning_rate": 0.00017347727784244768,
        "gradient_norm": 0.555500328540802,
        "train_loss": 3.083378553390503,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21350,
        "tokens": 11193548800,
        "learning_rate": 0.00017345393756860845,
        "gradient_norm": 0.47108036279678345,
        "train_loss": 3.0617313385009766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21351,
        "tokens": 11194073088,
        "learning_rate": 0.00017343059905689016,
        "gradient_norm": 0.4242374002933502,
        "train_loss": 3.0611724853515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21352,
        "tokens": 11194597376,
        "learning_rate": 0.0001734072623075558,
        "gradient_norm": 0.40728917717933655,
        "train_loss": 3.05153751373291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21353,
        "tokens": 11195121664,
        "learning_rate": 0.00017338392732086776,
        "gradient_norm": 0.41086459159851074,
        "train_loss": 3.0744268894195557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21354,
        "tokens": 11195645952,
        "learning_rate": 0.00017336059409708897,
        "gradient_norm": 0.4247977137565613,
        "train_loss": 3.043911933898926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21355,
        "tokens": 11196170240,
        "learning_rate": 0.00017333726263648181,
        "gradient_norm": 0.44918155670166016,
        "train_loss": 3.0992796421051025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21356,
        "tokens": 11196694528,
        "learning_rate": 0.0001733139329393092,
        "gradient_norm": 0.3869558274745941,
        "train_loss": 3.0530288219451904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21357,
        "tokens": 11197218816,
        "learning_rate": 0.00017329060500583345,
        "gradient_norm": 0.3992295265197754,
        "train_loss": 3.059978485107422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21358,
        "tokens": 11197743104,
        "learning_rate": 0.00017326727883631743,
        "gradient_norm": 0.41162872314453125,
        "train_loss": 3.018418312072754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21359,
        "tokens": 11198267392,
        "learning_rate": 0.0001732439544310234,
        "gradient_norm": 0.3695049285888672,
        "train_loss": 3.0557303428649902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21360,
        "tokens": 11198791680,
        "learning_rate": 0.00017322063179021408,
        "gradient_norm": 0.3581872582435608,
        "train_loss": 3.0458176136016846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21361,
        "tokens": 11199315968,
        "learning_rate": 0.0001731973109141521,
        "gradient_norm": 0.36483269929885864,
        "train_loss": 3.0839154720306396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21362,
        "tokens": 11199840256,
        "learning_rate": 0.00017317399180309976,
        "gradient_norm": 0.36118245124816895,
        "train_loss": 3.003739833831787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21363,
        "tokens": 11200364544,
        "learning_rate": 0.00017315067445731967,
        "gradient_norm": 0.36643508076667786,
        "train_loss": 3.0769851207733154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21364,
        "tokens": 11200888832,
        "learning_rate": 0.0001731273588770742,
        "gradient_norm": 0.4110495150089264,
        "train_loss": 3.119565010070801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21365,
        "tokens": 11201413120,
        "learning_rate": 0.00017310404506262593,
        "gradient_norm": 0.41367387771606445,
        "train_loss": 3.0657522678375244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21366,
        "tokens": 11201937408,
        "learning_rate": 0.00017308073301423713,
        "gradient_norm": 0.3279760181903839,
        "train_loss": 3.0787127017974854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21367,
        "tokens": 11202461696,
        "learning_rate": 0.0001730574227321704,
        "gradient_norm": 0.3825003206729889,
        "train_loss": 3.067110776901245,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21368,
        "tokens": 11202985984,
        "learning_rate": 0.0001730341142166879,
        "gradient_norm": 0.3591610789299011,
        "train_loss": 3.0276260375976562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21369,
        "tokens": 11203510272,
        "learning_rate": 0.0001730108074680522,
        "gradient_norm": 0.43011394143104553,
        "train_loss": 3.101013422012329,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21370,
        "tokens": 11204034560,
        "learning_rate": 0.00017298750248652541,
        "gradient_norm": 0.4184862971305847,
        "train_loss": 3.015286445617676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21371,
        "tokens": 11204558848,
        "learning_rate": 0.00017296419927237004,
        "gradient_norm": 0.3818398416042328,
        "train_loss": 3.014090061187744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21372,
        "tokens": 11205083136,
        "learning_rate": 0.00017294089782584848,
        "gradient_norm": 0.3958490490913391,
        "train_loss": 3.0468733310699463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21373,
        "tokens": 11205607424,
        "learning_rate": 0.00017291759814722278,
        "gradient_norm": 0.4160988926887512,
        "train_loss": 3.0641303062438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21374,
        "tokens": 11206131712,
        "learning_rate": 0.00017289430023675542,
        "gradient_norm": 0.3752865195274353,
        "train_loss": 3.0525174140930176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21375,
        "tokens": 11206656000,
        "learning_rate": 0.0001728710040947084,
        "gradient_norm": 0.406070739030838,
        "train_loss": 3.0683114528656006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21376,
        "tokens": 11207180288,
        "learning_rate": 0.00017284770972134426,
        "gradient_norm": 0.39283487200737,
        "train_loss": 2.9904685020446777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21377,
        "tokens": 11207704576,
        "learning_rate": 0.00017282441711692495,
        "gradient_norm": 0.39852607250213623,
        "train_loss": 3.0151805877685547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21378,
        "tokens": 11208228864,
        "learning_rate": 0.0001728011262817128,
        "gradient_norm": 0.4022911787033081,
        "train_loss": 3.042644500732422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21379,
        "tokens": 11208753152,
        "learning_rate": 0.00017277783721596985,
        "gradient_norm": 0.3905813992023468,
        "train_loss": 3.0408802032470703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21380,
        "tokens": 11209277440,
        "learning_rate": 0.00017275454991995835,
        "gradient_norm": 0.5015279054641724,
        "train_loss": 3.0707993507385254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21381,
        "tokens": 11209801728,
        "learning_rate": 0.00017273126439394044,
        "gradient_norm": 0.38436704874038696,
        "train_loss": 3.0557780265808105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21382,
        "tokens": 11210326016,
        "learning_rate": 0.00017270798063817814,
        "gradient_norm": 0.4264959692955017,
        "train_loss": 3.0373973846435547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21383,
        "tokens": 11210850304,
        "learning_rate": 0.00017268469865293367,
        "gradient_norm": 0.3877537250518799,
        "train_loss": 3.038790702819824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21384,
        "tokens": 11211374592,
        "learning_rate": 0.0001726614184384689,
        "gradient_norm": 0.44187891483306885,
        "train_loss": 3.0713582038879395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21385,
        "tokens": 11211898880,
        "learning_rate": 0.00017263813999504615,
        "gradient_norm": 0.3995361626148224,
        "train_loss": 3.0634946823120117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21386,
        "tokens": 11212423168,
        "learning_rate": 0.00017261486332292714,
        "gradient_norm": 0.3973262906074524,
        "train_loss": 3.030618667602539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21387,
        "tokens": 11212947456,
        "learning_rate": 0.00017259158842237413,
        "gradient_norm": 0.43330472707748413,
        "train_loss": 3.020341396331787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21388,
        "tokens": 11213471744,
        "learning_rate": 0.00017256831529364891,
        "gradient_norm": 0.4009690284729004,
        "train_loss": 3.0630929470062256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21389,
        "tokens": 11213996032,
        "learning_rate": 0.00017254504393701366,
        "gradient_norm": 0.4462309181690216,
        "train_loss": 3.059602975845337,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21390,
        "tokens": 11214520320,
        "learning_rate": 0.00017252177435273013,
        "gradient_norm": 0.44409117102622986,
        "train_loss": 3.077608108520508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21391,
        "tokens": 11215044608,
        "learning_rate": 0.00017249850654106028,
        "gradient_norm": 0.40804144740104675,
        "train_loss": 3.0204696655273438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21392,
        "tokens": 11215568896,
        "learning_rate": 0.00017247524050226622,
        "gradient_norm": 0.4294770359992981,
        "train_loss": 3.02150297164917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21393,
        "tokens": 11216093184,
        "learning_rate": 0.00017245197623660957,
        "gradient_norm": 0.41769129037857056,
        "train_loss": 3.057168960571289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21394,
        "tokens": 11216617472,
        "learning_rate": 0.0001724287137443524,
        "gradient_norm": 0.44051605463027954,
        "train_loss": 3.065581798553467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21395,
        "tokens": 11217141760,
        "learning_rate": 0.00017240545302575638,
        "gradient_norm": 0.39389824867248535,
        "train_loss": 3.0298919677734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21396,
        "tokens": 11217666048,
        "learning_rate": 0.00017238219408108354,
        "gradient_norm": 0.39224231243133545,
        "train_loss": 3.106529712677002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21397,
        "tokens": 11218190336,
        "learning_rate": 0.0001723589369105955,
        "gradient_norm": 0.45658227801322937,
        "train_loss": 3.0456809997558594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21398,
        "tokens": 11218714624,
        "learning_rate": 0.00017233568151455418,
        "gradient_norm": 0.3736947178840637,
        "train_loss": 3.0574753284454346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21399,
        "tokens": 11219238912,
        "learning_rate": 0.00017231242789322125,
        "gradient_norm": 0.40004071593284607,
        "train_loss": 3.0250344276428223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21400,
        "tokens": 11219763200,
        "learning_rate": 0.00017228917604685846,
        "gradient_norm": 0.4094211757183075,
        "train_loss": 3.048288345336914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21401,
        "tokens": 11220287488,
        "learning_rate": 0.00017226592597572774,
        "gradient_norm": 0.40536484122276306,
        "train_loss": 3.010800361633301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21402,
        "tokens": 11220811776,
        "learning_rate": 0.0001722426776800905,
        "gradient_norm": 0.42845505475997925,
        "train_loss": 3.0625228881835938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21403,
        "tokens": 11221336064,
        "learning_rate": 0.0001722194311602087,
        "gradient_norm": 0.4056812822818756,
        "train_loss": 3.0420193672180176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21404,
        "tokens": 11221860352,
        "learning_rate": 0.00017219618641634376,
        "gradient_norm": 0.38743746280670166,
        "train_loss": 3.062288761138916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21405,
        "tokens": 11222384640,
        "learning_rate": 0.00017217294344875754,
        "gradient_norm": 0.4270656406879425,
        "train_loss": 3.108914375305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21406,
        "tokens": 11222908928,
        "learning_rate": 0.00017214970225771153,
        "gradient_norm": 0.41841742396354675,
        "train_loss": 2.9914650917053223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21407,
        "tokens": 11223433216,
        "learning_rate": 0.00017212646284346742,
        "gradient_norm": 0.3495900332927704,
        "train_loss": 3.035158634185791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21408,
        "tokens": 11223957504,
        "learning_rate": 0.00017210322520628673,
        "gradient_norm": 0.4354110360145569,
        "train_loss": 3.11088228225708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21409,
        "tokens": 11224481792,
        "learning_rate": 0.00017207998934643112,
        "gradient_norm": 0.3460999131202698,
        "train_loss": 3.031609535217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21410,
        "tokens": 11225006080,
        "learning_rate": 0.000172056755264162,
        "gradient_norm": 0.4168958365917206,
        "train_loss": 2.978440284729004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21411,
        "tokens": 11225530368,
        "learning_rate": 0.00017203352295974095,
        "gradient_norm": 0.38299429416656494,
        "train_loss": 3.0524001121520996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21412,
        "tokens": 11226054656,
        "learning_rate": 0.00017201029243342963,
        "gradient_norm": 0.4063418209552765,
        "train_loss": 3.04823637008667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21413,
        "tokens": 11226578944,
        "learning_rate": 0.00017198706368548936,
        "gradient_norm": 0.3811282813549042,
        "train_loss": 3.0216493606567383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21414,
        "tokens": 11227103232,
        "learning_rate": 0.00017196383671618169,
        "gradient_norm": 0.4278794229030609,
        "train_loss": 3.050111770629883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21415,
        "tokens": 11227627520,
        "learning_rate": 0.00017194061152576794,
        "gradient_norm": 0.41034555435180664,
        "train_loss": 3.139786720275879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21416,
        "tokens": 11228151808,
        "learning_rate": 0.00017191738811450977,
        "gradient_norm": 0.4387231767177582,
        "train_loss": 3.010636329650879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21417,
        "tokens": 11228676096,
        "learning_rate": 0.00017189416648266833,
        "gradient_norm": 0.3699438273906708,
        "train_loss": 3.0533151626586914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21418,
        "tokens": 11229200384,
        "learning_rate": 0.00017187094663050523,
        "gradient_norm": 0.4440496861934662,
        "train_loss": 3.0240204334259033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21419,
        "tokens": 11229724672,
        "learning_rate": 0.0001718477285582816,
        "gradient_norm": 0.39182913303375244,
        "train_loss": 3.0130105018615723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21420,
        "tokens": 11230248960,
        "learning_rate": 0.00017182451226625898,
        "gradient_norm": 0.3887888491153717,
        "train_loss": 3.0317444801330566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21421,
        "tokens": 11230773248,
        "learning_rate": 0.00017180129775469874,
        "gradient_norm": 0.3941314220428467,
        "train_loss": 2.9319331645965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21422,
        "tokens": 11231297536,
        "learning_rate": 0.00017177808502386198,
        "gradient_norm": 0.4335058927536011,
        "train_loss": 3.008000373840332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21423,
        "tokens": 11231821824,
        "learning_rate": 0.0001717548740740102,
        "gradient_norm": 0.37381139397621155,
        "train_loss": 3.0299477577209473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21424,
        "tokens": 11232346112,
        "learning_rate": 0.00017173166490540447,
        "gradient_norm": 0.41482484340667725,
        "train_loss": 3.032409191131592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21425,
        "tokens": 11232870400,
        "learning_rate": 0.00017170845751830624,
        "gradient_norm": 0.44953176379203796,
        "train_loss": 3.072227954864502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21426,
        "tokens": 11233394688,
        "learning_rate": 0.00017168525191297657,
        "gradient_norm": 0.3935208320617676,
        "train_loss": 2.9922444820404053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21427,
        "tokens": 11233918976,
        "learning_rate": 0.00017166204808967677,
        "gradient_norm": 0.3990883231163025,
        "train_loss": 3.064732074737549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21428,
        "tokens": 11234443264,
        "learning_rate": 0.00017163884604866794,
        "gradient_norm": 0.3946090638637543,
        "train_loss": 3.0638976097106934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21429,
        "tokens": 11234967552,
        "learning_rate": 0.0001716156457902114,
        "gradient_norm": 0.3932693302631378,
        "train_loss": 3.130976676940918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21430,
        "tokens": 11235491840,
        "learning_rate": 0.00017159244731456807,
        "gradient_norm": 0.4518563747406006,
        "train_loss": 3.020529270172119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21431,
        "tokens": 11236016128,
        "learning_rate": 0.00017156925062199922,
        "gradient_norm": 0.3822000324726105,
        "train_loss": 3.071444034576416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21432,
        "tokens": 11236540416,
        "learning_rate": 0.00017154605571276604,
        "gradient_norm": 0.40067312121391296,
        "train_loss": 3.057018756866455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21433,
        "tokens": 11237064704,
        "learning_rate": 0.00017152286258712945,
        "gradient_norm": 0.38613009452819824,
        "train_loss": 3.059727668762207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21434,
        "tokens": 11237588992,
        "learning_rate": 0.00017149967124535065,
        "gradient_norm": 0.40379688143730164,
        "train_loss": 3.0417840480804443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21435,
        "tokens": 11238113280,
        "learning_rate": 0.00017147648168769054,
        "gradient_norm": 0.37645161151885986,
        "train_loss": 3.047452449798584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21436,
        "tokens": 11238637568,
        "learning_rate": 0.00017145329391441032,
        "gradient_norm": 0.41883784532546997,
        "train_loss": 3.114811897277832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21437,
        "tokens": 11239161856,
        "learning_rate": 0.00017143010792577084,
        "gradient_norm": 0.4114334285259247,
        "train_loss": 3.0227203369140625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21438,
        "tokens": 11239686144,
        "learning_rate": 0.00017140692372203322,
        "gradient_norm": 0.3893822431564331,
        "train_loss": 3.0558972358703613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21439,
        "tokens": 11240210432,
        "learning_rate": 0.00017138374130345828,
        "gradient_norm": 0.38167524337768555,
        "train_loss": 3.0250144004821777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21440,
        "tokens": 11240734720,
        "learning_rate": 0.00017136056067030707,
        "gradient_norm": 0.35806727409362793,
        "train_loss": 3.0884907245635986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21441,
        "tokens": 11241259008,
        "learning_rate": 0.0001713373818228406,
        "gradient_norm": 0.38063496351242065,
        "train_loss": 3.0117383003234863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21442,
        "tokens": 11241783296,
        "learning_rate": 0.00017131420476131957,
        "gradient_norm": 0.3527706563472748,
        "train_loss": 3.0604491233825684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21443,
        "tokens": 11242307584,
        "learning_rate": 0.00017129102948600507,
        "gradient_norm": 0.3882591426372528,
        "train_loss": 3.0755879878997803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21444,
        "tokens": 11242831872,
        "learning_rate": 0.00017126785599715772,
        "gradient_norm": 0.35152944922447205,
        "train_loss": 3.036334753036499,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21445,
        "tokens": 11243356160,
        "learning_rate": 0.00017124468429503869,
        "gradient_norm": 0.36245450377464294,
        "train_loss": 3.082095146179199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21446,
        "tokens": 11243880448,
        "learning_rate": 0.0001712215143799085,
        "gradient_norm": 0.37313222885131836,
        "train_loss": 3.017448902130127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21447,
        "tokens": 11244404736,
        "learning_rate": 0.00017119834625202817,
        "gradient_norm": 0.3567989766597748,
        "train_loss": 3.0442376136779785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21448,
        "tokens": 11244929024,
        "learning_rate": 0.00017117517991165835,
        "gradient_norm": 0.37708690762519836,
        "train_loss": 3.0301761627197266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21449,
        "tokens": 11245453312,
        "learning_rate": 0.00017115201535905993,
        "gradient_norm": 0.37386229634284973,
        "train_loss": 3.0428504943847656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21450,
        "tokens": 11245977600,
        "learning_rate": 0.0001711288525944935,
        "gradient_norm": 0.3469475507736206,
        "train_loss": 3.063549518585205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21451,
        "tokens": 11246501888,
        "learning_rate": 0.00017110569161821995,
        "gradient_norm": 0.37929192185401917,
        "train_loss": 3.0362963676452637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21452,
        "tokens": 11247026176,
        "learning_rate": 0.00017108253243049983,
        "gradient_norm": 0.37099266052246094,
        "train_loss": 3.0235705375671387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21453,
        "tokens": 11247550464,
        "learning_rate": 0.00017105937503159399,
        "gradient_norm": 0.37813064455986023,
        "train_loss": 3.0943212509155273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21454,
        "tokens": 11248074752,
        "learning_rate": 0.00017103621942176288,
        "gradient_norm": 0.3867112994194031,
        "train_loss": 3.0549097061157227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21455,
        "tokens": 11248599040,
        "learning_rate": 0.00017101306560126744,
        "gradient_norm": 0.41408246755599976,
        "train_loss": 3.065861225128174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21456,
        "tokens": 11249123328,
        "learning_rate": 0.00017098991357036798,
        "gradient_norm": 0.3764914274215698,
        "train_loss": 3.012509346008301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21457,
        "tokens": 11249647616,
        "learning_rate": 0.00017096676332932536,
        "gradient_norm": 0.3819383382797241,
        "train_loss": 3.0671441555023193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21458,
        "tokens": 11250171904,
        "learning_rate": 0.0001709436148784,
        "gradient_norm": 0.339998334646225,
        "train_loss": 3.083341121673584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21459,
        "tokens": 11250696192,
        "learning_rate": 0.0001709204682178526,
        "gradient_norm": 0.4257621765136719,
        "train_loss": 3.152432918548584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21460,
        "tokens": 11251220480,
        "learning_rate": 0.00017089732334794351,
        "gradient_norm": 0.36606764793395996,
        "train_loss": 2.9952778816223145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21461,
        "tokens": 11251744768,
        "learning_rate": 0.00017087418026893347,
        "gradient_norm": 0.42824921011924744,
        "train_loss": 3.0478036403656006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21462,
        "tokens": 11252269056,
        "learning_rate": 0.0001708510389810828,
        "gradient_norm": 0.3773718476295471,
        "train_loss": 3.019486904144287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21463,
        "tokens": 11252793344,
        "learning_rate": 0.0001708278994846522,
        "gradient_norm": 0.3835267722606659,
        "train_loss": 3.0526270866394043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21464,
        "tokens": 11253317632,
        "learning_rate": 0.00017080476177990184,
        "gradient_norm": 0.3901906907558441,
        "train_loss": 3.067155361175537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21465,
        "tokens": 11253841920,
        "learning_rate": 0.00017078162586709248,
        "gradient_norm": 0.44403669238090515,
        "train_loss": 3.0255517959594727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21466,
        "tokens": 11254366208,
        "learning_rate": 0.00017075849174648427,
        "gradient_norm": 0.39037856459617615,
        "train_loss": 3.0737099647521973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21467,
        "tokens": 11254890496,
        "learning_rate": 0.00017073535941833785,
        "gradient_norm": 0.3810335695743561,
        "train_loss": 3.026259422302246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21468,
        "tokens": 11255414784,
        "learning_rate": 0.00017071222888291338,
        "gradient_norm": 0.36986851692199707,
        "train_loss": 3.063767433166504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21469,
        "tokens": 11255939072,
        "learning_rate": 0.0001706891001404714,
        "gradient_norm": 0.34491315484046936,
        "train_loss": 2.968547821044922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21470,
        "tokens": 11256463360,
        "learning_rate": 0.0001706659731912721,
        "gradient_norm": 0.37745073437690735,
        "train_loss": 3.0237817764282227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21471,
        "tokens": 11256987648,
        "learning_rate": 0.00017064284803557594,
        "gradient_norm": 0.34990552067756653,
        "train_loss": 2.980414390563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21472,
        "tokens": 11257511936,
        "learning_rate": 0.00017061972467364322,
        "gradient_norm": 0.38758814334869385,
        "train_loss": 3.070140838623047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21473,
        "tokens": 11258036224,
        "learning_rate": 0.0001705966031057341,
        "gradient_norm": 0.3697962462902069,
        "train_loss": 3.027977466583252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21474,
        "tokens": 11258560512,
        "learning_rate": 0.000170573483332109,
        "gradient_norm": 0.37890058755874634,
        "train_loss": 3.1100306510925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21475,
        "tokens": 11259084800,
        "learning_rate": 0.00017055036535302794,
        "gradient_norm": 0.356343537569046,
        "train_loss": 3.0196518898010254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21476,
        "tokens": 11259609088,
        "learning_rate": 0.0001705272491687514,
        "gradient_norm": 0.36686384677886963,
        "train_loss": 3.035499095916748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21477,
        "tokens": 11260133376,
        "learning_rate": 0.0001705041347795394,
        "gradient_norm": 0.41705840826034546,
        "train_loss": 3.05549955368042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21478,
        "tokens": 11260657664,
        "learning_rate": 0.0001704810221856522,
        "gradient_norm": 0.36699628829956055,
        "train_loss": 3.0514073371887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21479,
        "tokens": 11261181952,
        "learning_rate": 0.00017045791138734992,
        "gradient_norm": 0.43402692675590515,
        "train_loss": 2.9938364028930664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21480,
        "tokens": 11261706240,
        "learning_rate": 0.0001704348023848927,
        "gradient_norm": 0.37843120098114014,
        "train_loss": 3.0991930961608887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21481,
        "tokens": 11262230528,
        "learning_rate": 0.00017041169517854074,
        "gradient_norm": 0.4242858290672302,
        "train_loss": 3.0106067657470703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21482,
        "tokens": 11262754816,
        "learning_rate": 0.00017038858976855403,
        "gradient_norm": 0.4429548382759094,
        "train_loss": 3.082219123840332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21483,
        "tokens": 11263279104,
        "learning_rate": 0.00017036548615519278,
        "gradient_norm": 0.3616235852241516,
        "train_loss": 3.078892230987549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21484,
        "tokens": 11263803392,
        "learning_rate": 0.00017034238433871686,
        "gradient_norm": 0.40705645084381104,
        "train_loss": 2.984193801879883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21485,
        "tokens": 11264327680,
        "learning_rate": 0.00017031928431938655,
        "gradient_norm": 0.38294222950935364,
        "train_loss": 3.055542469024658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21486,
        "tokens": 11264851968,
        "learning_rate": 0.00017029618609746167,
        "gradient_norm": 0.3655269145965576,
        "train_loss": 3.027740955352783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21487,
        "tokens": 11265376256,
        "learning_rate": 0.00017027308967320232,
        "gradient_norm": 0.34785643219947815,
        "train_loss": 3.032433032989502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21488,
        "tokens": 11265900544,
        "learning_rate": 0.00017024999504686842,
        "gradient_norm": 0.4179673492908478,
        "train_loss": 3.0816617012023926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21489,
        "tokens": 11266424832,
        "learning_rate": 0.00017022690221872,
        "gradient_norm": 0.3811604082584381,
        "train_loss": 3.0741024017333984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21490,
        "tokens": 11266949120,
        "learning_rate": 0.0001702038111890169,
        "gradient_norm": 0.3465521037578583,
        "train_loss": 3.028804302215576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21491,
        "tokens": 11267473408,
        "learning_rate": 0.00017018072195801908,
        "gradient_norm": 0.3695661127567291,
        "train_loss": 3.0181074142456055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21492,
        "tokens": 11267997696,
        "learning_rate": 0.00017015763452598654,
        "gradient_norm": 0.3780887722969055,
        "train_loss": 3.0353569984436035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21493,
        "tokens": 11268521984,
        "learning_rate": 0.00017013454889317896,
        "gradient_norm": 0.3783089220523834,
        "train_loss": 3.0294368267059326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21494,
        "tokens": 11269046272,
        "learning_rate": 0.00017011146505985645,
        "gradient_norm": 0.38141000270843506,
        "train_loss": 3.045652389526367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21495,
        "tokens": 11269570560,
        "learning_rate": 0.00017008838302627862,
        "gradient_norm": 0.38892805576324463,
        "train_loss": 3.024430751800537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21496,
        "tokens": 11270094848,
        "learning_rate": 0.00017006530279270544,
        "gradient_norm": 0.3954876661300659,
        "train_loss": 3.074171304702759,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21497,
        "tokens": 11270619136,
        "learning_rate": 0.00017004222435939654,
        "gradient_norm": 0.3987729251384735,
        "train_loss": 3.0335135459899902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21498,
        "tokens": 11271143424,
        "learning_rate": 0.0001700191477266119,
        "gradient_norm": 0.4426325559616089,
        "train_loss": 3.112076759338379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21499,
        "tokens": 11271667712,
        "learning_rate": 0.00016999607289461109,
        "gradient_norm": 0.37746280431747437,
        "train_loss": 3.038149356842041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21500,
        "tokens": 11272192000,
        "learning_rate": 0.00016997299986365393,
        "gradient_norm": 0.4465850293636322,
        "train_loss": 3.0152244567871094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21501,
        "tokens": 11272716288,
        "learning_rate": 0.00016994992863400023,
        "gradient_norm": 0.4783512353897095,
        "train_loss": 3.0100462436676025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21502,
        "tokens": 11273240576,
        "learning_rate": 0.00016992685920590948,
        "gradient_norm": 0.39088207483291626,
        "train_loss": 3.104749917984009,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21503,
        "tokens": 11273764864,
        "learning_rate": 0.00016990379157964155,
        "gradient_norm": 0.47702136635780334,
        "train_loss": 3.0052247047424316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21504,
        "tokens": 11274289152,
        "learning_rate": 0.00016988072575545594,
        "gradient_norm": 0.4661974608898163,
        "train_loss": 3.0474700927734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21505,
        "tokens": 11274813440,
        "learning_rate": 0.00016985766173361244,
        "gradient_norm": 0.39158838987350464,
        "train_loss": 3.0128300189971924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21506,
        "tokens": 11275337728,
        "learning_rate": 0.0001698345995143705,
        "gradient_norm": 0.391149640083313,
        "train_loss": 3.0276589393615723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21507,
        "tokens": 11275862016,
        "learning_rate": 0.00016981153909798987,
        "gradient_norm": 0.46599218249320984,
        "train_loss": 3.084620475769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21508,
        "tokens": 11276386304,
        "learning_rate": 0.00016978848048473,
        "gradient_norm": 0.3963313400745392,
        "train_loss": 3.087693929672241,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21509,
        "tokens": 11276910592,
        "learning_rate": 0.00016976542367485052,
        "gradient_norm": 0.43179693818092346,
        "train_loss": 3.0564687252044678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21510,
        "tokens": 11277434880,
        "learning_rate": 0.00016974236866861087,
        "gradient_norm": 0.5408207774162292,
        "train_loss": 3.068753242492676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21511,
        "tokens": 11277959168,
        "learning_rate": 0.0001697193154662706,
        "gradient_norm": 0.4846678376197815,
        "train_loss": 3.0926971435546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21512,
        "tokens": 11278483456,
        "learning_rate": 0.00016969626406808939,
        "gradient_norm": 0.5293641090393066,
        "train_loss": 3.076077938079834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21513,
        "tokens": 11279007744,
        "learning_rate": 0.00016967321447432641,
        "gradient_norm": 0.4548412263393402,
        "train_loss": 3.0254554748535156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21514,
        "tokens": 11279532032,
        "learning_rate": 0.00016965016668524132,
        "gradient_norm": 0.4585815966129303,
        "train_loss": 3.1153383255004883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21515,
        "tokens": 11280056320,
        "learning_rate": 0.00016962712070109343,
        "gradient_norm": 0.4522111713886261,
        "train_loss": 3.036895513534546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21516,
        "tokens": 11280580608,
        "learning_rate": 0.0001696040765221423,
        "gradient_norm": 0.42244285345077515,
        "train_loss": 3.0646276473999023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21517,
        "tokens": 11281104896,
        "learning_rate": 0.00016958103414864713,
        "gradient_norm": 0.4085593521595001,
        "train_loss": 3.0824170112609863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21518,
        "tokens": 11281629184,
        "learning_rate": 0.00016955799358086746,
        "gradient_norm": 0.4246983528137207,
        "train_loss": 3.078428268432617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21519,
        "tokens": 11282153472,
        "learning_rate": 0.0001695349548190625,
        "gradient_norm": 0.3862963616847992,
        "train_loss": 3.058683395385742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21520,
        "tokens": 11282677760,
        "learning_rate": 0.00016951191786349166,
        "gradient_norm": 0.40775248408317566,
        "train_loss": 2.997816562652588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21521,
        "tokens": 11283202048,
        "learning_rate": 0.00016948888271441434,
        "gradient_norm": 0.42813852429389954,
        "train_loss": 3.0824756622314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21522,
        "tokens": 11283726336,
        "learning_rate": 0.00016946584937208958,
        "gradient_norm": 0.350135862827301,
        "train_loss": 3.025784492492676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21523,
        "tokens": 11284250624,
        "learning_rate": 0.00016944281783677693,
        "gradient_norm": 0.40432068705558777,
        "train_loss": 3.0641367435455322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21524,
        "tokens": 11284774912,
        "learning_rate": 0.00016941978810873542,
        "gradient_norm": 0.33622434735298157,
        "train_loss": 2.9973878860473633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21525,
        "tokens": 11285299200,
        "learning_rate": 0.00016939676018822442,
        "gradient_norm": 0.3842313587665558,
        "train_loss": 3.0531177520751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21526,
        "tokens": 11285823488,
        "learning_rate": 0.00016937373407550303,
        "gradient_norm": 0.37278497219085693,
        "train_loss": 3.001817226409912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21527,
        "tokens": 11286347776,
        "learning_rate": 0.0001693507097708305,
        "gradient_norm": 0.40289896726608276,
        "train_loss": 3.102670669555664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21528,
        "tokens": 11286872064,
        "learning_rate": 0.000169327687274466,
        "gradient_norm": 0.42915278673171997,
        "train_loss": 3.0504150390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21529,
        "tokens": 11287396352,
        "learning_rate": 0.00016930466658666868,
        "gradient_norm": 0.3929324448108673,
        "train_loss": 3.086829900741577,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21530,
        "tokens": 11287920640,
        "learning_rate": 0.0001692816477076976,
        "gradient_norm": 0.395094096660614,
        "train_loss": 3.054889440536499,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21531,
        "tokens": 11288444928,
        "learning_rate": 0.0001692586306378119,
        "gradient_norm": 0.3566579818725586,
        "train_loss": 3.044593572616577,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21532,
        "tokens": 11288969216,
        "learning_rate": 0.00016923561537727076,
        "gradient_norm": 0.4207685887813568,
        "train_loss": 3.0677618980407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21533,
        "tokens": 11289493504,
        "learning_rate": 0.00016921260192633307,
        "gradient_norm": 0.38152241706848145,
        "train_loss": 3.0176784992218018,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21534,
        "tokens": 11290017792,
        "learning_rate": 0.0001691895902852581,
        "gradient_norm": 0.3747704327106476,
        "train_loss": 3.0849671363830566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21535,
        "tokens": 11290542080,
        "learning_rate": 0.00016916658045430466,
        "gradient_norm": 0.43208184838294983,
        "train_loss": 3.0072431564331055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21536,
        "tokens": 11291066368,
        "learning_rate": 0.0001691435724337319,
        "gradient_norm": 0.4245290458202362,
        "train_loss": 3.0519790649414062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21537,
        "tokens": 11291590656,
        "learning_rate": 0.00016912056622379865,
        "gradient_norm": 0.504570722579956,
        "train_loss": 3.036170482635498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21538,
        "tokens": 11292114944,
        "learning_rate": 0.0001690975618247641,
        "gradient_norm": 0.3803691267967224,
        "train_loss": 3.058445692062378,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21539,
        "tokens": 11292639232,
        "learning_rate": 0.0001690745592368869,
        "gradient_norm": 0.4551418125629425,
        "train_loss": 3.0014748573303223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21540,
        "tokens": 11293163520,
        "learning_rate": 0.0001690515584604262,
        "gradient_norm": 0.40093082189559937,
        "train_loss": 3.059154748916626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21541,
        "tokens": 11293687808,
        "learning_rate": 0.0001690285594956409,
        "gradient_norm": 0.3731820583343506,
        "train_loss": 3.072768211364746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21542,
        "tokens": 11294212096,
        "learning_rate": 0.00016900556234278975,
        "gradient_norm": 0.4375956356525421,
        "train_loss": 2.9966559410095215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21543,
        "tokens": 11294736384,
        "learning_rate": 0.00016898256700213175,
        "gradient_norm": 0.397386759519577,
        "train_loss": 3.0637292861938477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21544,
        "tokens": 11295260672,
        "learning_rate": 0.0001689595734739256,
        "gradient_norm": 0.4096052050590515,
        "train_loss": 3.085516929626465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21545,
        "tokens": 11295784960,
        "learning_rate": 0.00016893658175843028,
        "gradient_norm": 0.3643052279949188,
        "train_loss": 3.10443377494812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21546,
        "tokens": 11296309248,
        "learning_rate": 0.00016891359185590437,
        "gradient_norm": 0.44511279463768005,
        "train_loss": 3.011049270629883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21547,
        "tokens": 11296833536,
        "learning_rate": 0.0001688906037666069,
        "gradient_norm": 0.41150426864624023,
        "train_loss": 3.021451950073242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21548,
        "tokens": 11297357824,
        "learning_rate": 0.00016886761749079646,
        "gradient_norm": 0.4254743158817291,
        "train_loss": 3.075439453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21549,
        "tokens": 11297882112,
        "learning_rate": 0.0001688446330287319,
        "gradient_norm": 0.39704179763793945,
        "train_loss": 3.0041799545288086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21550,
        "tokens": 11298406400,
        "learning_rate": 0.00016882165038067178,
        "gradient_norm": 0.4221687316894531,
        "train_loss": 3.077544689178467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21551,
        "tokens": 11298930688,
        "learning_rate": 0.00016879866954687498,
        "gradient_norm": 0.4285266697406769,
        "train_loss": 3.0806760787963867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21552,
        "tokens": 11299454976,
        "learning_rate": 0.00016877569052760005,
        "gradient_norm": 0.41183266043663025,
        "train_loss": 3.0967049598693848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21553,
        "tokens": 11299979264,
        "learning_rate": 0.00016875271332310576,
        "gradient_norm": 0.42368245124816895,
        "train_loss": 3.0146427154541016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21554,
        "tokens": 11300503552,
        "learning_rate": 0.0001687297379336506,
        "gradient_norm": 0.4193154275417328,
        "train_loss": 3.0540051460266113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21555,
        "tokens": 11301027840,
        "learning_rate": 0.00016870676435949336,
        "gradient_norm": 0.40066951513290405,
        "train_loss": 3.043546199798584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21556,
        "tokens": 11301552128,
        "learning_rate": 0.00016868379260089243,
        "gradient_norm": 0.43777793645858765,
        "train_loss": 3.0976972579956055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21557,
        "tokens": 11302076416,
        "learning_rate": 0.00016866082265810662,
        "gradient_norm": 0.4572378098964691,
        "train_loss": 3.0411376953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21558,
        "tokens": 11302600704,
        "learning_rate": 0.00016863785453139426,
        "gradient_norm": 0.4440556764602661,
        "train_loss": 3.129181385040283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21559,
        "tokens": 11303124992,
        "learning_rate": 0.00016861488822101408,
        "gradient_norm": 0.3976992666721344,
        "train_loss": 3.004807949066162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21560,
        "tokens": 11303649280,
        "learning_rate": 0.0001685919237272244,
        "gradient_norm": 0.3716461956501007,
        "train_loss": 2.988583564758301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21561,
        "tokens": 11304173568,
        "learning_rate": 0.00016856896105028394,
        "gradient_norm": 0.39677906036376953,
        "train_loss": 2.9873228073120117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21562,
        "tokens": 11304697856,
        "learning_rate": 0.00016854600019045095,
        "gradient_norm": 0.35493651032447815,
        "train_loss": 3.007380485534668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21563,
        "tokens": 11305222144,
        "learning_rate": 0.0001685230411479841,
        "gradient_norm": 0.4032945930957794,
        "train_loss": 2.9785871505737305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21564,
        "tokens": 11305746432,
        "learning_rate": 0.00016850008392314155,
        "gradient_norm": 0.46044549345970154,
        "train_loss": 3.0880703926086426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21565,
        "tokens": 11306270720,
        "learning_rate": 0.000168477128516182,
        "gradient_norm": 0.44185468554496765,
        "train_loss": 3.0430002212524414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21566,
        "tokens": 11306795008,
        "learning_rate": 0.00016845417492736365,
        "gradient_norm": 0.3835698366165161,
        "train_loss": 3.0390167236328125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21567,
        "tokens": 11307319296,
        "learning_rate": 0.000168431223156945,
        "gradient_norm": 0.47189223766326904,
        "train_loss": 3.0183334350585938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21568,
        "tokens": 11307843584,
        "learning_rate": 0.00016840827320518427,
        "gradient_norm": 0.37342628836631775,
        "train_loss": 3.0167958736419678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21569,
        "tokens": 11308367872,
        "learning_rate": 0.0001683853250723398,
        "gradient_norm": 0.41780564188957214,
        "train_loss": 3.051570415496826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21570,
        "tokens": 11308892160,
        "learning_rate": 0.00016836237875867007,
        "gradient_norm": 0.40277373790740967,
        "train_loss": 3.006725788116455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21571,
        "tokens": 11309416448,
        "learning_rate": 0.00016833943426443316,
        "gradient_norm": 0.3878272771835327,
        "train_loss": 3.0692458152770996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21572,
        "tokens": 11309940736,
        "learning_rate": 0.00016831649158988754,
        "gradient_norm": 0.4055306315422058,
        "train_loss": 3.061023235321045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21573,
        "tokens": 11310465024,
        "learning_rate": 0.00016829355073529122,
        "gradient_norm": 0.37620124220848083,
        "train_loss": 3.0750646591186523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21574,
        "tokens": 11310989312,
        "learning_rate": 0.0001682706117009027,
        "gradient_norm": 0.4396827220916748,
        "train_loss": 3.0029070377349854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21575,
        "tokens": 11311513600,
        "learning_rate": 0.00016824767448697992,
        "gradient_norm": 0.39293399453163147,
        "train_loss": 3.0265910625457764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21576,
        "tokens": 11312037888,
        "learning_rate": 0.00016822473909378132,
        "gradient_norm": 0.3942641019821167,
        "train_loss": 3.063528060913086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21577,
        "tokens": 11312562176,
        "learning_rate": 0.0001682018055215648,
        "gradient_norm": 0.400178998708725,
        "train_loss": 3.030228614807129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21578,
        "tokens": 11313086464,
        "learning_rate": 0.00016817887377058876,
        "gradient_norm": 0.9715730547904968,
        "train_loss": 2.6816561222076416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21579,
        "tokens": 11313610752,
        "learning_rate": 0.00016815594384111113,
        "gradient_norm": 0.496237188577652,
        "train_loss": 3.0909957885742188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21580,
        "tokens": 11314135040,
        "learning_rate": 0.00016813301573339012,
        "gradient_norm": 0.452531635761261,
        "train_loss": 3.0179734230041504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21581,
        "tokens": 11314659328,
        "learning_rate": 0.0001681100894476838,
        "gradient_norm": 0.45138442516326904,
        "train_loss": 2.9866175651550293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21582,
        "tokens": 11315183616,
        "learning_rate": 0.0001680871649842502,
        "gradient_norm": 0.452665239572525,
        "train_loss": 3.051180839538574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21583,
        "tokens": 11315707904,
        "learning_rate": 0.00016806424234334748,
        "gradient_norm": 0.4712250232696533,
        "train_loss": 3.049947738647461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21584,
        "tokens": 11316232192,
        "learning_rate": 0.00016804132152523345,
        "gradient_norm": 0.3848686218261719,
        "train_loss": 3.119750738143921,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21585,
        "tokens": 11316756480,
        "learning_rate": 0.00016801840253016635,
        "gradient_norm": 0.4589877128601074,
        "train_loss": 3.066399097442627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21586,
        "tokens": 11317280768,
        "learning_rate": 0.0001679954853584039,
        "gradient_norm": 0.4175674021244049,
        "train_loss": 3.020723581314087,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21587,
        "tokens": 11317805056,
        "learning_rate": 0.00016797257001020436,
        "gradient_norm": 0.39935213327407837,
        "train_loss": 3.048029899597168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21588,
        "tokens": 11318329344,
        "learning_rate": 0.0001679496564858254,
        "gradient_norm": 0.46240368485450745,
        "train_loss": 3.043027400970459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21589,
        "tokens": 11318853632,
        "learning_rate": 0.00016792674478552515,
        "gradient_norm": 0.3839966058731079,
        "train_loss": 3.021420955657959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21590,
        "tokens": 11319377920,
        "learning_rate": 0.0001679038349095613,
        "gradient_norm": 0.4504922032356262,
        "train_loss": 3.0539541244506836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21591,
        "tokens": 11319902208,
        "learning_rate": 0.0001678809268581919,
        "gradient_norm": 0.48409244418144226,
        "train_loss": 3.0498602390289307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21592,
        "tokens": 11320426496,
        "learning_rate": 0.0001678580206316748,
        "gradient_norm": 0.4142068326473236,
        "train_loss": 3.036302089691162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21593,
        "tokens": 11320950784,
        "learning_rate": 0.00016783511623026776,
        "gradient_norm": 0.46329382061958313,
        "train_loss": 3.1310372352600098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21594,
        "tokens": 11321475072,
        "learning_rate": 0.00016781221365422865,
        "gradient_norm": 0.3835311233997345,
        "train_loss": 3.0662763118743896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21595,
        "tokens": 11321999360,
        "learning_rate": 0.0001677893129038152,
        "gradient_norm": 0.4042283296585083,
        "train_loss": 3.032681941986084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21596,
        "tokens": 11322523648,
        "learning_rate": 0.00016776641397928533,
        "gradient_norm": 0.4001663029193878,
        "train_loss": 3.009152889251709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21597,
        "tokens": 11323047936,
        "learning_rate": 0.00016774351688089657,
        "gradient_norm": 0.42449310421943665,
        "train_loss": 3.0966391563415527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21598,
        "tokens": 11323572224,
        "learning_rate": 0.00016772062160890693,
        "gradient_norm": 0.44947656989097595,
        "train_loss": 3.082810878753662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21599,
        "tokens": 11324096512,
        "learning_rate": 0.00016769772816357386,
        "gradient_norm": 0.4126248061656952,
        "train_loss": 3.0274500846862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21600,
        "tokens": 11324620800,
        "learning_rate": 0.00016767483654515518,
        "gradient_norm": 0.4191420078277588,
        "train_loss": 3.073922872543335,
        "val_loss": 3.008974075317383,
        "hellaswag_acc": 0.28311091661453247,
        "hellaswag_acc_norm": 0.2927703559398651
    },
    {
        "step": 21601,
        "tokens": 11325145088,
        "learning_rate": 0.00016765194675390864,
        "gradient_norm": 0.420869380235672,
        "train_loss": 3.0426363945007324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21602,
        "tokens": 11325669376,
        "learning_rate": 0.0001676290587900917,
        "gradient_norm": 0.3950904905796051,
        "train_loss": 3.0298478603363037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21603,
        "tokens": 11326193664,
        "learning_rate": 0.00016760617265396222,
        "gradient_norm": 0.38375189900398254,
        "train_loss": 3.06782603263855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21604,
        "tokens": 11326717952,
        "learning_rate": 0.0001675832883457776,
        "gradient_norm": 0.39167219400405884,
        "train_loss": 3.0500717163085938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21605,
        "tokens": 11327242240,
        "learning_rate": 0.00016756040586579564,
        "gradient_norm": 0.4048757255077362,
        "train_loss": 3.0080459117889404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21606,
        "tokens": 11327766528,
        "learning_rate": 0.00016753752521427368,
        "gradient_norm": 0.37651991844177246,
        "train_loss": 3.0229804515838623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21607,
        "tokens": 11328290816,
        "learning_rate": 0.0001675146463914695,
        "gradient_norm": 0.35282957553863525,
        "train_loss": 3.0292177200317383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21608,
        "tokens": 11328815104,
        "learning_rate": 0.0001674917693976404,
        "gradient_norm": 0.43891486525535583,
        "train_loss": 3.0430307388305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21609,
        "tokens": 11329339392,
        "learning_rate": 0.00016746889423304413,
        "gradient_norm": 0.38002264499664307,
        "train_loss": 3.094442367553711,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21610,
        "tokens": 11329863680,
        "learning_rate": 0.00016744602089793794,
        "gradient_norm": 0.4905734658241272,
        "train_loss": 3.060877561569214,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21611,
        "tokens": 11330387968,
        "learning_rate": 0.00016742314939257943,
        "gradient_norm": 0.40620797872543335,
        "train_loss": 3.0430188179016113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21612,
        "tokens": 11330912256,
        "learning_rate": 0.0001674002797172261,
        "gradient_norm": 0.44893819093704224,
        "train_loss": 3.0291059017181396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21613,
        "tokens": 11331436544,
        "learning_rate": 0.00016737741187213527,
        "gradient_norm": 0.4383930265903473,
        "train_loss": 3.0763497352600098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21614,
        "tokens": 11331960832,
        "learning_rate": 0.00016735454585756443,
        "gradient_norm": 0.41336995363235474,
        "train_loss": 3.071920394897461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21615,
        "tokens": 11332485120,
        "learning_rate": 0.00016733168167377082,
        "gradient_norm": 0.4039892852306366,
        "train_loss": 3.0192723274230957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21616,
        "tokens": 11333009408,
        "learning_rate": 0.00016730881932101201,
        "gradient_norm": 0.4160146713256836,
        "train_loss": 3.0690770149230957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21617,
        "tokens": 11333533696,
        "learning_rate": 0.00016728595879954517,
        "gradient_norm": 0.34400179982185364,
        "train_loss": 3.044607162475586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21618,
        "tokens": 11334057984,
        "learning_rate": 0.00016726310010962774,
        "gradient_norm": 0.4117411673069,
        "train_loss": 3.0454752445220947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21619,
        "tokens": 11334582272,
        "learning_rate": 0.0001672402432515169,
        "gradient_norm": 0.35238346457481384,
        "train_loss": 3.0795130729675293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21620,
        "tokens": 11335106560,
        "learning_rate": 0.00016721738822547002,
        "gradient_norm": 0.349590539932251,
        "train_loss": 3.096268892288208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21621,
        "tokens": 11335630848,
        "learning_rate": 0.00016719453503174443,
        "gradient_norm": 0.3879016637802124,
        "train_loss": 3.0179929733276367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21622,
        "tokens": 11336155136,
        "learning_rate": 0.0001671716836705972,
        "gradient_norm": 0.36896318197250366,
        "train_loss": 3.081240653991699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21623,
        "tokens": 11336679424,
        "learning_rate": 0.00016714883414228575,
        "gradient_norm": 0.38098791241645813,
        "train_loss": 3.114961624145508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21624,
        "tokens": 11337203712,
        "learning_rate": 0.00016712598644706705,
        "gradient_norm": 0.3779260516166687,
        "train_loss": 3.0397441387176514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21625,
        "tokens": 11337728000,
        "learning_rate": 0.00016710314058519853,
        "gradient_norm": 0.403552770614624,
        "train_loss": 3.033052921295166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21626,
        "tokens": 11338252288,
        "learning_rate": 0.00016708029655693708,
        "gradient_norm": 0.34221529960632324,
        "train_loss": 3.0935559272766113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21627,
        "tokens": 11338776576,
        "learning_rate": 0.00016705745436254007,
        "gradient_norm": 0.43574604392051697,
        "train_loss": 3.070354461669922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21628,
        "tokens": 11339300864,
        "learning_rate": 0.0001670346140022645,
        "gradient_norm": 0.39055898785591125,
        "train_loss": 3.0478296279907227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21629,
        "tokens": 11339825152,
        "learning_rate": 0.00016701177547636753,
        "gradient_norm": 0.41291165351867676,
        "train_loss": 3.0878138542175293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21630,
        "tokens": 11340349440,
        "learning_rate": 0.0001669889387851061,
        "gradient_norm": 0.35322973132133484,
        "train_loss": 2.9740753173828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21631,
        "tokens": 11340873728,
        "learning_rate": 0.00016696610392873736,
        "gradient_norm": 0.42212390899658203,
        "train_loss": 3.042015552520752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21632,
        "tokens": 11341398016,
        "learning_rate": 0.00016694327090751847,
        "gradient_norm": 0.38852959871292114,
        "train_loss": 3.024442672729492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21633,
        "tokens": 11341922304,
        "learning_rate": 0.0001669204397217062,
        "gradient_norm": 0.38577619194984436,
        "train_loss": 3.0651721954345703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21634,
        "tokens": 11342446592,
        "learning_rate": 0.0001668976103715578,
        "gradient_norm": 0.38378819823265076,
        "train_loss": 3.0455801486968994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21635,
        "tokens": 11342970880,
        "learning_rate": 0.00016687478285732998,
        "gradient_norm": 0.375901460647583,
        "train_loss": 3.049929618835449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21636,
        "tokens": 11343495168,
        "learning_rate": 0.00016685195717927988,
        "gradient_norm": 0.36072608828544617,
        "train_loss": 3.029963731765747,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21637,
        "tokens": 11344019456,
        "learning_rate": 0.00016682913333766433,
        "gradient_norm": 0.3860056698322296,
        "train_loss": 3.0365376472473145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21638,
        "tokens": 11344543744,
        "learning_rate": 0.00016680631133274038,
        "gradient_norm": 0.37381309270858765,
        "train_loss": 3.109025478363037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21639,
        "tokens": 11345068032,
        "learning_rate": 0.00016678349116476472,
        "gradient_norm": 0.37210899591445923,
        "train_loss": 3.0051941871643066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21640,
        "tokens": 11345592320,
        "learning_rate": 0.00016676067283399429,
        "gradient_norm": 0.3647271394729614,
        "train_loss": 3.008493661880493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21641,
        "tokens": 11346116608,
        "learning_rate": 0.0001667378563406861,
        "gradient_norm": 0.4371289014816284,
        "train_loss": 3.0602498054504395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21642,
        "tokens": 11346640896,
        "learning_rate": 0.00016671504168509673,
        "gradient_norm": 0.38177353143692017,
        "train_loss": 3.020214080810547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21643,
        "tokens": 11347165184,
        "learning_rate": 0.0001666922288674832,
        "gradient_norm": 0.4000598192214966,
        "train_loss": 3.0807268619537354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21644,
        "tokens": 11347689472,
        "learning_rate": 0.00016666941788810215,
        "gradient_norm": 0.35749945044517517,
        "train_loss": 3.1005215644836426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21645,
        "tokens": 11348213760,
        "learning_rate": 0.00016664660874721047,
        "gradient_norm": 0.38324734568595886,
        "train_loss": 3.046069383621216,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21646,
        "tokens": 11348738048,
        "learning_rate": 0.0001666238014450647,
        "gradient_norm": 0.3739352524280548,
        "train_loss": 3.03468656539917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21647,
        "tokens": 11349262336,
        "learning_rate": 0.00016660099598192184,
        "gradient_norm": 0.4282579720020294,
        "train_loss": 3.0997536182403564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21648,
        "tokens": 11349786624,
        "learning_rate": 0.00016657819235803837,
        "gradient_norm": 0.3793319761753082,
        "train_loss": 3.057649612426758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21649,
        "tokens": 11350310912,
        "learning_rate": 0.0001665553905736711,
        "gradient_norm": 0.4062696099281311,
        "train_loss": 3.03292179107666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21650,
        "tokens": 11350835200,
        "learning_rate": 0.00016653259062907657,
        "gradient_norm": 0.370888888835907,
        "train_loss": 3.014270305633545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21651,
        "tokens": 11351359488,
        "learning_rate": 0.00016650979252451153,
        "gradient_norm": 0.3577648401260376,
        "train_loss": 3.028775691986084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21652,
        "tokens": 11351883776,
        "learning_rate": 0.00016648699626023263,
        "gradient_norm": 0.4358642101287842,
        "train_loss": 3.035618782043457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21653,
        "tokens": 11352408064,
        "learning_rate": 0.00016646420183649634,
        "gradient_norm": 0.38935622572898865,
        "train_loss": 3.0737009048461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21654,
        "tokens": 11352932352,
        "learning_rate": 0.0001664414092535594,
        "gradient_norm": 0.393824964761734,
        "train_loss": 3.1214685440063477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21655,
        "tokens": 11353456640,
        "learning_rate": 0.00016641861851167817,
        "gradient_norm": 0.419969379901886,
        "train_loss": 3.0687508583068848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21656,
        "tokens": 11353980928,
        "learning_rate": 0.0001663958296111094,
        "gradient_norm": 0.3764669597148895,
        "train_loss": 3.060436487197876,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21657,
        "tokens": 11354505216,
        "learning_rate": 0.00016637304255210942,
        "gradient_norm": 0.4149545133113861,
        "train_loss": 3.054982900619507,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21658,
        "tokens": 11355029504,
        "learning_rate": 0.0001663502573349349,
        "gradient_norm": 0.3581655025482178,
        "train_loss": 3.116626262664795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21659,
        "tokens": 11355553792,
        "learning_rate": 0.0001663274739598421,
        "gradient_norm": 0.41577568650245667,
        "train_loss": 3.0591859817504883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21660,
        "tokens": 11356078080,
        "learning_rate": 0.00016630469242708777,
        "gradient_norm": 0.38183459639549255,
        "train_loss": 3.0909860134124756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21661,
        "tokens": 11356602368,
        "learning_rate": 0.00016628191273692803,
        "gradient_norm": 0.4183807373046875,
        "train_loss": 3.0193612575531006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21662,
        "tokens": 11357126656,
        "learning_rate": 0.00016625913488961958,
        "gradient_norm": 0.40246981382369995,
        "train_loss": 3.1156156063079834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21663,
        "tokens": 11357650944,
        "learning_rate": 0.00016623635888541853,
        "gradient_norm": 0.3782324492931366,
        "train_loss": 3.028068780899048,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21664,
        "tokens": 11358175232,
        "learning_rate": 0.00016621358472458154,
        "gradient_norm": 0.38178005814552307,
        "train_loss": 3.117158889770508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21665,
        "tokens": 11358699520,
        "learning_rate": 0.0001661908124073647,
        "gradient_norm": 0.4225168526172638,
        "train_loss": 3.0862832069396973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21666,
        "tokens": 11359223808,
        "learning_rate": 0.00016616804193402454,
        "gradient_norm": 0.3786938190460205,
        "train_loss": 3.0990889072418213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21667,
        "tokens": 11359748096,
        "learning_rate": 0.00016614527330481723,
        "gradient_norm": 0.39671340584754944,
        "train_loss": 3.062551498413086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21668,
        "tokens": 11360272384,
        "learning_rate": 0.0001661225065199992,
        "gradient_norm": 0.3685959279537201,
        "train_loss": 3.0528364181518555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21669,
        "tokens": 11360796672,
        "learning_rate": 0.00016609974157982653,
        "gradient_norm": 0.35154131054878235,
        "train_loss": 3.042968273162842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21670,
        "tokens": 11361320960,
        "learning_rate": 0.00016607697848455567,
        "gradient_norm": 0.36434587836265564,
        "train_loss": 3.0732603073120117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21671,
        "tokens": 11361845248,
        "learning_rate": 0.00016605421723444268,
        "gradient_norm": 0.36512064933776855,
        "train_loss": 3.0494494438171387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21672,
        "tokens": 11362369536,
        "learning_rate": 0.00016603145782974392,
        "gradient_norm": 0.37929126620292664,
        "train_loss": 3.0228004455566406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21673,
        "tokens": 11362893824,
        "learning_rate": 0.00016600870027071537,
        "gradient_norm": 0.4072335958480835,
        "train_loss": 3.046710729598999,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21674,
        "tokens": 11363418112,
        "learning_rate": 0.00016598594455761347,
        "gradient_norm": 0.3433949947357178,
        "train_loss": 3.0545542240142822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21675,
        "tokens": 11363942400,
        "learning_rate": 0.00016596319069069407,
        "gradient_norm": 0.37549784779548645,
        "train_loss": 3.0328621864318848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21676,
        "tokens": 11364466688,
        "learning_rate": 0.00016594043867021354,
        "gradient_norm": 0.3652230501174927,
        "train_loss": 3.114607334136963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21677,
        "tokens": 11364990976,
        "learning_rate": 0.0001659176884964278,
        "gradient_norm": 0.41745731234550476,
        "train_loss": 3.062746286392212,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21678,
        "tokens": 11365515264,
        "learning_rate": 0.0001658949401695931,
        "gradient_norm": 0.4813065528869629,
        "train_loss": 3.236978054046631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21679,
        "tokens": 11366039552,
        "learning_rate": 0.0001658721936899653,
        "gradient_norm": 0.4996238648891449,
        "train_loss": 3.071660280227661,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21680,
        "tokens": 11366563840,
        "learning_rate": 0.00016584944905780058,
        "gradient_norm": 0.49005746841430664,
        "train_loss": 3.0308852195739746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21681,
        "tokens": 11367088128,
        "learning_rate": 0.000165826706273355,
        "gradient_norm": 0.5625983476638794,
        "train_loss": 3.052652359008789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21682,
        "tokens": 11367612416,
        "learning_rate": 0.00016580396533688444,
        "gradient_norm": 0.42174118757247925,
        "train_loss": 3.074801445007324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21683,
        "tokens": 11368136704,
        "learning_rate": 0.00016578122624864497,
        "gradient_norm": 0.47757911682128906,
        "train_loss": 3.0579183101654053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21684,
        "tokens": 11368660992,
        "learning_rate": 0.00016575848900889241,
        "gradient_norm": 0.47362953424453735,
        "train_loss": 3.0508384704589844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21685,
        "tokens": 11369185280,
        "learning_rate": 0.0001657357536178829,
        "gradient_norm": 0.41436612606048584,
        "train_loss": 3.038578987121582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21686,
        "tokens": 11369709568,
        "learning_rate": 0.00016571302007587215,
        "gradient_norm": 0.39641517400741577,
        "train_loss": 3.08065128326416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21687,
        "tokens": 11370233856,
        "learning_rate": 0.00016569028838311626,
        "gradient_norm": 0.43053486943244934,
        "train_loss": 3.06084942817688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21688,
        "tokens": 11370758144,
        "learning_rate": 0.00016566755853987086,
        "gradient_norm": 0.43420863151550293,
        "train_loss": 3.1710522174835205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21689,
        "tokens": 11371282432,
        "learning_rate": 0.00016564483054639205,
        "gradient_norm": 0.47399890422821045,
        "train_loss": 3.0744614601135254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21690,
        "tokens": 11371806720,
        "learning_rate": 0.00016562210440293544,
        "gradient_norm": 0.41605260968208313,
        "train_loss": 3.0307116508483887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21691,
        "tokens": 11372331008,
        "learning_rate": 0.00016559938010975695,
        "gradient_norm": 0.4272424876689911,
        "train_loss": 3.0367116928100586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21692,
        "tokens": 11372855296,
        "learning_rate": 0.00016557665766711246,
        "gradient_norm": 0.43996718525886536,
        "train_loss": 3.0807933807373047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21693,
        "tokens": 11373379584,
        "learning_rate": 0.0001655539370752576,
        "gradient_norm": 0.48244526982307434,
        "train_loss": 3.0413384437561035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21694,
        "tokens": 11373903872,
        "learning_rate": 0.0001655312183344482,
        "gradient_norm": 0.4209945499897003,
        "train_loss": 3.040076732635498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21695,
        "tokens": 11374428160,
        "learning_rate": 0.00016550850144493985,
        "gradient_norm": 0.4100865125656128,
        "train_loss": 3.017374038696289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21696,
        "tokens": 11374952448,
        "learning_rate": 0.0001654857864069885,
        "gradient_norm": 0.4471118748188019,
        "train_loss": 3.0220022201538086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21697,
        "tokens": 11375476736,
        "learning_rate": 0.00016546307322084957,
        "gradient_norm": 0.39101845026016235,
        "train_loss": 3.0679259300231934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21698,
        "tokens": 11376001024,
        "learning_rate": 0.000165440361886779,
        "gradient_norm": 0.4662650525569916,
        "train_loss": 3.0174667835235596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21699,
        "tokens": 11376525312,
        "learning_rate": 0.00016541765240503213,
        "gradient_norm": 0.41439613699913025,
        "train_loss": 3.042497158050537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21700,
        "tokens": 11377049600,
        "learning_rate": 0.00016539494477586477,
        "gradient_norm": 0.45367103815078735,
        "train_loss": 3.003267288208008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21701,
        "tokens": 11377573888,
        "learning_rate": 0.00016537223899953257,
        "gradient_norm": 0.40140607953071594,
        "train_loss": 3.0508596897125244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21702,
        "tokens": 11378098176,
        "learning_rate": 0.00016534953507629094,
        "gradient_norm": 0.3815266489982605,
        "train_loss": 3.0497007369995117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21703,
        "tokens": 11378622464,
        "learning_rate": 0.00016532683300639561,
        "gradient_norm": 0.39331337809562683,
        "train_loss": 3.0143344402313232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21704,
        "tokens": 11379146752,
        "learning_rate": 0.000165304132790102,
        "gradient_norm": 0.3864176571369171,
        "train_loss": 2.987842559814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21705,
        "tokens": 11379671040,
        "learning_rate": 0.00016528143442766575,
        "gradient_norm": 0.3918011784553528,
        "train_loss": 3.0622661113739014,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21706,
        "tokens": 11380195328,
        "learning_rate": 0.00016525873791934216,
        "gradient_norm": 0.3973669409751892,
        "train_loss": 3.0282950401306152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21707,
        "tokens": 11380719616,
        "learning_rate": 0.000165236043265387,
        "gradient_norm": 0.3541681468486786,
        "train_loss": 3.0154354572296143,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21708,
        "tokens": 11381243904,
        "learning_rate": 0.00016521335046605537,
        "gradient_norm": 0.3878295421600342,
        "train_loss": 3.0863163471221924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21709,
        "tokens": 11381768192,
        "learning_rate": 0.00016519065952160298,
        "gradient_norm": 0.3588397800922394,
        "train_loss": 3.030916213989258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21710,
        "tokens": 11382292480,
        "learning_rate": 0.00016516797043228517,
        "gradient_norm": 0.42129942774772644,
        "train_loss": 3.053483724594116,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21711,
        "tokens": 11382816768,
        "learning_rate": 0.00016514528319835724,
        "gradient_norm": 0.360873281955719,
        "train_loss": 3.020277261734009,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21712,
        "tokens": 11383341056,
        "learning_rate": 0.00016512259782007477,
        "gradient_norm": 0.3677470088005066,
        "train_loss": 3.037841558456421,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21713,
        "tokens": 11383865344,
        "learning_rate": 0.00016509991429769288,
        "gradient_norm": 0.35777637362480164,
        "train_loss": 3.0480093955993652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21714,
        "tokens": 11384389632,
        "learning_rate": 0.00016507723263146714,
        "gradient_norm": 0.36732447147369385,
        "train_loss": 3.075201988220215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21715,
        "tokens": 11384913920,
        "learning_rate": 0.0001650545528216526,
        "gradient_norm": 0.3825334310531616,
        "train_loss": 3.058720111846924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21716,
        "tokens": 11385438208,
        "learning_rate": 0.00016503187486850473,
        "gradient_norm": 0.35574740171432495,
        "train_loss": 3.0074117183685303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21717,
        "tokens": 11385962496,
        "learning_rate": 0.00016500919877227873,
        "gradient_norm": 0.3599775731563568,
        "train_loss": 3.0362513065338135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21718,
        "tokens": 11386486784,
        "learning_rate": 0.0001649865245332299,
        "gradient_norm": 0.41139084100723267,
        "train_loss": 3.001889944076538,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21719,
        "tokens": 11387011072,
        "learning_rate": 0.00016496385215161336,
        "gradient_norm": 0.38251397013664246,
        "train_loss": 3.061244010925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21720,
        "tokens": 11387535360,
        "learning_rate": 0.0001649411816276844,
        "gradient_norm": 0.3449161946773529,
        "train_loss": 2.9946393966674805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21721,
        "tokens": 11388059648,
        "learning_rate": 0.00016491851296169825,
        "gradient_norm": 0.4468408226966858,
        "train_loss": 3.112239122390747,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21722,
        "tokens": 11388583936,
        "learning_rate": 0.00016489584615390996,
        "gradient_norm": 0.44169071316719055,
        "train_loss": 3.040374279022217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21723,
        "tokens": 11389108224,
        "learning_rate": 0.0001648731812045748,
        "gradient_norm": 0.4087296724319458,
        "train_loss": 3.108346700668335,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21724,
        "tokens": 11389632512,
        "learning_rate": 0.00016485051811394776,
        "gradient_norm": 0.4138789176940918,
        "train_loss": 2.9792957305908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21725,
        "tokens": 11390156800,
        "learning_rate": 0.00016482785688228405,
        "gradient_norm": 0.4544908404350281,
        "train_loss": 3.0903496742248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21726,
        "tokens": 11390681088,
        "learning_rate": 0.00016480519750983864,
        "gradient_norm": 0.4175218939781189,
        "train_loss": 3.087531089782715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21727,
        "tokens": 11391205376,
        "learning_rate": 0.00016478253999686676,
        "gradient_norm": 0.4424006938934326,
        "train_loss": 3.023655414581299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21728,
        "tokens": 11391729664,
        "learning_rate": 0.0001647598843436232,
        "gradient_norm": 0.4113387167453766,
        "train_loss": 3.0961642265319824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21729,
        "tokens": 11392253952,
        "learning_rate": 0.00016473723055036315,
        "gradient_norm": 0.4003572165966034,
        "train_loss": 3.0430245399475098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21730,
        "tokens": 11392778240,
        "learning_rate": 0.00016471457861734164,
        "gradient_norm": 0.3975387215614319,
        "train_loss": 3.063290596008301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21731,
        "tokens": 11393302528,
        "learning_rate": 0.00016469192854481353,
        "gradient_norm": 0.3925102949142456,
        "train_loss": 3.0711288452148438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21732,
        "tokens": 11393826816,
        "learning_rate": 0.0001646692803330339,
        "gradient_norm": 0.39039716124534607,
        "train_loss": 3.0324811935424805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21733,
        "tokens": 11394351104,
        "learning_rate": 0.0001646466339822575,
        "gradient_norm": 0.4191823899745941,
        "train_loss": 3.0198605060577393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21734,
        "tokens": 11394875392,
        "learning_rate": 0.00016462398949273945,
        "gradient_norm": 0.38939616084098816,
        "train_loss": 3.0343408584594727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21735,
        "tokens": 11395399680,
        "learning_rate": 0.0001646013468647345,
        "gradient_norm": 0.39610978960990906,
        "train_loss": 2.97684383392334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21736,
        "tokens": 11395923968,
        "learning_rate": 0.00016457870609849762,
        "gradient_norm": 0.41794028878211975,
        "train_loss": 3.108349323272705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21737,
        "tokens": 11396448256,
        "learning_rate": 0.0001645560671942835,
        "gradient_norm": 0.35781747102737427,
        "train_loss": 3.0606584548950195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21738,
        "tokens": 11396972544,
        "learning_rate": 0.0001645334301523472,
        "gradient_norm": 0.42958927154541016,
        "train_loss": 3.0352580547332764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21739,
        "tokens": 11397496832,
        "learning_rate": 0.00016451079497294328,
        "gradient_norm": 0.3798247277736664,
        "train_loss": 2.9705324172973633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21740,
        "tokens": 11398021120,
        "learning_rate": 0.00016448816165632669,
        "gradient_norm": 0.39725103974342346,
        "train_loss": 3.0623934268951416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21741,
        "tokens": 11398545408,
        "learning_rate": 0.00016446553020275218,
        "gradient_norm": 0.3868379592895508,
        "train_loss": 3.0293312072753906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21742,
        "tokens": 11399069696,
        "learning_rate": 0.00016444290061247446,
        "gradient_norm": 0.3959462344646454,
        "train_loss": 3.060903549194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21743,
        "tokens": 11399593984,
        "learning_rate": 0.00016442027288574831,
        "gradient_norm": 0.41993317008018494,
        "train_loss": 3.0403478145599365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21744,
        "tokens": 11400118272,
        "learning_rate": 0.00016439764702282832,
        "gradient_norm": 0.4075997769832611,
        "train_loss": 3.005380392074585,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21745,
        "tokens": 11400642560,
        "learning_rate": 0.0001643750230239693,
        "gradient_norm": 0.3936077952384949,
        "train_loss": 3.1087703704833984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21746,
        "tokens": 11401166848,
        "learning_rate": 0.0001643524008894258,
        "gradient_norm": 0.41780856251716614,
        "train_loss": 3.106642723083496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21747,
        "tokens": 11401691136,
        "learning_rate": 0.0001643297806194526,
        "gradient_norm": 0.4821508526802063,
        "train_loss": 2.998678207397461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21748,
        "tokens": 11402215424,
        "learning_rate": 0.0001643071622143041,
        "gradient_norm": 0.4105900526046753,
        "train_loss": 3.0681676864624023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21749,
        "tokens": 11402739712,
        "learning_rate": 0.00016428454567423507,
        "gradient_norm": 0.4038519263267517,
        "train_loss": 3.0271012783050537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21750,
        "tokens": 11403264000,
        "learning_rate": 0.00016426193099950017,
        "gradient_norm": 0.4536263346672058,
        "train_loss": 3.0929157733917236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21751,
        "tokens": 11403788288,
        "learning_rate": 0.00016423931819035367,
        "gradient_norm": 0.46018022298812866,
        "train_loss": 3.033083438873291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21752,
        "tokens": 11404312576,
        "learning_rate": 0.0001642167072470504,
        "gradient_norm": 0.4234059453010559,
        "train_loss": 3.054828405380249,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21753,
        "tokens": 11404836864,
        "learning_rate": 0.00016419409816984464,
        "gradient_norm": 0.48296961188316345,
        "train_loss": 3.1080422401428223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21754,
        "tokens": 11405361152,
        "learning_rate": 0.00016417149095899108,
        "gradient_norm": 0.3874751031398773,
        "train_loss": 3.0660133361816406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21755,
        "tokens": 11405885440,
        "learning_rate": 0.00016414888561474403,
        "gradient_norm": 0.43444499373435974,
        "train_loss": 3.062830924987793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21756,
        "tokens": 11406409728,
        "learning_rate": 0.00016412628213735808,
        "gradient_norm": 0.39317500591278076,
        "train_loss": 3.0284714698791504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21757,
        "tokens": 11406934016,
        "learning_rate": 0.0001641036805270875,
        "gradient_norm": 0.41724464297294617,
        "train_loss": 3.0460634231567383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21758,
        "tokens": 11407458304,
        "learning_rate": 0.0001640810807841869,
        "gradient_norm": 0.4472138285636902,
        "train_loss": 3.05043625831604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21759,
        "tokens": 11407982592,
        "learning_rate": 0.00016405848290891047,
        "gradient_norm": 0.4217653274536133,
        "train_loss": 3.082390785217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21760,
        "tokens": 11408506880,
        "learning_rate": 0.00016403588690151272,
        "gradient_norm": 0.44043150544166565,
        "train_loss": 3.074810028076172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21761,
        "tokens": 11409031168,
        "learning_rate": 0.0001640132927622479,
        "gradient_norm": 0.4167416989803314,
        "train_loss": 3.0768373012542725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21762,
        "tokens": 11409555456,
        "learning_rate": 0.00016399070049137043,
        "gradient_norm": 0.43446600437164307,
        "train_loss": 3.0532593727111816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21763,
        "tokens": 11410079744,
        "learning_rate": 0.0001639681100891345,
        "gradient_norm": 0.3715280592441559,
        "train_loss": 3.0572421550750732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21764,
        "tokens": 11410604032,
        "learning_rate": 0.00016394552155579451,
        "gradient_norm": 0.4305291473865509,
        "train_loss": 3.0815114974975586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21765,
        "tokens": 11411128320,
        "learning_rate": 0.0001639229348916046,
        "gradient_norm": 0.3784162104129791,
        "train_loss": 3.011481285095215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21766,
        "tokens": 11411652608,
        "learning_rate": 0.00016390035009681918,
        "gradient_norm": 0.371314138174057,
        "train_loss": 3.0278494358062744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21767,
        "tokens": 11412176896,
        "learning_rate": 0.00016387776717169227,
        "gradient_norm": 0.3913944959640503,
        "train_loss": 3.0129222869873047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21768,
        "tokens": 11412701184,
        "learning_rate": 0.00016385518611647826,
        "gradient_norm": 0.42820611596107483,
        "train_loss": 3.0556862354278564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21769,
        "tokens": 11413225472,
        "learning_rate": 0.0001638326069314311,
        "gradient_norm": 0.388561874628067,
        "train_loss": 3.010636806488037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21770,
        "tokens": 11413749760,
        "learning_rate": 0.00016381002961680523,
        "gradient_norm": 0.38613301515579224,
        "train_loss": 3.086437702178955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21771,
        "tokens": 11414274048,
        "learning_rate": 0.00016378745417285453,
        "gradient_norm": 0.4153485596179962,
        "train_loss": 3.0964527130126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21772,
        "tokens": 11414798336,
        "learning_rate": 0.00016376488059983331,
        "gradient_norm": 0.390791654586792,
        "train_loss": 3.062300205230713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21773,
        "tokens": 11415322624,
        "learning_rate": 0.00016374230889799549,
        "gradient_norm": 0.41757285594940186,
        "train_loss": 3.0943760871887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21774,
        "tokens": 11415846912,
        "learning_rate": 0.00016371973906759523,
        "gradient_norm": 0.413044273853302,
        "train_loss": 2.9989702701568604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21775,
        "tokens": 11416371200,
        "learning_rate": 0.00016369717110888666,
        "gradient_norm": 0.41916656494140625,
        "train_loss": 3.0450406074523926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21776,
        "tokens": 11416895488,
        "learning_rate": 0.00016367460502212365,
        "gradient_norm": 0.3679434359073639,
        "train_loss": 3.0616183280944824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21777,
        "tokens": 11417419776,
        "learning_rate": 0.00016365204080756037,
        "gradient_norm": 0.44789689779281616,
        "train_loss": 3.1081061363220215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21778,
        "tokens": 11417944064,
        "learning_rate": 0.00016362947846545065,
        "gradient_norm": 0.3808913826942444,
        "train_loss": 3.1061885356903076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21779,
        "tokens": 11418468352,
        "learning_rate": 0.00016360691799604862,
        "gradient_norm": 0.40688732266426086,
        "train_loss": 3.0328500270843506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21780,
        "tokens": 11418992640,
        "learning_rate": 0.00016358435939960807,
        "gradient_norm": 0.4050595462322235,
        "train_loss": 2.9914960861206055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21781,
        "tokens": 11419516928,
        "learning_rate": 0.00016356180267638304,
        "gradient_norm": 0.3908684253692627,
        "train_loss": 3.0706100463867188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21782,
        "tokens": 11420041216,
        "learning_rate": 0.00016353924782662736,
        "gradient_norm": 0.35077038407325745,
        "train_loss": 3.0512142181396484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21783,
        "tokens": 11420565504,
        "learning_rate": 0.000163516694850595,
        "gradient_norm": 0.4591915011405945,
        "train_loss": 2.984966278076172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21784,
        "tokens": 11421089792,
        "learning_rate": 0.0001634941437485397,
        "gradient_norm": 0.43449845910072327,
        "train_loss": 3.055919647216797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21785,
        "tokens": 11421614080,
        "learning_rate": 0.00016347159452071542,
        "gradient_norm": 0.3964327573776245,
        "train_loss": 3.05275821685791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21786,
        "tokens": 11422138368,
        "learning_rate": 0.00016344904716737588,
        "gradient_norm": 0.39454323053359985,
        "train_loss": 3.07503080368042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21787,
        "tokens": 11422662656,
        "learning_rate": 0.00016342650168877499,
        "gradient_norm": 0.38704559206962585,
        "train_loss": 3.0679781436920166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21788,
        "tokens": 11423186944,
        "learning_rate": 0.00016340395808516639,
        "gradient_norm": 0.4165307879447937,
        "train_loss": 3.050144910812378,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21789,
        "tokens": 11423711232,
        "learning_rate": 0.00016338141635680387,
        "gradient_norm": 0.40105199813842773,
        "train_loss": 3.061704158782959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21790,
        "tokens": 11424235520,
        "learning_rate": 0.00016335887650394134,
        "gradient_norm": 0.37449756264686584,
        "train_loss": 3.090595006942749,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21791,
        "tokens": 11424759808,
        "learning_rate": 0.00016333633852683225,
        "gradient_norm": 0.4558413624763489,
        "train_loss": 3.0329530239105225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21792,
        "tokens": 11425284096,
        "learning_rate": 0.00016331380242573054,
        "gradient_norm": 0.44515132904052734,
        "train_loss": 3.0993692874908447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21793,
        "tokens": 11425808384,
        "learning_rate": 0.00016329126820088967,
        "gradient_norm": 0.48184460401535034,
        "train_loss": 3.0249056816101074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21794,
        "tokens": 11426332672,
        "learning_rate": 0.00016326873585256345,
        "gradient_norm": 0.4328405261039734,
        "train_loss": 3.0742406845092773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21795,
        "tokens": 11426856960,
        "learning_rate": 0.00016324620538100542,
        "gradient_norm": 0.4388909637928009,
        "train_loss": 3.076542377471924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21796,
        "tokens": 11427381248,
        "learning_rate": 0.00016322367678646923,
        "gradient_norm": 0.44412463903427124,
        "train_loss": 3.020601987838745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21797,
        "tokens": 11427905536,
        "learning_rate": 0.0001632011500692084,
        "gradient_norm": 0.4231541156768799,
        "train_loss": 3.0954103469848633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21798,
        "tokens": 11428429824,
        "learning_rate": 0.00016317862522947658,
        "gradient_norm": 0.4169788658618927,
        "train_loss": 3.050236225128174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21799,
        "tokens": 11428954112,
        "learning_rate": 0.00016315610226752726,
        "gradient_norm": 0.37762895226478577,
        "train_loss": 3.004948616027832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21800,
        "tokens": 11429478400,
        "learning_rate": 0.00016313358118361397,
        "gradient_norm": 0.44865939021110535,
        "train_loss": 3.0561256408691406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21801,
        "tokens": 11430002688,
        "learning_rate": 0.0001631110619779903,
        "gradient_norm": 0.34713467955589294,
        "train_loss": 3.0506691932678223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21802,
        "tokens": 11430526976,
        "learning_rate": 0.00016308854465090959,
        "gradient_norm": 0.42237168550491333,
        "train_loss": 3.0550899505615234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21803,
        "tokens": 11431051264,
        "learning_rate": 0.00016306602920262544,
        "gradient_norm": 0.39370518922805786,
        "train_loss": 3.0349173545837402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21804,
        "tokens": 11431575552,
        "learning_rate": 0.00016304351563339113,
        "gradient_norm": 0.37177255749702454,
        "train_loss": 3.034379005432129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21805,
        "tokens": 11432099840,
        "learning_rate": 0.00016302100394346026,
        "gradient_norm": 0.420545369386673,
        "train_loss": 3.043544292449951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21806,
        "tokens": 11432624128,
        "learning_rate": 0.00016299849413308604,
        "gradient_norm": 0.4048196077346802,
        "train_loss": 3.0580296516418457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21807,
        "tokens": 11433148416,
        "learning_rate": 0.00016297598620252203,
        "gradient_norm": 0.39953696727752686,
        "train_loss": 3.0373079776763916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21808,
        "tokens": 11433672704,
        "learning_rate": 0.00016295348015202146,
        "gradient_norm": 0.3877805173397064,
        "train_loss": 3.0283260345458984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21809,
        "tokens": 11434196992,
        "learning_rate": 0.00016293097598183762,
        "gradient_norm": 0.45576369762420654,
        "train_loss": 3.052846908569336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21810,
        "tokens": 11434721280,
        "learning_rate": 0.00016290847369222403,
        "gradient_norm": 0.4373631179332733,
        "train_loss": 3.02184796333313,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21811,
        "tokens": 11435245568,
        "learning_rate": 0.00016288597328343378,
        "gradient_norm": 0.36671099066734314,
        "train_loss": 3.0478923320770264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21812,
        "tokens": 11435769856,
        "learning_rate": 0.0001628634747557203,
        "gradient_norm": 0.39309996366500854,
        "train_loss": 3.0174858570098877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21813,
        "tokens": 11436294144,
        "learning_rate": 0.00016284097810933664,
        "gradient_norm": 0.396367609500885,
        "train_loss": 3.0901265144348145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21814,
        "tokens": 11436818432,
        "learning_rate": 0.00016281848334453623,
        "gradient_norm": 0.37239930033683777,
        "train_loss": 3.035994529724121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21815,
        "tokens": 11437342720,
        "learning_rate": 0.0001627959904615721,
        "gradient_norm": 0.3870212733745575,
        "train_loss": 3.0045933723449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21816,
        "tokens": 11437867008,
        "learning_rate": 0.00016277349946069764,
        "gradient_norm": 0.3518698811531067,
        "train_loss": 3.0190248489379883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21817,
        "tokens": 11438391296,
        "learning_rate": 0.0001627510103421658,
        "gradient_norm": 0.3882157504558563,
        "train_loss": 3.0317811965942383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21818,
        "tokens": 11438915584,
        "learning_rate": 0.0001627285231062299,
        "gradient_norm": 0.4019041955471039,
        "train_loss": 3.0406908988952637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21819,
        "tokens": 11439439872,
        "learning_rate": 0.00016270603775314288,
        "gradient_norm": 0.388862669467926,
        "train_loss": 3.1167478561401367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21820,
        "tokens": 11439964160,
        "learning_rate": 0.00016268355428315795,
        "gradient_norm": 0.3723069131374359,
        "train_loss": 3.0832138061523438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21821,
        "tokens": 11440488448,
        "learning_rate": 0.00016266107269652827,
        "gradient_norm": 0.42874079942703247,
        "train_loss": 3.065802574157715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21822,
        "tokens": 11441012736,
        "learning_rate": 0.00016263859299350673,
        "gradient_norm": 0.3718366324901581,
        "train_loss": 3.0775890350341797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21823,
        "tokens": 11441537024,
        "learning_rate": 0.00016261611517434652,
        "gradient_norm": 0.3695826530456543,
        "train_loss": 3.0132040977478027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21824,
        "tokens": 11442061312,
        "learning_rate": 0.0001625936392393005,
        "gradient_norm": 0.4020671546459198,
        "train_loss": 3.0590755939483643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21825,
        "tokens": 11442585600,
        "learning_rate": 0.00016257116518862187,
        "gradient_norm": 0.3730548918247223,
        "train_loss": 3.1327016353607178,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21826,
        "tokens": 11443109888,
        "learning_rate": 0.00016254869302256332,
        "gradient_norm": 0.3992956280708313,
        "train_loss": 3.039808750152588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21827,
        "tokens": 11443634176,
        "learning_rate": 0.0001625262227413781,
        "gradient_norm": 0.3829154372215271,
        "train_loss": 3.053842306137085,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21828,
        "tokens": 11444158464,
        "learning_rate": 0.00016250375434531894,
        "gradient_norm": 0.40964171290397644,
        "train_loss": 3.016929864883423,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21829,
        "tokens": 11444682752,
        "learning_rate": 0.0001624812878346388,
        "gradient_norm": 0.45168107748031616,
        "train_loss": 3.149341106414795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21830,
        "tokens": 11445207040,
        "learning_rate": 0.00016245882320959065,
        "gradient_norm": 0.35152554512023926,
        "train_loss": 3.0717687606811523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21831,
        "tokens": 11445731328,
        "learning_rate": 0.0001624363604704272,
        "gradient_norm": 0.43215376138687134,
        "train_loss": 3.046506404876709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21832,
        "tokens": 11446255616,
        "learning_rate": 0.0001624138996174015,
        "gradient_norm": 0.41650494933128357,
        "train_loss": 3.0500521659851074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21833,
        "tokens": 11446779904,
        "learning_rate": 0.00016239144065076616,
        "gradient_norm": 0.39990729093551636,
        "train_loss": 3.060255527496338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21834,
        "tokens": 11447304192,
        "learning_rate": 0.00016236898357077417,
        "gradient_norm": 0.39720168709754944,
        "train_loss": 3.0197479724884033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21835,
        "tokens": 11447828480,
        "learning_rate": 0.00016234652837767813,
        "gradient_norm": 0.4041769802570343,
        "train_loss": 3.066209554672241,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21836,
        "tokens": 11448352768,
        "learning_rate": 0.000162324075071731,
        "gradient_norm": 0.3704724609851837,
        "train_loss": 3.0448527336120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21837,
        "tokens": 11448877056,
        "learning_rate": 0.0001623016236531853,
        "gradient_norm": 0.4035889506340027,
        "train_loss": 3.0476150512695312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21838,
        "tokens": 11449401344,
        "learning_rate": 0.00016227917412229399,
        "gradient_norm": 0.40187638998031616,
        "train_loss": 3.023886203765869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21839,
        "tokens": 11449925632,
        "learning_rate": 0.00016225672647930957,
        "gradient_norm": 0.4120299816131592,
        "train_loss": 3.0700879096984863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21840,
        "tokens": 11450449920,
        "learning_rate": 0.00016223428072448476,
        "gradient_norm": 0.37328240275382996,
        "train_loss": 3.049903631210327,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21841,
        "tokens": 11450974208,
        "learning_rate": 0.00016221183685807236,
        "gradient_norm": 0.3911665678024292,
        "train_loss": 3.0535905361175537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21842,
        "tokens": 11451498496,
        "learning_rate": 0.00016218939488032476,
        "gradient_norm": 0.39104676246643066,
        "train_loss": 3.041956663131714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21843,
        "tokens": 11452022784,
        "learning_rate": 0.00016216695479149483,
        "gradient_norm": 0.37933701276779175,
        "train_loss": 3.1101267337799072,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21844,
        "tokens": 11452547072,
        "learning_rate": 0.00016214451659183493,
        "gradient_norm": 0.4188764691352844,
        "train_loss": 3.0373573303222656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21845,
        "tokens": 11453071360,
        "learning_rate": 0.00016212208028159783,
        "gradient_norm": 0.40905195474624634,
        "train_loss": 3.038128614425659,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21846,
        "tokens": 11453595648,
        "learning_rate": 0.0001620996458610359,
        "gradient_norm": 0.5038632154464722,
        "train_loss": 3.1759586334228516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21847,
        "tokens": 11454119936,
        "learning_rate": 0.00016207721333040182,
        "gradient_norm": 0.4597153663635254,
        "train_loss": 3.0030176639556885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21848,
        "tokens": 11454644224,
        "learning_rate": 0.00016205478268994795,
        "gradient_norm": 0.4982885718345642,
        "train_loss": 3.078184127807617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21849,
        "tokens": 11455168512,
        "learning_rate": 0.00016203235393992684,
        "gradient_norm": 0.427809476852417,
        "train_loss": 3.044766426086426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21850,
        "tokens": 11455692800,
        "learning_rate": 0.00016200992708059102,
        "gradient_norm": 0.44749611616134644,
        "train_loss": 3.061960220336914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21851,
        "tokens": 11456217088,
        "learning_rate": 0.00016198750211219285,
        "gradient_norm": 0.4013961851596832,
        "train_loss": 3.0711865425109863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21852,
        "tokens": 11456741376,
        "learning_rate": 0.0001619650790349848,
        "gradient_norm": 0.4182760715484619,
        "train_loss": 3.0723037719726562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21853,
        "tokens": 11457265664,
        "learning_rate": 0.0001619426578492192,
        "gradient_norm": 0.4045392572879791,
        "train_loss": 3.0901904106140137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21854,
        "tokens": 11457789952,
        "learning_rate": 0.00016192023855514856,
        "gradient_norm": 0.4224083423614502,
        "train_loss": 2.9664316177368164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21855,
        "tokens": 11458314240,
        "learning_rate": 0.00016189782115302506,
        "gradient_norm": 0.41440916061401367,
        "train_loss": 3.053028106689453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21856,
        "tokens": 11458838528,
        "learning_rate": 0.00016187540564310124,
        "gradient_norm": 0.42203524708747864,
        "train_loss": 3.0657382011413574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21857,
        "tokens": 11459362816,
        "learning_rate": 0.00016185299202562916,
        "gradient_norm": 0.3991742730140686,
        "train_loss": 3.0537776947021484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21858,
        "tokens": 11459887104,
        "learning_rate": 0.0001618305803008614,
        "gradient_norm": 0.38377320766448975,
        "train_loss": 3.0162861347198486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21859,
        "tokens": 11460411392,
        "learning_rate": 0.00016180817046904995,
        "gradient_norm": 0.4075770974159241,
        "train_loss": 3.0214943885803223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21860,
        "tokens": 11460935680,
        "learning_rate": 0.00016178576253044724,
        "gradient_norm": 0.36895298957824707,
        "train_loss": 3.0457160472869873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21861,
        "tokens": 11461459968,
        "learning_rate": 0.0001617633564853055,
        "gradient_norm": 0.37788790464401245,
        "train_loss": 3.0768356323242188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21862,
        "tokens": 11461984256,
        "learning_rate": 0.00016174095233387686,
        "gradient_norm": 0.41251105070114136,
        "train_loss": 3.045563220977783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21863,
        "tokens": 11462508544,
        "learning_rate": 0.0001617185500764136,
        "gradient_norm": 0.4152974784374237,
        "train_loss": 3.102717876434326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21864,
        "tokens": 11463032832,
        "learning_rate": 0.00016169614971316774,
        "gradient_norm": 0.37940284609794617,
        "train_loss": 3.0344176292419434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21865,
        "tokens": 11463557120,
        "learning_rate": 0.0001616737512443916,
        "gradient_norm": 0.43004152178764343,
        "train_loss": 3.0377116203308105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21866,
        "tokens": 11464081408,
        "learning_rate": 0.00016165135467033714,
        "gradient_norm": 0.37083521485328674,
        "train_loss": 3.0375165939331055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21867,
        "tokens": 11464605696,
        "learning_rate": 0.0001616289599912566,
        "gradient_norm": 0.37396711111068726,
        "train_loss": 3.034276008605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21868,
        "tokens": 11465129984,
        "learning_rate": 0.00016160656720740193,
        "gradient_norm": 0.3988643288612366,
        "train_loss": 3.030707836151123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21869,
        "tokens": 11465654272,
        "learning_rate": 0.00016158417631902534,
        "gradient_norm": 0.3652365505695343,
        "train_loss": 3.0378808975219727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21870,
        "tokens": 11466178560,
        "learning_rate": 0.0001615617873263787,
        "gradient_norm": 0.42975902557373047,
        "train_loss": 3.146383047103882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21871,
        "tokens": 11466702848,
        "learning_rate": 0.00016153940022971416,
        "gradient_norm": 0.46196499466896057,
        "train_loss": 3.0540246963500977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21872,
        "tokens": 11467227136,
        "learning_rate": 0.00016151701502928356,
        "gradient_norm": 0.37255510687828064,
        "train_loss": 3.1038694381713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21873,
        "tokens": 11467751424,
        "learning_rate": 0.00016149463172533912,
        "gradient_norm": 0.42816638946533203,
        "train_loss": 3.1002800464630127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21874,
        "tokens": 11468275712,
        "learning_rate": 0.00016147225031813256,
        "gradient_norm": 0.3865261673927307,
        "train_loss": 3.029754161834717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21875,
        "tokens": 11468800000,
        "learning_rate": 0.00016144987080791596,
        "gradient_norm": 0.3887566328048706,
        "train_loss": 3.0472350120544434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21876,
        "tokens": 11469324288,
        "learning_rate": 0.00016142749319494106,
        "gradient_norm": 0.4095887839794159,
        "train_loss": 3.124488353729248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21877,
        "tokens": 11469848576,
        "learning_rate": 0.00016140511747945996,
        "gradient_norm": 0.3970584273338318,
        "train_loss": 3.0638222694396973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21878,
        "tokens": 11470372864,
        "learning_rate": 0.00016138274366172436,
        "gradient_norm": 0.3728937804698944,
        "train_loss": 3.066824436187744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21879,
        "tokens": 11470897152,
        "learning_rate": 0.00016136037174198622,
        "gradient_norm": 0.6192049384117126,
        "train_loss": 3.148427963256836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21880,
        "tokens": 11471421440,
        "learning_rate": 0.00016133800172049725,
        "gradient_norm": 0.6196295022964478,
        "train_loss": 3.021812915802002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21881,
        "tokens": 11471945728,
        "learning_rate": 0.0001613156335975094,
        "gradient_norm": 0.46794113516807556,
        "train_loss": 3.0192642211914062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21882,
        "tokens": 11472470016,
        "learning_rate": 0.00016129326737327425,
        "gradient_norm": 0.4788372814655304,
        "train_loss": 3.03611421585083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21883,
        "tokens": 11472994304,
        "learning_rate": 0.00016127090304804377,
        "gradient_norm": 0.4181627631187439,
        "train_loss": 3.0607709884643555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21884,
        "tokens": 11473518592,
        "learning_rate": 0.00016124854062206953,
        "gradient_norm": 0.4721026122570038,
        "train_loss": 3.0407257080078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21885,
        "tokens": 11474042880,
        "learning_rate": 0.0001612261800956034,
        "gradient_norm": 0.42178335785865784,
        "train_loss": 3.052067279815674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21886,
        "tokens": 11474567168,
        "learning_rate": 0.00016120382146889687,
        "gradient_norm": 0.4561353325843811,
        "train_loss": 3.0285935401916504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21887,
        "tokens": 11475091456,
        "learning_rate": 0.0001611814647422019,
        "gradient_norm": 0.40624672174453735,
        "train_loss": 3.095193862915039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21888,
        "tokens": 11475615744,
        "learning_rate": 0.00016115910991576984,
        "gradient_norm": 0.43450745940208435,
        "train_loss": 3.101661205291748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21889,
        "tokens": 11476140032,
        "learning_rate": 0.00016113675698985249,
        "gradient_norm": 0.3649013638496399,
        "train_loss": 3.023503303527832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21890,
        "tokens": 11476664320,
        "learning_rate": 0.0001611144059647015,
        "gradient_norm": 0.37847083806991577,
        "train_loss": 3.0367252826690674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21891,
        "tokens": 11477188608,
        "learning_rate": 0.00016109205684056833,
        "gradient_norm": 0.38536199927330017,
        "train_loss": 3.071444511413574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21892,
        "tokens": 11477712896,
        "learning_rate": 0.00016106970961770467,
        "gradient_norm": 0.36017686128616333,
        "train_loss": 3.0022377967834473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21893,
        "tokens": 11478237184,
        "learning_rate": 0.00016104736429636195,
        "gradient_norm": 0.41620153188705444,
        "train_loss": 3.0632567405700684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21894,
        "tokens": 11478761472,
        "learning_rate": 0.0001610250208767918,
        "gradient_norm": 0.38080406188964844,
        "train_loss": 3.091460704803467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21895,
        "tokens": 11479285760,
        "learning_rate": 0.0001610026793592456,
        "gradient_norm": 0.3837231397628784,
        "train_loss": 3.0277769565582275,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21896,
        "tokens": 11479810048,
        "learning_rate": 0.000160980339743975,
        "gradient_norm": 0.3806799054145813,
        "train_loss": 3.038266181945801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21897,
        "tokens": 11480334336,
        "learning_rate": 0.0001609580020312313,
        "gradient_norm": 0.3749122619628906,
        "train_loss": 3.051295757293701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21898,
        "tokens": 11480858624,
        "learning_rate": 0.00016093566622126605,
        "gradient_norm": 0.3751252293586731,
        "train_loss": 2.984063148498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21899,
        "tokens": 11481382912,
        "learning_rate": 0.00016091333231433054,
        "gradient_norm": 0.3889954388141632,
        "train_loss": 3.055769443511963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21900,
        "tokens": 11481907200,
        "learning_rate": 0.00016089100031067626,
        "gradient_norm": 0.47956573963165283,
        "train_loss": 3.014183759689331,
        "val_loss": 3.004690408706665,
        "hellaswag_acc": 0.28460466861724854,
        "hellaswag_acc_norm": 0.2935670018196106
    },
    {
        "step": 21901,
        "tokens": 11482431488,
        "learning_rate": 0.00016086867021055466,
        "gradient_norm": 0.4270465075969696,
        "train_loss": 3.0294365882873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21902,
        "tokens": 11482955776,
        "learning_rate": 0.00016084634201421689,
        "gradient_norm": 0.414558470249176,
        "train_loss": 3.0188333988189697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21903,
        "tokens": 11483480064,
        "learning_rate": 0.00016082401572191452,
        "gradient_norm": 0.4077039659023285,
        "train_loss": 3.0853137969970703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21904,
        "tokens": 11484004352,
        "learning_rate": 0.00016080169133389862,
        "gradient_norm": 0.37535685300827026,
        "train_loss": 3.077864646911621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21905,
        "tokens": 11484528640,
        "learning_rate": 0.00016077936885042072,
        "gradient_norm": 0.3857223391532898,
        "train_loss": 3.0545201301574707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21906,
        "tokens": 11485052928,
        "learning_rate": 0.00016075704827173186,
        "gradient_norm": 0.3836875855922699,
        "train_loss": 3.0671606063842773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21907,
        "tokens": 11485577216,
        "learning_rate": 0.00016073472959808344,
        "gradient_norm": 0.3841351270675659,
        "train_loss": 3.0160069465637207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21908,
        "tokens": 11486101504,
        "learning_rate": 0.0001607124128297266,
        "gradient_norm": 0.37604576349258423,
        "train_loss": 3.000727891921997,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21909,
        "tokens": 11486625792,
        "learning_rate": 0.00016069009796691253,
        "gradient_norm": 0.3959830403327942,
        "train_loss": 3.024559497833252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21910,
        "tokens": 11487150080,
        "learning_rate": 0.00016066778500989256,
        "gradient_norm": 0.38983047008514404,
        "train_loss": 2.9852776527404785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21911,
        "tokens": 11487674368,
        "learning_rate": 0.00016064547395891766,
        "gradient_norm": 0.3825463056564331,
        "train_loss": 3.050987958908081,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21912,
        "tokens": 11488198656,
        "learning_rate": 0.00016062316481423917,
        "gradient_norm": 0.4041929841041565,
        "train_loss": 2.9796805381774902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21913,
        "tokens": 11488722944,
        "learning_rate": 0.000160600857576108,
        "gradient_norm": 0.4427404999732971,
        "train_loss": 3.091312885284424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21914,
        "tokens": 11489247232,
        "learning_rate": 0.0001605785522447754,
        "gradient_norm": 0.4925040006637573,
        "train_loss": 3.0254900455474854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21915,
        "tokens": 11489771520,
        "learning_rate": 0.00016055624882049233,
        "gradient_norm": 0.4382856786251068,
        "train_loss": 3.0301661491394043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21916,
        "tokens": 11490295808,
        "learning_rate": 0.00016053394730350992,
        "gradient_norm": 0.39019423723220825,
        "train_loss": 3.0141241550445557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21917,
        "tokens": 11490820096,
        "learning_rate": 0.00016051164769407915,
        "gradient_norm": 0.44661831855773926,
        "train_loss": 3.1058735847473145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21918,
        "tokens": 11491344384,
        "learning_rate": 0.00016048934999245113,
        "gradient_norm": 0.37028223276138306,
        "train_loss": 3.057124614715576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21919,
        "tokens": 11491868672,
        "learning_rate": 0.00016046705419887666,
        "gradient_norm": 0.4134971797466278,
        "train_loss": 3.054180145263672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21920,
        "tokens": 11492392960,
        "learning_rate": 0.00016044476031360687,
        "gradient_norm": 0.4381438195705414,
        "train_loss": 3.0276052951812744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21921,
        "tokens": 11492917248,
        "learning_rate": 0.00016042246833689272,
        "gradient_norm": 0.377760648727417,
        "train_loss": 2.9952552318573,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21922,
        "tokens": 11493441536,
        "learning_rate": 0.000160400178268985,
        "gradient_norm": 0.5063462853431702,
        "train_loss": 3.0036158561706543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21923,
        "tokens": 11493965824,
        "learning_rate": 0.00016037789011013475,
        "gradient_norm": 0.4012247920036316,
        "train_loss": 3.057833671569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21924,
        "tokens": 11494490112,
        "learning_rate": 0.00016035560386059273,
        "gradient_norm": 0.42115160822868347,
        "train_loss": 3.0426833629608154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21925,
        "tokens": 11495014400,
        "learning_rate": 0.00016033331952060992,
        "gradient_norm": 0.42090708017349243,
        "train_loss": 2.9927306175231934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21926,
        "tokens": 11495538688,
        "learning_rate": 0.00016031103709043704,
        "gradient_norm": 0.3874955177307129,
        "train_loss": 3.072471857070923,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21927,
        "tokens": 11496062976,
        "learning_rate": 0.00016028875657032502,
        "gradient_norm": 0.3918896019458771,
        "train_loss": 3.0272397994995117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21928,
        "tokens": 11496587264,
        "learning_rate": 0.0001602664779605245,
        "gradient_norm": 0.4042302966117859,
        "train_loss": 2.9995713233947754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21929,
        "tokens": 11497111552,
        "learning_rate": 0.00016024420126128637,
        "gradient_norm": 0.4245419204235077,
        "train_loss": 3.0808448791503906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21930,
        "tokens": 11497635840,
        "learning_rate": 0.00016022192647286142,
        "gradient_norm": 0.4114770293235779,
        "train_loss": 3.0265309810638428,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21931,
        "tokens": 11498160128,
        "learning_rate": 0.00016019965359550026,
        "gradient_norm": 0.3920002281665802,
        "train_loss": 2.97086763381958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21932,
        "tokens": 11498684416,
        "learning_rate": 0.00016017738262945374,
        "gradient_norm": 0.41829758882522583,
        "train_loss": 2.986382484436035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21933,
        "tokens": 11499208704,
        "learning_rate": 0.00016015511357497238,
        "gradient_norm": 0.3925432562828064,
        "train_loss": 3.074460029602051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21934,
        "tokens": 11499732992,
        "learning_rate": 0.000160132846432307,
        "gradient_norm": 0.4586687386035919,
        "train_loss": 2.982447624206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21935,
        "tokens": 11500257280,
        "learning_rate": 0.00016011058120170814,
        "gradient_norm": 0.39610961079597473,
        "train_loss": 2.990811347961426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21936,
        "tokens": 11500781568,
        "learning_rate": 0.0001600883178834265,
        "gradient_norm": 0.4028555154800415,
        "train_loss": 3.0293478965759277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21937,
        "tokens": 11501305856,
        "learning_rate": 0.00016006605647771258,
        "gradient_norm": 0.38926076889038086,
        "train_loss": 3.0024874210357666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21938,
        "tokens": 11501830144,
        "learning_rate": 0.00016004379698481708,
        "gradient_norm": 0.3877620995044708,
        "train_loss": 3.0020174980163574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21939,
        "tokens": 11502354432,
        "learning_rate": 0.00016002153940499045,
        "gradient_norm": 0.39311107993125916,
        "train_loss": 3.0180726051330566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21940,
        "tokens": 11502878720,
        "learning_rate": 0.00015999928373848325,
        "gradient_norm": 0.3716249167919159,
        "train_loss": 3.0392954349517822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21941,
        "tokens": 11503403008,
        "learning_rate": 0.00015997702998554617,
        "gradient_norm": 0.39291471242904663,
        "train_loss": 2.979055643081665,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21942,
        "tokens": 11503927296,
        "learning_rate": 0.00015995477814642942,
        "gradient_norm": 0.37765979766845703,
        "train_loss": 3.027717113494873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21943,
        "tokens": 11504451584,
        "learning_rate": 0.00015993252822138368,
        "gradient_norm": 0.38218966126441956,
        "train_loss": 3.0924525260925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21944,
        "tokens": 11504975872,
        "learning_rate": 0.0001599102802106593,
        "gradient_norm": 0.4095160663127899,
        "train_loss": 2.9878196716308594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21945,
        "tokens": 11505500160,
        "learning_rate": 0.00015988803411450675,
        "gradient_norm": 0.4380744695663452,
        "train_loss": 3.014770984649658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21946,
        "tokens": 11506024448,
        "learning_rate": 0.0001598657899331764,
        "gradient_norm": 0.39952149987220764,
        "train_loss": 3.0929646492004395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21947,
        "tokens": 11506548736,
        "learning_rate": 0.00015984354766691874,
        "gradient_norm": 0.4817812144756317,
        "train_loss": 3.0576224327087402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21948,
        "tokens": 11507073024,
        "learning_rate": 0.00015982130731598395,
        "gradient_norm": 0.5247227549552917,
        "train_loss": 3.1102378368377686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21949,
        "tokens": 11507597312,
        "learning_rate": 0.00015979906888062247,
        "gradient_norm": 0.5173127055168152,
        "train_loss": 2.96293044090271,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21950,
        "tokens": 11508121600,
        "learning_rate": 0.00015977683236108477,
        "gradient_norm": 0.47165557742118835,
        "train_loss": 3.032050132751465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21951,
        "tokens": 11508645888,
        "learning_rate": 0.00015975459775762087,
        "gradient_norm": 0.4479485750198364,
        "train_loss": 3.050776481628418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21952,
        "tokens": 11509170176,
        "learning_rate": 0.0001597323650704813,
        "gradient_norm": 0.45587679743766785,
        "train_loss": 3.0269737243652344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21953,
        "tokens": 11509694464,
        "learning_rate": 0.0001597101342999161,
        "gradient_norm": 0.5077915191650391,
        "train_loss": 3.0048904418945312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21954,
        "tokens": 11510218752,
        "learning_rate": 0.0001596879054461757,
        "gradient_norm": 0.4533299207687378,
        "train_loss": 3.0232977867126465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21955,
        "tokens": 11510743040,
        "learning_rate": 0.00015966567850951018,
        "gradient_norm": 0.43363434076309204,
        "train_loss": 3.0554003715515137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21956,
        "tokens": 11511267328,
        "learning_rate": 0.00015964345349016984,
        "gradient_norm": 0.4317874014377594,
        "train_loss": 3.0325541496276855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21957,
        "tokens": 11511791616,
        "learning_rate": 0.00015962123038840468,
        "gradient_norm": 0.44028881192207336,
        "train_loss": 2.995959758758545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21958,
        "tokens": 11512315904,
        "learning_rate": 0.00015959900920446506,
        "gradient_norm": 0.4719431698322296,
        "train_loss": 3.0478639602661133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21959,
        "tokens": 11512840192,
        "learning_rate": 0.0001595767899386009,
        "gradient_norm": 0.4137348234653473,
        "train_loss": 3.044245719909668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21960,
        "tokens": 11513364480,
        "learning_rate": 0.0001595545725910624,
        "gradient_norm": 0.4007246196269989,
        "train_loss": 3.0515356063842773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21961,
        "tokens": 11513888768,
        "learning_rate": 0.00015953235716209974,
        "gradient_norm": 0.4064272344112396,
        "train_loss": 3.0013492107391357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21962,
        "tokens": 11514413056,
        "learning_rate": 0.0001595101436519628,
        "gradient_norm": 0.39493030309677124,
        "train_loss": 3.0319995880126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21963,
        "tokens": 11514937344,
        "learning_rate": 0.00015948793206090186,
        "gradient_norm": 0.44035661220550537,
        "train_loss": 3.0300300121307373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21964,
        "tokens": 11515461632,
        "learning_rate": 0.00015946572238916662,
        "gradient_norm": 0.39030301570892334,
        "train_loss": 3.014263153076172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21965,
        "tokens": 11515985920,
        "learning_rate": 0.00015944351463700743,
        "gradient_norm": 0.4034633934497833,
        "train_loss": 3.023282766342163,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21966,
        "tokens": 11516510208,
        "learning_rate": 0.00015942130880467395,
        "gradient_norm": 0.4075029790401459,
        "train_loss": 3.0964744091033936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21967,
        "tokens": 11517034496,
        "learning_rate": 0.00015939910489241632,
        "gradient_norm": 0.3708030879497528,
        "train_loss": 2.9925291538238525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21968,
        "tokens": 11517558784,
        "learning_rate": 0.0001593769029004844,
        "gradient_norm": 0.41988101601600647,
        "train_loss": 2.917081356048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21969,
        "tokens": 11518083072,
        "learning_rate": 0.00015935470282912818,
        "gradient_norm": 0.4353145360946655,
        "train_loss": 3.115650177001953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21970,
        "tokens": 11518607360,
        "learning_rate": 0.00015933250467859745,
        "gradient_norm": 0.43202850222587585,
        "train_loss": 3.0313215255737305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21971,
        "tokens": 11519131648,
        "learning_rate": 0.00015931030844914217,
        "gradient_norm": 0.43531036376953125,
        "train_loss": 3.029519557952881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21972,
        "tokens": 11519655936,
        "learning_rate": 0.00015928811414101207,
        "gradient_norm": 0.4044017195701599,
        "train_loss": 2.9915170669555664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21973,
        "tokens": 11520180224,
        "learning_rate": 0.00015926592175445712,
        "gradient_norm": 0.4608157277107239,
        "train_loss": 2.9245591163635254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21974,
        "tokens": 11520704512,
        "learning_rate": 0.00015924373128972696,
        "gradient_norm": 0.3786645829677582,
        "train_loss": 3.031127691268921,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21975,
        "tokens": 11521228800,
        "learning_rate": 0.00015922154274707154,
        "gradient_norm": 0.4275405704975128,
        "train_loss": 2.978731632232666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21976,
        "tokens": 11521753088,
        "learning_rate": 0.00015919935612674046,
        "gradient_norm": 0.35642093420028687,
        "train_loss": 2.996595859527588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21977,
        "tokens": 11522277376,
        "learning_rate": 0.00015917717142898362,
        "gradient_norm": 0.37598371505737305,
        "train_loss": 3.0088889598846436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21978,
        "tokens": 11522801664,
        "learning_rate": 0.00015915498865405055,
        "gradient_norm": 0.39126449823379517,
        "train_loss": 2.9214539527893066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21979,
        "tokens": 11523325952,
        "learning_rate": 0.00015913280780219106,
        "gradient_norm": 0.3680531978607178,
        "train_loss": 2.9928174018859863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21980,
        "tokens": 11523850240,
        "learning_rate": 0.00015911062887365488,
        "gradient_norm": 0.4018300473690033,
        "train_loss": 3.0184574127197266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21981,
        "tokens": 11524374528,
        "learning_rate": 0.00015908845186869154,
        "gradient_norm": 0.38667964935302734,
        "train_loss": 3.0062038898468018,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21982,
        "tokens": 11524898816,
        "learning_rate": 0.00015906627678755078,
        "gradient_norm": 0.36006560921669006,
        "train_loss": 2.98949933052063,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21983,
        "tokens": 11525423104,
        "learning_rate": 0.00015904410363048208,
        "gradient_norm": 0.35594576597213745,
        "train_loss": 3.0118117332458496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21984,
        "tokens": 11525947392,
        "learning_rate": 0.0001590219323977352,
        "gradient_norm": 0.39431560039520264,
        "train_loss": 3.059414863586426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21985,
        "tokens": 11526471680,
        "learning_rate": 0.00015899976308955948,
        "gradient_norm": 0.38334569334983826,
        "train_loss": 3.011176347732544,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21986,
        "tokens": 11526995968,
        "learning_rate": 0.00015897759570620464,
        "gradient_norm": 0.4099077880382538,
        "train_loss": 3.041454792022705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21987,
        "tokens": 11527520256,
        "learning_rate": 0.0001589554302479201,
        "gradient_norm": 0.38934290409088135,
        "train_loss": 3.0373733043670654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21988,
        "tokens": 11528044544,
        "learning_rate": 0.0001589332667149555,
        "gradient_norm": 0.36221858859062195,
        "train_loss": 3.0453531742095947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21989,
        "tokens": 11528568832,
        "learning_rate": 0.0001589111051075601,
        "gradient_norm": 0.41231393814086914,
        "train_loss": 3.0252561569213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21990,
        "tokens": 11529093120,
        "learning_rate": 0.00015888894542598364,
        "gradient_norm": 0.3781368136405945,
        "train_loss": 2.987015724182129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21991,
        "tokens": 11529617408,
        "learning_rate": 0.00015886678767047522,
        "gradient_norm": 0.3817218840122223,
        "train_loss": 3.0155868530273438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21992,
        "tokens": 11530141696,
        "learning_rate": 0.0001588446318412846,
        "gradient_norm": 0.42256519198417664,
        "train_loss": 3.0194849967956543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21993,
        "tokens": 11530665984,
        "learning_rate": 0.00015882247793866082,
        "gradient_norm": 0.36226198077201843,
        "train_loss": 2.97348690032959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21994,
        "tokens": 11531190272,
        "learning_rate": 0.00015880032596285356,
        "gradient_norm": 0.4461672902107239,
        "train_loss": 2.9759812355041504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21995,
        "tokens": 11531714560,
        "learning_rate": 0.000158778175914112,
        "gradient_norm": 0.41797658801078796,
        "train_loss": 2.9897587299346924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21996,
        "tokens": 11532238848,
        "learning_rate": 0.00015875602779268552,
        "gradient_norm": 0.432097464799881,
        "train_loss": 2.9613466262817383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21997,
        "tokens": 11532763136,
        "learning_rate": 0.00015873388159882333,
        "gradient_norm": 0.5157800912857056,
        "train_loss": 3.0704073905944824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21998,
        "tokens": 11533287424,
        "learning_rate": 0.00015871173733277488,
        "gradient_norm": 0.4154074192047119,
        "train_loss": 3.006312131881714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 21999,
        "tokens": 11533811712,
        "learning_rate": 0.00015868959499478928,
        "gradient_norm": 0.511255145072937,
        "train_loss": 3.0896053314208984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22000,
        "tokens": 11534336000,
        "learning_rate": 0.0001586674545851158,
        "gradient_norm": 0.4315568506717682,
        "train_loss": 3.0547242164611816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22001,
        "tokens": 11534860288,
        "learning_rate": 0.00015864531610400382,
        "gradient_norm": 0.43423736095428467,
        "train_loss": 3.0370140075683594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22002,
        "tokens": 11535384576,
        "learning_rate": 0.0001586231795517023,
        "gradient_norm": 0.42928358912467957,
        "train_loss": 3.0001800060272217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22003,
        "tokens": 11535908864,
        "learning_rate": 0.0001586010449284606,
        "gradient_norm": 0.3968751132488251,
        "train_loss": 3.0222415924072266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22004,
        "tokens": 11536433152,
        "learning_rate": 0.0001585789122345277,
        "gradient_norm": 0.43098047375679016,
        "train_loss": 3.032343626022339,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22005,
        "tokens": 11536957440,
        "learning_rate": 0.00015855678147015296,
        "gradient_norm": 0.42988020181655884,
        "train_loss": 3.0275990962982178,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22006,
        "tokens": 11537481728,
        "learning_rate": 0.00015853465263558522,
        "gradient_norm": 0.39849916100502014,
        "train_loss": 3.0186386108398438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22007,
        "tokens": 11538006016,
        "learning_rate": 0.0001585125257310738,
        "gradient_norm": 0.4364384710788727,
        "train_loss": 3.016561985015869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22008,
        "tokens": 11538530304,
        "learning_rate": 0.0001584904007568676,
        "gradient_norm": 0.418978214263916,
        "train_loss": 3.0594043731689453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22009,
        "tokens": 11539054592,
        "learning_rate": 0.00015846827771321567,
        "gradient_norm": 0.41548576951026917,
        "train_loss": 3.0681228637695312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22010,
        "tokens": 11539578880,
        "learning_rate": 0.00015844615660036724,
        "gradient_norm": 0.4569999873638153,
        "train_loss": 3.0712897777557373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22011,
        "tokens": 11540103168,
        "learning_rate": 0.00015842403741857106,
        "gradient_norm": 0.4842768609523773,
        "train_loss": 3.0299673080444336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22012,
        "tokens": 11540627456,
        "learning_rate": 0.0001584019201680763,
        "gradient_norm": 0.42103540897369385,
        "train_loss": 3.024082660675049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22013,
        "tokens": 11541151744,
        "learning_rate": 0.00015837980484913175,
        "gradient_norm": 0.43209338188171387,
        "train_loss": 3.017627239227295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22014,
        "tokens": 11541676032,
        "learning_rate": 0.0001583576914619865,
        "gradient_norm": 0.3989323377609253,
        "train_loss": 3.0041327476501465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22015,
        "tokens": 11542200320,
        "learning_rate": 0.0001583355800068893,
        "gradient_norm": 0.4415312707424164,
        "train_loss": 3.0089163780212402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22016,
        "tokens": 11542724608,
        "learning_rate": 0.00015831347048408928,
        "gradient_norm": 0.3899511992931366,
        "train_loss": 3.048178195953369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22017,
        "tokens": 11543248896,
        "learning_rate": 0.00015829136289383498,
        "gradient_norm": 0.49558836221694946,
        "train_loss": 3.0093369483947754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22018,
        "tokens": 11543773184,
        "learning_rate": 0.0001582692572363756,
        "gradient_norm": 0.41672077775001526,
        "train_loss": 3.0043551921844482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22019,
        "tokens": 11544297472,
        "learning_rate": 0.00015824715351195969,
        "gradient_norm": 0.40692606568336487,
        "train_loss": 2.995365619659424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22020,
        "tokens": 11544821760,
        "learning_rate": 0.00015822505172083612,
        "gradient_norm": 0.4550023376941681,
        "train_loss": 3.008779287338257,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22021,
        "tokens": 11545346048,
        "learning_rate": 0.00015820295186325385,
        "gradient_norm": 0.39683797955513,
        "train_loss": 3.0419154167175293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22022,
        "tokens": 11545870336,
        "learning_rate": 0.0001581808539394614,
        "gradient_norm": 0.38597041368484497,
        "train_loss": 3.091920852661133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22023,
        "tokens": 11546394624,
        "learning_rate": 0.0001581587579497077,
        "gradient_norm": 0.3865705728530884,
        "train_loss": 3.0844953060150146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22024,
        "tokens": 11546918912,
        "learning_rate": 0.0001581366638942413,
        "gradient_norm": 0.41964468359947205,
        "train_loss": 3.0164523124694824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22025,
        "tokens": 11547443200,
        "learning_rate": 0.0001581145717733111,
        "gradient_norm": 0.4264136254787445,
        "train_loss": 3.0660648345947266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22026,
        "tokens": 11547967488,
        "learning_rate": 0.00015809248158716552,
        "gradient_norm": 0.3926845192909241,
        "train_loss": 2.9850521087646484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22027,
        "tokens": 11548491776,
        "learning_rate": 0.00015807039333605346,
        "gradient_norm": 0.4039075970649719,
        "train_loss": 3.029366970062256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22028,
        "tokens": 11549016064,
        "learning_rate": 0.00015804830702022336,
        "gradient_norm": 0.4140544831752777,
        "train_loss": 3.051547050476074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22029,
        "tokens": 11549540352,
        "learning_rate": 0.00015802622263992388,
        "gradient_norm": 0.48604708909988403,
        "train_loss": 2.9925193786621094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22030,
        "tokens": 11550064640,
        "learning_rate": 0.00015800414019540373,
        "gradient_norm": 0.3930624723434448,
        "train_loss": 2.945591688156128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22031,
        "tokens": 11550588928,
        "learning_rate": 0.00015798205968691132,
        "gradient_norm": 0.4312637746334076,
        "train_loss": 3.0284175872802734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22032,
        "tokens": 11551113216,
        "learning_rate": 0.00015795998111469534,
        "gradient_norm": 0.390390008687973,
        "train_loss": 3.0080699920654297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22033,
        "tokens": 11551637504,
        "learning_rate": 0.0001579379044790041,
        "gradient_norm": 0.3949652910232544,
        "train_loss": 3.010291337966919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22034,
        "tokens": 11552161792,
        "learning_rate": 0.00015791582978008634,
        "gradient_norm": 0.3704961836338043,
        "train_loss": 3.0059847831726074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22035,
        "tokens": 11552686080,
        "learning_rate": 0.0001578937570181903,
        "gradient_norm": 0.39823800325393677,
        "train_loss": 3.0380043983459473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22036,
        "tokens": 11553210368,
        "learning_rate": 0.00015787168619356472,
        "gradient_norm": 0.38467004895210266,
        "train_loss": 3.005948543548584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22037,
        "tokens": 11553734656,
        "learning_rate": 0.00015784961730645774,
        "gradient_norm": 0.36862844228744507,
        "train_loss": 2.9816181659698486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22038,
        "tokens": 11554258944,
        "learning_rate": 0.00015782755035711804,
        "gradient_norm": 0.37476879358291626,
        "train_loss": 3.0050716400146484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22039,
        "tokens": 11554783232,
        "learning_rate": 0.00015780548534579373,
        "gradient_norm": 0.36869481205940247,
        "train_loss": 3.0431838035583496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22040,
        "tokens": 11555307520,
        "learning_rate": 0.00015778342227273337,
        "gradient_norm": 0.41668957471847534,
        "train_loss": 2.9891300201416016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22041,
        "tokens": 11555831808,
        "learning_rate": 0.00015776136113818532,
        "gradient_norm": 0.3616306185722351,
        "train_loss": 3.034824848175049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22042,
        "tokens": 11556356096,
        "learning_rate": 0.0001577393019423978,
        "gradient_norm": 0.3998512625694275,
        "train_loss": 3.013500928878784,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22043,
        "tokens": 11556880384,
        "learning_rate": 0.00015771724468561924,
        "gradient_norm": 0.3908959925174713,
        "train_loss": 3.0273537635803223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22044,
        "tokens": 11557404672,
        "learning_rate": 0.00015769518936809771,
        "gradient_norm": 0.4254436492919922,
        "train_loss": 3.0426783561706543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22045,
        "tokens": 11557928960,
        "learning_rate": 0.00015767313599008176,
        "gradient_norm": 0.41343623399734497,
        "train_loss": 3.015840768814087,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22046,
        "tokens": 11558453248,
        "learning_rate": 0.00015765108455181935,
        "gradient_norm": 0.3615596890449524,
        "train_loss": 3.012251138687134,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22047,
        "tokens": 11558977536,
        "learning_rate": 0.00015762903505355896,
        "gradient_norm": 0.3997119963169098,
        "train_loss": 2.9786205291748047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22048,
        "tokens": 11559501824,
        "learning_rate": 0.00015760698749554852,
        "gradient_norm": 0.3553847670555115,
        "train_loss": 3.038940906524658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22049,
        "tokens": 11560026112,
        "learning_rate": 0.00015758494187803634,
        "gradient_norm": 0.36196133494377136,
        "train_loss": 3.0385022163391113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22050,
        "tokens": 11560550400,
        "learning_rate": 0.00015756289820127064,
        "gradient_norm": 0.3743188679218292,
        "train_loss": 3.008986711502075,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22051,
        "tokens": 11561074688,
        "learning_rate": 0.0001575408564654994,
        "gradient_norm": 0.4231104254722595,
        "train_loss": 3.0493898391723633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22052,
        "tokens": 11561598976,
        "learning_rate": 0.00015751881667097086,
        "gradient_norm": 0.3951259255409241,
        "train_loss": 3.066584587097168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22053,
        "tokens": 11562123264,
        "learning_rate": 0.00015749677881793297,
        "gradient_norm": 0.3859214782714844,
        "train_loss": 3.0067601203918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22054,
        "tokens": 11562647552,
        "learning_rate": 0.00015747474290663392,
        "gradient_norm": 0.3929155468940735,
        "train_loss": 3.0222256183624268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22055,
        "tokens": 11563171840,
        "learning_rate": 0.00015745270893732164,
        "gradient_norm": 0.4152618944644928,
        "train_loss": 3.072307825088501,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22056,
        "tokens": 11563696128,
        "learning_rate": 0.0001574306769102443,
        "gradient_norm": 0.38652876019477844,
        "train_loss": 3.058342456817627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22057,
        "tokens": 11564220416,
        "learning_rate": 0.0001574086468256497,
        "gradient_norm": 0.37688910961151123,
        "train_loss": 2.994450569152832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22058,
        "tokens": 11564744704,
        "learning_rate": 0.00015738661868378603,
        "gradient_norm": 0.43394148349761963,
        "train_loss": 3.017597198486328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22059,
        "tokens": 11565268992,
        "learning_rate": 0.00015736459248490105,
        "gradient_norm": 0.3875890374183655,
        "train_loss": 2.9664416313171387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22060,
        "tokens": 11565793280,
        "learning_rate": 0.00015734256822924272,
        "gradient_norm": 0.42331209778785706,
        "train_loss": 3.0545120239257812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22061,
        "tokens": 11566317568,
        "learning_rate": 0.00015732054591705914,
        "gradient_norm": 0.4385755658149719,
        "train_loss": 3.0285301208496094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22062,
        "tokens": 11566841856,
        "learning_rate": 0.000157298525548598,
        "gradient_norm": 0.46085721254348755,
        "train_loss": 3.045114040374756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22063,
        "tokens": 11567366144,
        "learning_rate": 0.00015727650712410728,
        "gradient_norm": 0.4191522002220154,
        "train_loss": 3.0175259113311768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22064,
        "tokens": 11567890432,
        "learning_rate": 0.0001572544906438347,
        "gradient_norm": 0.4106248915195465,
        "train_loss": 3.006770133972168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22065,
        "tokens": 11568414720,
        "learning_rate": 0.00015723247610802826,
        "gradient_norm": 0.4012852907180786,
        "train_loss": 3.0641660690307617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22066,
        "tokens": 11568939008,
        "learning_rate": 0.00015721046351693558,
        "gradient_norm": 0.3970780372619629,
        "train_loss": 2.982473373413086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22067,
        "tokens": 11569463296,
        "learning_rate": 0.00015718845287080458,
        "gradient_norm": 0.4185557961463928,
        "train_loss": 3.0139098167419434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22068,
        "tokens": 11569987584,
        "learning_rate": 0.00015716644416988287,
        "gradient_norm": 0.3535371720790863,
        "train_loss": 3.0019211769104004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22069,
        "tokens": 11570511872,
        "learning_rate": 0.00015714443741441828,
        "gradient_norm": 0.36954328417778015,
        "train_loss": 2.9815919399261475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22070,
        "tokens": 11571036160,
        "learning_rate": 0.00015712243260465863,
        "gradient_norm": 0.4072757065296173,
        "train_loss": 3.0341384410858154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22071,
        "tokens": 11571560448,
        "learning_rate": 0.00015710042974085138,
        "gradient_norm": 0.42053160071372986,
        "train_loss": 3.0589399337768555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22072,
        "tokens": 11572084736,
        "learning_rate": 0.00015707842882324444,
        "gradient_norm": 0.40383514761924744,
        "train_loss": 3.0379245281219482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22073,
        "tokens": 11572609024,
        "learning_rate": 0.00015705642985208522,
        "gradient_norm": 0.3743532598018646,
        "train_loss": 2.9992177486419678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22074,
        "tokens": 11573133312,
        "learning_rate": 0.00015703443282762158,
        "gradient_norm": 0.40339091420173645,
        "train_loss": 3.0561180114746094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22075,
        "tokens": 11573657600,
        "learning_rate": 0.00015701243775010092,
        "gradient_norm": 0.42554154992103577,
        "train_loss": 3.0885162353515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22076,
        "tokens": 11574181888,
        "learning_rate": 0.00015699044461977093,
        "gradient_norm": 0.4431241750717163,
        "train_loss": 2.985440492630005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22077,
        "tokens": 11574706176,
        "learning_rate": 0.00015696845343687914,
        "gradient_norm": 0.4638162851333618,
        "train_loss": 3.0425002574920654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22078,
        "tokens": 11575230464,
        "learning_rate": 0.00015694646420167312,
        "gradient_norm": 0.40648725628852844,
        "train_loss": 3.024677276611328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22079,
        "tokens": 11575754752,
        "learning_rate": 0.0001569244769144003,
        "gradient_norm": 0.4381733238697052,
        "train_loss": 3.0374929904937744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22080,
        "tokens": 11576279040,
        "learning_rate": 0.00015690249157530834,
        "gradient_norm": 0.45646271109580994,
        "train_loss": 3.1002063751220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22081,
        "tokens": 11576803328,
        "learning_rate": 0.00015688050818464451,
        "gradient_norm": 0.4612042009830475,
        "train_loss": 3.0287206172943115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22082,
        "tokens": 11577327616,
        "learning_rate": 0.00015685852674265645,
        "gradient_norm": 0.39195558428764343,
        "train_loss": 3.0052499771118164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22083,
        "tokens": 11577851904,
        "learning_rate": 0.0001568365472495914,
        "gradient_norm": 0.4455236494541168,
        "train_loss": 3.0152156352996826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22084,
        "tokens": 11578376192,
        "learning_rate": 0.00015681456970569694,
        "gradient_norm": 0.4281463921070099,
        "train_loss": 3.041497230529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22085,
        "tokens": 11578900480,
        "learning_rate": 0.00015679259411122032,
        "gradient_norm": 0.40377354621887207,
        "train_loss": 2.9960784912109375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22086,
        "tokens": 11579424768,
        "learning_rate": 0.00015677062046640905,
        "gradient_norm": 0.46259668469429016,
        "train_loss": 2.9966750144958496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22087,
        "tokens": 11579949056,
        "learning_rate": 0.00015674864877151027,
        "gradient_norm": 0.4377019703388214,
        "train_loss": 2.972607135772705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22088,
        "tokens": 11580473344,
        "learning_rate": 0.00015672667902677151,
        "gradient_norm": 0.46457818150520325,
        "train_loss": 3.0079455375671387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22089,
        "tokens": 11580997632,
        "learning_rate": 0.00015670471123243988,
        "gradient_norm": 0.4115700125694275,
        "train_loss": 3.03004789352417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22090,
        "tokens": 11581521920,
        "learning_rate": 0.00015668274538876284,
        "gradient_norm": 0.4176212549209595,
        "train_loss": 3.0078208446502686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22091,
        "tokens": 11582046208,
        "learning_rate": 0.00015666078149598745,
        "gradient_norm": 0.47030937671661377,
        "train_loss": 3.0398054122924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22092,
        "tokens": 11582570496,
        "learning_rate": 0.00015663881955436113,
        "gradient_norm": 0.44045528769493103,
        "train_loss": 3.0277023315429688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22093,
        "tokens": 11583094784,
        "learning_rate": 0.0001566168595641309,
        "gradient_norm": 0.4976159930229187,
        "train_loss": 3.040609836578369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22094,
        "tokens": 11583619072,
        "learning_rate": 0.00015659490152554416,
        "gradient_norm": 0.4673180878162384,
        "train_loss": 3.033752918243408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22095,
        "tokens": 11584143360,
        "learning_rate": 0.00015657294543884782,
        "gradient_norm": 0.41193220019340515,
        "train_loss": 2.956439256668091,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22096,
        "tokens": 11584667648,
        "learning_rate": 0.0001565509913042893,
        "gradient_norm": 0.4388934373855591,
        "train_loss": 3.025608539581299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22097,
        "tokens": 11585191936,
        "learning_rate": 0.00015652903912211546,
        "gradient_norm": 0.3959454298019409,
        "train_loss": 3.030453681945801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22098,
        "tokens": 11585716224,
        "learning_rate": 0.00015650708889257354,
        "gradient_norm": 0.5095203518867493,
        "train_loss": 3.0295376777648926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22099,
        "tokens": 11586240512,
        "learning_rate": 0.00015648514061591067,
        "gradient_norm": 0.4072941839694977,
        "train_loss": 3.0830893516540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22100,
        "tokens": 11586764800,
        "learning_rate": 0.00015646319429237377,
        "gradient_norm": 0.48311617970466614,
        "train_loss": 3.0211713314056396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22101,
        "tokens": 11587289088,
        "learning_rate": 0.00015644124992221002,
        "gradient_norm": 0.42179059982299805,
        "train_loss": 3.0664596557617188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22102,
        "tokens": 11587813376,
        "learning_rate": 0.00015641930750566626,
        "gradient_norm": 0.413631796836853,
        "train_loss": 2.9981207847595215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22103,
        "tokens": 11588337664,
        "learning_rate": 0.0001563973670429896,
        "gradient_norm": 0.45460447669029236,
        "train_loss": 3.043586254119873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22104,
        "tokens": 11588861952,
        "learning_rate": 0.00015637542853442696,
        "gradient_norm": 0.37172746658325195,
        "train_loss": 3.008389472961426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22105,
        "tokens": 11589386240,
        "learning_rate": 0.00015635349198022538,
        "gradient_norm": 0.442933052778244,
        "train_loss": 3.043566942214966,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22106,
        "tokens": 11589910528,
        "learning_rate": 0.0001563315573806316,
        "gradient_norm": 0.43336108326911926,
        "train_loss": 3.104337215423584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22107,
        "tokens": 11590434816,
        "learning_rate": 0.00015630962473589272,
        "gradient_norm": 0.4596239924430847,
        "train_loss": 3.2023143768310547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22108,
        "tokens": 11590959104,
        "learning_rate": 0.00015628769404625543,
        "gradient_norm": 0.42653539776802063,
        "train_loss": 3.0035059452056885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22109,
        "tokens": 11591483392,
        "learning_rate": 0.00015626576531196668,
        "gradient_norm": 0.3825606107711792,
        "train_loss": 2.996772050857544,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22110,
        "tokens": 11592007680,
        "learning_rate": 0.0001562438385332734,
        "gradient_norm": 0.3949718177318573,
        "train_loss": 3.0504045486450195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22111,
        "tokens": 11592531968,
        "learning_rate": 0.00015622191371042222,
        "gradient_norm": 0.4271101653575897,
        "train_loss": 3.0323052406311035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22112,
        "tokens": 11593056256,
        "learning_rate": 0.0001561999908436601,
        "gradient_norm": 0.3766525089740753,
        "train_loss": 3.0198910236358643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22113,
        "tokens": 11593580544,
        "learning_rate": 0.00015617806993323366,
        "gradient_norm": 0.3750472962856293,
        "train_loss": 3.0529370307922363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22114,
        "tokens": 11594104832,
        "learning_rate": 0.0001561561509793898,
        "gradient_norm": 0.4154731333255768,
        "train_loss": 3.0428924560546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22115,
        "tokens": 11594629120,
        "learning_rate": 0.00015613423398237505,
        "gradient_norm": 0.422525554895401,
        "train_loss": 3.07029390335083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22116,
        "tokens": 11595153408,
        "learning_rate": 0.00015611231894243634,
        "gradient_norm": 0.397988498210907,
        "train_loss": 3.0507097244262695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22117,
        "tokens": 11595677696,
        "learning_rate": 0.00015609040585982015,
        "gradient_norm": 0.41261306405067444,
        "train_loss": 3.0126442909240723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22118,
        "tokens": 11596201984,
        "learning_rate": 0.0001560684947347732,
        "gradient_norm": 0.4033336341381073,
        "train_loss": 3.0377492904663086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22119,
        "tokens": 11596726272,
        "learning_rate": 0.00015604658556754228,
        "gradient_norm": 0.43262606859207153,
        "train_loss": 3.033616542816162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22120,
        "tokens": 11597250560,
        "learning_rate": 0.00015602467835837378,
        "gradient_norm": 0.3945249021053314,
        "train_loss": 3.0588088035583496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22121,
        "tokens": 11597774848,
        "learning_rate": 0.00015600277310751445,
        "gradient_norm": 0.3995048403739929,
        "train_loss": 2.997772693634033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22122,
        "tokens": 11598299136,
        "learning_rate": 0.00015598086981521075,
        "gradient_norm": 0.3927970826625824,
        "train_loss": 3.049227714538574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22123,
        "tokens": 11598823424,
        "learning_rate": 0.00015595896848170937,
        "gradient_norm": 0.41362494230270386,
        "train_loss": 3.032468795776367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22124,
        "tokens": 11599347712,
        "learning_rate": 0.00015593706910725663,
        "gradient_norm": 0.40261387825012207,
        "train_loss": 3.0258846282958984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22125,
        "tokens": 11599872000,
        "learning_rate": 0.00015591517169209925,
        "gradient_norm": 0.43385475873947144,
        "train_loss": 3.0311598777770996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22126,
        "tokens": 11600396288,
        "learning_rate": 0.00015589327623648355,
        "gradient_norm": 0.40283405780792236,
        "train_loss": 2.9825186729431152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22127,
        "tokens": 11600920576,
        "learning_rate": 0.00015587138274065612,
        "gradient_norm": 0.4280720353126526,
        "train_loss": 3.069345474243164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22128,
        "tokens": 11601444864,
        "learning_rate": 0.00015584949120486325,
        "gradient_norm": 0.3957696557044983,
        "train_loss": 3.051239013671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22129,
        "tokens": 11601969152,
        "learning_rate": 0.0001558276016293514,
        "gradient_norm": 0.44267529249191284,
        "train_loss": 3.067060708999634,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22130,
        "tokens": 11602493440,
        "learning_rate": 0.00015580571401436715,
        "gradient_norm": 0.41614386439323425,
        "train_loss": 3.019531726837158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22131,
        "tokens": 11603017728,
        "learning_rate": 0.00015578382836015661,
        "gradient_norm": 0.41716763377189636,
        "train_loss": 3.0777900218963623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22132,
        "tokens": 11603542016,
        "learning_rate": 0.00015576194466696637,
        "gradient_norm": 0.3769384026527405,
        "train_loss": 2.9993791580200195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22133,
        "tokens": 11604066304,
        "learning_rate": 0.0001557400629350425,
        "gradient_norm": 0.3959485590457916,
        "train_loss": 3.005039691925049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22134,
        "tokens": 11604590592,
        "learning_rate": 0.00015571818316463158,
        "gradient_norm": 0.3895185589790344,
        "train_loss": 3.035922050476074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22135,
        "tokens": 11605114880,
        "learning_rate": 0.00015569630535597966,
        "gradient_norm": 0.399704247713089,
        "train_loss": 3.10766339302063,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22136,
        "tokens": 11605639168,
        "learning_rate": 0.00015567442950933317,
        "gradient_norm": 0.3945441246032715,
        "train_loss": 3.050295352935791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22137,
        "tokens": 11606163456,
        "learning_rate": 0.0001556525556249382,
        "gradient_norm": 0.39912357926368713,
        "train_loss": 3.065525770187378,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22138,
        "tokens": 11606687744,
        "learning_rate": 0.00015563068370304104,
        "gradient_norm": 0.4550105035305023,
        "train_loss": 3.049342632293701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22139,
        "tokens": 11607212032,
        "learning_rate": 0.00015560881374388795,
        "gradient_norm": 0.4148922860622406,
        "train_loss": 3.024919033050537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22140,
        "tokens": 11607736320,
        "learning_rate": 0.000155586945747725,
        "gradient_norm": 0.42279520630836487,
        "train_loss": 3.036271333694458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22141,
        "tokens": 11608260608,
        "learning_rate": 0.00015556507971479846,
        "gradient_norm": 0.41329720616340637,
        "train_loss": 3.085054874420166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22142,
        "tokens": 11608784896,
        "learning_rate": 0.00015554321564535434,
        "gradient_norm": 0.4118659198284149,
        "train_loss": 3.025550603866577,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22143,
        "tokens": 11609309184,
        "learning_rate": 0.00015552135353963883,
        "gradient_norm": 0.4517258107662201,
        "train_loss": 3.0109002590179443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22144,
        "tokens": 11609833472,
        "learning_rate": 0.00015549949339789787,
        "gradient_norm": 0.3797508776187897,
        "train_loss": 2.965656280517578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22145,
        "tokens": 11610357760,
        "learning_rate": 0.00015547763522037777,
        "gradient_norm": 0.44179996848106384,
        "train_loss": 3.0416507720947266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22146,
        "tokens": 11610882048,
        "learning_rate": 0.00015545577900732434,
        "gradient_norm": 0.42157912254333496,
        "train_loss": 3.0503602027893066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22147,
        "tokens": 11611406336,
        "learning_rate": 0.00015543392475898376,
        "gradient_norm": 0.40662574768066406,
        "train_loss": 3.0771284103393555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22148,
        "tokens": 11611930624,
        "learning_rate": 0.00015541207247560192,
        "gradient_norm": 0.37324264645576477,
        "train_loss": 3.0949275493621826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22149,
        "tokens": 11612454912,
        "learning_rate": 0.00015539022215742477,
        "gradient_norm": 0.404603511095047,
        "train_loss": 3.1219301223754883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22150,
        "tokens": 11612979200,
        "learning_rate": 0.00015536837380469842,
        "gradient_norm": 0.3903484046459198,
        "train_loss": 3.033320903778076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22151,
        "tokens": 11613503488,
        "learning_rate": 0.00015534652741766867,
        "gradient_norm": 0.3541586697101593,
        "train_loss": 2.978302478790283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22152,
        "tokens": 11614027776,
        "learning_rate": 0.00015532468299658152,
        "gradient_norm": 0.39956629276275635,
        "train_loss": 3.046008825302124,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22153,
        "tokens": 11614552064,
        "learning_rate": 0.0001553028405416827,
        "gradient_norm": 0.39892077445983887,
        "train_loss": 3.017545223236084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22154,
        "tokens": 11615076352,
        "learning_rate": 0.0001552810000532183,
        "gradient_norm": 0.376558393239975,
        "train_loss": 3.0732414722442627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22155,
        "tokens": 11615600640,
        "learning_rate": 0.00015525916153143388,
        "gradient_norm": 0.36894091963768005,
        "train_loss": 3.022891044616699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22156,
        "tokens": 11616124928,
        "learning_rate": 0.00015523732497657556,
        "gradient_norm": 0.3620232939720154,
        "train_loss": 3.059767723083496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22157,
        "tokens": 11616649216,
        "learning_rate": 0.00015521549038888894,
        "gradient_norm": 0.4308878779411316,
        "train_loss": 3.0902013778686523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22158,
        "tokens": 11617173504,
        "learning_rate": 0.00015519365776861977,
        "gradient_norm": 0.4494319260120392,
        "train_loss": 3.040721893310547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22159,
        "tokens": 11617697792,
        "learning_rate": 0.00015517182711601403,
        "gradient_norm": 0.40518271923065186,
        "train_loss": 3.0665524005889893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22160,
        "tokens": 11618222080,
        "learning_rate": 0.0001551499984313172,
        "gradient_norm": 0.45799970626831055,
        "train_loss": 3.048675298690796,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22161,
        "tokens": 11618746368,
        "learning_rate": 0.0001551281717147752,
        "gradient_norm": 0.44056710600852966,
        "train_loss": 3.011730194091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22162,
        "tokens": 11619270656,
        "learning_rate": 0.0001551063469666335,
        "gradient_norm": 0.44157835841178894,
        "train_loss": 3.0820653438568115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22163,
        "tokens": 11619794944,
        "learning_rate": 0.00015508452418713797,
        "gradient_norm": 0.4024018943309784,
        "train_loss": 3.0264220237731934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22164,
        "tokens": 11620319232,
        "learning_rate": 0.00015506270337653407,
        "gradient_norm": 0.40399718284606934,
        "train_loss": 3.013500690460205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22165,
        "tokens": 11620843520,
        "learning_rate": 0.0001550408845350676,
        "gradient_norm": 0.42881232500076294,
        "train_loss": 3.0871243476867676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22166,
        "tokens": 11621367808,
        "learning_rate": 0.00015501906766298394,
        "gradient_norm": 0.3953305780887604,
        "train_loss": 3.005037784576416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22167,
        "tokens": 11621892096,
        "learning_rate": 0.00015499725276052893,
        "gradient_norm": 0.42290154099464417,
        "train_loss": 3.1037492752075195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22168,
        "tokens": 11622416384,
        "learning_rate": 0.00015497543982794787,
        "gradient_norm": 0.38682106137275696,
        "train_loss": 3.0828652381896973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22169,
        "tokens": 11622940672,
        "learning_rate": 0.00015495362886548642,
        "gradient_norm": 0.39824801683425903,
        "train_loss": 3.0493783950805664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22170,
        "tokens": 11623464960,
        "learning_rate": 0.00015493181987339018,
        "gradient_norm": 0.36263442039489746,
        "train_loss": 3.001976728439331,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22171,
        "tokens": 11623989248,
        "learning_rate": 0.00015491001285190446,
        "gradient_norm": 0.41841092705726624,
        "train_loss": 3.053614616394043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22172,
        "tokens": 11624513536,
        "learning_rate": 0.00015488820780127483,
        "gradient_norm": 0.4115593731403351,
        "train_loss": 3.054131031036377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22173,
        "tokens": 11625037824,
        "learning_rate": 0.00015486640472174665,
        "gradient_norm": 0.48971277475357056,
        "train_loss": 3.0401973724365234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22174,
        "tokens": 11625562112,
        "learning_rate": 0.00015484460361356547,
        "gradient_norm": 0.38339149951934814,
        "train_loss": 3.0621695518493652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22175,
        "tokens": 11626086400,
        "learning_rate": 0.00015482280447697656,
        "gradient_norm": 0.4771505892276764,
        "train_loss": 3.04461669921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22176,
        "tokens": 11626610688,
        "learning_rate": 0.0001548010073122254,
        "gradient_norm": 0.395050048828125,
        "train_loss": 3.0077428817749023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22177,
        "tokens": 11627134976,
        "learning_rate": 0.00015477921211955723,
        "gradient_norm": 0.5011910796165466,
        "train_loss": 3.1842880249023438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22178,
        "tokens": 11627659264,
        "learning_rate": 0.0001547574188992175,
        "gradient_norm": 0.41235363483428955,
        "train_loss": 3.0325369834899902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22179,
        "tokens": 11628183552,
        "learning_rate": 0.00015473562765145143,
        "gradient_norm": 0.4639979898929596,
        "train_loss": 3.0158562660217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22180,
        "tokens": 11628707840,
        "learning_rate": 0.0001547138383765044,
        "gradient_norm": 0.4492616653442383,
        "train_loss": 3.0328099727630615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22181,
        "tokens": 11629232128,
        "learning_rate": 0.00015469205107462153,
        "gradient_norm": 0.44269368052482605,
        "train_loss": 3.051408529281616,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22182,
        "tokens": 11629756416,
        "learning_rate": 0.00015467026574604825,
        "gradient_norm": 0.4614521265029907,
        "train_loss": 3.083275318145752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22183,
        "tokens": 11630280704,
        "learning_rate": 0.0001546484823910296,
        "gradient_norm": 0.41411182284355164,
        "train_loss": 3.051313877105713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22184,
        "tokens": 11630804992,
        "learning_rate": 0.00015462670100981085,
        "gradient_norm": 0.4187551438808441,
        "train_loss": 3.0101468563079834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22185,
        "tokens": 11631329280,
        "learning_rate": 0.00015460492160263728,
        "gradient_norm": 0.4253690540790558,
        "train_loss": 3.0614867210388184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22186,
        "tokens": 11631853568,
        "learning_rate": 0.00015458314416975387,
        "gradient_norm": 0.4342016577720642,
        "train_loss": 3.0448241233825684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22187,
        "tokens": 11632377856,
        "learning_rate": 0.00015456136871140592,
        "gradient_norm": 0.4621739387512207,
        "train_loss": 3.0608160495758057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22188,
        "tokens": 11632902144,
        "learning_rate": 0.00015453959522783835,
        "gradient_norm": 0.5034632086753845,
        "train_loss": 3.074765682220459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22189,
        "tokens": 11633426432,
        "learning_rate": 0.00015451782371929645,
        "gradient_norm": 0.40674126148223877,
        "train_loss": 3.0310182571411133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22190,
        "tokens": 11633950720,
        "learning_rate": 0.0001544960541860251,
        "gradient_norm": 0.4111475944519043,
        "train_loss": 3.0732197761535645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22191,
        "tokens": 11634475008,
        "learning_rate": 0.00015447428662826953,
        "gradient_norm": 0.4088745415210724,
        "train_loss": 3.1298751831054688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22192,
        "tokens": 11634999296,
        "learning_rate": 0.00015445252104627456,
        "gradient_norm": 0.39201104640960693,
        "train_loss": 3.008507251739502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22193,
        "tokens": 11635523584,
        "learning_rate": 0.0001544307574402854,
        "gradient_norm": 0.3894466757774353,
        "train_loss": 3.0325708389282227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22194,
        "tokens": 11636047872,
        "learning_rate": 0.00015440899581054685,
        "gradient_norm": 0.4029718339443207,
        "train_loss": 3.0280466079711914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22195,
        "tokens": 11636572160,
        "learning_rate": 0.00015438723615730397,
        "gradient_norm": 0.390244722366333,
        "train_loss": 3.0436806678771973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22196,
        "tokens": 11637096448,
        "learning_rate": 0.0001543654784808016,
        "gradient_norm": 0.39483121037483215,
        "train_loss": 3.0189967155456543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22197,
        "tokens": 11637620736,
        "learning_rate": 0.00015434372278128478,
        "gradient_norm": 0.3900950849056244,
        "train_loss": 3.0941503047943115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22198,
        "tokens": 11638145024,
        "learning_rate": 0.0001543219690589982,
        "gradient_norm": 0.3978380560874939,
        "train_loss": 2.9655323028564453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22199,
        "tokens": 11638669312,
        "learning_rate": 0.00015430021731418695,
        "gradient_norm": 0.4661925733089447,
        "train_loss": 3.057373046875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22200,
        "tokens": 11639193600,
        "learning_rate": 0.0001542784675470957,
        "gradient_norm": 0.44417238235473633,
        "train_loss": 3.0883936882019043,
        "val_loss": 3.000645399093628,
        "hellaswag_acc": 0.28440549969673157,
        "hellaswag_acc_norm": 0.2973511219024658
    },
    {
        "step": 22201,
        "tokens": 11639717888,
        "learning_rate": 0.00015425671975796945,
        "gradient_norm": 0.41793292760849,
        "train_loss": 3.045830249786377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22202,
        "tokens": 11640242176,
        "learning_rate": 0.00015423497394705278,
        "gradient_norm": 0.4848094880580902,
        "train_loss": 3.095694065093994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22203,
        "tokens": 11640766464,
        "learning_rate": 0.00015421323011459068,
        "gradient_norm": 0.45040640234947205,
        "train_loss": 3.125913143157959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22204,
        "tokens": 11641290752,
        "learning_rate": 0.00015419148826082769,
        "gradient_norm": 0.4752148389816284,
        "train_loss": 3.0415916442871094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22205,
        "tokens": 11641815040,
        "learning_rate": 0.00015416974838600872,
        "gradient_norm": 0.4193095564842224,
        "train_loss": 3.066164016723633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22206,
        "tokens": 11642339328,
        "learning_rate": 0.00015414801049037832,
        "gradient_norm": 0.39042195677757263,
        "train_loss": 3.0524067878723145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22207,
        "tokens": 11642863616,
        "learning_rate": 0.0001541262745741814,
        "gradient_norm": 0.4414581060409546,
        "train_loss": 3.0194201469421387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22208,
        "tokens": 11643387904,
        "learning_rate": 0.00015410454063766237,
        "gradient_norm": 0.38635823130607605,
        "train_loss": 3.0579729080200195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22209,
        "tokens": 11643912192,
        "learning_rate": 0.000154082808681066,
        "gradient_norm": 0.4225787818431854,
        "train_loss": 3.0158090591430664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22210,
        "tokens": 11644436480,
        "learning_rate": 0.000154061078704637,
        "gradient_norm": 0.3983169198036194,
        "train_loss": 3.1143031120300293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22211,
        "tokens": 11644960768,
        "learning_rate": 0.0001540393507086198,
        "gradient_norm": 0.3924766480922699,
        "train_loss": 3.008517265319824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22212,
        "tokens": 11645485056,
        "learning_rate": 0.0001540176246932591,
        "gradient_norm": 0.4204549491405487,
        "train_loss": 3.033646583557129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22213,
        "tokens": 11646009344,
        "learning_rate": 0.00015399590065879934,
        "gradient_norm": 0.46365609765052795,
        "train_loss": 3.059884548187256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22214,
        "tokens": 11646533632,
        "learning_rate": 0.0001539741786054852,
        "gradient_norm": 0.37069573998451233,
        "train_loss": 3.0407774448394775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22215,
        "tokens": 11647057920,
        "learning_rate": 0.000153952458533561,
        "gradient_norm": 0.3792368769645691,
        "train_loss": 3.029231548309326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22216,
        "tokens": 11647582208,
        "learning_rate": 0.00015393074044327146,
        "gradient_norm": 0.3748664855957031,
        "train_loss": 3.0947327613830566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22217,
        "tokens": 11648106496,
        "learning_rate": 0.00015390902433486077,
        "gradient_norm": 0.3864324986934662,
        "train_loss": 3.066199541091919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22218,
        "tokens": 11648630784,
        "learning_rate": 0.00015388731020857352,
        "gradient_norm": 0.3635321855545044,
        "train_loss": 3.0625083446502686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22219,
        "tokens": 11649155072,
        "learning_rate": 0.00015386559806465422,
        "gradient_norm": 0.3683130145072937,
        "train_loss": 3.015495538711548,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22220,
        "tokens": 11649679360,
        "learning_rate": 0.00015384388790334712,
        "gradient_norm": 0.38873228430747986,
        "train_loss": 3.0315942764282227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22221,
        "tokens": 11650203648,
        "learning_rate": 0.00015382217972489666,
        "gradient_norm": 0.39202332496643066,
        "train_loss": 3.0000298023223877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22222,
        "tokens": 11650727936,
        "learning_rate": 0.00015380047352954717,
        "gradient_norm": 0.377512127161026,
        "train_loss": 3.0517120361328125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22223,
        "tokens": 11651252224,
        "learning_rate": 0.00015377876931754302,
        "gradient_norm": 0.3950904607772827,
        "train_loss": 3.071572780609131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22224,
        "tokens": 11651776512,
        "learning_rate": 0.0001537570670891284,
        "gradient_norm": 0.3839050531387329,
        "train_loss": 3.0044898986816406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22225,
        "tokens": 11652300800,
        "learning_rate": 0.0001537353668445478,
        "gradient_norm": 0.4181783199310303,
        "train_loss": 3.0141072273254395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22226,
        "tokens": 11652825088,
        "learning_rate": 0.00015371366858404526,
        "gradient_norm": 0.4166400730609894,
        "train_loss": 2.9827466011047363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22227,
        "tokens": 11653349376,
        "learning_rate": 0.00015369197230786523,
        "gradient_norm": 0.40391913056373596,
        "train_loss": 3.023381233215332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22228,
        "tokens": 11653873664,
        "learning_rate": 0.00015367027801625171,
        "gradient_norm": 0.3995096683502197,
        "train_loss": 3.0611352920532227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22229,
        "tokens": 11654397952,
        "learning_rate": 0.00015364858570944903,
        "gradient_norm": 0.40138205885887146,
        "train_loss": 3.034205913543701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22230,
        "tokens": 11654922240,
        "learning_rate": 0.00015362689538770145,
        "gradient_norm": 0.3802046477794647,
        "train_loss": 3.0103394985198975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22231,
        "tokens": 11655446528,
        "learning_rate": 0.0001536052070512529,
        "gradient_norm": 0.3882032334804535,
        "train_loss": 3.051382064819336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22232,
        "tokens": 11655970816,
        "learning_rate": 0.00015358352070034774,
        "gradient_norm": 0.3520068824291229,
        "train_loss": 3.0511250495910645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22233,
        "tokens": 11656495104,
        "learning_rate": 0.00015356183633522986,
        "gradient_norm": 0.38959628343582153,
        "train_loss": 3.0540244579315186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22234,
        "tokens": 11657019392,
        "learning_rate": 0.00015354015395614354,
        "gradient_norm": 0.3828199803829193,
        "train_loss": 3.081005573272705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22235,
        "tokens": 11657543680,
        "learning_rate": 0.00015351847356333265,
        "gradient_norm": 0.3888261318206787,
        "train_loss": 3.0640769004821777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22236,
        "tokens": 11658067968,
        "learning_rate": 0.00015349679515704143,
        "gradient_norm": 0.3768449127674103,
        "train_loss": 3.016890048980713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22237,
        "tokens": 11658592256,
        "learning_rate": 0.00015347511873751372,
        "gradient_norm": 0.3882160484790802,
        "train_loss": 3.052387237548828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22238,
        "tokens": 11659116544,
        "learning_rate": 0.00015345344430499358,
        "gradient_norm": 0.40842199325561523,
        "train_loss": 3.0737743377685547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22239,
        "tokens": 11659640832,
        "learning_rate": 0.0001534317718597251,
        "gradient_norm": 0.39419159293174744,
        "train_loss": 3.053671360015869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22240,
        "tokens": 11660165120,
        "learning_rate": 0.000153410101401952,
        "gradient_norm": 0.4250563085079193,
        "train_loss": 3.054208755493164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22241,
        "tokens": 11660689408,
        "learning_rate": 0.00015338843293191844,
        "gradient_norm": 0.35261720418930054,
        "train_loss": 3.0237784385681152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22242,
        "tokens": 11661213696,
        "learning_rate": 0.00015336676644986814,
        "gradient_norm": 0.4093751013278961,
        "train_loss": 3.073873519897461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22243,
        "tokens": 11661737984,
        "learning_rate": 0.00015334510195604516,
        "gradient_norm": 0.38309305906295776,
        "train_loss": 3.042651414871216,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22244,
        "tokens": 11662262272,
        "learning_rate": 0.00015332343945069314,
        "gradient_norm": 0.4628472924232483,
        "train_loss": 3.127267837524414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22245,
        "tokens": 11662786560,
        "learning_rate": 0.00015330177893405617,
        "gradient_norm": 0.4380178153514862,
        "train_loss": 3.0460968017578125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22246,
        "tokens": 11663310848,
        "learning_rate": 0.00015328012040637782,
        "gradient_norm": 0.39990338683128357,
        "train_loss": 3.0716938972473145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22247,
        "tokens": 11663835136,
        "learning_rate": 0.0001532584638679021,
        "gradient_norm": 0.42804211378097534,
        "train_loss": 2.9912004470825195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22248,
        "tokens": 11664359424,
        "learning_rate": 0.0001532368093188726,
        "gradient_norm": 0.3945358693599701,
        "train_loss": 3.071237087249756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22249,
        "tokens": 11664883712,
        "learning_rate": 0.00015321515675953315,
        "gradient_norm": 0.4397062361240387,
        "train_loss": 3.0539207458496094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22250,
        "tokens": 11665408000,
        "learning_rate": 0.00015319350619012756,
        "gradient_norm": 0.4155610203742981,
        "train_loss": 2.9895360469818115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22251,
        "tokens": 11665932288,
        "learning_rate": 0.0001531718576108994,
        "gradient_norm": 0.42807915806770325,
        "train_loss": 3.0866708755493164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22252,
        "tokens": 11666456576,
        "learning_rate": 0.00015315021102209244,
        "gradient_norm": 0.39650672674179077,
        "train_loss": 3.0153255462646484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22253,
        "tokens": 11666980864,
        "learning_rate": 0.00015312856642395027,
        "gradient_norm": 0.5438611507415771,
        "train_loss": 3.073568820953369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22254,
        "tokens": 11667505152,
        "learning_rate": 0.0001531069238167166,
        "gradient_norm": 0.5053747296333313,
        "train_loss": 3.0310230255126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22255,
        "tokens": 11668029440,
        "learning_rate": 0.00015308528320063494,
        "gradient_norm": 0.5509560108184814,
        "train_loss": 3.0442237854003906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22256,
        "tokens": 11668553728,
        "learning_rate": 0.00015306364457594903,
        "gradient_norm": 0.39283522963523865,
        "train_loss": 3.031360149383545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22257,
        "tokens": 11669078016,
        "learning_rate": 0.00015304200794290224,
        "gradient_norm": 0.4643517732620239,
        "train_loss": 3.037360668182373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22258,
        "tokens": 11669602304,
        "learning_rate": 0.00015302037330173828,
        "gradient_norm": 0.47789624333381653,
        "train_loss": 3.0435726642608643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22259,
        "tokens": 11670126592,
        "learning_rate": 0.00015299874065270074,
        "gradient_norm": 0.42088747024536133,
        "train_loss": 3.030489921569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22260,
        "tokens": 11670650880,
        "learning_rate": 0.00015297710999603284,
        "gradient_norm": 0.43402236700057983,
        "train_loss": 3.0094356536865234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22261,
        "tokens": 11671175168,
        "learning_rate": 0.00015295548133197837,
        "gradient_norm": 0.4150645434856415,
        "train_loss": 3.0023837089538574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22262,
        "tokens": 11671699456,
        "learning_rate": 0.00015293385466078058,
        "gradient_norm": 0.41958943009376526,
        "train_loss": 3.0254712104797363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22263,
        "tokens": 11672223744,
        "learning_rate": 0.00015291222998268302,
        "gradient_norm": 0.4528834819793701,
        "train_loss": 2.9796133041381836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22264,
        "tokens": 11672748032,
        "learning_rate": 0.000152890607297929,
        "gradient_norm": 0.40016859769821167,
        "train_loss": 3.0629453659057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22265,
        "tokens": 11673272320,
        "learning_rate": 0.00015286898660676204,
        "gradient_norm": 0.46369266510009766,
        "train_loss": 3.0125715732574463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22266,
        "tokens": 11673796608,
        "learning_rate": 0.00015284736790942537,
        "gradient_norm": 0.42740580439567566,
        "train_loss": 3.0740716457366943,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22267,
        "tokens": 11674320896,
        "learning_rate": 0.00015282575120616245,
        "gradient_norm": 0.43647608160972595,
        "train_loss": 3.051325798034668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22268,
        "tokens": 11674845184,
        "learning_rate": 0.0001528041364972165,
        "gradient_norm": 0.38614651560783386,
        "train_loss": 3.0973856449127197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22269,
        "tokens": 11675369472,
        "learning_rate": 0.00015278252378283087,
        "gradient_norm": 0.5104835033416748,
        "train_loss": 3.0493040084838867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22270,
        "tokens": 11675893760,
        "learning_rate": 0.00015276091306324892,
        "gradient_norm": 0.3842688500881195,
        "train_loss": 3.130056858062744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22271,
        "tokens": 11676418048,
        "learning_rate": 0.00015273930433871372,
        "gradient_norm": 0.5249276757240295,
        "train_loss": 3.057781219482422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22272,
        "tokens": 11676942336,
        "learning_rate": 0.00015271769760946875,
        "gradient_norm": 0.4463345408439636,
        "train_loss": 3.0501279830932617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22273,
        "tokens": 11677466624,
        "learning_rate": 0.00015269609287575696,
        "gradient_norm": 0.44118788838386536,
        "train_loss": 3.023873805999756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22274,
        "tokens": 11677990912,
        "learning_rate": 0.0001526744901378217,
        "gradient_norm": 0.41310182213783264,
        "train_loss": 2.991515636444092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22275,
        "tokens": 11678515200,
        "learning_rate": 0.00015265288939590607,
        "gradient_norm": 0.4177664518356323,
        "train_loss": 3.0495901107788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22276,
        "tokens": 11679039488,
        "learning_rate": 0.00015263129065025335,
        "gradient_norm": 0.42288094758987427,
        "train_loss": 3.0117123126983643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22277,
        "tokens": 11679563776,
        "learning_rate": 0.00015260969390110642,
        "gradient_norm": 0.4220846891403198,
        "train_loss": 3.0206732749938965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22278,
        "tokens": 11680088064,
        "learning_rate": 0.0001525880991487085,
        "gradient_norm": 0.47703689336776733,
        "train_loss": 3.017333984375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22279,
        "tokens": 11680612352,
        "learning_rate": 0.0001525665063933028,
        "gradient_norm": 0.4076077938079834,
        "train_loss": 3.076246738433838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22280,
        "tokens": 11681136640,
        "learning_rate": 0.00015254491563513212,
        "gradient_norm": 0.4032764732837677,
        "train_loss": 3.014324426651001,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22281,
        "tokens": 11681660928,
        "learning_rate": 0.00015252332687443974,
        "gradient_norm": 0.4256727695465088,
        "train_loss": 3.0655221939086914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22282,
        "tokens": 11682185216,
        "learning_rate": 0.00015250174011146843,
        "gradient_norm": 0.4098663628101349,
        "train_loss": 3.0927700996398926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22283,
        "tokens": 11682709504,
        "learning_rate": 0.00015248015534646142,
        "gradient_norm": 0.4241162836551666,
        "train_loss": 3.0493130683898926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22284,
        "tokens": 11683233792,
        "learning_rate": 0.0001524585725796614,
        "gradient_norm": 0.36389830708503723,
        "train_loss": 3.0549519062042236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22285,
        "tokens": 11683758080,
        "learning_rate": 0.0001524369918113116,
        "gradient_norm": 0.4160495698451996,
        "train_loss": 3.0904159545898438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22286,
        "tokens": 11684282368,
        "learning_rate": 0.00015241541304165465,
        "gradient_norm": 0.4101496636867523,
        "train_loss": 3.0148327350616455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22287,
        "tokens": 11684806656,
        "learning_rate": 0.0001523938362709337,
        "gradient_norm": 0.5387670993804932,
        "train_loss": 3.1283817291259766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22288,
        "tokens": 11685330944,
        "learning_rate": 0.00015237226149939143,
        "gradient_norm": 0.4578286111354828,
        "train_loss": 3.063883066177368,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22289,
        "tokens": 11685855232,
        "learning_rate": 0.0001523506887272709,
        "gradient_norm": 0.5007954239845276,
        "train_loss": 3.037266254425049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22290,
        "tokens": 11686379520,
        "learning_rate": 0.00015232911795481468,
        "gradient_norm": 0.40194281935691833,
        "train_loss": 3.0446290969848633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22291,
        "tokens": 11686903808,
        "learning_rate": 0.00015230754918226582,
        "gradient_norm": 0.5020451545715332,
        "train_loss": 3.120328664779663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22292,
        "tokens": 11687428096,
        "learning_rate": 0.00015228598240986689,
        "gradient_norm": 0.45182615518569946,
        "train_loss": 3.1502938270568848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22293,
        "tokens": 11687952384,
        "learning_rate": 0.0001522644176378609,
        "gradient_norm": 0.4318106472492218,
        "train_loss": 3.028883457183838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22294,
        "tokens": 11688476672,
        "learning_rate": 0.00015224285486649028,
        "gradient_norm": 0.4227713942527771,
        "train_loss": 3.0465028285980225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22295,
        "tokens": 11689000960,
        "learning_rate": 0.000152221294095998,
        "gradient_norm": 0.41407260298728943,
        "train_loss": 3.0460922718048096,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22296,
        "tokens": 11689525248,
        "learning_rate": 0.00015219973532662663,
        "gradient_norm": 0.43524256348609924,
        "train_loss": 3.081956386566162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22297,
        "tokens": 11690049536,
        "learning_rate": 0.00015217817855861895,
        "gradient_norm": 0.44338804483413696,
        "train_loss": 3.0524587631225586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22298,
        "tokens": 11690573824,
        "learning_rate": 0.0001521566237922174,
        "gradient_norm": 0.44792845845222473,
        "train_loss": 3.02768611907959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22299,
        "tokens": 11691098112,
        "learning_rate": 0.00015213507102766484,
        "gradient_norm": 0.43469464778900146,
        "train_loss": 2.991931438446045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22300,
        "tokens": 11691622400,
        "learning_rate": 0.0001521135202652037,
        "gradient_norm": 0.46436282992362976,
        "train_loss": 3.0965540409088135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22301,
        "tokens": 11692146688,
        "learning_rate": 0.00015209197150507667,
        "gradient_norm": 0.39276495575904846,
        "train_loss": 3.074108600616455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22302,
        "tokens": 11692670976,
        "learning_rate": 0.00015207042474752624,
        "gradient_norm": 0.40632304549217224,
        "train_loss": 3.099229335784912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22303,
        "tokens": 11693195264,
        "learning_rate": 0.00015204887999279506,
        "gradient_norm": 0.43497928977012634,
        "train_loss": 3.0919952392578125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22304,
        "tokens": 11693719552,
        "learning_rate": 0.00015202733724112543,
        "gradient_norm": 0.4318029582500458,
        "train_loss": 3.039109230041504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22305,
        "tokens": 11694243840,
        "learning_rate": 0.00015200579649276007,
        "gradient_norm": 0.42817193269729614,
        "train_loss": 3.073108673095703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22306,
        "tokens": 11694768128,
        "learning_rate": 0.00015198425774794126,
        "gradient_norm": 0.400389701128006,
        "train_loss": 2.9999868869781494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22307,
        "tokens": 11695292416,
        "learning_rate": 0.00015196272100691165,
        "gradient_norm": 0.3867369294166565,
        "train_loss": 3.0514140129089355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22308,
        "tokens": 11695816704,
        "learning_rate": 0.00015194118626991342,
        "gradient_norm": 0.4064834713935852,
        "train_loss": 3.035306215286255,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22309,
        "tokens": 11696340992,
        "learning_rate": 0.00015191965353718914,
        "gradient_norm": 0.38708797097206116,
        "train_loss": 3.010951519012451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22310,
        "tokens": 11696865280,
        "learning_rate": 0.00015189812280898117,
        "gradient_norm": 0.3758475184440613,
        "train_loss": 3.0173213481903076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22311,
        "tokens": 11697389568,
        "learning_rate": 0.00015187659408553175,
        "gradient_norm": 0.4487704634666443,
        "train_loss": 3.197098970413208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22312,
        "tokens": 11697913856,
        "learning_rate": 0.00015185506736708343,
        "gradient_norm": 0.44863054156303406,
        "train_loss": 3.0801949501037598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22313,
        "tokens": 11698438144,
        "learning_rate": 0.00015183354265387825,
        "gradient_norm": 0.39644110202789307,
        "train_loss": 3.0215437412261963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22314,
        "tokens": 11698962432,
        "learning_rate": 0.0001518120199461588,
        "gradient_norm": 0.4898623526096344,
        "train_loss": 3.0033910274505615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22315,
        "tokens": 11699486720,
        "learning_rate": 0.00015179049924416707,
        "gradient_norm": 0.7017791271209717,
        "train_loss": 3.2588038444519043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22316,
        "tokens": 11700011008,
        "learning_rate": 0.00015176898054814546,
        "gradient_norm": 0.6900585293769836,
        "train_loss": 3.057873487472534,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22317,
        "tokens": 11700535296,
        "learning_rate": 0.00015174746385833608,
        "gradient_norm": 0.6020140051841736,
        "train_loss": 3.1116323471069336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22318,
        "tokens": 11701059584,
        "learning_rate": 0.00015172594917498122,
        "gradient_norm": 0.5462723970413208,
        "train_loss": 3.00246524810791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22319,
        "tokens": 11701583872,
        "learning_rate": 0.00015170443649832306,
        "gradient_norm": 0.5635059475898743,
        "train_loss": 3.0590438842773438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22320,
        "tokens": 11702108160,
        "learning_rate": 0.00015168292582860366,
        "gradient_norm": 0.49686405062675476,
        "train_loss": 3.1083908081054688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22321,
        "tokens": 11702632448,
        "learning_rate": 0.00015166141716606532,
        "gradient_norm": 0.4521617591381073,
        "train_loss": 3.026876449584961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22322,
        "tokens": 11703156736,
        "learning_rate": 0.0001516399105109499,
        "gradient_norm": 0.4390783905982971,
        "train_loss": 3.003605842590332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22323,
        "tokens": 11703681024,
        "learning_rate": 0.00015161840586349975,
        "gradient_norm": 0.42159074544906616,
        "train_loss": 3.007269859313965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22324,
        "tokens": 11704205312,
        "learning_rate": 0.00015159690322395672,
        "gradient_norm": 0.43152040243148804,
        "train_loss": 3.017982244491577,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22325,
        "tokens": 11704729600,
        "learning_rate": 0.00015157540259256298,
        "gradient_norm": 0.40987494587898254,
        "train_loss": 3.0031962394714355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22326,
        "tokens": 11705253888,
        "learning_rate": 0.0001515539039695604,
        "gradient_norm": 0.3770795166492462,
        "train_loss": 3.0134942531585693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22327,
        "tokens": 11705778176,
        "learning_rate": 0.00015153240735519118,
        "gradient_norm": 0.5207241773605347,
        "train_loss": 3.0792760848999023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22328,
        "tokens": 11706302464,
        "learning_rate": 0.0001515109127496971,
        "gradient_norm": 0.4461497664451599,
        "train_loss": 2.986992359161377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22329,
        "tokens": 11706826752,
        "learning_rate": 0.00015148942015332016,
        "gradient_norm": 0.42289042472839355,
        "train_loss": 3.034870147705078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22330,
        "tokens": 11707351040,
        "learning_rate": 0.00015146792956630242,
        "gradient_norm": 0.4437340199947357,
        "train_loss": 3.0872342586517334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22331,
        "tokens": 11707875328,
        "learning_rate": 0.0001514464409888856,
        "gradient_norm": 0.42670127749443054,
        "train_loss": 3.0043728351593018,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22332,
        "tokens": 11708399616,
        "learning_rate": 0.00015142495442131175,
        "gradient_norm": 0.42793944478034973,
        "train_loss": 3.0685911178588867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22333,
        "tokens": 11708923904,
        "learning_rate": 0.00015140346986382253,
        "gradient_norm": 0.4391629993915558,
        "train_loss": 3.0291426181793213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22334,
        "tokens": 11709448192,
        "learning_rate": 0.00015138198731665998,
        "gradient_norm": 0.45113903284072876,
        "train_loss": 3.0450077056884766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22335,
        "tokens": 11709972480,
        "learning_rate": 0.00015136050678006576,
        "gradient_norm": 0.4118995666503906,
        "train_loss": 3.050633430480957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22336,
        "tokens": 11710496768,
        "learning_rate": 0.00015133902825428174,
        "gradient_norm": 0.41648441553115845,
        "train_loss": 3.0465927124023438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22337,
        "tokens": 11711021056,
        "learning_rate": 0.00015131755173954963,
        "gradient_norm": 0.4043925404548645,
        "train_loss": 3.0740389823913574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22338,
        "tokens": 11711545344,
        "learning_rate": 0.00015129607723611118,
        "gradient_norm": 0.5202771425247192,
        "train_loss": 3.021002769470215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22339,
        "tokens": 11712069632,
        "learning_rate": 0.00015127460474420823,
        "gradient_norm": 0.39700913429260254,
        "train_loss": 3.017643928527832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22340,
        "tokens": 11712593920,
        "learning_rate": 0.0001512531342640823,
        "gradient_norm": 0.4513702392578125,
        "train_loss": 3.0226144790649414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22341,
        "tokens": 11713118208,
        "learning_rate": 0.00015123166579597528,
        "gradient_norm": 0.43548423051834106,
        "train_loss": 3.124016284942627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22342,
        "tokens": 11713642496,
        "learning_rate": 0.0001512101993401286,
        "gradient_norm": 0.4190509617328644,
        "train_loss": 3.0373129844665527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22343,
        "tokens": 11714166784,
        "learning_rate": 0.00015118873489678407,
        "gradient_norm": 0.3965366780757904,
        "train_loss": 3.0687789916992188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22344,
        "tokens": 11714691072,
        "learning_rate": 0.00015116727246618314,
        "gradient_norm": 0.3990480899810791,
        "train_loss": 3.0399904251098633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22345,
        "tokens": 11715215360,
        "learning_rate": 0.00015114581204856754,
        "gradient_norm": 0.3890657126903534,
        "train_loss": 3.0751068592071533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22346,
        "tokens": 11715739648,
        "learning_rate": 0.00015112435364417873,
        "gradient_norm": 0.38479912281036377,
        "train_loss": 3.060631513595581,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22347,
        "tokens": 11716263936,
        "learning_rate": 0.00015110289725325836,
        "gradient_norm": 0.3990112841129303,
        "train_loss": 3.052974224090576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22348,
        "tokens": 11716788224,
        "learning_rate": 0.0001510814428760478,
        "gradient_norm": 0.4148588478565216,
        "train_loss": 3.0351457595825195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22349,
        "tokens": 11717312512,
        "learning_rate": 0.00015105999051278862,
        "gradient_norm": 0.38256245851516724,
        "train_loss": 3.0470094680786133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22350,
        "tokens": 11717836800,
        "learning_rate": 0.00015103854016372239,
        "gradient_norm": 0.4396626651287079,
        "train_loss": 3.128279685974121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22351,
        "tokens": 11718361088,
        "learning_rate": 0.00015101709182909037,
        "gradient_norm": 0.4610081613063812,
        "train_loss": 3.172621965408325,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22352,
        "tokens": 11718885376,
        "learning_rate": 0.0001509956455091342,
        "gradient_norm": 0.4536915123462677,
        "train_loss": 3.026212215423584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22353,
        "tokens": 11719409664,
        "learning_rate": 0.00015097420120409506,
        "gradient_norm": 0.5243606567382812,
        "train_loss": 3.057856559753418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22354,
        "tokens": 11719933952,
        "learning_rate": 0.00015095275891421458,
        "gradient_norm": 0.42489999532699585,
        "train_loss": 3.018974781036377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22355,
        "tokens": 11720458240,
        "learning_rate": 0.00015093131863973388,
        "gradient_norm": 0.4610358774662018,
        "train_loss": 3.0412144660949707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22356,
        "tokens": 11720982528,
        "learning_rate": 0.0001509098803808945,
        "gradient_norm": 0.43743211030960083,
        "train_loss": 3.031458854675293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22357,
        "tokens": 11721506816,
        "learning_rate": 0.00015088844413793754,
        "gradient_norm": 0.41287049651145935,
        "train_loss": 3.052464485168457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22358,
        "tokens": 11722031104,
        "learning_rate": 0.00015086700991110444,
        "gradient_norm": 0.4446176588535309,
        "train_loss": 3.088134765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22359,
        "tokens": 11722555392,
        "learning_rate": 0.0001508455777006365,
        "gradient_norm": 0.44696125388145447,
        "train_loss": 3.0933761596679688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22360,
        "tokens": 11723079680,
        "learning_rate": 0.0001508241475067748,
        "gradient_norm": 0.4241984486579895,
        "train_loss": 2.981083869934082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22361,
        "tokens": 11723603968,
        "learning_rate": 0.0001508027193297608,
        "gradient_norm": 0.38316282629966736,
        "train_loss": 3.0159528255462646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22362,
        "tokens": 11724128256,
        "learning_rate": 0.00015078129316983547,
        "gradient_norm": 0.42696690559387207,
        "train_loss": 3.033191204071045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22363,
        "tokens": 11724652544,
        "learning_rate": 0.00015075986902724018,
        "gradient_norm": 0.4645443558692932,
        "train_loss": 3.1634464263916016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22364,
        "tokens": 11725176832,
        "learning_rate": 0.0001507384469022159,
        "gradient_norm": 0.4025912582874298,
        "train_loss": 3.0388946533203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22365,
        "tokens": 11725701120,
        "learning_rate": 0.00015071702679500393,
        "gradient_norm": 0.4933323264122009,
        "train_loss": 3.0386762619018555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22366,
        "tokens": 11726225408,
        "learning_rate": 0.00015069560870584523,
        "gradient_norm": 0.4380043148994446,
        "train_loss": 3.011049747467041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22367,
        "tokens": 11726749696,
        "learning_rate": 0.00015067419263498105,
        "gradient_norm": 0.4481225907802582,
        "train_loss": 3.0414557456970215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22368,
        "tokens": 11727273984,
        "learning_rate": 0.00015065277858265227,
        "gradient_norm": 0.44610172510147095,
        "train_loss": 3.0120112895965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22369,
        "tokens": 11727798272,
        "learning_rate": 0.00015063136654910002,
        "gradient_norm": 0.42674770951271057,
        "train_loss": 2.9617788791656494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22370,
        "tokens": 11728322560,
        "learning_rate": 0.00015060995653456548,
        "gradient_norm": 0.4162847101688385,
        "train_loss": 3.030869483947754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22371,
        "tokens": 11728846848,
        "learning_rate": 0.00015058854853928935,
        "gradient_norm": 0.39500096440315247,
        "train_loss": 3.0322115421295166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22372,
        "tokens": 11729371136,
        "learning_rate": 0.00015056714256351283,
        "gradient_norm": 0.4209115505218506,
        "train_loss": 3.0549213886260986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22373,
        "tokens": 11729895424,
        "learning_rate": 0.00015054573860747672,
        "gradient_norm": 0.4122275710105896,
        "train_loss": 3.038282871246338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22374,
        "tokens": 11730419712,
        "learning_rate": 0.0001505243366714221,
        "gradient_norm": 0.44384685158729553,
        "train_loss": 2.9888694286346436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22375,
        "tokens": 11730944000,
        "learning_rate": 0.0001505029367555897,
        "gradient_norm": 0.41796717047691345,
        "train_loss": 3.039018392562866,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22376,
        "tokens": 11731468288,
        "learning_rate": 0.00015048153886022063,
        "gradient_norm": 0.41978710889816284,
        "train_loss": 3.0628767013549805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22377,
        "tokens": 11731992576,
        "learning_rate": 0.00015046014298555546,
        "gradient_norm": 0.42873120307922363,
        "train_loss": 3.0561938285827637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22378,
        "tokens": 11732516864,
        "learning_rate": 0.00015043874913183523,
        "gradient_norm": 0.3956533372402191,
        "train_loss": 3.056432008743286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22379,
        "tokens": 11733041152,
        "learning_rate": 0.0001504173572993008,
        "gradient_norm": 0.44676172733306885,
        "train_loss": 3.0089378356933594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22380,
        "tokens": 11733565440,
        "learning_rate": 0.00015039596748819272,
        "gradient_norm": 0.46437227725982666,
        "train_loss": 3.0339560508728027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22381,
        "tokens": 11734089728,
        "learning_rate": 0.00015037457969875205,
        "gradient_norm": 0.3928340673446655,
        "train_loss": 3.036224842071533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22382,
        "tokens": 11734614016,
        "learning_rate": 0.00015035319393121932,
        "gradient_norm": 0.4788863956928253,
        "train_loss": 3.073209285736084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22383,
        "tokens": 11735138304,
        "learning_rate": 0.00015033181018583538,
        "gradient_norm": 0.4339843690395355,
        "train_loss": 3.0651416778564453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22384,
        "tokens": 11735662592,
        "learning_rate": 0.0001503104284628408,
        "gradient_norm": 0.47053611278533936,
        "train_loss": 3.0434627532958984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22385,
        "tokens": 11736186880,
        "learning_rate": 0.00015028904876247644,
        "gradient_norm": 0.6113222241401672,
        "train_loss": 3.000504970550537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22386,
        "tokens": 11736711168,
        "learning_rate": 0.0001502676710849827,
        "gradient_norm": 0.5300238728523254,
        "train_loss": 3.0761160850524902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22387,
        "tokens": 11737235456,
        "learning_rate": 0.00015024629543060049,
        "gradient_norm": 0.467342734336853,
        "train_loss": 3.010477066040039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22388,
        "tokens": 11737759744,
        "learning_rate": 0.00015022492179957023,
        "gradient_norm": 0.49997803568840027,
        "train_loss": 3.0124549865722656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22389,
        "tokens": 11738284032,
        "learning_rate": 0.0001502035501921326,
        "gradient_norm": 0.4866378605365753,
        "train_loss": 2.9786829948425293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22390,
        "tokens": 11738808320,
        "learning_rate": 0.00015018218060852814,
        "gradient_norm": 0.4227590560913086,
        "train_loss": 3.0227365493774414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22391,
        "tokens": 11739332608,
        "learning_rate": 0.00015016081304899736,
        "gradient_norm": 0.4904021918773651,
        "train_loss": 3.0634992122650146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22392,
        "tokens": 11739856896,
        "learning_rate": 0.00015013944751378084,
        "gradient_norm": 0.44225385785102844,
        "train_loss": 3.038702964782715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22393,
        "tokens": 11740381184,
        "learning_rate": 0.000150118084003119,
        "gradient_norm": 0.5024958252906799,
        "train_loss": 3.042271614074707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22394,
        "tokens": 11740905472,
        "learning_rate": 0.00015009672251725242,
        "gradient_norm": 0.46411484479904175,
        "train_loss": 2.9700369834899902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22395,
        "tokens": 11741429760,
        "learning_rate": 0.0001500753630564214,
        "gradient_norm": 0.4399157464504242,
        "train_loss": 3.040914535522461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22396,
        "tokens": 11741954048,
        "learning_rate": 0.00015005400562086656,
        "gradient_norm": 0.49288398027420044,
        "train_loss": 3.0067801475524902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22397,
        "tokens": 11742478336,
        "learning_rate": 0.00015003265021082808,
        "gradient_norm": 0.4083020091056824,
        "train_loss": 3.000779390335083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22398,
        "tokens": 11743002624,
        "learning_rate": 0.00015001129682654655,
        "gradient_norm": 0.517678439617157,
        "train_loss": 3.0497069358825684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22399,
        "tokens": 11743526912,
        "learning_rate": 0.00014998994546826214,
        "gradient_norm": 0.4332732856273651,
        "train_loss": 3.0156967639923096,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22400,
        "tokens": 11744051200,
        "learning_rate": 0.00014996859613621537,
        "gradient_norm": 0.505325436592102,
        "train_loss": 3.072871446609497,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22401,
        "tokens": 11744575488,
        "learning_rate": 0.00014994724883064637,
        "gradient_norm": 0.45958128571510315,
        "train_loss": 3.038806915283203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22402,
        "tokens": 11745099776,
        "learning_rate": 0.00014992590355179564,
        "gradient_norm": 0.4212161898612976,
        "train_loss": 3.060448169708252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22403,
        "tokens": 11745624064,
        "learning_rate": 0.00014990456029990323,
        "gradient_norm": 0.46511319279670715,
        "train_loss": 3.114497661590576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22404,
        "tokens": 11746148352,
        "learning_rate": 0.0001498832190752096,
        "gradient_norm": 0.42258337140083313,
        "train_loss": 3.014738082885742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22405,
        "tokens": 11746672640,
        "learning_rate": 0.00014986187987795472,
        "gradient_norm": 0.4192866384983063,
        "train_loss": 3.0284104347229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22406,
        "tokens": 11747196928,
        "learning_rate": 0.00014984054270837907,
        "gradient_norm": 0.4196119010448456,
        "train_loss": 3.045943260192871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22407,
        "tokens": 11747721216,
        "learning_rate": 0.00014981920756672258,
        "gradient_norm": 0.5148369669914246,
        "train_loss": 3.0570545196533203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22408,
        "tokens": 11748245504,
        "learning_rate": 0.0001497978744532256,
        "gradient_norm": 0.4090302288532257,
        "train_loss": 3.0736989974975586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22409,
        "tokens": 11748769792,
        "learning_rate": 0.00014977654336812806,
        "gradient_norm": 0.5113691091537476,
        "train_loss": 3.10081148147583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22410,
        "tokens": 11749294080,
        "learning_rate": 0.0001497552143116703,
        "gradient_norm": 0.45701006054878235,
        "train_loss": 2.9869823455810547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22411,
        "tokens": 11749818368,
        "learning_rate": 0.00014973388728409218,
        "gradient_norm": 0.48715487122535706,
        "train_loss": 3.0989015102386475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22412,
        "tokens": 11750342656,
        "learning_rate": 0.000149712562285634,
        "gradient_norm": 0.5292164087295532,
        "train_loss": 3.0342588424682617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22413,
        "tokens": 11750866944,
        "learning_rate": 0.00014969123931653553,
        "gradient_norm": 0.40649721026420593,
        "train_loss": 3.0456724166870117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22414,
        "tokens": 11751391232,
        "learning_rate": 0.000149669918377037,
        "gradient_norm": 0.4883320927619934,
        "train_loss": 2.9916677474975586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22415,
        "tokens": 11751915520,
        "learning_rate": 0.00014964859946737824,
        "gradient_norm": 0.4312427043914795,
        "train_loss": 2.9747657775878906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22416,
        "tokens": 11752439808,
        "learning_rate": 0.00014962728258779943,
        "gradient_norm": 0.47762882709503174,
        "train_loss": 3.035748243331909,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22417,
        "tokens": 11752964096,
        "learning_rate": 0.00014960596773854026,
        "gradient_norm": 0.4205913841724396,
        "train_loss": 3.028188705444336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22418,
        "tokens": 11753488384,
        "learning_rate": 0.00014958465491984082,
        "gradient_norm": 0.5064985752105713,
        "train_loss": 3.103794813156128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22419,
        "tokens": 11754012672,
        "learning_rate": 0.00014956334413194111,
        "gradient_norm": 0.4454348385334015,
        "train_loss": 3.0074119567871094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22420,
        "tokens": 11754536960,
        "learning_rate": 0.00014954203537508073,
        "gradient_norm": 0.42900702357292175,
        "train_loss": 3.0088956356048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22421,
        "tokens": 11755061248,
        "learning_rate": 0.00014952072864949978,
        "gradient_norm": 0.4304727017879486,
        "train_loss": 3.091167688369751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22422,
        "tokens": 11755585536,
        "learning_rate": 0.00014949942395543796,
        "gradient_norm": 0.40427982807159424,
        "train_loss": 3.036351203918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22423,
        "tokens": 11756109824,
        "learning_rate": 0.00014947812129313518,
        "gradient_norm": 0.47264721989631653,
        "train_loss": 3.063992500305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22424,
        "tokens": 11756634112,
        "learning_rate": 0.00014945682066283108,
        "gradient_norm": 0.5215283632278442,
        "train_loss": 3.040018320083618,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22425,
        "tokens": 11757158400,
        "learning_rate": 0.0001494355220647656,
        "gradient_norm": 0.4534798860549927,
        "train_loss": 3.033493757247925,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22426,
        "tokens": 11757682688,
        "learning_rate": 0.0001494142254991783,
        "gradient_norm": 0.4200748801231384,
        "train_loss": 3.068145751953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22427,
        "tokens": 11758206976,
        "learning_rate": 0.00014939293096630912,
        "gradient_norm": 0.4500306248664856,
        "train_loss": 2.9862842559814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22428,
        "tokens": 11758731264,
        "learning_rate": 0.00014937163846639757,
        "gradient_norm": 0.442909300327301,
        "train_loss": 3.0456676483154297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22429,
        "tokens": 11759255552,
        "learning_rate": 0.00014935034799968335,
        "gradient_norm": 0.4428097903728485,
        "train_loss": 3.0572519302368164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22430,
        "tokens": 11759779840,
        "learning_rate": 0.00014932905956640622,
        "gradient_norm": 0.519012987613678,
        "train_loss": 3.031693935394287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22431,
        "tokens": 11760304128,
        "learning_rate": 0.00014930777316680567,
        "gradient_norm": 0.412855863571167,
        "train_loss": 3.0166778564453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22432,
        "tokens": 11760828416,
        "learning_rate": 0.00014928648880112145,
        "gradient_norm": 0.4757862687110901,
        "train_loss": 3.0544862747192383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22433,
        "tokens": 11761352704,
        "learning_rate": 0.00014926520646959298,
        "gradient_norm": 0.450994610786438,
        "train_loss": 3.095383644104004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22434,
        "tokens": 11761876992,
        "learning_rate": 0.00014924392617245998,
        "gradient_norm": 0.40435343980789185,
        "train_loss": 3.025906562805176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22435,
        "tokens": 11762401280,
        "learning_rate": 0.00014922264790996186,
        "gradient_norm": 0.3964490592479706,
        "train_loss": 3.042165994644165,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22436,
        "tokens": 11762925568,
        "learning_rate": 0.00014920137168233824,
        "gradient_norm": 0.4058198630809784,
        "train_loss": 2.9976706504821777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22437,
        "tokens": 11763449856,
        "learning_rate": 0.0001491800974898285,
        "gradient_norm": 0.44353827834129333,
        "train_loss": 3.0610597133636475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22438,
        "tokens": 11763974144,
        "learning_rate": 0.00014915882533267212,
        "gradient_norm": 0.4326512813568115,
        "train_loss": 3.0356807708740234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22439,
        "tokens": 11764498432,
        "learning_rate": 0.00014913755521110867,
        "gradient_norm": 0.4684246778488159,
        "train_loss": 3.0599164962768555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22440,
        "tokens": 11765022720,
        "learning_rate": 0.00014911628712537743,
        "gradient_norm": 0.3862188756465912,
        "train_loss": 2.989793062210083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22441,
        "tokens": 11765547008,
        "learning_rate": 0.0001490950210757179,
        "gradient_norm": 0.400168240070343,
        "train_loss": 2.9957001209259033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22442,
        "tokens": 11766071296,
        "learning_rate": 0.0001490737570623694,
        "gradient_norm": 0.42289304733276367,
        "train_loss": 3.023167610168457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22443,
        "tokens": 11766595584,
        "learning_rate": 0.00014905249508557133,
        "gradient_norm": 0.39120790362358093,
        "train_loss": 3.0630059242248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22444,
        "tokens": 11767119872,
        "learning_rate": 0.0001490312351455629,
        "gradient_norm": 0.392084002494812,
        "train_loss": 3.045372486114502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22445,
        "tokens": 11767644160,
        "learning_rate": 0.0001490099772425836,
        "gradient_norm": 0.4286435544490814,
        "train_loss": 3.0601983070373535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22446,
        "tokens": 11768168448,
        "learning_rate": 0.00014898872137687248,
        "gradient_norm": 0.4970620572566986,
        "train_loss": 3.1738338470458984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22447,
        "tokens": 11768692736,
        "learning_rate": 0.00014896746754866912,
        "gradient_norm": 0.3862350285053253,
        "train_loss": 3.04929256439209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22448,
        "tokens": 11769217024,
        "learning_rate": 0.0001489462157582124,
        "gradient_norm": 0.45396560430526733,
        "train_loss": 3.0290138721466064,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22449,
        "tokens": 11769741312,
        "learning_rate": 0.00014892496600574175,
        "gradient_norm": 0.38515689969062805,
        "train_loss": 2.9991068840026855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22450,
        "tokens": 11770265600,
        "learning_rate": 0.0001489037182914964,
        "gradient_norm": 0.42475512623786926,
        "train_loss": 3.0868053436279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22451,
        "tokens": 11770789888,
        "learning_rate": 0.00014888247261571536,
        "gradient_norm": 0.38084301352500916,
        "train_loss": 3.1228179931640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22452,
        "tokens": 11771314176,
        "learning_rate": 0.00014886122897863797,
        "gradient_norm": 0.41292062401771545,
        "train_loss": 3.020632266998291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22453,
        "tokens": 11771838464,
        "learning_rate": 0.00014883998738050313,
        "gradient_norm": 0.43521055579185486,
        "train_loss": 3.0305676460266113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22454,
        "tokens": 11772362752,
        "learning_rate": 0.00014881874782155012,
        "gradient_norm": 0.4174308180809021,
        "train_loss": 3.1099257469177246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22455,
        "tokens": 11772887040,
        "learning_rate": 0.00014879751030201792,
        "gradient_norm": 0.4108383357524872,
        "train_loss": 3.0520975589752197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22456,
        "tokens": 11773411328,
        "learning_rate": 0.00014877627482214566,
        "gradient_norm": 0.4127615988254547,
        "train_loss": 3.0024328231811523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22457,
        "tokens": 11773935616,
        "learning_rate": 0.00014875504138217225,
        "gradient_norm": 0.40983298420906067,
        "train_loss": 3.015166759490967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22458,
        "tokens": 11774459904,
        "learning_rate": 0.0001487338099823368,
        "gradient_norm": 0.4750257730484009,
        "train_loss": 3.0423524379730225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22459,
        "tokens": 11774984192,
        "learning_rate": 0.00014871258062287832,
        "gradient_norm": 0.40141186118125916,
        "train_loss": 3.0385918617248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22460,
        "tokens": 11775508480,
        "learning_rate": 0.00014869135330403566,
        "gradient_norm": 0.42943739891052246,
        "train_loss": 2.98738956451416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22461,
        "tokens": 11776032768,
        "learning_rate": 0.0001486701280260479,
        "gradient_norm": 0.427390456199646,
        "train_loss": 3.0269553661346436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22462,
        "tokens": 11776557056,
        "learning_rate": 0.00014864890478915384,
        "gradient_norm": 0.43090111017227173,
        "train_loss": 3.0488617420196533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22463,
        "tokens": 11777081344,
        "learning_rate": 0.00014862768359359246,
        "gradient_norm": 0.4698447585105896,
        "train_loss": 3.0666913986206055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22464,
        "tokens": 11777605632,
        "learning_rate": 0.00014860646443960252,
        "gradient_norm": 0.4641614258289337,
        "train_loss": 3.0322909355163574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22465,
        "tokens": 11778129920,
        "learning_rate": 0.00014858524732742304,
        "gradient_norm": 0.4129808843135834,
        "train_loss": 3.022913932800293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22466,
        "tokens": 11778654208,
        "learning_rate": 0.0001485640322572926,
        "gradient_norm": 0.4197259247303009,
        "train_loss": 3.0191924571990967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22467,
        "tokens": 11779178496,
        "learning_rate": 0.0001485428192294502,
        "gradient_norm": 0.4036637544631958,
        "train_loss": 3.0109004974365234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22468,
        "tokens": 11779702784,
        "learning_rate": 0.0001485216082441346,
        "gradient_norm": 0.4998071491718292,
        "train_loss": 3.1102702617645264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22469,
        "tokens": 11780227072,
        "learning_rate": 0.00014850039930158445,
        "gradient_norm": 0.4599326252937317,
        "train_loss": 3.032618522644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22470,
        "tokens": 11780751360,
        "learning_rate": 0.00014847919240203866,
        "gradient_norm": 0.45898687839508057,
        "train_loss": 3.0634403228759766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22471,
        "tokens": 11781275648,
        "learning_rate": 0.0001484579875457357,
        "gradient_norm": 0.40806546807289124,
        "train_loss": 3.0286624431610107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22472,
        "tokens": 11781799936,
        "learning_rate": 0.0001484367847329145,
        "gradient_norm": 0.4804060459136963,
        "train_loss": 3.078911304473877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22473,
        "tokens": 11782324224,
        "learning_rate": 0.00014841558396381352,
        "gradient_norm": 0.41991686820983887,
        "train_loss": 3.028946876525879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22474,
        "tokens": 11782848512,
        "learning_rate": 0.00014839438523867157,
        "gradient_norm": 0.5051066279411316,
        "train_loss": 3.0797386169433594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22475,
        "tokens": 11783372800,
        "learning_rate": 0.00014837318855772714,
        "gradient_norm": 0.44298920035362244,
        "train_loss": 3.000295877456665,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22476,
        "tokens": 11783897088,
        "learning_rate": 0.00014835199392121895,
        "gradient_norm": 0.4330112636089325,
        "train_loss": 3.035202980041504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22477,
        "tokens": 11784421376,
        "learning_rate": 0.0001483308013293854,
        "gradient_norm": 0.4403800070285797,
        "train_loss": 3.0773143768310547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22478,
        "tokens": 11784945664,
        "learning_rate": 0.00014830961078246514,
        "gradient_norm": 0.5302718281745911,
        "train_loss": 3.0646114349365234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22479,
        "tokens": 11785469952,
        "learning_rate": 0.0001482884222806968,
        "gradient_norm": 0.4088946580886841,
        "train_loss": 3.045635223388672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22480,
        "tokens": 11785994240,
        "learning_rate": 0.00014826723582431867,
        "gradient_norm": 0.46607160568237305,
        "train_loss": 3.015085220336914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22481,
        "tokens": 11786518528,
        "learning_rate": 0.00014824605141356944,
        "gradient_norm": 0.3944624960422516,
        "train_loss": 3.0512094497680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22482,
        "tokens": 11787042816,
        "learning_rate": 0.0001482248690486873,
        "gradient_norm": 0.5144782662391663,
        "train_loss": 3.0124943256378174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22483,
        "tokens": 11787567104,
        "learning_rate": 0.000148203688729911,
        "gradient_norm": 0.40841954946517944,
        "train_loss": 3.0880513191223145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22484,
        "tokens": 11788091392,
        "learning_rate": 0.00014818251045747876,
        "gradient_norm": 0.6294196248054504,
        "train_loss": 3.131068468093872,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22485,
        "tokens": 11788615680,
        "learning_rate": 0.00014816133423162903,
        "gradient_norm": 0.4861021041870117,
        "train_loss": 3.0967023372650146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22486,
        "tokens": 11789139968,
        "learning_rate": 0.00014814016005260008,
        "gradient_norm": 0.5718456506729126,
        "train_loss": 3.0797863006591797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22487,
        "tokens": 11789664256,
        "learning_rate": 0.00014811898792063032,
        "gradient_norm": 0.5336117148399353,
        "train_loss": 3.0384268760681152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22488,
        "tokens": 11790188544,
        "learning_rate": 0.00014809781783595816,
        "gradient_norm": 0.4398116171360016,
        "train_loss": 3.0138137340545654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22489,
        "tokens": 11790712832,
        "learning_rate": 0.0001480766497988217,
        "gradient_norm": 0.4378752112388611,
        "train_loss": 3.0580644607543945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22490,
        "tokens": 11791237120,
        "learning_rate": 0.00014805548380945945,
        "gradient_norm": 0.51207035779953,
        "train_loss": 3.1289618015289307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22491,
        "tokens": 11791761408,
        "learning_rate": 0.0001480343198681094,
        "gradient_norm": 0.4201796352863312,
        "train_loss": 3.046175956726074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22492,
        "tokens": 11792285696,
        "learning_rate": 0.00014801315797501003,
        "gradient_norm": 0.4868115782737732,
        "train_loss": 3.0878381729125977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22493,
        "tokens": 11792809984,
        "learning_rate": 0.00014799199813039928,
        "gradient_norm": 0.4189525246620178,
        "train_loss": 3.013188362121582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22494,
        "tokens": 11793334272,
        "learning_rate": 0.0001479708403345156,
        "gradient_norm": 0.4300863444805145,
        "train_loss": 3.040205955505371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22495,
        "tokens": 11793858560,
        "learning_rate": 0.00014794968458759693,
        "gradient_norm": 0.4130055010318756,
        "train_loss": 3.0217268466949463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22496,
        "tokens": 11794382848,
        "learning_rate": 0.00014792853088988156,
        "gradient_norm": 0.4231003224849701,
        "train_loss": 3.0191240310668945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22497,
        "tokens": 11794907136,
        "learning_rate": 0.00014790737924160748,
        "gradient_norm": 0.5454322695732117,
        "train_loss": 2.988644599914551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22498,
        "tokens": 11795431424,
        "learning_rate": 0.00014788622964301287,
        "gradient_norm": 0.3891410827636719,
        "train_loss": 3.0518670082092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22499,
        "tokens": 11795955712,
        "learning_rate": 0.00014786508209433568,
        "gradient_norm": 0.453902006149292,
        "train_loss": 3.027798891067505,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22500,
        "tokens": 11796480000,
        "learning_rate": 0.00014784393659581413,
        "gradient_norm": 0.40621912479400635,
        "train_loss": 3.003075122833252,
        "val_loss": 2.999722480773926,
        "hellaswag_acc": 0.28579962253570557,
        "hellaswag_acc_norm": 0.29635530710220337
    },
    {
        "step": 22501,
        "tokens": 11797004288,
        "learning_rate": 0.00014782279314768607,
        "gradient_norm": 0.47838953137397766,
        "train_loss": 3.034506320953369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22502,
        "tokens": 11797528576,
        "learning_rate": 0.00014780165175018963,
        "gradient_norm": 0.4212299585342407,
        "train_loss": 3.068107843399048,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22503,
        "tokens": 11798052864,
        "learning_rate": 0.0001477805124035626,
        "gradient_norm": 0.4166935384273529,
        "train_loss": 3.043943405151367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22504,
        "tokens": 11798577152,
        "learning_rate": 0.00014775937510804317,
        "gradient_norm": 0.3703369200229645,
        "train_loss": 3.030578136444092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22505,
        "tokens": 11799101440,
        "learning_rate": 0.00014773823986386904,
        "gradient_norm": 0.4027601480484009,
        "train_loss": 3.077439785003662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22506,
        "tokens": 11799625728,
        "learning_rate": 0.00014771710667127832,
        "gradient_norm": 0.38984063267707825,
        "train_loss": 3.008711338043213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22507,
        "tokens": 11800150016,
        "learning_rate": 0.00014769597553050868,
        "gradient_norm": 0.396506667137146,
        "train_loss": 3.0095362663269043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22508,
        "tokens": 11800674304,
        "learning_rate": 0.00014767484644179815,
        "gradient_norm": 0.41819724440574646,
        "train_loss": 3.0351340770721436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22509,
        "tokens": 11801198592,
        "learning_rate": 0.00014765371940538447,
        "gradient_norm": 0.4020562767982483,
        "train_loss": 3.014864921569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22510,
        "tokens": 11801722880,
        "learning_rate": 0.0001476325944215055,
        "gradient_norm": 0.38110360503196716,
        "train_loss": 3.031834602355957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22511,
        "tokens": 11802247168,
        "learning_rate": 0.000147611471490399,
        "gradient_norm": 0.4375819265842438,
        "train_loss": 3.106278419494629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22512,
        "tokens": 11802771456,
        "learning_rate": 0.00014759035061230274,
        "gradient_norm": 0.3680957853794098,
        "train_loss": 3.0009512901306152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22513,
        "tokens": 11803295744,
        "learning_rate": 0.00014756923178745442,
        "gradient_norm": 0.4278186857700348,
        "train_loss": 3.088203191757202,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22514,
        "tokens": 11803820032,
        "learning_rate": 0.00014754811501609187,
        "gradient_norm": 0.39140552282333374,
        "train_loss": 3.047393798828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22515,
        "tokens": 11804344320,
        "learning_rate": 0.00014752700029845267,
        "gradient_norm": 0.3786468505859375,
        "train_loss": 3.0724575519561768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22516,
        "tokens": 11804868608,
        "learning_rate": 0.00014750588763477458,
        "gradient_norm": 0.3971719741821289,
        "train_loss": 3.009700298309326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22517,
        "tokens": 11805392896,
        "learning_rate": 0.00014748477702529515,
        "gradient_norm": 0.4451450705528259,
        "train_loss": 3.1173782348632812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22518,
        "tokens": 11805917184,
        "learning_rate": 0.00014746366847025207,
        "gradient_norm": 0.452248215675354,
        "train_loss": 3.0155563354492188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22519,
        "tokens": 11806441472,
        "learning_rate": 0.00014744256196988302,
        "gradient_norm": 0.385491281747818,
        "train_loss": 3.0689990520477295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22520,
        "tokens": 11806965760,
        "learning_rate": 0.00014742145752442542,
        "gradient_norm": 0.4427376687526703,
        "train_loss": 3.1130082607269287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22521,
        "tokens": 11807490048,
        "learning_rate": 0.000147400355134117,
        "gradient_norm": 0.41672927141189575,
        "train_loss": 3.0011496543884277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22522,
        "tokens": 11808014336,
        "learning_rate": 0.0001473792547991951,
        "gradient_norm": 0.4932602643966675,
        "train_loss": 3.0768465995788574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22523,
        "tokens": 11808538624,
        "learning_rate": 0.0001473581565198974,
        "gradient_norm": 0.43694770336151123,
        "train_loss": 3.066861391067505,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22524,
        "tokens": 11809062912,
        "learning_rate": 0.00014733706029646123,
        "gradient_norm": 0.46693217754364014,
        "train_loss": 3.032421112060547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22525,
        "tokens": 11809587200,
        "learning_rate": 0.00014731596612912423,
        "gradient_norm": 0.5127546191215515,
        "train_loss": 3.0546956062316895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22526,
        "tokens": 11810111488,
        "learning_rate": 0.0001472948740181237,
        "gradient_norm": 0.41236984729766846,
        "train_loss": 3.1176986694335938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22527,
        "tokens": 11810635776,
        "learning_rate": 0.00014727378396369708,
        "gradient_norm": 0.42431119084358215,
        "train_loss": 3.05417537689209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22528,
        "tokens": 11811160064,
        "learning_rate": 0.0001472526959660819,
        "gradient_norm": 0.4210484027862549,
        "train_loss": 3.0509228706359863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22529,
        "tokens": 11811684352,
        "learning_rate": 0.00014723161002551535,
        "gradient_norm": 0.5181581974029541,
        "train_loss": 3.118342399597168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22530,
        "tokens": 11812208640,
        "learning_rate": 0.0001472105261422349,
        "gradient_norm": 0.44863852858543396,
        "train_loss": 3.0408780574798584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22531,
        "tokens": 11812732928,
        "learning_rate": 0.00014718944431647775,
        "gradient_norm": 0.41250407695770264,
        "train_loss": 3.0932514667510986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22532,
        "tokens": 11813257216,
        "learning_rate": 0.0001471683645484814,
        "gradient_norm": 0.481042742729187,
        "train_loss": 3.087398052215576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22533,
        "tokens": 11813781504,
        "learning_rate": 0.0001471472868384829,
        "gradient_norm": 0.47419917583465576,
        "train_loss": 3.021836280822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22534,
        "tokens": 11814305792,
        "learning_rate": 0.00014712621118671972,
        "gradient_norm": 0.41181525588035583,
        "train_loss": 3.0615954399108887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22535,
        "tokens": 11814830080,
        "learning_rate": 0.00014710513759342891,
        "gradient_norm": 0.3898387551307678,
        "train_loss": 3.0627524852752686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22536,
        "tokens": 11815354368,
        "learning_rate": 0.00014708406605884786,
        "gradient_norm": 0.45214134454727173,
        "train_loss": 3.06375789642334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22537,
        "tokens": 11815878656,
        "learning_rate": 0.00014706299658321352,
        "gradient_norm": 0.3966023623943329,
        "train_loss": 3.0283474922180176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22538,
        "tokens": 11816402944,
        "learning_rate": 0.00014704192916676324,
        "gradient_norm": 0.40849560499191284,
        "train_loss": 3.030940055847168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22539,
        "tokens": 11816927232,
        "learning_rate": 0.00014702086380973418,
        "gradient_norm": 0.4570119380950928,
        "train_loss": 3.085923433303833,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22540,
        "tokens": 11817451520,
        "learning_rate": 0.0001469998005123633,
        "gradient_norm": 0.4500123858451843,
        "train_loss": 3.0162761211395264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22541,
        "tokens": 11817975808,
        "learning_rate": 0.00014697873927488786,
        "gradient_norm": 0.44928163290023804,
        "train_loss": 2.9647347927093506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22542,
        "tokens": 11818500096,
        "learning_rate": 0.00014695768009754476,
        "gradient_norm": 0.40597885847091675,
        "train_loss": 3.023517608642578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22543,
        "tokens": 11819024384,
        "learning_rate": 0.00014693662298057128,
        "gradient_norm": 0.4154856503009796,
        "train_loss": 3.0423145294189453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22544,
        "tokens": 11819548672,
        "learning_rate": 0.00014691556792420415,
        "gradient_norm": 0.39733371138572693,
        "train_loss": 3.0405006408691406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22545,
        "tokens": 11820072960,
        "learning_rate": 0.00014689451492868065,
        "gradient_norm": 0.3991404175758362,
        "train_loss": 3.0418930053710938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22546,
        "tokens": 11820597248,
        "learning_rate": 0.0001468734639942375,
        "gradient_norm": 0.3933497667312622,
        "train_loss": 3.045248508453369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22547,
        "tokens": 11821121536,
        "learning_rate": 0.00014685241512111182,
        "gradient_norm": 0.3572632968425751,
        "train_loss": 2.990658760070801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22548,
        "tokens": 11821645824,
        "learning_rate": 0.00014683136830954063,
        "gradient_norm": 0.3853186070919037,
        "train_loss": 3.027043342590332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22549,
        "tokens": 11822170112,
        "learning_rate": 0.00014681032355976057,
        "gradient_norm": 0.3903443217277527,
        "train_loss": 3.0081868171691895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22550,
        "tokens": 11822694400,
        "learning_rate": 0.00014678928087200876,
        "gradient_norm": 0.4720281660556793,
        "train_loss": 3.0658187866210938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22551,
        "tokens": 11823218688,
        "learning_rate": 0.0001467682402465219,
        "gradient_norm": 0.38599199056625366,
        "train_loss": 3.0283308029174805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22552,
        "tokens": 11823742976,
        "learning_rate": 0.000146747201683537,
        "gradient_norm": 0.5068778991699219,
        "train_loss": 3.001023530960083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22553,
        "tokens": 11824267264,
        "learning_rate": 0.00014672616518329067,
        "gradient_norm": 0.4502738118171692,
        "train_loss": 2.996756076812744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22554,
        "tokens": 11824791552,
        "learning_rate": 0.00014670513074601987,
        "gradient_norm": 0.4168524742126465,
        "train_loss": 3.043299436569214,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22555,
        "tokens": 11825315840,
        "learning_rate": 0.0001466840983719613,
        "gradient_norm": 0.4395099878311157,
        "train_loss": 3.030170440673828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22556,
        "tokens": 11825840128,
        "learning_rate": 0.0001466630680613517,
        "gradient_norm": 0.45130372047424316,
        "train_loss": 3.0581326484680176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22557,
        "tokens": 11826364416,
        "learning_rate": 0.0001466420398144278,
        "gradient_norm": 0.38682296872138977,
        "train_loss": 3.0643420219421387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22558,
        "tokens": 11826888704,
        "learning_rate": 0.00014662101363142625,
        "gradient_norm": 0.42856892943382263,
        "train_loss": 3.0461249351501465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22559,
        "tokens": 11827412992,
        "learning_rate": 0.00014659998951258387,
        "gradient_norm": 0.40104272961616516,
        "train_loss": 3.0554451942443848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22560,
        "tokens": 11827937280,
        "learning_rate": 0.00014657896745813717,
        "gradient_norm": 0.47851598262786865,
        "train_loss": 3.035731315612793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22561,
        "tokens": 11828461568,
        "learning_rate": 0.00014655794746832291,
        "gradient_norm": 0.39737117290496826,
        "train_loss": 3.0062994956970215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22562,
        "tokens": 11828985856,
        "learning_rate": 0.00014653692954337753,
        "gradient_norm": 0.39970406889915466,
        "train_loss": 3.0320770740509033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22563,
        "tokens": 11829510144,
        "learning_rate": 0.00014651591368353777,
        "gradient_norm": 0.44609108567237854,
        "train_loss": 3.097064971923828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22564,
        "tokens": 11830034432,
        "learning_rate": 0.00014649489988904007,
        "gradient_norm": 0.44865939021110535,
        "train_loss": 3.0341529846191406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22565,
        "tokens": 11830558720,
        "learning_rate": 0.00014647388816012107,
        "gradient_norm": 0.43109551072120667,
        "train_loss": 2.9835104942321777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22566,
        "tokens": 11831083008,
        "learning_rate": 0.00014645287849701712,
        "gradient_norm": 0.45540544390678406,
        "train_loss": 3.0745983123779297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22567,
        "tokens": 11831607296,
        "learning_rate": 0.00014643187089996486,
        "gradient_norm": 0.4429931044578552,
        "train_loss": 3.022508144378662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22568,
        "tokens": 11832131584,
        "learning_rate": 0.0001464108653692008,
        "gradient_norm": 0.4776020348072052,
        "train_loss": 3.0800416469573975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22569,
        "tokens": 11832655872,
        "learning_rate": 0.0001463898619049612,
        "gradient_norm": 0.4341806173324585,
        "train_loss": 3.1019279956817627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22570,
        "tokens": 11833180160,
        "learning_rate": 0.00014636886050748267,
        "gradient_norm": 0.5145210027694702,
        "train_loss": 3.005807399749756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22571,
        "tokens": 11833704448,
        "learning_rate": 0.00014634786117700144,
        "gradient_norm": 0.43736156821250916,
        "train_loss": 3.0530478954315186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22572,
        "tokens": 11834228736,
        "learning_rate": 0.00014632686391375402,
        "gradient_norm": 0.5035180449485779,
        "train_loss": 3.1348490715026855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22573,
        "tokens": 11834753024,
        "learning_rate": 0.00014630586871797665,
        "gradient_norm": 0.4823691248893738,
        "train_loss": 3.0373387336730957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22574,
        "tokens": 11835277312,
        "learning_rate": 0.0001462848755899058,
        "gradient_norm": 0.4332311451435089,
        "train_loss": 2.9859697818756104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22575,
        "tokens": 11835801600,
        "learning_rate": 0.00014626388452977754,
        "gradient_norm": 0.43493539094924927,
        "train_loss": 3.0535497665405273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22576,
        "tokens": 11836325888,
        "learning_rate": 0.00014624289553782842,
        "gradient_norm": 0.4864821135997772,
        "train_loss": 3.0620388984680176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22577,
        "tokens": 11836850176,
        "learning_rate": 0.00014622190861429452,
        "gradient_norm": 0.4534265995025635,
        "train_loss": 3.0162384510040283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22578,
        "tokens": 11837374464,
        "learning_rate": 0.00014620092375941204,
        "gradient_norm": 0.4162975251674652,
        "train_loss": 2.9911179542541504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22579,
        "tokens": 11837898752,
        "learning_rate": 0.00014617994097341743,
        "gradient_norm": 0.46150586009025574,
        "train_loss": 3.02392840385437,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22580,
        "tokens": 11838423040,
        "learning_rate": 0.0001461589602565466,
        "gradient_norm": 0.4060817062854767,
        "train_loss": 3.0268449783325195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22581,
        "tokens": 11838947328,
        "learning_rate": 0.00014613798160903593,
        "gradient_norm": 0.41278618574142456,
        "train_loss": 3.0406274795532227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22582,
        "tokens": 11839471616,
        "learning_rate": 0.00014611700503112138,
        "gradient_norm": 0.42550957202911377,
        "train_loss": 3.1051461696624756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22583,
        "tokens": 11839995904,
        "learning_rate": 0.00014609603052303925,
        "gradient_norm": 0.41600891947746277,
        "train_loss": 3.1206307411193848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22584,
        "tokens": 11840520192,
        "learning_rate": 0.00014607505808502546,
        "gradient_norm": 0.4232442080974579,
        "train_loss": 3.019099712371826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22585,
        "tokens": 11841044480,
        "learning_rate": 0.00014605408771731622,
        "gradient_norm": 0.4306357800960541,
        "train_loss": 3.075572967529297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22586,
        "tokens": 11841568768,
        "learning_rate": 0.00014603311942014744,
        "gradient_norm": 0.40556827187538147,
        "train_loss": 3.048492908477783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22587,
        "tokens": 11842093056,
        "learning_rate": 0.0001460121531937552,
        "gradient_norm": 0.41261789202690125,
        "train_loss": 3.067272186279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22588,
        "tokens": 11842617344,
        "learning_rate": 0.00014599118903837566,
        "gradient_norm": 0.42001643776893616,
        "train_loss": 3.051189422607422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22589,
        "tokens": 11843141632,
        "learning_rate": 0.00014597022695424456,
        "gradient_norm": 0.4277648329734802,
        "train_loss": 3.079193592071533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22590,
        "tokens": 11843665920,
        "learning_rate": 0.00014594926694159804,
        "gradient_norm": 0.415198415517807,
        "train_loss": 3.0769731998443604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22591,
        "tokens": 11844190208,
        "learning_rate": 0.00014592830900067181,
        "gradient_norm": 0.4337293803691864,
        "train_loss": 2.981564521789551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22592,
        "tokens": 11844714496,
        "learning_rate": 0.00014590735313170207,
        "gradient_norm": 0.4506211578845978,
        "train_loss": 3.0102272033691406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22593,
        "tokens": 11845238784,
        "learning_rate": 0.00014588639933492441,
        "gradient_norm": 0.41777563095092773,
        "train_loss": 3.028226375579834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22594,
        "tokens": 11845763072,
        "learning_rate": 0.00014586544761057495,
        "gradient_norm": 0.39665043354034424,
        "train_loss": 3.0176987648010254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22595,
        "tokens": 11846287360,
        "learning_rate": 0.0001458444979588893,
        "gradient_norm": 0.4236287772655487,
        "train_loss": 2.997781276702881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22596,
        "tokens": 11846811648,
        "learning_rate": 0.00014582355038010347,
        "gradient_norm": 0.4209239184856415,
        "train_loss": 3.0709919929504395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22597,
        "tokens": 11847335936,
        "learning_rate": 0.0001458026048744531,
        "gradient_norm": 0.44307711720466614,
        "train_loss": 3.0401039123535156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22598,
        "tokens": 11847860224,
        "learning_rate": 0.00014578166144217397,
        "gradient_norm": 0.4047539234161377,
        "train_loss": 3.041065216064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22599,
        "tokens": 11848384512,
        "learning_rate": 0.00014576072008350198,
        "gradient_norm": 0.423414409160614,
        "train_loss": 3.043863296508789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22600,
        "tokens": 11848908800,
        "learning_rate": 0.00014573978079867266,
        "gradient_norm": 0.41287723183631897,
        "train_loss": 3.0431313514709473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22601,
        "tokens": 11849433088,
        "learning_rate": 0.00014571884358792193,
        "gradient_norm": 0.42310479283332825,
        "train_loss": 3.060976505279541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22602,
        "tokens": 11849957376,
        "learning_rate": 0.00014569790845148518,
        "gradient_norm": 0.44798997044563293,
        "train_loss": 3.0169425010681152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22603,
        "tokens": 11850481664,
        "learning_rate": 0.00014567697538959832,
        "gradient_norm": 0.43907642364501953,
        "train_loss": 3.068155288696289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22604,
        "tokens": 11851005952,
        "learning_rate": 0.0001456560444024968,
        "gradient_norm": 0.43631231784820557,
        "train_loss": 3.0526602268218994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22605,
        "tokens": 11851530240,
        "learning_rate": 0.00014563511549041635,
        "gradient_norm": 0.42674553394317627,
        "train_loss": 3.089451551437378,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22606,
        "tokens": 11852054528,
        "learning_rate": 0.00014561418865359241,
        "gradient_norm": 0.4458088278770447,
        "train_loss": 3.042980432510376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22607,
        "tokens": 11852578816,
        "learning_rate": 0.0001455932638922607,
        "gradient_norm": 0.4269739091396332,
        "train_loss": 3.055126190185547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22608,
        "tokens": 11853103104,
        "learning_rate": 0.00014557234120665658,
        "gradient_norm": 0.3849613070487976,
        "train_loss": 3.070291519165039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22609,
        "tokens": 11853627392,
        "learning_rate": 0.00014555142059701577,
        "gradient_norm": 0.4059820771217346,
        "train_loss": 3.063877820968628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22610,
        "tokens": 11854151680,
        "learning_rate": 0.00014553050206357355,
        "gradient_norm": 0.4169965386390686,
        "train_loss": 3.083235502243042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22611,
        "tokens": 11854675968,
        "learning_rate": 0.00014550958560656554,
        "gradient_norm": 0.37498536705970764,
        "train_loss": 3.0284981727600098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22612,
        "tokens": 11855200256,
        "learning_rate": 0.00014548867122622704,
        "gradient_norm": 0.438961923122406,
        "train_loss": 3.1089444160461426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22613,
        "tokens": 11855724544,
        "learning_rate": 0.00014546775892279362,
        "gradient_norm": 0.4163990020751953,
        "train_loss": 3.0671591758728027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22614,
        "tokens": 11856248832,
        "learning_rate": 0.00014544684869650059,
        "gradient_norm": 0.41890454292297363,
        "train_loss": 3.0497357845306396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22615,
        "tokens": 11856773120,
        "learning_rate": 0.0001454259405475833,
        "gradient_norm": 0.4032300114631653,
        "train_loss": 3.0323386192321777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22616,
        "tokens": 11857297408,
        "learning_rate": 0.00014540503447627712,
        "gradient_norm": 0.40434831380844116,
        "train_loss": 3.031930923461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22617,
        "tokens": 11857821696,
        "learning_rate": 0.00014538413048281745,
        "gradient_norm": 0.4454052746295929,
        "train_loss": 3.0523645877838135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22618,
        "tokens": 11858345984,
        "learning_rate": 0.00014536322856743941,
        "gradient_norm": 0.49242982268333435,
        "train_loss": 3.052624225616455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22619,
        "tokens": 11858870272,
        "learning_rate": 0.0001453423287303785,
        "gradient_norm": 0.4099915325641632,
        "train_loss": 3.026721477508545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22620,
        "tokens": 11859394560,
        "learning_rate": 0.00014532143097186978,
        "gradient_norm": 0.4685116112232208,
        "train_loss": 3.0524778366088867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22621,
        "tokens": 11859918848,
        "learning_rate": 0.00014530053529214861,
        "gradient_norm": 0.4147231876850128,
        "train_loss": 3.0627832412719727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22622,
        "tokens": 11860443136,
        "learning_rate": 0.0001452796416914501,
        "gradient_norm": 0.41422519087791443,
        "train_loss": 3.030590534210205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22623,
        "tokens": 11860967424,
        "learning_rate": 0.00014525875017000955,
        "gradient_norm": 0.4074561297893524,
        "train_loss": 2.994330883026123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22624,
        "tokens": 11861491712,
        "learning_rate": 0.00014523786072806198,
        "gradient_norm": 0.426527738571167,
        "train_loss": 3.0013155937194824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22625,
        "tokens": 11862016000,
        "learning_rate": 0.00014521697336584267,
        "gradient_norm": 0.39423543214797974,
        "train_loss": 2.99251389503479,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22626,
        "tokens": 11862540288,
        "learning_rate": 0.0001451960880835866,
        "gradient_norm": 0.45630189776420593,
        "train_loss": 2.9815287590026855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22627,
        "tokens": 11863064576,
        "learning_rate": 0.0001451752048815289,
        "gradient_norm": 0.3907712399959564,
        "train_loss": 3.0469837188720703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22628,
        "tokens": 11863588864,
        "learning_rate": 0.00014515432375990472,
        "gradient_norm": 0.4234536588191986,
        "train_loss": 3.048365592956543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22629,
        "tokens": 11864113152,
        "learning_rate": 0.00014513344471894904,
        "gradient_norm": 0.43447133898735046,
        "train_loss": 3.0078210830688477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22630,
        "tokens": 11864637440,
        "learning_rate": 0.0001451125677588969,
        "gradient_norm": 0.40998005867004395,
        "train_loss": 3.022495746612549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22631,
        "tokens": 11865161728,
        "learning_rate": 0.00014509169287998323,
        "gradient_norm": 0.4168390929698944,
        "train_loss": 3.0826058387756348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22632,
        "tokens": 11865686016,
        "learning_rate": 0.0001450708200824431,
        "gradient_norm": 0.40395763516426086,
        "train_loss": 3.038766622543335,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22633,
        "tokens": 11866210304,
        "learning_rate": 0.00014504994936651134,
        "gradient_norm": 0.3923295736312866,
        "train_loss": 3.053400754928589,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22634,
        "tokens": 11866734592,
        "learning_rate": 0.00014502908073242302,
        "gradient_norm": 0.4101716876029968,
        "train_loss": 3.0635504722595215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22635,
        "tokens": 11867258880,
        "learning_rate": 0.0001450082141804129,
        "gradient_norm": 0.4404974579811096,
        "train_loss": 3.145467758178711,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22636,
        "tokens": 11867783168,
        "learning_rate": 0.00014498734971071602,
        "gradient_norm": 0.49700862169265747,
        "train_loss": 3.022407054901123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22637,
        "tokens": 11868307456,
        "learning_rate": 0.00014496648732356703,
        "gradient_norm": 0.4402655065059662,
        "train_loss": 3.067343235015869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22638,
        "tokens": 11868831744,
        "learning_rate": 0.0001449456270192009,
        "gradient_norm": 0.42598778009414673,
        "train_loss": 3.059962511062622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22639,
        "tokens": 11869356032,
        "learning_rate": 0.0001449247687978525,
        "gradient_norm": 0.4653123915195465,
        "train_loss": 2.987947940826416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22640,
        "tokens": 11869880320,
        "learning_rate": 0.00014490391265975644,
        "gradient_norm": 0.4231702387332916,
        "train_loss": 3.055241107940674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22641,
        "tokens": 11870404608,
        "learning_rate": 0.00014488305860514765,
        "gradient_norm": 0.44721803069114685,
        "train_loss": 3.107006549835205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22642,
        "tokens": 11870928896,
        "learning_rate": 0.0001448622066342607,
        "gradient_norm": 0.4408673942089081,
        "train_loss": 3.097303867340088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22643,
        "tokens": 11871453184,
        "learning_rate": 0.0001448413567473305,
        "gradient_norm": 0.5068191289901733,
        "train_loss": 2.982093572616577,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22644,
        "tokens": 11871977472,
        "learning_rate": 0.00014482050894459156,
        "gradient_norm": 0.39354053139686584,
        "train_loss": 3.0255489349365234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22645,
        "tokens": 11872501760,
        "learning_rate": 0.00014479966322627867,
        "gradient_norm": 0.45875096321105957,
        "train_loss": 3.047898054122925,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22646,
        "tokens": 11873026048,
        "learning_rate": 0.00014477881959262638,
        "gradient_norm": 0.42720556259155273,
        "train_loss": 3.0512444972991943,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22647,
        "tokens": 11873550336,
        "learning_rate": 0.00014475797804386933,
        "gradient_norm": 0.4716912508010864,
        "train_loss": 3.0930590629577637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22648,
        "tokens": 11874074624,
        "learning_rate": 0.00014473713858024223,
        "gradient_norm": 0.4432728886604309,
        "train_loss": 3.019914150238037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22649,
        "tokens": 11874598912,
        "learning_rate": 0.0001447163012019795,
        "gradient_norm": 0.44660940766334534,
        "train_loss": 3.042323589324951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22650,
        "tokens": 11875123200,
        "learning_rate": 0.00014469546590931587,
        "gradient_norm": 0.44270575046539307,
        "train_loss": 3.0512845516204834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22651,
        "tokens": 11875647488,
        "learning_rate": 0.00014467463270248564,
        "gradient_norm": 0.4111659824848175,
        "train_loss": 2.9810736179351807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22652,
        "tokens": 11876171776,
        "learning_rate": 0.00014465380158172354,
        "gradient_norm": 0.44472578167915344,
        "train_loss": 3.055708408355713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22653,
        "tokens": 11876696064,
        "learning_rate": 0.00014463297254726384,
        "gradient_norm": 0.37766918540000916,
        "train_loss": 3.03549861907959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22654,
        "tokens": 11877220352,
        "learning_rate": 0.0001446121455993412,
        "gradient_norm": 0.4097506105899811,
        "train_loss": 3.0800724029541016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22655,
        "tokens": 11877744640,
        "learning_rate": 0.00014459132073818987,
        "gradient_norm": 0.41969552636146545,
        "train_loss": 3.051450252532959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22656,
        "tokens": 11878268928,
        "learning_rate": 0.0001445704979640444,
        "gradient_norm": 0.40727120637893677,
        "train_loss": 3.0028533935546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22657,
        "tokens": 11878793216,
        "learning_rate": 0.00014454967727713905,
        "gradient_norm": 0.36690396070480347,
        "train_loss": 3.04327654838562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22658,
        "tokens": 11879317504,
        "learning_rate": 0.00014452885867770825,
        "gradient_norm": 0.46181732416152954,
        "train_loss": 3.089348554611206,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22659,
        "tokens": 11879841792,
        "learning_rate": 0.00014450804216598645,
        "gradient_norm": 0.46753600239753723,
        "train_loss": 3.069463014602661,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22660,
        "tokens": 11880366080,
        "learning_rate": 0.00014448722774220774,
        "gradient_norm": 0.4604052007198334,
        "train_loss": 3.0223727226257324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22661,
        "tokens": 11880890368,
        "learning_rate": 0.00014446641540660665,
        "gradient_norm": 0.40510421991348267,
        "train_loss": 3.050682544708252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22662,
        "tokens": 11881414656,
        "learning_rate": 0.0001444456051594172,
        "gradient_norm": 0.4363141655921936,
        "train_loss": 3.071427822113037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22663,
        "tokens": 11881938944,
        "learning_rate": 0.0001444247970008739,
        "gradient_norm": 0.3870854377746582,
        "train_loss": 3.0647435188293457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22664,
        "tokens": 11882463232,
        "learning_rate": 0.0001444039909312107,
        "gradient_norm": 0.43367981910705566,
        "train_loss": 3.0008625984191895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22665,
        "tokens": 11882987520,
        "learning_rate": 0.00014438318695066205,
        "gradient_norm": 0.4064095914363861,
        "train_loss": 3.0480661392211914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22666,
        "tokens": 11883511808,
        "learning_rate": 0.0001443623850594619,
        "gradient_norm": 0.41443929076194763,
        "train_loss": 3.0847644805908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22667,
        "tokens": 11884036096,
        "learning_rate": 0.00014434158525784453,
        "gradient_norm": 0.4431467056274414,
        "train_loss": 3.0424458980560303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22668,
        "tokens": 11884560384,
        "learning_rate": 0.00014432078754604414,
        "gradient_norm": 0.41509658098220825,
        "train_loss": 2.9971652030944824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22669,
        "tokens": 11885084672,
        "learning_rate": 0.00014429999192429462,
        "gradient_norm": 0.5127795934677124,
        "train_loss": 3.0972042083740234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22670,
        "tokens": 11885608960,
        "learning_rate": 0.0001442791983928303,
        "gradient_norm": 0.4334411025047302,
        "train_loss": 2.9689786434173584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22671,
        "tokens": 11886133248,
        "learning_rate": 0.00014425840695188498,
        "gradient_norm": 0.453083872795105,
        "train_loss": 3.0819249153137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22672,
        "tokens": 11886657536,
        "learning_rate": 0.00014423761760169295,
        "gradient_norm": 0.4183194935321808,
        "train_loss": 3.0239968299865723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22673,
        "tokens": 11887181824,
        "learning_rate": 0.00014421683034248798,
        "gradient_norm": 0.4255872964859009,
        "train_loss": 3.069032669067383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22674,
        "tokens": 11887706112,
        "learning_rate": 0.00014419604517450425,
        "gradient_norm": 0.46598121523857117,
        "train_loss": 3.0595626831054688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22675,
        "tokens": 11888230400,
        "learning_rate": 0.00014417526209797556,
        "gradient_norm": 0.44417744874954224,
        "train_loss": 3.0970370769500732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22676,
        "tokens": 11888754688,
        "learning_rate": 0.00014415448111313605,
        "gradient_norm": 0.45109888911247253,
        "train_loss": 2.9702348709106445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22677,
        "tokens": 11889278976,
        "learning_rate": 0.00014413370222021943,
        "gradient_norm": 0.47820255160331726,
        "train_loss": 3.003830909729004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22678,
        "tokens": 11889803264,
        "learning_rate": 0.00014411292541945963,
        "gradient_norm": 0.4429425001144409,
        "train_loss": 3.0710818767547607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22679,
        "tokens": 11890327552,
        "learning_rate": 0.0001440921507110907,
        "gradient_norm": 0.43238985538482666,
        "train_loss": 3.02278733253479,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22680,
        "tokens": 11890851840,
        "learning_rate": 0.00014407137809534622,
        "gradient_norm": 0.4129912853240967,
        "train_loss": 3.0655598640441895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22681,
        "tokens": 11891376128,
        "learning_rate": 0.00014405060757246028,
        "gradient_norm": 0.4514032304286957,
        "train_loss": 3.0339760780334473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22682,
        "tokens": 11891900416,
        "learning_rate": 0.00014402983914266646,
        "gradient_norm": 0.42933592200279236,
        "train_loss": 3.0173468589782715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22683,
        "tokens": 11892424704,
        "learning_rate": 0.00014400907280619866,
        "gradient_norm": 0.41048160195350647,
        "train_loss": 3.056891441345215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22684,
        "tokens": 11892948992,
        "learning_rate": 0.00014398830856329054,
        "gradient_norm": 0.47353821992874146,
        "train_loss": 3.1839680671691895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22685,
        "tokens": 11893473280,
        "learning_rate": 0.00014396754641417595,
        "gradient_norm": 0.45440682768821716,
        "train_loss": 3.1027817726135254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22686,
        "tokens": 11893997568,
        "learning_rate": 0.00014394678635908843,
        "gradient_norm": 0.4596545398235321,
        "train_loss": 3.0119247436523438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22687,
        "tokens": 11894521856,
        "learning_rate": 0.00014392602839826177,
        "gradient_norm": 0.4272440969944,
        "train_loss": 3.037531852722168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22688,
        "tokens": 11895046144,
        "learning_rate": 0.00014390527253192967,
        "gradient_norm": 0.44849175214767456,
        "train_loss": 3.026658058166504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22689,
        "tokens": 11895570432,
        "learning_rate": 0.00014388451876032562,
        "gradient_norm": 0.4658873975276947,
        "train_loss": 3.0253233909606934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22690,
        "tokens": 11896094720,
        "learning_rate": 0.0001438637670836834,
        "gradient_norm": 0.4660490155220032,
        "train_loss": 3.0006165504455566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22691,
        "tokens": 11896619008,
        "learning_rate": 0.00014384301750223642,
        "gradient_norm": 0.4763922691345215,
        "train_loss": 3.0471458435058594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22692,
        "tokens": 11897143296,
        "learning_rate": 0.00014382227001621842,
        "gradient_norm": 0.44843578338623047,
        "train_loss": 3.0339083671569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22693,
        "tokens": 11897667584,
        "learning_rate": 0.00014380152462586276,
        "gradient_norm": 0.4004448354244232,
        "train_loss": 3.0267539024353027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22694,
        "tokens": 11898191872,
        "learning_rate": 0.00014378078133140315,
        "gradient_norm": 0.4103669822216034,
        "train_loss": 3.066037654876709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22695,
        "tokens": 11898716160,
        "learning_rate": 0.00014376004013307283,
        "gradient_norm": 0.454649955034256,
        "train_loss": 3.1096909046173096,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22696,
        "tokens": 11899240448,
        "learning_rate": 0.00014373930103110555,
        "gradient_norm": 0.4148106873035431,
        "train_loss": 3.0908594131469727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22697,
        "tokens": 11899764736,
        "learning_rate": 0.00014371856402573452,
        "gradient_norm": 0.43510520458221436,
        "train_loss": 3.025181770324707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22698,
        "tokens": 11900289024,
        "learning_rate": 0.00014369782911719323,
        "gradient_norm": 0.38505128026008606,
        "train_loss": 3.032654285430908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22699,
        "tokens": 11900813312,
        "learning_rate": 0.00014367709630571523,
        "gradient_norm": 0.4609280228614807,
        "train_loss": 3.106114625930786,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22700,
        "tokens": 11901337600,
        "learning_rate": 0.00014365636559153367,
        "gradient_norm": 0.3939766585826874,
        "train_loss": 3.008089065551758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22701,
        "tokens": 11901861888,
        "learning_rate": 0.00014363563697488205,
        "gradient_norm": 0.44568774104118347,
        "train_loss": 3.02455997467041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22702,
        "tokens": 11902386176,
        "learning_rate": 0.0001436149104559936,
        "gradient_norm": 0.4241519272327423,
        "train_loss": 3.0427422523498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22703,
        "tokens": 11902910464,
        "learning_rate": 0.00014359418603510177,
        "gradient_norm": 0.41944870352745056,
        "train_loss": 3.006594181060791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22704,
        "tokens": 11903434752,
        "learning_rate": 0.00014357346371243962,
        "gradient_norm": 0.40737658739089966,
        "train_loss": 2.9974172115325928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22705,
        "tokens": 11903959040,
        "learning_rate": 0.00014355274348824062,
        "gradient_norm": 0.41636741161346436,
        "train_loss": 3.0172719955444336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22706,
        "tokens": 11904483328,
        "learning_rate": 0.0001435320253627378,
        "gradient_norm": 0.4286123216152191,
        "train_loss": 3.088858127593994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22707,
        "tokens": 11905007616,
        "learning_rate": 0.00014351130933616457,
        "gradient_norm": 0.4131528437137604,
        "train_loss": 3.029242515563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22708,
        "tokens": 11905531904,
        "learning_rate": 0.00014349059540875395,
        "gradient_norm": 0.47865167260169983,
        "train_loss": 3.055637836456299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22709,
        "tokens": 11906056192,
        "learning_rate": 0.00014346988358073922,
        "gradient_norm": 0.4245482087135315,
        "train_loss": 3.045917272567749,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22710,
        "tokens": 11906580480,
        "learning_rate": 0.0001434491738523534,
        "gradient_norm": 0.5072088837623596,
        "train_loss": 3.0723958015441895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22711,
        "tokens": 11907104768,
        "learning_rate": 0.00014342846622382978,
        "gradient_norm": 0.41968733072280884,
        "train_loss": 3.084007978439331,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22712,
        "tokens": 11907629056,
        "learning_rate": 0.00014340776069540122,
        "gradient_norm": 0.4440249502658844,
        "train_loss": 3.1018073558807373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22713,
        "tokens": 11908153344,
        "learning_rate": 0.000143387057267301,
        "gradient_norm": 0.4319932162761688,
        "train_loss": 3.0503005981445312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22714,
        "tokens": 11908677632,
        "learning_rate": 0.00014336635593976195,
        "gradient_norm": 0.40667375922203064,
        "train_loss": 3.0453295707702637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22715,
        "tokens": 11909201920,
        "learning_rate": 0.00014334565671301737,
        "gradient_norm": 0.421400785446167,
        "train_loss": 3.0423498153686523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22716,
        "tokens": 11909726208,
        "learning_rate": 0.00014332495958729993,
        "gradient_norm": 0.41627979278564453,
        "train_loss": 3.0085721015930176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22717,
        "tokens": 11910250496,
        "learning_rate": 0.0001433042645628429,
        "gradient_norm": 0.46474772691726685,
        "train_loss": 3.0399937629699707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22718,
        "tokens": 11910774784,
        "learning_rate": 0.000143283571639879,
        "gradient_norm": 0.4212702214717865,
        "train_loss": 3.0556399822235107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22719,
        "tokens": 11911299072,
        "learning_rate": 0.00014326288081864134,
        "gradient_norm": 0.4879240393638611,
        "train_loss": 3.0696115493774414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22720,
        "tokens": 11911823360,
        "learning_rate": 0.00014324219209936264,
        "gradient_norm": 0.4157767593860626,
        "train_loss": 3.038731098175049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22721,
        "tokens": 11912347648,
        "learning_rate": 0.00014322150548227595,
        "gradient_norm": 0.46342578530311584,
        "train_loss": 3.0504515171051025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22722,
        "tokens": 11912871936,
        "learning_rate": 0.00014320082096761394,
        "gradient_norm": 0.4460879862308502,
        "train_loss": 3.0296249389648438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22723,
        "tokens": 11913396224,
        "learning_rate": 0.00014318013855560966,
        "gradient_norm": 0.4152414798736572,
        "train_loss": 3.055107593536377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22724,
        "tokens": 11913920512,
        "learning_rate": 0.0001431594582464957,
        "gradient_norm": 0.41098904609680176,
        "train_loss": 2.973837375640869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22725,
        "tokens": 11914444800,
        "learning_rate": 0.00014313878004050502,
        "gradient_norm": 0.4809122383594513,
        "train_loss": 3.0830278396606445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22726,
        "tokens": 11914969088,
        "learning_rate": 0.0001431181039378702,
        "gradient_norm": 0.42266568541526794,
        "train_loss": 3.036919593811035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22727,
        "tokens": 11915493376,
        "learning_rate": 0.00014309742993882414,
        "gradient_norm": 0.41826024651527405,
        "train_loss": 3.0071887969970703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22728,
        "tokens": 11916017664,
        "learning_rate": 0.00014307675804359947,
        "gradient_norm": 0.40633711218833923,
        "train_loss": 3.0465261936187744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22729,
        "tokens": 11916541952,
        "learning_rate": 0.00014305608825242888,
        "gradient_norm": 0.4390113055706024,
        "train_loss": 3.071868896484375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22730,
        "tokens": 11917066240,
        "learning_rate": 0.00014303542056554513,
        "gradient_norm": 0.4197794795036316,
        "train_loss": 3.105785608291626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22731,
        "tokens": 11917590528,
        "learning_rate": 0.00014301475498318067,
        "gradient_norm": 0.41648101806640625,
        "train_loss": 3.064408302307129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22732,
        "tokens": 11918114816,
        "learning_rate": 0.00014299409150556833,
        "gradient_norm": 0.4096910059452057,
        "train_loss": 3.0364248752593994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22733,
        "tokens": 11918639104,
        "learning_rate": 0.0001429734301329405,
        "gradient_norm": 0.4049575626850128,
        "train_loss": 3.0999462604522705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22734,
        "tokens": 11919163392,
        "learning_rate": 0.00014295277086552995,
        "gradient_norm": 0.4270775020122528,
        "train_loss": 3.0147624015808105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22735,
        "tokens": 11919687680,
        "learning_rate": 0.000142932113703569,
        "gradient_norm": 0.43871670961380005,
        "train_loss": 3.031155824661255,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22736,
        "tokens": 11920211968,
        "learning_rate": 0.0001429114586472904,
        "gradient_norm": 0.4300726652145386,
        "train_loss": 2.9931836128234863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22737,
        "tokens": 11920736256,
        "learning_rate": 0.0001428908056969265,
        "gradient_norm": 0.41923263669013977,
        "train_loss": 3.0934290885925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22738,
        "tokens": 11921260544,
        "learning_rate": 0.00014287015485270978,
        "gradient_norm": 0.4420202672481537,
        "train_loss": 3.0078792572021484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22739,
        "tokens": 11921784832,
        "learning_rate": 0.0001428495061148728,
        "gradient_norm": 0.4806746542453766,
        "train_loss": 3.0850977897644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22740,
        "tokens": 11922309120,
        "learning_rate": 0.00014282885948364786,
        "gradient_norm": 0.44111770391464233,
        "train_loss": 2.979158401489258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22741,
        "tokens": 11922833408,
        "learning_rate": 0.00014280821495926753,
        "gradient_norm": 0.5541785955429077,
        "train_loss": 3.093740463256836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22742,
        "tokens": 11923357696,
        "learning_rate": 0.00014278757254196394,
        "gradient_norm": 0.4606742858886719,
        "train_loss": 3.0052003860473633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22743,
        "tokens": 11923881984,
        "learning_rate": 0.00014276693223196971,
        "gradient_norm": 0.479376882314682,
        "train_loss": 3.0383758544921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22744,
        "tokens": 11924406272,
        "learning_rate": 0.00014274629402951695,
        "gradient_norm": 0.428658127784729,
        "train_loss": 3.05745530128479,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22745,
        "tokens": 11924930560,
        "learning_rate": 0.0001427256579348382,
        "gradient_norm": 0.4490661323070526,
        "train_loss": 3.080251932144165,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22746,
        "tokens": 11925454848,
        "learning_rate": 0.00014270502394816547,
        "gradient_norm": 0.4402609169483185,
        "train_loss": 3.008568286895752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22747,
        "tokens": 11925979136,
        "learning_rate": 0.0001426843920697312,
        "gradient_norm": 0.43133366107940674,
        "train_loss": 3.0361804962158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22748,
        "tokens": 11926503424,
        "learning_rate": 0.00014266376229976765,
        "gradient_norm": 0.4171871840953827,
        "train_loss": 3.05385422706604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22749,
        "tokens": 11927027712,
        "learning_rate": 0.00014264313463850688,
        "gradient_norm": 0.4076842665672302,
        "train_loss": 3.0441389083862305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22750,
        "tokens": 11927552000,
        "learning_rate": 0.00014262250908618127,
        "gradient_norm": 0.40193799138069153,
        "train_loss": 2.9957942962646484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22751,
        "tokens": 11928076288,
        "learning_rate": 0.00014260188564302285,
        "gradient_norm": 0.41832154989242554,
        "train_loss": 3.0631041526794434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22752,
        "tokens": 11928600576,
        "learning_rate": 0.00014258126430926384,
        "gradient_norm": 0.4170301854610443,
        "train_loss": 3.058681011199951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22753,
        "tokens": 11929124864,
        "learning_rate": 0.00014256064508513626,
        "gradient_norm": 0.4301477074623108,
        "train_loss": 3.046283006668091,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22754,
        "tokens": 11929649152,
        "learning_rate": 0.00014254002797087234,
        "gradient_norm": 0.44654542207717896,
        "train_loss": 3.0782713890075684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22755,
        "tokens": 11930173440,
        "learning_rate": 0.00014251941296670404,
        "gradient_norm": 0.4120572805404663,
        "train_loss": 2.995784282684326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22756,
        "tokens": 11930697728,
        "learning_rate": 0.0001424988000728635,
        "gradient_norm": 0.4193200469017029,
        "train_loss": 3.0360939502716064,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22757,
        "tokens": 11931222016,
        "learning_rate": 0.00014247818928958257,
        "gradient_norm": 0.38367581367492676,
        "train_loss": 3.0727219581604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22758,
        "tokens": 11931746304,
        "learning_rate": 0.00014245758061709343,
        "gradient_norm": 0.4270707070827484,
        "train_loss": 3.0570149421691895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22759,
        "tokens": 11932270592,
        "learning_rate": 0.00014243697405562806,
        "gradient_norm": 0.41581106185913086,
        "train_loss": 3.0580716133117676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22760,
        "tokens": 11932794880,
        "learning_rate": 0.00014241636960541827,
        "gradient_norm": 0.47952714562416077,
        "train_loss": 3.092825412750244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22761,
        "tokens": 11933319168,
        "learning_rate": 0.00014239576726669616,
        "gradient_norm": 0.449104368686676,
        "train_loss": 2.996518135070801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22762,
        "tokens": 11933843456,
        "learning_rate": 0.00014237516703969344,
        "gradient_norm": 0.429328590631485,
        "train_loss": 3.0518391132354736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22763,
        "tokens": 11934367744,
        "learning_rate": 0.0001423545689246422,
        "gradient_norm": 0.40544241666793823,
        "train_loss": 3.0570688247680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22764,
        "tokens": 11934892032,
        "learning_rate": 0.0001423339729217741,
        "gradient_norm": 0.4645754396915436,
        "train_loss": 3.0598950386047363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22765,
        "tokens": 11935416320,
        "learning_rate": 0.00014231337903132117,
        "gradient_norm": 0.3874782919883728,
        "train_loss": 3.0355582237243652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22766,
        "tokens": 11935940608,
        "learning_rate": 0.000142292787253515,
        "gradient_norm": 0.41001003980636597,
        "train_loss": 3.038942813873291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22767,
        "tokens": 11936464896,
        "learning_rate": 0.0001422721975885875,
        "gradient_norm": 0.4317321181297302,
        "train_loss": 3.0745153427124023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22768,
        "tokens": 11936989184,
        "learning_rate": 0.0001422516100367705,
        "gradient_norm": 0.4074779748916626,
        "train_loss": 3.1045260429382324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22769,
        "tokens": 11937513472,
        "learning_rate": 0.0001422310245982956,
        "gradient_norm": 0.43349191546440125,
        "train_loss": 3.040584087371826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22770,
        "tokens": 11938037760,
        "learning_rate": 0.00014221044127339465,
        "gradient_norm": 0.372501939535141,
        "train_loss": 3.0185208320617676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22771,
        "tokens": 11938562048,
        "learning_rate": 0.0001421898600622992,
        "gradient_norm": 0.4533294439315796,
        "train_loss": 3.039252281188965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22772,
        "tokens": 11939086336,
        "learning_rate": 0.00014216928096524108,
        "gradient_norm": 0.43776750564575195,
        "train_loss": 3.015779733657837,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22773,
        "tokens": 11939610624,
        "learning_rate": 0.00014214870398245174,
        "gradient_norm": 0.4097039997577667,
        "train_loss": 3.0197229385375977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22774,
        "tokens": 11940134912,
        "learning_rate": 0.00014212812911416298,
        "gradient_norm": 0.4529055953025818,
        "train_loss": 2.988833427429199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22775,
        "tokens": 11940659200,
        "learning_rate": 0.00014210755636060623,
        "gradient_norm": 0.43172144889831543,
        "train_loss": 3.029716730117798,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22776,
        "tokens": 11941183488,
        "learning_rate": 0.00014208698572201322,
        "gradient_norm": 0.4120234251022339,
        "train_loss": 2.978395938873291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22777,
        "tokens": 11941707776,
        "learning_rate": 0.00014206641719861535,
        "gradient_norm": 0.4423348605632782,
        "train_loss": 3.059563159942627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22778,
        "tokens": 11942232064,
        "learning_rate": 0.00014204585079064425,
        "gradient_norm": 0.4322953224182129,
        "train_loss": 3.0137839317321777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22779,
        "tokens": 11942756352,
        "learning_rate": 0.00014202528649833143,
        "gradient_norm": 0.3979984223842621,
        "train_loss": 3.020397186279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22780,
        "tokens": 11943280640,
        "learning_rate": 0.00014200472432190827,
        "gradient_norm": 0.3768575191497803,
        "train_loss": 3.0266151428222656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22781,
        "tokens": 11943804928,
        "learning_rate": 0.00014198416426160633,
        "gradient_norm": 0.40104353427886963,
        "train_loss": 3.072370767593384,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22782,
        "tokens": 11944329216,
        "learning_rate": 0.00014196360631765694,
        "gradient_norm": 0.376765638589859,
        "train_loss": 3.013101100921631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22783,
        "tokens": 11944853504,
        "learning_rate": 0.00014194305049029164,
        "gradient_norm": 0.4233419597148895,
        "train_loss": 3.0901522636413574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22784,
        "tokens": 11945377792,
        "learning_rate": 0.00014192249677974164,
        "gradient_norm": 0.39691001176834106,
        "train_loss": 2.9889984130859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22785,
        "tokens": 11945902080,
        "learning_rate": 0.00014190194518623846,
        "gradient_norm": 0.42443934082984924,
        "train_loss": 3.0429229736328125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22786,
        "tokens": 11946426368,
        "learning_rate": 0.00014188139571001327,
        "gradient_norm": 0.3981587588787079,
        "train_loss": 3.0318267345428467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22787,
        "tokens": 11946950656,
        "learning_rate": 0.00014186084835129747,
        "gradient_norm": 0.4031708836555481,
        "train_loss": 2.986739158630371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22788,
        "tokens": 11947474944,
        "learning_rate": 0.00014184030311032242,
        "gradient_norm": 0.4320718050003052,
        "train_loss": 3.0581095218658447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22789,
        "tokens": 11947999232,
        "learning_rate": 0.00014181975998731923,
        "gradient_norm": 0.4067128300666809,
        "train_loss": 3.0658650398254395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22790,
        "tokens": 11948523520,
        "learning_rate": 0.0001417992189825193,
        "gradient_norm": 0.40096765756607056,
        "train_loss": 3.1004042625427246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22791,
        "tokens": 11949047808,
        "learning_rate": 0.00014177868009615367,
        "gradient_norm": 0.37896713614463806,
        "train_loss": 3.0615813732147217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22792,
        "tokens": 11949572096,
        "learning_rate": 0.00014175814332845367,
        "gradient_norm": 0.448086142539978,
        "train_loss": 3.071061134338379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22793,
        "tokens": 11950096384,
        "learning_rate": 0.00014173760867965037,
        "gradient_norm": 0.4351073205471039,
        "train_loss": 3.0241289138793945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22794,
        "tokens": 11950620672,
        "learning_rate": 0.00014171707614997508,
        "gradient_norm": 0.4318997859954834,
        "train_loss": 3.0162465572357178,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22795,
        "tokens": 11951144960,
        "learning_rate": 0.00014169654573965867,
        "gradient_norm": 0.4186514616012573,
        "train_loss": 3.079801082611084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22796,
        "tokens": 11951669248,
        "learning_rate": 0.00014167601744893247,
        "gradient_norm": 0.4745923578739166,
        "train_loss": 3.0251901149749756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22797,
        "tokens": 11952193536,
        "learning_rate": 0.0001416554912780273,
        "gradient_norm": 0.4092828035354614,
        "train_loss": 3.0375006198883057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22798,
        "tokens": 11952717824,
        "learning_rate": 0.00014163496722717443,
        "gradient_norm": 0.4499288499355316,
        "train_loss": 3.046022415161133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22799,
        "tokens": 11953242112,
        "learning_rate": 0.00014161444529660485,
        "gradient_norm": 0.4409869313240051,
        "train_loss": 3.037315845489502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22800,
        "tokens": 11953766400,
        "learning_rate": 0.00014159392548654943,
        "gradient_norm": 0.4187992811203003,
        "train_loss": 3.0430660247802734,
        "val_loss": 2.9967055320739746,
        "hellaswag_acc": 0.28589922189712524,
        "hellaswag_acc_norm": 0.29386574029922485
    },
    {
        "step": 22801,
        "tokens": 11954290688,
        "learning_rate": 0.00014157340779723934,
        "gradient_norm": 0.4784879684448242,
        "train_loss": 3.041444778442383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22802,
        "tokens": 11954814976,
        "learning_rate": 0.00014155289222890534,
        "gradient_norm": 0.4118858277797699,
        "train_loss": 3.0602102279663086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22803,
        "tokens": 11955339264,
        "learning_rate": 0.00014153237878177853,
        "gradient_norm": 0.41008099913597107,
        "train_loss": 3.036837577819824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22804,
        "tokens": 11955863552,
        "learning_rate": 0.00014151186745608963,
        "gradient_norm": 0.5448093414306641,
        "train_loss": 2.97961163520813,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22805,
        "tokens": 11956387840,
        "learning_rate": 0.00014149135825206968,
        "gradient_norm": 0.45386117696762085,
        "train_loss": 3.067272186279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22806,
        "tokens": 11956912128,
        "learning_rate": 0.00014147085116994942,
        "gradient_norm": 0.41135701537132263,
        "train_loss": 2.9762325286865234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22807,
        "tokens": 11957436416,
        "learning_rate": 0.00014145034620995973,
        "gradient_norm": 0.47168290615081787,
        "train_loss": 3.0643115043640137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22808,
        "tokens": 11957960704,
        "learning_rate": 0.00014142984337233152,
        "gradient_norm": 0.3999914824962616,
        "train_loss": 3.0872714519500732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22809,
        "tokens": 11958484992,
        "learning_rate": 0.0001414093426572954,
        "gradient_norm": 0.37640970945358276,
        "train_loss": 3.0660111904144287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22810,
        "tokens": 11959009280,
        "learning_rate": 0.0001413888440650823,
        "gradient_norm": 0.38872700929641724,
        "train_loss": 2.9917545318603516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22811,
        "tokens": 11959533568,
        "learning_rate": 0.00014136834759592275,
        "gradient_norm": 0.41426077485084534,
        "train_loss": 3.019775390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22812,
        "tokens": 11960057856,
        "learning_rate": 0.0001413478532500477,
        "gradient_norm": 0.4137513041496277,
        "train_loss": 3.063203811645508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22813,
        "tokens": 11960582144,
        "learning_rate": 0.00014132736102768763,
        "gradient_norm": 0.43293118476867676,
        "train_loss": 3.0344669818878174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22814,
        "tokens": 11961106432,
        "learning_rate": 0.00014130687092907339,
        "gradient_norm": 0.42049214243888855,
        "train_loss": 3.0952842235565186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22815,
        "tokens": 11961630720,
        "learning_rate": 0.00014128638295443543,
        "gradient_norm": 0.40768977999687195,
        "train_loss": 3.047780990600586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22816,
        "tokens": 11962155008,
        "learning_rate": 0.00014126589710400454,
        "gradient_norm": 0.38177621364593506,
        "train_loss": 2.984069347381592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22817,
        "tokens": 11962679296,
        "learning_rate": 0.0001412454133780112,
        "gradient_norm": 0.4165678024291992,
        "train_loss": 3.0849609375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22818,
        "tokens": 11963203584,
        "learning_rate": 0.0001412249317766861,
        "gradient_norm": 0.3848281800746918,
        "train_loss": 2.9993202686309814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22819,
        "tokens": 11963727872,
        "learning_rate": 0.00014120445230025958,
        "gradient_norm": 0.38818302750587463,
        "train_loss": 3.0835394859313965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22820,
        "tokens": 11964252160,
        "learning_rate": 0.0001411839749489624,
        "gradient_norm": 0.4210665225982666,
        "train_loss": 3.021620273590088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22821,
        "tokens": 11964776448,
        "learning_rate": 0.00014116349972302487,
        "gradient_norm": 0.4399382770061493,
        "train_loss": 3.0231733322143555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22822,
        "tokens": 11965300736,
        "learning_rate": 0.00014114302662267763,
        "gradient_norm": 0.41074416041374207,
        "train_loss": 3.0017781257629395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22823,
        "tokens": 11965825024,
        "learning_rate": 0.00014112255564815093,
        "gradient_norm": 0.42141038179397583,
        "train_loss": 3.0942420959472656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22824,
        "tokens": 11966349312,
        "learning_rate": 0.0001411020867996754,
        "gradient_norm": 0.3849303126335144,
        "train_loss": 3.091832399368286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22825,
        "tokens": 11966873600,
        "learning_rate": 0.0001410816200774813,
        "gradient_norm": 0.4419246017932892,
        "train_loss": 3.013798713684082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22826,
        "tokens": 11967397888,
        "learning_rate": 0.0001410611554817991,
        "gradient_norm": 0.5715501308441162,
        "train_loss": 2.8636393547058105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22827,
        "tokens": 11967922176,
        "learning_rate": 0.00014104069301285906,
        "gradient_norm": 0.510508120059967,
        "train_loss": 2.9659583568573,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22828,
        "tokens": 11968446464,
        "learning_rate": 0.00014102023267089164,
        "gradient_norm": 0.4519024193286896,
        "train_loss": 2.9924192428588867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22829,
        "tokens": 11968970752,
        "learning_rate": 0.000140999774456127,
        "gradient_norm": 0.40833303332328796,
        "train_loss": 3.071699619293213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22830,
        "tokens": 11969495040,
        "learning_rate": 0.00014097931836879553,
        "gradient_norm": 0.45555612444877625,
        "train_loss": 3.0367817878723145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22831,
        "tokens": 11970019328,
        "learning_rate": 0.0001409588644091274,
        "gradient_norm": 0.4202480912208557,
        "train_loss": 3.0382425785064697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22832,
        "tokens": 11970543616,
        "learning_rate": 0.00014093841257735296,
        "gradient_norm": 0.42837581038475037,
        "train_loss": 3.0055418014526367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22833,
        "tokens": 11971067904,
        "learning_rate": 0.00014091796287370233,
        "gradient_norm": 0.4124167263507843,
        "train_loss": 3.0473175048828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22834,
        "tokens": 11971592192,
        "learning_rate": 0.00014089751529840574,
        "gradient_norm": 0.48295825719833374,
        "train_loss": 2.9825191497802734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22835,
        "tokens": 11972116480,
        "learning_rate": 0.0001408770698516933,
        "gradient_norm": 0.42759305238723755,
        "train_loss": 3.059753179550171,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22836,
        "tokens": 11972640768,
        "learning_rate": 0.00014085662653379516,
        "gradient_norm": 0.441956102848053,
        "train_loss": 3.027520179748535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22837,
        "tokens": 11973165056,
        "learning_rate": 0.00014083618534494157,
        "gradient_norm": 0.3966280221939087,
        "train_loss": 3.0025203227996826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22838,
        "tokens": 11973689344,
        "learning_rate": 0.00014081574628536242,
        "gradient_norm": 0.4303697347640991,
        "train_loss": 3.065728187561035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22839,
        "tokens": 11974213632,
        "learning_rate": 0.00014079530935528795,
        "gradient_norm": 0.4143395721912384,
        "train_loss": 3.0183563232421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22840,
        "tokens": 11974737920,
        "learning_rate": 0.00014077487455494802,
        "gradient_norm": 0.42694929242134094,
        "train_loss": 3.012761354446411,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22841,
        "tokens": 11975262208,
        "learning_rate": 0.00014075444188457287,
        "gradient_norm": 0.4431805908679962,
        "train_loss": 3.07476806640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22842,
        "tokens": 11975786496,
        "learning_rate": 0.00014073401134439227,
        "gradient_norm": 0.40676355361938477,
        "train_loss": 3.0412497520446777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22843,
        "tokens": 11976310784,
        "learning_rate": 0.00014071358293463637,
        "gradient_norm": 0.40998849272727966,
        "train_loss": 3.003525733947754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22844,
        "tokens": 11976835072,
        "learning_rate": 0.000140693156655535,
        "gradient_norm": 0.43421366810798645,
        "train_loss": 3.0943031311035156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22845,
        "tokens": 11977359360,
        "learning_rate": 0.00014067273250731823,
        "gradient_norm": 0.3932769000530243,
        "train_loss": 3.0267605781555176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22846,
        "tokens": 11977883648,
        "learning_rate": 0.00014065231049021574,
        "gradient_norm": 0.40109992027282715,
        "train_loss": 3.1137583255767822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22847,
        "tokens": 11978407936,
        "learning_rate": 0.0001406318906044575,
        "gradient_norm": 0.4356737732887268,
        "train_loss": 3.040337562561035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22848,
        "tokens": 11978932224,
        "learning_rate": 0.0001406114728502735,
        "gradient_norm": 0.42670661211013794,
        "train_loss": 3.0107593536376953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22849,
        "tokens": 11979456512,
        "learning_rate": 0.00014059105722789335,
        "gradient_norm": 0.3974626064300537,
        "train_loss": 3.0261826515197754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22850,
        "tokens": 11979980800,
        "learning_rate": 0.00014057064373754706,
        "gradient_norm": 0.4564947187900543,
        "train_loss": 3.09429931640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22851,
        "tokens": 11980505088,
        "learning_rate": 0.0001405502323794642,
        "gradient_norm": 0.4102048873901367,
        "train_loss": 3.0253803730010986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22852,
        "tokens": 11981029376,
        "learning_rate": 0.00014052982315387473,
        "gradient_norm": 0.40021154284477234,
        "train_loss": 3.00836181640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22853,
        "tokens": 11981553664,
        "learning_rate": 0.00014050941606100822,
        "gradient_norm": 0.41058477759361267,
        "train_loss": 3.0444531440734863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22854,
        "tokens": 11982077952,
        "learning_rate": 0.00014048901110109448,
        "gradient_norm": 0.4132831394672394,
        "train_loss": 3.057905673980713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22855,
        "tokens": 11982602240,
        "learning_rate": 0.0001404686082743631,
        "gradient_norm": 0.4145633578300476,
        "train_loss": 3.0606112480163574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22856,
        "tokens": 11983126528,
        "learning_rate": 0.00014044820758104374,
        "gradient_norm": 0.49270734190940857,
        "train_loss": 3.0283021926879883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22857,
        "tokens": 11983650816,
        "learning_rate": 0.00014042780902136622,
        "gradient_norm": 0.42955896258354187,
        "train_loss": 3.0221593379974365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22858,
        "tokens": 11984175104,
        "learning_rate": 0.00014040741259555988,
        "gradient_norm": 0.427010178565979,
        "train_loss": 3.027066707611084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22859,
        "tokens": 11984699392,
        "learning_rate": 0.0001403870183038546,
        "gradient_norm": 0.44439437985420227,
        "train_loss": 3.0382485389709473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22860,
        "tokens": 11985223680,
        "learning_rate": 0.00014036662614647967,
        "gradient_norm": 0.42108017206192017,
        "train_loss": 3.057126522064209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22861,
        "tokens": 11985747968,
        "learning_rate": 0.00014034623612366482,
        "gradient_norm": 0.4353320896625519,
        "train_loss": 3.0446457862854004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22862,
        "tokens": 11986272256,
        "learning_rate": 0.0001403258482356394,
        "gradient_norm": 0.5613633394241333,
        "train_loss": 3.0423688888549805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22863,
        "tokens": 11986796544,
        "learning_rate": 0.0001403054624826331,
        "gradient_norm": 0.4770485460758209,
        "train_loss": 3.0009610652923584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22864,
        "tokens": 11987320832,
        "learning_rate": 0.00014028507886487522,
        "gradient_norm": 0.45645707845687866,
        "train_loss": 3.009005069732666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22865,
        "tokens": 11987845120,
        "learning_rate": 0.00014026469738259527,
        "gradient_norm": 0.46607187390327454,
        "train_loss": 3.1110782623291016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22866,
        "tokens": 11988369408,
        "learning_rate": 0.00014024431803602263,
        "gradient_norm": 0.45091697573661804,
        "train_loss": 3.00775146484375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22867,
        "tokens": 11988893696,
        "learning_rate": 0.00014022394082538676,
        "gradient_norm": 0.4161299467086792,
        "train_loss": 3.1000192165374756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22868,
        "tokens": 11989417984,
        "learning_rate": 0.00014020356575091702,
        "gradient_norm": 0.4309104084968567,
        "train_loss": 3.04837703704834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22869,
        "tokens": 11989942272,
        "learning_rate": 0.0001401831928128427,
        "gradient_norm": 0.45864009857177734,
        "train_loss": 3.060708522796631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22870,
        "tokens": 11990466560,
        "learning_rate": 0.00014016282201139322,
        "gradient_norm": 0.4030783772468567,
        "train_loss": 3.056871175765991,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22871,
        "tokens": 11990990848,
        "learning_rate": 0.0001401424533467977,
        "gradient_norm": 0.42774760723114014,
        "train_loss": 3.074037790298462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22872,
        "tokens": 11991515136,
        "learning_rate": 0.00014012208681928566,
        "gradient_norm": 0.46375808119773865,
        "train_loss": 3.039064884185791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22873,
        "tokens": 11992039424,
        "learning_rate": 0.00014010172242908612,
        "gradient_norm": 0.5404397249221802,
        "train_loss": 3.0758824348449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22874,
        "tokens": 11992563712,
        "learning_rate": 0.00014008136017642852,
        "gradient_norm": 0.44759953022003174,
        "train_loss": 3.063105583190918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22875,
        "tokens": 11993088000,
        "learning_rate": 0.00014006100006154184,
        "gradient_norm": 0.45359060168266296,
        "train_loss": 3.0408525466918945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22876,
        "tokens": 11993612288,
        "learning_rate": 0.00014004064208465538,
        "gradient_norm": 0.45700907707214355,
        "train_loss": 2.978929281234741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22877,
        "tokens": 11994136576,
        "learning_rate": 0.00014002028624599834,
        "gradient_norm": 0.4694996476173401,
        "train_loss": 3.0657315254211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22878,
        "tokens": 11994660864,
        "learning_rate": 0.00013999993254579972,
        "gradient_norm": 0.42499786615371704,
        "train_loss": 3.0280961990356445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22879,
        "tokens": 11995185152,
        "learning_rate": 0.00013997958098428882,
        "gradient_norm": 0.5366364121437073,
        "train_loss": 3.0571234226226807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22880,
        "tokens": 11995709440,
        "learning_rate": 0.0001399592315616945,
        "gradient_norm": 0.4589180052280426,
        "train_loss": 3.024806022644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22881,
        "tokens": 11996233728,
        "learning_rate": 0.000139938884278246,
        "gradient_norm": 0.4396389424800873,
        "train_loss": 3.068802833557129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22882,
        "tokens": 11996758016,
        "learning_rate": 0.0001399185391341722,
        "gradient_norm": 0.5168923735618591,
        "train_loss": 3.0499885082244873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22883,
        "tokens": 11997282304,
        "learning_rate": 0.00013989819612970222,
        "gradient_norm": 0.41636690497398376,
        "train_loss": 3.030712127685547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22884,
        "tokens": 11997806592,
        "learning_rate": 0.000139877855265065,
        "gradient_norm": 0.5437256693840027,
        "train_loss": 3.0051088333129883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22885,
        "tokens": 11998330880,
        "learning_rate": 0.00013985751654048954,
        "gradient_norm": 0.41085124015808105,
        "train_loss": 3.079280376434326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22886,
        "tokens": 11998855168,
        "learning_rate": 0.0001398371799562047,
        "gradient_norm": 0.43704575300216675,
        "train_loss": 3.09898042678833,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22887,
        "tokens": 11999379456,
        "learning_rate": 0.00013981684551243943,
        "gradient_norm": 0.47625163197517395,
        "train_loss": 3.0054657459259033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22888,
        "tokens": 11999903744,
        "learning_rate": 0.00013979651320942274,
        "gradient_norm": 0.39915749430656433,
        "train_loss": 3.027848720550537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22889,
        "tokens": 12000428032,
        "learning_rate": 0.00013977618304738325,
        "gradient_norm": 0.44126904010772705,
        "train_loss": 2.9796714782714844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22890,
        "tokens": 12000952320,
        "learning_rate": 0.00013975585502655008,
        "gradient_norm": 0.398723840713501,
        "train_loss": 3.0420784950256348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22891,
        "tokens": 12001476608,
        "learning_rate": 0.0001397355291471518,
        "gradient_norm": 0.40569740533828735,
        "train_loss": 3.0583839416503906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22892,
        "tokens": 12002000896,
        "learning_rate": 0.0001397152054094174,
        "gradient_norm": 0.3803471326828003,
        "train_loss": 3.017544746398926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22893,
        "tokens": 12002525184,
        "learning_rate": 0.00013969488381357543,
        "gradient_norm": 0.397507905960083,
        "train_loss": 3.058624267578125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22894,
        "tokens": 12003049472,
        "learning_rate": 0.00013967456435985491,
        "gradient_norm": 0.3846897780895233,
        "train_loss": 3.0544652938842773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22895,
        "tokens": 12003573760,
        "learning_rate": 0.0001396542470484843,
        "gradient_norm": 0.39267697930336,
        "train_loss": 3.044480800628662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22896,
        "tokens": 12004098048,
        "learning_rate": 0.00013963393187969243,
        "gradient_norm": 0.37937405705451965,
        "train_loss": 3.0419023036956787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22897,
        "tokens": 12004622336,
        "learning_rate": 0.00013961361885370804,
        "gradient_norm": 0.37765395641326904,
        "train_loss": 2.997244358062744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22898,
        "tokens": 12005146624,
        "learning_rate": 0.0001395933079707596,
        "gradient_norm": 0.47570836544036865,
        "train_loss": 3.1525135040283203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22899,
        "tokens": 12005670912,
        "learning_rate": 0.0001395729992310759,
        "gradient_norm": 0.4607906937599182,
        "train_loss": 3.0087199211120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22900,
        "tokens": 12006195200,
        "learning_rate": 0.0001395526926348854,
        "gradient_norm": 0.42219704389572144,
        "train_loss": 3.0334043502807617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22901,
        "tokens": 12006719488,
        "learning_rate": 0.0001395323881824168,
        "gradient_norm": 0.4156416058540344,
        "train_loss": 3.012181043624878,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22902,
        "tokens": 12007243776,
        "learning_rate": 0.00013951208587389854,
        "gradient_norm": 0.41731998324394226,
        "train_loss": 3.0246424674987793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22903,
        "tokens": 12007768064,
        "learning_rate": 0.0001394917857095593,
        "gradient_norm": 0.41124483942985535,
        "train_loss": 3.1024622917175293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22904,
        "tokens": 12008292352,
        "learning_rate": 0.00013947148768962735,
        "gradient_norm": 0.4188356101512909,
        "train_loss": 3.0381436347961426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22905,
        "tokens": 12008816640,
        "learning_rate": 0.00013945119181433142,
        "gradient_norm": 0.39705774188041687,
        "train_loss": 3.060906410217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22906,
        "tokens": 12009340928,
        "learning_rate": 0.0001394308980838998,
        "gradient_norm": 0.46893706917762756,
        "train_loss": 2.9940505027770996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22907,
        "tokens": 12009865216,
        "learning_rate": 0.00013941060649856092,
        "gradient_norm": 0.4562992453575134,
        "train_loss": 3.0719809532165527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22908,
        "tokens": 12010389504,
        "learning_rate": 0.00013939031705854335,
        "gradient_norm": 0.42039403319358826,
        "train_loss": 3.032733678817749,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22909,
        "tokens": 12010913792,
        "learning_rate": 0.00013937002976407525,
        "gradient_norm": 0.44002124667167664,
        "train_loss": 2.9937028884887695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22910,
        "tokens": 12011438080,
        "learning_rate": 0.00013934974461538523,
        "gradient_norm": 0.4154035449028015,
        "train_loss": 3.0267815589904785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22911,
        "tokens": 12011962368,
        "learning_rate": 0.00013932946161270137,
        "gradient_norm": 0.42936670780181885,
        "train_loss": 3.0566844940185547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22912,
        "tokens": 12012486656,
        "learning_rate": 0.00013930918075625215,
        "gradient_norm": 0.4464304447174072,
        "train_loss": 3.098473072052002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22913,
        "tokens": 12013010944,
        "learning_rate": 0.00013928890204626578,
        "gradient_norm": 0.43172240257263184,
        "train_loss": 3.040553331375122,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22914,
        "tokens": 12013535232,
        "learning_rate": 0.0001392686254829706,
        "gradient_norm": 0.42357590794563293,
        "train_loss": 3.0181336402893066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22915,
        "tokens": 12014059520,
        "learning_rate": 0.0001392483510665947,
        "gradient_norm": 0.4032985270023346,
        "train_loss": 2.998027801513672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22916,
        "tokens": 12014583808,
        "learning_rate": 0.0001392280787973665,
        "gradient_norm": 0.4567135274410248,
        "train_loss": 3.0268301963806152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22917,
        "tokens": 12015108096,
        "learning_rate": 0.00013920780867551395,
        "gradient_norm": 0.4089829921722412,
        "train_loss": 3.0435357093811035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22918,
        "tokens": 12015632384,
        "learning_rate": 0.00013918754070126543,
        "gradient_norm": 0.42206642031669617,
        "train_loss": 3.001173496246338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22919,
        "tokens": 12016156672,
        "learning_rate": 0.00013916727487484895,
        "gradient_norm": 0.3790411651134491,
        "train_loss": 3.0030951499938965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22920,
        "tokens": 12016680960,
        "learning_rate": 0.00013914701119649274,
        "gradient_norm": 0.4670426845550537,
        "train_loss": 3.0555615425109863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22921,
        "tokens": 12017205248,
        "learning_rate": 0.00013912674966642472,
        "gradient_norm": 0.3901435434818268,
        "train_loss": 3.061072826385498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22922,
        "tokens": 12017729536,
        "learning_rate": 0.00013910649028487317,
        "gradient_norm": 0.4346197843551636,
        "train_loss": 3.0404553413391113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22923,
        "tokens": 12018253824,
        "learning_rate": 0.0001390862330520659,
        "gradient_norm": 0.41904085874557495,
        "train_loss": 3.0464134216308594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22924,
        "tokens": 12018778112,
        "learning_rate": 0.0001390659779682312,
        "gradient_norm": 0.437611848115921,
        "train_loss": 3.0585920810699463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22925,
        "tokens": 12019302400,
        "learning_rate": 0.00013904572503359682,
        "gradient_norm": 0.3833264708518982,
        "train_loss": 2.9764459133148193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22926,
        "tokens": 12019826688,
        "learning_rate": 0.0001390254742483909,
        "gradient_norm": 0.47206035256385803,
        "train_loss": 3.1152944564819336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22927,
        "tokens": 12020350976,
        "learning_rate": 0.00013900522561284122,
        "gradient_norm": 0.46479156613349915,
        "train_loss": 3.049586772918701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22928,
        "tokens": 12020875264,
        "learning_rate": 0.00013898497912717597,
        "gradient_norm": 0.44647061824798584,
        "train_loss": 3.0600643157958984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22929,
        "tokens": 12021399552,
        "learning_rate": 0.00013896473479162272,
        "gradient_norm": 0.4345848262310028,
        "train_loss": 3.015890121459961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22930,
        "tokens": 12021923840,
        "learning_rate": 0.0001389444926064096,
        "gradient_norm": 0.4183870553970337,
        "train_loss": 3.0004231929779053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22931,
        "tokens": 12022448128,
        "learning_rate": 0.00013892425257176435,
        "gradient_norm": 0.41540393233299255,
        "train_loss": 3.011679172515869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22932,
        "tokens": 12022972416,
        "learning_rate": 0.00013890401468791486,
        "gradient_norm": 0.41488760709762573,
        "train_loss": 3.0402650833129883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22933,
        "tokens": 12023496704,
        "learning_rate": 0.00013888377895508882,
        "gradient_norm": 0.458586186170578,
        "train_loss": 3.0357985496520996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22934,
        "tokens": 12024020992,
        "learning_rate": 0.00013886354537351417,
        "gradient_norm": 0.4237961173057556,
        "train_loss": 3.0525951385498047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22935,
        "tokens": 12024545280,
        "learning_rate": 0.0001388433139434185,
        "gradient_norm": 0.44623634219169617,
        "train_loss": 3.0375704765319824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22936,
        "tokens": 12025069568,
        "learning_rate": 0.0001388230846650296,
        "gradient_norm": 0.49945786595344543,
        "train_loss": 3.032379627227783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22937,
        "tokens": 12025593856,
        "learning_rate": 0.00013880285753857524,
        "gradient_norm": 0.4172878861427307,
        "train_loss": 3.003213882446289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22938,
        "tokens": 12026118144,
        "learning_rate": 0.00013878263256428302,
        "gradient_norm": 0.45477837324142456,
        "train_loss": 3.0296924114227295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22939,
        "tokens": 12026642432,
        "learning_rate": 0.00013876240974238071,
        "gradient_norm": 0.4270862936973572,
        "train_loss": 2.993924140930176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22940,
        "tokens": 12027166720,
        "learning_rate": 0.00013874218907309574,
        "gradient_norm": 0.42306697368621826,
        "train_loss": 3.048396587371826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22941,
        "tokens": 12027691008,
        "learning_rate": 0.00013872197055665595,
        "gradient_norm": 0.45413169264793396,
        "train_loss": 2.9840009212493896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22942,
        "tokens": 12028215296,
        "learning_rate": 0.00013870175419328874,
        "gradient_norm": 0.4320993423461914,
        "train_loss": 3.1167421340942383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22943,
        "tokens": 12028739584,
        "learning_rate": 0.00013868153998322183,
        "gradient_norm": 0.4403230845928192,
        "train_loss": 3.077385663986206,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22944,
        "tokens": 12029263872,
        "learning_rate": 0.00013866132792668257,
        "gradient_norm": 0.5019584894180298,
        "train_loss": 3.208596706390381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22945,
        "tokens": 12029788160,
        "learning_rate": 0.00013864111802389865,
        "gradient_norm": 0.4729537069797516,
        "train_loss": 3.0815610885620117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22946,
        "tokens": 12030312448,
        "learning_rate": 0.00013862091027509743,
        "gradient_norm": 0.46507686376571655,
        "train_loss": 3.070035457611084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22947,
        "tokens": 12030836736,
        "learning_rate": 0.0001386007046805064,
        "gradient_norm": 0.42873087525367737,
        "train_loss": 3.0791008472442627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22948,
        "tokens": 12031361024,
        "learning_rate": 0.00013858050124035312,
        "gradient_norm": 0.45371103286743164,
        "train_loss": 3.064941883087158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22949,
        "tokens": 12031885312,
        "learning_rate": 0.00013856029995486482,
        "gradient_norm": 0.513712465763092,
        "train_loss": 3.0626323223114014,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22950,
        "tokens": 12032409600,
        "learning_rate": 0.00013854010082426906,
        "gradient_norm": 0.43793222308158875,
        "train_loss": 3.0464487075805664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22951,
        "tokens": 12032933888,
        "learning_rate": 0.00013851990384879304,
        "gradient_norm": 0.4553971290588379,
        "train_loss": 2.985485553741455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22952,
        "tokens": 12033458176,
        "learning_rate": 0.0001384997090286643,
        "gradient_norm": 0.5308740735054016,
        "train_loss": 3.0993287563323975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22953,
        "tokens": 12033982464,
        "learning_rate": 0.00013847951636410994,
        "gradient_norm": 0.4653007984161377,
        "train_loss": 3.0544519424438477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22954,
        "tokens": 12034506752,
        "learning_rate": 0.00013845932585535746,
        "gradient_norm": 0.5498838424682617,
        "train_loss": 3.0629453659057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22955,
        "tokens": 12035031040,
        "learning_rate": 0.00013843913750263392,
        "gradient_norm": 0.4926624000072479,
        "train_loss": 3.0628528594970703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22956,
        "tokens": 12035555328,
        "learning_rate": 0.00013841895130616667,
        "gradient_norm": 0.48756176233291626,
        "train_loss": 3.0396625995635986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22957,
        "tokens": 12036079616,
        "learning_rate": 0.00013839876726618307,
        "gradient_norm": 0.5059233903884888,
        "train_loss": 3.0636661052703857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22958,
        "tokens": 12036603904,
        "learning_rate": 0.00013837858538291004,
        "gradient_norm": 0.4515376687049866,
        "train_loss": 3.0634360313415527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22959,
        "tokens": 12037128192,
        "learning_rate": 0.000138358405656575,
        "gradient_norm": 0.4766142666339874,
        "train_loss": 3.0956177711486816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22960,
        "tokens": 12037652480,
        "learning_rate": 0.0001383382280874049,
        "gradient_norm": 0.42090722918510437,
        "train_loss": 3.079227924346924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22961,
        "tokens": 12038176768,
        "learning_rate": 0.00013831805267562706,
        "gradient_norm": 0.435916930437088,
        "train_loss": 3.041660785675049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22962,
        "tokens": 12038701056,
        "learning_rate": 0.00013829787942146838,
        "gradient_norm": 0.45128434896469116,
        "train_loss": 3.0512123107910156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22963,
        "tokens": 12039225344,
        "learning_rate": 0.0001382777083251561,
        "gradient_norm": 0.4104943871498108,
        "train_loss": 3.0475802421569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22964,
        "tokens": 12039749632,
        "learning_rate": 0.00013825753938691716,
        "gradient_norm": 0.4633851647377014,
        "train_loss": 3.02864933013916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22965,
        "tokens": 12040273920,
        "learning_rate": 0.00013823737260697868,
        "gradient_norm": 0.4159274697303772,
        "train_loss": 3.059478998184204,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22966,
        "tokens": 12040798208,
        "learning_rate": 0.0001382172079855675,
        "gradient_norm": 0.4534637928009033,
        "train_loss": 3.0724406242370605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22967,
        "tokens": 12041322496,
        "learning_rate": 0.00013819704552291075,
        "gradient_norm": 0.41790297627449036,
        "train_loss": 3.0586204528808594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22968,
        "tokens": 12041846784,
        "learning_rate": 0.0001381768852192354,
        "gradient_norm": 0.48755019903182983,
        "train_loss": 3.0471951961517334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22969,
        "tokens": 12042371072,
        "learning_rate": 0.00013815672707476824,
        "gradient_norm": 0.41367897391319275,
        "train_loss": 3.0034642219543457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22970,
        "tokens": 12042895360,
        "learning_rate": 0.00013813657108973637,
        "gradient_norm": 0.40423640608787537,
        "train_loss": 3.008352756500244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22971,
        "tokens": 12043419648,
        "learning_rate": 0.00013811641726436643,
        "gradient_norm": 0.43215981125831604,
        "train_loss": 3.050339937210083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22972,
        "tokens": 12043943936,
        "learning_rate": 0.00013809626559888554,
        "gradient_norm": 0.3959409296512604,
        "train_loss": 3.049767017364502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22973,
        "tokens": 12044468224,
        "learning_rate": 0.00013807611609352027,
        "gradient_norm": 0.3913975656032562,
        "train_loss": 3.0289664268493652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22974,
        "tokens": 12044992512,
        "learning_rate": 0.00013805596874849765,
        "gradient_norm": 0.4464518129825592,
        "train_loss": 2.993199348449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22975,
        "tokens": 12045516800,
        "learning_rate": 0.00013803582356404425,
        "gradient_norm": 0.47115105390548706,
        "train_loss": 3.0534629821777344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22976,
        "tokens": 12046041088,
        "learning_rate": 0.00013801568054038697,
        "gradient_norm": 0.3890966773033142,
        "train_loss": 3.0537619590759277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22977,
        "tokens": 12046565376,
        "learning_rate": 0.00013799553967775262,
        "gradient_norm": 0.48398157954216003,
        "train_loss": 2.995260715484619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22978,
        "tokens": 12047089664,
        "learning_rate": 0.0001379754009763677,
        "gradient_norm": 0.39186757802963257,
        "train_loss": 3.033189296722412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22979,
        "tokens": 12047613952,
        "learning_rate": 0.0001379552644364591,
        "gradient_norm": 0.4796115756034851,
        "train_loss": 3.030456066131592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22980,
        "tokens": 12048138240,
        "learning_rate": 0.00013793513005825334,
        "gradient_norm": 0.4369457960128784,
        "train_loss": 3.0298800468444824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22981,
        "tokens": 12048662528,
        "learning_rate": 0.00013791499784197715,
        "gradient_norm": 0.47395870089530945,
        "train_loss": 2.9333508014678955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22982,
        "tokens": 12049186816,
        "learning_rate": 0.00013789486778785704,
        "gradient_norm": 0.47948765754699707,
        "train_loss": 3.0725576877593994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22983,
        "tokens": 12049711104,
        "learning_rate": 0.0001378747398961197,
        "gradient_norm": 0.42075204849243164,
        "train_loss": 3.0495142936706543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22984,
        "tokens": 12050235392,
        "learning_rate": 0.0001378546141669916,
        "gradient_norm": 0.4754853844642639,
        "train_loss": 2.979748249053955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22985,
        "tokens": 12050759680,
        "learning_rate": 0.0001378344906006994,
        "gradient_norm": 0.43176138401031494,
        "train_loss": 3.0877773761749268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22986,
        "tokens": 12051283968,
        "learning_rate": 0.00013781436919746946,
        "gradient_norm": 0.5284493565559387,
        "train_loss": 3.0193655490875244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22987,
        "tokens": 12051808256,
        "learning_rate": 0.0001377942499575284,
        "gradient_norm": 0.4394449293613434,
        "train_loss": 3.1140127182006836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22988,
        "tokens": 12052332544,
        "learning_rate": 0.00013777413288110273,
        "gradient_norm": 0.4543305039405823,
        "train_loss": 3.023338794708252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22989,
        "tokens": 12052856832,
        "learning_rate": 0.00013775401796841866,
        "gradient_norm": 0.4273098111152649,
        "train_loss": 3.0083022117614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22990,
        "tokens": 12053381120,
        "learning_rate": 0.00013773390521970292,
        "gradient_norm": 0.4443987309932709,
        "train_loss": 3.0964460372924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22991,
        "tokens": 12053905408,
        "learning_rate": 0.00013771379463518163,
        "gradient_norm": 0.4397529661655426,
        "train_loss": 3.016932487487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22992,
        "tokens": 12054429696,
        "learning_rate": 0.00013769368621508132,
        "gradient_norm": 0.41029566526412964,
        "train_loss": 3.0531153678894043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22993,
        "tokens": 12054953984,
        "learning_rate": 0.00013767357995962825,
        "gradient_norm": 0.3883996605873108,
        "train_loss": 3.0373587608337402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22994,
        "tokens": 12055478272,
        "learning_rate": 0.00013765347586904887,
        "gradient_norm": 0.4364843964576721,
        "train_loss": 3.061018705368042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22995,
        "tokens": 12056002560,
        "learning_rate": 0.00013763337394356927,
        "gradient_norm": 0.42342615127563477,
        "train_loss": 3.0870940685272217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22996,
        "tokens": 12056526848,
        "learning_rate": 0.00013761327418341585,
        "gradient_norm": 0.4308057427406311,
        "train_loss": 3.0770797729492188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22997,
        "tokens": 12057051136,
        "learning_rate": 0.0001375931765888149,
        "gradient_norm": 0.4100837707519531,
        "train_loss": 3.0139522552490234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22998,
        "tokens": 12057575424,
        "learning_rate": 0.00013757308115999256,
        "gradient_norm": 0.46994996070861816,
        "train_loss": 3.033710479736328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 22999,
        "tokens": 12058099712,
        "learning_rate": 0.00013755298789717513,
        "gradient_norm": 0.47168052196502686,
        "train_loss": 3.082003593444824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23000,
        "tokens": 12058624000,
        "learning_rate": 0.0001375328968005886,
        "gradient_norm": 0.44628122448921204,
        "train_loss": 3.03385591506958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23001,
        "tokens": 12059148288,
        "learning_rate": 0.00013751280787045934,
        "gradient_norm": 0.4581068754196167,
        "train_loss": 3.051398277282715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23002,
        "tokens": 12059672576,
        "learning_rate": 0.00013749272110701326,
        "gradient_norm": 0.44195669889450073,
        "train_loss": 3.082066059112549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23003,
        "tokens": 12060196864,
        "learning_rate": 0.00013747263651047668,
        "gradient_norm": 0.43348023295402527,
        "train_loss": 2.992966651916504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23004,
        "tokens": 12060721152,
        "learning_rate": 0.00013745255408107547,
        "gradient_norm": 0.43992164731025696,
        "train_loss": 3.0665671825408936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23005,
        "tokens": 12061245440,
        "learning_rate": 0.00013743247381903584,
        "gradient_norm": 0.4594596326351166,
        "train_loss": 3.068209409713745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23006,
        "tokens": 12061769728,
        "learning_rate": 0.00013741239572458372,
        "gradient_norm": 0.48796436190605164,
        "train_loss": 3.0368382930755615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23007,
        "tokens": 12062294016,
        "learning_rate": 0.00013739231979794514,
        "gradient_norm": 0.41976913809776306,
        "train_loss": 3.0375380516052246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23008,
        "tokens": 12062818304,
        "learning_rate": 0.00013737224603934615,
        "gradient_norm": 0.4385732114315033,
        "train_loss": 3.0413613319396973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23009,
        "tokens": 12063342592,
        "learning_rate": 0.00013735217444901262,
        "gradient_norm": 0.45858922600746155,
        "train_loss": 3.103585720062256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23010,
        "tokens": 12063866880,
        "learning_rate": 0.00013733210502717055,
        "gradient_norm": 0.42368340492248535,
        "train_loss": 3.009359359741211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23011,
        "tokens": 12064391168,
        "learning_rate": 0.00013731203777404572,
        "gradient_norm": 0.4337274730205536,
        "train_loss": 3.047701597213745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23012,
        "tokens": 12064915456,
        "learning_rate": 0.0001372919726898642,
        "gradient_norm": 0.46224164962768555,
        "train_loss": 3.0300352573394775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23013,
        "tokens": 12065439744,
        "learning_rate": 0.00013727190977485165,
        "gradient_norm": 0.592191219329834,
        "train_loss": 3.0746870040893555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23014,
        "tokens": 12065964032,
        "learning_rate": 0.0001372518490292341,
        "gradient_norm": 0.46449217200279236,
        "train_loss": 3.012193441390991,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23015,
        "tokens": 12066488320,
        "learning_rate": 0.00013723179045323713,
        "gradient_norm": 0.6072198748588562,
        "train_loss": 3.0516891479492188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23016,
        "tokens": 12067012608,
        "learning_rate": 0.0001372117340470867,
        "gradient_norm": 0.4033627510070801,
        "train_loss": 3.029512882232666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23017,
        "tokens": 12067536896,
        "learning_rate": 0.00013719167981100856,
        "gradient_norm": 0.5104605555534363,
        "train_loss": 3.073652982711792,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23018,
        "tokens": 12068061184,
        "learning_rate": 0.0001371716277452283,
        "gradient_norm": 0.41557955741882324,
        "train_loss": 3.0369060039520264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23019,
        "tokens": 12068585472,
        "learning_rate": 0.00013715157784997188,
        "gradient_norm": 0.4954509437084198,
        "train_loss": 3.0969653129577637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23020,
        "tokens": 12069109760,
        "learning_rate": 0.00013713153012546477,
        "gradient_norm": 0.46523529291152954,
        "train_loss": 3.0219554901123047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23021,
        "tokens": 12069634048,
        "learning_rate": 0.00013711148457193275,
        "gradient_norm": 0.5299829840660095,
        "train_loss": 3.1012279987335205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23022,
        "tokens": 12070158336,
        "learning_rate": 0.00013709144118960134,
        "gradient_norm": 0.436893105506897,
        "train_loss": 3.011972188949585,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23023,
        "tokens": 12070682624,
        "learning_rate": 0.00013707139997869627,
        "gradient_norm": 0.455127090215683,
        "train_loss": 2.9912123680114746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23024,
        "tokens": 12071206912,
        "learning_rate": 0.00013705136093944306,
        "gradient_norm": 0.48767611384391785,
        "train_loss": 3.070546865463257,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23025,
        "tokens": 12071731200,
        "learning_rate": 0.00013703132407206735,
        "gradient_norm": 0.48725149035453796,
        "train_loss": 2.993717670440674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23026,
        "tokens": 12072255488,
        "learning_rate": 0.00013701128937679456,
        "gradient_norm": 0.4271842837333679,
        "train_loss": 3.007589340209961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23027,
        "tokens": 12072779776,
        "learning_rate": 0.00013699125685385038,
        "gradient_norm": 0.44253140687942505,
        "train_loss": 3.0377285480499268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23028,
        "tokens": 12073304064,
        "learning_rate": 0.00013697122650346009,
        "gradient_norm": 0.44997918605804443,
        "train_loss": 3.008788585662842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23029,
        "tokens": 12073828352,
        "learning_rate": 0.00013695119832584932,
        "gradient_norm": 0.3879680037498474,
        "train_loss": 3.015867233276367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23030,
        "tokens": 12074352640,
        "learning_rate": 0.0001369311723212434,
        "gradient_norm": 0.48412078619003296,
        "train_loss": 3.0582339763641357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23031,
        "tokens": 12074876928,
        "learning_rate": 0.0001369111484898679,
        "gradient_norm": 0.41934046149253845,
        "train_loss": 3.0366060733795166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23032,
        "tokens": 12075401216,
        "learning_rate": 0.00013689112683194798,
        "gradient_norm": 0.463196337223053,
        "train_loss": 3.097115993499756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23033,
        "tokens": 12075925504,
        "learning_rate": 0.00013687110734770928,
        "gradient_norm": 0.45120176672935486,
        "train_loss": 3.0377206802368164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23034,
        "tokens": 12076449792,
        "learning_rate": 0.00013685109003737692,
        "gradient_norm": 0.4447581470012665,
        "train_loss": 3.027987003326416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23035,
        "tokens": 12076974080,
        "learning_rate": 0.00013683107490117637,
        "gradient_norm": 0.4731731712818146,
        "train_loss": 3.0278115272521973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23036,
        "tokens": 12077498368,
        "learning_rate": 0.00013681106193933276,
        "gradient_norm": 0.3963140547275543,
        "train_loss": 3.056448459625244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23037,
        "tokens": 12078022656,
        "learning_rate": 0.0001367910511520716,
        "gradient_norm": 0.4760165810585022,
        "train_loss": 3.0340089797973633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23038,
        "tokens": 12078546944,
        "learning_rate": 0.00013677104253961787,
        "gradient_norm": 0.40369367599487305,
        "train_loss": 3.05111026763916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23039,
        "tokens": 12079071232,
        "learning_rate": 0.00013675103610219706,
        "gradient_norm": 0.4054136574268341,
        "train_loss": 2.992180824279785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23040,
        "tokens": 12079595520,
        "learning_rate": 0.0001367310318400341,
        "gradient_norm": 0.41641032695770264,
        "train_loss": 3.0774588584899902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23041,
        "tokens": 12080119808,
        "learning_rate": 0.00013671102975335437,
        "gradient_norm": 0.41557544469833374,
        "train_loss": 3.010995388031006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23042,
        "tokens": 12080644096,
        "learning_rate": 0.0001366910298423829,
        "gradient_norm": 0.5147761702537537,
        "train_loss": 3.1394271850585938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23043,
        "tokens": 12081168384,
        "learning_rate": 0.0001366710321073449,
        "gradient_norm": 0.424780935049057,
        "train_loss": 3.041919231414795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23044,
        "tokens": 12081692672,
        "learning_rate": 0.00013665103654846535,
        "gradient_norm": 0.4449409544467926,
        "train_loss": 2.9896020889282227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23045,
        "tokens": 12082216960,
        "learning_rate": 0.0001366310431659695,
        "gradient_norm": 0.4631878435611725,
        "train_loss": 3.085629940032959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23046,
        "tokens": 12082741248,
        "learning_rate": 0.0001366110519600822,
        "gradient_norm": 0.4475664496421814,
        "train_loss": 3.029287338256836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23047,
        "tokens": 12083265536,
        "learning_rate": 0.0001365910629310286,
        "gradient_norm": 0.3941936194896698,
        "train_loss": 3.0167136192321777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23048,
        "tokens": 12083789824,
        "learning_rate": 0.00013657107607903374,
        "gradient_norm": 0.4401441812515259,
        "train_loss": 3.054931640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23049,
        "tokens": 12084314112,
        "learning_rate": 0.00013655109140432243,
        "gradient_norm": 0.3886587619781494,
        "train_loss": 3.015688896179199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23050,
        "tokens": 12084838400,
        "learning_rate": 0.00013653110890711988,
        "gradient_norm": 0.41696855425834656,
        "train_loss": 3.004157543182373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23051,
        "tokens": 12085362688,
        "learning_rate": 0.0001365111285876507,
        "gradient_norm": 0.3979053199291229,
        "train_loss": 3.0696096420288086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23052,
        "tokens": 12085886976,
        "learning_rate": 0.0001364911504461401,
        "gradient_norm": 0.3979150354862213,
        "train_loss": 3.1195549964904785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23053,
        "tokens": 12086411264,
        "learning_rate": 0.00013647117448281268,
        "gradient_norm": 0.48736968636512756,
        "train_loss": 3.085347890853882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23054,
        "tokens": 12086935552,
        "learning_rate": 0.00013645120069789358,
        "gradient_norm": 0.4584539532661438,
        "train_loss": 2.9751107692718506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23055,
        "tokens": 12087459840,
        "learning_rate": 0.00013643122909160735,
        "gradient_norm": 0.4664703607559204,
        "train_loss": 3.0140302181243896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23056,
        "tokens": 12087984128,
        "learning_rate": 0.00013641125966417896,
        "gradient_norm": 0.4293406009674072,
        "train_loss": 3.109694004058838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23057,
        "tokens": 12088508416,
        "learning_rate": 0.0001363912924158332,
        "gradient_norm": 0.42415499687194824,
        "train_loss": 3.0414085388183594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23058,
        "tokens": 12089032704,
        "learning_rate": 0.00013637132734679473,
        "gradient_norm": 0.3913782238960266,
        "train_loss": 3.0517678260803223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23059,
        "tokens": 12089556992,
        "learning_rate": 0.0001363513644572884,
        "gradient_norm": 0.4209958016872406,
        "train_loss": 2.9836201667785645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23060,
        "tokens": 12090081280,
        "learning_rate": 0.00013633140374753877,
        "gradient_norm": 0.36468932032585144,
        "train_loss": 3.018277645111084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23061,
        "tokens": 12090605568,
        "learning_rate": 0.00013631144521777068,
        "gradient_norm": 0.4000322222709656,
        "train_loss": 3.017134428024292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23062,
        "tokens": 12091129856,
        "learning_rate": 0.00013629148886820866,
        "gradient_norm": 0.44740867614746094,
        "train_loss": 3.069556951522827,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23063,
        "tokens": 12091654144,
        "learning_rate": 0.00013627153469907748,
        "gradient_norm": 0.4032723903656006,
        "train_loss": 3.0086843967437744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23064,
        "tokens": 12092178432,
        "learning_rate": 0.00013625158271060155,
        "gradient_norm": 0.45115700364112854,
        "train_loss": 2.980384349822998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23065,
        "tokens": 12092702720,
        "learning_rate": 0.00013623163290300567,
        "gradient_norm": 0.4205837845802307,
        "train_loss": 2.9827470779418945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23066,
        "tokens": 12093227008,
        "learning_rate": 0.0001362116852765142,
        "gradient_norm": 0.45315033197402954,
        "train_loss": 3.026427745819092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23067,
        "tokens": 12093751296,
        "learning_rate": 0.0001361917398313518,
        "gradient_norm": 0.46559855341911316,
        "train_loss": 3.0559394359588623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23068,
        "tokens": 12094275584,
        "learning_rate": 0.00013617179656774306,
        "gradient_norm": 0.40118128061294556,
        "train_loss": 3.061328649520874,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23069,
        "tokens": 12094799872,
        "learning_rate": 0.00013615185548591224,
        "gradient_norm": 0.3846895694732666,
        "train_loss": 3.0605618953704834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23070,
        "tokens": 12095324160,
        "learning_rate": 0.000136131916586084,
        "gradient_norm": 0.45741039514541626,
        "train_loss": 3.0792088508605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23071,
        "tokens": 12095848448,
        "learning_rate": 0.00013611197986848264,
        "gradient_norm": 0.3975217640399933,
        "train_loss": 3.0150461196899414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23072,
        "tokens": 12096372736,
        "learning_rate": 0.00013609204533333275,
        "gradient_norm": 0.4475315511226654,
        "train_loss": 3.0221357345581055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23073,
        "tokens": 12096897024,
        "learning_rate": 0.00013607211298085847,
        "gradient_norm": 0.40136685967445374,
        "train_loss": 3.022381544113159,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23074,
        "tokens": 12097421312,
        "learning_rate": 0.0001360521828112844,
        "gradient_norm": 0.43765655159950256,
        "train_loss": 3.0586156845092773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23075,
        "tokens": 12097945600,
        "learning_rate": 0.00013603225482483467,
        "gradient_norm": 0.39443856477737427,
        "train_loss": 3.0379295349121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23076,
        "tokens": 12098469888,
        "learning_rate": 0.0001360123290217337,
        "gradient_norm": 0.4351392388343811,
        "train_loss": 3.0028810501098633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23077,
        "tokens": 12098994176,
        "learning_rate": 0.00013599240540220593,
        "gradient_norm": 0.38583439588546753,
        "train_loss": 3.0813984870910645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23078,
        "tokens": 12099518464,
        "learning_rate": 0.00013597248396647534,
        "gradient_norm": 0.4210202693939209,
        "train_loss": 2.9815142154693604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23079,
        "tokens": 12100042752,
        "learning_rate": 0.00013595256471476632,
        "gradient_norm": 0.39806079864501953,
        "train_loss": 2.987760066986084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23080,
        "tokens": 12100567040,
        "learning_rate": 0.0001359326476473031,
        "gradient_norm": 0.41023877263069153,
        "train_loss": 3.0845704078674316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23081,
        "tokens": 12101091328,
        "learning_rate": 0.00013591273276430986,
        "gradient_norm": 0.4261215627193451,
        "train_loss": 3.028637647628784,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23082,
        "tokens": 12101615616,
        "learning_rate": 0.00013589282006601068,
        "gradient_norm": 0.41392409801483154,
        "train_loss": 2.9702980518341064,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23083,
        "tokens": 12102139904,
        "learning_rate": 0.00013587290955262987,
        "gradient_norm": 0.42193183302879333,
        "train_loss": 3.041755437850952,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23084,
        "tokens": 12102664192,
        "learning_rate": 0.00013585300122439134,
        "gradient_norm": 0.4086838662624359,
        "train_loss": 3.0488510131835938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23085,
        "tokens": 12103188480,
        "learning_rate": 0.0001358330950815194,
        "gradient_norm": 0.42050328850746155,
        "train_loss": 3.0878639221191406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23086,
        "tokens": 12103712768,
        "learning_rate": 0.0001358131911242379,
        "gradient_norm": 0.40736842155456543,
        "train_loss": 3.014322280883789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23087,
        "tokens": 12104237056,
        "learning_rate": 0.000135793289352771,
        "gradient_norm": 0.4191737174987793,
        "train_loss": 3.0906519889831543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23088,
        "tokens": 12104761344,
        "learning_rate": 0.00013577338976734286,
        "gradient_norm": 0.45361146330833435,
        "train_loss": 3.0932986736297607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23089,
        "tokens": 12105285632,
        "learning_rate": 0.00013575349236817717,
        "gradient_norm": 0.4602241814136505,
        "train_loss": 3.0925045013427734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23090,
        "tokens": 12105809920,
        "learning_rate": 0.00013573359715549817,
        "gradient_norm": 0.4589998424053192,
        "train_loss": 3.0632593631744385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23091,
        "tokens": 12106334208,
        "learning_rate": 0.00013571370412952962,
        "gradient_norm": 0.4426732659339905,
        "train_loss": 3.168337345123291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23092,
        "tokens": 12106858496,
        "learning_rate": 0.00013569381329049554,
        "gradient_norm": 0.45332881808280945,
        "train_loss": 3.10125732421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23093,
        "tokens": 12107382784,
        "learning_rate": 0.0001356739246386198,
        "gradient_norm": 0.41908594965934753,
        "train_loss": 2.995697021484375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23094,
        "tokens": 12107907072,
        "learning_rate": 0.00013565403817412627,
        "gradient_norm": 0.5286511182785034,
        "train_loss": 3.0378363132476807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23095,
        "tokens": 12108431360,
        "learning_rate": 0.0001356341538972388,
        "gradient_norm": 0.40920788049697876,
        "train_loss": 3.0146331787109375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23096,
        "tokens": 12108955648,
        "learning_rate": 0.00013561427180818115,
        "gradient_norm": 0.4329959452152252,
        "train_loss": 3.023376226425171,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23097,
        "tokens": 12109479936,
        "learning_rate": 0.0001355943919071773,
        "gradient_norm": 0.41446197032928467,
        "train_loss": 3.086690902709961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23098,
        "tokens": 12110004224,
        "learning_rate": 0.00013557451419445078,
        "gradient_norm": 0.40683209896087646,
        "train_loss": 3.1175951957702637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23099,
        "tokens": 12110528512,
        "learning_rate": 0.00013555463867022556,
        "gradient_norm": 0.48730412125587463,
        "train_loss": 3.0080161094665527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23100,
        "tokens": 12111052800,
        "learning_rate": 0.0001355347653347252,
        "gradient_norm": 0.42269477248191833,
        "train_loss": 3.018118381500244,
        "val_loss": 2.9944310188293457,
        "hellaswag_acc": 0.2841067612171173,
        "hellaswag_acc_norm": 0.2948615849018097
    },
    {
        "step": 23101,
        "tokens": 12111577088,
        "learning_rate": 0.00013551489418817353,
        "gradient_norm": 0.4802929759025574,
        "train_loss": 3.073556661605835,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23102,
        "tokens": 12112101376,
        "learning_rate": 0.0001354950252307941,
        "gradient_norm": 0.4308461546897888,
        "train_loss": 3.0241036415100098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23103,
        "tokens": 12112625664,
        "learning_rate": 0.00013547515846281066,
        "gradient_norm": 0.42019081115722656,
        "train_loss": 3.07466983795166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23104,
        "tokens": 12113149952,
        "learning_rate": 0.00013545529388444674,
        "gradient_norm": 0.4407440423965454,
        "train_loss": 3.019427537918091,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23105,
        "tokens": 12113674240,
        "learning_rate": 0.00013543543149592603,
        "gradient_norm": 0.4184817373752594,
        "train_loss": 3.0371646881103516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23106,
        "tokens": 12114198528,
        "learning_rate": 0.00013541557129747203,
        "gradient_norm": 0.430987149477005,
        "train_loss": 3.0096724033355713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23107,
        "tokens": 12114722816,
        "learning_rate": 0.00013539571328930833,
        "gradient_norm": 0.4196399748325348,
        "train_loss": 3.070890426635742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23108,
        "tokens": 12115247104,
        "learning_rate": 0.00013537585747165853,
        "gradient_norm": 0.4258604645729065,
        "train_loss": 2.991211175918579,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23109,
        "tokens": 12115771392,
        "learning_rate": 0.00013535600384474597,
        "gradient_norm": 0.45528385043144226,
        "train_loss": 3.0827817916870117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23110,
        "tokens": 12116295680,
        "learning_rate": 0.0001353361524087943,
        "gradient_norm": 0.41390904784202576,
        "train_loss": 2.9928348064422607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23111,
        "tokens": 12116819968,
        "learning_rate": 0.00013531630316402683,
        "gradient_norm": 0.47241488099098206,
        "train_loss": 2.968219757080078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23112,
        "tokens": 12117344256,
        "learning_rate": 0.0001352964561106671,
        "gradient_norm": 0.43944939970970154,
        "train_loss": 3.0779576301574707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23113,
        "tokens": 12117868544,
        "learning_rate": 0.00013527661124893844,
        "gradient_norm": 0.4544767439365387,
        "train_loss": 3.042064666748047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23114,
        "tokens": 12118392832,
        "learning_rate": 0.00013525676857906426,
        "gradient_norm": 0.4456152021884918,
        "train_loss": 3.035094738006592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23115,
        "tokens": 12118917120,
        "learning_rate": 0.00013523692810126785,
        "gradient_norm": 0.45186275243759155,
        "train_loss": 3.0858590602874756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23116,
        "tokens": 12119441408,
        "learning_rate": 0.00013521708981577258,
        "gradient_norm": 0.41772761940956116,
        "train_loss": 3.0259902477264404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23117,
        "tokens": 12119965696,
        "learning_rate": 0.00013519725372280187,
        "gradient_norm": 0.4483893811702728,
        "train_loss": 3.0268778800964355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23118,
        "tokens": 12120489984,
        "learning_rate": 0.00013517741982257882,
        "gradient_norm": 0.4471546709537506,
        "train_loss": 3.027369737625122,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23119,
        "tokens": 12121014272,
        "learning_rate": 0.00013515758811532684,
        "gradient_norm": 0.43045949935913086,
        "train_loss": 3.0893054008483887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23120,
        "tokens": 12121538560,
        "learning_rate": 0.00013513775860126898,
        "gradient_norm": 0.47044074535369873,
        "train_loss": 3.0654115676879883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23121,
        "tokens": 12122062848,
        "learning_rate": 0.00013511793128062865,
        "gradient_norm": 0.4242657721042633,
        "train_loss": 3.0854053497314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23122,
        "tokens": 12122587136,
        "learning_rate": 0.00013509810615362883,
        "gradient_norm": 0.45394665002822876,
        "train_loss": 3.0302786827087402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23123,
        "tokens": 12123111424,
        "learning_rate": 0.00013507828322049286,
        "gradient_norm": 0.4542767107486725,
        "train_loss": 3.1391289234161377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23124,
        "tokens": 12123635712,
        "learning_rate": 0.00013505846248144373,
        "gradient_norm": 0.4860336482524872,
        "train_loss": 3.010349750518799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23125,
        "tokens": 12124160000,
        "learning_rate": 0.00013503864393670466,
        "gradient_norm": 0.4568016827106476,
        "train_loss": 3.047482490539551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23126,
        "tokens": 12124684288,
        "learning_rate": 0.0001350188275864986,
        "gradient_norm": 0.6342674493789673,
        "train_loss": 3.042471170425415,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23127,
        "tokens": 12125208576,
        "learning_rate": 0.00013499901343104877,
        "gradient_norm": 0.4043864607810974,
        "train_loss": 3.04420804977417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23128,
        "tokens": 12125732864,
        "learning_rate": 0.00013497920147057804,
        "gradient_norm": 0.4549572467803955,
        "train_loss": 3.027148723602295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23129,
        "tokens": 12126257152,
        "learning_rate": 0.0001349593917053096,
        "gradient_norm": 0.4813920259475708,
        "train_loss": 3.0041604042053223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23130,
        "tokens": 12126781440,
        "learning_rate": 0.00013493958413546622,
        "gradient_norm": 0.46738481521606445,
        "train_loss": 3.073690414428711,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23131,
        "tokens": 12127305728,
        "learning_rate": 0.00013491977876127107,
        "gradient_norm": 0.41961669921875,
        "train_loss": 3.0482189655303955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23132,
        "tokens": 12127830016,
        "learning_rate": 0.0001348999755829469,
        "gradient_norm": 0.4286608397960663,
        "train_loss": 3.0744752883911133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23133,
        "tokens": 12128354304,
        "learning_rate": 0.0001348801746007168,
        "gradient_norm": 0.5070874691009521,
        "train_loss": 3.028975009918213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23134,
        "tokens": 12128878592,
        "learning_rate": 0.00013486037581480345,
        "gradient_norm": 0.3965652883052826,
        "train_loss": 3.0353033542633057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23135,
        "tokens": 12129402880,
        "learning_rate": 0.00013484057922542994,
        "gradient_norm": 0.4267125129699707,
        "train_loss": 3.0092222690582275,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23136,
        "tokens": 12129927168,
        "learning_rate": 0.00013482078483281884,
        "gradient_norm": 0.4067424535751343,
        "train_loss": 3.0259597301483154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23137,
        "tokens": 12130451456,
        "learning_rate": 0.00013480099263719322,
        "gradient_norm": 0.483011931180954,
        "train_loss": 3.005512237548828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23138,
        "tokens": 12130975744,
        "learning_rate": 0.00013478120263877566,
        "gradient_norm": 0.4325660765171051,
        "train_loss": 3.1130995750427246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23139,
        "tokens": 12131500032,
        "learning_rate": 0.0001347614148377891,
        "gradient_norm": 0.47528523206710815,
        "train_loss": 3.1945948600769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23140,
        "tokens": 12132024320,
        "learning_rate": 0.00013474162923445611,
        "gradient_norm": 0.49281564354896545,
        "train_loss": 3.057626247406006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23141,
        "tokens": 12132548608,
        "learning_rate": 0.00013472184582899953,
        "gradient_norm": 0.47683000564575195,
        "train_loss": 3.0417439937591553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23142,
        "tokens": 12133072896,
        "learning_rate": 0.00013470206462164197,
        "gradient_norm": 0.4296274483203888,
        "train_loss": 3.0431365966796875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23143,
        "tokens": 12133597184,
        "learning_rate": 0.00013468228561260617,
        "gradient_norm": 0.46911105513572693,
        "train_loss": 3.0373706817626953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23144,
        "tokens": 12134121472,
        "learning_rate": 0.0001346625088021146,
        "gradient_norm": 0.4092695713043213,
        "train_loss": 3.0475804805755615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23145,
        "tokens": 12134645760,
        "learning_rate": 0.0001346427341903901,
        "gradient_norm": 0.42684611678123474,
        "train_loss": 3.020904541015625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23146,
        "tokens": 12135170048,
        "learning_rate": 0.00013462296177765506,
        "gradient_norm": 0.5181117057800293,
        "train_loss": 3.1756792068481445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23147,
        "tokens": 12135694336,
        "learning_rate": 0.00013460319156413214,
        "gradient_norm": 0.43362167477607727,
        "train_loss": 3.0739150047302246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23148,
        "tokens": 12136218624,
        "learning_rate": 0.0001345834235500439,
        "gradient_norm": 0.43998581171035767,
        "train_loss": 3.078953981399536,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23149,
        "tokens": 12136742912,
        "learning_rate": 0.0001345636577356128,
        "gradient_norm": 0.4424935281276703,
        "train_loss": 3.062073230743408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23150,
        "tokens": 12137267200,
        "learning_rate": 0.00013454389412106144,
        "gradient_norm": 0.393960177898407,
        "train_loss": 3.0140891075134277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23151,
        "tokens": 12137791488,
        "learning_rate": 0.00013452413270661207,
        "gradient_norm": 0.41615116596221924,
        "train_loss": 2.982227087020874,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23152,
        "tokens": 12138315776,
        "learning_rate": 0.00013450437349248734,
        "gradient_norm": 0.41899797320365906,
        "train_loss": 3.0420398712158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23153,
        "tokens": 12138840064,
        "learning_rate": 0.00013448461647890951,
        "gradient_norm": 0.3858967125415802,
        "train_loss": 3.029177188873291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23154,
        "tokens": 12139364352,
        "learning_rate": 0.00013446486166610115,
        "gradient_norm": 0.4132218360900879,
        "train_loss": 3.0546302795410156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23155,
        "tokens": 12139888640,
        "learning_rate": 0.0001344451090542844,
        "gradient_norm": 0.43371811509132385,
        "train_loss": 3.1599907875061035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23156,
        "tokens": 12140412928,
        "learning_rate": 0.00013442535864368168,
        "gradient_norm": 0.4604197144508362,
        "train_loss": 3.0551280975341797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23157,
        "tokens": 12140937216,
        "learning_rate": 0.00013440561043451545,
        "gradient_norm": 0.4460732042789459,
        "train_loss": 3.1335716247558594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23158,
        "tokens": 12141461504,
        "learning_rate": 0.00013438586442700783,
        "gradient_norm": 0.40185314416885376,
        "train_loss": 3.039729595184326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23159,
        "tokens": 12141985792,
        "learning_rate": 0.0001343661206213812,
        "gradient_norm": 0.3993639647960663,
        "train_loss": 3.016491651535034,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23160,
        "tokens": 12142510080,
        "learning_rate": 0.00013434637901785766,
        "gradient_norm": 0.47424429655075073,
        "train_loss": 3.1124110221862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23161,
        "tokens": 12143034368,
        "learning_rate": 0.0001343266396166596,
        "gradient_norm": 0.43493619561195374,
        "train_loss": 3.0077285766601562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23162,
        "tokens": 12143558656,
        "learning_rate": 0.00013430690241800902,
        "gradient_norm": 0.44299745559692383,
        "train_loss": 3.066974639892578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23163,
        "tokens": 12144082944,
        "learning_rate": 0.00013428716742212835,
        "gradient_norm": 0.45342281460762024,
        "train_loss": 3.082211971282959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23164,
        "tokens": 12144607232,
        "learning_rate": 0.00013426743462923943,
        "gradient_norm": 0.41827645897865295,
        "train_loss": 3.014863967895508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23165,
        "tokens": 12145131520,
        "learning_rate": 0.0001342477040395646,
        "gradient_norm": 0.46058911085128784,
        "train_loss": 3.1358134746551514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23166,
        "tokens": 12145655808,
        "learning_rate": 0.00013422797565332582,
        "gradient_norm": 0.40433499217033386,
        "train_loss": 3.05600643157959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23167,
        "tokens": 12146180096,
        "learning_rate": 0.0001342082494707452,
        "gradient_norm": 0.43825140595436096,
        "train_loss": 3.021599292755127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23168,
        "tokens": 12146704384,
        "learning_rate": 0.00013418852549204485,
        "gradient_norm": 0.4157772362232208,
        "train_loss": 3.025374412536621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23169,
        "tokens": 12147228672,
        "learning_rate": 0.00013416880371744667,
        "gradient_norm": 0.4957512319087982,
        "train_loss": 3.042388439178467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23170,
        "tokens": 12147752960,
        "learning_rate": 0.0001341490841471728,
        "gradient_norm": 0.41688063740730286,
        "train_loss": 3.0185670852661133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23171,
        "tokens": 12148277248,
        "learning_rate": 0.00013412936678144504,
        "gradient_norm": 0.4646703600883484,
        "train_loss": 3.015338897705078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23172,
        "tokens": 12148801536,
        "learning_rate": 0.0001341096516204855,
        "gradient_norm": 0.41351112723350525,
        "train_loss": 3.0193395614624023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23173,
        "tokens": 12149325824,
        "learning_rate": 0.00013408993866451593,
        "gradient_norm": 0.4625473916530609,
        "train_loss": 3.047745704650879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23174,
        "tokens": 12149850112,
        "learning_rate": 0.00013407022791375836,
        "gradient_norm": 0.4274556040763855,
        "train_loss": 2.96663236618042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23175,
        "tokens": 12150374400,
        "learning_rate": 0.00013405051936843458,
        "gradient_norm": 0.48943018913269043,
        "train_loss": 3.041171073913574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23176,
        "tokens": 12150898688,
        "learning_rate": 0.00013403081302876642,
        "gradient_norm": 0.3638142943382263,
        "train_loss": 2.99505615234375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23177,
        "tokens": 12151422976,
        "learning_rate": 0.00013401110889497584,
        "gradient_norm": 0.4120010435581207,
        "train_loss": 3.087090253829956,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23178,
        "tokens": 12151947264,
        "learning_rate": 0.00013399140696728444,
        "gradient_norm": 0.44782817363739014,
        "train_loss": 3.0204226970672607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23179,
        "tokens": 12152471552,
        "learning_rate": 0.0001339717072459142,
        "gradient_norm": 0.38978445529937744,
        "train_loss": 3.0784552097320557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23180,
        "tokens": 12152995840,
        "learning_rate": 0.00013395200973108666,
        "gradient_norm": 0.49488359689712524,
        "train_loss": 3.0076441764831543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23181,
        "tokens": 12153520128,
        "learning_rate": 0.00013393231442302366,
        "gradient_norm": 0.40706291794776917,
        "train_loss": 3.003021240234375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23182,
        "tokens": 12154044416,
        "learning_rate": 0.00013391262132194683,
        "gradient_norm": 0.4248391389846802,
        "train_loss": 3.002917766571045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23183,
        "tokens": 12154568704,
        "learning_rate": 0.00013389293042807794,
        "gradient_norm": 0.39934566617012024,
        "train_loss": 3.0464842319488525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23184,
        "tokens": 12155092992,
        "learning_rate": 0.00013387324174163854,
        "gradient_norm": 0.4840705692768097,
        "train_loss": 3.1002893447875977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23185,
        "tokens": 12155617280,
        "learning_rate": 0.00013385355526285031,
        "gradient_norm": 0.41632241010665894,
        "train_loss": 3.038491725921631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23186,
        "tokens": 12156141568,
        "learning_rate": 0.00013383387099193475,
        "gradient_norm": 0.41504809260368347,
        "train_loss": 3.0039329528808594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23187,
        "tokens": 12156665856,
        "learning_rate": 0.00013381418892911351,
        "gradient_norm": 0.3997960686683655,
        "train_loss": 3.0239405632019043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23188,
        "tokens": 12157190144,
        "learning_rate": 0.00013379450907460822,
        "gradient_norm": 0.44664302468299866,
        "train_loss": 3.0206174850463867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23189,
        "tokens": 12157714432,
        "learning_rate": 0.00013377483142864018,
        "gradient_norm": 0.4166302978992462,
        "train_loss": 3.0400309562683105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23190,
        "tokens": 12158238720,
        "learning_rate": 0.00013375515599143114,
        "gradient_norm": 0.43460509181022644,
        "train_loss": 2.9840638637542725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23191,
        "tokens": 12158763008,
        "learning_rate": 0.0001337354827632023,
        "gradient_norm": 0.39932307600975037,
        "train_loss": 3.024712562561035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23192,
        "tokens": 12159287296,
        "learning_rate": 0.00013371581174417542,
        "gradient_norm": 0.46137529611587524,
        "train_loss": 3.038160800933838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23193,
        "tokens": 12159811584,
        "learning_rate": 0.0001336961429345716,
        "gradient_norm": 0.4416669011116028,
        "train_loss": 3.0520706176757812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23194,
        "tokens": 12160335872,
        "learning_rate": 0.00013367647633461254,
        "gradient_norm": 0.4062698185443878,
        "train_loss": 2.973268508911133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23195,
        "tokens": 12160860160,
        "learning_rate": 0.00013365681194451933,
        "gradient_norm": 0.4532122015953064,
        "train_loss": 3.0522983074188232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23196,
        "tokens": 12161384448,
        "learning_rate": 0.00013363714976451346,
        "gradient_norm": 0.38848742842674255,
        "train_loss": 3.065182685852051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23197,
        "tokens": 12161908736,
        "learning_rate": 0.00013361748979481635,
        "gradient_norm": 0.40560197830200195,
        "train_loss": 3.067793846130371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23198,
        "tokens": 12162433024,
        "learning_rate": 0.00013359783203564904,
        "gradient_norm": 0.4342305660247803,
        "train_loss": 3.0862321853637695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23199,
        "tokens": 12162957312,
        "learning_rate": 0.00013357817648723309,
        "gradient_norm": 0.39764106273651123,
        "train_loss": 2.99473237991333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23200,
        "tokens": 12163481600,
        "learning_rate": 0.00013355852314978953,
        "gradient_norm": 0.420127809047699,
        "train_loss": 3.00114107131958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23201,
        "tokens": 12164005888,
        "learning_rate": 0.00013353887202353972,
        "gradient_norm": 0.44111502170562744,
        "train_loss": 3.0723700523376465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23202,
        "tokens": 12164530176,
        "learning_rate": 0.0001335192231087047,
        "gradient_norm": 0.41596129536628723,
        "train_loss": 2.9944820404052734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23203,
        "tokens": 12165054464,
        "learning_rate": 0.00013349957640550588,
        "gradient_norm": 0.45080527663230896,
        "train_loss": 3.104881763458252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23204,
        "tokens": 12165578752,
        "learning_rate": 0.0001334799319141642,
        "gradient_norm": 0.3921152949333191,
        "train_loss": 3.081307888031006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23205,
        "tokens": 12166103040,
        "learning_rate": 0.0001334602896349008,
        "gradient_norm": 0.43085628747940063,
        "train_loss": 3.0514469146728516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23206,
        "tokens": 12166627328,
        "learning_rate": 0.0001334406495679369,
        "gradient_norm": 0.3796067535877228,
        "train_loss": 3.0917253494262695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23207,
        "tokens": 12167151616,
        "learning_rate": 0.0001334210117134935,
        "gradient_norm": 0.4552903175354004,
        "train_loss": 3.081892490386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23208,
        "tokens": 12167675904,
        "learning_rate": 0.00013340137607179171,
        "gradient_norm": 0.4878212511539459,
        "train_loss": 3.100965976715088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23209,
        "tokens": 12168200192,
        "learning_rate": 0.00013338174264305238,
        "gradient_norm": 0.5291368961334229,
        "train_loss": 3.1266140937805176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23210,
        "tokens": 12168724480,
        "learning_rate": 0.00013336211142749672,
        "gradient_norm": 0.5941122770309448,
        "train_loss": 3.010134220123291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23211,
        "tokens": 12169248768,
        "learning_rate": 0.00013334248242534555,
        "gradient_norm": 0.45520809292793274,
        "train_loss": 3.011139154434204,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23212,
        "tokens": 12169773056,
        "learning_rate": 0.00013332285563681995,
        "gradient_norm": 0.4837085008621216,
        "train_loss": 3.050626039505005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23213,
        "tokens": 12170297344,
        "learning_rate": 0.0001333032310621407,
        "gradient_norm": 0.44482070207595825,
        "train_loss": 3.058526039123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23214,
        "tokens": 12170821632,
        "learning_rate": 0.00013328360870152884,
        "gradient_norm": 0.5015270709991455,
        "train_loss": 3.0281548500061035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23215,
        "tokens": 12171345920,
        "learning_rate": 0.00013326398855520514,
        "gradient_norm": 0.45458415150642395,
        "train_loss": 3.0504355430603027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23216,
        "tokens": 12171870208,
        "learning_rate": 0.00013324437062339046,
        "gradient_norm": 0.44346433877944946,
        "train_loss": 3.0761256217956543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23217,
        "tokens": 12172394496,
        "learning_rate": 0.00013322475490630574,
        "gradient_norm": 0.4329618513584137,
        "train_loss": 3.0200905799865723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23218,
        "tokens": 12172918784,
        "learning_rate": 0.00013320514140417158,
        "gradient_norm": 0.4469859302043915,
        "train_loss": 2.9975523948669434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23219,
        "tokens": 12173443072,
        "learning_rate": 0.00013318553011720897,
        "gradient_norm": 0.37832897901535034,
        "train_loss": 3.0358633995056152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23220,
        "tokens": 12173967360,
        "learning_rate": 0.00013316592104563844,
        "gradient_norm": 0.43405938148498535,
        "train_loss": 3.040843963623047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23221,
        "tokens": 12174491648,
        "learning_rate": 0.00013314631418968095,
        "gradient_norm": 0.38837265968322754,
        "train_loss": 3.0138702392578125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23222,
        "tokens": 12175015936,
        "learning_rate": 0.00013312670954955698,
        "gradient_norm": 0.3995138704776764,
        "train_loss": 3.0039772987365723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23223,
        "tokens": 12175540224,
        "learning_rate": 0.0001331071071254874,
        "gradient_norm": 0.3997947573661804,
        "train_loss": 3.0940301418304443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23224,
        "tokens": 12176064512,
        "learning_rate": 0.00013308750691769266,
        "gradient_norm": 0.43482327461242676,
        "train_loss": 2.9993982315063477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23225,
        "tokens": 12176588800,
        "learning_rate": 0.0001330679089263935,
        "gradient_norm": 0.4242664873600006,
        "train_loss": 3.098623275756836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23226,
        "tokens": 12177113088,
        "learning_rate": 0.00013304831315181058,
        "gradient_norm": 0.3883395493030548,
        "train_loss": 3.0436997413635254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23227,
        "tokens": 12177637376,
        "learning_rate": 0.00013302871959416433,
        "gradient_norm": 0.4377944767475128,
        "train_loss": 3.0418994426727295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23228,
        "tokens": 12178161664,
        "learning_rate": 0.00013300912825367543,
        "gradient_norm": 0.42234620451927185,
        "train_loss": 3.0709166526794434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23229,
        "tokens": 12178685952,
        "learning_rate": 0.0001329895391305643,
        "gradient_norm": 0.4141416549682617,
        "train_loss": 3.0357985496520996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23230,
        "tokens": 12179210240,
        "learning_rate": 0.00013296995222505156,
        "gradient_norm": 0.43401575088500977,
        "train_loss": 3.0435447692871094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23231,
        "tokens": 12179734528,
        "learning_rate": 0.00013295036753735754,
        "gradient_norm": 0.5057825446128845,
        "train_loss": 3.0348310470581055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23232,
        "tokens": 12180258816,
        "learning_rate": 0.00013293078506770278,
        "gradient_norm": 0.4019346833229065,
        "train_loss": 3.0829739570617676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23233,
        "tokens": 12180783104,
        "learning_rate": 0.00013291120481630767,
        "gradient_norm": 0.527649998664856,
        "train_loss": 3.024017333984375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23234,
        "tokens": 12181307392,
        "learning_rate": 0.0001328916267833927,
        "gradient_norm": 0.46135735511779785,
        "train_loss": 3.0771780014038086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23235,
        "tokens": 12181831680,
        "learning_rate": 0.0001328720509691781,
        "gradient_norm": 0.4557710289955139,
        "train_loss": 3.037982225418091,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23236,
        "tokens": 12182355968,
        "learning_rate": 0.00013285247737388433,
        "gradient_norm": 0.4755879044532776,
        "train_loss": 3.0165598392486572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23237,
        "tokens": 12182880256,
        "learning_rate": 0.00013283290599773164,
        "gradient_norm": 0.4188123941421509,
        "train_loss": 3.040820837020874,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23238,
        "tokens": 12183404544,
        "learning_rate": 0.0001328133368409404,
        "gradient_norm": 0.45646458864212036,
        "train_loss": 3.035740613937378,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23239,
        "tokens": 12183928832,
        "learning_rate": 0.0001327937699037308,
        "gradient_norm": 0.41068506240844727,
        "train_loss": 3.0285887718200684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23240,
        "tokens": 12184453120,
        "learning_rate": 0.00013277420518632328,
        "gradient_norm": 0.4261322021484375,
        "train_loss": 3.0352840423583984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23241,
        "tokens": 12184977408,
        "learning_rate": 0.00013275464268893778,
        "gradient_norm": 0.41320788860321045,
        "train_loss": 2.984055757522583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23242,
        "tokens": 12185501696,
        "learning_rate": 0.00013273508241179476,
        "gradient_norm": 0.441811740398407,
        "train_loss": 3.05176043510437,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23243,
        "tokens": 12186025984,
        "learning_rate": 0.0001327155243551142,
        "gradient_norm": 0.407019704580307,
        "train_loss": 3.039957046508789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23244,
        "tokens": 12186550272,
        "learning_rate": 0.00013269596851911642,
        "gradient_norm": 0.38640064001083374,
        "train_loss": 3.037862777709961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23245,
        "tokens": 12187074560,
        "learning_rate": 0.00013267641490402132,
        "gradient_norm": 0.394972562789917,
        "train_loss": 3.056979179382324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23246,
        "tokens": 12187598848,
        "learning_rate": 0.00013265686351004926,
        "gradient_norm": 0.4165986180305481,
        "train_loss": 3.0005555152893066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23247,
        "tokens": 12188123136,
        "learning_rate": 0.00013263731433742014,
        "gradient_norm": 0.3800671398639679,
        "train_loss": 3.0004241466522217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23248,
        "tokens": 12188647424,
        "learning_rate": 0.00013261776738635414,
        "gradient_norm": 0.3862508535385132,
        "train_loss": 3.025134563446045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23249,
        "tokens": 12189171712,
        "learning_rate": 0.0001325982226570711,
        "gradient_norm": 0.41270911693573,
        "train_loss": 2.9904518127441406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23250,
        "tokens": 12189696000,
        "learning_rate": 0.00013257868014979125,
        "gradient_norm": 0.41372111439704895,
        "train_loss": 3.008091926574707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23251,
        "tokens": 12190220288,
        "learning_rate": 0.00013255913986473435,
        "gradient_norm": 0.4056943356990814,
        "train_loss": 2.9735267162323,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23252,
        "tokens": 12190744576,
        "learning_rate": 0.00013253960180212052,
        "gradient_norm": 0.4592914581298828,
        "train_loss": 3.0214080810546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23253,
        "tokens": 12191268864,
        "learning_rate": 0.00013252006596216955,
        "gradient_norm": 0.4134228229522705,
        "train_loss": 3.040675640106201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23254,
        "tokens": 12191793152,
        "learning_rate": 0.00013250053234510148,
        "gradient_norm": 0.42046186327934265,
        "train_loss": 2.9966721534729004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23255,
        "tokens": 12192317440,
        "learning_rate": 0.00013248100095113603,
        "gradient_norm": 0.4338175356388092,
        "train_loss": 3.043605327606201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23256,
        "tokens": 12192841728,
        "learning_rate": 0.0001324614717804931,
        "gradient_norm": 0.4597594738006592,
        "train_loss": 3.0502514839172363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23257,
        "tokens": 12193366016,
        "learning_rate": 0.00013244194483339266,
        "gradient_norm": 0.4037975072860718,
        "train_loss": 3.030146598815918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23258,
        "tokens": 12193890304,
        "learning_rate": 0.00013242242011005426,
        "gradient_norm": 0.4503602087497711,
        "train_loss": 3.018954038619995,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23259,
        "tokens": 12194414592,
        "learning_rate": 0.00013240289761069795,
        "gradient_norm": 0.4332432746887207,
        "train_loss": 3.024970531463623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23260,
        "tokens": 12194938880,
        "learning_rate": 0.00013238337733554323,
        "gradient_norm": 0.39389947056770325,
        "train_loss": 3.012406826019287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23261,
        "tokens": 12195463168,
        "learning_rate": 0.00013236385928481006,
        "gradient_norm": 0.38623762130737305,
        "train_loss": 3.0332093238830566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23262,
        "tokens": 12195987456,
        "learning_rate": 0.00013234434345871785,
        "gradient_norm": 0.4160204529762268,
        "train_loss": 3.072183132171631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23263,
        "tokens": 12196511744,
        "learning_rate": 0.00013232482985748656,
        "gradient_norm": 0.414931058883667,
        "train_loss": 3.003507137298584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23264,
        "tokens": 12197036032,
        "learning_rate": 0.00013230531848133567,
        "gradient_norm": 0.40942272543907166,
        "train_loss": 3.0761733055114746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23265,
        "tokens": 12197560320,
        "learning_rate": 0.0001322858093304848,
        "gradient_norm": 0.41452521085739136,
        "train_loss": 3.0571272373199463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23266,
        "tokens": 12198084608,
        "learning_rate": 0.0001322663024051537,
        "gradient_norm": 0.39761224389076233,
        "train_loss": 3.043891191482544,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23267,
        "tokens": 12198608896,
        "learning_rate": 0.00013224679770556177,
        "gradient_norm": 0.4290764331817627,
        "train_loss": 3.0403289794921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23268,
        "tokens": 12199133184,
        "learning_rate": 0.00013222729523192873,
        "gradient_norm": 0.38989928364753723,
        "train_loss": 3.018541097640991,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23269,
        "tokens": 12199657472,
        "learning_rate": 0.00013220779498447394,
        "gradient_norm": 0.4627871811389923,
        "train_loss": 3.043020725250244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23270,
        "tokens": 12200181760,
        "learning_rate": 0.000132188296963417,
        "gradient_norm": 0.4046326279640198,
        "train_loss": 3.037677049636841,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23271,
        "tokens": 12200706048,
        "learning_rate": 0.00013216880116897735,
        "gradient_norm": 0.40755850076675415,
        "train_loss": 2.994464635848999,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23272,
        "tokens": 12201230336,
        "learning_rate": 0.00013214930760137446,
        "gradient_norm": 0.3914716839790344,
        "train_loss": 3.0451090335845947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23273,
        "tokens": 12201754624,
        "learning_rate": 0.00013212981626082768,
        "gradient_norm": 0.4168241322040558,
        "train_loss": 3.0625905990600586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23274,
        "tokens": 12202278912,
        "learning_rate": 0.00013211032714755656,
        "gradient_norm": 0.39684784412384033,
        "train_loss": 3.0364441871643066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23275,
        "tokens": 12202803200,
        "learning_rate": 0.0001320908402617803,
        "gradient_norm": 0.43584123253822327,
        "train_loss": 3.0435118675231934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23276,
        "tokens": 12203327488,
        "learning_rate": 0.00013207135560371834,
        "gradient_norm": 0.40305086970329285,
        "train_loss": 3.0006415843963623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23277,
        "tokens": 12203851776,
        "learning_rate": 0.00013205187317359007,
        "gradient_norm": 0.4242514371871948,
        "train_loss": 3.0696425437927246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23278,
        "tokens": 12204376064,
        "learning_rate": 0.00013203239297161464,
        "gradient_norm": 0.4192159175872803,
        "train_loss": 3.070308208465576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23279,
        "tokens": 12204900352,
        "learning_rate": 0.00013201291499801148,
        "gradient_norm": 0.40153825283050537,
        "train_loss": 3.0299649238586426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23280,
        "tokens": 12205424640,
        "learning_rate": 0.00013199343925299965,
        "gradient_norm": 0.3806072175502777,
        "train_loss": 3.0413436889648438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23281,
        "tokens": 12205948928,
        "learning_rate": 0.0001319739657367986,
        "gradient_norm": 0.4156637191772461,
        "train_loss": 3.0338268280029297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23282,
        "tokens": 12206473216,
        "learning_rate": 0.00013195449444962734,
        "gradient_norm": 0.39401862025260925,
        "train_loss": 3.03109073638916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23283,
        "tokens": 12206997504,
        "learning_rate": 0.0001319350253917052,
        "gradient_norm": 0.4194423258304596,
        "train_loss": 3.0567121505737305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23284,
        "tokens": 12207521792,
        "learning_rate": 0.00013191555856325113,
        "gradient_norm": 0.45940840244293213,
        "train_loss": 3.0518198013305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23285,
        "tokens": 12208046080,
        "learning_rate": 0.00013189609396448436,
        "gradient_norm": 0.4288802146911621,
        "train_loss": 3.0230321884155273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23286,
        "tokens": 12208570368,
        "learning_rate": 0.00013187663159562412,
        "gradient_norm": 0.44037064909935,
        "train_loss": 3.0649654865264893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23287,
        "tokens": 12209094656,
        "learning_rate": 0.00013185717145688925,
        "gradient_norm": 0.4416860342025757,
        "train_loss": 3.0411360263824463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23288,
        "tokens": 12209618944,
        "learning_rate": 0.00013183771354849898,
        "gradient_norm": 0.44093164801597595,
        "train_loss": 2.966710090637207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23289,
        "tokens": 12210143232,
        "learning_rate": 0.00013181825787067218,
        "gradient_norm": 0.39557355642318726,
        "train_loss": 3.053384304046631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23290,
        "tokens": 12210667520,
        "learning_rate": 0.000131798804423628,
        "gradient_norm": 0.4823441803455353,
        "train_loss": 3.032557964324951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23291,
        "tokens": 12211191808,
        "learning_rate": 0.0001317793532075853,
        "gradient_norm": 0.4044463038444519,
        "train_loss": 3.023926258087158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23292,
        "tokens": 12211716096,
        "learning_rate": 0.00013175990422276308,
        "gradient_norm": 0.42176058888435364,
        "train_loss": 2.968916654586792,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23293,
        "tokens": 12212240384,
        "learning_rate": 0.00013174045746938023,
        "gradient_norm": 0.44152194261550903,
        "train_loss": 3.031099557876587,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23294,
        "tokens": 12212764672,
        "learning_rate": 0.00013172101294765576,
        "gradient_norm": 0.3925400674343109,
        "train_loss": 3.061103343963623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23295,
        "tokens": 12213288960,
        "learning_rate": 0.00013170157065780833,
        "gradient_norm": 0.42974790930747986,
        "train_loss": 3.0213918685913086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23296,
        "tokens": 12213813248,
        "learning_rate": 0.0001316821306000569,
        "gradient_norm": 0.4250147044658661,
        "train_loss": 3.038196563720703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23297,
        "tokens": 12214337536,
        "learning_rate": 0.0001316626927746204,
        "gradient_norm": 0.4167958199977875,
        "train_loss": 3.069030523300171,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23298,
        "tokens": 12214861824,
        "learning_rate": 0.00013164325718171746,
        "gradient_norm": 0.3994455933570862,
        "train_loss": 3.037001609802246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23299,
        "tokens": 12215386112,
        "learning_rate": 0.000131623823821567,
        "gradient_norm": 0.4432777166366577,
        "train_loss": 3.023406982421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23300,
        "tokens": 12215910400,
        "learning_rate": 0.0001316043926943876,
        "gradient_norm": 0.4327618181705475,
        "train_loss": 3.066788673400879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23301,
        "tokens": 12216434688,
        "learning_rate": 0.00013158496380039813,
        "gradient_norm": 0.4315379559993744,
        "train_loss": 2.966909646987915,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23302,
        "tokens": 12216958976,
        "learning_rate": 0.00013156553713981715,
        "gradient_norm": 0.42411065101623535,
        "train_loss": 3.0288403034210205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23303,
        "tokens": 12217483264,
        "learning_rate": 0.00013154611271286347,
        "gradient_norm": 0.4100942313671112,
        "train_loss": 3.0773448944091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23304,
        "tokens": 12218007552,
        "learning_rate": 0.0001315266905197556,
        "gradient_norm": 0.41296645998954773,
        "train_loss": 2.9910693168640137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23305,
        "tokens": 12218531840,
        "learning_rate": 0.00013150727056071226,
        "gradient_norm": 0.4143749475479126,
        "train_loss": 3.026078939437866,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23306,
        "tokens": 12219056128,
        "learning_rate": 0.00013148785283595204,
        "gradient_norm": 0.4096570611000061,
        "train_loss": 3.1072967052459717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23307,
        "tokens": 12219580416,
        "learning_rate": 0.0001314684373456935,
        "gradient_norm": 0.45158857107162476,
        "train_loss": 3.0312163829803467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23308,
        "tokens": 12220104704,
        "learning_rate": 0.00013144902409015517,
        "gradient_norm": 0.4426569640636444,
        "train_loss": 3.061549663543701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23309,
        "tokens": 12220628992,
        "learning_rate": 0.00013142961306955554,
        "gradient_norm": 0.3969729244709015,
        "train_loss": 2.979074001312256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23310,
        "tokens": 12221153280,
        "learning_rate": 0.0001314102042841132,
        "gradient_norm": 0.49283087253570557,
        "train_loss": 3.113687515258789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23311,
        "tokens": 12221677568,
        "learning_rate": 0.00013139079773404646,
        "gradient_norm": 0.3925478160381317,
        "train_loss": 2.9816622734069824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23312,
        "tokens": 12222201856,
        "learning_rate": 0.000131371393419574,
        "gradient_norm": 0.4163588881492615,
        "train_loss": 3.050246238708496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23313,
        "tokens": 12222726144,
        "learning_rate": 0.00013135199134091396,
        "gradient_norm": 0.4304873049259186,
        "train_loss": 3.070298671722412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23314,
        "tokens": 12223250432,
        "learning_rate": 0.00013133259149828499,
        "gradient_norm": 0.41748788952827454,
        "train_loss": 3.059408664703369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23315,
        "tokens": 12223774720,
        "learning_rate": 0.00013131319389190528,
        "gradient_norm": 0.4048018753528595,
        "train_loss": 3.0674610137939453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23316,
        "tokens": 12224299008,
        "learning_rate": 0.0001312937985219932,
        "gradient_norm": 0.4298759400844574,
        "train_loss": 2.995826005935669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23317,
        "tokens": 12224823296,
        "learning_rate": 0.00013127440538876722,
        "gradient_norm": 0.46428608894348145,
        "train_loss": 2.99206280708313,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23318,
        "tokens": 12225347584,
        "learning_rate": 0.00013125501449244548,
        "gradient_norm": 0.43293043971061707,
        "train_loss": 3.0285892486572266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23319,
        "tokens": 12225871872,
        "learning_rate": 0.0001312356258332463,
        "gradient_norm": 0.43440523743629456,
        "train_loss": 3.062386989593506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23320,
        "tokens": 12226396160,
        "learning_rate": 0.0001312162394113879,
        "gradient_norm": 0.4473203718662262,
        "train_loss": 3.0446348190307617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23321,
        "tokens": 12226920448,
        "learning_rate": 0.00013119685522708857,
        "gradient_norm": 0.4260164499282837,
        "train_loss": 3.0357441902160645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23322,
        "tokens": 12227444736,
        "learning_rate": 0.00013117747328056638,
        "gradient_norm": 0.4042855203151703,
        "train_loss": 3.061227798461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23323,
        "tokens": 12227969024,
        "learning_rate": 0.00013115809357203964,
        "gradient_norm": 0.4438752233982086,
        "train_loss": 3.014949083328247,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23324,
        "tokens": 12228493312,
        "learning_rate": 0.0001311387161017263,
        "gradient_norm": 0.39460983872413635,
        "train_loss": 3.064406156539917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23325,
        "tokens": 12229017600,
        "learning_rate": 0.00013111934086984468,
        "gradient_norm": 0.4380614459514618,
        "train_loss": 2.9828667640686035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23326,
        "tokens": 12229541888,
        "learning_rate": 0.0001310999678766128,
        "gradient_norm": 0.41866961121559143,
        "train_loss": 3.045355796813965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23327,
        "tokens": 12230066176,
        "learning_rate": 0.00013108059712224867,
        "gradient_norm": 0.4198576509952545,
        "train_loss": 3.0400784015655518,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23328,
        "tokens": 12230590464,
        "learning_rate": 0.00013106122860697046,
        "gradient_norm": 0.4430398941040039,
        "train_loss": 3.084095001220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23329,
        "tokens": 12231114752,
        "learning_rate": 0.00013104186233099603,
        "gradient_norm": 0.39094287157058716,
        "train_loss": 3.0448503494262695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23330,
        "tokens": 12231639040,
        "learning_rate": 0.0001310224982945435,
        "gradient_norm": 0.412855327129364,
        "train_loss": 3.021665573120117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23331,
        "tokens": 12232163328,
        "learning_rate": 0.0001310031364978307,
        "gradient_norm": 0.4509678781032562,
        "train_loss": 3.0187225341796875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23332,
        "tokens": 12232687616,
        "learning_rate": 0.00013098377694107578,
        "gradient_norm": 0.3921576142311096,
        "train_loss": 3.002490997314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23333,
        "tokens": 12233211904,
        "learning_rate": 0.0001309644196244964,
        "gradient_norm": 0.47617700695991516,
        "train_loss": 3.030485153198242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23334,
        "tokens": 12233736192,
        "learning_rate": 0.00013094506454831072,
        "gradient_norm": 0.4247579574584961,
        "train_loss": 3.0433735847473145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23335,
        "tokens": 12234260480,
        "learning_rate": 0.00013092571171273632,
        "gradient_norm": 0.4461314082145691,
        "train_loss": 3.033329486846924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23336,
        "tokens": 12234784768,
        "learning_rate": 0.00013090636111799133,
        "gradient_norm": 0.41714197397232056,
        "train_loss": 3.038853406906128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23337,
        "tokens": 12235309056,
        "learning_rate": 0.0001308870127642933,
        "gradient_norm": 0.4437117576599121,
        "train_loss": 3.031217098236084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23338,
        "tokens": 12235833344,
        "learning_rate": 0.00013086766665186024,
        "gradient_norm": 0.3897143602371216,
        "train_loss": 3.039376735687256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23339,
        "tokens": 12236357632,
        "learning_rate": 0.00013084832278090973,
        "gradient_norm": 0.3994075059890747,
        "train_loss": 2.9992079734802246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23340,
        "tokens": 12236881920,
        "learning_rate": 0.0001308289811516597,
        "gradient_norm": 0.4411391615867615,
        "train_loss": 3.0230798721313477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23341,
        "tokens": 12237406208,
        "learning_rate": 0.00013080964176432762,
        "gradient_norm": 0.4278544485569,
        "train_loss": 3.005916118621826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23342,
        "tokens": 12237930496,
        "learning_rate": 0.00013079030461913145,
        "gradient_norm": 0.41572022438049316,
        "train_loss": 3.0514960289001465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23343,
        "tokens": 12238454784,
        "learning_rate": 0.00013077096971628863,
        "gradient_norm": 0.440154105424881,
        "train_loss": 3.0748229026794434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23344,
        "tokens": 12238979072,
        "learning_rate": 0.00013075163705601696,
        "gradient_norm": 0.40982726216316223,
        "train_loss": 3.051269769668579,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23345,
        "tokens": 12239503360,
        "learning_rate": 0.00013073230663853395,
        "gradient_norm": 0.4007405638694763,
        "train_loss": 3.0369131565093994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23346,
        "tokens": 12240027648,
        "learning_rate": 0.00013071297846405723,
        "gradient_norm": 0.4110896587371826,
        "train_loss": 3.0461108684539795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23347,
        "tokens": 12240551936,
        "learning_rate": 0.00013069365253280432,
        "gradient_norm": 0.4046361744403839,
        "train_loss": 3.0132036209106445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23348,
        "tokens": 12241076224,
        "learning_rate": 0.00013067432884499285,
        "gradient_norm": 0.41418567299842834,
        "train_loss": 3.055382251739502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23349,
        "tokens": 12241600512,
        "learning_rate": 0.00013065500740084022,
        "gradient_norm": 0.44160082936286926,
        "train_loss": 3.0550708770751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23350,
        "tokens": 12242124800,
        "learning_rate": 0.00013063568820056407,
        "gradient_norm": 0.4006442427635193,
        "train_loss": 3.060302257537842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23351,
        "tokens": 12242649088,
        "learning_rate": 0.00013061637124438163,
        "gradient_norm": 0.4285471737384796,
        "train_loss": 3.0259108543395996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23352,
        "tokens": 12243173376,
        "learning_rate": 0.0001305970565325106,
        "gradient_norm": 0.4197847247123718,
        "train_loss": 3.008943796157837,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23353,
        "tokens": 12243697664,
        "learning_rate": 0.00013057774406516814,
        "gradient_norm": 0.42364129424095154,
        "train_loss": 3.0971012115478516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23354,
        "tokens": 12244221952,
        "learning_rate": 0.00013055843384257186,
        "gradient_norm": 0.5231238603591919,
        "train_loss": 3.0159525871276855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23355,
        "tokens": 12244746240,
        "learning_rate": 0.00013053912586493893,
        "gradient_norm": 0.39462727308273315,
        "train_loss": 3.024083137512207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23356,
        "tokens": 12245270528,
        "learning_rate": 0.00013051982013248677,
        "gradient_norm": 0.545642614364624,
        "train_loss": 3.0355944633483887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23357,
        "tokens": 12245794816,
        "learning_rate": 0.00013050051664543276,
        "gradient_norm": 0.5324872732162476,
        "train_loss": 3.1274797916412354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23358,
        "tokens": 12246319104,
        "learning_rate": 0.00013048121540399407,
        "gradient_norm": 0.4583856165409088,
        "train_loss": 3.0154240131378174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23359,
        "tokens": 12246843392,
        "learning_rate": 0.00013046191640838807,
        "gradient_norm": 0.4918142259120941,
        "train_loss": 3.0443789958953857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23360,
        "tokens": 12247367680,
        "learning_rate": 0.00013044261965883185,
        "gradient_norm": 0.45163774490356445,
        "train_loss": 3.046663284301758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23361,
        "tokens": 12247891968,
        "learning_rate": 0.0001304233251555428,
        "gradient_norm": 0.5106759667396545,
        "train_loss": 3.0365045070648193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23362,
        "tokens": 12248416256,
        "learning_rate": 0.00013040403289873789,
        "gradient_norm": 0.41613584756851196,
        "train_loss": 3.0896737575531006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23363,
        "tokens": 12248940544,
        "learning_rate": 0.0001303847428886345,
        "gradient_norm": 0.47028815746307373,
        "train_loss": 3.0082101821899414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23364,
        "tokens": 12249464832,
        "learning_rate": 0.00013036545512544958,
        "gradient_norm": 0.4479377865791321,
        "train_loss": 3.042560577392578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23365,
        "tokens": 12249989120,
        "learning_rate": 0.0001303461696094003,
        "gradient_norm": 0.4266350269317627,
        "train_loss": 3.0117273330688477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23366,
        "tokens": 12250513408,
        "learning_rate": 0.00013032688634070382,
        "gradient_norm": 0.4844452738761902,
        "train_loss": 3.0577030181884766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23367,
        "tokens": 12251037696,
        "learning_rate": 0.0001303076053195771,
        "gradient_norm": 0.3987724781036377,
        "train_loss": 2.954707622528076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23368,
        "tokens": 12251561984,
        "learning_rate": 0.00013028832654623723,
        "gradient_norm": 0.46270257234573364,
        "train_loss": 3.0381035804748535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23369,
        "tokens": 12252086272,
        "learning_rate": 0.00013026905002090113,
        "gradient_norm": 0.448260635137558,
        "train_loss": 3.0406198501586914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23370,
        "tokens": 12252610560,
        "learning_rate": 0.00013024977574378592,
        "gradient_norm": 0.38515734672546387,
        "train_loss": 3.0401079654693604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23371,
        "tokens": 12253134848,
        "learning_rate": 0.00013023050371510842,
        "gradient_norm": 0.4409971237182617,
        "train_loss": 3.017585515975952,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23372,
        "tokens": 12253659136,
        "learning_rate": 0.0001302112339350857,
        "gradient_norm": 0.42918482422828674,
        "train_loss": 3.038423538208008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23373,
        "tokens": 12254183424,
        "learning_rate": 0.0001301919664039345,
        "gradient_norm": 0.40671852231025696,
        "train_loss": 3.0821526050567627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23374,
        "tokens": 12254707712,
        "learning_rate": 0.00013017270112187184,
        "gradient_norm": 0.4407150149345398,
        "train_loss": 3.071549415588379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23375,
        "tokens": 12255232000,
        "learning_rate": 0.00013015343808911445,
        "gradient_norm": 0.42216700315475464,
        "train_loss": 3.063248872756958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23376,
        "tokens": 12255756288,
        "learning_rate": 0.00013013417730587927,
        "gradient_norm": 0.39839547872543335,
        "train_loss": 3.0453531742095947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23377,
        "tokens": 12256280576,
        "learning_rate": 0.00013011491877238312,
        "gradient_norm": 0.40900763869285583,
        "train_loss": 3.0319857597351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23378,
        "tokens": 12256804864,
        "learning_rate": 0.00013009566248884264,
        "gradient_norm": 0.4380017817020416,
        "train_loss": 3.03017520904541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23379,
        "tokens": 12257329152,
        "learning_rate": 0.0001300764084554747,
        "gradient_norm": 0.4286409914493561,
        "train_loss": 3.067146062850952,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23380,
        "tokens": 12257853440,
        "learning_rate": 0.00013005715667249599,
        "gradient_norm": 0.40197983384132385,
        "train_loss": 2.9846577644348145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23381,
        "tokens": 12258377728,
        "learning_rate": 0.00013003790714012325,
        "gradient_norm": 0.48889413475990295,
        "train_loss": 3.0204591751098633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23382,
        "tokens": 12258902016,
        "learning_rate": 0.00013001865985857306,
        "gradient_norm": 0.4304922819137573,
        "train_loss": 3.093538284301758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23383,
        "tokens": 12259426304,
        "learning_rate": 0.0001299994148280622,
        "gradient_norm": 0.4179452657699585,
        "train_loss": 3.081178665161133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23384,
        "tokens": 12259950592,
        "learning_rate": 0.00012998017204880717,
        "gradient_norm": 0.3888893723487854,
        "train_loss": 2.998354434967041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23385,
        "tokens": 12260474880,
        "learning_rate": 0.00012996093152102463,
        "gradient_norm": 0.48138299584388733,
        "train_loss": 3.110980749130249,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23386,
        "tokens": 12260999168,
        "learning_rate": 0.00012994169324493125,
        "gradient_norm": 0.41576334834098816,
        "train_loss": 3.0915377140045166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23387,
        "tokens": 12261523456,
        "learning_rate": 0.0001299224572207434,
        "gradient_norm": 0.46310901641845703,
        "train_loss": 3.02547025680542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23388,
        "tokens": 12262047744,
        "learning_rate": 0.0001299032234486778,
        "gradient_norm": 0.4366969168186188,
        "train_loss": 3.0191850662231445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23389,
        "tokens": 12262572032,
        "learning_rate": 0.00012988399192895072,
        "gradient_norm": 0.4870869219303131,
        "train_loss": 3.044734477996826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23390,
        "tokens": 12263096320,
        "learning_rate": 0.00012986476266177888,
        "gradient_norm": 0.40741869807243347,
        "train_loss": 2.9964442253112793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23391,
        "tokens": 12263620608,
        "learning_rate": 0.00012984553564737852,
        "gradient_norm": 0.44145768880844116,
        "train_loss": 3.0429039001464844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23392,
        "tokens": 12264144896,
        "learning_rate": 0.00012982631088596626,
        "gradient_norm": 0.47740238904953003,
        "train_loss": 3.0736734867095947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23393,
        "tokens": 12264669184,
        "learning_rate": 0.0001298070883777583,
        "gradient_norm": 0.39385122060775757,
        "train_loss": 3.021092414855957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23394,
        "tokens": 12265193472,
        "learning_rate": 0.00012978786812297116,
        "gradient_norm": 0.49625590443611145,
        "train_loss": 3.0682902336120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23395,
        "tokens": 12265717760,
        "learning_rate": 0.00012976865012182106,
        "gradient_norm": 0.40067943930625916,
        "train_loss": 3.073697566986084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23396,
        "tokens": 12266242048,
        "learning_rate": 0.00012974943437452443,
        "gradient_norm": 0.4225988984107971,
        "train_loss": 3.0033059120178223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23397,
        "tokens": 12266766336,
        "learning_rate": 0.00012973022088129757,
        "gradient_norm": 0.43153297901153564,
        "train_loss": 2.9755897521972656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23398,
        "tokens": 12267290624,
        "learning_rate": 0.0001297110096423567,
        "gradient_norm": 0.4422188103199005,
        "train_loss": 3.0042190551757812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23399,
        "tokens": 12267814912,
        "learning_rate": 0.00012969180065791811,
        "gradient_norm": 0.4069388210773468,
        "train_loss": 3.0668959617614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23400,
        "tokens": 12268339200,
        "learning_rate": 0.00012967259392819797,
        "gradient_norm": 0.5152629613876343,
        "train_loss": 3.051362991333008,
        "val_loss": 2.991853713989258,
        "hellaswag_acc": 0.2859988212585449,
        "hellaswag_acc_norm": 0.29595696926116943
    },
    {
        "step": 23401,
        "tokens": 12268863488,
        "learning_rate": 0.0001296533894534125,
        "gradient_norm": 0.3886062800884247,
        "train_loss": 3.0346317291259766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23402,
        "tokens": 12269387776,
        "learning_rate": 0.00012963418723377785,
        "gradient_norm": 0.42810356616973877,
        "train_loss": 2.98635196685791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23403,
        "tokens": 12269912064,
        "learning_rate": 0.00012961498726951024,
        "gradient_norm": 0.41596031188964844,
        "train_loss": 3.029329299926758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23404,
        "tokens": 12270436352,
        "learning_rate": 0.00012959578956082566,
        "gradient_norm": 0.40531548857688904,
        "train_loss": 3.0361216068267822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23405,
        "tokens": 12270960640,
        "learning_rate": 0.0001295765941079403,
        "gradient_norm": 0.43611234426498413,
        "train_loss": 2.9872522354125977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23406,
        "tokens": 12271484928,
        "learning_rate": 0.00012955740091107024,
        "gradient_norm": 0.3966299891471863,
        "train_loss": 3.0876805782318115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23407,
        "tokens": 12272009216,
        "learning_rate": 0.00012953820997043146,
        "gradient_norm": 0.4167310893535614,
        "train_loss": 3.0524377822875977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23408,
        "tokens": 12272533504,
        "learning_rate": 0.00012951902128624005,
        "gradient_norm": 0.40010756254196167,
        "train_loss": 3.027773857116699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23409,
        "tokens": 12273057792,
        "learning_rate": 0.00012949983485871188,
        "gradient_norm": 0.4191792607307434,
        "train_loss": 3.0650508403778076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23410,
        "tokens": 12273582080,
        "learning_rate": 0.00012948065068806312,
        "gradient_norm": 0.4257863163948059,
        "train_loss": 3.104264259338379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23411,
        "tokens": 12274106368,
        "learning_rate": 0.00012946146877450948,
        "gradient_norm": 0.46045443415641785,
        "train_loss": 3.009699583053589,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23412,
        "tokens": 12274630656,
        "learning_rate": 0.0001294422891182671,
        "gradient_norm": 0.4297582805156708,
        "train_loss": 3.0232434272766113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23413,
        "tokens": 12275154944,
        "learning_rate": 0.00012942311171955164,
        "gradient_norm": 0.47710588574409485,
        "train_loss": 3.09985089302063,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23414,
        "tokens": 12275679232,
        "learning_rate": 0.00012940393657857917,
        "gradient_norm": 0.4450150728225708,
        "train_loss": 3.0444724559783936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23415,
        "tokens": 12276203520,
        "learning_rate": 0.00012938476369556538,
        "gradient_norm": 0.4579688608646393,
        "train_loss": 3.0069990158081055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23416,
        "tokens": 12276727808,
        "learning_rate": 0.00012936559307072615,
        "gradient_norm": 0.39299440383911133,
        "train_loss": 3.040243148803711,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23417,
        "tokens": 12277252096,
        "learning_rate": 0.0001293464247042773,
        "gradient_norm": 0.39707064628601074,
        "train_loss": 3.065760612487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23418,
        "tokens": 12277776384,
        "learning_rate": 0.00012932725859643457,
        "gradient_norm": 0.42221346497535706,
        "train_loss": 3.035505771636963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23419,
        "tokens": 12278300672,
        "learning_rate": 0.00012930809474741365,
        "gradient_norm": 0.4200628697872162,
        "train_loss": 3.0756711959838867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23420,
        "tokens": 12278824960,
        "learning_rate": 0.00012928893315743031,
        "gradient_norm": 0.4319193959236145,
        "train_loss": 2.9991354942321777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23421,
        "tokens": 12279349248,
        "learning_rate": 0.00012926977382670025,
        "gradient_norm": 0.4342976212501526,
        "train_loss": 3.0171303749084473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23422,
        "tokens": 12279873536,
        "learning_rate": 0.00012925061675543906,
        "gradient_norm": 0.47649338841438293,
        "train_loss": 3.066373348236084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23423,
        "tokens": 12280397824,
        "learning_rate": 0.0001292314619438625,
        "gradient_norm": 0.44535699486732483,
        "train_loss": 3.042235851287842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23424,
        "tokens": 12280922112,
        "learning_rate": 0.000129212309392186,
        "gradient_norm": 0.4184526205062866,
        "train_loss": 3.0163803100585938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23425,
        "tokens": 12281446400,
        "learning_rate": 0.00012919315910062522,
        "gradient_norm": 0.45279714465141296,
        "train_loss": 3.0274031162261963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23426,
        "tokens": 12281970688,
        "learning_rate": 0.00012917401106939585,
        "gradient_norm": 0.4024032950401306,
        "train_loss": 3.025057792663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23427,
        "tokens": 12282494976,
        "learning_rate": 0.00012915486529871325,
        "gradient_norm": 0.43402382731437683,
        "train_loss": 3.022489547729492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23428,
        "tokens": 12283019264,
        "learning_rate": 0.00012913572178879307,
        "gradient_norm": 0.47884052991867065,
        "train_loss": 3.000603675842285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23429,
        "tokens": 12283543552,
        "learning_rate": 0.00012911658053985065,
        "gradient_norm": 0.914040207862854,
        "train_loss": 3.105320453643799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23430,
        "tokens": 12284067840,
        "learning_rate": 0.00012909744155210163,
        "gradient_norm": 0.6357638239860535,
        "train_loss": 3.033339738845825,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23431,
        "tokens": 12284592128,
        "learning_rate": 0.00012907830482576123,
        "gradient_norm": 0.6261957883834839,
        "train_loss": 2.9864323139190674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23432,
        "tokens": 12285116416,
        "learning_rate": 0.00012905917036104504,
        "gradient_norm": 0.5568804144859314,
        "train_loss": 3.0323657989501953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23433,
        "tokens": 12285640704,
        "learning_rate": 0.0001290400381581683,
        "gradient_norm": 0.47854700684547424,
        "train_loss": 3.0417118072509766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23434,
        "tokens": 12286164992,
        "learning_rate": 0.00012902090821734653,
        "gradient_norm": 0.4741984009742737,
        "train_loss": 3.0260133743286133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23435,
        "tokens": 12286689280,
        "learning_rate": 0.00012900178053879485,
        "gradient_norm": 0.4894295930862427,
        "train_loss": 3.1464247703552246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23436,
        "tokens": 12287213568,
        "learning_rate": 0.00012898265512272867,
        "gradient_norm": 0.48558124899864197,
        "train_loss": 2.9965968132019043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23437,
        "tokens": 12287737856,
        "learning_rate": 0.00012896353196936337,
        "gradient_norm": 0.4889827072620392,
        "train_loss": 3.000013589859009,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23438,
        "tokens": 12288262144,
        "learning_rate": 0.00012894441107891408,
        "gradient_norm": 0.41870808601379395,
        "train_loss": 3.01959228515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23439,
        "tokens": 12288786432,
        "learning_rate": 0.0001289252924515961,
        "gradient_norm": 0.5044809579849243,
        "train_loss": 3.045598030090332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23440,
        "tokens": 12289310720,
        "learning_rate": 0.00012890617608762455,
        "gradient_norm": 0.42578819394111633,
        "train_loss": 3.0438449382781982,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23441,
        "tokens": 12289835008,
        "learning_rate": 0.0001288870619872147,
        "gradient_norm": 0.5120169520378113,
        "train_loss": 3.237497568130493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23442,
        "tokens": 12290359296,
        "learning_rate": 0.00012886795015058162,
        "gradient_norm": 0.42545753717422485,
        "train_loss": 3.033052921295166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23443,
        "tokens": 12290883584,
        "learning_rate": 0.00012884884057794057,
        "gradient_norm": 0.41380250453948975,
        "train_loss": 3.0242254734039307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23444,
        "tokens": 12291407872,
        "learning_rate": 0.00012882973326950643,
        "gradient_norm": 0.47031667828559875,
        "train_loss": 3.100670576095581,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23445,
        "tokens": 12291932160,
        "learning_rate": 0.0001288106282254945,
        "gradient_norm": 0.48866042494773865,
        "train_loss": 3.029979944229126,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23446,
        "tokens": 12292456448,
        "learning_rate": 0.00012879152544611967,
        "gradient_norm": 0.4114413261413574,
        "train_loss": 3.04284405708313,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23447,
        "tokens": 12292980736,
        "learning_rate": 0.00012877242493159713,
        "gradient_norm": 0.44539791345596313,
        "train_loss": 3.01962947845459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23448,
        "tokens": 12293505024,
        "learning_rate": 0.00012875332668214168,
        "gradient_norm": 0.42110317945480347,
        "train_loss": 3.05330753326416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23449,
        "tokens": 12294029312,
        "learning_rate": 0.0001287342306979685,
        "gradient_norm": 0.4438483715057373,
        "train_loss": 3.0642600059509277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23450,
        "tokens": 12294553600,
        "learning_rate": 0.00012871513697929236,
        "gradient_norm": 0.4023051857948303,
        "train_loss": 3.005679130554199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23451,
        "tokens": 12295077888,
        "learning_rate": 0.00012869604552632832,
        "gradient_norm": 0.4071703553199768,
        "train_loss": 3.0568289756774902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23452,
        "tokens": 12295602176,
        "learning_rate": 0.00012867695633929114,
        "gradient_norm": 0.45800530910491943,
        "train_loss": 3.020566463470459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23453,
        "tokens": 12296126464,
        "learning_rate": 0.00012865786941839585,
        "gradient_norm": 0.4124138355255127,
        "train_loss": 3.041403293609619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23454,
        "tokens": 12296650752,
        "learning_rate": 0.00012863878476385718,
        "gradient_norm": 0.4414237141609192,
        "train_loss": 2.980828285217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23455,
        "tokens": 12297175040,
        "learning_rate": 0.00012861970237589,
        "gradient_norm": 0.40676149725914,
        "train_loss": 3.034628391265869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23456,
        "tokens": 12297699328,
        "learning_rate": 0.00012860062225470906,
        "gradient_norm": 0.4549819231033325,
        "train_loss": 3.015737295150757,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23457,
        "tokens": 12298223616,
        "learning_rate": 0.00012858154440052928,
        "gradient_norm": 0.41138583421707153,
        "train_loss": 3.024141788482666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23458,
        "tokens": 12298747904,
        "learning_rate": 0.00012856246881356515,
        "gradient_norm": 0.47901880741119385,
        "train_loss": 3.027255058288574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23459,
        "tokens": 12299272192,
        "learning_rate": 0.00012854339549403163,
        "gradient_norm": 0.39787939190864563,
        "train_loss": 3.082040548324585,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23460,
        "tokens": 12299796480,
        "learning_rate": 0.00012852432444214324,
        "gradient_norm": 0.4925738275051117,
        "train_loss": 3.0197482109069824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23461,
        "tokens": 12300320768,
        "learning_rate": 0.00012850525565811483,
        "gradient_norm": 0.37668201327323914,
        "train_loss": 3.0498716831207275,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23462,
        "tokens": 12300845056,
        "learning_rate": 0.00012848618914216084,
        "gradient_norm": 0.413432240486145,
        "train_loss": 3.1112937927246094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23463,
        "tokens": 12301369344,
        "learning_rate": 0.00012846712489449606,
        "gradient_norm": 0.44398200511932373,
        "train_loss": 3.037606716156006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23464,
        "tokens": 12301893632,
        "learning_rate": 0.00012844806291533492,
        "gradient_norm": 0.3793036937713623,
        "train_loss": 3.036078929901123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23465,
        "tokens": 12302417920,
        "learning_rate": 0.00012842900320489208,
        "gradient_norm": 0.4073885381221771,
        "train_loss": 3.0192437171936035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23466,
        "tokens": 12302942208,
        "learning_rate": 0.00012840994576338217,
        "gradient_norm": 0.4206767976284027,
        "train_loss": 3.041848659515381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23467,
        "tokens": 12303466496,
        "learning_rate": 0.00012839089059101948,
        "gradient_norm": 0.3806881904602051,
        "train_loss": 3.001400947570801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23468,
        "tokens": 12303990784,
        "learning_rate": 0.00012837183768801876,
        "gradient_norm": 0.3790943920612335,
        "train_loss": 3.0441513061523438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23469,
        "tokens": 12304515072,
        "learning_rate": 0.00012835278705459425,
        "gradient_norm": 0.41092243790626526,
        "train_loss": 2.9883737564086914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23470,
        "tokens": 12305039360,
        "learning_rate": 0.00012833373869096054,
        "gradient_norm": 0.3729439377784729,
        "train_loss": 3.0225372314453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23471,
        "tokens": 12305563648,
        "learning_rate": 0.00012831469259733192,
        "gradient_norm": 0.44568416476249695,
        "train_loss": 3.034191608428955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23472,
        "tokens": 12306087936,
        "learning_rate": 0.00012829564877392293,
        "gradient_norm": 0.4182332456111908,
        "train_loss": 3.0901970863342285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23473,
        "tokens": 12306612224,
        "learning_rate": 0.00012827660722094776,
        "gradient_norm": 0.3884645998477936,
        "train_loss": 3.003995418548584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23474,
        "tokens": 12307136512,
        "learning_rate": 0.0001282575679386209,
        "gradient_norm": 0.4467298984527588,
        "train_loss": 3.0272061824798584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23475,
        "tokens": 12307660800,
        "learning_rate": 0.00012823853092715652,
        "gradient_norm": 0.4175170660018921,
        "train_loss": 3.0191102027893066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23476,
        "tokens": 12308185088,
        "learning_rate": 0.00012821949618676897,
        "gradient_norm": 0.4675050377845764,
        "train_loss": 3.038687229156494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23477,
        "tokens": 12308709376,
        "learning_rate": 0.00012820046371767263,
        "gradient_norm": 0.4240894615650177,
        "train_loss": 3.0522568225860596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23478,
        "tokens": 12309233664,
        "learning_rate": 0.00012818143352008148,
        "gradient_norm": 0.4330517649650574,
        "train_loss": 3.1301608085632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23479,
        "tokens": 12309757952,
        "learning_rate": 0.00012816240559421,
        "gradient_norm": 0.47693589329719543,
        "train_loss": 3.045360565185547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23480,
        "tokens": 12310282240,
        "learning_rate": 0.00012814337994027214,
        "gradient_norm": 0.4536581337451935,
        "train_loss": 3.013887405395508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23481,
        "tokens": 12310806528,
        "learning_rate": 0.00012812435655848222,
        "gradient_norm": 0.4947138726711273,
        "train_loss": 3.0077462196350098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23482,
        "tokens": 12311330816,
        "learning_rate": 0.00012810533544905427,
        "gradient_norm": 0.410905122756958,
        "train_loss": 2.9678053855895996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23483,
        "tokens": 12311855104,
        "learning_rate": 0.0001280863166122025,
        "gradient_norm": 0.43982985615730286,
        "train_loss": 2.9859657287597656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23484,
        "tokens": 12312379392,
        "learning_rate": 0.00012806730004814084,
        "gradient_norm": 0.4306892454624176,
        "train_loss": 3.0541257858276367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23485,
        "tokens": 12312903680,
        "learning_rate": 0.00012804828575708343,
        "gradient_norm": 0.41315749287605286,
        "train_loss": 3.0137948989868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23486,
        "tokens": 12313427968,
        "learning_rate": 0.00012802927373924442,
        "gradient_norm": 0.4431684911251068,
        "train_loss": 3.054208278656006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23487,
        "tokens": 12313952256,
        "learning_rate": 0.00012801026399483762,
        "gradient_norm": 0.41646477580070496,
        "train_loss": 3.052114486694336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23488,
        "tokens": 12314476544,
        "learning_rate": 0.00012799125652407711,
        "gradient_norm": 0.39986154437065125,
        "train_loss": 3.092609405517578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23489,
        "tokens": 12315000832,
        "learning_rate": 0.00012797225132717678,
        "gradient_norm": 0.4153272807598114,
        "train_loss": 3.0466654300689697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23490,
        "tokens": 12315525120,
        "learning_rate": 0.00012795324840435068,
        "gradient_norm": 0.41494375467300415,
        "train_loss": 3.0430099964141846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23491,
        "tokens": 12316049408,
        "learning_rate": 0.00012793424775581251,
        "gradient_norm": 0.40086880326271057,
        "train_loss": 3.042354106903076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23492,
        "tokens": 12316573696,
        "learning_rate": 0.00012791524938177636,
        "gradient_norm": 0.4195321500301361,
        "train_loss": 3.0053977966308594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23493,
        "tokens": 12317097984,
        "learning_rate": 0.0001278962532824559,
        "gradient_norm": 0.4016525149345398,
        "train_loss": 3.0253262519836426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23494,
        "tokens": 12317622272,
        "learning_rate": 0.00012787725945806515,
        "gradient_norm": 0.4157073497772217,
        "train_loss": 3.0252416133880615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23495,
        "tokens": 12318146560,
        "learning_rate": 0.0001278582679088177,
        "gradient_norm": 0.41385576128959656,
        "train_loss": 3.039105176925659,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23496,
        "tokens": 12318670848,
        "learning_rate": 0.00012783927863492742,
        "gradient_norm": 0.4134834110736847,
        "train_loss": 3.061734676361084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23497,
        "tokens": 12319195136,
        "learning_rate": 0.00012782029163660815,
        "gradient_norm": 0.413999080657959,
        "train_loss": 2.984531879425049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23498,
        "tokens": 12319719424,
        "learning_rate": 0.0001278013069140734,
        "gradient_norm": 0.4287624955177307,
        "train_loss": 3.003551483154297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23499,
        "tokens": 12320243712,
        "learning_rate": 0.0001277823244675371,
        "gradient_norm": 0.3905862271785736,
        "train_loss": 3.009636402130127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23500,
        "tokens": 12320768000,
        "learning_rate": 0.00012776334429721273,
        "gradient_norm": 0.41778942942619324,
        "train_loss": 2.978017807006836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23501,
        "tokens": 12321292288,
        "learning_rate": 0.00012774436640331405,
        "gradient_norm": 0.402630090713501,
        "train_loss": 2.970796585083008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23502,
        "tokens": 12321816576,
        "learning_rate": 0.00012772539078605464,
        "gradient_norm": 0.44896143674850464,
        "train_loss": 3.0549678802490234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23503,
        "tokens": 12322340864,
        "learning_rate": 0.0001277064174456481,
        "gradient_norm": 0.3879489302635193,
        "train_loss": 3.078200578689575,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23504,
        "tokens": 12322865152,
        "learning_rate": 0.000127687446382308,
        "gradient_norm": 0.43494081497192383,
        "train_loss": 2.992809772491455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23505,
        "tokens": 12323389440,
        "learning_rate": 0.0001276684775962478,
        "gradient_norm": 0.39575570821762085,
        "train_loss": 3.018702507019043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23506,
        "tokens": 12323913728,
        "learning_rate": 0.0001276495110876812,
        "gradient_norm": 0.5474123954772949,
        "train_loss": 3.0355894565582275,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23507,
        "tokens": 12324438016,
        "learning_rate": 0.00012763054685682154,
        "gradient_norm": 0.44893380999565125,
        "train_loss": 2.966184139251709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23508,
        "tokens": 12324962304,
        "learning_rate": 0.0001276115849038824,
        "gradient_norm": 0.5156552195549011,
        "train_loss": 3.028421401977539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23509,
        "tokens": 12325486592,
        "learning_rate": 0.00012759262522907708,
        "gradient_norm": 0.45099353790283203,
        "train_loss": 3.0331170558929443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23510,
        "tokens": 12326010880,
        "learning_rate": 0.00012757366783261914,
        "gradient_norm": 0.46097061038017273,
        "train_loss": 3.031050205230713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23511,
        "tokens": 12326535168,
        "learning_rate": 0.00012755471271472184,
        "gradient_norm": 0.4279172718524933,
        "train_loss": 3.0285017490386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23512,
        "tokens": 12327059456,
        "learning_rate": 0.00012753575987559866,
        "gradient_norm": 0.4371388554573059,
        "train_loss": 3.105825424194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23513,
        "tokens": 12327583744,
        "learning_rate": 0.00012751680931546278,
        "gradient_norm": 0.50563645362854,
        "train_loss": 3.033432960510254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23514,
        "tokens": 12328108032,
        "learning_rate": 0.00012749786103452774,
        "gradient_norm": 0.4202756881713867,
        "train_loss": 3.0227773189544678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23515,
        "tokens": 12328632320,
        "learning_rate": 0.0001274789150330066,
        "gradient_norm": 0.5493761897087097,
        "train_loss": 3.098019599914551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23516,
        "tokens": 12329156608,
        "learning_rate": 0.00012745997131111272,
        "gradient_norm": 0.4933815896511078,
        "train_loss": 3.0376229286193848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23517,
        "tokens": 12329680896,
        "learning_rate": 0.00012744102986905943,
        "gradient_norm": 0.44628438353538513,
        "train_loss": 3.045462131500244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23518,
        "tokens": 12330205184,
        "learning_rate": 0.00012742209070705978,
        "gradient_norm": 0.45902732014656067,
        "train_loss": 2.9927749633789062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23519,
        "tokens": 12330729472,
        "learning_rate": 0.00012740315382532704,
        "gradient_norm": 0.40322303771972656,
        "train_loss": 3.0540761947631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23520,
        "tokens": 12331253760,
        "learning_rate": 0.0001273842192240743,
        "gradient_norm": 0.4324507415294647,
        "train_loss": 3.0196611881256104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23521,
        "tokens": 12331778048,
        "learning_rate": 0.00012736528690351483,
        "gradient_norm": 0.44344985485076904,
        "train_loss": 3.0067660808563232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23522,
        "tokens": 12332302336,
        "learning_rate": 0.00012734635686386154,
        "gradient_norm": 0.4221920371055603,
        "train_loss": 3.0459108352661133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23523,
        "tokens": 12332826624,
        "learning_rate": 0.0001273274291053277,
        "gradient_norm": 0.44288715720176697,
        "train_loss": 3.0543956756591797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23524,
        "tokens": 12333350912,
        "learning_rate": 0.00012730850362812626,
        "gradient_norm": 0.391650527715683,
        "train_loss": 3.0837738513946533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23525,
        "tokens": 12333875200,
        "learning_rate": 0.0001272895804324702,
        "gradient_norm": 0.4562486708164215,
        "train_loss": 3.056011915206909,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23526,
        "tokens": 12334399488,
        "learning_rate": 0.0001272706595185727,
        "gradient_norm": 0.418892502784729,
        "train_loss": 3.0548126697540283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23527,
        "tokens": 12334923776,
        "learning_rate": 0.00012725174088664657,
        "gradient_norm": 0.3927784264087677,
        "train_loss": 3.069197654724121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23528,
        "tokens": 12335448064,
        "learning_rate": 0.00012723282453690492,
        "gradient_norm": 0.4589775502681732,
        "train_loss": 3.01143741607666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23529,
        "tokens": 12335972352,
        "learning_rate": 0.00012721391046956047,
        "gradient_norm": 0.4019697308540344,
        "train_loss": 3.0217723846435547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23530,
        "tokens": 12336496640,
        "learning_rate": 0.00012719499868482637,
        "gradient_norm": 0.41871893405914307,
        "train_loss": 3.0241167545318604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23531,
        "tokens": 12337020928,
        "learning_rate": 0.00012717608918291523,
        "gradient_norm": 0.37721458077430725,
        "train_loss": 2.974087715148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23532,
        "tokens": 12337545216,
        "learning_rate": 0.0001271571819640401,
        "gradient_norm": 0.46208277344703674,
        "train_loss": 3.0590438842773438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23533,
        "tokens": 12338069504,
        "learning_rate": 0.0001271382770284137,
        "gradient_norm": 0.41426610946655273,
        "train_loss": 3.0079426765441895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23534,
        "tokens": 12338593792,
        "learning_rate": 0.00012711937437624894,
        "gradient_norm": 0.4290946424007416,
        "train_loss": 3.0844645500183105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23535,
        "tokens": 12339118080,
        "learning_rate": 0.00012710047400775845,
        "gradient_norm": 0.45840466022491455,
        "train_loss": 3.00833797454834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23536,
        "tokens": 12339642368,
        "learning_rate": 0.000127081575923155,
        "gradient_norm": 0.44719359278678894,
        "train_loss": 3.0499629974365234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23537,
        "tokens": 12340166656,
        "learning_rate": 0.00012706268012265147,
        "gradient_norm": 0.48291516304016113,
        "train_loss": 3.0926475524902344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23538,
        "tokens": 12340690944,
        "learning_rate": 0.00012704378660646036,
        "gradient_norm": 0.4252307415008545,
        "train_loss": 2.967761993408203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23539,
        "tokens": 12341215232,
        "learning_rate": 0.0001270248953747945,
        "gradient_norm": 0.4399164915084839,
        "train_loss": 3.019528865814209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23540,
        "tokens": 12341739520,
        "learning_rate": 0.00012700600642786641,
        "gradient_norm": 0.4393857717514038,
        "train_loss": 3.049377918243408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23541,
        "tokens": 12342263808,
        "learning_rate": 0.00012698711976588878,
        "gradient_norm": 0.38678091764450073,
        "train_loss": 3.020965576171875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23542,
        "tokens": 12342788096,
        "learning_rate": 0.00012696823538907413,
        "gradient_norm": 0.4781249165534973,
        "train_loss": 3.0396158695220947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23543,
        "tokens": 12343312384,
        "learning_rate": 0.0001269493532976352,
        "gradient_norm": 0.41643181443214417,
        "train_loss": 3.0151796340942383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23544,
        "tokens": 12343836672,
        "learning_rate": 0.00012693047349178423,
        "gradient_norm": 0.40458330512046814,
        "train_loss": 3.0265464782714844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23545,
        "tokens": 12344360960,
        "learning_rate": 0.00012691159597173405,
        "gradient_norm": 0.38603612780570984,
        "train_loss": 3.065140962600708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23546,
        "tokens": 12344885248,
        "learning_rate": 0.0001268927207376969,
        "gradient_norm": 0.4099777936935425,
        "train_loss": 3.068354845046997,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23547,
        "tokens": 12345409536,
        "learning_rate": 0.00012687384778988547,
        "gradient_norm": 0.4361584186553955,
        "train_loss": 3.090508460998535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23548,
        "tokens": 12345933824,
        "learning_rate": 0.00012685497712851203,
        "gradient_norm": 0.38987812399864197,
        "train_loss": 3.005795478820801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23549,
        "tokens": 12346458112,
        "learning_rate": 0.00012683610875378909,
        "gradient_norm": 0.45036354660987854,
        "train_loss": 2.9916563034057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23550,
        "tokens": 12346982400,
        "learning_rate": 0.00012681724266592893,
        "gradient_norm": 0.40061402320861816,
        "train_loss": 3.031045913696289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23551,
        "tokens": 12347506688,
        "learning_rate": 0.00012679837886514405,
        "gradient_norm": 0.47441574931144714,
        "train_loss": 3.012986660003662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23552,
        "tokens": 12348030976,
        "learning_rate": 0.00012677951735164664,
        "gradient_norm": 0.417986124753952,
        "train_loss": 3.0107831954956055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23553,
        "tokens": 12348555264,
        "learning_rate": 0.00012676065812564915,
        "gradient_norm": 0.43391773104667664,
        "train_loss": 3.0165839195251465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23554,
        "tokens": 12349079552,
        "learning_rate": 0.00012674180118736372,
        "gradient_norm": 0.4223734736442566,
        "train_loss": 3.007761001586914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23555,
        "tokens": 12349603840,
        "learning_rate": 0.0001267229465370028,
        "gradient_norm": 0.3927166163921356,
        "train_loss": 3.0319247245788574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23556,
        "tokens": 12350128128,
        "learning_rate": 0.00012670409417477838,
        "gradient_norm": 0.5593211650848389,
        "train_loss": 3.0884103775024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23557,
        "tokens": 12350652416,
        "learning_rate": 0.00012668524410090293,
        "gradient_norm": 0.42567914724349976,
        "train_loss": 3.0718464851379395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23558,
        "tokens": 12351176704,
        "learning_rate": 0.00012666639631558836,
        "gradient_norm": 0.49930986762046814,
        "train_loss": 3.1135501861572266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23559,
        "tokens": 12351700992,
        "learning_rate": 0.00012664755081904708,
        "gradient_norm": 0.4870968163013458,
        "train_loss": 3.102354049682617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23560,
        "tokens": 12352225280,
        "learning_rate": 0.000126628707611491,
        "gradient_norm": 0.4210737645626068,
        "train_loss": 3.0377354621887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23561,
        "tokens": 12352749568,
        "learning_rate": 0.00012660986669313235,
        "gradient_norm": 0.396616667509079,
        "train_loss": 3.094395160675049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23562,
        "tokens": 12353273856,
        "learning_rate": 0.0001265910280641832,
        "gradient_norm": 0.4321333169937134,
        "train_loss": 3.0756218433380127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23563,
        "tokens": 12353798144,
        "learning_rate": 0.0001265721917248556,
        "gradient_norm": 0.41479021310806274,
        "train_loss": 3.060600757598877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23564,
        "tokens": 12354322432,
        "learning_rate": 0.00012655335767536156,
        "gradient_norm": 0.4128973186016083,
        "train_loss": 3.0406789779663086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23565,
        "tokens": 12354846720,
        "learning_rate": 0.00012653452591591304,
        "gradient_norm": 0.4083915650844574,
        "train_loss": 3.0406174659729004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23566,
        "tokens": 12355371008,
        "learning_rate": 0.00012651569644672213,
        "gradient_norm": 0.4417417049407959,
        "train_loss": 3.0099353790283203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23567,
        "tokens": 12355895296,
        "learning_rate": 0.00012649686926800066,
        "gradient_norm": 0.41951870918273926,
        "train_loss": 3.01228404045105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23568,
        "tokens": 12356419584,
        "learning_rate": 0.0001264780443799606,
        "gradient_norm": 0.44880416989326477,
        "train_loss": 3.054443359375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23569,
        "tokens": 12356943872,
        "learning_rate": 0.00012645922178281384,
        "gradient_norm": 0.41747409105300903,
        "train_loss": 2.9925644397735596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23570,
        "tokens": 12357468160,
        "learning_rate": 0.0001264404014767723,
        "gradient_norm": 0.4258962571620941,
        "train_loss": 3.027194023132324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23571,
        "tokens": 12357992448,
        "learning_rate": 0.0001264215834620477,
        "gradient_norm": 0.4049326181411743,
        "train_loss": 3.015004873275757,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23572,
        "tokens": 12358516736,
        "learning_rate": 0.00012640276773885205,
        "gradient_norm": 0.42267659306526184,
        "train_loss": 3.006542682647705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23573,
        "tokens": 12359041024,
        "learning_rate": 0.00012638395430739695,
        "gradient_norm": 0.4439176023006439,
        "train_loss": 3.0118374824523926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23574,
        "tokens": 12359565312,
        "learning_rate": 0.00012636514316789434,
        "gradient_norm": 0.42118340730667114,
        "train_loss": 3.0215907096862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23575,
        "tokens": 12360089600,
        "learning_rate": 0.00012634633432055583,
        "gradient_norm": 0.4567597210407257,
        "train_loss": 3.0267865657806396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23576,
        "tokens": 12360613888,
        "learning_rate": 0.00012632752776559314,
        "gradient_norm": 0.4449249804019928,
        "train_loss": 3.089824676513672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23577,
        "tokens": 12361138176,
        "learning_rate": 0.0001263087235032181,
        "gradient_norm": 0.44206491112709045,
        "train_loss": 3.001741647720337,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23578,
        "tokens": 12361662464,
        "learning_rate": 0.00012628992153364222,
        "gradient_norm": 0.4205843210220337,
        "train_loss": 3.0072436332702637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23579,
        "tokens": 12362186752,
        "learning_rate": 0.00012627112185707728,
        "gradient_norm": 0.430743008852005,
        "train_loss": 3.0118985176086426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23580,
        "tokens": 12362711040,
        "learning_rate": 0.00012625232447373476,
        "gradient_norm": 0.4562159776687622,
        "train_loss": 3.030407190322876,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23581,
        "tokens": 12363235328,
        "learning_rate": 0.00012623352938382634,
        "gradient_norm": 0.3993247151374817,
        "train_loss": 3.0453577041625977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23582,
        "tokens": 12363759616,
        "learning_rate": 0.0001262147365875635,
        "gradient_norm": 0.4070322513580322,
        "train_loss": 3.0330874919891357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23583,
        "tokens": 12364283904,
        "learning_rate": 0.0001261959460851579,
        "gradient_norm": 0.43677276372909546,
        "train_loss": 3.0484676361083984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23584,
        "tokens": 12364808192,
        "learning_rate": 0.00012617715787682088,
        "gradient_norm": 0.3924486041069031,
        "train_loss": 2.998389720916748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23585,
        "tokens": 12365332480,
        "learning_rate": 0.00012615837196276402,
        "gradient_norm": 0.49997034668922424,
        "train_loss": 3.0172715187072754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23586,
        "tokens": 12365856768,
        "learning_rate": 0.0001261395883431989,
        "gradient_norm": 0.5167722702026367,
        "train_loss": 3.0525994300842285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23587,
        "tokens": 12366381056,
        "learning_rate": 0.0001261208070183367,
        "gradient_norm": 0.4773435890674591,
        "train_loss": 3.082934856414795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23588,
        "tokens": 12366905344,
        "learning_rate": 0.00012610202798838907,
        "gradient_norm": 0.4901726245880127,
        "train_loss": 2.973612070083618,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23589,
        "tokens": 12367429632,
        "learning_rate": 0.0001260832512535672,
        "gradient_norm": 0.48183849453926086,
        "train_loss": 3.0607361793518066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23590,
        "tokens": 12367953920,
        "learning_rate": 0.00012606447681408258,
        "gradient_norm": 0.40402379631996155,
        "train_loss": 3.0424318313598633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23591,
        "tokens": 12368478208,
        "learning_rate": 0.00012604570467014643,
        "gradient_norm": 0.5264317393302917,
        "train_loss": 3.103086471557617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23592,
        "tokens": 12369002496,
        "learning_rate": 0.0001260269348219702,
        "gradient_norm": 0.43068763613700867,
        "train_loss": 3.0468974113464355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23593,
        "tokens": 12369526784,
        "learning_rate": 0.00012600816726976498,
        "gradient_norm": 0.504780113697052,
        "train_loss": 3.012661933898926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23594,
        "tokens": 12370051072,
        "learning_rate": 0.0001259894020137421,
        "gradient_norm": 0.40938282012939453,
        "train_loss": 3.031601905822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23595,
        "tokens": 12370575360,
        "learning_rate": 0.00012597063905411292,
        "gradient_norm": 0.47993704676628113,
        "train_loss": 3.0296692848205566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23596,
        "tokens": 12371099648,
        "learning_rate": 0.00012595187839108845,
        "gradient_norm": 1.121521234512329,
        "train_loss": 3.094059467315674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23597,
        "tokens": 12371623936,
        "learning_rate": 0.00012593312002487998,
        "gradient_norm": 0.6554564833641052,
        "train_loss": 3.1191396713256836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23598,
        "tokens": 12372148224,
        "learning_rate": 0.00012591436395569856,
        "gradient_norm": 0.5819315910339355,
        "train_loss": 3.0740647315979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23599,
        "tokens": 12372672512,
        "learning_rate": 0.00012589561018375547,
        "gradient_norm": 0.5906532406806946,
        "train_loss": 3.0355658531188965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23600,
        "tokens": 12373196800,
        "learning_rate": 0.00012587685870926163,
        "gradient_norm": 0.5848908424377441,
        "train_loss": 3.1310243606567383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23601,
        "tokens": 12373721088,
        "learning_rate": 0.00012585810953242823,
        "gradient_norm": 0.46715036034584045,
        "train_loss": 2.994760513305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23602,
        "tokens": 12374245376,
        "learning_rate": 0.00012583936265346622,
        "gradient_norm": 0.48524633049964905,
        "train_loss": 2.9914121627807617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23603,
        "tokens": 12374769664,
        "learning_rate": 0.00012582061807258678,
        "gradient_norm": 0.4797779619693756,
        "train_loss": 3.0791990756988525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23604,
        "tokens": 12375293952,
        "learning_rate": 0.0001258018757900007,
        "gradient_norm": 0.42215514183044434,
        "train_loss": 2.9802021980285645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23605,
        "tokens": 12375818240,
        "learning_rate": 0.00012578313580591905,
        "gradient_norm": 0.4330800473690033,
        "train_loss": 3.0668458938598633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23606,
        "tokens": 12376342528,
        "learning_rate": 0.00012576439812055285,
        "gradient_norm": 0.45054465532302856,
        "train_loss": 3.0269289016723633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23607,
        "tokens": 12376866816,
        "learning_rate": 0.00012574566273411286,
        "gradient_norm": 0.3757999837398529,
        "train_loss": 2.9856271743774414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23608,
        "tokens": 12377391104,
        "learning_rate": 0.00012572692964681013,
        "gradient_norm": 0.4317127466201782,
        "train_loss": 3.0614662170410156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23609,
        "tokens": 12377915392,
        "learning_rate": 0.00012570819885885536,
        "gradient_norm": 0.4101144075393677,
        "train_loss": 3.077730655670166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23610,
        "tokens": 12378439680,
        "learning_rate": 0.00012568947037045955,
        "gradient_norm": 0.42746856808662415,
        "train_loss": 3.039710760116577,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23611,
        "tokens": 12378963968,
        "learning_rate": 0.00012567074418183332,
        "gradient_norm": 0.526361882686615,
        "train_loss": 2.992100238800049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23612,
        "tokens": 12379488256,
        "learning_rate": 0.00012565202029318767,
        "gradient_norm": 0.4329011142253876,
        "train_loss": 3.0826311111450195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23613,
        "tokens": 12380012544,
        "learning_rate": 0.00012563329870473314,
        "gradient_norm": 0.5097848773002625,
        "train_loss": 3.0299839973449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23614,
        "tokens": 12380536832,
        "learning_rate": 0.00012561457941668067,
        "gradient_norm": 0.5156307816505432,
        "train_loss": 3.0512938499450684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23615,
        "tokens": 12381061120,
        "learning_rate": 0.00012559586242924086,
        "gradient_norm": 0.4014696776866913,
        "train_loss": 3.046295404434204,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23616,
        "tokens": 12381585408,
        "learning_rate": 0.0001255771477426244,
        "gradient_norm": 0.47943779826164246,
        "train_loss": 3.010166645050049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23617,
        "tokens": 12382109696,
        "learning_rate": 0.00012555843535704204,
        "gradient_norm": 0.4558529257774353,
        "train_loss": 3.015994071960449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23618,
        "tokens": 12382633984,
        "learning_rate": 0.00012553972527270423,
        "gradient_norm": 0.469271183013916,
        "train_loss": 2.9959611892700195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23619,
        "tokens": 12383158272,
        "learning_rate": 0.00012552101748982179,
        "gradient_norm": 0.4362853467464447,
        "train_loss": 3.006730556488037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23620,
        "tokens": 12383682560,
        "learning_rate": 0.00012550231200860506,
        "gradient_norm": 0.4613029658794403,
        "train_loss": 3.1213316917419434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23621,
        "tokens": 12384206848,
        "learning_rate": 0.00012548360882926485,
        "gradient_norm": 0.4577655494213104,
        "train_loss": 3.06392240524292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23622,
        "tokens": 12384731136,
        "learning_rate": 0.00012546490795201144,
        "gradient_norm": 0.5057070255279541,
        "train_loss": 3.0127625465393066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23623,
        "tokens": 12385255424,
        "learning_rate": 0.00012544620937705555,
        "gradient_norm": 0.4720378518104553,
        "train_loss": 3.062925100326538,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23624,
        "tokens": 12385779712,
        "learning_rate": 0.00012542751310460747,
        "gradient_norm": 0.43153077363967896,
        "train_loss": 3.061213970184326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23625,
        "tokens": 12386304000,
        "learning_rate": 0.00012540881913487774,
        "gradient_norm": 0.4068186581134796,
        "train_loss": 3.018315553665161,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23626,
        "tokens": 12386828288,
        "learning_rate": 0.00012539012746807686,
        "gradient_norm": 0.48960551619529724,
        "train_loss": 2.989534378051758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23627,
        "tokens": 12387352576,
        "learning_rate": 0.00012537143810441504,
        "gradient_norm": 0.43979623913764954,
        "train_loss": 3.0354156494140625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23628,
        "tokens": 12387876864,
        "learning_rate": 0.00012535275104410287,
        "gradient_norm": 0.4104268252849579,
        "train_loss": 3.022639274597168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23629,
        "tokens": 12388401152,
        "learning_rate": 0.00012533406628735056,
        "gradient_norm": 0.4509202539920807,
        "train_loss": 3.032334327697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23630,
        "tokens": 12388925440,
        "learning_rate": 0.00012531538383436845,
        "gradient_norm": 0.545482873916626,
        "train_loss": 3.058549165725708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23631,
        "tokens": 12389449728,
        "learning_rate": 0.00012529670368536679,
        "gradient_norm": 0.4488156735897064,
        "train_loss": 3.0267250537872314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23632,
        "tokens": 12389974016,
        "learning_rate": 0.000125278025840556,
        "gradient_norm": 0.4159824848175049,
        "train_loss": 3.012052059173584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23633,
        "tokens": 12390498304,
        "learning_rate": 0.0001252593503001461,
        "gradient_norm": 0.47477859258651733,
        "train_loss": 3.0631351470947266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23634,
        "tokens": 12391022592,
        "learning_rate": 0.00012524067706434745,
        "gradient_norm": 0.4067017734050751,
        "train_loss": 3.0555951595306396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23635,
        "tokens": 12391546880,
        "learning_rate": 0.00012522200613337032,
        "gradient_norm": 0.5191525220870972,
        "train_loss": 3.026386260986328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23636,
        "tokens": 12392071168,
        "learning_rate": 0.00012520333750742468,
        "gradient_norm": 0.39404723048210144,
        "train_loss": 3.00246000289917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23637,
        "tokens": 12392595456,
        "learning_rate": 0.0001251846711867208,
        "gradient_norm": 0.45245784521102905,
        "train_loss": 3.0385918617248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23638,
        "tokens": 12393119744,
        "learning_rate": 0.00012516600717146873,
        "gradient_norm": 0.4594448506832123,
        "train_loss": 3.0342671871185303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23639,
        "tokens": 12393644032,
        "learning_rate": 0.00012514734546187865,
        "gradient_norm": 0.3926475942134857,
        "train_loss": 3.0592329502105713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23640,
        "tokens": 12394168320,
        "learning_rate": 0.00012512868605816044,
        "gradient_norm": 0.4406728446483612,
        "train_loss": 3.0550365447998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23641,
        "tokens": 12394692608,
        "learning_rate": 0.00012511002896052435,
        "gradient_norm": 0.3935234844684601,
        "train_loss": 3.0195765495300293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23642,
        "tokens": 12395216896,
        "learning_rate": 0.00012509137416918026,
        "gradient_norm": 0.548480212688446,
        "train_loss": 3.1241724491119385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23643,
        "tokens": 12395741184,
        "learning_rate": 0.00012507272168433818,
        "gradient_norm": 0.43365880846977234,
        "train_loss": 3.039259195327759,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23644,
        "tokens": 12396265472,
        "learning_rate": 0.000125054071506208,
        "gradient_norm": 0.46625933051109314,
        "train_loss": 3.047271728515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23645,
        "tokens": 12396789760,
        "learning_rate": 0.00012503542363499976,
        "gradient_norm": 0.43510866165161133,
        "train_loss": 3.0165858268737793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23646,
        "tokens": 12397314048,
        "learning_rate": 0.00012501677807092338,
        "gradient_norm": 0.4372310936450958,
        "train_loss": 3.0222110748291016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23647,
        "tokens": 12397838336,
        "learning_rate": 0.00012499813481418857,
        "gradient_norm": 0.4118175804615021,
        "train_loss": 2.9955873489379883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23648,
        "tokens": 12398362624,
        "learning_rate": 0.00012497949386500537,
        "gradient_norm": 0.44809383153915405,
        "train_loss": 3.06752347946167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23649,
        "tokens": 12398886912,
        "learning_rate": 0.00012496085522358352,
        "gradient_norm": 0.4454492926597595,
        "train_loss": 3.0114128589630127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23650,
        "tokens": 12399411200,
        "learning_rate": 0.00012494221889013286,
        "gradient_norm": 0.3917437791824341,
        "train_loss": 3.0058963298797607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23651,
        "tokens": 12399935488,
        "learning_rate": 0.00012492358486486307,
        "gradient_norm": 0.44466134905815125,
        "train_loss": 2.9849929809570312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23652,
        "tokens": 12400459776,
        "learning_rate": 0.00012490495314798405,
        "gradient_norm": 0.3759141266345978,
        "train_loss": 2.978994369506836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23653,
        "tokens": 12400984064,
        "learning_rate": 0.00012488632373970534,
        "gradient_norm": 0.47252899408340454,
        "train_loss": 3.050567626953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23654,
        "tokens": 12401508352,
        "learning_rate": 0.00012486769664023684,
        "gradient_norm": 0.4944470524787903,
        "train_loss": 3.060957431793213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23655,
        "tokens": 12402032640,
        "learning_rate": 0.00012484907184978807,
        "gradient_norm": 0.40710464119911194,
        "train_loss": 3.005166530609131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23656,
        "tokens": 12402556928,
        "learning_rate": 0.00012483044936856876,
        "gradient_norm": 0.47244787216186523,
        "train_loss": 2.9787206649780273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23657,
        "tokens": 12403081216,
        "learning_rate": 0.0001248118291967884,
        "gradient_norm": 0.44007229804992676,
        "train_loss": 2.991452932357788,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23658,
        "tokens": 12403605504,
        "learning_rate": 0.00012479321133465675,
        "gradient_norm": 0.45655888319015503,
        "train_loss": 3.0526528358459473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23659,
        "tokens": 12404129792,
        "learning_rate": 0.00012477459578238325,
        "gradient_norm": 0.45542657375335693,
        "train_loss": 3.0599594116210938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23660,
        "tokens": 12404654080,
        "learning_rate": 0.00012475598254017758,
        "gradient_norm": 0.46884778141975403,
        "train_loss": 3.0391321182250977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23661,
        "tokens": 12405178368,
        "learning_rate": 0.0001247373716082491,
        "gradient_norm": 0.4243452847003937,
        "train_loss": 2.9919753074645996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23662,
        "tokens": 12405702656,
        "learning_rate": 0.00012471876298680742,
        "gradient_norm": 0.4454920291900635,
        "train_loss": 3.0060932636260986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23663,
        "tokens": 12406226944,
        "learning_rate": 0.00012470015667606188,
        "gradient_norm": 0.3911179304122925,
        "train_loss": 3.013969898223877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23664,
        "tokens": 12406751232,
        "learning_rate": 0.00012468155267622208,
        "gradient_norm": 0.46290624141693115,
        "train_loss": 3.0525710582733154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23665,
        "tokens": 12407275520,
        "learning_rate": 0.00012466295098749724,
        "gradient_norm": 0.4253418445587158,
        "train_loss": 3.0238423347473145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23666,
        "tokens": 12407799808,
        "learning_rate": 0.00012464435161009692,
        "gradient_norm": 0.4012591242790222,
        "train_loss": 2.998560667037964,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23667,
        "tokens": 12408324096,
        "learning_rate": 0.00012462575454423038,
        "gradient_norm": 0.4612925052642822,
        "train_loss": 3.0024635791778564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23668,
        "tokens": 12408848384,
        "learning_rate": 0.00012460715979010703,
        "gradient_norm": 0.42331382632255554,
        "train_loss": 3.0879836082458496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23669,
        "tokens": 12409372672,
        "learning_rate": 0.000124588567347936,
        "gradient_norm": 0.48449835181236267,
        "train_loss": 3.050391674041748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23670,
        "tokens": 12409896960,
        "learning_rate": 0.00012456997721792685,
        "gradient_norm": 0.43225014209747314,
        "train_loss": 3.033236503601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23671,
        "tokens": 12410421248,
        "learning_rate": 0.00012455138940028858,
        "gradient_norm": 0.4073551595211029,
        "train_loss": 3.0302867889404297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23672,
        "tokens": 12410945536,
        "learning_rate": 0.00012453280389523055,
        "gradient_norm": 0.42214953899383545,
        "train_loss": 3.1180999279022217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23673,
        "tokens": 12411469824,
        "learning_rate": 0.0001245142207029619,
        "gradient_norm": 0.4658432602882385,
        "train_loss": 2.9864487648010254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23674,
        "tokens": 12411994112,
        "learning_rate": 0.00012449563982369182,
        "gradient_norm": 0.4348801374435425,
        "train_loss": 3.0386476516723633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23675,
        "tokens": 12412518400,
        "learning_rate": 0.00012447706125762962,
        "gradient_norm": 0.5018023252487183,
        "train_loss": 3.074523448944092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23676,
        "tokens": 12413042688,
        "learning_rate": 0.00012445848500498415,
        "gradient_norm": 0.412437379360199,
        "train_loss": 3.0179567337036133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23677,
        "tokens": 12413566976,
        "learning_rate": 0.00012443991106596473,
        "gradient_norm": 0.46060916781425476,
        "train_loss": 3.0210461616516113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23678,
        "tokens": 12414091264,
        "learning_rate": 0.00012442133944078027,
        "gradient_norm": 0.45547109842300415,
        "train_loss": 3.05116605758667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23679,
        "tokens": 12414615552,
        "learning_rate": 0.00012440277012963998,
        "gradient_norm": 0.4447270631790161,
        "train_loss": 3.019563674926758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23680,
        "tokens": 12415139840,
        "learning_rate": 0.0001243842031327527,
        "gradient_norm": 0.45295608043670654,
        "train_loss": 3.0345053672790527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23681,
        "tokens": 12415664128,
        "learning_rate": 0.00012436563845032763,
        "gradient_norm": 0.4491281807422638,
        "train_loss": 2.9997286796569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23682,
        "tokens": 12416188416,
        "learning_rate": 0.00012434707608257353,
        "gradient_norm": 0.43576690554618835,
        "train_loss": 3.0811104774475098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23683,
        "tokens": 12416712704,
        "learning_rate": 0.00012432851602969954,
        "gradient_norm": 0.42642414569854736,
        "train_loss": 2.987706422805786,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23684,
        "tokens": 12417236992,
        "learning_rate": 0.00012430995829191437,
        "gradient_norm": 0.4121898114681244,
        "train_loss": 3.084878921508789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23685,
        "tokens": 12417761280,
        "learning_rate": 0.00012429140286942706,
        "gradient_norm": 0.43167129158973694,
        "train_loss": 3.030890464782715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23686,
        "tokens": 12418285568,
        "learning_rate": 0.00012427284976244648,
        "gradient_norm": 0.4359944760799408,
        "train_loss": 3.046764612197876,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23687,
        "tokens": 12418809856,
        "learning_rate": 0.00012425429897118133,
        "gradient_norm": 0.4347894787788391,
        "train_loss": 3.0456719398498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23688,
        "tokens": 12419334144,
        "learning_rate": 0.00012423575049584062,
        "gradient_norm": 0.46183058619499207,
        "train_loss": 2.9797189235687256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23689,
        "tokens": 12419858432,
        "learning_rate": 0.00012421720433663293,
        "gradient_norm": 0.4813244640827179,
        "train_loss": 2.9936470985412598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23690,
        "tokens": 12420382720,
        "learning_rate": 0.00012419866049376722,
        "gradient_norm": 0.41473647952079773,
        "train_loss": 3.017730474472046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23691,
        "tokens": 12420907008,
        "learning_rate": 0.00012418011896745204,
        "gradient_norm": 0.44250810146331787,
        "train_loss": 3.0192947387695312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23692,
        "tokens": 12421431296,
        "learning_rate": 0.00012416157975789625,
        "gradient_norm": 0.3733369708061218,
        "train_loss": 2.9466309547424316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23693,
        "tokens": 12421955584,
        "learning_rate": 0.0001241430428653084,
        "gradient_norm": 0.43178749084472656,
        "train_loss": 3.0362343788146973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23694,
        "tokens": 12422479872,
        "learning_rate": 0.00012412450828989718,
        "gradient_norm": 0.4263105094432831,
        "train_loss": 3.0669126510620117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23695,
        "tokens": 12423004160,
        "learning_rate": 0.00012410597603187138,
        "gradient_norm": 0.44369176030158997,
        "train_loss": 3.070178985595703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23696,
        "tokens": 12423528448,
        "learning_rate": 0.0001240874460914394,
        "gradient_norm": 0.4654388427734375,
        "train_loss": 3.0032200813293457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23697,
        "tokens": 12424052736,
        "learning_rate": 0.00012406891846880992,
        "gradient_norm": 0.43839386105537415,
        "train_loss": 3.034477710723877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23698,
        "tokens": 12424577024,
        "learning_rate": 0.00012405039316419137,
        "gradient_norm": 0.44385668635368347,
        "train_loss": 3.102985382080078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23699,
        "tokens": 12425101312,
        "learning_rate": 0.0001240318701777925,
        "gradient_norm": 0.4741646945476532,
        "train_loss": 2.99783992767334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23700,
        "tokens": 12425625600,
        "learning_rate": 0.0001240133495098216,
        "gradient_norm": 0.4308757781982422,
        "train_loss": 3.0245933532714844,
        "val_loss": 2.989377975463867,
        "hellaswag_acc": 0.2849034070968628,
        "hellaswag_acc_norm": 0.2960565686225891
    },
    {
        "step": 23701,
        "tokens": 12426149888,
        "learning_rate": 0.00012399483116048724,
        "gradient_norm": 0.41713014245033264,
        "train_loss": 2.995732307434082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23702,
        "tokens": 12426674176,
        "learning_rate": 0.00012397631512999781,
        "gradient_norm": 0.4258024990558624,
        "train_loss": 3.0235376358032227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23703,
        "tokens": 12427198464,
        "learning_rate": 0.00012395780141856184,
        "gradient_norm": 0.41378799080848694,
        "train_loss": 3.0118815898895264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23704,
        "tokens": 12427722752,
        "learning_rate": 0.00012393929002638758,
        "gradient_norm": 0.44096359610557556,
        "train_loss": 2.996368885040283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23705,
        "tokens": 12428247040,
        "learning_rate": 0.00012392078095368347,
        "gradient_norm": 0.4543082118034363,
        "train_loss": 3.040748119354248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23706,
        "tokens": 12428771328,
        "learning_rate": 0.0001239022742006579,
        "gradient_norm": 0.42443642020225525,
        "train_loss": 3.0685129165649414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23707,
        "tokens": 12429295616,
        "learning_rate": 0.00012388376976751913,
        "gradient_norm": 0.4588109850883484,
        "train_loss": 2.9833638668060303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23708,
        "tokens": 12429819904,
        "learning_rate": 0.0001238652676544755,
        "gradient_norm": 0.4109329283237457,
        "train_loss": 3.0346405506134033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23709,
        "tokens": 12430344192,
        "learning_rate": 0.00012384676786173518,
        "gradient_norm": 0.4067375957965851,
        "train_loss": 3.0361366271972656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23710,
        "tokens": 12430868480,
        "learning_rate": 0.0001238282703895065,
        "gradient_norm": 0.39589157700538635,
        "train_loss": 3.0599701404571533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23711,
        "tokens": 12431392768,
        "learning_rate": 0.0001238097752379976,
        "gradient_norm": 0.3973887860774994,
        "train_loss": 3.047269344329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23712,
        "tokens": 12431917056,
        "learning_rate": 0.00012379128240741673,
        "gradient_norm": 0.4056738317012787,
        "train_loss": 3.028414726257324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23713,
        "tokens": 12432441344,
        "learning_rate": 0.00012377279189797197,
        "gradient_norm": 0.4222632348537445,
        "train_loss": 3.0567708015441895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23714,
        "tokens": 12432965632,
        "learning_rate": 0.00012375430370987155,
        "gradient_norm": 0.43894198536872864,
        "train_loss": 3.1098792552948,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23715,
        "tokens": 12433489920,
        "learning_rate": 0.00012373581784332356,
        "gradient_norm": 0.42318835854530334,
        "train_loss": 3.001781940460205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23716,
        "tokens": 12434014208,
        "learning_rate": 0.00012371733429853603,
        "gradient_norm": 0.422870934009552,
        "train_loss": 3.024242401123047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23717,
        "tokens": 12434538496,
        "learning_rate": 0.00012369885307571705,
        "gradient_norm": 0.4039877653121948,
        "train_loss": 2.9963717460632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23718,
        "tokens": 12435062784,
        "learning_rate": 0.00012368037417507459,
        "gradient_norm": 0.42063745856285095,
        "train_loss": 3.012085437774658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23719,
        "tokens": 12435587072,
        "learning_rate": 0.0001236618975968168,
        "gradient_norm": 0.44927623867988586,
        "train_loss": 3.0620367527008057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23720,
        "tokens": 12436111360,
        "learning_rate": 0.00012364342334115146,
        "gradient_norm": 0.38741955161094666,
        "train_loss": 3.0487701892852783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23721,
        "tokens": 12436635648,
        "learning_rate": 0.0001236249514082867,
        "gradient_norm": 0.46905937790870667,
        "train_loss": 3.0799498558044434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23722,
        "tokens": 12437159936,
        "learning_rate": 0.0001236064817984303,
        "gradient_norm": 0.40553128719329834,
        "train_loss": 3.0375747680664062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23723,
        "tokens": 12437684224,
        "learning_rate": 0.00012358801451179026,
        "gradient_norm": 0.4398987293243408,
        "train_loss": 3.013399124145508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23724,
        "tokens": 12438208512,
        "learning_rate": 0.00012356954954857442,
        "gradient_norm": 0.40227001905441284,
        "train_loss": 3.0222771167755127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23725,
        "tokens": 12438732800,
        "learning_rate": 0.00012355108690899057,
        "gradient_norm": 0.42891180515289307,
        "train_loss": 3.0447041988372803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23726,
        "tokens": 12439257088,
        "learning_rate": 0.00012353262659324662,
        "gradient_norm": 0.40791240334510803,
        "train_loss": 2.9842844009399414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23727,
        "tokens": 12439781376,
        "learning_rate": 0.00012351416860155033,
        "gradient_norm": 0.39776578545570374,
        "train_loss": 2.991058826446533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23728,
        "tokens": 12440305664,
        "learning_rate": 0.0001234957129341095,
        "gradient_norm": 0.4231437146663666,
        "train_loss": 3.014106512069702,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23729,
        "tokens": 12440829952,
        "learning_rate": 0.00012347725959113178,
        "gradient_norm": 0.41343873739242554,
        "train_loss": 3.082350254058838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23730,
        "tokens": 12441354240,
        "learning_rate": 0.00012345880857282497,
        "gradient_norm": 0.3835330009460449,
        "train_loss": 3.0284457206726074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23731,
        "tokens": 12441878528,
        "learning_rate": 0.00012344035987939668,
        "gradient_norm": 0.38535305857658386,
        "train_loss": 3.080028533935547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23732,
        "tokens": 12442402816,
        "learning_rate": 0.00012342191351105472,
        "gradient_norm": 0.4168526530265808,
        "train_loss": 3.021629571914673,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23733,
        "tokens": 12442927104,
        "learning_rate": 0.00012340346946800653,
        "gradient_norm": 0.4359745383262634,
        "train_loss": 2.9947762489318848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23734,
        "tokens": 12443451392,
        "learning_rate": 0.0001233850277504598,
        "gradient_norm": 0.3841744065284729,
        "train_loss": 3.0421388149261475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23735,
        "tokens": 12443975680,
        "learning_rate": 0.00012336658835862224,
        "gradient_norm": 0.4527910053730011,
        "train_loss": 3.0426716804504395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23736,
        "tokens": 12444499968,
        "learning_rate": 0.00012334815129270125,
        "gradient_norm": 0.3978530168533325,
        "train_loss": 3.0612902641296387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23737,
        "tokens": 12445024256,
        "learning_rate": 0.00012332971655290445,
        "gradient_norm": 0.41758888959884644,
        "train_loss": 3.02622652053833,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23738,
        "tokens": 12445548544,
        "learning_rate": 0.00012331128413943924,
        "gradient_norm": 0.4008467197418213,
        "train_loss": 3.024113178253174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23739,
        "tokens": 12446072832,
        "learning_rate": 0.00012329285405251328,
        "gradient_norm": 0.4415324330329895,
        "train_loss": 3.0633902549743652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23740,
        "tokens": 12446597120,
        "learning_rate": 0.0001232744262923338,
        "gradient_norm": 0.39323678612709045,
        "train_loss": 3.0128228664398193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23741,
        "tokens": 12447121408,
        "learning_rate": 0.00012325600085910844,
        "gradient_norm": 0.4032445549964905,
        "train_loss": 3.0401406288146973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23742,
        "tokens": 12447645696,
        "learning_rate": 0.00012323757775304443,
        "gradient_norm": 0.4412182867527008,
        "train_loss": 3.0381901264190674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23743,
        "tokens": 12448169984,
        "learning_rate": 0.00012321915697434928,
        "gradient_norm": 0.6386537551879883,
        "train_loss": 2.9626622200012207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23744,
        "tokens": 12448694272,
        "learning_rate": 0.00012320073852323021,
        "gradient_norm": 0.4445701539516449,
        "train_loss": 3.0179402828216553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23745,
        "tokens": 12449218560,
        "learning_rate": 0.0001231823223998946,
        "gradient_norm": 0.4525143504142761,
        "train_loss": 3.036466598510742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23746,
        "tokens": 12449742848,
        "learning_rate": 0.00012316390860454983,
        "gradient_norm": 0.44273075461387634,
        "train_loss": 3.0068752765655518,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23747,
        "tokens": 12450267136,
        "learning_rate": 0.00012314549713740304,
        "gradient_norm": 0.4265346825122833,
        "train_loss": 3.0070643424987793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23748,
        "tokens": 12450791424,
        "learning_rate": 0.00012312708799866164,
        "gradient_norm": 0.41056081652641296,
        "train_loss": 3.0383572578430176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23749,
        "tokens": 12451315712,
        "learning_rate": 0.00012310868118853258,
        "gradient_norm": 0.459749311208725,
        "train_loss": 2.9935243129730225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23750,
        "tokens": 12451840000,
        "learning_rate": 0.00012309027670722334,
        "gradient_norm": 0.43219223618507385,
        "train_loss": 3.0485424995422363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23751,
        "tokens": 12452364288,
        "learning_rate": 0.00012307187455494088,
        "gradient_norm": 0.4208095073699951,
        "train_loss": 3.0515098571777344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23752,
        "tokens": 12452888576,
        "learning_rate": 0.00012305347473189244,
        "gradient_norm": 0.42490458488464355,
        "train_loss": 3.0320229530334473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23753,
        "tokens": 12453412864,
        "learning_rate": 0.0001230350772382851,
        "gradient_norm": 0.40104928612709045,
        "train_loss": 3.010251522064209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23754,
        "tokens": 12453937152,
        "learning_rate": 0.000123016682074326,
        "gradient_norm": 0.42595112323760986,
        "train_loss": 3.028308629989624,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23755,
        "tokens": 12454461440,
        "learning_rate": 0.00012299828924022205,
        "gradient_norm": 0.4067561626434326,
        "train_loss": 3.024033308029175,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23756,
        "tokens": 12454985728,
        "learning_rate": 0.00012297989873618048,
        "gradient_norm": 0.4320148825645447,
        "train_loss": 3.0627312660217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23757,
        "tokens": 12455510016,
        "learning_rate": 0.00012296151056240818,
        "gradient_norm": 0.43252649903297424,
        "train_loss": 3.1406760215759277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23758,
        "tokens": 12456034304,
        "learning_rate": 0.00012294312471911219,
        "gradient_norm": 0.41540664434432983,
        "train_loss": 3.046013832092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23759,
        "tokens": 12456558592,
        "learning_rate": 0.00012292474120649934,
        "gradient_norm": 0.4108714163303375,
        "train_loss": 3.0573010444641113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23760,
        "tokens": 12457082880,
        "learning_rate": 0.00012290636002477677,
        "gradient_norm": 0.3683631718158722,
        "train_loss": 3.0676159858703613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23761,
        "tokens": 12457607168,
        "learning_rate": 0.00012288798117415117,
        "gradient_norm": 0.4062623679637909,
        "train_loss": 3.0648510456085205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23762,
        "tokens": 12458131456,
        "learning_rate": 0.0001228696046548296,
        "gradient_norm": 0.44864678382873535,
        "train_loss": 3.0244133472442627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23763,
        "tokens": 12458655744,
        "learning_rate": 0.00012285123046701875,
        "gradient_norm": 0.37791725993156433,
        "train_loss": 2.997267961502075,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23764,
        "tokens": 12459180032,
        "learning_rate": 0.0001228328586109256,
        "gradient_norm": 0.3908272087574005,
        "train_loss": 3.0034122467041016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23765,
        "tokens": 12459704320,
        "learning_rate": 0.00012281448908675678,
        "gradient_norm": 0.3816675841808319,
        "train_loss": 3.015000343322754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23766,
        "tokens": 12460228608,
        "learning_rate": 0.00012279612189471914,
        "gradient_norm": 0.4078505039215088,
        "train_loss": 3.097588539123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23767,
        "tokens": 12460752896,
        "learning_rate": 0.0001227777570350195,
        "gradient_norm": 0.3680408298969269,
        "train_loss": 3.0599467754364014,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23768,
        "tokens": 12461277184,
        "learning_rate": 0.00012275939450786448,
        "gradient_norm": 0.4005102813243866,
        "train_loss": 3.019622802734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23769,
        "tokens": 12461801472,
        "learning_rate": 0.00012274103431346087,
        "gradient_norm": 0.3964373469352722,
        "train_loss": 3.015754461288452,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23770,
        "tokens": 12462325760,
        "learning_rate": 0.0001227226764520152,
        "gradient_norm": 0.38629427552223206,
        "train_loss": 3.0110769271850586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23771,
        "tokens": 12462850048,
        "learning_rate": 0.00012270432092373424,
        "gradient_norm": 0.41248753666877747,
        "train_loss": 3.024731159210205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23772,
        "tokens": 12463374336,
        "learning_rate": 0.00012268596772882447,
        "gradient_norm": 0.3454289138317108,
        "train_loss": 3.0047993659973145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23773,
        "tokens": 12463898624,
        "learning_rate": 0.00012266761686749266,
        "gradient_norm": 0.40142300724983215,
        "train_loss": 3.0224204063415527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23774,
        "tokens": 12464422912,
        "learning_rate": 0.00012264926833994516,
        "gradient_norm": 0.3815799355506897,
        "train_loss": 3.0593979358673096,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23775,
        "tokens": 12464947200,
        "learning_rate": 0.00012263092214638872,
        "gradient_norm": 0.39170747995376587,
        "train_loss": 3.0872578620910645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23776,
        "tokens": 12465471488,
        "learning_rate": 0.00012261257828702967,
        "gradient_norm": 0.39352792501449585,
        "train_loss": 2.994652271270752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23777,
        "tokens": 12465995776,
        "learning_rate": 0.00012259423676207458,
        "gradient_norm": 0.4072566628456116,
        "train_loss": 3.06722354888916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23778,
        "tokens": 12466520064,
        "learning_rate": 0.0001225758975717299,
        "gradient_norm": 0.37591972947120667,
        "train_loss": 3.038418769836426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23779,
        "tokens": 12467044352,
        "learning_rate": 0.0001225575607162021,
        "gradient_norm": 0.3695797920227051,
        "train_loss": 2.9588615894317627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23780,
        "tokens": 12467568640,
        "learning_rate": 0.00012253922619569744,
        "gradient_norm": 0.4372442960739136,
        "train_loss": 3.040647268295288,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23781,
        "tokens": 12468092928,
        "learning_rate": 0.0001225208940104225,
        "gradient_norm": 0.4062453508377075,
        "train_loss": 2.997727870941162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23782,
        "tokens": 12468617216,
        "learning_rate": 0.00012250256416058343,
        "gradient_norm": 0.39295822381973267,
        "train_loss": 3.018880605697632,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23783,
        "tokens": 12469141504,
        "learning_rate": 0.00012248423664638675,
        "gradient_norm": 0.4236016869544983,
        "train_loss": 3.0440797805786133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23784,
        "tokens": 12469665792,
        "learning_rate": 0.00012246591146803856,
        "gradient_norm": 0.4319095313549042,
        "train_loss": 3.030982494354248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23785,
        "tokens": 12470190080,
        "learning_rate": 0.00012244758862574526,
        "gradient_norm": 0.4367161691188812,
        "train_loss": 3.0104308128356934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23786,
        "tokens": 12470714368,
        "learning_rate": 0.00012242926811971313,
        "gradient_norm": 0.449179083108902,
        "train_loss": 3.0111083984375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23787,
        "tokens": 12471238656,
        "learning_rate": 0.00012241094995014826,
        "gradient_norm": 0.39247727394104004,
        "train_loss": 3.005768299102783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23788,
        "tokens": 12471762944,
        "learning_rate": 0.000122392634117257,
        "gradient_norm": 0.4252770245075226,
        "train_loss": 3.017761707305908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23789,
        "tokens": 12472287232,
        "learning_rate": 0.00012237432062124536,
        "gradient_norm": 0.3952135145664215,
        "train_loss": 3.024271249771118,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23790,
        "tokens": 12472811520,
        "learning_rate": 0.0001223560094623196,
        "gradient_norm": 0.3937864303588867,
        "train_loss": 3.032543659210205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23791,
        "tokens": 12473335808,
        "learning_rate": 0.00012233770064068575,
        "gradient_norm": 0.47853100299835205,
        "train_loss": 3.0599403381347656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23792,
        "tokens": 12473860096,
        "learning_rate": 0.00012231939415654997,
        "gradient_norm": 0.45256149768829346,
        "train_loss": 2.980154514312744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23793,
        "tokens": 12474384384,
        "learning_rate": 0.00012230109001011824,
        "gradient_norm": 0.4736274480819702,
        "train_loss": 3.0612387657165527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23794,
        "tokens": 12474908672,
        "learning_rate": 0.00012228278820159666,
        "gradient_norm": 0.47850653529167175,
        "train_loss": 3.030510902404785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23795,
        "tokens": 12475432960,
        "learning_rate": 0.00012226448873119128,
        "gradient_norm": 0.48095032572746277,
        "train_loss": 3.035816192626953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23796,
        "tokens": 12475957248,
        "learning_rate": 0.00012224619159910795,
        "gradient_norm": 0.43829864263534546,
        "train_loss": 3.002260684967041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23797,
        "tokens": 12476481536,
        "learning_rate": 0.00012222789680555281,
        "gradient_norm": 0.3909004032611847,
        "train_loss": 3.011840581893921,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23798,
        "tokens": 12477005824,
        "learning_rate": 0.0001222096043507316,
        "gradient_norm": 0.45093780755996704,
        "train_loss": 3.042097330093384,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23799,
        "tokens": 12477530112,
        "learning_rate": 0.00012219131423485034,
        "gradient_norm": 0.48289912939071655,
        "train_loss": 3.0331740379333496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23800,
        "tokens": 12478054400,
        "learning_rate": 0.00012217302645811483,
        "gradient_norm": 0.4583274722099304,
        "train_loss": 3.01275634765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23801,
        "tokens": 12478578688,
        "learning_rate": 0.00012215474102073107,
        "gradient_norm": 0.41248318552970886,
        "train_loss": 2.9616127014160156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23802,
        "tokens": 12479102976,
        "learning_rate": 0.00012213645792290468,
        "gradient_norm": 0.44277358055114746,
        "train_loss": 3.035944938659668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23803,
        "tokens": 12479627264,
        "learning_rate": 0.00012211817716484166,
        "gradient_norm": 0.4123087227344513,
        "train_loss": 3.049960136413574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23804,
        "tokens": 12480151552,
        "learning_rate": 0.0001220998987467476,
        "gradient_norm": 0.4826905131340027,
        "train_loss": 3.0377073287963867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23805,
        "tokens": 12480675840,
        "learning_rate": 0.00012208162266882835,
        "gradient_norm": 0.42225658893585205,
        "train_loss": 2.989262819290161,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23806,
        "tokens": 12481200128,
        "learning_rate": 0.00012206334893128966,
        "gradient_norm": 0.4111519753932953,
        "train_loss": 3.0976407527923584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23807,
        "tokens": 12481724416,
        "learning_rate": 0.00012204507753433715,
        "gradient_norm": 0.4319247603416443,
        "train_loss": 2.9957008361816406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23808,
        "tokens": 12482248704,
        "learning_rate": 0.00012202680847817655,
        "gradient_norm": 0.4178498387336731,
        "train_loss": 2.9989614486694336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23809,
        "tokens": 12482772992,
        "learning_rate": 0.00012200854176301339,
        "gradient_norm": 0.4276432693004608,
        "train_loss": 3.038517951965332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23810,
        "tokens": 12483297280,
        "learning_rate": 0.00012199027738905345,
        "gradient_norm": 0.3918718695640564,
        "train_loss": 2.9828596115112305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23811,
        "tokens": 12483821568,
        "learning_rate": 0.00012197201535650215,
        "gradient_norm": 0.4452853202819824,
        "train_loss": 3.02346134185791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23812,
        "tokens": 12484345856,
        "learning_rate": 0.00012195375566556523,
        "gradient_norm": 0.4189108908176422,
        "train_loss": 3.0554730892181396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23813,
        "tokens": 12484870144,
        "learning_rate": 0.000121935498316448,
        "gradient_norm": 0.46249085664749146,
        "train_loss": 3.024362087249756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23814,
        "tokens": 12485394432,
        "learning_rate": 0.00012191724330935615,
        "gradient_norm": 0.4433106780052185,
        "train_loss": 3.002424955368042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23815,
        "tokens": 12485918720,
        "learning_rate": 0.00012189899064449516,
        "gradient_norm": 0.39078769087791443,
        "train_loss": 2.996230363845825,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23816,
        "tokens": 12486443008,
        "learning_rate": 0.00012188074032207035,
        "gradient_norm": 0.4216654896736145,
        "train_loss": 2.989996910095215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23817,
        "tokens": 12486967296,
        "learning_rate": 0.0001218624923422873,
        "gradient_norm": 0.3795018494129181,
        "train_loss": 2.9575252532958984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23818,
        "tokens": 12487491584,
        "learning_rate": 0.00012184424670535129,
        "gradient_norm": 0.4493248462677002,
        "train_loss": 3.013852596282959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23819,
        "tokens": 12488015872,
        "learning_rate": 0.00012182600341146785,
        "gradient_norm": 0.41553911566734314,
        "train_loss": 3.088273048400879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23820,
        "tokens": 12488540160,
        "learning_rate": 0.00012180776246084214,
        "gradient_norm": 0.41656920313835144,
        "train_loss": 2.9963626861572266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23821,
        "tokens": 12489064448,
        "learning_rate": 0.00012178952385367966,
        "gradient_norm": 0.3734736442565918,
        "train_loss": 3.018825054168701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23822,
        "tokens": 12489588736,
        "learning_rate": 0.00012177128759018556,
        "gradient_norm": 0.4028587341308594,
        "train_loss": 3.0480356216430664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23823,
        "tokens": 12490113024,
        "learning_rate": 0.00012175305367056525,
        "gradient_norm": 0.4614003896713257,
        "train_loss": 3.0068047046661377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23824,
        "tokens": 12490637312,
        "learning_rate": 0.00012173482209502385,
        "gradient_norm": 0.39206910133361816,
        "train_loss": 3.025665521621704,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23825,
        "tokens": 12491161600,
        "learning_rate": 0.00012171659286376664,
        "gradient_norm": 0.39943286776542664,
        "train_loss": 3.033477306365967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23826,
        "tokens": 12491685888,
        "learning_rate": 0.00012169836597699885,
        "gradient_norm": 0.39669090509414673,
        "train_loss": 3.008301258087158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23827,
        "tokens": 12492210176,
        "learning_rate": 0.00012168014143492554,
        "gradient_norm": 0.3912328779697418,
        "train_loss": 2.9749982357025146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23828,
        "tokens": 12492734464,
        "learning_rate": 0.000121661919237752,
        "gradient_norm": 0.41021519899368286,
        "train_loss": 3.071284294128418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23829,
        "tokens": 12493258752,
        "learning_rate": 0.00012164369938568318,
        "gradient_norm": 0.39745545387268066,
        "train_loss": 3.082402229309082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23830,
        "tokens": 12493783040,
        "learning_rate": 0.00012162548187892432,
        "gradient_norm": 0.4016522169113159,
        "train_loss": 3.0560507774353027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23831,
        "tokens": 12494307328,
        "learning_rate": 0.00012160726671768036,
        "gradient_norm": 0.41395294666290283,
        "train_loss": 3.0372095108032227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23832,
        "tokens": 12494831616,
        "learning_rate": 0.00012158905390215642,
        "gradient_norm": 0.4431004226207733,
        "train_loss": 3.00968074798584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23833,
        "tokens": 12495355904,
        "learning_rate": 0.00012157084343255741,
        "gradient_norm": 0.3994615375995636,
        "train_loss": 3.074005126953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23834,
        "tokens": 12495880192,
        "learning_rate": 0.00012155263530908837,
        "gradient_norm": 0.38311243057250977,
        "train_loss": 3.0399274826049805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23835,
        "tokens": 12496404480,
        "learning_rate": 0.00012153442953195435,
        "gradient_norm": 0.3674798309803009,
        "train_loss": 2.9976348876953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23836,
        "tokens": 12496928768,
        "learning_rate": 0.00012151622610136007,
        "gradient_norm": 0.38290801644325256,
        "train_loss": 3.0616300106048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23837,
        "tokens": 12497453056,
        "learning_rate": 0.00012149802501751067,
        "gradient_norm": 0.42297011613845825,
        "train_loss": 3.067727565765381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23838,
        "tokens": 12497977344,
        "learning_rate": 0.00012147982628061077,
        "gradient_norm": 0.41734886169433594,
        "train_loss": 3.0771260261535645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23839,
        "tokens": 12498501632,
        "learning_rate": 0.00012146162989086548,
        "gradient_norm": 0.41677355766296387,
        "train_loss": 3.0250792503356934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23840,
        "tokens": 12499025920,
        "learning_rate": 0.0001214434358484794,
        "gradient_norm": 0.4244837760925293,
        "train_loss": 3.0435805320739746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23841,
        "tokens": 12499550208,
        "learning_rate": 0.00012142524415365748,
        "gradient_norm": 0.4295955300331116,
        "train_loss": 3.0627129077911377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23842,
        "tokens": 12500074496,
        "learning_rate": 0.00012140705480660438,
        "gradient_norm": 0.47201621532440186,
        "train_loss": 3.017455816268921,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23843,
        "tokens": 12500598784,
        "learning_rate": 0.00012138886780752497,
        "gradient_norm": 0.4111221134662628,
        "train_loss": 2.992051124572754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23844,
        "tokens": 12501123072,
        "learning_rate": 0.00012137068315662381,
        "gradient_norm": 0.4456397294998169,
        "train_loss": 3.10829496383667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23845,
        "tokens": 12501647360,
        "learning_rate": 0.00012135250085410568,
        "gradient_norm": 0.44824859499931335,
        "train_loss": 3.01131010055542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23846,
        "tokens": 12502171648,
        "learning_rate": 0.00012133432090017529,
        "gradient_norm": 0.4489659368991852,
        "train_loss": 3.0969583988189697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23847,
        "tokens": 12502695936,
        "learning_rate": 0.00012131614329503719,
        "gradient_norm": 0.4058423936367035,
        "train_loss": 2.995567798614502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23848,
        "tokens": 12503220224,
        "learning_rate": 0.00012129796803889606,
        "gradient_norm": 0.4407239258289337,
        "train_loss": 2.9895267486572266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23849,
        "tokens": 12503744512,
        "learning_rate": 0.0001212797951319564,
        "gradient_norm": 0.4372309148311615,
        "train_loss": 3.006847381591797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23850,
        "tokens": 12504268800,
        "learning_rate": 0.00012126162457442293,
        "gradient_norm": 0.4468782842159271,
        "train_loss": 3.0019450187683105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23851,
        "tokens": 12504793088,
        "learning_rate": 0.00012124345636649996,
        "gradient_norm": 0.4434906244277954,
        "train_loss": 3.0411040782928467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23852,
        "tokens": 12505317376,
        "learning_rate": 0.00012122529050839221,
        "gradient_norm": 0.46710464358329773,
        "train_loss": 3.012242078781128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23853,
        "tokens": 12505841664,
        "learning_rate": 0.00012120712700030394,
        "gradient_norm": 0.4552248418331146,
        "train_loss": 3.045769691467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23854,
        "tokens": 12506365952,
        "learning_rate": 0.00012118896584243978,
        "gradient_norm": 0.4331836402416229,
        "train_loss": 2.994788646697998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23855,
        "tokens": 12506890240,
        "learning_rate": 0.00012117080703500413,
        "gradient_norm": 0.46535027027130127,
        "train_loss": 3.0719234943389893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23856,
        "tokens": 12507414528,
        "learning_rate": 0.00012115265057820132,
        "gradient_norm": 0.39512792229652405,
        "train_loss": 3.003729820251465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23857,
        "tokens": 12507938816,
        "learning_rate": 0.00012113449647223581,
        "gradient_norm": 0.432915061712265,
        "train_loss": 3.054426908493042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23858,
        "tokens": 12508463104,
        "learning_rate": 0.00012111634471731183,
        "gradient_norm": 0.39333635568618774,
        "train_loss": 3.0290048122406006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23859,
        "tokens": 12508987392,
        "learning_rate": 0.00012109819531363385,
        "gradient_norm": 0.41124483942985535,
        "train_loss": 3.0291330814361572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23860,
        "tokens": 12509511680,
        "learning_rate": 0.000121080048261406,
        "gradient_norm": 0.39492976665496826,
        "train_loss": 2.9992618560791016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23861,
        "tokens": 12510035968,
        "learning_rate": 0.00012106190356083275,
        "gradient_norm": 0.43362411856651306,
        "train_loss": 3.1175146102905273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23862,
        "tokens": 12510560256,
        "learning_rate": 0.00012104376121211812,
        "gradient_norm": 0.4384039640426636,
        "train_loss": 3.0491092205047607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23863,
        "tokens": 12511084544,
        "learning_rate": 0.00012102562121546649,
        "gradient_norm": 0.38184258341789246,
        "train_loss": 3.007108211517334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23864,
        "tokens": 12511608832,
        "learning_rate": 0.0001210074835710819,
        "gradient_norm": 0.46708929538726807,
        "train_loss": 3.02182674407959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23865,
        "tokens": 12512133120,
        "learning_rate": 0.00012098934827916869,
        "gradient_norm": 0.40838173031806946,
        "train_loss": 3.0320425033569336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23866,
        "tokens": 12512657408,
        "learning_rate": 0.00012097121533993084,
        "gradient_norm": 0.42504626512527466,
        "train_loss": 3.0493767261505127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23867,
        "tokens": 12513181696,
        "learning_rate": 0.00012095308475357263,
        "gradient_norm": 0.438522607088089,
        "train_loss": 3.0540354251861572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23868,
        "tokens": 12513705984,
        "learning_rate": 0.0001209349565202979,
        "gradient_norm": 0.46223458647727966,
        "train_loss": 3.0129644870758057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23869,
        "tokens": 12514230272,
        "learning_rate": 0.00012091683064031092,
        "gradient_norm": 0.3919762670993805,
        "train_loss": 3.0414023399353027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23870,
        "tokens": 12514754560,
        "learning_rate": 0.0001208987071138156,
        "gradient_norm": 0.4116239845752716,
        "train_loss": 3.0270895957946777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23871,
        "tokens": 12515278848,
        "learning_rate": 0.00012088058594101604,
        "gradient_norm": 0.4307064414024353,
        "train_loss": 3.018423080444336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23872,
        "tokens": 12515803136,
        "learning_rate": 0.00012086246712211606,
        "gradient_norm": 0.4424862563610077,
        "train_loss": 3.131500720977783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23873,
        "tokens": 12516327424,
        "learning_rate": 0.00012084435065731983,
        "gradient_norm": 0.4804348945617676,
        "train_loss": 3.0554304122924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23874,
        "tokens": 12516851712,
        "learning_rate": 0.00012082623654683104,
        "gradient_norm": 0.4659242033958435,
        "train_loss": 3.010223150253296,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23875,
        "tokens": 12517376000,
        "learning_rate": 0.00012080812479085381,
        "gradient_norm": 0.4537739157676697,
        "train_loss": 3.044234037399292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23876,
        "tokens": 12517900288,
        "learning_rate": 0.0001207900153895918,
        "gradient_norm": 0.42574840784072876,
        "train_loss": 3.073354959487915,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23877,
        "tokens": 12518424576,
        "learning_rate": 0.00012077190834324905,
        "gradient_norm": 0.4669913053512573,
        "train_loss": 2.980377197265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23878,
        "tokens": 12518948864,
        "learning_rate": 0.00012075380365202918,
        "gradient_norm": 0.4496210217475891,
        "train_loss": 2.9816153049468994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23879,
        "tokens": 12519473152,
        "learning_rate": 0.00012073570131613618,
        "gradient_norm": 0.42992284893989563,
        "train_loss": 3.021143913269043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23880,
        "tokens": 12519997440,
        "learning_rate": 0.00012071760133577362,
        "gradient_norm": 0.4199308156967163,
        "train_loss": 3.011662483215332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23881,
        "tokens": 12520521728,
        "learning_rate": 0.00012069950371114543,
        "gradient_norm": 0.44741129875183105,
        "train_loss": 3.0425267219543457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23882,
        "tokens": 12521046016,
        "learning_rate": 0.00012068140844245512,
        "gradient_norm": 0.42705073952674866,
        "train_loss": 3.0756797790527344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23883,
        "tokens": 12521570304,
        "learning_rate": 0.00012066331552990657,
        "gradient_norm": 0.45406073331832886,
        "train_loss": 3.051908493041992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23884,
        "tokens": 12522094592,
        "learning_rate": 0.00012064522497370328,
        "gradient_norm": 0.3986760675907135,
        "train_loss": 3.0371599197387695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23885,
        "tokens": 12522618880,
        "learning_rate": 0.00012062713677404895,
        "gradient_norm": 0.41906577348709106,
        "train_loss": 3.0482430458068848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23886,
        "tokens": 12523143168,
        "learning_rate": 0.00012060905093114728,
        "gradient_norm": 0.4219261407852173,
        "train_loss": 2.9980340003967285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23887,
        "tokens": 12523667456,
        "learning_rate": 0.00012059096744520164,
        "gradient_norm": 0.4172040820121765,
        "train_loss": 2.9971609115600586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23888,
        "tokens": 12524191744,
        "learning_rate": 0.00012057288631641579,
        "gradient_norm": 0.4237063229084015,
        "train_loss": 3.033263683319092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23889,
        "tokens": 12524716032,
        "learning_rate": 0.00012055480754499309,
        "gradient_norm": 0.42987769842147827,
        "train_loss": 3.032499313354492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23890,
        "tokens": 12525240320,
        "learning_rate": 0.00012053673113113719,
        "gradient_norm": 0.4126602113246918,
        "train_loss": 2.9991207122802734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23891,
        "tokens": 12525764608,
        "learning_rate": 0.00012051865707505142,
        "gradient_norm": 0.3912801146507263,
        "train_loss": 3.0178489685058594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23892,
        "tokens": 12526288896,
        "learning_rate": 0.00012050058537693933,
        "gradient_norm": 0.48675644397735596,
        "train_loss": 3.1003897190093994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23893,
        "tokens": 12526813184,
        "learning_rate": 0.00012048251603700425,
        "gradient_norm": 0.4428565800189972,
        "train_loss": 3.0156469345092773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23894,
        "tokens": 12527337472,
        "learning_rate": 0.00012046444905544962,
        "gradient_norm": 0.474042147397995,
        "train_loss": 3.085587501525879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23895,
        "tokens": 12527861760,
        "learning_rate": 0.00012044638443247887,
        "gradient_norm": 0.44531315565109253,
        "train_loss": 2.992915630340576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23896,
        "tokens": 12528386048,
        "learning_rate": 0.00012042832216829521,
        "gradient_norm": 0.4676598310470581,
        "train_loss": 3.0489683151245117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23897,
        "tokens": 12528910336,
        "learning_rate": 0.0001204102622631021,
        "gradient_norm": 0.4648635685443878,
        "train_loss": 2.989821434020996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23898,
        "tokens": 12529434624,
        "learning_rate": 0.00012039220471710267,
        "gradient_norm": 0.42444178462028503,
        "train_loss": 3.0661892890930176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23899,
        "tokens": 12529958912,
        "learning_rate": 0.00012037414953050035,
        "gradient_norm": 0.436321496963501,
        "train_loss": 3.030467987060547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23900,
        "tokens": 12530483200,
        "learning_rate": 0.00012035609670349817,
        "gradient_norm": 0.4392029643058777,
        "train_loss": 3.0390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23901,
        "tokens": 12531007488,
        "learning_rate": 0.00012033804623629958,
        "gradient_norm": 0.38501179218292236,
        "train_loss": 3.0413713455200195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23902,
        "tokens": 12531531776,
        "learning_rate": 0.0001203199981291075,
        "gradient_norm": 0.44541260600090027,
        "train_loss": 3.071402072906494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23903,
        "tokens": 12532056064,
        "learning_rate": 0.00012030195238212532,
        "gradient_norm": 0.3964492976665497,
        "train_loss": 3.031153678894043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23904,
        "tokens": 12532580352,
        "learning_rate": 0.00012028390899555596,
        "gradient_norm": 0.4151129722595215,
        "train_loss": 3.0559840202331543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23905,
        "tokens": 12533104640,
        "learning_rate": 0.00012026586796960267,
        "gradient_norm": 0.42969653010368347,
        "train_loss": 3.060821771621704,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23906,
        "tokens": 12533628928,
        "learning_rate": 0.0001202478293044685,
        "gradient_norm": 0.46970218420028687,
        "train_loss": 3.128915309906006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23907,
        "tokens": 12534153216,
        "learning_rate": 0.00012022979300035645,
        "gradient_norm": 0.5011496543884277,
        "train_loss": 3.0060417652130127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23908,
        "tokens": 12534677504,
        "learning_rate": 0.0001202117590574696,
        "gradient_norm": 0.44805046916007996,
        "train_loss": 3.032620906829834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23909,
        "tokens": 12535201792,
        "learning_rate": 0.00012019372747601087,
        "gradient_norm": 0.46003851294517517,
        "train_loss": 2.9716427326202393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23910,
        "tokens": 12535726080,
        "learning_rate": 0.0001201756982561833,
        "gradient_norm": 0.4493180513381958,
        "train_loss": 3.03226900100708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23911,
        "tokens": 12536250368,
        "learning_rate": 0.00012015767139818975,
        "gradient_norm": 0.4601162075996399,
        "train_loss": 3.0206961631774902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23912,
        "tokens": 12536774656,
        "learning_rate": 0.00012013964690223326,
        "gradient_norm": 0.4446432888507843,
        "train_loss": 3.045750617980957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23913,
        "tokens": 12537298944,
        "learning_rate": 0.00012012162476851655,
        "gradient_norm": 0.47889798879623413,
        "train_loss": 3.0622854232788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23914,
        "tokens": 12537823232,
        "learning_rate": 0.00012010360499724258,
        "gradient_norm": 0.43165886402130127,
        "train_loss": 3.0640673637390137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23915,
        "tokens": 12538347520,
        "learning_rate": 0.00012008558758861427,
        "gradient_norm": 0.4589223861694336,
        "train_loss": 3.052773952484131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23916,
        "tokens": 12538871808,
        "learning_rate": 0.00012006757254283424,
        "gradient_norm": 0.4193025827407837,
        "train_loss": 3.055304527282715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23917,
        "tokens": 12539396096,
        "learning_rate": 0.00012004955986010546,
        "gradient_norm": 0.3841319680213928,
        "train_loss": 3.005953073501587,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23918,
        "tokens": 12539920384,
        "learning_rate": 0.00012003154954063052,
        "gradient_norm": 0.40848422050476074,
        "train_loss": 3.035646438598633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23919,
        "tokens": 12540444672,
        "learning_rate": 0.00012001354158461226,
        "gradient_norm": 0.41940614581108093,
        "train_loss": 3.022127866744995,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23920,
        "tokens": 12540968960,
        "learning_rate": 0.00011999553599225331,
        "gradient_norm": 0.37745535373687744,
        "train_loss": 3.065253734588623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23921,
        "tokens": 12541493248,
        "learning_rate": 0.00011997753276375643,
        "gradient_norm": 0.4177885353565216,
        "train_loss": 3.040295362472534,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23922,
        "tokens": 12542017536,
        "learning_rate": 0.00011995953189932417,
        "gradient_norm": 0.42697519063949585,
        "train_loss": 3.004037380218506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23923,
        "tokens": 12542541824,
        "learning_rate": 0.00011994153339915926,
        "gradient_norm": 0.44538912177085876,
        "train_loss": 3.06349778175354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23924,
        "tokens": 12543066112,
        "learning_rate": 0.00011992353726346416,
        "gradient_norm": 0.3771989941596985,
        "train_loss": 3.0407586097717285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23925,
        "tokens": 12543590400,
        "learning_rate": 0.00011990554349244155,
        "gradient_norm": 0.4539041817188263,
        "train_loss": 2.9952220916748047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23926,
        "tokens": 12544114688,
        "learning_rate": 0.00011988755208629396,
        "gradient_norm": 0.4263440668582916,
        "train_loss": 2.9772162437438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23927,
        "tokens": 12544638976,
        "learning_rate": 0.00011986956304522382,
        "gradient_norm": 0.4172135591506958,
        "train_loss": 3.027526378631592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23928,
        "tokens": 12545163264,
        "learning_rate": 0.00011985157636943378,
        "gradient_norm": 0.3521714508533478,
        "train_loss": 3.0705723762512207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23929,
        "tokens": 12545687552,
        "learning_rate": 0.00011983359205912611,
        "gradient_norm": 0.4045589566230774,
        "train_loss": 3.0306801795959473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23930,
        "tokens": 12546211840,
        "learning_rate": 0.00011981561011450341,
        "gradient_norm": 0.4210010766983032,
        "train_loss": 3.0672667026519775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23931,
        "tokens": 12546736128,
        "learning_rate": 0.00011979763053576796,
        "gradient_norm": 0.381224125623703,
        "train_loss": 3.0309743881225586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23932,
        "tokens": 12547260416,
        "learning_rate": 0.00011977965332312228,
        "gradient_norm": 0.4552198648452759,
        "train_loss": 3.009045124053955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23933,
        "tokens": 12547784704,
        "learning_rate": 0.00011976167847676858,
        "gradient_norm": 0.4293789863586426,
        "train_loss": 3.0930306911468506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23934,
        "tokens": 12548308992,
        "learning_rate": 0.00011974370599690923,
        "gradient_norm": 0.4135032594203949,
        "train_loss": 3.053891181945801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23935,
        "tokens": 12548833280,
        "learning_rate": 0.00011972573588374665,
        "gradient_norm": 0.4618135690689087,
        "train_loss": 3.013204574584961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23936,
        "tokens": 12549357568,
        "learning_rate": 0.00011970776813748297,
        "gradient_norm": 0.4269573390483856,
        "train_loss": 3.025847911834717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23937,
        "tokens": 12549881856,
        "learning_rate": 0.00011968980275832054,
        "gradient_norm": 0.4704049527645111,
        "train_loss": 3.039900302886963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23938,
        "tokens": 12550406144,
        "learning_rate": 0.00011967183974646148,
        "gradient_norm": 0.4122338891029358,
        "train_loss": 3.004092216491699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23939,
        "tokens": 12550930432,
        "learning_rate": 0.00011965387910210813,
        "gradient_norm": 0.46248859167099,
        "train_loss": 3.029661178588867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23940,
        "tokens": 12551454720,
        "learning_rate": 0.00011963592082546247,
        "gradient_norm": 0.4099079370498657,
        "train_loss": 3.020430088043213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23941,
        "tokens": 12551979008,
        "learning_rate": 0.00011961796491672686,
        "gradient_norm": 0.4078883230686188,
        "train_loss": 3.0365540981292725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23942,
        "tokens": 12552503296,
        "learning_rate": 0.00011960001137610319,
        "gradient_norm": 0.4365062713623047,
        "train_loss": 3.028430461883545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23943,
        "tokens": 12553027584,
        "learning_rate": 0.00011958206020379377,
        "gradient_norm": 0.4982988238334656,
        "train_loss": 3.063539981842041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23944,
        "tokens": 12553551872,
        "learning_rate": 0.00011956411140000047,
        "gradient_norm": 0.46402254700660706,
        "train_loss": 2.9914984703063965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23945,
        "tokens": 12554076160,
        "learning_rate": 0.00011954616496492537,
        "gradient_norm": 0.5550825595855713,
        "train_loss": 3.0481741428375244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23946,
        "tokens": 12554600448,
        "learning_rate": 0.00011952822089877064,
        "gradient_norm": 0.41644611954689026,
        "train_loss": 3.029198169708252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23947,
        "tokens": 12555124736,
        "learning_rate": 0.00011951027920173806,
        "gradient_norm": 0.44494393467903137,
        "train_loss": 2.995241165161133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23948,
        "tokens": 12555649024,
        "learning_rate": 0.00011949233987402976,
        "gradient_norm": 0.4500349164009094,
        "train_loss": 3.0228705406188965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23949,
        "tokens": 12556173312,
        "learning_rate": 0.00011947440291584747,
        "gradient_norm": 0.4461424648761749,
        "train_loss": 3.028820276260376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23950,
        "tokens": 12556697600,
        "learning_rate": 0.00011945646832739332,
        "gradient_norm": 0.45892566442489624,
        "train_loss": 3.02608585357666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23951,
        "tokens": 12557221888,
        "learning_rate": 0.00011943853610886894,
        "gradient_norm": 0.41911256313323975,
        "train_loss": 3.040473699569702,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23952,
        "tokens": 12557746176,
        "learning_rate": 0.00011942060626047644,
        "gradient_norm": 0.4271571934223175,
        "train_loss": 2.99924635887146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23953,
        "tokens": 12558270464,
        "learning_rate": 0.00011940267878241739,
        "gradient_norm": 0.44619497656822205,
        "train_loss": 3.0017900466918945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23954,
        "tokens": 12558794752,
        "learning_rate": 0.00011938475367489373,
        "gradient_norm": 0.3845466673374176,
        "train_loss": 2.9941229820251465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23955,
        "tokens": 12559319040,
        "learning_rate": 0.00011936683093810726,
        "gradient_norm": 0.4451116919517517,
        "train_loss": 2.9984445571899414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23956,
        "tokens": 12559843328,
        "learning_rate": 0.00011934891057225963,
        "gradient_norm": 0.37951529026031494,
        "train_loss": 2.9831581115722656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23957,
        "tokens": 12560367616,
        "learning_rate": 0.00011933099257755266,
        "gradient_norm": 0.3850104510784149,
        "train_loss": 2.983170986175537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23958,
        "tokens": 12560891904,
        "learning_rate": 0.00011931307695418788,
        "gradient_norm": 0.42034828662872314,
        "train_loss": 3.080420970916748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23959,
        "tokens": 12561416192,
        "learning_rate": 0.00011929516370236712,
        "gradient_norm": 0.4111557900905609,
        "train_loss": 3.014155387878418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23960,
        "tokens": 12561940480,
        "learning_rate": 0.00011927725282229187,
        "gradient_norm": 0.5055918097496033,
        "train_loss": 3.0797717571258545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23961,
        "tokens": 12562464768,
        "learning_rate": 0.00011925934431416391,
        "gradient_norm": 0.45243868231773376,
        "train_loss": 3.016411781311035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23962,
        "tokens": 12562989056,
        "learning_rate": 0.00011924143817818462,
        "gradient_norm": 0.5097125172615051,
        "train_loss": 3.0400474071502686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23963,
        "tokens": 12563513344,
        "learning_rate": 0.00011922353441455577,
        "gradient_norm": 0.4695238471031189,
        "train_loss": 2.992288112640381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23964,
        "tokens": 12564037632,
        "learning_rate": 0.00011920563302347868,
        "gradient_norm": 0.41232141852378845,
        "train_loss": 3.074801206588745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23965,
        "tokens": 12564561920,
        "learning_rate": 0.00011918773400515503,
        "gradient_norm": 0.4593169093132019,
        "train_loss": 3.047135353088379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23966,
        "tokens": 12565086208,
        "learning_rate": 0.00011916983735978616,
        "gradient_norm": 0.41640669107437134,
        "train_loss": 3.0144033432006836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23967,
        "tokens": 12565610496,
        "learning_rate": 0.00011915194308757362,
        "gradient_norm": 0.45095884799957275,
        "train_loss": 3.030533790588379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23968,
        "tokens": 12566134784,
        "learning_rate": 0.00011913405118871875,
        "gradient_norm": 0.40434518456459045,
        "train_loss": 3.0129265785217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23969,
        "tokens": 12566659072,
        "learning_rate": 0.00011911616166342303,
        "gradient_norm": 0.45544418692588806,
        "train_loss": 3.090810775756836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23970,
        "tokens": 12567183360,
        "learning_rate": 0.00011909827451188774,
        "gradient_norm": 0.4360532760620117,
        "train_loss": 2.977470874786377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23971,
        "tokens": 12567707648,
        "learning_rate": 0.00011908038973431424,
        "gradient_norm": 0.4433487355709076,
        "train_loss": 3.065333366394043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23972,
        "tokens": 12568231936,
        "learning_rate": 0.00011906250733090395,
        "gradient_norm": 0.4192359149456024,
        "train_loss": 3.0378599166870117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23973,
        "tokens": 12568756224,
        "learning_rate": 0.00011904462730185804,
        "gradient_norm": 0.42308029532432556,
        "train_loss": 3.062084197998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23974,
        "tokens": 12569280512,
        "learning_rate": 0.00011902674964737783,
        "gradient_norm": 0.4024142324924469,
        "train_loss": 3.1133947372436523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23975,
        "tokens": 12569804800,
        "learning_rate": 0.00011900887436766452,
        "gradient_norm": 0.41936245560646057,
        "train_loss": 2.9966020584106445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23976,
        "tokens": 12570329088,
        "learning_rate": 0.00011899100146291936,
        "gradient_norm": 0.4094914197921753,
        "train_loss": 2.992809295654297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23977,
        "tokens": 12570853376,
        "learning_rate": 0.00011897313093334347,
        "gradient_norm": 0.4348491430282593,
        "train_loss": 2.998037576675415,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23978,
        "tokens": 12571377664,
        "learning_rate": 0.0001189552627791381,
        "gradient_norm": 0.45448431372642517,
        "train_loss": 3.004383087158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23979,
        "tokens": 12571901952,
        "learning_rate": 0.00011893739700050425,
        "gradient_norm": 0.46409106254577637,
        "train_loss": 3.0537452697753906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23980,
        "tokens": 12572426240,
        "learning_rate": 0.00011891953359764317,
        "gradient_norm": 0.4770581126213074,
        "train_loss": 3.084730863571167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23981,
        "tokens": 12572950528,
        "learning_rate": 0.00011890167257075577,
        "gradient_norm": 0.5021387338638306,
        "train_loss": 3.073514223098755,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23982,
        "tokens": 12573474816,
        "learning_rate": 0.00011888381392004328,
        "gradient_norm": 0.39791226387023926,
        "train_loss": 2.980497360229492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23983,
        "tokens": 12573999104,
        "learning_rate": 0.00011886595764570656,
        "gradient_norm": 0.44458338618278503,
        "train_loss": 2.9540677070617676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23984,
        "tokens": 12574523392,
        "learning_rate": 0.00011884810374794673,
        "gradient_norm": 0.48091253638267517,
        "train_loss": 3.019169569015503,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23985,
        "tokens": 12575047680,
        "learning_rate": 0.00011883025222696463,
        "gradient_norm": 0.40159931778907776,
        "train_loss": 3.074625015258789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23986,
        "tokens": 12575571968,
        "learning_rate": 0.00011881240308296134,
        "gradient_norm": 0.5092361569404602,
        "train_loss": 2.9933111667633057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23987,
        "tokens": 12576096256,
        "learning_rate": 0.00011879455631613763,
        "gradient_norm": 0.41205814480781555,
        "train_loss": 2.9641435146331787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23988,
        "tokens": 12576620544,
        "learning_rate": 0.00011877671192669453,
        "gradient_norm": 0.5195598602294922,
        "train_loss": 3.04587459564209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23989,
        "tokens": 12577144832,
        "learning_rate": 0.0001187588699148328,
        "gradient_norm": 0.4810566008090973,
        "train_loss": 3.0674688816070557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23990,
        "tokens": 12577669120,
        "learning_rate": 0.00011874103028075335,
        "gradient_norm": 0.40649840235710144,
        "train_loss": 3.0311989784240723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23991,
        "tokens": 12578193408,
        "learning_rate": 0.00011872319302465687,
        "gradient_norm": 0.4526185393333435,
        "train_loss": 3.0300869941711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23992,
        "tokens": 12578717696,
        "learning_rate": 0.0001187053581467443,
        "gradient_norm": 0.455837219953537,
        "train_loss": 3.062056541442871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23993,
        "tokens": 12579241984,
        "learning_rate": 0.00011868752564721624,
        "gradient_norm": 0.41949111223220825,
        "train_loss": 3.0154945850372314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23994,
        "tokens": 12579766272,
        "learning_rate": 0.00011866969552627348,
        "gradient_norm": 0.4792507588863373,
        "train_loss": 2.9815640449523926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23995,
        "tokens": 12580290560,
        "learning_rate": 0.00011865186778411678,
        "gradient_norm": 0.44108372926712036,
        "train_loss": 3.0439507961273193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23996,
        "tokens": 12580814848,
        "learning_rate": 0.0001186340424209467,
        "gradient_norm": 0.39283478260040283,
        "train_loss": 3.0402777194976807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23997,
        "tokens": 12581339136,
        "learning_rate": 0.00011861621943696405,
        "gradient_norm": 0.4311491549015045,
        "train_loss": 3.0120558738708496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23998,
        "tokens": 12581863424,
        "learning_rate": 0.00011859839883236924,
        "gradient_norm": 0.3890804350376129,
        "train_loss": 3.022186279296875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 23999,
        "tokens": 12582387712,
        "learning_rate": 0.00011858058060736306,
        "gradient_norm": 0.48800235986709595,
        "train_loss": 3.0655875205993652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24000,
        "tokens": 12582912000,
        "learning_rate": 0.0001185627647621459,
        "gradient_norm": 0.4417583644390106,
        "train_loss": 3.1227705478668213,
        "val_loss": 2.9868860244750977,
        "hellaswag_acc": 0.2850029766559601,
        "hellaswag_acc_norm": 0.2976498603820801
    },
    {
        "step": 24001,
        "tokens": 12583436288,
        "learning_rate": 0.00011854495129691846,
        "gradient_norm": 0.4885536730289459,
        "train_loss": 3.111086368560791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24002,
        "tokens": 12583960576,
        "learning_rate": 0.00011852714021188113,
        "gradient_norm": 0.5422635674476624,
        "train_loss": 3.0777621269226074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24003,
        "tokens": 12584484864,
        "learning_rate": 0.00011850933150723444,
        "gradient_norm": 0.48503756523132324,
        "train_loss": 3.043487548828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24004,
        "tokens": 12585009152,
        "learning_rate": 0.0001184915251831789,
        "gradient_norm": 0.5454264283180237,
        "train_loss": 3.052860975265503,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24005,
        "tokens": 12585533440,
        "learning_rate": 0.00011847372123991481,
        "gradient_norm": 0.4394683241844177,
        "train_loss": 2.981626510620117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24006,
        "tokens": 12586057728,
        "learning_rate": 0.00011845591967764277,
        "gradient_norm": 0.5282676219940186,
        "train_loss": 2.9615869522094727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24007,
        "tokens": 12586582016,
        "learning_rate": 0.00011843812049656296,
        "gradient_norm": 0.42880985140800476,
        "train_loss": 3.0570218563079834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24008,
        "tokens": 12587106304,
        "learning_rate": 0.00011842032369687591,
        "gradient_norm": 0.49213147163391113,
        "train_loss": 3.0044922828674316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24009,
        "tokens": 12587630592,
        "learning_rate": 0.00011840252927878181,
        "gradient_norm": 0.46218445897102356,
        "train_loss": 2.9810643196105957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24010,
        "tokens": 12588154880,
        "learning_rate": 0.00011838473724248104,
        "gradient_norm": 0.5039126873016357,
        "train_loss": 3.0362086296081543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24011,
        "tokens": 12588679168,
        "learning_rate": 0.00011836694758817376,
        "gradient_norm": 0.43167030811309814,
        "train_loss": 2.980905771255493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24012,
        "tokens": 12589203456,
        "learning_rate": 0.00011834916031606041,
        "gradient_norm": 0.46306538581848145,
        "train_loss": 3.007138729095459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24013,
        "tokens": 12589727744,
        "learning_rate": 0.00011833137542634098,
        "gradient_norm": 0.43833163380622864,
        "train_loss": 3.0331568717956543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24014,
        "tokens": 12590252032,
        "learning_rate": 0.00011831359291921578,
        "gradient_norm": 0.4036407172679901,
        "train_loss": 3.0031776428222656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24015,
        "tokens": 12590776320,
        "learning_rate": 0.00011829581279488502,
        "gradient_norm": 0.4009801149368286,
        "train_loss": 3.0585203170776367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24016,
        "tokens": 12591300608,
        "learning_rate": 0.00011827803505354874,
        "gradient_norm": 0.3789197504520416,
        "train_loss": 2.937884569168091,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24017,
        "tokens": 12591824896,
        "learning_rate": 0.00011826025969540713,
        "gradient_norm": 0.4007197916507721,
        "train_loss": 2.9490232467651367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24018,
        "tokens": 12592349184,
        "learning_rate": 0.0001182424867206602,
        "gradient_norm": 0.39612963795661926,
        "train_loss": 3.0145208835601807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24019,
        "tokens": 12592873472,
        "learning_rate": 0.00011822471612950812,
        "gradient_norm": 0.39328327775001526,
        "train_loss": 2.966935873031616,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24020,
        "tokens": 12593397760,
        "learning_rate": 0.00011820694792215074,
        "gradient_norm": 0.38982221484184265,
        "train_loss": 2.968658924102783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24021,
        "tokens": 12593922048,
        "learning_rate": 0.00011818918209878825,
        "gradient_norm": 0.3901801109313965,
        "train_loss": 3.0199618339538574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24022,
        "tokens": 12594446336,
        "learning_rate": 0.00011817141865962048,
        "gradient_norm": 0.40404433012008667,
        "train_loss": 2.9932966232299805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24023,
        "tokens": 12594970624,
        "learning_rate": 0.00011815365760484744,
        "gradient_norm": 0.4041747450828552,
        "train_loss": 3.025113344192505,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24024,
        "tokens": 12595494912,
        "learning_rate": 0.00011813589893466915,
        "gradient_norm": 0.37766122817993164,
        "train_loss": 2.963878870010376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24025,
        "tokens": 12596019200,
        "learning_rate": 0.00011811814264928534,
        "gradient_norm": 0.42122146487236023,
        "train_loss": 3.085261344909668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24026,
        "tokens": 12596543488,
        "learning_rate": 0.00011810038874889599,
        "gradient_norm": 0.4174146354198456,
        "train_loss": 2.986499547958374,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24027,
        "tokens": 12597067776,
        "learning_rate": 0.00011808263723370088,
        "gradient_norm": 0.45092955231666565,
        "train_loss": 3.1111624240875244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24028,
        "tokens": 12597592064,
        "learning_rate": 0.00011806488810389987,
        "gradient_norm": 0.39559218287467957,
        "train_loss": 3.0080726146698,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24029,
        "tokens": 12598116352,
        "learning_rate": 0.00011804714135969267,
        "gradient_norm": 0.47446882724761963,
        "train_loss": 3.0524449348449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24030,
        "tokens": 12598640640,
        "learning_rate": 0.0001180293970012792,
        "gradient_norm": 0.427312433719635,
        "train_loss": 3.0274393558502197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24031,
        "tokens": 12599164928,
        "learning_rate": 0.00011801165502885901,
        "gradient_norm": 0.44928887486457825,
        "train_loss": 2.999019145965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24032,
        "tokens": 12599689216,
        "learning_rate": 0.00011799391544263194,
        "gradient_norm": 0.427117258310318,
        "train_loss": 3.004354953765869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24033,
        "tokens": 12600213504,
        "learning_rate": 0.00011797617824279758,
        "gradient_norm": 0.46818938851356506,
        "train_loss": 3.0052831172943115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24034,
        "tokens": 12600737792,
        "learning_rate": 0.00011795844342955565,
        "gradient_norm": 0.4078459143638611,
        "train_loss": 2.9737701416015625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24035,
        "tokens": 12601262080,
        "learning_rate": 0.00011794071100310578,
        "gradient_norm": 0.4702799916267395,
        "train_loss": 2.9765701293945312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24036,
        "tokens": 12601786368,
        "learning_rate": 0.00011792298096364748,
        "gradient_norm": 0.40670448541641235,
        "train_loss": 3.035642385482788,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24037,
        "tokens": 12602310656,
        "learning_rate": 0.00011790525331138047,
        "gradient_norm": 0.4224139451980591,
        "train_loss": 2.9896020889282227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24038,
        "tokens": 12602834944,
        "learning_rate": 0.00011788752804650418,
        "gradient_norm": 0.4213300943374634,
        "train_loss": 2.9969258308410645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24039,
        "tokens": 12603359232,
        "learning_rate": 0.0001178698051692182,
        "gradient_norm": 0.3834342062473297,
        "train_loss": 2.9646029472351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24040,
        "tokens": 12603883520,
        "learning_rate": 0.00011785208467972193,
        "gradient_norm": 0.42882040143013,
        "train_loss": 2.974398612976074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24041,
        "tokens": 12604407808,
        "learning_rate": 0.00011783436657821495,
        "gradient_norm": 0.39969635009765625,
        "train_loss": 2.9898643493652344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24042,
        "tokens": 12604932096,
        "learning_rate": 0.00011781665086489659,
        "gradient_norm": 0.3962135314941406,
        "train_loss": 2.9932363033294678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24043,
        "tokens": 12605456384,
        "learning_rate": 0.00011779893753996633,
        "gradient_norm": 0.42142048478126526,
        "train_loss": 2.9761626720428467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24044,
        "tokens": 12605980672,
        "learning_rate": 0.00011778122660362358,
        "gradient_norm": 0.3749290108680725,
        "train_loss": 3.0030860900878906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24045,
        "tokens": 12606504960,
        "learning_rate": 0.00011776351805606764,
        "gradient_norm": 0.4047829210758209,
        "train_loss": 3.0069305896759033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24046,
        "tokens": 12607029248,
        "learning_rate": 0.00011774581189749789,
        "gradient_norm": 0.39151087403297424,
        "train_loss": 2.9997432231903076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24047,
        "tokens": 12607553536,
        "learning_rate": 0.00011772810812811355,
        "gradient_norm": 0.45630502700805664,
        "train_loss": 3.050198554992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24048,
        "tokens": 12608077824,
        "learning_rate": 0.00011771040674811404,
        "gradient_norm": 0.4256581962108612,
        "train_loss": 3.0485928058624268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24049,
        "tokens": 12608602112,
        "learning_rate": 0.00011769270775769845,
        "gradient_norm": 0.45526835322380066,
        "train_loss": 3.007503032684326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24050,
        "tokens": 12609126400,
        "learning_rate": 0.00011767501115706616,
        "gradient_norm": 0.41243812441825867,
        "train_loss": 3.0338709354400635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24051,
        "tokens": 12609650688,
        "learning_rate": 0.00011765731694641623,
        "gradient_norm": 0.4284572899341583,
        "train_loss": 3.0708844661712646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24052,
        "tokens": 12610174976,
        "learning_rate": 0.00011763962512594792,
        "gradient_norm": 0.43654337525367737,
        "train_loss": 2.991057872772217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24053,
        "tokens": 12610699264,
        "learning_rate": 0.00011762193569586032,
        "gradient_norm": 0.4446530044078827,
        "train_loss": 3.0426950454711914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24054,
        "tokens": 12611223552,
        "learning_rate": 0.00011760424865635253,
        "gradient_norm": 0.4401684105396271,
        "train_loss": 3.0113489627838135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24055,
        "tokens": 12611747840,
        "learning_rate": 0.00011758656400762379,
        "gradient_norm": 0.42390790581703186,
        "train_loss": 3.0386734008789062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24056,
        "tokens": 12612272128,
        "learning_rate": 0.00011756888174987296,
        "gradient_norm": 0.42457860708236694,
        "train_loss": 2.969104766845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24057,
        "tokens": 12612796416,
        "learning_rate": 0.00011755120188329922,
        "gradient_norm": 0.4019920527935028,
        "train_loss": 3.0318751335144043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24058,
        "tokens": 12613320704,
        "learning_rate": 0.00011753352440810146,
        "gradient_norm": 0.4014948308467865,
        "train_loss": 3.0216336250305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24059,
        "tokens": 12613844992,
        "learning_rate": 0.00011751584932447883,
        "gradient_norm": 0.4234206974506378,
        "train_loss": 2.9932122230529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24060,
        "tokens": 12614369280,
        "learning_rate": 0.0001174981766326301,
        "gradient_norm": 0.3931937515735626,
        "train_loss": 2.980398654937744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24061,
        "tokens": 12614893568,
        "learning_rate": 0.00011748050633275435,
        "gradient_norm": 0.48481476306915283,
        "train_loss": 3.0022542476654053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24062,
        "tokens": 12615417856,
        "learning_rate": 0.00011746283842505033,
        "gradient_norm": 0.4095211327075958,
        "train_loss": 3.0270910263061523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24063,
        "tokens": 12615942144,
        "learning_rate": 0.000117445172909717,
        "gradient_norm": 0.41927507519721985,
        "train_loss": 3.0527262687683105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24064,
        "tokens": 12616466432,
        "learning_rate": 0.0001174275097869533,
        "gradient_norm": 0.4213058054447174,
        "train_loss": 3.0042307376861572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24065,
        "tokens": 12616990720,
        "learning_rate": 0.00011740984905695787,
        "gradient_norm": 0.39407411217689514,
        "train_loss": 2.981616497039795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24066,
        "tokens": 12617515008,
        "learning_rate": 0.00011739219071992967,
        "gradient_norm": 0.41737979650497437,
        "train_loss": 2.9777393341064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24067,
        "tokens": 12618039296,
        "learning_rate": 0.00011737453477606732,
        "gradient_norm": 0.422029972076416,
        "train_loss": 3.032317638397217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24068,
        "tokens": 12618563584,
        "learning_rate": 0.0001173568812255697,
        "gradient_norm": 0.43445247411727905,
        "train_loss": 3.044431209564209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24069,
        "tokens": 12619087872,
        "learning_rate": 0.00011733923006863534,
        "gradient_norm": 0.40428659319877625,
        "train_loss": 3.06174373626709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24070,
        "tokens": 12619612160,
        "learning_rate": 0.00011732158130546314,
        "gradient_norm": 0.40720152854919434,
        "train_loss": 2.9768528938293457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24071,
        "tokens": 12620136448,
        "learning_rate": 0.00011730393493625154,
        "gradient_norm": 0.442259281873703,
        "train_loss": 3.010996103286743,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24072,
        "tokens": 12620660736,
        "learning_rate": 0.00011728629096119942,
        "gradient_norm": 0.3855869770050049,
        "train_loss": 3.0874924659729004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24073,
        "tokens": 12621185024,
        "learning_rate": 0.00011726864938050511,
        "gradient_norm": 0.4301685094833374,
        "train_loss": 3.002042770385742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24074,
        "tokens": 12621709312,
        "learning_rate": 0.00011725101019436744,
        "gradient_norm": 0.413695752620697,
        "train_loss": 3.0811171531677246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24075,
        "tokens": 12622233600,
        "learning_rate": 0.00011723337340298478,
        "gradient_norm": 0.4010787010192871,
        "train_loss": 2.9587063789367676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24076,
        "tokens": 12622757888,
        "learning_rate": 0.00011721573900655577,
        "gradient_norm": 0.40781912207603455,
        "train_loss": 2.9874114990234375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24077,
        "tokens": 12623282176,
        "learning_rate": 0.00011719810700527882,
        "gradient_norm": 0.3899928629398346,
        "train_loss": 2.935213088989258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24078,
        "tokens": 12623806464,
        "learning_rate": 0.00011718047739935248,
        "gradient_norm": 0.48268723487854004,
        "train_loss": 3.0179762840270996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24079,
        "tokens": 12624330752,
        "learning_rate": 0.00011716285018897512,
        "gradient_norm": 0.37599268555641174,
        "train_loss": 3.000819206237793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24080,
        "tokens": 12624855040,
        "learning_rate": 0.00011714522537434522,
        "gradient_norm": 0.45372846722602844,
        "train_loss": 3.0282812118530273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24081,
        "tokens": 12625379328,
        "learning_rate": 0.00011712760295566109,
        "gradient_norm": 0.4748457968235016,
        "train_loss": 3.031520366668701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24082,
        "tokens": 12625903616,
        "learning_rate": 0.00011710998293312121,
        "gradient_norm": 0.48880496621131897,
        "train_loss": 2.9930989742279053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24083,
        "tokens": 12626427904,
        "learning_rate": 0.00011709236530692377,
        "gradient_norm": 0.38869789242744446,
        "train_loss": 2.9983856678009033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24084,
        "tokens": 12626952192,
        "learning_rate": 0.00011707475007726725,
        "gradient_norm": 0.452228844165802,
        "train_loss": 3.051971435546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24085,
        "tokens": 12627476480,
        "learning_rate": 0.00011705713724434973,
        "gradient_norm": 0.4300420880317688,
        "train_loss": 3.0431594848632812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24086,
        "tokens": 12628000768,
        "learning_rate": 0.00011703952680836965,
        "gradient_norm": 0.3983954191207886,
        "train_loss": 3.0151896476745605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24087,
        "tokens": 12628525056,
        "learning_rate": 0.00011702191876952509,
        "gradient_norm": 0.48307496309280396,
        "train_loss": 3.008528470993042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24088,
        "tokens": 12629049344,
        "learning_rate": 0.00011700431312801441,
        "gradient_norm": 0.3927132189273834,
        "train_loss": 2.9609835147857666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24089,
        "tokens": 12629573632,
        "learning_rate": 0.00011698670988403558,
        "gradient_norm": 0.41782185435295105,
        "train_loss": 2.9947195053100586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24090,
        "tokens": 12630097920,
        "learning_rate": 0.00011696910903778696,
        "gradient_norm": 0.4322979748249054,
        "train_loss": 3.014662742614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24091,
        "tokens": 12630622208,
        "learning_rate": 0.0001169515105894665,
        "gradient_norm": 0.4302922785282135,
        "train_loss": 2.997793197631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24092,
        "tokens": 12631146496,
        "learning_rate": 0.00011693391453927241,
        "gradient_norm": 0.3899489939212799,
        "train_loss": 3.0070321559906006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24093,
        "tokens": 12631670784,
        "learning_rate": 0.00011691632088740264,
        "gradient_norm": 0.5032984614372253,
        "train_loss": 3.00590181350708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24094,
        "tokens": 12632195072,
        "learning_rate": 0.00011689872963405531,
        "gradient_norm": 0.4065847098827362,
        "train_loss": 2.96195125579834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24095,
        "tokens": 12632719360,
        "learning_rate": 0.00011688114077942849,
        "gradient_norm": 0.4330390393733978,
        "train_loss": 2.997284173965454,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24096,
        "tokens": 12633243648,
        "learning_rate": 0.00011686355432371999,
        "gradient_norm": 0.4882794916629791,
        "train_loss": 2.963705539703369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24097,
        "tokens": 12633767936,
        "learning_rate": 0.00011684597026712796,
        "gradient_norm": 0.4264872670173645,
        "train_loss": 2.9731805324554443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24098,
        "tokens": 12634292224,
        "learning_rate": 0.00011682838860985014,
        "gradient_norm": 0.4090825915336609,
        "train_loss": 3.0202860832214355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24099,
        "tokens": 12634816512,
        "learning_rate": 0.00011681080935208463,
        "gradient_norm": 0.4530242383480072,
        "train_loss": 2.9653000831604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24100,
        "tokens": 12635340800,
        "learning_rate": 0.00011679323249402915,
        "gradient_norm": 0.4113099277019501,
        "train_loss": 3.005352020263672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24101,
        "tokens": 12635865088,
        "learning_rate": 0.00011677565803588165,
        "gradient_norm": 0.453961044549942,
        "train_loss": 3.0504250526428223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24102,
        "tokens": 12636389376,
        "learning_rate": 0.00011675808597783985,
        "gradient_norm": 0.40377917885780334,
        "train_loss": 2.998490810394287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24103,
        "tokens": 12636913664,
        "learning_rate": 0.00011674051632010159,
        "gradient_norm": 0.4608132839202881,
        "train_loss": 3.0273094177246094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24104,
        "tokens": 12637437952,
        "learning_rate": 0.00011672294906286474,
        "gradient_norm": 0.43047598004341125,
        "train_loss": 3.013164520263672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24105,
        "tokens": 12637962240,
        "learning_rate": 0.00011670538420632687,
        "gradient_norm": 0.49136510491371155,
        "train_loss": 3.0463755130767822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24106,
        "tokens": 12638486528,
        "learning_rate": 0.00011668782175068589,
        "gradient_norm": 0.46013811230659485,
        "train_loss": 3.010071277618408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24107,
        "tokens": 12639010816,
        "learning_rate": 0.00011667026169613927,
        "gradient_norm": 0.4839838147163391,
        "train_loss": 3.02901554107666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24108,
        "tokens": 12639535104,
        "learning_rate": 0.00011665270404288486,
        "gradient_norm": 0.4688538908958435,
        "train_loss": 3.007936954498291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24109,
        "tokens": 12640059392,
        "learning_rate": 0.00011663514879112013,
        "gradient_norm": 0.4625661075115204,
        "train_loss": 2.976830005645752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24110,
        "tokens": 12640583680,
        "learning_rate": 0.00011661759594104284,
        "gradient_norm": 0.43007153272628784,
        "train_loss": 3.007758140563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24111,
        "tokens": 12641107968,
        "learning_rate": 0.00011660004549285044,
        "gradient_norm": 0.43351197242736816,
        "train_loss": 3.021193504333496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24112,
        "tokens": 12641632256,
        "learning_rate": 0.0001165824974467406,
        "gradient_norm": 0.49973300099372864,
        "train_loss": 3.010986328125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24113,
        "tokens": 12642156544,
        "learning_rate": 0.00011656495180291069,
        "gradient_norm": 0.3999587297439575,
        "train_loss": 3.0089287757873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24114,
        "tokens": 12642680832,
        "learning_rate": 0.00011654740856155832,
        "gradient_norm": 0.5240228176116943,
        "train_loss": 3.014963150024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24115,
        "tokens": 12643205120,
        "learning_rate": 0.00011652986772288102,
        "gradient_norm": 0.41511860489845276,
        "train_loss": 2.9944581985473633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24116,
        "tokens": 12643729408,
        "learning_rate": 0.00011651232928707608,
        "gradient_norm": 0.48601841926574707,
        "train_loss": 2.986055374145508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24117,
        "tokens": 12644253696,
        "learning_rate": 0.00011649479325434107,
        "gradient_norm": 0.42438018321990967,
        "train_loss": 3.0117831230163574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24118,
        "tokens": 12644777984,
        "learning_rate": 0.00011647725962487323,
        "gradient_norm": 0.412700891494751,
        "train_loss": 3.0018887519836426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24119,
        "tokens": 12645302272,
        "learning_rate": 0.00011645972839887005,
        "gradient_norm": 0.40886199474334717,
        "train_loss": 3.030576229095459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24120,
        "tokens": 12645826560,
        "learning_rate": 0.00011644219957652877,
        "gradient_norm": 0.4113805294036865,
        "train_loss": 3.0007829666137695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24121,
        "tokens": 12646350848,
        "learning_rate": 0.00011642467315804678,
        "gradient_norm": 0.5104044675827026,
        "train_loss": 2.9938549995422363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24122,
        "tokens": 12646875136,
        "learning_rate": 0.00011640714914362128,
        "gradient_norm": 0.38885438442230225,
        "train_loss": 2.979546070098877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24123,
        "tokens": 12647399424,
        "learning_rate": 0.00011638962753344952,
        "gradient_norm": 0.4783766269683838,
        "train_loss": 3.030705690383911,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24124,
        "tokens": 12647923712,
        "learning_rate": 0.00011637210832772891,
        "gradient_norm": 0.4642684757709503,
        "train_loss": 3.058856964111328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24125,
        "tokens": 12648448000,
        "learning_rate": 0.0001163545915266564,
        "gradient_norm": 0.5501773953437805,
        "train_loss": 3.086047649383545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24126,
        "tokens": 12648972288,
        "learning_rate": 0.00011633707713042937,
        "gradient_norm": 0.49539390206336975,
        "train_loss": 3.0158543586730957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24127,
        "tokens": 12649496576,
        "learning_rate": 0.00011631956513924478,
        "gradient_norm": 0.49807584285736084,
        "train_loss": 2.8938369750976562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24128,
        "tokens": 12650020864,
        "learning_rate": 0.00011630205555329996,
        "gradient_norm": 0.4800157845020294,
        "train_loss": 3.0426101684570312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24129,
        "tokens": 12650545152,
        "learning_rate": 0.00011628454837279176,
        "gradient_norm": 0.43505990505218506,
        "train_loss": 3.0108654499053955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24130,
        "tokens": 12651069440,
        "learning_rate": 0.00011626704359791746,
        "gradient_norm": 0.43922194838523865,
        "train_loss": 3.0499773025512695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24131,
        "tokens": 12651593728,
        "learning_rate": 0.00011624954122887396,
        "gradient_norm": 0.4307335913181305,
        "train_loss": 2.9887123107910156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24132,
        "tokens": 12652118016,
        "learning_rate": 0.00011623204126585839,
        "gradient_norm": 0.4053960144519806,
        "train_loss": 2.953322410583496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24133,
        "tokens": 12652642304,
        "learning_rate": 0.00011621454370906755,
        "gradient_norm": 0.42476698756217957,
        "train_loss": 2.9809017181396484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24134,
        "tokens": 12653166592,
        "learning_rate": 0.00011619704855869858,
        "gradient_norm": 0.46107205748558044,
        "train_loss": 3.0208749771118164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24135,
        "tokens": 12653690880,
        "learning_rate": 0.00011617955581494837,
        "gradient_norm": 0.4426592290401459,
        "train_loss": 3.024125576019287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24136,
        "tokens": 12654215168,
        "learning_rate": 0.00011616206547801371,
        "gradient_norm": 0.4519636631011963,
        "train_loss": 2.992849349975586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24137,
        "tokens": 12654739456,
        "learning_rate": 0.00011614457754809166,
        "gradient_norm": 0.4063485264778137,
        "train_loss": 3.020419120788574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24138,
        "tokens": 12655263744,
        "learning_rate": 0.00011612709202537886,
        "gradient_norm": 0.4652408957481384,
        "train_loss": 2.999807596206665,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24139,
        "tokens": 12655788032,
        "learning_rate": 0.00011610960891007236,
        "gradient_norm": 0.38628271222114563,
        "train_loss": 3.048900842666626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24140,
        "tokens": 12656312320,
        "learning_rate": 0.00011609212820236871,
        "gradient_norm": 0.3734051585197449,
        "train_loss": 2.960819721221924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24141,
        "tokens": 12656836608,
        "learning_rate": 0.0001160746499024649,
        "gradient_norm": 0.44098031520843506,
        "train_loss": 3.002096176147461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24142,
        "tokens": 12657360896,
        "learning_rate": 0.00011605717401055749,
        "gradient_norm": 0.448808878660202,
        "train_loss": 2.983036994934082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24143,
        "tokens": 12657885184,
        "learning_rate": 0.00011603970052684328,
        "gradient_norm": 0.44867369532585144,
        "train_loss": 3.0412542819976807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24144,
        "tokens": 12658409472,
        "learning_rate": 0.000116022229451519,
        "gradient_norm": 0.5387051105499268,
        "train_loss": 3.057488441467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24145,
        "tokens": 12658933760,
        "learning_rate": 0.00011600476078478124,
        "gradient_norm": 0.466637521982193,
        "train_loss": 2.972409725189209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24146,
        "tokens": 12659458048,
        "learning_rate": 0.00011598729452682669,
        "gradient_norm": 0.44441744685173035,
        "train_loss": 3.011931896209717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24147,
        "tokens": 12659982336,
        "learning_rate": 0.00011596983067785184,
        "gradient_norm": 0.4568401575088501,
        "train_loss": 2.9850802421569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24148,
        "tokens": 12660506624,
        "learning_rate": 0.00011595236923805341,
        "gradient_norm": 0.3972439467906952,
        "train_loss": 2.915132522583008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24149,
        "tokens": 12661030912,
        "learning_rate": 0.0001159349102076278,
        "gradient_norm": 0.42071032524108887,
        "train_loss": 3.0110390186309814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24150,
        "tokens": 12661555200,
        "learning_rate": 0.00011591745358677171,
        "gradient_norm": 0.4154350757598877,
        "train_loss": 2.9737062454223633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24151,
        "tokens": 12662079488,
        "learning_rate": 0.00011589999937568144,
        "gradient_norm": 0.4669095277786255,
        "train_loss": 2.9784531593322754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24152,
        "tokens": 12662603776,
        "learning_rate": 0.00011588254757455365,
        "gradient_norm": 0.46186432242393494,
        "train_loss": 3.012619733810425,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24153,
        "tokens": 12663128064,
        "learning_rate": 0.00011586509818358461,
        "gradient_norm": 0.41396117210388184,
        "train_loss": 3.0069315433502197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24154,
        "tokens": 12663652352,
        "learning_rate": 0.00011584765120297084,
        "gradient_norm": 0.43129047751426697,
        "train_loss": 2.9813876152038574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24155,
        "tokens": 12664176640,
        "learning_rate": 0.00011583020663290876,
        "gradient_norm": 0.4507700204849243,
        "train_loss": 2.951104164123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24156,
        "tokens": 12664700928,
        "learning_rate": 0.00011581276447359461,
        "gradient_norm": 0.3902973234653473,
        "train_loss": 2.964524745941162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24157,
        "tokens": 12665225216,
        "learning_rate": 0.00011579532472522484,
        "gradient_norm": 0.4168851673603058,
        "train_loss": 2.9908533096313477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24158,
        "tokens": 12665749504,
        "learning_rate": 0.00011577788738799564,
        "gradient_norm": 0.42144376039505005,
        "train_loss": 2.9768221378326416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24159,
        "tokens": 12666273792,
        "learning_rate": 0.00011576045246210345,
        "gradient_norm": 0.44079825282096863,
        "train_loss": 2.956995964050293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24160,
        "tokens": 12666798080,
        "learning_rate": 0.00011574301994774431,
        "gradient_norm": 0.4109942615032196,
        "train_loss": 2.9472808837890625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24161,
        "tokens": 12667322368,
        "learning_rate": 0.00011572558984511463,
        "gradient_norm": 0.40476059913635254,
        "train_loss": 2.965855360031128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24162,
        "tokens": 12667846656,
        "learning_rate": 0.00011570816215441049,
        "gradient_norm": 0.4157169759273529,
        "train_loss": 3.013504981994629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24163,
        "tokens": 12668370944,
        "learning_rate": 0.0001156907368758281,
        "gradient_norm": 0.4409163296222687,
        "train_loss": 2.982163906097412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24164,
        "tokens": 12668895232,
        "learning_rate": 0.00011567331400956369,
        "gradient_norm": 0.4192628860473633,
        "train_loss": 2.983654499053955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24165,
        "tokens": 12669419520,
        "learning_rate": 0.00011565589355581323,
        "gradient_norm": 0.43906569480895996,
        "train_loss": 2.955915927886963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24166,
        "tokens": 12669943808,
        "learning_rate": 0.00011563847551477292,
        "gradient_norm": 0.4387771189212799,
        "train_loss": 3.0197744369506836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24167,
        "tokens": 12670468096,
        "learning_rate": 0.00011562105988663872,
        "gradient_norm": 0.427082896232605,
        "train_loss": 3.025360584259033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24168,
        "tokens": 12670992384,
        "learning_rate": 0.00011560364667160679,
        "gradient_norm": 0.44859692454338074,
        "train_loss": 3.0145277976989746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24169,
        "tokens": 12671516672,
        "learning_rate": 0.00011558623586987302,
        "gradient_norm": 0.4203771650791168,
        "train_loss": 3.0222740173339844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24170,
        "tokens": 12672040960,
        "learning_rate": 0.00011556882748163348,
        "gradient_norm": 0.44346264004707336,
        "train_loss": 3.0187344551086426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24171,
        "tokens": 12672565248,
        "learning_rate": 0.00011555142150708402,
        "gradient_norm": 0.4391670525074005,
        "train_loss": 2.9946861267089844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24172,
        "tokens": 12673089536,
        "learning_rate": 0.00011553401794642067,
        "gradient_norm": 0.443745493888855,
        "train_loss": 3.0367159843444824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24173,
        "tokens": 12673613824,
        "learning_rate": 0.00011551661679983927,
        "gradient_norm": 0.42986762523651123,
        "train_loss": 2.981236457824707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24174,
        "tokens": 12674138112,
        "learning_rate": 0.00011549921806753575,
        "gradient_norm": 0.4407114088535309,
        "train_loss": 2.988340377807617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24175,
        "tokens": 12674662400,
        "learning_rate": 0.00011548182174970584,
        "gradient_norm": 0.4274185597896576,
        "train_loss": 3.1027824878692627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24176,
        "tokens": 12675186688,
        "learning_rate": 0.00011546442784654544,
        "gradient_norm": 0.4024992287158966,
        "train_loss": 3.0355687141418457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24177,
        "tokens": 12675710976,
        "learning_rate": 0.00011544703635825042,
        "gradient_norm": 0.40437883138656616,
        "train_loss": 2.9752488136291504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24178,
        "tokens": 12676235264,
        "learning_rate": 0.00011542964728501634,
        "gradient_norm": 0.3838595151901245,
        "train_loss": 2.971543312072754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24179,
        "tokens": 12676759552,
        "learning_rate": 0.00011541226062703914,
        "gradient_norm": 0.46684592962265015,
        "train_loss": 2.981682777404785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24180,
        "tokens": 12677283840,
        "learning_rate": 0.00011539487638451438,
        "gradient_norm": 0.3691190779209137,
        "train_loss": 2.989199638366699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24181,
        "tokens": 12677808128,
        "learning_rate": 0.00011537749455763783,
        "gradient_norm": 0.421534925699234,
        "train_loss": 2.9965898990631104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24182,
        "tokens": 12678332416,
        "learning_rate": 0.00011536011514660507,
        "gradient_norm": 0.4253953993320465,
        "train_loss": 2.928492546081543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24183,
        "tokens": 12678856704,
        "learning_rate": 0.00011534273815161184,
        "gradient_norm": 0.4237343370914459,
        "train_loss": 3.006122589111328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24184,
        "tokens": 12679380992,
        "learning_rate": 0.0001153253635728536,
        "gradient_norm": 0.42803916335105896,
        "train_loss": 3.0477726459503174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24185,
        "tokens": 12679905280,
        "learning_rate": 0.00011530799141052606,
        "gradient_norm": 0.43808382749557495,
        "train_loss": 3.0072312355041504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24186,
        "tokens": 12680429568,
        "learning_rate": 0.00011529062166482464,
        "gradient_norm": 0.4384661018848419,
        "train_loss": 3.006467342376709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24187,
        "tokens": 12680953856,
        "learning_rate": 0.00011527325433594498,
        "gradient_norm": 0.41617050766944885,
        "train_loss": 2.999558448791504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24188,
        "tokens": 12681478144,
        "learning_rate": 0.0001152558894240824,
        "gradient_norm": 0.42730116844177246,
        "train_loss": 3.035001754760742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24189,
        "tokens": 12682002432,
        "learning_rate": 0.00011523852692943258,
        "gradient_norm": 0.398415744304657,
        "train_loss": 2.9881491661071777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24190,
        "tokens": 12682526720,
        "learning_rate": 0.00011522116685219074,
        "gradient_norm": 0.5091837048530579,
        "train_loss": 3.0669736862182617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24191,
        "tokens": 12683051008,
        "learning_rate": 0.00011520380919255251,
        "gradient_norm": 0.40727803111076355,
        "train_loss": 2.997265338897705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24192,
        "tokens": 12683575296,
        "learning_rate": 0.00011518645395071307,
        "gradient_norm": 0.4621758460998535,
        "train_loss": 3.006524085998535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24193,
        "tokens": 12684099584,
        "learning_rate": 0.00011516910112686796,
        "gradient_norm": 0.5074707269668579,
        "train_loss": 3.0065417289733887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24194,
        "tokens": 12684623872,
        "learning_rate": 0.00011515175072121228,
        "gradient_norm": 0.47206535935401917,
        "train_loss": 3.023470401763916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24195,
        "tokens": 12685148160,
        "learning_rate": 0.00011513440273394157,
        "gradient_norm": 0.46303197741508484,
        "train_loss": 3.0158166885375977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24196,
        "tokens": 12685672448,
        "learning_rate": 0.0001151170571652509,
        "gradient_norm": 0.5125319361686707,
        "train_loss": 3.0569980144500732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24197,
        "tokens": 12686196736,
        "learning_rate": 0.0001150997140153357,
        "gradient_norm": 0.4490754306316376,
        "train_loss": 3.0240745544433594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24198,
        "tokens": 12686721024,
        "learning_rate": 0.00011508237328439103,
        "gradient_norm": 0.46760016679763794,
        "train_loss": 3.0196585655212402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24199,
        "tokens": 12687245312,
        "learning_rate": 0.0001150650349726122,
        "gradient_norm": 0.4636837840080261,
        "train_loss": 3.0025978088378906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24200,
        "tokens": 12687769600,
        "learning_rate": 0.0001150476990801943,
        "gradient_norm": 0.420642226934433,
        "train_loss": 3.0562331676483154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24201,
        "tokens": 12688293888,
        "learning_rate": 0.00011503036560733254,
        "gradient_norm": 0.4124492108821869,
        "train_loss": 3.016049861907959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24202,
        "tokens": 12688818176,
        "learning_rate": 0.00011501303455422192,
        "gradient_norm": 0.45236340165138245,
        "train_loss": 3.098459243774414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24203,
        "tokens": 12689342464,
        "learning_rate": 0.00011499570592105756,
        "gradient_norm": 0.42048314213752747,
        "train_loss": 3.005225658416748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24204,
        "tokens": 12689866752,
        "learning_rate": 0.00011497837970803458,
        "gradient_norm": 0.4178915321826935,
        "train_loss": 3.042722702026367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24205,
        "tokens": 12690391040,
        "learning_rate": 0.00011496105591534794,
        "gradient_norm": 0.40989255905151367,
        "train_loss": 3.017763137817383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24206,
        "tokens": 12690915328,
        "learning_rate": 0.00011494373454319276,
        "gradient_norm": 0.4955606162548065,
        "train_loss": 3.015671730041504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24207,
        "tokens": 12691439616,
        "learning_rate": 0.00011492641559176383,
        "gradient_norm": 0.3954927325248718,
        "train_loss": 3.021087646484375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24208,
        "tokens": 12691963904,
        "learning_rate": 0.00011490909906125625,
        "gradient_norm": 0.4561554789543152,
        "train_loss": 3.0368475914001465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24209,
        "tokens": 12692488192,
        "learning_rate": 0.00011489178495186481,
        "gradient_norm": 0.4325343668460846,
        "train_loss": 3.0670700073242188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24210,
        "tokens": 12693012480,
        "learning_rate": 0.00011487447326378455,
        "gradient_norm": 0.46994858980178833,
        "train_loss": 2.9960319995880127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24211,
        "tokens": 12693536768,
        "learning_rate": 0.0001148571639972102,
        "gradient_norm": 0.36695659160614014,
        "train_loss": 2.991702079772949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24212,
        "tokens": 12694061056,
        "learning_rate": 0.00011483985715233667,
        "gradient_norm": 0.5052713751792908,
        "train_loss": 3.0084545612335205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24213,
        "tokens": 12694585344,
        "learning_rate": 0.00011482255272935874,
        "gradient_norm": 0.46840009093284607,
        "train_loss": 3.0752735137939453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24214,
        "tokens": 12695109632,
        "learning_rate": 0.00011480525072847116,
        "gradient_norm": 0.44304999709129333,
        "train_loss": 3.023359775543213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24215,
        "tokens": 12695633920,
        "learning_rate": 0.00011478795114986881,
        "gradient_norm": 0.4315122663974762,
        "train_loss": 3.056914806365967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24216,
        "tokens": 12696158208,
        "learning_rate": 0.0001147706539937463,
        "gradient_norm": 0.4207937717437744,
        "train_loss": 3.037299871444702,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24217,
        "tokens": 12696682496,
        "learning_rate": 0.00011475335926029842,
        "gradient_norm": 0.38686487078666687,
        "train_loss": 2.9997100830078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24218,
        "tokens": 12697206784,
        "learning_rate": 0.00011473606694971971,
        "gradient_norm": 0.42902877926826477,
        "train_loss": 3.0387117862701416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24219,
        "tokens": 12697731072,
        "learning_rate": 0.00011471877706220497,
        "gradient_norm": 0.43696174025535583,
        "train_loss": 3.041945457458496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24220,
        "tokens": 12698255360,
        "learning_rate": 0.0001147014895979487,
        "gradient_norm": 0.39632999897003174,
        "train_loss": 3.0412333011627197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24221,
        "tokens": 12698779648,
        "learning_rate": 0.0001146842045571456,
        "gradient_norm": 0.4424414038658142,
        "train_loss": 3.052771806716919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24222,
        "tokens": 12699303936,
        "learning_rate": 0.00011466692193999009,
        "gradient_norm": 0.4241126477718353,
        "train_loss": 3.029294013977051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24223,
        "tokens": 12699828224,
        "learning_rate": 0.0001146496417466768,
        "gradient_norm": 0.3769869804382324,
        "train_loss": 3.000546455383301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24224,
        "tokens": 12700352512,
        "learning_rate": 0.00011463236397740033,
        "gradient_norm": 0.46162545680999756,
        "train_loss": 3.018509864807129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24225,
        "tokens": 12700876800,
        "learning_rate": 0.00011461508863235498,
        "gradient_norm": 0.39531800150871277,
        "train_loss": 3.0653960704803467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24226,
        "tokens": 12701401088,
        "learning_rate": 0.00011459781571173538,
        "gradient_norm": 0.40804532170295715,
        "train_loss": 3.065001964569092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24227,
        "tokens": 12701925376,
        "learning_rate": 0.00011458054521573576,
        "gradient_norm": 0.4383496046066284,
        "train_loss": 2.954486846923828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24228,
        "tokens": 12702449664,
        "learning_rate": 0.00011456327714455072,
        "gradient_norm": 0.45082467794418335,
        "train_loss": 3.0302224159240723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24229,
        "tokens": 12702973952,
        "learning_rate": 0.0001145460114983745,
        "gradient_norm": 0.4063023030757904,
        "train_loss": 3.0243539810180664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24230,
        "tokens": 12703498240,
        "learning_rate": 0.00011452874827740152,
        "gradient_norm": 0.39850232005119324,
        "train_loss": 3.0548081398010254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24231,
        "tokens": 12704022528,
        "learning_rate": 0.00011451148748182603,
        "gradient_norm": 0.4024406373500824,
        "train_loss": 2.9880237579345703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24232,
        "tokens": 12704546816,
        "learning_rate": 0.0001144942291118424,
        "gradient_norm": 0.39725154638290405,
        "train_loss": 3.080315113067627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24233,
        "tokens": 12705071104,
        "learning_rate": 0.00011447697316764482,
        "gradient_norm": 0.4176381230354309,
        "train_loss": 3.0221447944641113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24234,
        "tokens": 12705595392,
        "learning_rate": 0.00011445971964942754,
        "gradient_norm": 0.3951594829559326,
        "train_loss": 2.9485371112823486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24235,
        "tokens": 12706119680,
        "learning_rate": 0.00011444246855738487,
        "gradient_norm": 0.44412386417388916,
        "train_loss": 3.0203635692596436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24236,
        "tokens": 12706643968,
        "learning_rate": 0.00011442521989171085,
        "gradient_norm": 0.43148893117904663,
        "train_loss": 3.0563173294067383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24237,
        "tokens": 12707168256,
        "learning_rate": 0.00011440797365259978,
        "gradient_norm": 0.4743482172489166,
        "train_loss": 3.011587142944336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24238,
        "tokens": 12707692544,
        "learning_rate": 0.00011439072984024562,
        "gradient_norm": 0.42777732014656067,
        "train_loss": 3.015531539916992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24239,
        "tokens": 12708216832,
        "learning_rate": 0.00011437348845484265,
        "gradient_norm": 0.42684537172317505,
        "train_loss": 3.0607376098632812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24240,
        "tokens": 12708741120,
        "learning_rate": 0.00011435624949658476,
        "gradient_norm": 0.5197722911834717,
        "train_loss": 3.0434043407440186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24241,
        "tokens": 12709265408,
        "learning_rate": 0.00011433901296566618,
        "gradient_norm": 0.41428902745246887,
        "train_loss": 3.0088610649108887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24242,
        "tokens": 12709789696,
        "learning_rate": 0.00011432177886228076,
        "gradient_norm": 0.42421266436576843,
        "train_loss": 3.0251567363739014,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24243,
        "tokens": 12710313984,
        "learning_rate": 0.00011430454718662256,
        "gradient_norm": 0.4423830509185791,
        "train_loss": 2.9981696605682373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24244,
        "tokens": 12710838272,
        "learning_rate": 0.00011428731793888563,
        "gradient_norm": 0.47377848625183105,
        "train_loss": 2.981663227081299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24245,
        "tokens": 12711362560,
        "learning_rate": 0.00011427009111926375,
        "gradient_norm": 0.44412466883659363,
        "train_loss": 3.0185742378234863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24246,
        "tokens": 12711886848,
        "learning_rate": 0.00011425286672795101,
        "gradient_norm": 0.4650363028049469,
        "train_loss": 3.001030445098877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24247,
        "tokens": 12712411136,
        "learning_rate": 0.00011423564476514106,
        "gradient_norm": 0.4127074182033539,
        "train_loss": 2.997788906097412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24248,
        "tokens": 12712935424,
        "learning_rate": 0.00011421842523102801,
        "gradient_norm": 0.4159190058708191,
        "train_loss": 3.045728921890259,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24249,
        "tokens": 12713459712,
        "learning_rate": 0.0001142012081258055,
        "gradient_norm": 0.5013272166252136,
        "train_loss": 3.051891326904297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24250,
        "tokens": 12713984000,
        "learning_rate": 0.00011418399344966742,
        "gradient_norm": 0.4185115396976471,
        "train_loss": 3.030210494995117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24251,
        "tokens": 12714508288,
        "learning_rate": 0.00011416678120280748,
        "gradient_norm": 0.3997010886669159,
        "train_loss": 3.0101654529571533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24252,
        "tokens": 12715032576,
        "learning_rate": 0.00011414957138541951,
        "gradient_norm": 0.45276767015457153,
        "train_loss": 3.07132625579834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24253,
        "tokens": 12715556864,
        "learning_rate": 0.00011413236399769711,
        "gradient_norm": 0.42353400588035583,
        "train_loss": 3.080533981323242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24254,
        "tokens": 12716081152,
        "learning_rate": 0.00011411515903983406,
        "gradient_norm": 0.432131826877594,
        "train_loss": 3.010885238647461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24255,
        "tokens": 12716605440,
        "learning_rate": 0.00011409795651202406,
        "gradient_norm": 0.4047833979129791,
        "train_loss": 3.059202194213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24256,
        "tokens": 12717129728,
        "learning_rate": 0.0001140807564144606,
        "gradient_norm": 0.4485262930393219,
        "train_loss": 3.0482494831085205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24257,
        "tokens": 12717654016,
        "learning_rate": 0.00011406355874733748,
        "gradient_norm": 0.4542422592639923,
        "train_loss": 3.017303466796875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24258,
        "tokens": 12718178304,
        "learning_rate": 0.00011404636351084808,
        "gradient_norm": 0.42192980647087097,
        "train_loss": 3.095637321472168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24259,
        "tokens": 12718702592,
        "learning_rate": 0.0001140291707051861,
        "gradient_norm": 0.44098883867263794,
        "train_loss": 3.0252161026000977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24260,
        "tokens": 12719226880,
        "learning_rate": 0.000114011980330545,
        "gradient_norm": 0.42782723903656006,
        "train_loss": 3.114800453186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24261,
        "tokens": 12719751168,
        "learning_rate": 0.00011399479238711834,
        "gradient_norm": 0.41704070568084717,
        "train_loss": 3.0270872116088867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24262,
        "tokens": 12720275456,
        "learning_rate": 0.00011397760687509949,
        "gradient_norm": 0.44044578075408936,
        "train_loss": 3.038280487060547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24263,
        "tokens": 12720799744,
        "learning_rate": 0.00011396042379468196,
        "gradient_norm": 0.520203709602356,
        "train_loss": 3.032352924346924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24264,
        "tokens": 12721324032,
        "learning_rate": 0.00011394324314605923,
        "gradient_norm": 0.4294980466365814,
        "train_loss": 2.9798455238342285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24265,
        "tokens": 12721848320,
        "learning_rate": 0.00011392606492942453,
        "gradient_norm": 0.46226465702056885,
        "train_loss": 3.0016024112701416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24266,
        "tokens": 12722372608,
        "learning_rate": 0.0001139088891449714,
        "gradient_norm": 0.45213454961776733,
        "train_loss": 3.0094969272613525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24267,
        "tokens": 12722896896,
        "learning_rate": 0.00011389171579289301,
        "gradient_norm": 0.4224347770214081,
        "train_loss": 3.017965316772461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24268,
        "tokens": 12723421184,
        "learning_rate": 0.00011387454487338281,
        "gradient_norm": 0.4206206202507019,
        "train_loss": 3.126021385192871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24269,
        "tokens": 12723945472,
        "learning_rate": 0.00011385737638663395,
        "gradient_norm": 0.44333890080451965,
        "train_loss": 2.971005916595459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24270,
        "tokens": 12724469760,
        "learning_rate": 0.00011384021033283983,
        "gradient_norm": 0.4938742518424988,
        "train_loss": 3.084181308746338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24271,
        "tokens": 12724994048,
        "learning_rate": 0.0001138230467121935,
        "gradient_norm": 0.4332849979400635,
        "train_loss": 3.053253650665283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24272,
        "tokens": 12725518336,
        "learning_rate": 0.00011380588552488833,
        "gradient_norm": 0.4692392647266388,
        "train_loss": 2.996971845626831,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24273,
        "tokens": 12726042624,
        "learning_rate": 0.00011378872677111736,
        "gradient_norm": 0.43391653895378113,
        "train_loss": 3.0266776084899902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24274,
        "tokens": 12726566912,
        "learning_rate": 0.00011377157045107375,
        "gradient_norm": 0.40364977717399597,
        "train_loss": 2.9938273429870605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24275,
        "tokens": 12727091200,
        "learning_rate": 0.00011375441656495076,
        "gradient_norm": 0.44280239939689636,
        "train_loss": 3.0614852905273438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24276,
        "tokens": 12727615488,
        "learning_rate": 0.00011373726511294126,
        "gradient_norm": 0.4451819658279419,
        "train_loss": 3.0355377197265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24277,
        "tokens": 12728139776,
        "learning_rate": 0.0001137201160952385,
        "gradient_norm": 0.4402787685394287,
        "train_loss": 3.004836320877075,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24278,
        "tokens": 12728664064,
        "learning_rate": 0.00011370296951203538,
        "gradient_norm": 0.5080104470252991,
        "train_loss": 3.105626344680786,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24279,
        "tokens": 12729188352,
        "learning_rate": 0.00011368582536352501,
        "gradient_norm": 0.5062525272369385,
        "train_loss": 3.072415828704834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24280,
        "tokens": 12729712640,
        "learning_rate": 0.00011366868364990029,
        "gradient_norm": 0.44264593720436096,
        "train_loss": 3.0510787963867188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24281,
        "tokens": 12730236928,
        "learning_rate": 0.00011365154437135421,
        "gradient_norm": 0.5397244095802307,
        "train_loss": 3.0267910957336426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24282,
        "tokens": 12730761216,
        "learning_rate": 0.00011363440752807965,
        "gradient_norm": 0.4484492540359497,
        "train_loss": 3.0464324951171875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24283,
        "tokens": 12731285504,
        "learning_rate": 0.00011361727312026961,
        "gradient_norm": 0.4969807267189026,
        "train_loss": 3.0506386756896973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24284,
        "tokens": 12731809792,
        "learning_rate": 0.00011360014114811679,
        "gradient_norm": 0.5382267236709595,
        "train_loss": 2.997903347015381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24285,
        "tokens": 12732334080,
        "learning_rate": 0.00011358301161181424,
        "gradient_norm": 0.4950177073478699,
        "train_loss": 3.066746711730957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24286,
        "tokens": 12732858368,
        "learning_rate": 0.00011356588451155456,
        "gradient_norm": 0.4382486641407013,
        "train_loss": 2.9972543716430664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24287,
        "tokens": 12733382656,
        "learning_rate": 0.00011354875984753075,
        "gradient_norm": 0.43294432759284973,
        "train_loss": 3.026010751724243,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24288,
        "tokens": 12733906944,
        "learning_rate": 0.00011353163761993536,
        "gradient_norm": 0.4429720640182495,
        "train_loss": 3.023629665374756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24289,
        "tokens": 12734431232,
        "learning_rate": 0.00011351451782896131,
        "gradient_norm": 0.39219579100608826,
        "train_loss": 3.0899643898010254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24290,
        "tokens": 12734955520,
        "learning_rate": 0.00011349740047480114,
        "gradient_norm": 0.4096960723400116,
        "train_loss": 2.986856698989868,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24291,
        "tokens": 12735479808,
        "learning_rate": 0.00011348028555764768,
        "gradient_norm": 0.4117680788040161,
        "train_loss": 3.0443825721740723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24292,
        "tokens": 12736004096,
        "learning_rate": 0.00011346317307769342,
        "gradient_norm": 0.4010434150695801,
        "train_loss": 3.0686380863189697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24293,
        "tokens": 12736528384,
        "learning_rate": 0.00011344606303513114,
        "gradient_norm": 0.3932343125343323,
        "train_loss": 3.0316944122314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24294,
        "tokens": 12737052672,
        "learning_rate": 0.00011342895543015331,
        "gradient_norm": 0.41879117488861084,
        "train_loss": 2.976923942565918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24295,
        "tokens": 12737576960,
        "learning_rate": 0.00011341185026295262,
        "gradient_norm": 0.4582579731941223,
        "train_loss": 3.0276663303375244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24296,
        "tokens": 12738101248,
        "learning_rate": 0.00011339474753372147,
        "gradient_norm": 0.3879126310348511,
        "train_loss": 3.072904586791992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24297,
        "tokens": 12738625536,
        "learning_rate": 0.0001133776472426525,
        "gradient_norm": 0.42930054664611816,
        "train_loss": 2.9937026500701904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24298,
        "tokens": 12739149824,
        "learning_rate": 0.00011336054938993807,
        "gradient_norm": 0.48811325430870056,
        "train_loss": 3.042088031768799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24299,
        "tokens": 12739674112,
        "learning_rate": 0.00011334345397577076,
        "gradient_norm": 0.4528709352016449,
        "train_loss": 3.1058788299560547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24300,
        "tokens": 12740198400,
        "learning_rate": 0.0001133263610003429,
        "gradient_norm": 0.4277030825614929,
        "train_loss": 3.0514023303985596,
        "val_loss": 2.9839439392089844,
        "hellaswag_acc": 0.2849034070968628,
        "hellaswag_acc_norm": 0.29705238342285156
    },
    {
        "step": 24301,
        "tokens": 12740722688,
        "learning_rate": 0.00011330927046384699,
        "gradient_norm": 0.41019028425216675,
        "train_loss": 3.03315806388855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24302,
        "tokens": 12741246976,
        "learning_rate": 0.0001132921823664753,
        "gradient_norm": 0.422712117433548,
        "train_loss": 3.028965473175049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24303,
        "tokens": 12741771264,
        "learning_rate": 0.00011327509670842022,
        "gradient_norm": 0.4514515697956085,
        "train_loss": 3.0528407096862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24304,
        "tokens": 12742295552,
        "learning_rate": 0.00011325801348987413,
        "gradient_norm": 0.4530900716781616,
        "train_loss": 3.1043035984039307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24305,
        "tokens": 12742819840,
        "learning_rate": 0.00011324093271102924,
        "gradient_norm": 0.44613879919052124,
        "train_loss": 3.0656208992004395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24306,
        "tokens": 12743344128,
        "learning_rate": 0.0001132238543720779,
        "gradient_norm": 0.44590333104133606,
        "train_loss": 3.015770673751831,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24307,
        "tokens": 12743868416,
        "learning_rate": 0.00011320677847321224,
        "gradient_norm": 0.4681423306465149,
        "train_loss": 3.0524649620056152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24308,
        "tokens": 12744392704,
        "learning_rate": 0.00011318970501462458,
        "gradient_norm": 0.47120389342308044,
        "train_loss": 2.9998292922973633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24309,
        "tokens": 12744916992,
        "learning_rate": 0.00011317263399650699,
        "gradient_norm": 0.42983031272888184,
        "train_loss": 3.027308940887451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24310,
        "tokens": 12745441280,
        "learning_rate": 0.00011315556541905177,
        "gradient_norm": 0.39784929156303406,
        "train_loss": 3.013963222503662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24311,
        "tokens": 12745965568,
        "learning_rate": 0.0001131384992824509,
        "gradient_norm": 0.38752132654190063,
        "train_loss": 3.028809070587158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24312,
        "tokens": 12746489856,
        "learning_rate": 0.00011312143558689659,
        "gradient_norm": 0.38100168108940125,
        "train_loss": 2.9818501472473145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24313,
        "tokens": 12747014144,
        "learning_rate": 0.0001131043743325808,
        "gradient_norm": 0.40637749433517456,
        "train_loss": 3.046675205230713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24314,
        "tokens": 12747538432,
        "learning_rate": 0.00011308731551969567,
        "gradient_norm": 0.4167187213897705,
        "train_loss": 3.011007308959961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24315,
        "tokens": 12748062720,
        "learning_rate": 0.00011307025914843321,
        "gradient_norm": 0.4368019998073578,
        "train_loss": 2.987720251083374,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24316,
        "tokens": 12748587008,
        "learning_rate": 0.00011305320521898539,
        "gradient_norm": 0.41962969303131104,
        "train_loss": 3.0359864234924316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24317,
        "tokens": 12749111296,
        "learning_rate": 0.00011303615373154421,
        "gradient_norm": 0.43986183404922485,
        "train_loss": 3.0012378692626953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24318,
        "tokens": 12749635584,
        "learning_rate": 0.00011301910468630152,
        "gradient_norm": 0.4298597574234009,
        "train_loss": 3.0250344276428223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24319,
        "tokens": 12750159872,
        "learning_rate": 0.00011300205808344932,
        "gradient_norm": 0.4459245800971985,
        "train_loss": 3.0861713886260986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24320,
        "tokens": 12750684160,
        "learning_rate": 0.0001129850139231794,
        "gradient_norm": 0.4172562062740326,
        "train_loss": 3.058741807937622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24321,
        "tokens": 12751208448,
        "learning_rate": 0.00011296797220568375,
        "gradient_norm": 0.4373871386051178,
        "train_loss": 3.046581745147705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24322,
        "tokens": 12751732736,
        "learning_rate": 0.00011295093293115401,
        "gradient_norm": 0.472136914730072,
        "train_loss": 3.046576976776123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24323,
        "tokens": 12752257024,
        "learning_rate": 0.00011293389609978209,
        "gradient_norm": 0.4243541359901428,
        "train_loss": 3.0065436363220215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24324,
        "tokens": 12752781312,
        "learning_rate": 0.00011291686171175982,
        "gradient_norm": 0.4228334426879883,
        "train_loss": 3.0207605361938477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24325,
        "tokens": 12753305600,
        "learning_rate": 0.0001128998297672788,
        "gradient_norm": 0.42818161845207214,
        "train_loss": 3.028667688369751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24326,
        "tokens": 12753829888,
        "learning_rate": 0.0001128828002665309,
        "gradient_norm": 0.4511118531227112,
        "train_loss": 3.0298168659210205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24327,
        "tokens": 12754354176,
        "learning_rate": 0.00011286577320970766,
        "gradient_norm": 0.3799036741256714,
        "train_loss": 3.0211830139160156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24328,
        "tokens": 12754878464,
        "learning_rate": 0.00011284874859700085,
        "gradient_norm": 0.4420270621776581,
        "train_loss": 3.0067102909088135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24329,
        "tokens": 12755402752,
        "learning_rate": 0.00011283172642860204,
        "gradient_norm": 0.3736995756626129,
        "train_loss": 3.064030647277832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24330,
        "tokens": 12755927040,
        "learning_rate": 0.00011281470670470286,
        "gradient_norm": 0.43867671489715576,
        "train_loss": 3.0634255409240723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24331,
        "tokens": 12756451328,
        "learning_rate": 0.00011279768942549484,
        "gradient_norm": 0.41699135303497314,
        "train_loss": 3.0616626739501953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24332,
        "tokens": 12756975616,
        "learning_rate": 0.00011278067459116961,
        "gradient_norm": 0.4212111532688141,
        "train_loss": 3.061349391937256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24333,
        "tokens": 12757499904,
        "learning_rate": 0.0001127636622019187,
        "gradient_norm": 0.42685917019844055,
        "train_loss": 2.9997470378875732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24334,
        "tokens": 12758024192,
        "learning_rate": 0.0001127466522579335,
        "gradient_norm": 0.4205003082752228,
        "train_loss": 3.027228355407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24335,
        "tokens": 12758548480,
        "learning_rate": 0.00011272964475940561,
        "gradient_norm": 0.41325345635414124,
        "train_loss": 3.0332298278808594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24336,
        "tokens": 12759072768,
        "learning_rate": 0.00011271263970652633,
        "gradient_norm": 0.4312065839767456,
        "train_loss": 3.0462770462036133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24337,
        "tokens": 12759597056,
        "learning_rate": 0.00011269563709948721,
        "gradient_norm": 0.4199289083480835,
        "train_loss": 3.045090913772583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24338,
        "tokens": 12760121344,
        "learning_rate": 0.0001126786369384795,
        "gradient_norm": 0.4300309717655182,
        "train_loss": 3.0995054244995117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24339,
        "tokens": 12760645632,
        "learning_rate": 0.00011266163922369471,
        "gradient_norm": 0.44945240020751953,
        "train_loss": 3.0689690113067627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24340,
        "tokens": 12761169920,
        "learning_rate": 0.00011264464395532406,
        "gradient_norm": 0.4415988326072693,
        "train_loss": 3.00592041015625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24341,
        "tokens": 12761694208,
        "learning_rate": 0.00011262765113355887,
        "gradient_norm": 0.40707719326019287,
        "train_loss": 3.0457699298858643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24342,
        "tokens": 12762218496,
        "learning_rate": 0.00011261066075859042,
        "gradient_norm": 0.4257250428199768,
        "train_loss": 3.0643744468688965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24343,
        "tokens": 12762742784,
        "learning_rate": 0.00011259367283060994,
        "gradient_norm": 0.4008019268512726,
        "train_loss": 3.042440891265869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24344,
        "tokens": 12763267072,
        "learning_rate": 0.00011257668734980876,
        "gradient_norm": 0.4544309675693512,
        "train_loss": 3.0159718990325928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24345,
        "tokens": 12763791360,
        "learning_rate": 0.00011255970431637792,
        "gradient_norm": 0.37505021691322327,
        "train_loss": 3.041170120239258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24346,
        "tokens": 12764315648,
        "learning_rate": 0.00011254272373050869,
        "gradient_norm": 0.45627549290657043,
        "train_loss": 3.05772066116333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24347,
        "tokens": 12764839936,
        "learning_rate": 0.00011252574559239215,
        "gradient_norm": 0.4386230707168579,
        "train_loss": 3.0259580612182617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24348,
        "tokens": 12765364224,
        "learning_rate": 0.00011250876990221947,
        "gradient_norm": 0.5003459453582764,
        "train_loss": 3.0192370414733887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24349,
        "tokens": 12765888512,
        "learning_rate": 0.00011249179666018163,
        "gradient_norm": 0.4244591295719147,
        "train_loss": 2.9956302642822266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24350,
        "tokens": 12766412800,
        "learning_rate": 0.00011247482586646982,
        "gradient_norm": 0.39910703897476196,
        "train_loss": 3.037551164627075,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24351,
        "tokens": 12766937088,
        "learning_rate": 0.00011245785752127493,
        "gradient_norm": 0.4572678804397583,
        "train_loss": 3.0659561157226562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24352,
        "tokens": 12767461376,
        "learning_rate": 0.00011244089162478805,
        "gradient_norm": 0.4230411648750305,
        "train_loss": 3.0474491119384766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24353,
        "tokens": 12767985664,
        "learning_rate": 0.00011242392817720017,
        "gradient_norm": 0.43046092987060547,
        "train_loss": 3.0607752799987793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24354,
        "tokens": 12768509952,
        "learning_rate": 0.00011240696717870214,
        "gradient_norm": 0.41763556003570557,
        "train_loss": 3.022284984588623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24355,
        "tokens": 12769034240,
        "learning_rate": 0.00011239000862948498,
        "gradient_norm": 0.41821396350860596,
        "train_loss": 3.0980916023254395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24356,
        "tokens": 12769558528,
        "learning_rate": 0.00011237305252973946,
        "gradient_norm": 0.42370325326919556,
        "train_loss": 3.026752233505249,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24357,
        "tokens": 12770082816,
        "learning_rate": 0.00011235609887965661,
        "gradient_norm": 0.4237668812274933,
        "train_loss": 3.022213935852051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24358,
        "tokens": 12770607104,
        "learning_rate": 0.00011233914767942709,
        "gradient_norm": 0.4426352083683014,
        "train_loss": 3.07625150680542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24359,
        "tokens": 12771131392,
        "learning_rate": 0.00011232219892924185,
        "gradient_norm": 0.4655403792858124,
        "train_loss": 2.94264554977417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24360,
        "tokens": 12771655680,
        "learning_rate": 0.00011230525262929151,
        "gradient_norm": 0.454455703496933,
        "train_loss": 3.077608585357666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24361,
        "tokens": 12772179968,
        "learning_rate": 0.00011228830877976703,
        "gradient_norm": 0.4743175506591797,
        "train_loss": 2.9783053398132324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24362,
        "tokens": 12772704256,
        "learning_rate": 0.00011227136738085891,
        "gradient_norm": 0.5073139071464539,
        "train_loss": 3.0292270183563232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24363,
        "tokens": 12773228544,
        "learning_rate": 0.00011225442843275797,
        "gradient_norm": 0.4626569151878357,
        "train_loss": 3.051868438720703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24364,
        "tokens": 12773752832,
        "learning_rate": 0.00011223749193565497,
        "gradient_norm": 0.4365701675415039,
        "train_loss": 3.043874502182007,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24365,
        "tokens": 12774277120,
        "learning_rate": 0.00011222055788974032,
        "gradient_norm": 0.40550461411476135,
        "train_loss": 3.0401577949523926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24366,
        "tokens": 12774801408,
        "learning_rate": 0.00011220362629520486,
        "gradient_norm": 0.4173143208026886,
        "train_loss": 3.016282320022583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24367,
        "tokens": 12775325696,
        "learning_rate": 0.000112186697152239,
        "gradient_norm": 0.4252200126647949,
        "train_loss": 3.003297805786133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24368,
        "tokens": 12775849984,
        "learning_rate": 0.00011216977046103345,
        "gradient_norm": 0.39332741498947144,
        "train_loss": 3.0296530723571777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24369,
        "tokens": 12776374272,
        "learning_rate": 0.0001121528462217786,
        "gradient_norm": 0.42865726351737976,
        "train_loss": 3.0970401763916016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24370,
        "tokens": 12776898560,
        "learning_rate": 0.00011213592443466508,
        "gradient_norm": 0.42998799681663513,
        "train_loss": 3.0118215084075928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24371,
        "tokens": 12777422848,
        "learning_rate": 0.00011211900509988322,
        "gradient_norm": 0.40833455324172974,
        "train_loss": 2.9762916564941406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24372,
        "tokens": 12777947136,
        "learning_rate": 0.00011210208821762359,
        "gradient_norm": 0.4291018843650818,
        "train_loss": 3.0247559547424316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24373,
        "tokens": 12778471424,
        "learning_rate": 0.00011208517378807659,
        "gradient_norm": 0.414361834526062,
        "train_loss": 2.987776756286621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24374,
        "tokens": 12778995712,
        "learning_rate": 0.00011206826181143257,
        "gradient_norm": 0.39384281635284424,
        "train_loss": 3.094245195388794,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24375,
        "tokens": 12779520000,
        "learning_rate": 0.000112051352287882,
        "gradient_norm": 0.3808511197566986,
        "train_loss": 3.0575613975524902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24376,
        "tokens": 12780044288,
        "learning_rate": 0.00011203444521761503,
        "gradient_norm": 0.38551726937294006,
        "train_loss": 3.0276012420654297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24377,
        "tokens": 12780568576,
        "learning_rate": 0.00011201754060082217,
        "gradient_norm": 0.3776666522026062,
        "train_loss": 3.0153369903564453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24378,
        "tokens": 12781092864,
        "learning_rate": 0.00011200063843769357,
        "gradient_norm": 0.40089502930641174,
        "train_loss": 2.981238842010498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24379,
        "tokens": 12781617152,
        "learning_rate": 0.00011198373872841956,
        "gradient_norm": 0.3917572498321533,
        "train_loss": 3.0228915214538574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24380,
        "tokens": 12782141440,
        "learning_rate": 0.0001119668414731903,
        "gradient_norm": 0.40579062700271606,
        "train_loss": 3.0176305770874023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24381,
        "tokens": 12782665728,
        "learning_rate": 0.00011194994667219606,
        "gradient_norm": 0.3636421859264374,
        "train_loss": 3.0267763137817383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24382,
        "tokens": 12783190016,
        "learning_rate": 0.00011193305432562694,
        "gradient_norm": 0.41686275601387024,
        "train_loss": 3.0172417163848877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24383,
        "tokens": 12783714304,
        "learning_rate": 0.00011191616443367308,
        "gradient_norm": 0.39594247937202454,
        "train_loss": 3.0504817962646484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24384,
        "tokens": 12784238592,
        "learning_rate": 0.00011189927699652472,
        "gradient_norm": 0.45273083448410034,
        "train_loss": 2.995389938354492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24385,
        "tokens": 12784762880,
        "learning_rate": 0.00011188239201437181,
        "gradient_norm": 0.3688206374645233,
        "train_loss": 3.0418572425842285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24386,
        "tokens": 12785287168,
        "learning_rate": 0.00011186550948740455,
        "gradient_norm": 0.41706913709640503,
        "train_loss": 3.0686917304992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24387,
        "tokens": 12785811456,
        "learning_rate": 0.0001118486294158128,
        "gradient_norm": 0.3789597153663635,
        "train_loss": 3.0216691493988037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24388,
        "tokens": 12786335744,
        "learning_rate": 0.00011183175179978672,
        "gradient_norm": 0.3993111848831177,
        "train_loss": 3.0469844341278076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24389,
        "tokens": 12786860032,
        "learning_rate": 0.0001118148766395162,
        "gradient_norm": 0.4634208679199219,
        "train_loss": 2.9946885108947754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24390,
        "tokens": 12787384320,
        "learning_rate": 0.00011179800393519123,
        "gradient_norm": 0.37450194358825684,
        "train_loss": 3.0523152351379395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24391,
        "tokens": 12787908608,
        "learning_rate": 0.00011178113368700169,
        "gradient_norm": 0.38847798109054565,
        "train_loss": 3.0098650455474854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24392,
        "tokens": 12788432896,
        "learning_rate": 0.00011176426589513757,
        "gradient_norm": 0.41458621621131897,
        "train_loss": 2.9976534843444824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24393,
        "tokens": 12788957184,
        "learning_rate": 0.00011174740055978861,
        "gradient_norm": 0.5374179482460022,
        "train_loss": 3.148613691329956,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24394,
        "tokens": 12789481472,
        "learning_rate": 0.0001117305376811448,
        "gradient_norm": 0.4393690526485443,
        "train_loss": 3.023012161254883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24395,
        "tokens": 12790005760,
        "learning_rate": 0.00011171367725939576,
        "gradient_norm": 0.4951000511646271,
        "train_loss": 3.017080307006836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24396,
        "tokens": 12790530048,
        "learning_rate": 0.00011169681929473147,
        "gradient_norm": 0.42957305908203125,
        "train_loss": 3.00113582611084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24397,
        "tokens": 12791054336,
        "learning_rate": 0.00011167996378734155,
        "gradient_norm": 0.42831018567085266,
        "train_loss": 3.038684844970703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24398,
        "tokens": 12791578624,
        "learning_rate": 0.00011166311073741584,
        "gradient_norm": 0.5274490714073181,
        "train_loss": 3.042048931121826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24399,
        "tokens": 12792102912,
        "learning_rate": 0.0001116462601451439,
        "gradient_norm": 0.4645790159702301,
        "train_loss": 3.057849884033203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24400,
        "tokens": 12792627200,
        "learning_rate": 0.00011162941201071555,
        "gradient_norm": 0.42275771498680115,
        "train_loss": 3.094714403152466,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24401,
        "tokens": 12793151488,
        "learning_rate": 0.00011161256633432034,
        "gradient_norm": 0.5104703903198242,
        "train_loss": 3.0294342041015625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24402,
        "tokens": 12793675776,
        "learning_rate": 0.00011159572311614797,
        "gradient_norm": 0.4950084388256073,
        "train_loss": 3.0298194885253906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24403,
        "tokens": 12794200064,
        "learning_rate": 0.0001115788823563879,
        "gradient_norm": 0.4517698585987091,
        "train_loss": 3.1101746559143066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24404,
        "tokens": 12794724352,
        "learning_rate": 0.00011156204405522988,
        "gradient_norm": 0.604773223400116,
        "train_loss": 2.9791181087493896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24405,
        "tokens": 12795248640,
        "learning_rate": 0.00011154520821286325,
        "gradient_norm": 0.4122290015220642,
        "train_loss": 3.0630664825439453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24406,
        "tokens": 12795772928,
        "learning_rate": 0.00011152837482947768,
        "gradient_norm": 0.4632432162761688,
        "train_loss": 3.005012035369873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24407,
        "tokens": 12796297216,
        "learning_rate": 0.00011151154390526254,
        "gradient_norm": 0.4144335389137268,
        "train_loss": 3.0133442878723145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24408,
        "tokens": 12796821504,
        "learning_rate": 0.00011149471544040737,
        "gradient_norm": 0.5233569145202637,
        "train_loss": 3.082200050354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24409,
        "tokens": 12797345792,
        "learning_rate": 0.00011147788943510149,
        "gradient_norm": 0.45623818039894104,
        "train_loss": 3.0174946784973145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24410,
        "tokens": 12797870080,
        "learning_rate": 0.00011146106588953445,
        "gradient_norm": 0.4278150498867035,
        "train_loss": 3.0993449687957764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24411,
        "tokens": 12798394368,
        "learning_rate": 0.00011144424480389543,
        "gradient_norm": 0.475452184677124,
        "train_loss": 3.0284478664398193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24412,
        "tokens": 12798918656,
        "learning_rate": 0.0001114274261783739,
        "gradient_norm": 0.44239941239356995,
        "train_loss": 2.989658832550049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24413,
        "tokens": 12799442944,
        "learning_rate": 0.0001114106100131592,
        "gradient_norm": 0.451964408159256,
        "train_loss": 2.9838056564331055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24414,
        "tokens": 12799967232,
        "learning_rate": 0.00011139379630844047,
        "gradient_norm": 0.4844803810119629,
        "train_loss": 3.0004024505615234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24415,
        "tokens": 12800491520,
        "learning_rate": 0.00011137698506440716,
        "gradient_norm": 0.4338017702102661,
        "train_loss": 3.020148754119873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24416,
        "tokens": 12801015808,
        "learning_rate": 0.00011136017628124831,
        "gradient_norm": 0.46526646614074707,
        "train_loss": 2.9918055534362793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24417,
        "tokens": 12801540096,
        "learning_rate": 0.00011134336995915331,
        "gradient_norm": 0.4285643696784973,
        "train_loss": 3.030148983001709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24418,
        "tokens": 12802064384,
        "learning_rate": 0.00011132656609831118,
        "gradient_norm": 0.42414024472236633,
        "train_loss": 3.0459136962890625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24419,
        "tokens": 12802588672,
        "learning_rate": 0.00011130976469891121,
        "gradient_norm": 0.42332130670547485,
        "train_loss": 2.9887726306915283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24420,
        "tokens": 12803112960,
        "learning_rate": 0.00011129296576114233,
        "gradient_norm": 0.47487157583236694,
        "train_loss": 3.0551891326904297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24421,
        "tokens": 12803637248,
        "learning_rate": 0.00011127616928519385,
        "gradient_norm": 0.445464551448822,
        "train_loss": 3.007382392883301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24422,
        "tokens": 12804161536,
        "learning_rate": 0.00011125937527125464,
        "gradient_norm": 0.4196825623512268,
        "train_loss": 3.0135016441345215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24423,
        "tokens": 12804685824,
        "learning_rate": 0.00011124258371951386,
        "gradient_norm": 0.4596277177333832,
        "train_loss": 3.0201799869537354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24424,
        "tokens": 12805210112,
        "learning_rate": 0.00011122579463016052,
        "gradient_norm": 0.4398905634880066,
        "train_loss": 3.046436071395874,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24425,
        "tokens": 12805734400,
        "learning_rate": 0.00011120900800338352,
        "gradient_norm": 0.4079239070415497,
        "train_loss": 3.0497395992279053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24426,
        "tokens": 12806258688,
        "learning_rate": 0.00011119222383937195,
        "gradient_norm": 0.4208502769470215,
        "train_loss": 3.0447797775268555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24427,
        "tokens": 12806782976,
        "learning_rate": 0.00011117544213831457,
        "gradient_norm": 0.41668108105659485,
        "train_loss": 2.978203773498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24428,
        "tokens": 12807307264,
        "learning_rate": 0.0001111586629004004,
        "gradient_norm": 0.43812716007232666,
        "train_loss": 3.0422863960266113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24429,
        "tokens": 12807831552,
        "learning_rate": 0.00011114188612581827,
        "gradient_norm": 0.44010505080223083,
        "train_loss": 2.9815356731414795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24430,
        "tokens": 12808355840,
        "learning_rate": 0.00011112511181475703,
        "gradient_norm": 0.468657910823822,
        "train_loss": 3.038323402404785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24431,
        "tokens": 12808880128,
        "learning_rate": 0.00011110833996740544,
        "gradient_norm": 0.43936148285865784,
        "train_loss": 3.0459890365600586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24432,
        "tokens": 12809404416,
        "learning_rate": 0.00011109157058395234,
        "gradient_norm": 0.4232196807861328,
        "train_loss": 3.064192771911621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24433,
        "tokens": 12809928704,
        "learning_rate": 0.00011107480366458657,
        "gradient_norm": 0.3960518538951874,
        "train_loss": 2.976557731628418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24434,
        "tokens": 12810452992,
        "learning_rate": 0.00011105803920949671,
        "gradient_norm": 0.4271797239780426,
        "train_loss": 3.06538987159729,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24435,
        "tokens": 12810977280,
        "learning_rate": 0.00011104127721887159,
        "gradient_norm": 0.47732245922088623,
        "train_loss": 3.0722622871398926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24436,
        "tokens": 12811501568,
        "learning_rate": 0.00011102451769289978,
        "gradient_norm": 0.4303934574127197,
        "train_loss": 2.943967342376709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24437,
        "tokens": 12812025856,
        "learning_rate": 0.00011100776063177007,
        "gradient_norm": 0.44112634658813477,
        "train_loss": 3.0092692375183105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24438,
        "tokens": 12812550144,
        "learning_rate": 0.0001109910060356709,
        "gradient_norm": 0.41060447692871094,
        "train_loss": 3.0031204223632812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24439,
        "tokens": 12813074432,
        "learning_rate": 0.00011097425390479103,
        "gradient_norm": 0.4747360348701477,
        "train_loss": 3.0426793098449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24440,
        "tokens": 12813598720,
        "learning_rate": 0.00011095750423931888,
        "gradient_norm": 0.4418713450431824,
        "train_loss": 3.030778169631958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24441,
        "tokens": 12814123008,
        "learning_rate": 0.00011094075703944317,
        "gradient_norm": 0.42926129698753357,
        "train_loss": 3.0714049339294434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24442,
        "tokens": 12814647296,
        "learning_rate": 0.00011092401230535218,
        "gradient_norm": 0.4573778212070465,
        "train_loss": 2.995849847793579,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24443,
        "tokens": 12815171584,
        "learning_rate": 0.00011090727003723454,
        "gradient_norm": 0.4316738545894623,
        "train_loss": 3.0635457038879395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24444,
        "tokens": 12815695872,
        "learning_rate": 0.00011089053023527877,
        "gradient_norm": 0.42686447501182556,
        "train_loss": 3.030447244644165,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24445,
        "tokens": 12816220160,
        "learning_rate": 0.00011087379289967312,
        "gradient_norm": 0.4218800961971283,
        "train_loss": 3.0436012744903564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24446,
        "tokens": 12816744448,
        "learning_rate": 0.00011085705803060616,
        "gradient_norm": 0.4309101104736328,
        "train_loss": 2.9938862323760986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24447,
        "tokens": 12817268736,
        "learning_rate": 0.00011084032562826611,
        "gradient_norm": 0.4510592818260193,
        "train_loss": 3.0386829376220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24448,
        "tokens": 12817793024,
        "learning_rate": 0.00011082359569284146,
        "gradient_norm": 0.4048250615596771,
        "train_loss": 2.9910287857055664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24449,
        "tokens": 12818317312,
        "learning_rate": 0.00011080686822452038,
        "gradient_norm": 0.46301478147506714,
        "train_loss": 2.975922107696533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24450,
        "tokens": 12818841600,
        "learning_rate": 0.00011079014322349127,
        "gradient_norm": 0.4222998023033142,
        "train_loss": 3.0849690437316895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24451,
        "tokens": 12819365888,
        "learning_rate": 0.00011077342068994229,
        "gradient_norm": 0.4294337034225464,
        "train_loss": 3.0842325687408447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24452,
        "tokens": 12819890176,
        "learning_rate": 0.00011075670062406175,
        "gradient_norm": 0.41496843099594116,
        "train_loss": 3.053135395050049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24453,
        "tokens": 12820414464,
        "learning_rate": 0.00011073998302603792,
        "gradient_norm": 0.3973957598209381,
        "train_loss": 3.011781692504883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24454,
        "tokens": 12820938752,
        "learning_rate": 0.00011072326789605879,
        "gradient_norm": 0.4374019205570221,
        "train_loss": 3.0040946006774902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24455,
        "tokens": 12821463040,
        "learning_rate": 0.0001107065552343127,
        "gradient_norm": 0.3882996141910553,
        "train_loss": 3.040126323699951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24456,
        "tokens": 12821987328,
        "learning_rate": 0.00011068984504098765,
        "gradient_norm": 0.4529638886451721,
        "train_loss": 3.1000003814697266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24457,
        "tokens": 12822511616,
        "learning_rate": 0.00011067313731627179,
        "gradient_norm": 0.4201160669326782,
        "train_loss": 3.03104305267334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24458,
        "tokens": 12823035904,
        "learning_rate": 0.00011065643206035314,
        "gradient_norm": 0.40268149971961975,
        "train_loss": 3.0411429405212402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24459,
        "tokens": 12823560192,
        "learning_rate": 0.0001106397292734198,
        "gradient_norm": 0.4091130495071411,
        "train_loss": 3.0249133110046387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24460,
        "tokens": 12824084480,
        "learning_rate": 0.00011062302895565972,
        "gradient_norm": 0.3806558847427368,
        "train_loss": 3.0486690998077393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24461,
        "tokens": 12824608768,
        "learning_rate": 0.00011060633110726092,
        "gradient_norm": 0.4306521713733673,
        "train_loss": 3.116772174835205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24462,
        "tokens": 12825133056,
        "learning_rate": 0.00011058963572841131,
        "gradient_norm": 0.3719281256198883,
        "train_loss": 3.0483150482177734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24463,
        "tokens": 12825657344,
        "learning_rate": 0.00011057294281929887,
        "gradient_norm": 0.4604191184043884,
        "train_loss": 3.046290636062622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24464,
        "tokens": 12826181632,
        "learning_rate": 0.00011055625238011151,
        "gradient_norm": 0.4325711131095886,
        "train_loss": 3.048948287963867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24465,
        "tokens": 12826705920,
        "learning_rate": 0.00011053956441103704,
        "gradient_norm": 0.4387942850589752,
        "train_loss": 2.9930062294006348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24466,
        "tokens": 12827230208,
        "learning_rate": 0.0001105228789122634,
        "gradient_norm": 0.4061303436756134,
        "train_loss": 2.9990041255950928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24467,
        "tokens": 12827754496,
        "learning_rate": 0.00011050619588397824,
        "gradient_norm": 0.4035584330558777,
        "train_loss": 2.9735217094421387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24468,
        "tokens": 12828278784,
        "learning_rate": 0.00011048951532636954,
        "gradient_norm": 0.41284146904945374,
        "train_loss": 3.019941806793213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24469,
        "tokens": 12828803072,
        "learning_rate": 0.00011047283723962491,
        "gradient_norm": 0.41835835576057434,
        "train_loss": 3.0573930740356445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24470,
        "tokens": 12829327360,
        "learning_rate": 0.00011045616162393222,
        "gradient_norm": 0.4114942252635956,
        "train_loss": 3.024832248687744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24471,
        "tokens": 12829851648,
        "learning_rate": 0.00011043948847947902,
        "gradient_norm": 0.4344365894794464,
        "train_loss": 3.0450704097747803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24472,
        "tokens": 12830375936,
        "learning_rate": 0.00011042281780645307,
        "gradient_norm": 0.4089109003543854,
        "train_loss": 3.0545783042907715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24473,
        "tokens": 12830900224,
        "learning_rate": 0.0001104061496050421,
        "gradient_norm": 0.3726283013820648,
        "train_loss": 3.0272765159606934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24474,
        "tokens": 12831424512,
        "learning_rate": 0.00011038948387543355,
        "gradient_norm": 0.4095577001571655,
        "train_loss": 3.042865514755249,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24475,
        "tokens": 12831948800,
        "learning_rate": 0.0001103728206178152,
        "gradient_norm": 0.43468138575553894,
        "train_loss": 3.0686798095703125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24476,
        "tokens": 12832473088,
        "learning_rate": 0.00011035615983237445,
        "gradient_norm": 0.4196847379207611,
        "train_loss": 2.993368625640869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24477,
        "tokens": 12832997376,
        "learning_rate": 0.00011033950151929899,
        "gradient_norm": 0.4030357003211975,
        "train_loss": 3.054522752761841,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24478,
        "tokens": 12833521664,
        "learning_rate": 0.00011032284567877616,
        "gradient_norm": 0.4168035387992859,
        "train_loss": 3.0231800079345703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24479,
        "tokens": 12834045952,
        "learning_rate": 0.00011030619231099364,
        "gradient_norm": 0.4225875735282898,
        "train_loss": 3.032536506652832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24480,
        "tokens": 12834570240,
        "learning_rate": 0.00011028954141613869,
        "gradient_norm": 0.3838686943054199,
        "train_loss": 2.9871087074279785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24481,
        "tokens": 12835094528,
        "learning_rate": 0.0001102728929943989,
        "gradient_norm": 0.44959792494773865,
        "train_loss": 2.9874026775360107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24482,
        "tokens": 12835618816,
        "learning_rate": 0.00011025624704596152,
        "gradient_norm": 0.4432402551174164,
        "train_loss": 3.0212297439575195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24483,
        "tokens": 12836143104,
        "learning_rate": 0.00011023960357101401,
        "gradient_norm": 0.4278247058391571,
        "train_loss": 3.0673587322235107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24484,
        "tokens": 12836667392,
        "learning_rate": 0.00011022296256974378,
        "gradient_norm": 0.42561963200569153,
        "train_loss": 3.072622299194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24485,
        "tokens": 12837191680,
        "learning_rate": 0.00011020632404233796,
        "gradient_norm": 0.4583398401737213,
        "train_loss": 3.028515338897705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24486,
        "tokens": 12837715968,
        "learning_rate": 0.00011018968798898406,
        "gradient_norm": 0.3884510099887848,
        "train_loss": 3.088714599609375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24487,
        "tokens": 12838240256,
        "learning_rate": 0.00011017305440986912,
        "gradient_norm": 0.4455307722091675,
        "train_loss": 2.9885683059692383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24488,
        "tokens": 12838764544,
        "learning_rate": 0.00011015642330518056,
        "gradient_norm": 0.3860040605068207,
        "train_loss": 2.959411144256592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24489,
        "tokens": 12839288832,
        "learning_rate": 0.00011013979467510542,
        "gradient_norm": 0.4082548916339874,
        "train_loss": 2.984039306640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24490,
        "tokens": 12839813120,
        "learning_rate": 0.00011012316851983103,
        "gradient_norm": 0.46365776658058167,
        "train_loss": 3.066568374633789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24491,
        "tokens": 12840337408,
        "learning_rate": 0.00011010654483954436,
        "gradient_norm": 0.4582206606864929,
        "train_loss": 3.0665793418884277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24492,
        "tokens": 12840861696,
        "learning_rate": 0.00011008992363443273,
        "gradient_norm": 0.5295768976211548,
        "train_loss": 3.0237793922424316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24493,
        "tokens": 12841385984,
        "learning_rate": 0.00011007330490468307,
        "gradient_norm": 0.4600193500518799,
        "train_loss": 3.008523464202881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24494,
        "tokens": 12841910272,
        "learning_rate": 0.00011005668865048259,
        "gradient_norm": 0.4214366674423218,
        "train_loss": 3.0370967388153076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24495,
        "tokens": 12842434560,
        "learning_rate": 0.00011004007487201814,
        "gradient_norm": 0.4496656358242035,
        "train_loss": 2.9773435592651367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24496,
        "tokens": 12842958848,
        "learning_rate": 0.00011002346356947691,
        "gradient_norm": 0.41197919845581055,
        "train_loss": 2.9887266159057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24497,
        "tokens": 12843483136,
        "learning_rate": 0.00011000685474304577,
        "gradient_norm": 0.45391935110092163,
        "train_loss": 3.0064492225646973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24498,
        "tokens": 12844007424,
        "learning_rate": 0.00010999024839291173,
        "gradient_norm": 0.41720831394195557,
        "train_loss": 3.0226638317108154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24499,
        "tokens": 12844531712,
        "learning_rate": 0.00010997364451926166,
        "gradient_norm": 0.43001142144203186,
        "train_loss": 3.0216095447540283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24500,
        "tokens": 12845056000,
        "learning_rate": 0.00010995704312228254,
        "gradient_norm": 0.424471378326416,
        "train_loss": 3.0259556770324707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24501,
        "tokens": 12845580288,
        "learning_rate": 0.00010994044420216115,
        "gradient_norm": 0.4220603108406067,
        "train_loss": 3.0139920711517334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24502,
        "tokens": 12846104576,
        "learning_rate": 0.00010992384775908442,
        "gradient_norm": 0.4481356143951416,
        "train_loss": 3.009505271911621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24503,
        "tokens": 12846628864,
        "learning_rate": 0.00010990725379323903,
        "gradient_norm": 0.42128103971481323,
        "train_loss": 3.022850513458252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24504,
        "tokens": 12847153152,
        "learning_rate": 0.00010989066230481195,
        "gradient_norm": 0.3893534541130066,
        "train_loss": 3.0417702198028564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24505,
        "tokens": 12847677440,
        "learning_rate": 0.00010987407329398976,
        "gradient_norm": 0.41057533025741577,
        "train_loss": 3.0052437782287598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24506,
        "tokens": 12848201728,
        "learning_rate": 0.00010985748676095933,
        "gradient_norm": 0.41906464099884033,
        "train_loss": 3.064182996749878,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24507,
        "tokens": 12848726016,
        "learning_rate": 0.00010984090270590725,
        "gradient_norm": 0.3815422058105469,
        "train_loss": 2.9986467361450195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24508,
        "tokens": 12849250304,
        "learning_rate": 0.00010982432112902032,
        "gradient_norm": 0.44195371866226196,
        "train_loss": 3.0839781761169434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24509,
        "tokens": 12849774592,
        "learning_rate": 0.000109807742030485,
        "gradient_norm": 0.4275842308998108,
        "train_loss": 3.055799961090088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24510,
        "tokens": 12850298880,
        "learning_rate": 0.00010979116541048813,
        "gradient_norm": 0.4546130299568176,
        "train_loss": 3.025493860244751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24511,
        "tokens": 12850823168,
        "learning_rate": 0.0001097745912692161,
        "gradient_norm": 0.3919566869735718,
        "train_loss": 3.0404582023620605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24512,
        "tokens": 12851347456,
        "learning_rate": 0.00010975801960685558,
        "gradient_norm": 0.4507599472999573,
        "train_loss": 3.041006088256836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24513,
        "tokens": 12851871744,
        "learning_rate": 0.00010974145042359315,
        "gradient_norm": 0.4479135274887085,
        "train_loss": 2.996610641479492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24514,
        "tokens": 12852396032,
        "learning_rate": 0.0001097248837196152,
        "gradient_norm": 0.4007345736026764,
        "train_loss": 3.0419461727142334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24515,
        "tokens": 12852920320,
        "learning_rate": 0.0001097083194951083,
        "gradient_norm": 0.4123047888278961,
        "train_loss": 2.989450454711914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24516,
        "tokens": 12853444608,
        "learning_rate": 0.00010969175775025881,
        "gradient_norm": 0.4043385088443756,
        "train_loss": 3.0339395999908447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24517,
        "tokens": 12853968896,
        "learning_rate": 0.0001096751984852533,
        "gradient_norm": 0.42357975244522095,
        "train_loss": 2.985564947128296,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24518,
        "tokens": 12854493184,
        "learning_rate": 0.00010965864170027798,
        "gradient_norm": 0.4310060739517212,
        "train_loss": 3.013740301132202,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24519,
        "tokens": 12855017472,
        "learning_rate": 0.00010964208739551936,
        "gradient_norm": 0.441327303647995,
        "train_loss": 3.0730202198028564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24520,
        "tokens": 12855541760,
        "learning_rate": 0.0001096255355711637,
        "gradient_norm": 0.4571336805820465,
        "train_loss": 2.9721944332122803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24521,
        "tokens": 12856066048,
        "learning_rate": 0.00010960898622739741,
        "gradient_norm": 0.45104673504829407,
        "train_loss": 3.108447313308716,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24522,
        "tokens": 12856590336,
        "learning_rate": 0.00010959243936440661,
        "gradient_norm": 0.4488932490348816,
        "train_loss": 3.0447943210601807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24523,
        "tokens": 12857114624,
        "learning_rate": 0.00010957589498237764,
        "gradient_norm": 0.39701056480407715,
        "train_loss": 3.020667552947998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24524,
        "tokens": 12857638912,
        "learning_rate": 0.00010955935308149686,
        "gradient_norm": 0.42761388421058655,
        "train_loss": 3.0370607376098633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24525,
        "tokens": 12858163200,
        "learning_rate": 0.00010954281366195022,
        "gradient_norm": 0.4799445867538452,
        "train_loss": 3.0203628540039062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24526,
        "tokens": 12858687488,
        "learning_rate": 0.00010952627672392414,
        "gradient_norm": 0.4324527084827423,
        "train_loss": 3.101637840270996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24527,
        "tokens": 12859211776,
        "learning_rate": 0.00010950974226760454,
        "gradient_norm": 0.5307525396347046,
        "train_loss": 3.0346508026123047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24528,
        "tokens": 12859736064,
        "learning_rate": 0.00010949321029317772,
        "gradient_norm": 0.41503918170928955,
        "train_loss": 3.0366768836975098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24529,
        "tokens": 12860260352,
        "learning_rate": 0.0001094766808008296,
        "gradient_norm": 0.4738706350326538,
        "train_loss": 3.0657780170440674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24530,
        "tokens": 12860784640,
        "learning_rate": 0.00010946015379074641,
        "gradient_norm": 0.4154617488384247,
        "train_loss": 3.073814630508423,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24531,
        "tokens": 12861308928,
        "learning_rate": 0.00010944362926311403,
        "gradient_norm": 0.41691821813583374,
        "train_loss": 3.041252851486206,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24532,
        "tokens": 12861833216,
        "learning_rate": 0.00010942710721811855,
        "gradient_norm": 0.44705846905708313,
        "train_loss": 3.0603904724121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24533,
        "tokens": 12862357504,
        "learning_rate": 0.00010941058765594598,
        "gradient_norm": 0.4280052185058594,
        "train_loss": 3.0077872276306152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24534,
        "tokens": 12862881792,
        "learning_rate": 0.00010939407057678215,
        "gradient_norm": 0.408285915851593,
        "train_loss": 3.035355806350708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24535,
        "tokens": 12863406080,
        "learning_rate": 0.00010937755598081311,
        "gradient_norm": 0.41925695538520813,
        "train_loss": 3.068509578704834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24536,
        "tokens": 12863930368,
        "learning_rate": 0.00010936104386822466,
        "gradient_norm": 0.4419304132461548,
        "train_loss": 3.055537462234497,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24537,
        "tokens": 12864454656,
        "learning_rate": 0.0001093445342392027,
        "gradient_norm": 0.4207289516925812,
        "train_loss": 2.974058151245117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24538,
        "tokens": 12864978944,
        "learning_rate": 0.00010932802709393303,
        "gradient_norm": 0.4043269753456116,
        "train_loss": 3.052729606628418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24539,
        "tokens": 12865503232,
        "learning_rate": 0.00010931152243260157,
        "gradient_norm": 0.45659053325653076,
        "train_loss": 3.047513484954834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24540,
        "tokens": 12866027520,
        "learning_rate": 0.00010929502025539394,
        "gradient_norm": 0.4296957850456238,
        "train_loss": 3.05059814453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24541,
        "tokens": 12866551808,
        "learning_rate": 0.00010927852056249604,
        "gradient_norm": 0.44512858986854553,
        "train_loss": 3.1733922958374023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24542,
        "tokens": 12867076096,
        "learning_rate": 0.00010926202335409344,
        "gradient_norm": 0.5065549612045288,
        "train_loss": 3.010798454284668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24543,
        "tokens": 12867600384,
        "learning_rate": 0.00010924552863037194,
        "gradient_norm": 0.43956202268600464,
        "train_loss": 3.0409412384033203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24544,
        "tokens": 12868124672,
        "learning_rate": 0.00010922903639151726,
        "gradient_norm": 0.4217631220817566,
        "train_loss": 3.010390281677246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24545,
        "tokens": 12868648960,
        "learning_rate": 0.00010921254663771491,
        "gradient_norm": 0.42335352301597595,
        "train_loss": 3.0249247550964355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24546,
        "tokens": 12869173248,
        "learning_rate": 0.00010919605936915067,
        "gradient_norm": 0.46625158190727234,
        "train_loss": 3.1077075004577637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24547,
        "tokens": 12869697536,
        "learning_rate": 0.00010917957458600991,
        "gradient_norm": 0.450581431388855,
        "train_loss": 3.001366138458252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24548,
        "tokens": 12870221824,
        "learning_rate": 0.00010916309228847836,
        "gradient_norm": 0.4283606708049774,
        "train_loss": 3.028550148010254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24549,
        "tokens": 12870746112,
        "learning_rate": 0.00010914661247674143,
        "gradient_norm": 0.4841141998767853,
        "train_loss": 3.0788331031799316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24550,
        "tokens": 12871270400,
        "learning_rate": 0.00010913013515098473,
        "gradient_norm": 0.4587104320526123,
        "train_loss": 3.03406023979187,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24551,
        "tokens": 12871794688,
        "learning_rate": 0.00010911366031139363,
        "gradient_norm": 0.41631612181663513,
        "train_loss": 2.992971897125244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24552,
        "tokens": 12872318976,
        "learning_rate": 0.00010909718795815364,
        "gradient_norm": 0.4456736445426941,
        "train_loss": 3.0226757526397705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24553,
        "tokens": 12872843264,
        "learning_rate": 0.00010908071809145021,
        "gradient_norm": 0.4338863790035248,
        "train_loss": 2.9946067333221436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24554,
        "tokens": 12873367552,
        "learning_rate": 0.00010906425071146862,
        "gradient_norm": 0.4366912543773651,
        "train_loss": 3.054896354675293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24555,
        "tokens": 12873891840,
        "learning_rate": 0.00010904778581839435,
        "gradient_norm": 0.43455907702445984,
        "train_loss": 2.977538585662842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24556,
        "tokens": 12874416128,
        "learning_rate": 0.00010903132341241262,
        "gradient_norm": 0.42041051387786865,
        "train_loss": 3.0059351921081543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24557,
        "tokens": 12874940416,
        "learning_rate": 0.00010901486349370888,
        "gradient_norm": 0.42706745862960815,
        "train_loss": 2.9942307472229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24558,
        "tokens": 12875464704,
        "learning_rate": 0.0001089984060624682,
        "gradient_norm": 0.4348675012588501,
        "train_loss": 3.039579153060913,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24559,
        "tokens": 12875988992,
        "learning_rate": 0.00010898195111887603,
        "gradient_norm": 0.4317665994167328,
        "train_loss": 2.9822659492492676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24560,
        "tokens": 12876513280,
        "learning_rate": 0.00010896549866311746,
        "gradient_norm": 0.5068842172622681,
        "train_loss": 3.0189409255981445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24561,
        "tokens": 12877037568,
        "learning_rate": 0.00010894904869537778,
        "gradient_norm": 0.40430521965026855,
        "train_loss": 3.044133186340332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24562,
        "tokens": 12877561856,
        "learning_rate": 0.00010893260121584202,
        "gradient_norm": 0.4198218882083893,
        "train_loss": 3.011507749557495,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24563,
        "tokens": 12878086144,
        "learning_rate": 0.00010891615622469542,
        "gradient_norm": 0.45323845744132996,
        "train_loss": 3.025905132293701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24564,
        "tokens": 12878610432,
        "learning_rate": 0.00010889971372212313,
        "gradient_norm": 0.41466251015663147,
        "train_loss": 3.0073962211608887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24565,
        "tokens": 12879134720,
        "learning_rate": 0.00010888327370831011,
        "gradient_norm": 0.4267783463001251,
        "train_loss": 3.064767360687256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24566,
        "tokens": 12879659008,
        "learning_rate": 0.00010886683618344155,
        "gradient_norm": 0.49620944261550903,
        "train_loss": 3.0106215476989746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24567,
        "tokens": 12880183296,
        "learning_rate": 0.00010885040114770231,
        "gradient_norm": 0.42353153228759766,
        "train_loss": 2.9909017086029053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24568,
        "tokens": 12880707584,
        "learning_rate": 0.00010883396860127756,
        "gradient_norm": 0.45038318634033203,
        "train_loss": 3.0532379150390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24569,
        "tokens": 12881231872,
        "learning_rate": 0.0001088175385443521,
        "gradient_norm": 0.4778716266155243,
        "train_loss": 3.136155128479004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24570,
        "tokens": 12881756160,
        "learning_rate": 0.00010880111097711104,
        "gradient_norm": 0.45021286606788635,
        "train_loss": 2.995049476623535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24571,
        "tokens": 12882280448,
        "learning_rate": 0.00010878468589973914,
        "gradient_norm": 0.5131439566612244,
        "train_loss": 3.0463995933532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24572,
        "tokens": 12882804736,
        "learning_rate": 0.00010876826331242132,
        "gradient_norm": 0.4087454378604889,
        "train_loss": 3.024747848510742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24573,
        "tokens": 12883329024,
        "learning_rate": 0.00010875184321534258,
        "gradient_norm": 0.477003812789917,
        "train_loss": 3.0116097927093506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24574,
        "tokens": 12883853312,
        "learning_rate": 0.00010873542560868753,
        "gradient_norm": 0.3993869423866272,
        "train_loss": 2.996457099914551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24575,
        "tokens": 12884377600,
        "learning_rate": 0.0001087190104926412,
        "gradient_norm": 0.585610568523407,
        "train_loss": 3.0246522426605225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24576,
        "tokens": 12884901888,
        "learning_rate": 0.00010870259786738811,
        "gradient_norm": 0.43381184339523315,
        "train_loss": 3.019092559814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24577,
        "tokens": 12885426176,
        "learning_rate": 0.00010868618773311324,
        "gradient_norm": 0.41110745072364807,
        "train_loss": 3.024808406829834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24578,
        "tokens": 12885950464,
        "learning_rate": 0.00010866978009000113,
        "gradient_norm": 0.5564326643943787,
        "train_loss": 3.0728321075439453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24579,
        "tokens": 12886474752,
        "learning_rate": 0.0001086533749382366,
        "gradient_norm": 0.43380892276763916,
        "train_loss": 3.00603985786438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24580,
        "tokens": 12886999040,
        "learning_rate": 0.00010863697227800418,
        "gradient_norm": 0.4330753982067108,
        "train_loss": 3.059659481048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24581,
        "tokens": 12887523328,
        "learning_rate": 0.00010862057210948866,
        "gradient_norm": 0.4192742705345154,
        "train_loss": 2.9700050354003906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24582,
        "tokens": 12888047616,
        "learning_rate": 0.00010860417443287447,
        "gradient_norm": 0.42014554142951965,
        "train_loss": 2.9749503135681152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24583,
        "tokens": 12888571904,
        "learning_rate": 0.00010858777924834629,
        "gradient_norm": 0.41926705837249756,
        "train_loss": 3.025378704071045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24584,
        "tokens": 12889096192,
        "learning_rate": 0.00010857138655608872,
        "gradient_norm": 0.5799753665924072,
        "train_loss": 3.0527851581573486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24585,
        "tokens": 12889620480,
        "learning_rate": 0.00010855499635628612,
        "gradient_norm": 0.40316155552864075,
        "train_loss": 3.02500319480896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24586,
        "tokens": 12890144768,
        "learning_rate": 0.00010853860864912319,
        "gradient_norm": 0.43154409527778625,
        "train_loss": 3.046328067779541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24587,
        "tokens": 12890669056,
        "learning_rate": 0.00010852222343478416,
        "gradient_norm": 0.4462583363056183,
        "train_loss": 3.01945161819458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24588,
        "tokens": 12891193344,
        "learning_rate": 0.00010850584071345368,
        "gradient_norm": 0.5681455731391907,
        "train_loss": 3.1428494453430176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24589,
        "tokens": 12891717632,
        "learning_rate": 0.000108489460485316,
        "gradient_norm": 0.5008750557899475,
        "train_loss": 2.975770950317383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24590,
        "tokens": 12892241920,
        "learning_rate": 0.0001084730827505556,
        "gradient_norm": 0.4146387577056885,
        "train_loss": 3.0290298461914062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24591,
        "tokens": 12892766208,
        "learning_rate": 0.00010845670750935676,
        "gradient_norm": 0.40989965200424194,
        "train_loss": 2.978261947631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24592,
        "tokens": 12893290496,
        "learning_rate": 0.00010844033476190381,
        "gradient_norm": 0.5075344443321228,
        "train_loss": 3.0520708560943604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24593,
        "tokens": 12893814784,
        "learning_rate": 0.00010842396450838116,
        "gradient_norm": 0.4319145679473877,
        "train_loss": 2.9877262115478516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24594,
        "tokens": 12894339072,
        "learning_rate": 0.0001084075967489729,
        "gradient_norm": 0.43290749192237854,
        "train_loss": 3.0665125846862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24595,
        "tokens": 12894863360,
        "learning_rate": 0.00010839123148386346,
        "gradient_norm": 0.4760393798351288,
        "train_loss": 3.016911506652832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24596,
        "tokens": 12895387648,
        "learning_rate": 0.00010837486871323685,
        "gradient_norm": 0.45141345262527466,
        "train_loss": 3.0870730876922607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24597,
        "tokens": 12895911936,
        "learning_rate": 0.00010835850843727746,
        "gradient_norm": 0.430650919675827,
        "train_loss": 3.0846877098083496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24598,
        "tokens": 12896436224,
        "learning_rate": 0.00010834215065616925,
        "gradient_norm": 0.4347972869873047,
        "train_loss": 3.066216468811035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24599,
        "tokens": 12896960512,
        "learning_rate": 0.00010832579537009653,
        "gradient_norm": 0.45584461092948914,
        "train_loss": 3.035365104675293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24600,
        "tokens": 12897484800,
        "learning_rate": 0.00010830944257924323,
        "gradient_norm": 0.4189282953739166,
        "train_loss": 3.0255818367004395,
        "val_loss": 2.9825096130371094,
        "hellaswag_acc": 0.28500300645828247,
        "hellaswag_acc_norm": 0.298048198223114
    },
    {
        "step": 24601,
        "tokens": 12898009088,
        "learning_rate": 0.00010829309228379354,
        "gradient_norm": 0.41670605540275574,
        "train_loss": 2.9893081188201904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24602,
        "tokens": 12898533376,
        "learning_rate": 0.00010827674448393142,
        "gradient_norm": 0.431435227394104,
        "train_loss": 3.0455169677734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24603,
        "tokens": 12899057664,
        "learning_rate": 0.000108260399179841,
        "gradient_norm": 0.42407310009002686,
        "train_loss": 3.050208568572998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24604,
        "tokens": 12899581952,
        "learning_rate": 0.00010824405637170608,
        "gradient_norm": 0.4694368839263916,
        "train_loss": 3.138227939605713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24605,
        "tokens": 12900106240,
        "learning_rate": 0.00010822771605971084,
        "gradient_norm": 0.3984721899032593,
        "train_loss": 3.038792371749878,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24606,
        "tokens": 12900630528,
        "learning_rate": 0.00010821137824403902,
        "gradient_norm": 0.4191940128803253,
        "train_loss": 3.011565685272217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24607,
        "tokens": 12901154816,
        "learning_rate": 0.00010819504292487468,
        "gradient_norm": 0.4092137813568115,
        "train_loss": 2.9975156784057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24608,
        "tokens": 12901679104,
        "learning_rate": 0.00010817871010240156,
        "gradient_norm": 0.4126277565956116,
        "train_loss": 2.972423553466797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24609,
        "tokens": 12902203392,
        "learning_rate": 0.00010816237977680362,
        "gradient_norm": 0.38948291540145874,
        "train_loss": 2.984696865081787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24610,
        "tokens": 12902727680,
        "learning_rate": 0.00010814605194826454,
        "gradient_norm": 0.5110501050949097,
        "train_loss": 3.160024642944336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24611,
        "tokens": 12903251968,
        "learning_rate": 0.00010812972661696828,
        "gradient_norm": 0.420893132686615,
        "train_loss": 3.02659273147583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24612,
        "tokens": 12903776256,
        "learning_rate": 0.00010811340378309844,
        "gradient_norm": 0.4818780720233917,
        "train_loss": 2.9973793029785156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24613,
        "tokens": 12904300544,
        "learning_rate": 0.00010809708344683892,
        "gradient_norm": 0.430601567029953,
        "train_loss": 3.082655429840088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24614,
        "tokens": 12904824832,
        "learning_rate": 0.00010808076560837326,
        "gradient_norm": 0.5027168393135071,
        "train_loss": 3.050159454345703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24615,
        "tokens": 12905349120,
        "learning_rate": 0.00010806445026788523,
        "gradient_norm": 0.3829894959926605,
        "train_loss": 3.0626578330993652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24616,
        "tokens": 12905873408,
        "learning_rate": 0.00010804813742555845,
        "gradient_norm": 0.45859119296073914,
        "train_loss": 3.0624587535858154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24617,
        "tokens": 12906397696,
        "learning_rate": 0.0001080318270815766,
        "gradient_norm": 0.4861023724079132,
        "train_loss": 3.0640950202941895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24618,
        "tokens": 12906921984,
        "learning_rate": 0.00010801551923612319,
        "gradient_norm": 0.39688754081726074,
        "train_loss": 3.021233558654785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24619,
        "tokens": 12907446272,
        "learning_rate": 0.00010799921388938187,
        "gradient_norm": 0.484158992767334,
        "train_loss": 2.9725120067596436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24620,
        "tokens": 12907970560,
        "learning_rate": 0.00010798291104153605,
        "gradient_norm": 0.43347516655921936,
        "train_loss": 2.9861066341400146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24621,
        "tokens": 12908494848,
        "learning_rate": 0.00010796661069276936,
        "gradient_norm": 0.46669742465019226,
        "train_loss": 2.996487617492676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24622,
        "tokens": 12909019136,
        "learning_rate": 0.0001079503128432652,
        "gradient_norm": 0.3978690803050995,
        "train_loss": 3.0296859741210938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24623,
        "tokens": 12909543424,
        "learning_rate": 0.00010793401749320709,
        "gradient_norm": 0.4703752398490906,
        "train_loss": 2.984976291656494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24624,
        "tokens": 12910067712,
        "learning_rate": 0.00010791772464277847,
        "gradient_norm": 0.4064757227897644,
        "train_loss": 3.012120246887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24625,
        "tokens": 12910592000,
        "learning_rate": 0.00010790143429216263,
        "gradient_norm": 0.42779454588890076,
        "train_loss": 2.9574055671691895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24626,
        "tokens": 12911116288,
        "learning_rate": 0.00010788514644154304,
        "gradient_norm": 0.41377097368240356,
        "train_loss": 3.060607433319092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24627,
        "tokens": 12911640576,
        "learning_rate": 0.00010786886109110297,
        "gradient_norm": 0.45603853464126587,
        "train_loss": 3.0340375900268555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24628,
        "tokens": 12912164864,
        "learning_rate": 0.0001078525782410258,
        "gradient_norm": 0.461312472820282,
        "train_loss": 3.029057025909424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24629,
        "tokens": 12912689152,
        "learning_rate": 0.0001078362978914947,
        "gradient_norm": 0.4163082540035248,
        "train_loss": 3.0470566749572754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24630,
        "tokens": 12913213440,
        "learning_rate": 0.0001078200200426931,
        "gradient_norm": 0.4837515354156494,
        "train_loss": 3.037862777709961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24631,
        "tokens": 12913737728,
        "learning_rate": 0.00010780374469480406,
        "gradient_norm": 0.3982774019241333,
        "train_loss": 2.9806556701660156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24632,
        "tokens": 12914262016,
        "learning_rate": 0.00010778747184801083,
        "gradient_norm": 0.4394114315509796,
        "train_loss": 3.0419204235076904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24633,
        "tokens": 12914786304,
        "learning_rate": 0.00010777120150249668,
        "gradient_norm": 0.41945287585258484,
        "train_loss": 3.063429117202759,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24634,
        "tokens": 12915310592,
        "learning_rate": 0.00010775493365844461,
        "gradient_norm": 0.44608667492866516,
        "train_loss": 3.0360913276672363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24635,
        "tokens": 12915834880,
        "learning_rate": 0.00010773866831603784,
        "gradient_norm": 0.49419698119163513,
        "train_loss": 3.051675319671631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24636,
        "tokens": 12916359168,
        "learning_rate": 0.00010772240547545937,
        "gradient_norm": 0.40174055099487305,
        "train_loss": 2.968761444091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24637,
        "tokens": 12916883456,
        "learning_rate": 0.00010770614513689236,
        "gradient_norm": 0.44719499349594116,
        "train_loss": 3.029423713684082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24638,
        "tokens": 12917407744,
        "learning_rate": 0.00010768988730051973,
        "gradient_norm": 0.4521782398223877,
        "train_loss": 2.9735710620880127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24639,
        "tokens": 12917932032,
        "learning_rate": 0.00010767363196652457,
        "gradient_norm": 0.517065167427063,
        "train_loss": 3.0988106727600098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24640,
        "tokens": 12918456320,
        "learning_rate": 0.0001076573791350898,
        "gradient_norm": 0.5389151573181152,
        "train_loss": 3.032491683959961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24641,
        "tokens": 12918980608,
        "learning_rate": 0.00010764112880639842,
        "gradient_norm": 0.4749230146408081,
        "train_loss": 2.9983272552490234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24642,
        "tokens": 12919504896,
        "learning_rate": 0.00010762488098063322,
        "gradient_norm": 0.4344092607498169,
        "train_loss": 2.9825034141540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24643,
        "tokens": 12920029184,
        "learning_rate": 0.00010760863565797724,
        "gradient_norm": 0.44213512539863586,
        "train_loss": 2.9975666999816895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24644,
        "tokens": 12920553472,
        "learning_rate": 0.0001075923928386133,
        "gradient_norm": 0.370840847492218,
        "train_loss": 2.9802985191345215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24645,
        "tokens": 12921077760,
        "learning_rate": 0.0001075761525227242,
        "gradient_norm": 0.40859535336494446,
        "train_loss": 3.0487422943115234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24646,
        "tokens": 12921602048,
        "learning_rate": 0.00010755991471049278,
        "gradient_norm": 0.4061088562011719,
        "train_loss": 2.987797737121582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24647,
        "tokens": 12922126336,
        "learning_rate": 0.00010754367940210178,
        "gradient_norm": 0.38959991931915283,
        "train_loss": 3.0177865028381348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24648,
        "tokens": 12922650624,
        "learning_rate": 0.000107527446597734,
        "gradient_norm": 0.4318869411945343,
        "train_loss": 3.0196533203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24649,
        "tokens": 12923174912,
        "learning_rate": 0.00010751121629757206,
        "gradient_norm": 0.43130478262901306,
        "train_loss": 3.044607162475586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24650,
        "tokens": 12923699200,
        "learning_rate": 0.00010749498850179879,
        "gradient_norm": 0.4159542918205261,
        "train_loss": 3.034785747528076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24651,
        "tokens": 12924223488,
        "learning_rate": 0.00010747876321059673,
        "gradient_norm": 0.40871384739875793,
        "train_loss": 3.009955644607544,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24652,
        "tokens": 12924747776,
        "learning_rate": 0.00010746254042414856,
        "gradient_norm": 0.3760005533695221,
        "train_loss": 3.0266332626342773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24653,
        "tokens": 12925272064,
        "learning_rate": 0.00010744632014263697,
        "gradient_norm": 0.4197617471218109,
        "train_loss": 3.052431583404541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24654,
        "tokens": 12925796352,
        "learning_rate": 0.00010743010236624442,
        "gradient_norm": 0.4067268371582031,
        "train_loss": 2.9701192378997803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24655,
        "tokens": 12926320640,
        "learning_rate": 0.00010741388709515354,
        "gradient_norm": 0.40075576305389404,
        "train_loss": 3.032320261001587,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24656,
        "tokens": 12926844928,
        "learning_rate": 0.00010739767432954678,
        "gradient_norm": 0.5218629837036133,
        "train_loss": 3.0509679317474365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24657,
        "tokens": 12927369216,
        "learning_rate": 0.00010738146406960672,
        "gradient_norm": 0.4279903769493103,
        "train_loss": 2.999607563018799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24658,
        "tokens": 12927893504,
        "learning_rate": 0.00010736525631551573,
        "gradient_norm": 0.4319463074207306,
        "train_loss": 3.006002426147461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24659,
        "tokens": 12928417792,
        "learning_rate": 0.00010734905106745638,
        "gradient_norm": 0.3836834728717804,
        "train_loss": 3.025700569152832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24660,
        "tokens": 12928942080,
        "learning_rate": 0.00010733284832561092,
        "gradient_norm": 0.4524317681789398,
        "train_loss": 3.028226375579834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24661,
        "tokens": 12929466368,
        "learning_rate": 0.00010731664809016187,
        "gradient_norm": 0.4120807945728302,
        "train_loss": 3.017458915710449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24662,
        "tokens": 12929990656,
        "learning_rate": 0.00010730045036129148,
        "gradient_norm": 0.3913784623146057,
        "train_loss": 3.060445547103882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24663,
        "tokens": 12930514944,
        "learning_rate": 0.00010728425513918213,
        "gradient_norm": 0.43694865703582764,
        "train_loss": 3.048032760620117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24664,
        "tokens": 12931039232,
        "learning_rate": 0.00010726806242401617,
        "gradient_norm": 0.4269953966140747,
        "train_loss": 3.010470390319824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24665,
        "tokens": 12931563520,
        "learning_rate": 0.00010725187221597571,
        "gradient_norm": 0.4074495732784271,
        "train_loss": 3.043912410736084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24666,
        "tokens": 12932087808,
        "learning_rate": 0.00010723568451524319,
        "gradient_norm": 0.43871137499809265,
        "train_loss": 2.992631435394287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24667,
        "tokens": 12932612096,
        "learning_rate": 0.00010721949932200066,
        "gradient_norm": 0.3963674306869507,
        "train_loss": 3.0386219024658203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24668,
        "tokens": 12933136384,
        "learning_rate": 0.00010720331663643045,
        "gradient_norm": 0.4480322599411011,
        "train_loss": 3.0385193824768066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24669,
        "tokens": 12933660672,
        "learning_rate": 0.00010718713645871454,
        "gradient_norm": 0.4099239706993103,
        "train_loss": 3.047562599182129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24670,
        "tokens": 12934184960,
        "learning_rate": 0.00010717095878903522,
        "gradient_norm": 0.44144967198371887,
        "train_loss": 3.0679690837860107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24671,
        "tokens": 12934709248,
        "learning_rate": 0.00010715478362757446,
        "gradient_norm": 0.4434751570224762,
        "train_loss": 3.054532766342163,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24672,
        "tokens": 12935233536,
        "learning_rate": 0.00010713861097451439,
        "gradient_norm": 0.4732726216316223,
        "train_loss": 3.0226731300354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24673,
        "tokens": 12935757824,
        "learning_rate": 0.00010712244083003713,
        "gradient_norm": 0.39716559648513794,
        "train_loss": 2.9968276023864746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24674,
        "tokens": 12936282112,
        "learning_rate": 0.00010710627319432457,
        "gradient_norm": 0.43493252992630005,
        "train_loss": 3.057936191558838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24675,
        "tokens": 12936806400,
        "learning_rate": 0.00010709010806755879,
        "gradient_norm": 0.4281100034713745,
        "train_loss": 3.033604621887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24676,
        "tokens": 12937330688,
        "learning_rate": 0.00010707394544992165,
        "gradient_norm": 0.4562627673149109,
        "train_loss": 3.063722848892212,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24677,
        "tokens": 12937854976,
        "learning_rate": 0.00010705778534159522,
        "gradient_norm": 0.4315442740917206,
        "train_loss": 2.9710464477539062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24678,
        "tokens": 12938379264,
        "learning_rate": 0.00010704162774276125,
        "gradient_norm": 0.4636472165584564,
        "train_loss": 3.0430917739868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24679,
        "tokens": 12938903552,
        "learning_rate": 0.00010702547265360172,
        "gradient_norm": 0.39447513222694397,
        "train_loss": 3.0980937480926514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24680,
        "tokens": 12939427840,
        "learning_rate": 0.0001070093200742984,
        "gradient_norm": 0.39143428206443787,
        "train_loss": 3.022580623626709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24681,
        "tokens": 12939952128,
        "learning_rate": 0.00010699317000503321,
        "gradient_norm": 0.43312960863113403,
        "train_loss": 3.0057249069213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24682,
        "tokens": 12940476416,
        "learning_rate": 0.00010697702244598783,
        "gradient_norm": 0.4894939661026001,
        "train_loss": 3.0762860774993896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24683,
        "tokens": 12941000704,
        "learning_rate": 0.00010696087739734405,
        "gradient_norm": 0.45287954807281494,
        "train_loss": 2.9971766471862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24684,
        "tokens": 12941524992,
        "learning_rate": 0.00010694473485928368,
        "gradient_norm": 0.5006136894226074,
        "train_loss": 3.0186848640441895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24685,
        "tokens": 12942049280,
        "learning_rate": 0.0001069285948319883,
        "gradient_norm": 0.43565964698791504,
        "train_loss": 3.0409488677978516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24686,
        "tokens": 12942573568,
        "learning_rate": 0.00010691245731563973,
        "gradient_norm": 0.45100849866867065,
        "train_loss": 2.99114990234375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24687,
        "tokens": 12943097856,
        "learning_rate": 0.00010689632231041947,
        "gradient_norm": 0.47477248311042786,
        "train_loss": 3.0226974487304688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24688,
        "tokens": 12943622144,
        "learning_rate": 0.00010688018981650926,
        "gradient_norm": 0.44187286496162415,
        "train_loss": 3.0287892818450928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24689,
        "tokens": 12944146432,
        "learning_rate": 0.00010686405983409059,
        "gradient_norm": 0.41665926575660706,
        "train_loss": 3.0309505462646484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24690,
        "tokens": 12944670720,
        "learning_rate": 0.00010684793236334513,
        "gradient_norm": 0.45604071021080017,
        "train_loss": 3.0172290802001953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24691,
        "tokens": 12945195008,
        "learning_rate": 0.00010683180740445428,
        "gradient_norm": 0.4183390438556671,
        "train_loss": 3.0374627113342285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24692,
        "tokens": 12945719296,
        "learning_rate": 0.00010681568495759966,
        "gradient_norm": 0.49897056818008423,
        "train_loss": 3.070357322692871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24693,
        "tokens": 12946243584,
        "learning_rate": 0.00010679956502296274,
        "gradient_norm": 0.4111327528953552,
        "train_loss": 3.028024196624756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24694,
        "tokens": 12946767872,
        "learning_rate": 0.00010678344760072489,
        "gradient_norm": 0.6023786067962646,
        "train_loss": 3.066314458847046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24695,
        "tokens": 12947292160,
        "learning_rate": 0.00010676733269106768,
        "gradient_norm": 0.41028815507888794,
        "train_loss": 2.985976219177246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24696,
        "tokens": 12947816448,
        "learning_rate": 0.0001067512202941723,
        "gradient_norm": 0.4897727966308594,
        "train_loss": 3.013597249984741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24697,
        "tokens": 12948340736,
        "learning_rate": 0.0001067351104102203,
        "gradient_norm": 0.43117353320121765,
        "train_loss": 2.9912335872650146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24698,
        "tokens": 12948865024,
        "learning_rate": 0.00010671900303939287,
        "gradient_norm": 0.46557047963142395,
        "train_loss": 3.0278403759002686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24699,
        "tokens": 12949389312,
        "learning_rate": 0.00010670289818187147,
        "gradient_norm": 0.4329109787940979,
        "train_loss": 2.998891830444336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24700,
        "tokens": 12949913600,
        "learning_rate": 0.00010668679583783721,
        "gradient_norm": 0.40771085023880005,
        "train_loss": 3.0076797008514404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24701,
        "tokens": 12950437888,
        "learning_rate": 0.00010667069600747153,
        "gradient_norm": 0.44715574383735657,
        "train_loss": 3.0112812519073486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24702,
        "tokens": 12950962176,
        "learning_rate": 0.00010665459869095545,
        "gradient_norm": 0.3961777687072754,
        "train_loss": 3.021806240081787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24703,
        "tokens": 12951486464,
        "learning_rate": 0.00010663850388847036,
        "gradient_norm": 0.41444075107574463,
        "train_loss": 3.065300464630127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24704,
        "tokens": 12952010752,
        "learning_rate": 0.00010662241160019727,
        "gradient_norm": 0.4300101399421692,
        "train_loss": 3.0673632621765137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24705,
        "tokens": 12952535040,
        "learning_rate": 0.00010660632182631743,
        "gradient_norm": 0.40468937158584595,
        "train_loss": 3.012735366821289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24706,
        "tokens": 12953059328,
        "learning_rate": 0.00010659023456701185,
        "gradient_norm": 0.4292565882205963,
        "train_loss": 3.0418214797973633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24707,
        "tokens": 12953583616,
        "learning_rate": 0.00010657414982246174,
        "gradient_norm": 0.45275062322616577,
        "train_loss": 3.0365641117095947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24708,
        "tokens": 12954107904,
        "learning_rate": 0.00010655806759284799,
        "gradient_norm": 0.44946396350860596,
        "train_loss": 2.9898343086242676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24709,
        "tokens": 12954632192,
        "learning_rate": 0.00010654198787835183,
        "gradient_norm": 0.42728346586227417,
        "train_loss": 3.0114874839782715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24710,
        "tokens": 12955156480,
        "learning_rate": 0.00010652591067915405,
        "gradient_norm": 0.39781057834625244,
        "train_loss": 3.014319896697998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24711,
        "tokens": 12955680768,
        "learning_rate": 0.00010650983599543578,
        "gradient_norm": 0.5528047680854797,
        "train_loss": 3.0864148139953613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24712,
        "tokens": 12956205056,
        "learning_rate": 0.00010649376382737781,
        "gradient_norm": 0.464988648891449,
        "train_loss": 3.0240254402160645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24713,
        "tokens": 12956729344,
        "learning_rate": 0.00010647769417516125,
        "gradient_norm": 0.4934622049331665,
        "train_loss": 2.991875171661377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24714,
        "tokens": 12957253632,
        "learning_rate": 0.00010646162703896677,
        "gradient_norm": 0.44283527135849,
        "train_loss": 3.0444836616516113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24715,
        "tokens": 12957777920,
        "learning_rate": 0.00010644556241897537,
        "gradient_norm": 0.47515806555747986,
        "train_loss": 3.009888172149658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24716,
        "tokens": 12958302208,
        "learning_rate": 0.00010642950031536782,
        "gradient_norm": 0.45951664447784424,
        "train_loss": 3.0224051475524902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24717,
        "tokens": 12958826496,
        "learning_rate": 0.00010641344072832496,
        "gradient_norm": 0.4433490037918091,
        "train_loss": 3.0727767944335938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24718,
        "tokens": 12959350784,
        "learning_rate": 0.00010639738365802747,
        "gradient_norm": 0.40775611996650696,
        "train_loss": 2.9655096530914307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24719,
        "tokens": 12959875072,
        "learning_rate": 0.00010638132910465624,
        "gradient_norm": 0.39330416917800903,
        "train_loss": 3.020066261291504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24720,
        "tokens": 12960399360,
        "learning_rate": 0.00010636527706839183,
        "gradient_norm": 0.4319457709789276,
        "train_loss": 2.9957897663116455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24721,
        "tokens": 12960923648,
        "learning_rate": 0.00010634922754941496,
        "gradient_norm": 0.39806002378463745,
        "train_loss": 3.002239227294922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24722,
        "tokens": 12961447936,
        "learning_rate": 0.00010633318054790642,
        "gradient_norm": 0.441400945186615,
        "train_loss": 3.0785763263702393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24723,
        "tokens": 12961972224,
        "learning_rate": 0.00010631713606404666,
        "gradient_norm": 0.4329921305179596,
        "train_loss": 3.009425163269043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24724,
        "tokens": 12962496512,
        "learning_rate": 0.00010630109409801643,
        "gradient_norm": 0.4309341609477997,
        "train_loss": 3.0149054527282715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24725,
        "tokens": 12963020800,
        "learning_rate": 0.00010628505464999619,
        "gradient_norm": 0.4404900074005127,
        "train_loss": 2.9993557929992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24726,
        "tokens": 12963545088,
        "learning_rate": 0.0001062690177201666,
        "gradient_norm": 0.4209598898887634,
        "train_loss": 2.9950146675109863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24727,
        "tokens": 12964069376,
        "learning_rate": 0.000106252983308708,
        "gradient_norm": 0.4155581593513489,
        "train_loss": 3.006044387817383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24728,
        "tokens": 12964593664,
        "learning_rate": 0.00010623695141580106,
        "gradient_norm": 0.4468131959438324,
        "train_loss": 3.029329299926758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24729,
        "tokens": 12965117952,
        "learning_rate": 0.0001062209220416261,
        "gradient_norm": 0.4275021255016327,
        "train_loss": 3.1055617332458496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24730,
        "tokens": 12965642240,
        "learning_rate": 0.00010620489518636368,
        "gradient_norm": 0.43497005105018616,
        "train_loss": 3.0350937843322754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24731,
        "tokens": 12966166528,
        "learning_rate": 0.00010618887085019405,
        "gradient_norm": 0.38965877890586853,
        "train_loss": 2.9923009872436523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24732,
        "tokens": 12966690816,
        "learning_rate": 0.00010617284903329766,
        "gradient_norm": 0.42181986570358276,
        "train_loss": 3.0790770053863525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24733,
        "tokens": 12967215104,
        "learning_rate": 0.00010615682973585494,
        "gradient_norm": 0.4066830575466156,
        "train_loss": 2.985098361968994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24734,
        "tokens": 12967739392,
        "learning_rate": 0.00010614081295804608,
        "gradient_norm": 0.4190083146095276,
        "train_loss": 3.047163486480713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24735,
        "tokens": 12968263680,
        "learning_rate": 0.00010612479870005148,
        "gradient_norm": 0.4101947546005249,
        "train_loss": 3.0401768684387207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24736,
        "tokens": 12968787968,
        "learning_rate": 0.00010610878696205124,
        "gradient_norm": 0.4240237772464752,
        "train_loss": 2.9924867153167725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24737,
        "tokens": 12969312256,
        "learning_rate": 0.0001060927777442258,
        "gradient_norm": 0.3851035237312317,
        "train_loss": 2.967885732650757,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24738,
        "tokens": 12969836544,
        "learning_rate": 0.00010607677104675515,
        "gradient_norm": 0.3833223879337311,
        "train_loss": 3.0307424068450928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24739,
        "tokens": 12970360832,
        "learning_rate": 0.00010606076686981965,
        "gradient_norm": 0.4025496542453766,
        "train_loss": 3.018665313720703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24740,
        "tokens": 12970885120,
        "learning_rate": 0.00010604476521359932,
        "gradient_norm": 0.4022442102432251,
        "train_loss": 3.0002870559692383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24741,
        "tokens": 12971409408,
        "learning_rate": 0.00010602876607827428,
        "gradient_norm": 0.3997960686683655,
        "train_loss": 3.043635845184326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24742,
        "tokens": 12971933696,
        "learning_rate": 0.0001060127694640248,
        "gradient_norm": 0.4094105660915375,
        "train_loss": 2.9889962673187256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24743,
        "tokens": 12972457984,
        "learning_rate": 0.0001059967753710307,
        "gradient_norm": 0.3970414698123932,
        "train_loss": 3.024533271789551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24744,
        "tokens": 12972982272,
        "learning_rate": 0.00010598078379947217,
        "gradient_norm": 0.41758793592453003,
        "train_loss": 3.035647392272949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24745,
        "tokens": 12973506560,
        "learning_rate": 0.00010596479474952913,
        "gradient_norm": 0.40894830226898193,
        "train_loss": 3.0197932720184326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24746,
        "tokens": 12974030848,
        "learning_rate": 0.00010594880822138164,
        "gradient_norm": 0.39098024368286133,
        "train_loss": 3.0127179622650146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24747,
        "tokens": 12974555136,
        "learning_rate": 0.00010593282421520953,
        "gradient_norm": 0.4619034230709076,
        "train_loss": 3.077871561050415,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24748,
        "tokens": 12975079424,
        "learning_rate": 0.00010591684273119289,
        "gradient_norm": 0.4534602463245392,
        "train_loss": 3.006396770477295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24749,
        "tokens": 12975603712,
        "learning_rate": 0.0001059008637695114,
        "gradient_norm": 0.4847372770309448,
        "train_loss": 3.021876335144043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24750,
        "tokens": 12976128000,
        "learning_rate": 0.00010588488733034512,
        "gradient_norm": 0.5633562803268433,
        "train_loss": 3.004906177520752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24751,
        "tokens": 12976652288,
        "learning_rate": 0.00010586891341387374,
        "gradient_norm": 0.44925224781036377,
        "train_loss": 3.0787134170532227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24752,
        "tokens": 12977176576,
        "learning_rate": 0.00010585294202027711,
        "gradient_norm": 0.4310087263584137,
        "train_loss": 2.987194299697876,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24753,
        "tokens": 12977700864,
        "learning_rate": 0.00010583697314973513,
        "gradient_norm": 0.4473102390766144,
        "train_loss": 3.048468828201294,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24754,
        "tokens": 12978225152,
        "learning_rate": 0.00010582100680242736,
        "gradient_norm": 0.418040931224823,
        "train_loss": 3.0299859046936035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24755,
        "tokens": 12978749440,
        "learning_rate": 0.00010580504297853365,
        "gradient_norm": 0.4378851354122162,
        "train_loss": 3.0307865142822266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24756,
        "tokens": 12979273728,
        "learning_rate": 0.00010578908167823358,
        "gradient_norm": 0.4656117558479309,
        "train_loss": 3.0399680137634277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24757,
        "tokens": 12979798016,
        "learning_rate": 0.00010577312290170696,
        "gradient_norm": 0.40720221400260925,
        "train_loss": 2.978537082672119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24758,
        "tokens": 12980322304,
        "learning_rate": 0.00010575716664913329,
        "gradient_norm": 0.450813353061676,
        "train_loss": 3.0552449226379395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24759,
        "tokens": 12980846592,
        "learning_rate": 0.0001057412129206923,
        "gradient_norm": 0.4668816030025482,
        "train_loss": 3.062983512878418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24760,
        "tokens": 12981370880,
        "learning_rate": 0.00010572526171656343,
        "gradient_norm": 0.36703553795814514,
        "train_loss": 3.0266709327697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24761,
        "tokens": 12981895168,
        "learning_rate": 0.00010570931303692632,
        "gradient_norm": 0.41027936339378357,
        "train_loss": 3.051372528076172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24762,
        "tokens": 12982419456,
        "learning_rate": 0.00010569336688196054,
        "gradient_norm": 0.40078601241111755,
        "train_loss": 3.0072851181030273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24763,
        "tokens": 12982943744,
        "learning_rate": 0.00010567742325184542,
        "gradient_norm": 0.41719886660575867,
        "train_loss": 3.0032958984375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24764,
        "tokens": 12983468032,
        "learning_rate": 0.00010566148214676062,
        "gradient_norm": 0.40889838337898254,
        "train_loss": 3.0238776206970215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24765,
        "tokens": 12983992320,
        "learning_rate": 0.00010564554356688545,
        "gradient_norm": 0.42715924978256226,
        "train_loss": 3.064812183380127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24766,
        "tokens": 12984516608,
        "learning_rate": 0.00010562960751239936,
        "gradient_norm": 0.4316897988319397,
        "train_loss": 3.0174198150634766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24767,
        "tokens": 12985040896,
        "learning_rate": 0.0001056136739834817,
        "gradient_norm": 0.43809494376182556,
        "train_loss": 3.0106582641601562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24768,
        "tokens": 12985565184,
        "learning_rate": 0.00010559774298031188,
        "gradient_norm": 0.39880236983299255,
        "train_loss": 2.98331356048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24769,
        "tokens": 12986089472,
        "learning_rate": 0.00010558181450306913,
        "gradient_norm": 0.39671266078948975,
        "train_loss": 3.003312110900879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24770,
        "tokens": 12986613760,
        "learning_rate": 0.00010556588855193289,
        "gradient_norm": 0.4440343677997589,
        "train_loss": 2.991274118423462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24771,
        "tokens": 12987138048,
        "learning_rate": 0.00010554996512708226,
        "gradient_norm": 0.40811634063720703,
        "train_loss": 2.9498138427734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24772,
        "tokens": 12987662336,
        "learning_rate": 0.00010553404422869656,
        "gradient_norm": 0.4368884861469269,
        "train_loss": 3.0386581420898438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24773,
        "tokens": 12988186624,
        "learning_rate": 0.00010551812585695503,
        "gradient_norm": 0.36162135004997253,
        "train_loss": 2.9978699684143066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24774,
        "tokens": 12988710912,
        "learning_rate": 0.00010550221001203681,
        "gradient_norm": 0.4715929627418518,
        "train_loss": 3.015651226043701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24775,
        "tokens": 12989235200,
        "learning_rate": 0.00010548629669412105,
        "gradient_norm": 0.3940822184085846,
        "train_loss": 2.9731438159942627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24776,
        "tokens": 12989759488,
        "learning_rate": 0.00010547038590338687,
        "gradient_norm": 0.42150184512138367,
        "train_loss": 3.0556797981262207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24777,
        "tokens": 12990283776,
        "learning_rate": 0.00010545447764001345,
        "gradient_norm": 0.37516817450523376,
        "train_loss": 2.950284481048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24778,
        "tokens": 12990808064,
        "learning_rate": 0.00010543857190417968,
        "gradient_norm": 0.4109875559806824,
        "train_loss": 2.974182605743408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24779,
        "tokens": 12991332352,
        "learning_rate": 0.00010542266869606481,
        "gradient_norm": 0.4742480516433716,
        "train_loss": 3.007051944732666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24780,
        "tokens": 12991856640,
        "learning_rate": 0.0001054067680158477,
        "gradient_norm": 0.42760372161865234,
        "train_loss": 3.0166096687316895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24781,
        "tokens": 12992380928,
        "learning_rate": 0.00010539086986370733,
        "gradient_norm": 0.4434947371482849,
        "train_loss": 3.020120620727539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24782,
        "tokens": 12992905216,
        "learning_rate": 0.00010537497423982278,
        "gradient_norm": 0.4150398075580597,
        "train_loss": 3.0321884155273438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24783,
        "tokens": 12993429504,
        "learning_rate": 0.00010535908114437287,
        "gradient_norm": 0.42434123158454895,
        "train_loss": 3.0348944664001465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24784,
        "tokens": 12993953792,
        "learning_rate": 0.00010534319057753654,
        "gradient_norm": 0.43858325481414795,
        "train_loss": 3.0550107955932617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24785,
        "tokens": 12994478080,
        "learning_rate": 0.00010532730253949262,
        "gradient_norm": 0.4194589853286743,
        "train_loss": 3.0022010803222656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24786,
        "tokens": 12995002368,
        "learning_rate": 0.00010531141703042001,
        "gradient_norm": 0.4304530918598175,
        "train_loss": 3.0633463859558105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24787,
        "tokens": 12995526656,
        "learning_rate": 0.00010529553405049742,
        "gradient_norm": 0.44310620427131653,
        "train_loss": 3.012058973312378,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24788,
        "tokens": 12996050944,
        "learning_rate": 0.00010527965359990375,
        "gradient_norm": 0.3725268244743347,
        "train_loss": 3.02858304977417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24789,
        "tokens": 12996575232,
        "learning_rate": 0.00010526377567881764,
        "gradient_norm": 0.4488757848739624,
        "train_loss": 3.0710201263427734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24790,
        "tokens": 12997099520,
        "learning_rate": 0.00010524790028741796,
        "gradient_norm": 0.7181700468063354,
        "train_loss": 3.146510601043701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24791,
        "tokens": 12997623808,
        "learning_rate": 0.00010523202742588323,
        "gradient_norm": 0.558255136013031,
        "train_loss": 3.0361642837524414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24792,
        "tokens": 12998148096,
        "learning_rate": 0.00010521615709439224,
        "gradient_norm": 0.49083319306373596,
        "train_loss": 2.990126132965088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24793,
        "tokens": 12998672384,
        "learning_rate": 0.00010520028929312367,
        "gradient_norm": 0.4738796055316925,
        "train_loss": 3.0482969284057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24794,
        "tokens": 12999196672,
        "learning_rate": 0.00010518442402225596,
        "gradient_norm": 0.4469524323940277,
        "train_loss": 3.0171327590942383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24795,
        "tokens": 12999720960,
        "learning_rate": 0.00010516856128196789,
        "gradient_norm": 0.4037106931209564,
        "train_loss": 2.9641852378845215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24796,
        "tokens": 13000245248,
        "learning_rate": 0.00010515270107243788,
        "gradient_norm": 0.45450958609580994,
        "train_loss": 3.0709500312805176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24797,
        "tokens": 13000769536,
        "learning_rate": 0.00010513684339384451,
        "gradient_norm": 0.4311148226261139,
        "train_loss": 3.0480594635009766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24798,
        "tokens": 13001293824,
        "learning_rate": 0.00010512098824636625,
        "gradient_norm": 0.4287623167037964,
        "train_loss": 3.00869083404541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24799,
        "tokens": 13001818112,
        "learning_rate": 0.00010510513563018165,
        "gradient_norm": 0.435211181640625,
        "train_loss": 3.065127372741699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24800,
        "tokens": 13002342400,
        "learning_rate": 0.00010508928554546897,
        "gradient_norm": 0.45008230209350586,
        "train_loss": 2.9793832302093506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24801,
        "tokens": 13002866688,
        "learning_rate": 0.00010507343799240678,
        "gradient_norm": 0.38798409700393677,
        "train_loss": 3.028017044067383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24802,
        "tokens": 13003390976,
        "learning_rate": 0.00010505759297117349,
        "gradient_norm": 0.43258410692214966,
        "train_loss": 3.048189878463745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24803,
        "tokens": 13003915264,
        "learning_rate": 0.00010504175048194732,
        "gradient_norm": 0.4169822633266449,
        "train_loss": 3.024118423461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24804,
        "tokens": 13004439552,
        "learning_rate": 0.00010502591052490671,
        "gradient_norm": 0.3778224289417267,
        "train_loss": 3.0395617485046387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24805,
        "tokens": 13004963840,
        "learning_rate": 0.00010501007310022989,
        "gradient_norm": 0.4359775483608246,
        "train_loss": 3.061893939971924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24806,
        "tokens": 13005488128,
        "learning_rate": 0.0001049942382080952,
        "gradient_norm": 0.43402963876724243,
        "train_loss": 3.1916160583496094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24807,
        "tokens": 13006012416,
        "learning_rate": 0.00010497840584868074,
        "gradient_norm": 0.4235544800758362,
        "train_loss": 3.0913593769073486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24808,
        "tokens": 13006536704,
        "learning_rate": 0.00010496257602216492,
        "gradient_norm": 0.39240068197250366,
        "train_loss": 3.0520009994506836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24809,
        "tokens": 13007060992,
        "learning_rate": 0.00010494674872872574,
        "gradient_norm": 0.41099998354911804,
        "train_loss": 3.1338367462158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24810,
        "tokens": 13007585280,
        "learning_rate": 0.00010493092396854153,
        "gradient_norm": 0.39349502325057983,
        "train_loss": 3.0536117553710938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24811,
        "tokens": 13008109568,
        "learning_rate": 0.00010491510174179024,
        "gradient_norm": 0.38239362835884094,
        "train_loss": 3.054905652999878,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24812,
        "tokens": 13008633856,
        "learning_rate": 0.00010489928204865014,
        "gradient_norm": 0.41621124744415283,
        "train_loss": 3.0632283687591553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24813,
        "tokens": 13009158144,
        "learning_rate": 0.00010488346488929913,
        "gradient_norm": 0.3997690975666046,
        "train_loss": 2.964477062225342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24814,
        "tokens": 13009682432,
        "learning_rate": 0.00010486765026391541,
        "gradient_norm": 0.3962068259716034,
        "train_loss": 3.0323843955993652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24815,
        "tokens": 13010206720,
        "learning_rate": 0.00010485183817267687,
        "gradient_norm": 0.43069562315940857,
        "train_loss": 3.0529494285583496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24816,
        "tokens": 13010731008,
        "learning_rate": 0.00010483602861576159,
        "gradient_norm": 0.48746803402900696,
        "train_loss": 3.0218732357025146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24817,
        "tokens": 13011255296,
        "learning_rate": 0.00010482022159334745,
        "gradient_norm": 0.4440436065196991,
        "train_loss": 3.04089617729187,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24818,
        "tokens": 13011779584,
        "learning_rate": 0.00010480441710561243,
        "gradient_norm": 0.4989820718765259,
        "train_loss": 3.0759992599487305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24819,
        "tokens": 13012303872,
        "learning_rate": 0.00010478861515273435,
        "gradient_norm": 0.4668416380882263,
        "train_loss": 3.0020275115966797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24820,
        "tokens": 13012828160,
        "learning_rate": 0.00010477281573489122,
        "gradient_norm": 0.42963987588882446,
        "train_loss": 3.0447776317596436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24821,
        "tokens": 13013352448,
        "learning_rate": 0.00010475701885226074,
        "gradient_norm": 0.517000675201416,
        "train_loss": 3.058824062347412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24822,
        "tokens": 13013876736,
        "learning_rate": 0.00010474122450502085,
        "gradient_norm": 0.41989365220069885,
        "train_loss": 3.0263805389404297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24823,
        "tokens": 13014401024,
        "learning_rate": 0.0001047254326933492,
        "gradient_norm": 0.5097402334213257,
        "train_loss": 3.01350736618042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24824,
        "tokens": 13014925312,
        "learning_rate": 0.0001047096434174237,
        "gradient_norm": 0.47679585218429565,
        "train_loss": 2.9501826763153076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24825,
        "tokens": 13015449600,
        "learning_rate": 0.0001046938566774219,
        "gradient_norm": 0.4752543866634369,
        "train_loss": 3.054154634475708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24826,
        "tokens": 13015973888,
        "learning_rate": 0.00010467807247352167,
        "gradient_norm": 0.47350314259529114,
        "train_loss": 3.0419600009918213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24827,
        "tokens": 13016498176,
        "learning_rate": 0.00010466229080590054,
        "gradient_norm": 0.4573875665664673,
        "train_loss": 2.9926042556762695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24828,
        "tokens": 13017022464,
        "learning_rate": 0.00010464651167473631,
        "gradient_norm": 0.43068280816078186,
        "train_loss": 3.0701725482940674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24829,
        "tokens": 13017546752,
        "learning_rate": 0.0001046307350802064,
        "gradient_norm": 0.4544517695903778,
        "train_loss": 3.072718620300293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24830,
        "tokens": 13018071040,
        "learning_rate": 0.00010461496102248856,
        "gradient_norm": 0.4913538992404938,
        "train_loss": 3.0362801551818848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24831,
        "tokens": 13018595328,
        "learning_rate": 0.00010459918950176024,
        "gradient_norm": 0.45022761821746826,
        "train_loss": 3.03609299659729,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24832,
        "tokens": 13019119616,
        "learning_rate": 0.00010458342051819901,
        "gradient_norm": 0.45746201276779175,
        "train_loss": 3.0093636512756348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24833,
        "tokens": 13019643904,
        "learning_rate": 0.00010456765407198244,
        "gradient_norm": 0.44575566053390503,
        "train_loss": 3.0396556854248047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24834,
        "tokens": 13020168192,
        "learning_rate": 0.00010455189016328787,
        "gradient_norm": 0.44961318373680115,
        "train_loss": 3.0199196338653564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24835,
        "tokens": 13020692480,
        "learning_rate": 0.00010453612879229285,
        "gradient_norm": 0.4798201620578766,
        "train_loss": 3.0579593181610107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24836,
        "tokens": 13021216768,
        "learning_rate": 0.00010452036995917469,
        "gradient_norm": 0.4142037630081177,
        "train_loss": 3.0356040000915527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24837,
        "tokens": 13021741056,
        "learning_rate": 0.0001045046136641109,
        "gradient_norm": 0.47805458307266235,
        "train_loss": 3.006317615509033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24838,
        "tokens": 13022265344,
        "learning_rate": 0.0001044888599072787,
        "gradient_norm": 0.3975282311439514,
        "train_loss": 3.0612218379974365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24839,
        "tokens": 13022789632,
        "learning_rate": 0.00010447310868885558,
        "gradient_norm": 0.5168113112449646,
        "train_loss": 3.110759735107422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24840,
        "tokens": 13023313920,
        "learning_rate": 0.00010445736000901866,
        "gradient_norm": 0.38865941762924194,
        "train_loss": 3.0449118614196777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24841,
        "tokens": 13023838208,
        "learning_rate": 0.00010444161386794531,
        "gradient_norm": 0.46509894728660583,
        "train_loss": 2.9955368041992188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24842,
        "tokens": 13024362496,
        "learning_rate": 0.00010442587026581279,
        "gradient_norm": 0.4046359658241272,
        "train_loss": 3.033245086669922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24843,
        "tokens": 13024886784,
        "learning_rate": 0.00010441012920279827,
        "gradient_norm": 0.3743583559989929,
        "train_loss": 2.9931159019470215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24844,
        "tokens": 13025411072,
        "learning_rate": 0.00010439439067907899,
        "gradient_norm": 0.47347378730773926,
        "train_loss": 3.03843092918396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24845,
        "tokens": 13025935360,
        "learning_rate": 0.00010437865469483203,
        "gradient_norm": 0.4303634464740753,
        "train_loss": 3.060401678085327,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24846,
        "tokens": 13026459648,
        "learning_rate": 0.00010436292125023459,
        "gradient_norm": 0.49123361706733704,
        "train_loss": 3.0037460327148438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24847,
        "tokens": 13026983936,
        "learning_rate": 0.00010434719034546367,
        "gradient_norm": 0.4215098023414612,
        "train_loss": 3.0318989753723145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24848,
        "tokens": 13027508224,
        "learning_rate": 0.0001043314619806965,
        "gradient_norm": 0.46363648772239685,
        "train_loss": 3.07564640045166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24849,
        "tokens": 13028032512,
        "learning_rate": 0.00010431573615610993,
        "gradient_norm": 0.4588592052459717,
        "train_loss": 2.987169027328491,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24850,
        "tokens": 13028556800,
        "learning_rate": 0.00010430001287188115,
        "gradient_norm": 0.41504213213920593,
        "train_loss": 3.0174479484558105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24851,
        "tokens": 13029081088,
        "learning_rate": 0.00010428429212818699,
        "gradient_norm": 0.443907231092453,
        "train_loss": 3.005739212036133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24852,
        "tokens": 13029605376,
        "learning_rate": 0.0001042685739252045,
        "gradient_norm": 0.39631497859954834,
        "train_loss": 2.996328353881836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24853,
        "tokens": 13030129664,
        "learning_rate": 0.00010425285826311066,
        "gradient_norm": 0.3933928608894348,
        "train_loss": 3.0947108268737793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24854,
        "tokens": 13030653952,
        "learning_rate": 0.00010423714514208226,
        "gradient_norm": 0.4493688642978668,
        "train_loss": 3.0270321369171143,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24855,
        "tokens": 13031178240,
        "learning_rate": 0.00010422143456229624,
        "gradient_norm": 0.3994629979133606,
        "train_loss": 2.9955925941467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24856,
        "tokens": 13031702528,
        "learning_rate": 0.00010420572652392935,
        "gradient_norm": 0.41355541348457336,
        "train_loss": 3.0312061309814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24857,
        "tokens": 13032226816,
        "learning_rate": 0.00010419002102715855,
        "gradient_norm": 0.43063947558403015,
        "train_loss": 3.002897262573242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24858,
        "tokens": 13032751104,
        "learning_rate": 0.00010417431807216048,
        "gradient_norm": 0.47289714217185974,
        "train_loss": 2.9874167442321777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24859,
        "tokens": 13033275392,
        "learning_rate": 0.000104158617659112,
        "gradient_norm": 0.4184352159500122,
        "train_loss": 3.00864577293396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24860,
        "tokens": 13033799680,
        "learning_rate": 0.00010414291978818977,
        "gradient_norm": 0.4022864103317261,
        "train_loss": 3.035989284515381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24861,
        "tokens": 13034323968,
        "learning_rate": 0.00010412722445957048,
        "gradient_norm": 0.5040740370750427,
        "train_loss": 3.0739238262176514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24862,
        "tokens": 13034848256,
        "learning_rate": 0.00010411153167343091,
        "gradient_norm": 0.4564073383808136,
        "train_loss": 3.0087437629699707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24863,
        "tokens": 13035372544,
        "learning_rate": 0.00010409584142994757,
        "gradient_norm": 0.5706058144569397,
        "train_loss": 3.0569708347320557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24864,
        "tokens": 13035896832,
        "learning_rate": 0.00010408015372929719,
        "gradient_norm": 0.4087528884410858,
        "train_loss": 3.051361560821533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24865,
        "tokens": 13036421120,
        "learning_rate": 0.00010406446857165623,
        "gradient_norm": 0.49594056606292725,
        "train_loss": 3.019838809967041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24866,
        "tokens": 13036945408,
        "learning_rate": 0.0001040487859572014,
        "gradient_norm": 0.42269355058670044,
        "train_loss": 3.0235133171081543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24867,
        "tokens": 13037469696,
        "learning_rate": 0.00010403310588610903,
        "gradient_norm": 0.4120717942714691,
        "train_loss": 3.05340576171875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24868,
        "tokens": 13037993984,
        "learning_rate": 0.00010401742835855584,
        "gradient_norm": 0.4354635179042816,
        "train_loss": 3.0143327713012695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24869,
        "tokens": 13038518272,
        "learning_rate": 0.00010400175337471809,
        "gradient_norm": 0.405865341424942,
        "train_loss": 2.992582082748413,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24870,
        "tokens": 13039042560,
        "learning_rate": 0.0001039860809347724,
        "gradient_norm": 0.42758622765541077,
        "train_loss": 3.072815418243408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24871,
        "tokens": 13039566848,
        "learning_rate": 0.00010397041103889504,
        "gradient_norm": 0.43748852610588074,
        "train_loss": 2.989469289779663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24872,
        "tokens": 13040091136,
        "learning_rate": 0.00010395474368726245,
        "gradient_norm": 0.4192160665988922,
        "train_loss": 3.06095027923584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24873,
        "tokens": 13040615424,
        "learning_rate": 0.00010393907888005106,
        "gradient_norm": 0.48450830578804016,
        "train_loss": 3.0587353706359863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24874,
        "tokens": 13041139712,
        "learning_rate": 0.00010392341661743707,
        "gradient_norm": 0.46221446990966797,
        "train_loss": 3.013939142227173,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24875,
        "tokens": 13041664000,
        "learning_rate": 0.0001039077568995969,
        "gradient_norm": 0.43364807963371277,
        "train_loss": 2.9311747550964355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24876,
        "tokens": 13042188288,
        "learning_rate": 0.0001038920997267067,
        "gradient_norm": 0.4843580722808838,
        "train_loss": 2.9720280170440674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24877,
        "tokens": 13042712576,
        "learning_rate": 0.00010387644509894282,
        "gradient_norm": 0.3988824486732483,
        "train_loss": 2.9412755966186523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24878,
        "tokens": 13043236864,
        "learning_rate": 0.00010386079301648135,
        "gradient_norm": 0.4673639237880707,
        "train_loss": 3.0259037017822266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24879,
        "tokens": 13043761152,
        "learning_rate": 0.0001038451434794986,
        "gradient_norm": 0.4516797661781311,
        "train_loss": 3.0103302001953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24880,
        "tokens": 13044285440,
        "learning_rate": 0.00010382949648817064,
        "gradient_norm": 0.38908886909484863,
        "train_loss": 3.0479001998901367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24881,
        "tokens": 13044809728,
        "learning_rate": 0.0001038138520426736,
        "gradient_norm": 0.39622700214385986,
        "train_loss": 3.062685966491699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24882,
        "tokens": 13045334016,
        "learning_rate": 0.00010379821014318371,
        "gradient_norm": 0.39627182483673096,
        "train_loss": 2.998613119125366,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24883,
        "tokens": 13045858304,
        "learning_rate": 0.0001037825707898768,
        "gradient_norm": 0.42055219411849976,
        "train_loss": 3.0137319564819336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24884,
        "tokens": 13046382592,
        "learning_rate": 0.00010376693398292917,
        "gradient_norm": 0.4430405795574188,
        "train_loss": 3.110194683074951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24885,
        "tokens": 13046906880,
        "learning_rate": 0.00010375129972251663,
        "gradient_norm": 0.43588656187057495,
        "train_loss": 3.082186460494995,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24886,
        "tokens": 13047431168,
        "learning_rate": 0.00010373566800881528,
        "gradient_norm": 0.4527457356452942,
        "train_loss": 3.0208234786987305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24887,
        "tokens": 13047955456,
        "learning_rate": 0.00010372003884200098,
        "gradient_norm": 0.4211004078388214,
        "train_loss": 3.0733723640441895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24888,
        "tokens": 13048479744,
        "learning_rate": 0.00010370441222224975,
        "gradient_norm": 0.4008304178714752,
        "train_loss": 3.0213019847869873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24889,
        "tokens": 13049004032,
        "learning_rate": 0.00010368878814973741,
        "gradient_norm": 0.44345733523368835,
        "train_loss": 3.0881810188293457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24890,
        "tokens": 13049528320,
        "learning_rate": 0.0001036731666246399,
        "gradient_norm": 0.45397472381591797,
        "train_loss": 2.945660352706909,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24891,
        "tokens": 13050052608,
        "learning_rate": 0.00010365754764713299,
        "gradient_norm": 0.4946709871292114,
        "train_loss": 3.0411477088928223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24892,
        "tokens": 13050576896,
        "learning_rate": 0.00010364193121739252,
        "gradient_norm": 0.4280860126018524,
        "train_loss": 3.051361560821533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24893,
        "tokens": 13051101184,
        "learning_rate": 0.00010362631733559433,
        "gradient_norm": 0.42158374190330505,
        "train_loss": 3.0232362747192383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24894,
        "tokens": 13051625472,
        "learning_rate": 0.00010361070600191407,
        "gradient_norm": 0.4073532521724701,
        "train_loss": 3.010075092315674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24895,
        "tokens": 13052149760,
        "learning_rate": 0.00010359509721652755,
        "gradient_norm": 0.42094019055366516,
        "train_loss": 3.084883213043213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24896,
        "tokens": 13052674048,
        "learning_rate": 0.0001035794909796104,
        "gradient_norm": 0.456952303647995,
        "train_loss": 3.077824115753174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24897,
        "tokens": 13053198336,
        "learning_rate": 0.00010356388729133834,
        "gradient_norm": 0.4664970338344574,
        "train_loss": 3.1215872764587402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24898,
        "tokens": 13053722624,
        "learning_rate": 0.00010354828615188698,
        "gradient_norm": 0.4072633981704712,
        "train_loss": 3.05428409576416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24899,
        "tokens": 13054246912,
        "learning_rate": 0.00010353268756143195,
        "gradient_norm": 0.4371289610862732,
        "train_loss": 3.090106964111328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24900,
        "tokens": 13054771200,
        "learning_rate": 0.00010351709152014879,
        "gradient_norm": 0.4214508533477783,
        "train_loss": 2.9779000282287598,
        "val_loss": 2.980246067047119,
        "hellaswag_acc": 0.28390759229660034,
        "hellaswag_acc_norm": 0.2941645085811615
    },
    {
        "step": 24901,
        "tokens": 13055295488,
        "learning_rate": 0.00010350149802821308,
        "gradient_norm": 0.44486019015312195,
        "train_loss": 3.0881738662719727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24902,
        "tokens": 13055819776,
        "learning_rate": 0.00010348590708580041,
        "gradient_norm": 0.4449651539325714,
        "train_loss": 3.0872538089752197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24903,
        "tokens": 13056344064,
        "learning_rate": 0.00010347031869308617,
        "gradient_norm": 0.41024845838546753,
        "train_loss": 2.954488515853882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24904,
        "tokens": 13056868352,
        "learning_rate": 0.0001034547328502459,
        "gradient_norm": 0.42627769708633423,
        "train_loss": 3.0298945903778076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24905,
        "tokens": 13057392640,
        "learning_rate": 0.00010343914955745495,
        "gradient_norm": 0.44516971707344055,
        "train_loss": 3.033812999725342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24906,
        "tokens": 13057916928,
        "learning_rate": 0.00010342356881488887,
        "gradient_norm": 0.44113314151763916,
        "train_loss": 3.012462615966797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24907,
        "tokens": 13058441216,
        "learning_rate": 0.00010340799062272286,
        "gradient_norm": 0.4078514277935028,
        "train_loss": 3.0549635887145996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24908,
        "tokens": 13058965504,
        "learning_rate": 0.00010339241498113247,
        "gradient_norm": 0.3995074927806854,
        "train_loss": 3.052807092666626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24909,
        "tokens": 13059489792,
        "learning_rate": 0.00010337684189029284,
        "gradient_norm": 0.42269402742385864,
        "train_loss": 3.038623809814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24910,
        "tokens": 13060014080,
        "learning_rate": 0.0001033612713503794,
        "gradient_norm": 0.4708411693572998,
        "train_loss": 3.068355083465576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24911,
        "tokens": 13060538368,
        "learning_rate": 0.00010334570336156733,
        "gradient_norm": 0.5288912057876587,
        "train_loss": 2.9982471466064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24912,
        "tokens": 13061062656,
        "learning_rate": 0.00010333013792403195,
        "gradient_norm": 0.7581068277359009,
        "train_loss": 2.9913129806518555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24913,
        "tokens": 13061586944,
        "learning_rate": 0.00010331457503794835,
        "gradient_norm": 0.4900647699832916,
        "train_loss": 3.0094847679138184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24914,
        "tokens": 13062111232,
        "learning_rate": 0.00010329901470349184,
        "gradient_norm": 0.5194981098175049,
        "train_loss": 3.046741008758545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24915,
        "tokens": 13062635520,
        "learning_rate": 0.00010328345692083745,
        "gradient_norm": 0.4956374168395996,
        "train_loss": 3.008333206176758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24916,
        "tokens": 13063159808,
        "learning_rate": 0.00010326790169016044,
        "gradient_norm": 0.48742732405662537,
        "train_loss": 3.065330743789673,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24917,
        "tokens": 13063684096,
        "learning_rate": 0.00010325234901163575,
        "gradient_norm": 0.4757711887359619,
        "train_loss": 3.048403024673462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24918,
        "tokens": 13064208384,
        "learning_rate": 0.00010323679888543858,
        "gradient_norm": 0.4408310651779175,
        "train_loss": 3.0028672218322754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24919,
        "tokens": 13064732672,
        "learning_rate": 0.00010322125131174383,
        "gradient_norm": 0.46482574939727783,
        "train_loss": 3.00822114944458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24920,
        "tokens": 13065256960,
        "learning_rate": 0.0001032057062907267,
        "gradient_norm": 0.4590327739715576,
        "train_loss": 2.990264892578125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24921,
        "tokens": 13065781248,
        "learning_rate": 0.00010319016382256193,
        "gradient_norm": 0.4676898717880249,
        "train_loss": 2.9735894203186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24922,
        "tokens": 13066305536,
        "learning_rate": 0.00010317462390742468,
        "gradient_norm": 0.42242103815078735,
        "train_loss": 2.973468065261841,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24923,
        "tokens": 13066829824,
        "learning_rate": 0.00010315908654548971,
        "gradient_norm": 0.45166608691215515,
        "train_loss": 3.0553624629974365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24924,
        "tokens": 13067354112,
        "learning_rate": 0.00010314355173693206,
        "gradient_norm": 0.4072006940841675,
        "train_loss": 3.016213893890381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24925,
        "tokens": 13067878400,
        "learning_rate": 0.00010312801948192647,
        "gradient_norm": 0.45375385880470276,
        "train_loss": 3.0521950721740723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24926,
        "tokens": 13068402688,
        "learning_rate": 0.00010311248978064785,
        "gradient_norm": 0.42808425426483154,
        "train_loss": 3.0470783710479736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24927,
        "tokens": 13068926976,
        "learning_rate": 0.00010309696263327092,
        "gradient_norm": 0.39886167645454407,
        "train_loss": 3.0579400062561035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24928,
        "tokens": 13069451264,
        "learning_rate": 0.00010308143803997063,
        "gradient_norm": 0.4183817505836487,
        "train_loss": 2.996211051940918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24929,
        "tokens": 13069975552,
        "learning_rate": 0.00010306591600092152,
        "gradient_norm": 0.38157451152801514,
        "train_loss": 3.0186638832092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24930,
        "tokens": 13070499840,
        "learning_rate": 0.00010305039651629846,
        "gradient_norm": 0.4075084924697876,
        "train_loss": 2.9337451457977295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24931,
        "tokens": 13071024128,
        "learning_rate": 0.00010303487958627602,
        "gradient_norm": 0.40395015478134155,
        "train_loss": 2.9847805500030518,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24932,
        "tokens": 13071548416,
        "learning_rate": 0.00010301936521102896,
        "gradient_norm": 0.40023332834243774,
        "train_loss": 3.020728588104248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24933,
        "tokens": 13072072704,
        "learning_rate": 0.00010300385339073193,
        "gradient_norm": 0.40838685631752014,
        "train_loss": 3.0282297134399414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24934,
        "tokens": 13072596992,
        "learning_rate": 0.00010298834412555943,
        "gradient_norm": 0.39489513635635376,
        "train_loss": 3.040635585784912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24935,
        "tokens": 13073121280,
        "learning_rate": 0.00010297283741568614,
        "gradient_norm": 0.42917826771736145,
        "train_loss": 3.0388970375061035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24936,
        "tokens": 13073645568,
        "learning_rate": 0.00010295733326128652,
        "gradient_norm": 0.4916422665119171,
        "train_loss": 3.120333433151245,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24937,
        "tokens": 13074169856,
        "learning_rate": 0.00010294183166253519,
        "gradient_norm": 0.3944850564002991,
        "train_loss": 3.0779566764831543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24938,
        "tokens": 13074694144,
        "learning_rate": 0.00010292633261960651,
        "gradient_norm": 0.44359827041625977,
        "train_loss": 3.0431289672851562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24939,
        "tokens": 13075218432,
        "learning_rate": 0.00010291083613267506,
        "gradient_norm": 0.4066581428050995,
        "train_loss": 2.985013484954834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24940,
        "tokens": 13075742720,
        "learning_rate": 0.0001028953422019152,
        "gradient_norm": 0.4387205243110657,
        "train_loss": 3.038067102432251,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24941,
        "tokens": 13076267008,
        "learning_rate": 0.00010287985082750132,
        "gradient_norm": 0.4269275665283203,
        "train_loss": 3.0164921283721924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24942,
        "tokens": 13076791296,
        "learning_rate": 0.0001028643620096079,
        "gradient_norm": 0.44184640049934387,
        "train_loss": 3.0469000339508057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24943,
        "tokens": 13077315584,
        "learning_rate": 0.00010284887574840918,
        "gradient_norm": 0.41586896777153015,
        "train_loss": 3.0267698764801025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24944,
        "tokens": 13077839872,
        "learning_rate": 0.00010283339204407956,
        "gradient_norm": 0.4564455449581146,
        "train_loss": 3.00669527053833,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24945,
        "tokens": 13078364160,
        "learning_rate": 0.00010281791089679322,
        "gradient_norm": 0.3897816836833954,
        "train_loss": 3.026499032974243,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24946,
        "tokens": 13078888448,
        "learning_rate": 0.00010280243230672453,
        "gradient_norm": 0.45329201221466064,
        "train_loss": 3.0501646995544434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24947,
        "tokens": 13079412736,
        "learning_rate": 0.00010278695627404763,
        "gradient_norm": 0.42254552245140076,
        "train_loss": 3.0489883422851562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24948,
        "tokens": 13079937024,
        "learning_rate": 0.00010277148279893683,
        "gradient_norm": 0.3908224105834961,
        "train_loss": 3.010138511657715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24949,
        "tokens": 13080461312,
        "learning_rate": 0.00010275601188156617,
        "gradient_norm": 0.42258259654045105,
        "train_loss": 3.0242443084716797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24950,
        "tokens": 13080985600,
        "learning_rate": 0.00010274054352210994,
        "gradient_norm": 0.4319015145301819,
        "train_loss": 3.059340476989746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24951,
        "tokens": 13081509888,
        "learning_rate": 0.00010272507772074208,
        "gradient_norm": 0.40190622210502625,
        "train_loss": 2.991849899291992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24952,
        "tokens": 13082034176,
        "learning_rate": 0.0001027096144776368,
        "gradient_norm": 0.4549288749694824,
        "train_loss": 3.0145163536071777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24953,
        "tokens": 13082558464,
        "learning_rate": 0.00010269415379296819,
        "gradient_norm": 0.41991883516311646,
        "train_loss": 3.0736420154571533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24954,
        "tokens": 13083082752,
        "learning_rate": 0.00010267869566691018,
        "gradient_norm": 0.41667887568473816,
        "train_loss": 3.0973246097564697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24955,
        "tokens": 13083607040,
        "learning_rate": 0.00010266324009963688,
        "gradient_norm": 0.6351061463356018,
        "train_loss": 3.050607204437256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24956,
        "tokens": 13084131328,
        "learning_rate": 0.00010264778709132211,
        "gradient_norm": 0.40834686160087585,
        "train_loss": 3.0170738697052,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24957,
        "tokens": 13084655616,
        "learning_rate": 0.00010263233664213996,
        "gradient_norm": 0.47834378480911255,
        "train_loss": 3.056527614593506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24958,
        "tokens": 13085179904,
        "learning_rate": 0.00010261688875226423,
        "gradient_norm": 0.4087906777858734,
        "train_loss": 2.9666521549224854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24959,
        "tokens": 13085704192,
        "learning_rate": 0.00010260144342186891,
        "gradient_norm": 0.40367794036865234,
        "train_loss": 2.9836313724517822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24960,
        "tokens": 13086228480,
        "learning_rate": 0.00010258600065112775,
        "gradient_norm": 0.4238165318965912,
        "train_loss": 3.0073041915893555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24961,
        "tokens": 13086752768,
        "learning_rate": 0.00010257056044021462,
        "gradient_norm": 0.4135787785053253,
        "train_loss": 3.060683012008667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24962,
        "tokens": 13087277056,
        "learning_rate": 0.00010255512278930341,
        "gradient_norm": 0.4347717761993408,
        "train_loss": 2.9934637546539307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24963,
        "tokens": 13087801344,
        "learning_rate": 0.00010253968769856773,
        "gradient_norm": 0.42387649416923523,
        "train_loss": 3.034731388092041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24964,
        "tokens": 13088325632,
        "learning_rate": 0.00010252425516818149,
        "gradient_norm": 0.43033239245414734,
        "train_loss": 2.9987030029296875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24965,
        "tokens": 13088849920,
        "learning_rate": 0.00010250882519831823,
        "gradient_norm": 0.4143562316894531,
        "train_loss": 3.0609726905822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24966,
        "tokens": 13089374208,
        "learning_rate": 0.00010249339778915178,
        "gradient_norm": 0.39496147632598877,
        "train_loss": 3.0126171112060547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24967,
        "tokens": 13089898496,
        "learning_rate": 0.00010247797294085568,
        "gradient_norm": 0.4326881766319275,
        "train_loss": 3.0324301719665527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24968,
        "tokens": 13090422784,
        "learning_rate": 0.00010246255065360367,
        "gradient_norm": 0.5477386116981506,
        "train_loss": 3.0357277393341064,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24969,
        "tokens": 13090947072,
        "learning_rate": 0.0001024471309275692,
        "gradient_norm": 0.4429199695587158,
        "train_loss": 3.0048251152038574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24970,
        "tokens": 13091471360,
        "learning_rate": 0.00010243171376292601,
        "gradient_norm": 0.5346740484237671,
        "train_loss": 2.9955239295959473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24971,
        "tokens": 13091995648,
        "learning_rate": 0.00010241629915984749,
        "gradient_norm": 0.44277194142341614,
        "train_loss": 3.000901937484741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24972,
        "tokens": 13092519936,
        "learning_rate": 0.00010240088711850722,
        "gradient_norm": 0.4600587487220764,
        "train_loss": 3.0292787551879883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24973,
        "tokens": 13093044224,
        "learning_rate": 0.00010238547763907872,
        "gradient_norm": 0.5303840041160583,
        "train_loss": 3.0132663249969482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24974,
        "tokens": 13093568512,
        "learning_rate": 0.00010237007072173536,
        "gradient_norm": 0.3960179388523102,
        "train_loss": 2.950406789779663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24975,
        "tokens": 13094092800,
        "learning_rate": 0.00010235466636665064,
        "gradient_norm": 0.4611603021621704,
        "train_loss": 3.02310848236084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24976,
        "tokens": 13094617088,
        "learning_rate": 0.00010233926457399787,
        "gradient_norm": 0.4270957410335541,
        "train_loss": 2.981039047241211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24977,
        "tokens": 13095141376,
        "learning_rate": 0.0001023238653439505,
        "gradient_norm": 0.4222586750984192,
        "train_loss": 2.931886672973633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24978,
        "tokens": 13095665664,
        "learning_rate": 0.00010230846867668178,
        "gradient_norm": 0.39684122800827026,
        "train_loss": 3.0410494804382324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24979,
        "tokens": 13096189952,
        "learning_rate": 0.00010229307457236515,
        "gradient_norm": 0.3967204689979553,
        "train_loss": 3.021578788757324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24980,
        "tokens": 13096714240,
        "learning_rate": 0.00010227768303117376,
        "gradient_norm": 0.43970346450805664,
        "train_loss": 3.0172953605651855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24981,
        "tokens": 13097238528,
        "learning_rate": 0.00010226229405328086,
        "gradient_norm": 0.403543621301651,
        "train_loss": 3.0263755321502686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24982,
        "tokens": 13097762816,
        "learning_rate": 0.00010224690763885982,
        "gradient_norm": 0.3994154930114746,
        "train_loss": 3.0488474369049072,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24983,
        "tokens": 13098287104,
        "learning_rate": 0.00010223152378808366,
        "gradient_norm": 0.40490591526031494,
        "train_loss": 3.002042293548584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24984,
        "tokens": 13098811392,
        "learning_rate": 0.0001022161425011257,
        "gradient_norm": 0.3747096061706543,
        "train_loss": 3.009753465652466,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24985,
        "tokens": 13099335680,
        "learning_rate": 0.00010220076377815893,
        "gradient_norm": 0.4252464771270752,
        "train_loss": 3.0061123371124268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24986,
        "tokens": 13099859968,
        "learning_rate": 0.00010218538761935656,
        "gradient_norm": 0.37422317266464233,
        "train_loss": 3.0286712646484375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24987,
        "tokens": 13100384256,
        "learning_rate": 0.00010217001402489159,
        "gradient_norm": 0.3822704553604126,
        "train_loss": 2.9985604286193848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24988,
        "tokens": 13100908544,
        "learning_rate": 0.00010215464299493717,
        "gradient_norm": 0.388705849647522,
        "train_loss": 3.0452795028686523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24989,
        "tokens": 13101432832,
        "learning_rate": 0.0001021392745296662,
        "gradient_norm": 0.43659675121307373,
        "train_loss": 3.0074310302734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24990,
        "tokens": 13101957120,
        "learning_rate": 0.00010212390862925178,
        "gradient_norm": 0.40334612131118774,
        "train_loss": 3.028008460998535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24991,
        "tokens": 13102481408,
        "learning_rate": 0.00010210854529386679,
        "gradient_norm": 0.4361521899700165,
        "train_loss": 2.9909400939941406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24992,
        "tokens": 13103005696,
        "learning_rate": 0.00010209318452368419,
        "gradient_norm": 0.4341411292552948,
        "train_loss": 3.041335105895996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24993,
        "tokens": 13103529984,
        "learning_rate": 0.00010207782631887694,
        "gradient_norm": 0.4761749505996704,
        "train_loss": 3.1218748092651367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24994,
        "tokens": 13104054272,
        "learning_rate": 0.00010206247067961779,
        "gradient_norm": 0.48913466930389404,
        "train_loss": 3.012516975402832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24995,
        "tokens": 13104578560,
        "learning_rate": 0.00010204711760607975,
        "gradient_norm": 0.41621649265289307,
        "train_loss": 3.027045488357544,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24996,
        "tokens": 13105102848,
        "learning_rate": 0.00010203176709843549,
        "gradient_norm": 0.41439729928970337,
        "train_loss": 2.9991602897644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24997,
        "tokens": 13105627136,
        "learning_rate": 0.00010201641915685792,
        "gradient_norm": 0.4673370122909546,
        "train_loss": 3.1035356521606445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24998,
        "tokens": 13106151424,
        "learning_rate": 0.00010200107378151969,
        "gradient_norm": 0.4928237199783325,
        "train_loss": 2.9986166954040527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 24999,
        "tokens": 13106675712,
        "learning_rate": 0.00010198573097259362,
        "gradient_norm": 0.440163254737854,
        "train_loss": 2.9887356758117676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25000,
        "tokens": 13107200000,
        "learning_rate": 0.0001019703907302523,
        "gradient_norm": 0.4456028342247009,
        "train_loss": 3.0172924995422363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25001,
        "tokens": 13107724288,
        "learning_rate": 0.0001019550530546685,
        "gradient_norm": 0.43179038166999817,
        "train_loss": 3.0299134254455566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25002,
        "tokens": 13108248576,
        "learning_rate": 0.00010193971794601492,
        "gradient_norm": 0.5920376181602478,
        "train_loss": 2.990241050720215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25003,
        "tokens": 13108772864,
        "learning_rate": 0.00010192438540446402,
        "gradient_norm": 0.47939422726631165,
        "train_loss": 2.9916012287139893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25004,
        "tokens": 13109297152,
        "learning_rate": 0.00010190905543018853,
        "gradient_norm": 0.4631623923778534,
        "train_loss": 3.0211377143859863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25005,
        "tokens": 13109821440,
        "learning_rate": 0.0001018937280233609,
        "gradient_norm": 0.45261290669441223,
        "train_loss": 2.989351749420166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25006,
        "tokens": 13110345728,
        "learning_rate": 0.00010187840318415375,
        "gradient_norm": 0.43923211097717285,
        "train_loss": 3.0378801822662354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25007,
        "tokens": 13110870016,
        "learning_rate": 0.00010186308091273945,
        "gradient_norm": 0.39886313676834106,
        "train_loss": 2.9751405715942383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25008,
        "tokens": 13111394304,
        "learning_rate": 0.00010184776120929066,
        "gradient_norm": 0.4244849979877472,
        "train_loss": 3.0172576904296875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25009,
        "tokens": 13111918592,
        "learning_rate": 0.00010183244407397963,
        "gradient_norm": 0.42954182624816895,
        "train_loss": 3.0062203407287598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25010,
        "tokens": 13112442880,
        "learning_rate": 0.00010181712950697893,
        "gradient_norm": 0.3838193714618683,
        "train_loss": 3.0360054969787598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25011,
        "tokens": 13112967168,
        "learning_rate": 0.00010180181750846077,
        "gradient_norm": 0.45792531967163086,
        "train_loss": 3.052830934524536,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25012,
        "tokens": 13113491456,
        "learning_rate": 0.00010178650807859767,
        "gradient_norm": 0.431413471698761,
        "train_loss": 3.0232367515563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25013,
        "tokens": 13114015744,
        "learning_rate": 0.00010177120121756193,
        "gradient_norm": 0.3931341767311096,
        "train_loss": 3.0338053703308105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25014,
        "tokens": 13114540032,
        "learning_rate": 0.00010175589692552577,
        "gradient_norm": 0.4467812776565552,
        "train_loss": 3.068767547607422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25015,
        "tokens": 13115064320,
        "learning_rate": 0.00010174059520266156,
        "gradient_norm": 0.4827893376350403,
        "train_loss": 2.9769763946533203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25016,
        "tokens": 13115588608,
        "learning_rate": 0.00010172529604914141,
        "gradient_norm": 0.42159757018089294,
        "train_loss": 3.077566146850586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25017,
        "tokens": 13116112896,
        "learning_rate": 0.00010170999946513767,
        "gradient_norm": 0.424144446849823,
        "train_loss": 3.105743885040283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25018,
        "tokens": 13116637184,
        "learning_rate": 0.00010169470545082242,
        "gradient_norm": 0.4202558994293213,
        "train_loss": 3.018918514251709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25019,
        "tokens": 13117161472,
        "learning_rate": 0.00010167941400636787,
        "gradient_norm": 0.4023433327674866,
        "train_loss": 3.0048828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25020,
        "tokens": 13117685760,
        "learning_rate": 0.0001016641251319461,
        "gradient_norm": 0.40865930914878845,
        "train_loss": 2.99139142036438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25021,
        "tokens": 13118210048,
        "learning_rate": 0.00010164883882772925,
        "gradient_norm": 0.4036180377006531,
        "train_loss": 3.0443410873413086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25022,
        "tokens": 13118734336,
        "learning_rate": 0.00010163355509388935,
        "gradient_norm": 0.4113825559616089,
        "train_loss": 3.0033154487609863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25023,
        "tokens": 13119258624,
        "learning_rate": 0.00010161827393059852,
        "gradient_norm": 0.35041138529777527,
        "train_loss": 2.967284679412842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25024,
        "tokens": 13119782912,
        "learning_rate": 0.0001016029953380286,
        "gradient_norm": 0.4174082279205322,
        "train_loss": 3.026423215866089,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25025,
        "tokens": 13120307200,
        "learning_rate": 0.00010158771931635172,
        "gradient_norm": 0.4112452566623688,
        "train_loss": 3.020083427429199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25026,
        "tokens": 13120831488,
        "learning_rate": 0.00010157244586573978,
        "gradient_norm": 0.37774863839149475,
        "train_loss": 3.0635037422180176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25027,
        "tokens": 13121355776,
        "learning_rate": 0.0001015571749863647,
        "gradient_norm": 0.4013887941837311,
        "train_loss": 3.052713394165039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25028,
        "tokens": 13121880064,
        "learning_rate": 0.00010154190667839837,
        "gradient_norm": 0.40202903747558594,
        "train_loss": 3.008157730102539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25029,
        "tokens": 13122404352,
        "learning_rate": 0.00010152664094201271,
        "gradient_norm": 0.39106592535972595,
        "train_loss": 3.0323617458343506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25030,
        "tokens": 13122928640,
        "learning_rate": 0.00010151137777737946,
        "gradient_norm": 0.4523942768573761,
        "train_loss": 3.0147387981414795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25031,
        "tokens": 13123452928,
        "learning_rate": 0.0001014961171846705,
        "gradient_norm": 0.44653812050819397,
        "train_loss": 3.0978219509124756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25032,
        "tokens": 13123977216,
        "learning_rate": 0.00010148085916405751,
        "gradient_norm": 0.38325437903404236,
        "train_loss": 2.9978463649749756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25033,
        "tokens": 13124501504,
        "learning_rate": 0.00010146560371571238,
        "gradient_norm": 0.41824689507484436,
        "train_loss": 3.0801453590393066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25034,
        "tokens": 13125025792,
        "learning_rate": 0.00010145035083980671,
        "gradient_norm": 0.45751136541366577,
        "train_loss": 3.1459250450134277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25035,
        "tokens": 13125550080,
        "learning_rate": 0.00010143510053651231,
        "gradient_norm": 0.46363216638565063,
        "train_loss": 3.0384135246276855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25036,
        "tokens": 13126074368,
        "learning_rate": 0.00010141985280600068,
        "gradient_norm": 0.46947652101516724,
        "train_loss": 3.034755229949951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25037,
        "tokens": 13126598656,
        "learning_rate": 0.0001014046076484436,
        "gradient_norm": 0.42848432064056396,
        "train_loss": 3.0465452671051025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25038,
        "tokens": 13127122944,
        "learning_rate": 0.00010138936506401255,
        "gradient_norm": 0.4228363335132599,
        "train_loss": 3.0258514881134033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25039,
        "tokens": 13127647232,
        "learning_rate": 0.00010137412505287923,
        "gradient_norm": 0.39546719193458557,
        "train_loss": 3.0366079807281494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25040,
        "tokens": 13128171520,
        "learning_rate": 0.00010135888761521507,
        "gradient_norm": 0.4429457187652588,
        "train_loss": 2.987483024597168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25041,
        "tokens": 13128695808,
        "learning_rate": 0.00010134365275119164,
        "gradient_norm": 0.4720013439655304,
        "train_loss": 3.0192346572875977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25042,
        "tokens": 13129220096,
        "learning_rate": 0.00010132842046098046,
        "gradient_norm": 0.3853493928909302,
        "train_loss": 3.032039165496826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25043,
        "tokens": 13129744384,
        "learning_rate": 0.00010131319074475293,
        "gradient_norm": 0.3779134452342987,
        "train_loss": 3.0192646980285645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25044,
        "tokens": 13130268672,
        "learning_rate": 0.00010129796360268053,
        "gradient_norm": 0.3823498785495758,
        "train_loss": 3.004216194152832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25045,
        "tokens": 13130792960,
        "learning_rate": 0.0001012827390349346,
        "gradient_norm": 0.40705084800720215,
        "train_loss": 3.0471558570861816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25046,
        "tokens": 13131317248,
        "learning_rate": 0.00010126751704168658,
        "gradient_norm": 0.39421603083610535,
        "train_loss": 3.0023438930511475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25047,
        "tokens": 13131841536,
        "learning_rate": 0.00010125229762310774,
        "gradient_norm": 0.42507386207580566,
        "train_loss": 3.039123296737671,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25048,
        "tokens": 13132365824,
        "learning_rate": 0.0001012370807793695,
        "gradient_norm": 0.4428442120552063,
        "train_loss": 3.0147624015808105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25049,
        "tokens": 13132890112,
        "learning_rate": 0.00010122186651064302,
        "gradient_norm": 0.4450649321079254,
        "train_loss": 3.036980152130127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25050,
        "tokens": 13133414400,
        "learning_rate": 0.00010120665481709965,
        "gradient_norm": 0.4483833611011505,
        "train_loss": 3.0242156982421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25051,
        "tokens": 13133938688,
        "learning_rate": 0.00010119144569891052,
        "gradient_norm": 0.43957632780075073,
        "train_loss": 3.0519208908081055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25052,
        "tokens": 13134462976,
        "learning_rate": 0.00010117623915624687,
        "gradient_norm": 0.4577432870864868,
        "train_loss": 3.030592441558838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25053,
        "tokens": 13134987264,
        "learning_rate": 0.00010116103518927999,
        "gradient_norm": 0.4175300598144531,
        "train_loss": 3.027332305908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25054,
        "tokens": 13135511552,
        "learning_rate": 0.00010114583379818083,
        "gradient_norm": 0.42943909764289856,
        "train_loss": 2.9736618995666504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25055,
        "tokens": 13136035840,
        "learning_rate": 0.00010113063498312063,
        "gradient_norm": 0.41975513100624084,
        "train_loss": 3.031494379043579,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25056,
        "tokens": 13136560128,
        "learning_rate": 0.00010111543874427039,
        "gradient_norm": 0.4069960117340088,
        "train_loss": 3.0391440391540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25057,
        "tokens": 13137084416,
        "learning_rate": 0.00010110024508180124,
        "gradient_norm": 0.4421526789665222,
        "train_loss": 2.999506950378418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25058,
        "tokens": 13137608704,
        "learning_rate": 0.0001010850539958841,
        "gradient_norm": 0.426814466714859,
        "train_loss": 2.9788665771484375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25059,
        "tokens": 13138132992,
        "learning_rate": 0.00010106986548669012,
        "gradient_norm": 0.43321678042411804,
        "train_loss": 3.0668528079986572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25060,
        "tokens": 13138657280,
        "learning_rate": 0.0001010546795543901,
        "gradient_norm": 0.42454397678375244,
        "train_loss": 3.0882530212402344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25061,
        "tokens": 13139181568,
        "learning_rate": 0.00010103949619915501,
        "gradient_norm": 0.44867122173309326,
        "train_loss": 3.0786547660827637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25062,
        "tokens": 13139705856,
        "learning_rate": 0.0001010243154211559,
        "gradient_norm": 0.4317886531352997,
        "train_loss": 3.0140209197998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25063,
        "tokens": 13140230144,
        "learning_rate": 0.00010100913722056348,
        "gradient_norm": 0.38456812500953674,
        "train_loss": 3.020610809326172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25064,
        "tokens": 13140754432,
        "learning_rate": 0.00010099396159754873,
        "gradient_norm": 0.4211038053035736,
        "train_loss": 2.963388204574585,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25065,
        "tokens": 13141278720,
        "learning_rate": 0.0001009787885522823,
        "gradient_norm": 0.4869880676269531,
        "train_loss": 3.0793981552124023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25066,
        "tokens": 13141803008,
        "learning_rate": 0.00010096361808493519,
        "gradient_norm": 0.4374004602432251,
        "train_loss": 3.078502655029297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25067,
        "tokens": 13142327296,
        "learning_rate": 0.000100948450195678,
        "gradient_norm": 0.44448500871658325,
        "train_loss": 3.0002238750457764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25068,
        "tokens": 13142851584,
        "learning_rate": 0.00010093328488468159,
        "gradient_norm": 0.4491221606731415,
        "train_loss": 3.009270191192627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25069,
        "tokens": 13143375872,
        "learning_rate": 0.00010091812215211652,
        "gradient_norm": 0.43016862869262695,
        "train_loss": 2.9896273612976074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25070,
        "tokens": 13143900160,
        "learning_rate": 0.0001009029619981536,
        "gradient_norm": 0.41637301445007324,
        "train_loss": 3.029975175857544,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25071,
        "tokens": 13144424448,
        "learning_rate": 0.00010088780442296335,
        "gradient_norm": 0.46153056621551514,
        "train_loss": 3.051525115966797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25072,
        "tokens": 13144948736,
        "learning_rate": 0.00010087264942671648,
        "gradient_norm": 0.38202664256095886,
        "train_loss": 2.995697498321533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25073,
        "tokens": 13145473024,
        "learning_rate": 0.00010085749700958362,
        "gradient_norm": 0.41826412081718445,
        "train_loss": 3.015227794647217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25074,
        "tokens": 13145997312,
        "learning_rate": 0.00010084234717173519,
        "gradient_norm": 0.3940146565437317,
        "train_loss": 3.0018386840820312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25075,
        "tokens": 13146521600,
        "learning_rate": 0.00010082719991334185,
        "gradient_norm": 0.4745672941207886,
        "train_loss": 3.112272262573242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25076,
        "tokens": 13147045888,
        "learning_rate": 0.00010081205523457399,
        "gradient_norm": 0.4042598009109497,
        "train_loss": 3.021029233932495,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25077,
        "tokens": 13147570176,
        "learning_rate": 0.00010079691313560221,
        "gradient_norm": 0.38380560278892517,
        "train_loss": 2.943821668624878,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25078,
        "tokens": 13148094464,
        "learning_rate": 0.00010078177361659682,
        "gradient_norm": 0.40730610489845276,
        "train_loss": 3.007935047149658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25079,
        "tokens": 13148618752,
        "learning_rate": 0.00010076663667772836,
        "gradient_norm": 0.381782591342926,
        "train_loss": 3.012143135070801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25080,
        "tokens": 13149143040,
        "learning_rate": 0.00010075150231916708,
        "gradient_norm": 0.40464168787002563,
        "train_loss": 3.057898759841919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25081,
        "tokens": 13149667328,
        "learning_rate": 0.00010073637054108339,
        "gradient_norm": 0.4700821042060852,
        "train_loss": 3.0208218097686768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25082,
        "tokens": 13150191616,
        "learning_rate": 0.00010072124134364773,
        "gradient_norm": 0.4031205177307129,
        "train_loss": 3.0468506813049316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25083,
        "tokens": 13150715904,
        "learning_rate": 0.00010070611472703022,
        "gradient_norm": 0.4306759238243103,
        "train_loss": 3.0484390258789062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25084,
        "tokens": 13151240192,
        "learning_rate": 0.00010069099069140128,
        "gradient_norm": 0.43386581540107727,
        "train_loss": 3.0267510414123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25085,
        "tokens": 13151764480,
        "learning_rate": 0.000100675869236931,
        "gradient_norm": 0.4222116470336914,
        "train_loss": 3.0177974700927734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25086,
        "tokens": 13152288768,
        "learning_rate": 0.00010066075036378977,
        "gradient_norm": 0.46794629096984863,
        "train_loss": 2.990063190460205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25087,
        "tokens": 13152813056,
        "learning_rate": 0.0001006456340721476,
        "gradient_norm": 0.4142761826515198,
        "train_loss": 2.990140914916992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25088,
        "tokens": 13153337344,
        "learning_rate": 0.00010063052036217478,
        "gradient_norm": 0.4265829026699066,
        "train_loss": 2.9878342151641846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25089,
        "tokens": 13153861632,
        "learning_rate": 0.00010061540923404129,
        "gradient_norm": 0.4579210579395294,
        "train_loss": 3.0954742431640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25090,
        "tokens": 13154385920,
        "learning_rate": 0.0001006003006879173,
        "gradient_norm": 0.46798062324523926,
        "train_loss": 3.0647025108337402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25091,
        "tokens": 13154910208,
        "learning_rate": 0.00010058519472397296,
        "gradient_norm": 0.45357364416122437,
        "train_loss": 3.006547451019287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25092,
        "tokens": 13155434496,
        "learning_rate": 0.00010057009134237815,
        "gradient_norm": 0.4405989646911621,
        "train_loss": 3.0602521896362305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25093,
        "tokens": 13155958784,
        "learning_rate": 0.00010055499054330302,
        "gradient_norm": 0.3975542485713959,
        "train_loss": 3.0576682090759277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25094,
        "tokens": 13156483072,
        "learning_rate": 0.00010053989232691743,
        "gradient_norm": 0.44480547308921814,
        "train_loss": 3.006978750228882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25095,
        "tokens": 13157007360,
        "learning_rate": 0.00010052479669339144,
        "gradient_norm": 0.48787981271743774,
        "train_loss": 3.0446114540100098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25096,
        "tokens": 13157531648,
        "learning_rate": 0.00010050970364289484,
        "gradient_norm": 0.4100090265274048,
        "train_loss": 3.0344972610473633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25097,
        "tokens": 13158055936,
        "learning_rate": 0.00010049461317559766,
        "gradient_norm": 0.46558862924575806,
        "train_loss": 2.955995798110962,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25098,
        "tokens": 13158580224,
        "learning_rate": 0.00010047952529166964,
        "gradient_norm": 0.4569490849971771,
        "train_loss": 2.9967050552368164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25099,
        "tokens": 13159104512,
        "learning_rate": 0.00010046443999128073,
        "gradient_norm": 0.4386492967605591,
        "train_loss": 3.006404161453247,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25100,
        "tokens": 13159628800,
        "learning_rate": 0.0001004493572746006,
        "gradient_norm": 0.41896894574165344,
        "train_loss": 3.0154504776000977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25101,
        "tokens": 13160153088,
        "learning_rate": 0.00010043427714179911,
        "gradient_norm": 0.4827042818069458,
        "train_loss": 3.14455509185791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25102,
        "tokens": 13160677376,
        "learning_rate": 0.00010041919959304605,
        "gradient_norm": 0.5296803116798401,
        "train_loss": 2.9312806129455566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25103,
        "tokens": 13161201664,
        "learning_rate": 0.000100404124628511,
        "gradient_norm": 0.4416361451148987,
        "train_loss": 3.027527332305908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25104,
        "tokens": 13161725952,
        "learning_rate": 0.0001003890522483638,
        "gradient_norm": 0.4326978623867035,
        "train_loss": 3.028350830078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25105,
        "tokens": 13162250240,
        "learning_rate": 0.00010037398245277398,
        "gradient_norm": 0.4584082067012787,
        "train_loss": 3.0407779216766357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25106,
        "tokens": 13162774528,
        "learning_rate": 0.00010035891524191127,
        "gradient_norm": 0.511216402053833,
        "train_loss": 3.1483259201049805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25107,
        "tokens": 13163298816,
        "learning_rate": 0.00010034385061594516,
        "gradient_norm": 0.5107918381690979,
        "train_loss": 3.0017428398132324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25108,
        "tokens": 13163823104,
        "learning_rate": 0.00010032878857504538,
        "gradient_norm": 0.488145112991333,
        "train_loss": 3.0521154403686523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25109,
        "tokens": 13164347392,
        "learning_rate": 0.00010031372911938129,
        "gradient_norm": 0.4521777033805847,
        "train_loss": 3.039912700653076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25110,
        "tokens": 13164871680,
        "learning_rate": 0.00010029867224912249,
        "gradient_norm": 0.4101911187171936,
        "train_loss": 3.0215489864349365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25111,
        "tokens": 13165395968,
        "learning_rate": 0.00010028361796443852,
        "gradient_norm": 0.4400458037853241,
        "train_loss": 3.0980355739593506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25112,
        "tokens": 13165920256,
        "learning_rate": 0.00010026856626549872,
        "gradient_norm": 0.4199925661087036,
        "train_loss": 3.009108543395996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25113,
        "tokens": 13166444544,
        "learning_rate": 0.00010025351715247264,
        "gradient_norm": 0.4483516216278076,
        "train_loss": 3.0647354125976562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25114,
        "tokens": 13166968832,
        "learning_rate": 0.00010023847062552954,
        "gradient_norm": 0.3908807933330536,
        "train_loss": 3.0752594470977783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25115,
        "tokens": 13167493120,
        "learning_rate": 0.00010022342668483894,
        "gradient_norm": 0.38517680764198303,
        "train_loss": 3.0188791751861572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25116,
        "tokens": 13168017408,
        "learning_rate": 0.00010020838533057004,
        "gradient_norm": 0.43545833230018616,
        "train_loss": 3.014777183532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25117,
        "tokens": 13168541696,
        "learning_rate": 0.00010019334656289224,
        "gradient_norm": 0.43722665309906006,
        "train_loss": 3.0100841522216797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25118,
        "tokens": 13169065984,
        "learning_rate": 0.00010017831038197474,
        "gradient_norm": 0.41324952244758606,
        "train_loss": 3.050450325012207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25119,
        "tokens": 13169590272,
        "learning_rate": 0.00010016327678798691,
        "gradient_norm": 0.4254281520843506,
        "train_loss": 3.019559860229492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25120,
        "tokens": 13170114560,
        "learning_rate": 0.00010014824578109782,
        "gradient_norm": 0.4193791151046753,
        "train_loss": 3.018439292907715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25121,
        "tokens": 13170638848,
        "learning_rate": 0.00010013321736147678,
        "gradient_norm": 0.4188057780265808,
        "train_loss": 2.9986538887023926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25122,
        "tokens": 13171163136,
        "learning_rate": 0.00010011819152929289,
        "gradient_norm": 0.4049951434135437,
        "train_loss": 3.0361087322235107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25123,
        "tokens": 13171687424,
        "learning_rate": 0.00010010316828471536,
        "gradient_norm": 0.4266664981842041,
        "train_loss": 3.0505433082580566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25124,
        "tokens": 13172211712,
        "learning_rate": 0.0001000881476279132,
        "gradient_norm": 0.4017651379108429,
        "train_loss": 2.9757847785949707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25125,
        "tokens": 13172736000,
        "learning_rate": 0.00010007312955905557,
        "gradient_norm": 0.3897891342639923,
        "train_loss": 2.9936275482177734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25126,
        "tokens": 13173260288,
        "learning_rate": 0.00010005811407831142,
        "gradient_norm": 0.4319223463535309,
        "train_loss": 3.0676746368408203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25127,
        "tokens": 13173784576,
        "learning_rate": 0.00010004310118584989,
        "gradient_norm": 0.44888412952423096,
        "train_loss": 3.082298994064331,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25128,
        "tokens": 13174308864,
        "learning_rate": 0.00010002809088183985,
        "gradient_norm": 0.4566073715686798,
        "train_loss": 3.0446457862854004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25129,
        "tokens": 13174833152,
        "learning_rate": 0.00010001308316645035,
        "gradient_norm": 0.40993380546569824,
        "train_loss": 2.989966869354248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25130,
        "tokens": 13175357440,
        "learning_rate": 9.999807803985026e-05,
        "gradient_norm": 0.451524019241333,
        "train_loss": 3.018378973007202,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25131,
        "tokens": 13175881728,
        "learning_rate": 9.998307550220855e-05,
        "gradient_norm": 0.4663771092891693,
        "train_loss": 2.9796180725097656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25132,
        "tokens": 13176406016,
        "learning_rate": 9.9968075553694e-05,
        "gradient_norm": 0.4070824682712555,
        "train_loss": 3.062913417816162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25133,
        "tokens": 13176930304,
        "learning_rate": 9.995307819447554e-05,
        "gradient_norm": 0.44858720898628235,
        "train_loss": 3.030477523803711,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25134,
        "tokens": 13177454592,
        "learning_rate": 9.993808342472189e-05,
        "gradient_norm": 0.43193677067756653,
        "train_loss": 3.0654876232147217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25135,
        "tokens": 13177978880,
        "learning_rate": 9.992309124460196e-05,
        "gradient_norm": 0.4236777424812317,
        "train_loss": 2.9969565868377686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25136,
        "tokens": 13178503168,
        "learning_rate": 9.990810165428439e-05,
        "gradient_norm": 0.41547757387161255,
        "train_loss": 3.023892641067505,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25137,
        "tokens": 13179027456,
        "learning_rate": 9.9893114653938e-05,
        "gradient_norm": 0.3957889974117279,
        "train_loss": 3.0421857833862305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25138,
        "tokens": 13179551744,
        "learning_rate": 9.987813024373136e-05,
        "gradient_norm": 0.41585105657577515,
        "train_loss": 2.9796485900878906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25139,
        "tokens": 13180076032,
        "learning_rate": 9.986314842383331e-05,
        "gradient_norm": 0.3776090443134308,
        "train_loss": 3.0420117378234863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25140,
        "tokens": 13180600320,
        "learning_rate": 9.984816919441233e-05,
        "gradient_norm": 0.3865502178668976,
        "train_loss": 3.0619735717773438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25141,
        "tokens": 13181124608,
        "learning_rate": 9.983319255563709e-05,
        "gradient_norm": 0.40535253286361694,
        "train_loss": 3.053359270095825,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25142,
        "tokens": 13181648896,
        "learning_rate": 9.981821850767623e-05,
        "gradient_norm": 0.41886278986930847,
        "train_loss": 2.9653632640838623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25143,
        "tokens": 13182173184,
        "learning_rate": 9.980324705069821e-05,
        "gradient_norm": 0.3860752284526825,
        "train_loss": 2.990450382232666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25144,
        "tokens": 13182697472,
        "learning_rate": 9.978827818487164e-05,
        "gradient_norm": 0.41134193539619446,
        "train_loss": 3.0526010990142822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25145,
        "tokens": 13183221760,
        "learning_rate": 9.977331191036492e-05,
        "gradient_norm": 0.40255966782569885,
        "train_loss": 3.0008440017700195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25146,
        "tokens": 13183746048,
        "learning_rate": 9.97583482273466e-05,
        "gradient_norm": 0.40072864294052124,
        "train_loss": 2.9667835235595703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25147,
        "tokens": 13184270336,
        "learning_rate": 9.974338713598501e-05,
        "gradient_norm": 0.3805975914001465,
        "train_loss": 3.017159938812256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25148,
        "tokens": 13184794624,
        "learning_rate": 9.972842863644871e-05,
        "gradient_norm": 0.41952574253082275,
        "train_loss": 3.0076117515563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25149,
        "tokens": 13185318912,
        "learning_rate": 9.971347272890589e-05,
        "gradient_norm": 0.35319966077804565,
        "train_loss": 3.037203788757324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25150,
        "tokens": 13185843200,
        "learning_rate": 9.969851941352503e-05,
        "gradient_norm": 0.3774358928203583,
        "train_loss": 2.993316650390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25151,
        "tokens": 13186367488,
        "learning_rate": 9.968356869047446e-05,
        "gradient_norm": 0.3695487976074219,
        "train_loss": 3.0650603771209717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25152,
        "tokens": 13186891776,
        "learning_rate": 9.966862055992236e-05,
        "gradient_norm": 0.42397457361221313,
        "train_loss": 2.9671878814697266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25153,
        "tokens": 13187416064,
        "learning_rate": 9.96536750220371e-05,
        "gradient_norm": 0.3764960765838623,
        "train_loss": 3.0543112754821777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25154,
        "tokens": 13187940352,
        "learning_rate": 9.963873207698681e-05,
        "gradient_norm": 0.389652818441391,
        "train_loss": 3.0172080993652344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25155,
        "tokens": 13188464640,
        "learning_rate": 9.962379172493979e-05,
        "gradient_norm": 0.3934187591075897,
        "train_loss": 3.092909812927246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25156,
        "tokens": 13188988928,
        "learning_rate": 9.960885396606412e-05,
        "gradient_norm": 0.45137453079223633,
        "train_loss": 3.0137100219726562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25157,
        "tokens": 13189513216,
        "learning_rate": 9.959391880052804e-05,
        "gradient_norm": 0.4078945517539978,
        "train_loss": 3.0468218326568604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25158,
        "tokens": 13190037504,
        "learning_rate": 9.957898622849957e-05,
        "gradient_norm": 0.4044586718082428,
        "train_loss": 2.999626636505127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25159,
        "tokens": 13190561792,
        "learning_rate": 9.95640562501469e-05,
        "gradient_norm": 0.44297662377357483,
        "train_loss": 3.0096092224121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25160,
        "tokens": 13191086080,
        "learning_rate": 9.954912886563793e-05,
        "gradient_norm": 0.40703484416007996,
        "train_loss": 3.004300594329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25161,
        "tokens": 13191610368,
        "learning_rate": 9.953420407514079e-05,
        "gradient_norm": 0.43744099140167236,
        "train_loss": 3.024264335632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25162,
        "tokens": 13192134656,
        "learning_rate": 9.951928187882354e-05,
        "gradient_norm": 0.42169317603111267,
        "train_loss": 3.059663772583008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25163,
        "tokens": 13192658944,
        "learning_rate": 9.950436227685401e-05,
        "gradient_norm": 0.4289598762989044,
        "train_loss": 3.0364818572998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25164,
        "tokens": 13193183232,
        "learning_rate": 9.948944526940026e-05,
        "gradient_norm": 0.43155112862586975,
        "train_loss": 3.0532541275024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25165,
        "tokens": 13193707520,
        "learning_rate": 9.947453085663009e-05,
        "gradient_norm": 0.4192367196083069,
        "train_loss": 3.065847158432007,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25166,
        "tokens": 13194231808,
        "learning_rate": 9.945961903871151e-05,
        "gradient_norm": 0.42567259073257446,
        "train_loss": 3.01556396484375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25167,
        "tokens": 13194756096,
        "learning_rate": 9.944470981581221e-05,
        "gradient_norm": 0.4549778699874878,
        "train_loss": 3.0121912956237793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25168,
        "tokens": 13195280384,
        "learning_rate": 9.942980318810015e-05,
        "gradient_norm": 0.41004228591918945,
        "train_loss": 3.0466837882995605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25169,
        "tokens": 13195804672,
        "learning_rate": 9.941489915574303e-05,
        "gradient_norm": 0.5291082262992859,
        "train_loss": 3.0094032287597656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25170,
        "tokens": 13196328960,
        "learning_rate": 9.939999771890865e-05,
        "gradient_norm": 0.4175202548503876,
        "train_loss": 3.0677034854888916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25171,
        "tokens": 13196853248,
        "learning_rate": 9.938509887776478e-05,
        "gradient_norm": 0.47265303134918213,
        "train_loss": 3.0074028968811035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25172,
        "tokens": 13197377536,
        "learning_rate": 9.937020263247901e-05,
        "gradient_norm": 0.3928728401660919,
        "train_loss": 2.988823413848877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25173,
        "tokens": 13197901824,
        "learning_rate": 9.935530898321922e-05,
        "gradient_norm": 0.4216797947883606,
        "train_loss": 3.0462021827697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25174,
        "tokens": 13198426112,
        "learning_rate": 9.934041793015284e-05,
        "gradient_norm": 0.39022210240364075,
        "train_loss": 3.0174293518066406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25175,
        "tokens": 13198950400,
        "learning_rate": 9.932552947344765e-05,
        "gradient_norm": 0.39343711733818054,
        "train_loss": 3.02927303314209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25176,
        "tokens": 13199474688,
        "learning_rate": 9.93106436132711e-05,
        "gradient_norm": 0.4352108836174011,
        "train_loss": 3.0538277626037598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25177,
        "tokens": 13199998976,
        "learning_rate": 9.929576034979089e-05,
        "gradient_norm": 0.4251646101474762,
        "train_loss": 3.032283306121826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25178,
        "tokens": 13200523264,
        "learning_rate": 9.92808796831744e-05,
        "gradient_norm": 0.39683452248573303,
        "train_loss": 3.00384259223938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25179,
        "tokens": 13201047552,
        "learning_rate": 9.926600161358929e-05,
        "gradient_norm": 0.4083065092563629,
        "train_loss": 3.051405429840088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25180,
        "tokens": 13201571840,
        "learning_rate": 9.925112614120289e-05,
        "gradient_norm": 0.4200838804244995,
        "train_loss": 3.0061917304992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25181,
        "tokens": 13202096128,
        "learning_rate": 9.923625326618265e-05,
        "gradient_norm": 0.4432407021522522,
        "train_loss": 3.074615955352783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25182,
        "tokens": 13202620416,
        "learning_rate": 9.922138298869615e-05,
        "gradient_norm": 0.43669262528419495,
        "train_loss": 3.0476293563842773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25183,
        "tokens": 13203144704,
        "learning_rate": 9.92065153089106e-05,
        "gradient_norm": 0.444065660238266,
        "train_loss": 2.9799628257751465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25184,
        "tokens": 13203668992,
        "learning_rate": 9.919165022699344e-05,
        "gradient_norm": 0.5966599583625793,
        "train_loss": 2.974430561065674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25185,
        "tokens": 13204193280,
        "learning_rate": 9.917678774311193e-05,
        "gradient_norm": 0.5154247879981995,
        "train_loss": 3.058584690093994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25186,
        "tokens": 13204717568,
        "learning_rate": 9.916192785743343e-05,
        "gradient_norm": 0.5679721832275391,
        "train_loss": 3.02048397064209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25187,
        "tokens": 13205241856,
        "learning_rate": 9.914707057012515e-05,
        "gradient_norm": 0.4335406422615051,
        "train_loss": 3.011445999145508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25188,
        "tokens": 13205766144,
        "learning_rate": 9.913221588135442e-05,
        "gradient_norm": 0.4405059814453125,
        "train_loss": 3.0173966884613037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25189,
        "tokens": 13206290432,
        "learning_rate": 9.911736379128829e-05,
        "gradient_norm": 0.7088441252708435,
        "train_loss": 3.1928837299346924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25190,
        "tokens": 13206814720,
        "learning_rate": 9.910251430009405e-05,
        "gradient_norm": 0.5558171272277832,
        "train_loss": 3.0983588695526123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25191,
        "tokens": 13207339008,
        "learning_rate": 9.908766740793891e-05,
        "gradient_norm": 0.5146745443344116,
        "train_loss": 3.0257740020751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25192,
        "tokens": 13207863296,
        "learning_rate": 9.907282311498987e-05,
        "gradient_norm": 0.49830612540245056,
        "train_loss": 3.034348726272583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25193,
        "tokens": 13208387584,
        "learning_rate": 9.905798142141408e-05,
        "gradient_norm": 0.5110425353050232,
        "train_loss": 3.0397934913635254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25194,
        "tokens": 13208911872,
        "learning_rate": 9.904314232737854e-05,
        "gradient_norm": 0.444527804851532,
        "train_loss": 3.0773417949676514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25195,
        "tokens": 13209436160,
        "learning_rate": 9.90283058330504e-05,
        "gradient_norm": 0.5286085605621338,
        "train_loss": 2.998581647872925,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25196,
        "tokens": 13209960448,
        "learning_rate": 9.90134719385965e-05,
        "gradient_norm": 0.5141814947128296,
        "train_loss": 3.0603907108306885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25197,
        "tokens": 13210484736,
        "learning_rate": 9.899864064418399e-05,
        "gradient_norm": 0.46792733669281006,
        "train_loss": 3.012051582336426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25198,
        "tokens": 13211009024,
        "learning_rate": 9.898381194997969e-05,
        "gradient_norm": 0.455940306186676,
        "train_loss": 3.0141780376434326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25199,
        "tokens": 13211533312,
        "learning_rate": 9.896898585615057e-05,
        "gradient_norm": 0.4907846450805664,
        "train_loss": 3.0477218627929688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25200,
        "tokens": 13212057600,
        "learning_rate": 9.895416236286346e-05,
        "gradient_norm": 0.44248032569885254,
        "train_loss": 3.0286319255828857,
        "val_loss": 2.9794235229492188,
        "hellaswag_acc": 0.2869946360588074,
        "hellaswag_acc_norm": 0.29784902930259705
    },
    {
        "step": 25201,
        "tokens": 13212581888,
        "learning_rate": 9.893934147028528e-05,
        "gradient_norm": 0.4104204773902893,
        "train_loss": 3.080207347869873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25202,
        "tokens": 13213106176,
        "learning_rate": 9.892452317858286e-05,
        "gradient_norm": 0.41843050718307495,
        "train_loss": 3.008803367614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25203,
        "tokens": 13213630464,
        "learning_rate": 9.890970748792295e-05,
        "gradient_norm": 0.43603047728538513,
        "train_loss": 3.0154411792755127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25204,
        "tokens": 13214154752,
        "learning_rate": 9.889489439847242e-05,
        "gradient_norm": 0.3981539011001587,
        "train_loss": 3.052262783050537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25205,
        "tokens": 13214679040,
        "learning_rate": 9.888008391039782e-05,
        "gradient_norm": 0.4100334644317627,
        "train_loss": 3.043548583984375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25206,
        "tokens": 13215203328,
        "learning_rate": 9.886527602386605e-05,
        "gradient_norm": 0.4483501613140106,
        "train_loss": 3.0369677543640137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25207,
        "tokens": 13215727616,
        "learning_rate": 9.885047073904366e-05,
        "gradient_norm": 0.3983473777770996,
        "train_loss": 3.0274510383605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25208,
        "tokens": 13216251904,
        "learning_rate": 9.883566805609742e-05,
        "gradient_norm": 0.4083983898162842,
        "train_loss": 3.012927770614624,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25209,
        "tokens": 13216776192,
        "learning_rate": 9.882086797519384e-05,
        "gradient_norm": 0.3996416926383972,
        "train_loss": 3.0220723152160645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25210,
        "tokens": 13217300480,
        "learning_rate": 9.880607049649956e-05,
        "gradient_norm": 0.4340851306915283,
        "train_loss": 3.0637896060943604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25211,
        "tokens": 13217824768,
        "learning_rate": 9.879127562018118e-05,
        "gradient_norm": 0.647311806678772,
        "train_loss": 3.0602059364318848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25212,
        "tokens": 13218349056,
        "learning_rate": 9.877648334640515e-05,
        "gradient_norm": 0.4779551327228546,
        "train_loss": 3.019568920135498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25213,
        "tokens": 13218873344,
        "learning_rate": 9.876169367533812e-05,
        "gradient_norm": 0.5416231751441956,
        "train_loss": 3.0486841201782227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25214,
        "tokens": 13219397632,
        "learning_rate": 9.87469066071464e-05,
        "gradient_norm": 0.42410069704055786,
        "train_loss": 3.031096935272217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25215,
        "tokens": 13219921920,
        "learning_rate": 9.873212214199657e-05,
        "gradient_norm": 0.45305684208869934,
        "train_loss": 3.0836310386657715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25216,
        "tokens": 13220446208,
        "learning_rate": 9.871734028005493e-05,
        "gradient_norm": 0.43914225697517395,
        "train_loss": 3.008030414581299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25217,
        "tokens": 13220970496,
        "learning_rate": 9.870256102148796e-05,
        "gradient_norm": 0.4568365812301636,
        "train_loss": 2.994833469390869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25218,
        "tokens": 13221494784,
        "learning_rate": 9.868778436646194e-05,
        "gradient_norm": 0.41719090938568115,
        "train_loss": 3.009921073913574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25219,
        "tokens": 13222019072,
        "learning_rate": 9.867301031514332e-05,
        "gradient_norm": 0.39291611313819885,
        "train_loss": 3.061056613922119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25220,
        "tokens": 13222543360,
        "learning_rate": 9.865823886769825e-05,
        "gradient_norm": 0.41898515820503235,
        "train_loss": 3.0258736610412598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25221,
        "tokens": 13223067648,
        "learning_rate": 9.864347002429308e-05,
        "gradient_norm": 0.42964425683021545,
        "train_loss": 3.0097193717956543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25222,
        "tokens": 13223591936,
        "learning_rate": 9.86287037850941e-05,
        "gradient_norm": 0.3826495409011841,
        "train_loss": 2.972365617752075,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25223,
        "tokens": 13224116224,
        "learning_rate": 9.861394015026742e-05,
        "gradient_norm": 0.3817709684371948,
        "train_loss": 3.0575411319732666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25224,
        "tokens": 13224640512,
        "learning_rate": 9.859917911997934e-05,
        "gradient_norm": 0.4231218099594116,
        "train_loss": 3.0945072174072266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25225,
        "tokens": 13225164800,
        "learning_rate": 9.858442069439591e-05,
        "gradient_norm": 0.42677974700927734,
        "train_loss": 3.0445213317871094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25226,
        "tokens": 13225689088,
        "learning_rate": 9.85696648736833e-05,
        "gradient_norm": 0.37395158410072327,
        "train_loss": 3.020859718322754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25227,
        "tokens": 13226213376,
        "learning_rate": 9.855491165800758e-05,
        "gradient_norm": 0.41560477018356323,
        "train_loss": 3.0415380001068115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25228,
        "tokens": 13226737664,
        "learning_rate": 9.854016104753486e-05,
        "gradient_norm": 0.4062466025352478,
        "train_loss": 3.059938907623291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25229,
        "tokens": 13227261952,
        "learning_rate": 9.852541304243112e-05,
        "gradient_norm": 0.42292270064353943,
        "train_loss": 2.9949097633361816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25230,
        "tokens": 13227786240,
        "learning_rate": 9.851066764286244e-05,
        "gradient_norm": 0.4298938810825348,
        "train_loss": 3.033390522003174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25231,
        "tokens": 13228310528,
        "learning_rate": 9.849592484899468e-05,
        "gradient_norm": 0.42257553339004517,
        "train_loss": 3.000459671020508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25232,
        "tokens": 13228834816,
        "learning_rate": 9.848118466099394e-05,
        "gradient_norm": 0.4088670313358307,
        "train_loss": 2.975433111190796,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25233,
        "tokens": 13229359104,
        "learning_rate": 9.8466447079026e-05,
        "gradient_norm": 0.7575150728225708,
        "train_loss": 3.2530457973480225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25234,
        "tokens": 13229883392,
        "learning_rate": 9.845171210325688e-05,
        "gradient_norm": 0.6333659887313843,
        "train_loss": 3.0181024074554443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25235,
        "tokens": 13230407680,
        "learning_rate": 9.84369797338523e-05,
        "gradient_norm": 0.5437353253364563,
        "train_loss": 2.992490530014038,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25236,
        "tokens": 13230931968,
        "learning_rate": 9.842224997097826e-05,
        "gradient_norm": 0.5531826019287109,
        "train_loss": 3.007880210876465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25237,
        "tokens": 13231456256,
        "learning_rate": 9.840752281480037e-05,
        "gradient_norm": 0.5490778088569641,
        "train_loss": 3.0545310974121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25238,
        "tokens": 13231980544,
        "learning_rate": 9.839279826548455e-05,
        "gradient_norm": 0.49209561944007874,
        "train_loss": 2.988065719604492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25239,
        "tokens": 13232504832,
        "learning_rate": 9.837807632319645e-05,
        "gradient_norm": 0.5411300659179688,
        "train_loss": 3.0263588428497314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25240,
        "tokens": 13233029120,
        "learning_rate": 9.836335698810189e-05,
        "gradient_norm": 0.4291861057281494,
        "train_loss": 3.003635883331299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25241,
        "tokens": 13233553408,
        "learning_rate": 9.834864026036643e-05,
        "gradient_norm": 0.5356172323226929,
        "train_loss": 3.0627903938293457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25242,
        "tokens": 13234077696,
        "learning_rate": 9.833392614015584e-05,
        "gradient_norm": 0.4845021069049835,
        "train_loss": 3.1010947227478027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25243,
        "tokens": 13234601984,
        "learning_rate": 9.831921462763563e-05,
        "gradient_norm": 0.4513135850429535,
        "train_loss": 3.0313844680786133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25244,
        "tokens": 13235126272,
        "learning_rate": 9.830450572297149e-05,
        "gradient_norm": 0.4390254020690918,
        "train_loss": 3.0113658905029297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25245,
        "tokens": 13235650560,
        "learning_rate": 9.828979942632893e-05,
        "gradient_norm": 0.4791819155216217,
        "train_loss": 3.039076805114746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25246,
        "tokens": 13236174848,
        "learning_rate": 9.827509573787355e-05,
        "gradient_norm": 0.4235912561416626,
        "train_loss": 3.068469285964966,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25247,
        "tokens": 13236699136,
        "learning_rate": 9.826039465777079e-05,
        "gradient_norm": 0.4531395733356476,
        "train_loss": 3.0304157733917236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25248,
        "tokens": 13237223424,
        "learning_rate": 9.82456961861862e-05,
        "gradient_norm": 0.5784779191017151,
        "train_loss": 3.0116522312164307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25249,
        "tokens": 13237747712,
        "learning_rate": 9.823100032328513e-05,
        "gradient_norm": 0.5937380790710449,
        "train_loss": 3.068769693374634,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25250,
        "tokens": 13238272000,
        "learning_rate": 9.821630706923303e-05,
        "gradient_norm": 0.5206374526023865,
        "train_loss": 3.035254955291748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25251,
        "tokens": 13238796288,
        "learning_rate": 9.820161642419541e-05,
        "gradient_norm": 0.43570849299430847,
        "train_loss": 3.014309883117676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25252,
        "tokens": 13239320576,
        "learning_rate": 9.818692838833749e-05,
        "gradient_norm": 0.4608185887336731,
        "train_loss": 3.0197291374206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25253,
        "tokens": 13239844864,
        "learning_rate": 9.81722429618247e-05,
        "gradient_norm": 0.42651551961898804,
        "train_loss": 2.9651970863342285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25254,
        "tokens": 13240369152,
        "learning_rate": 9.815756014482224e-05,
        "gradient_norm": 0.3956151008605957,
        "train_loss": 3.0583832263946533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25255,
        "tokens": 13240893440,
        "learning_rate": 9.814287993749552e-05,
        "gradient_norm": 0.47429031133651733,
        "train_loss": 3.0244038105010986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25256,
        "tokens": 13241417728,
        "learning_rate": 9.812820234000958e-05,
        "gradient_norm": 0.4148942828178406,
        "train_loss": 3.1023612022399902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25257,
        "tokens": 13241942016,
        "learning_rate": 9.811352735252988e-05,
        "gradient_norm": 0.4492793381214142,
        "train_loss": 3.07009220123291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25258,
        "tokens": 13242466304,
        "learning_rate": 9.80988549752214e-05,
        "gradient_norm": 0.4129336178302765,
        "train_loss": 2.9683685302734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25259,
        "tokens": 13242990592,
        "learning_rate": 9.808418520824946e-05,
        "gradient_norm": 0.3969084918498993,
        "train_loss": 3.0431389808654785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25260,
        "tokens": 13243514880,
        "learning_rate": 9.806951805177903e-05,
        "gradient_norm": 0.39842215180397034,
        "train_loss": 3.075451612472534,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25261,
        "tokens": 13244039168,
        "learning_rate": 9.805485350597527e-05,
        "gradient_norm": 0.44740065932273865,
        "train_loss": 3.062544107437134,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25262,
        "tokens": 13244563456,
        "learning_rate": 9.804019157100333e-05,
        "gradient_norm": 0.4387700855731964,
        "train_loss": 2.999401092529297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25263,
        "tokens": 13245087744,
        "learning_rate": 9.802553224702812e-05,
        "gradient_norm": 0.4007483720779419,
        "train_loss": 3.0155205726623535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25264,
        "tokens": 13245612032,
        "learning_rate": 9.801087553421478e-05,
        "gradient_norm": 0.4720298945903778,
        "train_loss": 3.0476951599121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25265,
        "tokens": 13246136320,
        "learning_rate": 9.799622143272814e-05,
        "gradient_norm": 0.4565412104129791,
        "train_loss": 3.040540933609009,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25266,
        "tokens": 13246660608,
        "learning_rate": 9.798156994273332e-05,
        "gradient_norm": 0.43298012018203735,
        "train_loss": 3.0171382427215576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25267,
        "tokens": 13247184896,
        "learning_rate": 9.796692106439506e-05,
        "gradient_norm": 0.40840065479278564,
        "train_loss": 3.0283353328704834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25268,
        "tokens": 13247709184,
        "learning_rate": 9.795227479787841e-05,
        "gradient_norm": 0.4006251096725464,
        "train_loss": 2.9924864768981934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25269,
        "tokens": 13248233472,
        "learning_rate": 9.79376311433481e-05,
        "gradient_norm": 0.43571269512176514,
        "train_loss": 3.022277355194092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25270,
        "tokens": 13248757760,
        "learning_rate": 9.792299010096901e-05,
        "gradient_norm": 0.44496506452560425,
        "train_loss": 3.0420427322387695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25271,
        "tokens": 13249282048,
        "learning_rate": 9.790835167090603e-05,
        "gradient_norm": 0.4151385724544525,
        "train_loss": 2.9679770469665527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25272,
        "tokens": 13249806336,
        "learning_rate": 9.78937158533238e-05,
        "gradient_norm": 0.47110310196876526,
        "train_loss": 2.9637184143066406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25273,
        "tokens": 13250330624,
        "learning_rate": 9.78790826483872e-05,
        "gradient_norm": 0.4217187464237213,
        "train_loss": 3.0366878509521484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25274,
        "tokens": 13250854912,
        "learning_rate": 9.78644520562608e-05,
        "gradient_norm": 0.40857475996017456,
        "train_loss": 3.0635337829589844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25275,
        "tokens": 13251379200,
        "learning_rate": 9.784982407710941e-05,
        "gradient_norm": 0.4165421426296234,
        "train_loss": 3.0430526733398438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25276,
        "tokens": 13251903488,
        "learning_rate": 9.78351987110976e-05,
        "gradient_norm": 0.5294374227523804,
        "train_loss": 3.108201742172241,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25277,
        "tokens": 13252427776,
        "learning_rate": 9.782057595839007e-05,
        "gradient_norm": 0.43971553444862366,
        "train_loss": 3.0384254455566406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25278,
        "tokens": 13252952064,
        "learning_rate": 9.780595581915133e-05,
        "gradient_norm": 0.4387209713459015,
        "train_loss": 2.9953315258026123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25279,
        "tokens": 13253476352,
        "learning_rate": 9.779133829354602e-05,
        "gradient_norm": 0.5401976108551025,
        "train_loss": 3.0511574745178223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25280,
        "tokens": 13254000640,
        "learning_rate": 9.777672338173862e-05,
        "gradient_norm": 0.42013904452323914,
        "train_loss": 3.02811336517334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25281,
        "tokens": 13254524928,
        "learning_rate": 9.776211108389367e-05,
        "gradient_norm": 0.45033666491508484,
        "train_loss": 3.003225803375244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25282,
        "tokens": 13255049216,
        "learning_rate": 9.774750140017569e-05,
        "gradient_norm": 0.4635527729988098,
        "train_loss": 3.0413107872009277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25283,
        "tokens": 13255573504,
        "learning_rate": 9.773289433074906e-05,
        "gradient_norm": 0.41192132234573364,
        "train_loss": 3.021808624267578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25284,
        "tokens": 13256097792,
        "learning_rate": 9.77182898757783e-05,
        "gradient_norm": 0.42040279507637024,
        "train_loss": 2.994171619415283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25285,
        "tokens": 13256622080,
        "learning_rate": 9.770368803542766e-05,
        "gradient_norm": 0.39565762877464294,
        "train_loss": 3.082164764404297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25286,
        "tokens": 13257146368,
        "learning_rate": 9.768908880986162e-05,
        "gradient_norm": 0.3833363950252533,
        "train_loss": 3.008277416229248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25287,
        "tokens": 13257670656,
        "learning_rate": 9.767449219924442e-05,
        "gradient_norm": 0.3866528272628784,
        "train_loss": 3.0284111499786377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25288,
        "tokens": 13258194944,
        "learning_rate": 9.765989820374046e-05,
        "gradient_norm": 0.40031591057777405,
        "train_loss": 3.022346258163452,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25289,
        "tokens": 13258719232,
        "learning_rate": 9.764530682351393e-05,
        "gradient_norm": 0.43519508838653564,
        "train_loss": 3.025155544281006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25290,
        "tokens": 13259243520,
        "learning_rate": 9.763071805872909e-05,
        "gradient_norm": 0.39390093088150024,
        "train_loss": 3.008604049682617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25291,
        "tokens": 13259767808,
        "learning_rate": 9.761613190955025e-05,
        "gradient_norm": 0.39648568630218506,
        "train_loss": 3.000843048095703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25292,
        "tokens": 13260292096,
        "learning_rate": 9.760154837614146e-05,
        "gradient_norm": 0.3768192231655121,
        "train_loss": 2.992685079574585,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25293,
        "tokens": 13260816384,
        "learning_rate": 9.758696745866698e-05,
        "gradient_norm": 0.4201112687587738,
        "train_loss": 3.0014901161193848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25294,
        "tokens": 13261340672,
        "learning_rate": 9.757238915729086e-05,
        "gradient_norm": 0.37017521262168884,
        "train_loss": 3.0020458698272705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25295,
        "tokens": 13261864960,
        "learning_rate": 9.755781347217725e-05,
        "gradient_norm": 0.3841794431209564,
        "train_loss": 3.0031697750091553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25296,
        "tokens": 13262389248,
        "learning_rate": 9.754324040349018e-05,
        "gradient_norm": 0.37962254881858826,
        "train_loss": 2.9906954765319824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25297,
        "tokens": 13262913536,
        "learning_rate": 9.752866995139372e-05,
        "gradient_norm": 0.3873705565929413,
        "train_loss": 3.0424773693084717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25298,
        "tokens": 13263437824,
        "learning_rate": 9.751410211605182e-05,
        "gradient_norm": 0.39326322078704834,
        "train_loss": 3.0013909339904785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25299,
        "tokens": 13263962112,
        "learning_rate": 9.749953689762857e-05,
        "gradient_norm": 0.4689483046531677,
        "train_loss": 3.0089590549468994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25300,
        "tokens": 13264486400,
        "learning_rate": 9.748497429628778e-05,
        "gradient_norm": 0.40950730443000793,
        "train_loss": 3.023587703704834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25301,
        "tokens": 13265010688,
        "learning_rate": 9.747041431219344e-05,
        "gradient_norm": 0.40505316853523254,
        "train_loss": 3.0497326850891113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25302,
        "tokens": 13265534976,
        "learning_rate": 9.745585694550952e-05,
        "gradient_norm": 0.41552838683128357,
        "train_loss": 3.0701088905334473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25303,
        "tokens": 13266059264,
        "learning_rate": 9.744130219639972e-05,
        "gradient_norm": 0.4427560567855835,
        "train_loss": 2.9926700592041016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25304,
        "tokens": 13266583552,
        "learning_rate": 9.742675006502803e-05,
        "gradient_norm": 0.45846253633499146,
        "train_loss": 3.0115115642547607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25305,
        "tokens": 13267107840,
        "learning_rate": 9.741220055155814e-05,
        "gradient_norm": 0.42974916100502014,
        "train_loss": 3.016944169998169,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25306,
        "tokens": 13267632128,
        "learning_rate": 9.739765365615389e-05,
        "gradient_norm": 0.404721200466156,
        "train_loss": 3.03871488571167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25307,
        "tokens": 13268156416,
        "learning_rate": 9.738310937897895e-05,
        "gradient_norm": 0.43469366431236267,
        "train_loss": 3.0447089672088623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25308,
        "tokens": 13268680704,
        "learning_rate": 9.73685677201971e-05,
        "gradient_norm": 0.45031318068504333,
        "train_loss": 3.003821849822998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25309,
        "tokens": 13269204992,
        "learning_rate": 9.735402867997199e-05,
        "gradient_norm": 0.4447703957557678,
        "train_loss": 2.999321937561035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25310,
        "tokens": 13269729280,
        "learning_rate": 9.733949225846729e-05,
        "gradient_norm": 0.4490354359149933,
        "train_loss": 3.031280994415283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25311,
        "tokens": 13270253568,
        "learning_rate": 9.732495845584665e-05,
        "gradient_norm": 0.616860032081604,
        "train_loss": 2.9681906700134277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25312,
        "tokens": 13270777856,
        "learning_rate": 9.73104272722736e-05,
        "gradient_norm": 0.41397958993911743,
        "train_loss": 2.9873361587524414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25313,
        "tokens": 13271302144,
        "learning_rate": 9.729589870791181e-05,
        "gradient_norm": 0.5796213150024414,
        "train_loss": 3.083512783050537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25314,
        "tokens": 13271826432,
        "learning_rate": 9.728137276292467e-05,
        "gradient_norm": 0.4147893190383911,
        "train_loss": 2.9953882694244385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25315,
        "tokens": 13272350720,
        "learning_rate": 9.726684943747586e-05,
        "gradient_norm": 0.6065369844436646,
        "train_loss": 3.017164945602417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25316,
        "tokens": 13272875008,
        "learning_rate": 9.72523287317287e-05,
        "gradient_norm": 0.5387001633644104,
        "train_loss": 3.0421295166015625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25317,
        "tokens": 13273399296,
        "learning_rate": 9.723781064584675e-05,
        "gradient_norm": 0.45043420791625977,
        "train_loss": 3.065147876739502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25318,
        "tokens": 13273923584,
        "learning_rate": 9.722329517999332e-05,
        "gradient_norm": 0.4905022084712982,
        "train_loss": 3.016981601715088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25319,
        "tokens": 13274447872,
        "learning_rate": 9.720878233433197e-05,
        "gradient_norm": 0.41334059834480286,
        "train_loss": 3.0125036239624023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25320,
        "tokens": 13274972160,
        "learning_rate": 9.719427210902588e-05,
        "gradient_norm": 0.48832130432128906,
        "train_loss": 3.0148119926452637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25321,
        "tokens": 13275496448,
        "learning_rate": 9.717976450423844e-05,
        "gradient_norm": 0.43763062357902527,
        "train_loss": 2.999600648880005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25322,
        "tokens": 13276020736,
        "learning_rate": 9.716525952013304e-05,
        "gradient_norm": 0.47729039192199707,
        "train_loss": 3.073195457458496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25323,
        "tokens": 13276545024,
        "learning_rate": 9.715075715687282e-05,
        "gradient_norm": 0.45319923758506775,
        "train_loss": 2.976395845413208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25324,
        "tokens": 13277069312,
        "learning_rate": 9.713625741462114e-05,
        "gradient_norm": 0.4210580885410309,
        "train_loss": 3.1163392066955566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25325,
        "tokens": 13277593600,
        "learning_rate": 9.71217602935411e-05,
        "gradient_norm": 0.45100975036621094,
        "train_loss": 3.057459592819214,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25326,
        "tokens": 13278117888,
        "learning_rate": 9.710726579379598e-05,
        "gradient_norm": 0.4107995331287384,
        "train_loss": 3.0067224502563477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25327,
        "tokens": 13278642176,
        "learning_rate": 9.709277391554887e-05,
        "gradient_norm": 0.4345132112503052,
        "train_loss": 3.064777135848999,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25328,
        "tokens": 13279166464,
        "learning_rate": 9.707828465896294e-05,
        "gradient_norm": 0.4181184470653534,
        "train_loss": 3.0388944149017334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25329,
        "tokens": 13279690752,
        "learning_rate": 9.706379802420121e-05,
        "gradient_norm": 0.43576714396476746,
        "train_loss": 3.0473523139953613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25330,
        "tokens": 13280215040,
        "learning_rate": 9.704931401142687e-05,
        "gradient_norm": 0.46188685297966003,
        "train_loss": 3.013355255126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25331,
        "tokens": 13280739328,
        "learning_rate": 9.703483262080281e-05,
        "gradient_norm": 0.4588754177093506,
        "train_loss": 3.0337533950805664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25332,
        "tokens": 13281263616,
        "learning_rate": 9.702035385249218e-05,
        "gradient_norm": 0.4646327495574951,
        "train_loss": 3.0185351371765137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25333,
        "tokens": 13281787904,
        "learning_rate": 9.700587770665778e-05,
        "gradient_norm": 0.402765691280365,
        "train_loss": 3.038330316543579,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25334,
        "tokens": 13282312192,
        "learning_rate": 9.699140418346276e-05,
        "gradient_norm": 0.5202361941337585,
        "train_loss": 2.992779016494751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25335,
        "tokens": 13282836480,
        "learning_rate": 9.697693328306986e-05,
        "gradient_norm": 0.3705641031265259,
        "train_loss": 3.020004987716675,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25336,
        "tokens": 13283360768,
        "learning_rate": 9.696246500564214e-05,
        "gradient_norm": 0.4558485150337219,
        "train_loss": 3.052889823913574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25337,
        "tokens": 13283885056,
        "learning_rate": 9.694799935134228e-05,
        "gradient_norm": 0.4395260512828827,
        "train_loss": 2.9754996299743652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25338,
        "tokens": 13284409344,
        "learning_rate": 9.693353632033325e-05,
        "gradient_norm": 0.41651928424835205,
        "train_loss": 3.0482563972473145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25339,
        "tokens": 13284933632,
        "learning_rate": 9.691907591277774e-05,
        "gradient_norm": 0.42958804965019226,
        "train_loss": 3.023678779602051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25340,
        "tokens": 13285457920,
        "learning_rate": 9.690461812883865e-05,
        "gradient_norm": 0.43110373616218567,
        "train_loss": 3.0437099933624268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25341,
        "tokens": 13285982208,
        "learning_rate": 9.689016296867857e-05,
        "gradient_norm": 0.4352097809314728,
        "train_loss": 3.016239643096924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25342,
        "tokens": 13286506496,
        "learning_rate": 9.687571043246035e-05,
        "gradient_norm": 0.3963310420513153,
        "train_loss": 3.0116777420043945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25343,
        "tokens": 13287030784,
        "learning_rate": 9.686126052034654e-05,
        "gradient_norm": 0.4786456227302551,
        "train_loss": 3.0708670616149902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25344,
        "tokens": 13287555072,
        "learning_rate": 9.684681323249991e-05,
        "gradient_norm": 0.381817102432251,
        "train_loss": 3.01705002784729,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25345,
        "tokens": 13288079360,
        "learning_rate": 9.683236856908298e-05,
        "gradient_norm": 0.43985551595687866,
        "train_loss": 3.072728395462036,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25346,
        "tokens": 13288603648,
        "learning_rate": 9.681792653025846e-05,
        "gradient_norm": 0.44527897238731384,
        "train_loss": 3.0685553550720215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25347,
        "tokens": 13289127936,
        "learning_rate": 9.680348711618876e-05,
        "gradient_norm": 0.4376600980758667,
        "train_loss": 3.0537352561950684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25348,
        "tokens": 13289652224,
        "learning_rate": 9.678905032703652e-05,
        "gradient_norm": 0.42242932319641113,
        "train_loss": 3.011353015899658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25349,
        "tokens": 13290176512,
        "learning_rate": 9.677461616296431e-05,
        "gradient_norm": 0.4487495422363281,
        "train_loss": 3.0552451610565186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25350,
        "tokens": 13290700800,
        "learning_rate": 9.676018462413441e-05,
        "gradient_norm": 0.43982064723968506,
        "train_loss": 3.009409189224243,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25351,
        "tokens": 13291225088,
        "learning_rate": 9.674575571070945e-05,
        "gradient_norm": 0.4124264717102051,
        "train_loss": 3.0583739280700684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25352,
        "tokens": 13291749376,
        "learning_rate": 9.673132942285173e-05,
        "gradient_norm": 0.3828998804092407,
        "train_loss": 3.020677328109741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25353,
        "tokens": 13292273664,
        "learning_rate": 9.671690576072371e-05,
        "gradient_norm": 0.4318733513355255,
        "train_loss": 3.0125391483306885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25354,
        "tokens": 13292797952,
        "learning_rate": 9.670248472448765e-05,
        "gradient_norm": 0.4606040120124817,
        "train_loss": 3.0190482139587402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25355,
        "tokens": 13293322240,
        "learning_rate": 9.668806631430598e-05,
        "gradient_norm": 0.39970144629478455,
        "train_loss": 2.986563205718994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25356,
        "tokens": 13293846528,
        "learning_rate": 9.667365053034094e-05,
        "gradient_norm": 0.4038305878639221,
        "train_loss": 3.0315499305725098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25357,
        "tokens": 13294370816,
        "learning_rate": 9.665923737275485e-05,
        "gradient_norm": 0.39226481318473816,
        "train_loss": 3.0051372051239014,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25358,
        "tokens": 13294895104,
        "learning_rate": 9.664482684170985e-05,
        "gradient_norm": 0.40042880177497864,
        "train_loss": 2.966567039489746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25359,
        "tokens": 13295419392,
        "learning_rate": 9.663041893736826e-05,
        "gradient_norm": 0.47221601009368896,
        "train_loss": 3.063241481781006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25360,
        "tokens": 13295943680,
        "learning_rate": 9.661601365989217e-05,
        "gradient_norm": 0.3777575194835663,
        "train_loss": 3.0499215126037598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25361,
        "tokens": 13296467968,
        "learning_rate": 9.660161100944374e-05,
        "gradient_norm": 0.3957535922527313,
        "train_loss": 3.0136141777038574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25362,
        "tokens": 13296992256,
        "learning_rate": 9.658721098618519e-05,
        "gradient_norm": 0.42289605736732483,
        "train_loss": 3.037369966506958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25363,
        "tokens": 13297516544,
        "learning_rate": 9.657281359027848e-05,
        "gradient_norm": 0.40293633937835693,
        "train_loss": 3.027414560317993,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25364,
        "tokens": 13298040832,
        "learning_rate": 9.65584188218858e-05,
        "gradient_norm": 0.4275767207145691,
        "train_loss": 3.0271708965301514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25365,
        "tokens": 13298565120,
        "learning_rate": 9.654402668116902e-05,
        "gradient_norm": 0.4153790771961212,
        "train_loss": 2.9985804557800293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25366,
        "tokens": 13299089408,
        "learning_rate": 9.652963716829031e-05,
        "gradient_norm": 0.4218690097332001,
        "train_loss": 2.961151599884033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25367,
        "tokens": 13299613696,
        "learning_rate": 9.65152502834115e-05,
        "gradient_norm": 0.4297422170639038,
        "train_loss": 2.956061601638794,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25368,
        "tokens": 13300137984,
        "learning_rate": 9.650086602669463e-05,
        "gradient_norm": 0.4288174510002136,
        "train_loss": 3.0202274322509766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25369,
        "tokens": 13300662272,
        "learning_rate": 9.648648439830154e-05,
        "gradient_norm": 0.40215733647346497,
        "train_loss": 3.0802435874938965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25370,
        "tokens": 13301186560,
        "learning_rate": 9.647210539839418e-05,
        "gradient_norm": 0.4205332100391388,
        "train_loss": 2.960285186767578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25371,
        "tokens": 13301710848,
        "learning_rate": 9.645772902713436e-05,
        "gradient_norm": 0.4184262752532959,
        "train_loss": 3.0165014266967773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25372,
        "tokens": 13302235136,
        "learning_rate": 9.644335528468393e-05,
        "gradient_norm": 0.430473268032074,
        "train_loss": 3.003721237182617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25373,
        "tokens": 13302759424,
        "learning_rate": 9.642898417120469e-05,
        "gradient_norm": 0.4061906337738037,
        "train_loss": 3.07405948638916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25374,
        "tokens": 13303283712,
        "learning_rate": 9.641461568685834e-05,
        "gradient_norm": 0.443229615688324,
        "train_loss": 3.0064804553985596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25375,
        "tokens": 13303808000,
        "learning_rate": 9.640024983180673e-05,
        "gradient_norm": 0.4169047772884369,
        "train_loss": 3.0050055980682373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25376,
        "tokens": 13304332288,
        "learning_rate": 9.638588660621141e-05,
        "gradient_norm": 0.4809885621070862,
        "train_loss": 2.9827542304992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25377,
        "tokens": 13304856576,
        "learning_rate": 9.637152601023425e-05,
        "gradient_norm": 0.4610421061515808,
        "train_loss": 3.030869960784912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25378,
        "tokens": 13305380864,
        "learning_rate": 9.63571680440367e-05,
        "gradient_norm": 0.41568103432655334,
        "train_loss": 3.0176382064819336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25379,
        "tokens": 13305905152,
        "learning_rate": 9.634281270778052e-05,
        "gradient_norm": 0.4546734094619751,
        "train_loss": 3.014378070831299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25380,
        "tokens": 13306429440,
        "learning_rate": 9.632846000162722e-05,
        "gradient_norm": 0.4347788393497467,
        "train_loss": 3.0436887741088867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25381,
        "tokens": 13306953728,
        "learning_rate": 9.631410992573831e-05,
        "gradient_norm": 0.3826257884502411,
        "train_loss": 3.014031171798706,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25382,
        "tokens": 13307478016,
        "learning_rate": 9.629976248027553e-05,
        "gradient_norm": 0.5029950737953186,
        "train_loss": 3.040682315826416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25383,
        "tokens": 13308002304,
        "learning_rate": 9.628541766540014e-05,
        "gradient_norm": 0.43472516536712646,
        "train_loss": 3.0905890464782715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25384,
        "tokens": 13308526592,
        "learning_rate": 9.627107548127377e-05,
        "gradient_norm": 0.45209282636642456,
        "train_loss": 2.999615430831909,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25385,
        "tokens": 13309050880,
        "learning_rate": 9.625673592805772e-05,
        "gradient_norm": 0.4489400386810303,
        "train_loss": 3.0403382778167725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25386,
        "tokens": 13309575168,
        "learning_rate": 9.624239900591356e-05,
        "gradient_norm": 0.4763587713241577,
        "train_loss": 3.0157580375671387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25387,
        "tokens": 13310099456,
        "learning_rate": 9.622806471500255e-05,
        "gradient_norm": 0.43859222531318665,
        "train_loss": 2.99861478805542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25388,
        "tokens": 13310623744,
        "learning_rate": 9.621373305548607e-05,
        "gradient_norm": 0.42724278569221497,
        "train_loss": 2.9772233963012695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25389,
        "tokens": 13311148032,
        "learning_rate": 9.619940402752546e-05,
        "gradient_norm": 0.434966117143631,
        "train_loss": 3.049891471862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25390,
        "tokens": 13311672320,
        "learning_rate": 9.618507763128192e-05,
        "gradient_norm": 0.40411126613616943,
        "train_loss": 3.029766082763672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25391,
        "tokens": 13312196608,
        "learning_rate": 9.617075386691691e-05,
        "gradient_norm": 0.47610995173454285,
        "train_loss": 3.0483479499816895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25392,
        "tokens": 13312720896,
        "learning_rate": 9.615643273459145e-05,
        "gradient_norm": 0.40629279613494873,
        "train_loss": 3.032409191131592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25393,
        "tokens": 13313245184,
        "learning_rate": 9.61421142344669e-05,
        "gradient_norm": 0.435283899307251,
        "train_loss": 3.0091538429260254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25394,
        "tokens": 13313769472,
        "learning_rate": 9.612779836670431e-05,
        "gradient_norm": 0.4113175868988037,
        "train_loss": 3.0100760459899902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25395,
        "tokens": 13314293760,
        "learning_rate": 9.611348513146497e-05,
        "gradient_norm": 0.4692192077636719,
        "train_loss": 2.985724449157715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25396,
        "tokens": 13314818048,
        "learning_rate": 9.609917452890979e-05,
        "gradient_norm": 0.40147864818573,
        "train_loss": 3.013735294342041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25397,
        "tokens": 13315342336,
        "learning_rate": 9.608486655920004e-05,
        "gradient_norm": 0.4160017967224121,
        "train_loss": 3.035154342651367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25398,
        "tokens": 13315866624,
        "learning_rate": 9.607056122249664e-05,
        "gradient_norm": 0.4407711327075958,
        "train_loss": 3.000385284423828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25399,
        "tokens": 13316390912,
        "learning_rate": 9.605625851896073e-05,
        "gradient_norm": 0.43700143694877625,
        "train_loss": 3.0090866088867188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25400,
        "tokens": 13316915200,
        "learning_rate": 9.60419584487532e-05,
        "gradient_norm": 0.42040953040122986,
        "train_loss": 3.061697483062744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25401,
        "tokens": 13317439488,
        "learning_rate": 9.602766101203506e-05,
        "gradient_norm": 0.401937335729599,
        "train_loss": 3.014765501022339,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25402,
        "tokens": 13317963776,
        "learning_rate": 9.601336620896733e-05,
        "gradient_norm": 0.4295615553855896,
        "train_loss": 3.0570545196533203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25403,
        "tokens": 13318488064,
        "learning_rate": 9.599907403971074e-05,
        "gradient_norm": 0.3871036767959595,
        "train_loss": 3.0619077682495117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25404,
        "tokens": 13319012352,
        "learning_rate": 9.598478450442635e-05,
        "gradient_norm": 0.4219673275947571,
        "train_loss": 2.962012767791748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25405,
        "tokens": 13319536640,
        "learning_rate": 9.597049760327486e-05,
        "gradient_norm": 0.3936099112033844,
        "train_loss": 3.002549171447754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25406,
        "tokens": 13320060928,
        "learning_rate": 9.595621333641719e-05,
        "gradient_norm": 0.3850184679031372,
        "train_loss": 3.0577821731567383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25407,
        "tokens": 13320585216,
        "learning_rate": 9.594193170401404e-05,
        "gradient_norm": 0.43060415983200073,
        "train_loss": 3.041329860687256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25408,
        "tokens": 13321109504,
        "learning_rate": 9.592765270622623e-05,
        "gradient_norm": 0.35135889053344727,
        "train_loss": 3.0341291427612305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25409,
        "tokens": 13321633792,
        "learning_rate": 9.591337634321442e-05,
        "gradient_norm": 0.4017024338245392,
        "train_loss": 2.994943380355835,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25410,
        "tokens": 13322158080,
        "learning_rate": 9.589910261513938e-05,
        "gradient_norm": 0.3802374005317688,
        "train_loss": 3.020432949066162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25411,
        "tokens": 13322682368,
        "learning_rate": 9.588483152216181e-05,
        "gradient_norm": 0.3980642557144165,
        "train_loss": 3.047530174255371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25412,
        "tokens": 13323206656,
        "learning_rate": 9.58705630644422e-05,
        "gradient_norm": 0.38874512910842896,
        "train_loss": 2.959832191467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25413,
        "tokens": 13323730944,
        "learning_rate": 9.585629724214134e-05,
        "gradient_norm": 0.4461202025413513,
        "train_loss": 3.036205291748047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25414,
        "tokens": 13324255232,
        "learning_rate": 9.584203405541968e-05,
        "gradient_norm": 0.44960731267929077,
        "train_loss": 3.031008243560791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25415,
        "tokens": 13324779520,
        "learning_rate": 9.582777350443784e-05,
        "gradient_norm": 0.414175808429718,
        "train_loss": 3.0504395961761475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25416,
        "tokens": 13325303808,
        "learning_rate": 9.581351558935628e-05,
        "gradient_norm": 0.47142237424850464,
        "train_loss": 2.934523105621338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25417,
        "tokens": 13325828096,
        "learning_rate": 9.579926031033555e-05,
        "gradient_norm": 0.47306200861930847,
        "train_loss": 2.9396190643310547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25418,
        "tokens": 13326352384,
        "learning_rate": 9.578500766753605e-05,
        "gradient_norm": 0.4228595495223999,
        "train_loss": 3.036501884460449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25419,
        "tokens": 13326876672,
        "learning_rate": 9.577075766111829e-05,
        "gradient_norm": 0.5436858534812927,
        "train_loss": 3.0458199977874756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25420,
        "tokens": 13327400960,
        "learning_rate": 9.575651029124258e-05,
        "gradient_norm": 0.5159910321235657,
        "train_loss": 3.0348095893859863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25421,
        "tokens": 13327925248,
        "learning_rate": 9.574226555806933e-05,
        "gradient_norm": 0.41207295656204224,
        "train_loss": 3.022362232208252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25422,
        "tokens": 13328449536,
        "learning_rate": 9.572802346175896e-05,
        "gradient_norm": 0.485868364572525,
        "train_loss": 3.0297136306762695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25423,
        "tokens": 13328973824,
        "learning_rate": 9.571378400247166e-05,
        "gradient_norm": 0.41475990414619446,
        "train_loss": 2.974710464477539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25424,
        "tokens": 13329498112,
        "learning_rate": 9.569954718036781e-05,
        "gradient_norm": 0.46722593903541565,
        "train_loss": 3.000617265701294,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25425,
        "tokens": 13330022400,
        "learning_rate": 9.568531299560757e-05,
        "gradient_norm": 0.44700750708580017,
        "train_loss": 3.0560431480407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25426,
        "tokens": 13330546688,
        "learning_rate": 9.567108144835126e-05,
        "gradient_norm": 0.3985382616519928,
        "train_loss": 3.0188746452331543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25427,
        "tokens": 13331070976,
        "learning_rate": 9.565685253875897e-05,
        "gradient_norm": 0.4881649315357208,
        "train_loss": 3.0522446632385254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25428,
        "tokens": 13331595264,
        "learning_rate": 9.5642626266991e-05,
        "gradient_norm": 0.39613741636276245,
        "train_loss": 3.0078024864196777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25429,
        "tokens": 13332119552,
        "learning_rate": 9.562840263320732e-05,
        "gradient_norm": 0.48209407925605774,
        "train_loss": 3.0674185752868652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25430,
        "tokens": 13332643840,
        "learning_rate": 9.561418163756811e-05,
        "gradient_norm": 0.41348353028297424,
        "train_loss": 3.0425009727478027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25431,
        "tokens": 13333168128,
        "learning_rate": 9.559996328023355e-05,
        "gradient_norm": 0.4373975396156311,
        "train_loss": 3.0400211811065674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25432,
        "tokens": 13333692416,
        "learning_rate": 9.558574756136352e-05,
        "gradient_norm": 0.4524739980697632,
        "train_loss": 3.0345335006713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25433,
        "tokens": 13334216704,
        "learning_rate": 9.557153448111816e-05,
        "gradient_norm": 0.41947874426841736,
        "train_loss": 3.0427727699279785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25434,
        "tokens": 13334740992,
        "learning_rate": 9.555732403965735e-05,
        "gradient_norm": 0.4186089336872101,
        "train_loss": 2.975616216659546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25435,
        "tokens": 13335265280,
        "learning_rate": 9.554311623714116e-05,
        "gradient_norm": 0.4203908145427704,
        "train_loss": 3.053813934326172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25436,
        "tokens": 13335789568,
        "learning_rate": 9.552891107372937e-05,
        "gradient_norm": 0.46370500326156616,
        "train_loss": 3.0511834621429443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25437,
        "tokens": 13336313856,
        "learning_rate": 9.551470854958204e-05,
        "gradient_norm": 0.4624233543872833,
        "train_loss": 3.0977606773376465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25438,
        "tokens": 13336838144,
        "learning_rate": 9.550050866485891e-05,
        "gradient_norm": 0.49838054180145264,
        "train_loss": 3.1081738471984863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25439,
        "tokens": 13337362432,
        "learning_rate": 9.548631141971991e-05,
        "gradient_norm": 0.4855608344078064,
        "train_loss": 3.004563331604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25440,
        "tokens": 13337886720,
        "learning_rate": 9.547211681432474e-05,
        "gradient_norm": 0.435588538646698,
        "train_loss": 3.042558193206787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25441,
        "tokens": 13338411008,
        "learning_rate": 9.545792484883332e-05,
        "gradient_norm": 0.4174347519874573,
        "train_loss": 3.0382771492004395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25442,
        "tokens": 13338935296,
        "learning_rate": 9.544373552340527e-05,
        "gradient_norm": 0.4186992645263672,
        "train_loss": 3.0211338996887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25443,
        "tokens": 13339459584,
        "learning_rate": 9.542954883820038e-05,
        "gradient_norm": 0.4289570152759552,
        "train_loss": 3.060347557067871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25444,
        "tokens": 13339983872,
        "learning_rate": 9.541536479337828e-05,
        "gradient_norm": 0.42795464396476746,
        "train_loss": 3.00028920173645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25445,
        "tokens": 13340508160,
        "learning_rate": 9.540118338909872e-05,
        "gradient_norm": 0.4113438129425049,
        "train_loss": 3.0221760272979736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25446,
        "tokens": 13341032448,
        "learning_rate": 9.538700462552123e-05,
        "gradient_norm": 0.43796399235725403,
        "train_loss": 3.05454158782959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25447,
        "tokens": 13341556736,
        "learning_rate": 9.537282850280551e-05,
        "gradient_norm": 0.40554726123809814,
        "train_loss": 2.991748809814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25448,
        "tokens": 13342081024,
        "learning_rate": 9.5358655021111e-05,
        "gradient_norm": 0.4344293475151062,
        "train_loss": 3.024118423461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25449,
        "tokens": 13342605312,
        "learning_rate": 9.53444841805974e-05,
        "gradient_norm": 0.4413888156414032,
        "train_loss": 3.045839309692383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25450,
        "tokens": 13343129600,
        "learning_rate": 9.533031598142407e-05,
        "gradient_norm": 0.3717110753059387,
        "train_loss": 2.9783573150634766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25451,
        "tokens": 13343653888,
        "learning_rate": 9.53161504237506e-05,
        "gradient_norm": 0.4405117332935333,
        "train_loss": 3.0362510681152344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25452,
        "tokens": 13344178176,
        "learning_rate": 9.530198750773634e-05,
        "gradient_norm": 0.40429431200027466,
        "train_loss": 3.0529332160949707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25453,
        "tokens": 13344702464,
        "learning_rate": 9.528782723354086e-05,
        "gradient_norm": 0.3971143960952759,
        "train_loss": 3.0591068267822266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25454,
        "tokens": 13345226752,
        "learning_rate": 9.527366960132337e-05,
        "gradient_norm": 0.4431911110877991,
        "train_loss": 3.010303497314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25455,
        "tokens": 13345751040,
        "learning_rate": 9.525951461124339e-05,
        "gradient_norm": 0.44913601875305176,
        "train_loss": 3.057433605194092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25456,
        "tokens": 13346275328,
        "learning_rate": 9.524536226346014e-05,
        "gradient_norm": 0.3877861201763153,
        "train_loss": 3.010570526123047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25457,
        "tokens": 13346799616,
        "learning_rate": 9.5231212558133e-05,
        "gradient_norm": 0.40720176696777344,
        "train_loss": 2.989485502243042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25458,
        "tokens": 13347323904,
        "learning_rate": 9.521706549542116e-05,
        "gradient_norm": 0.4124004542827606,
        "train_loss": 3.0909857749938965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25459,
        "tokens": 13347848192,
        "learning_rate": 9.520292107548391e-05,
        "gradient_norm": 0.44157734513282776,
        "train_loss": 3.049325942993164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25460,
        "tokens": 13348372480,
        "learning_rate": 9.518877929848055e-05,
        "gradient_norm": 0.393688440322876,
        "train_loss": 2.990739345550537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25461,
        "tokens": 13348896768,
        "learning_rate": 9.517464016457007e-05,
        "gradient_norm": 0.45007362961769104,
        "train_loss": 3.0263924598693848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25462,
        "tokens": 13349421056,
        "learning_rate": 9.516050367391184e-05,
        "gradient_norm": 0.4024737477302551,
        "train_loss": 3.013150691986084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25463,
        "tokens": 13349945344,
        "learning_rate": 9.514636982666479e-05,
        "gradient_norm": 0.4025852382183075,
        "train_loss": 3.0272514820098877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25464,
        "tokens": 13350469632,
        "learning_rate": 9.513223862298817e-05,
        "gradient_norm": 0.43031230568885803,
        "train_loss": 3.01865816116333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25465,
        "tokens": 13350993920,
        "learning_rate": 9.511811006304092e-05,
        "gradient_norm": 0.43103325366973877,
        "train_loss": 2.975339889526367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25466,
        "tokens": 13351518208,
        "learning_rate": 9.510398414698218e-05,
        "gradient_norm": 0.37806257605552673,
        "train_loss": 3.0363831520080566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25467,
        "tokens": 13352042496,
        "learning_rate": 9.508986087497085e-05,
        "gradient_norm": 0.4398212730884552,
        "train_loss": 3.0801310539245605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25468,
        "tokens": 13352566784,
        "learning_rate": 9.507574024716602e-05,
        "gradient_norm": 0.3977113962173462,
        "train_loss": 2.985507011413574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25469,
        "tokens": 13353091072,
        "learning_rate": 9.506162226372651e-05,
        "gradient_norm": 0.43405118584632874,
        "train_loss": 3.0445995330810547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25470,
        "tokens": 13353615360,
        "learning_rate": 9.50475069248113e-05,
        "gradient_norm": 0.390033096075058,
        "train_loss": 3.0263495445251465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25471,
        "tokens": 13354139648,
        "learning_rate": 9.503339423057934e-05,
        "gradient_norm": 0.3980507254600525,
        "train_loss": 2.969473123550415,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25472,
        "tokens": 13354663936,
        "learning_rate": 9.501928418118937e-05,
        "gradient_norm": 0.47203198075294495,
        "train_loss": 3.0269861221313477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25473,
        "tokens": 13355188224,
        "learning_rate": 9.500517677680029e-05,
        "gradient_norm": 0.4243105351924896,
        "train_loss": 3.011528253555298,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25474,
        "tokens": 13355712512,
        "learning_rate": 9.499107201757086e-05,
        "gradient_norm": 0.41351041197776794,
        "train_loss": 3.0174450874328613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25475,
        "tokens": 13356236800,
        "learning_rate": 9.497696990365989e-05,
        "gradient_norm": 0.4899889826774597,
        "train_loss": 2.9211955070495605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25476,
        "tokens": 13356761088,
        "learning_rate": 9.496287043522604e-05,
        "gradient_norm": 0.48216569423675537,
        "train_loss": 2.9208180904388428,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25477,
        "tokens": 13357285376,
        "learning_rate": 9.49487736124281e-05,
        "gradient_norm": 0.4031417965888977,
        "train_loss": 3.0349745750427246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25478,
        "tokens": 13357809664,
        "learning_rate": 9.493467943542469e-05,
        "gradient_norm": 0.4607236385345459,
        "train_loss": 3.039085865020752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25479,
        "tokens": 13358333952,
        "learning_rate": 9.492058790437445e-05,
        "gradient_norm": 0.4650980830192566,
        "train_loss": 3.0639188289642334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25480,
        "tokens": 13358858240,
        "learning_rate": 9.490649901943611e-05,
        "gradient_norm": 0.45846641063690186,
        "train_loss": 3.0894558429718018,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25481,
        "tokens": 13359382528,
        "learning_rate": 9.489241278076813e-05,
        "gradient_norm": 0.4045858085155487,
        "train_loss": 3.054142475128174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25482,
        "tokens": 13359906816,
        "learning_rate": 9.487832918852913e-05,
        "gradient_norm": 0.4192005395889282,
        "train_loss": 3.008152961730957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25483,
        "tokens": 13360431104,
        "learning_rate": 9.48642482428776e-05,
        "gradient_norm": 0.40302589535713196,
        "train_loss": 3.0177717208862305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25484,
        "tokens": 13360955392,
        "learning_rate": 9.485016994397209e-05,
        "gradient_norm": 0.46330419182777405,
        "train_loss": 3.0086307525634766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25485,
        "tokens": 13361479680,
        "learning_rate": 9.483609429197098e-05,
        "gradient_norm": 0.41133052110671997,
        "train_loss": 3.0287036895751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25486,
        "tokens": 13362003968,
        "learning_rate": 9.482202128703284e-05,
        "gradient_norm": 0.3811400830745697,
        "train_loss": 3.0296568870544434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25487,
        "tokens": 13362528256,
        "learning_rate": 9.480795092931595e-05,
        "gradient_norm": 0.42022907733917236,
        "train_loss": 2.9524295330047607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25488,
        "tokens": 13363052544,
        "learning_rate": 9.479388321897883e-05,
        "gradient_norm": 0.43833571672439575,
        "train_loss": 2.9785947799682617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25489,
        "tokens": 13363576832,
        "learning_rate": 9.477981815617964e-05,
        "gradient_norm": 0.44945216178894043,
        "train_loss": 2.9762678146362305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25490,
        "tokens": 13364101120,
        "learning_rate": 9.476575574107683e-05,
        "gradient_norm": 0.41983264684677124,
        "train_loss": 3.014185905456543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25491,
        "tokens": 13364625408,
        "learning_rate": 9.475169597382873e-05,
        "gradient_norm": 0.45605096220970154,
        "train_loss": 3.048232316970825,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25492,
        "tokens": 13365149696,
        "learning_rate": 9.473763885459345e-05,
        "gradient_norm": 0.4002976417541504,
        "train_loss": 3.050373077392578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25493,
        "tokens": 13365673984,
        "learning_rate": 9.472358438352938e-05,
        "gradient_norm": 0.4323166012763977,
        "train_loss": 3.0259852409362793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25494,
        "tokens": 13366198272,
        "learning_rate": 9.470953256079461e-05,
        "gradient_norm": 0.43711137771606445,
        "train_loss": 3.0596425533294678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25495,
        "tokens": 13366722560,
        "learning_rate": 9.46954833865474e-05,
        "gradient_norm": 0.4358290731906891,
        "train_loss": 3.0138959884643555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25496,
        "tokens": 13367246848,
        "learning_rate": 9.468143686094577e-05,
        "gradient_norm": 0.45419788360595703,
        "train_loss": 3.028811454772949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25497,
        "tokens": 13367771136,
        "learning_rate": 9.466739298414796e-05,
        "gradient_norm": 0.3886425197124481,
        "train_loss": 3.014345407485962,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25498,
        "tokens": 13368295424,
        "learning_rate": 9.465335175631192e-05,
        "gradient_norm": 0.43598848581314087,
        "train_loss": 3.0414955615997314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25499,
        "tokens": 13368819712,
        "learning_rate": 9.463931317759578e-05,
        "gradient_norm": 0.3901169002056122,
        "train_loss": 3.0312633514404297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25500,
        "tokens": 13369344000,
        "learning_rate": 9.462527724815766e-05,
        "gradient_norm": 0.4280683994293213,
        "train_loss": 2.964820384979248,
        "val_loss": 2.976217746734619,
        "hellaswag_acc": 0.2862975597381592,
        "hellaswag_acc_norm": 0.2981477677822113
    },
    {
        "step": 25501,
        "tokens": 13369868288,
        "learning_rate": 9.461124396815531e-05,
        "gradient_norm": 0.4452967643737793,
        "train_loss": 3.092815399169922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25502,
        "tokens": 13370392576,
        "learning_rate": 9.459721333774694e-05,
        "gradient_norm": 0.41091468930244446,
        "train_loss": 3.025907516479492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25503,
        "tokens": 13370916864,
        "learning_rate": 9.45831853570903e-05,
        "gradient_norm": 0.41188859939575195,
        "train_loss": 3.021914482116699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25504,
        "tokens": 13371441152,
        "learning_rate": 9.456916002634341e-05,
        "gradient_norm": 0.43393465876579285,
        "train_loss": 2.991570472717285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25505,
        "tokens": 13371965440,
        "learning_rate": 9.455513734566405e-05,
        "gradient_norm": 0.391476035118103,
        "train_loss": 2.9841036796569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25506,
        "tokens": 13372489728,
        "learning_rate": 9.454111731521017e-05,
        "gradient_norm": 0.5082178115844727,
        "train_loss": 3.102543830871582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25507,
        "tokens": 13373014016,
        "learning_rate": 9.452709993513945e-05,
        "gradient_norm": 0.4543759822845459,
        "train_loss": 3.161168336868286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25508,
        "tokens": 13373538304,
        "learning_rate": 9.451308520560983e-05,
        "gradient_norm": 0.5293321013450623,
        "train_loss": 3.015596866607666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25509,
        "tokens": 13374062592,
        "learning_rate": 9.44990731267789e-05,
        "gradient_norm": 0.42315688729286194,
        "train_loss": 2.9830374717712402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25510,
        "tokens": 13374586880,
        "learning_rate": 9.448506369880448e-05,
        "gradient_norm": 0.474746435880661,
        "train_loss": 3.005002975463867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25511,
        "tokens": 13375111168,
        "learning_rate": 9.447105692184428e-05,
        "gradient_norm": 0.4252263009548187,
        "train_loss": 3.0244863033294678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25512,
        "tokens": 13375635456,
        "learning_rate": 9.445705279605588e-05,
        "gradient_norm": 0.4328420162200928,
        "train_loss": 2.9981837272644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25513,
        "tokens": 13376159744,
        "learning_rate": 9.444305132159703e-05,
        "gradient_norm": 0.4257906675338745,
        "train_loss": 2.9971258640289307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25514,
        "tokens": 13376684032,
        "learning_rate": 9.442905249862517e-05,
        "gradient_norm": 0.4042268693447113,
        "train_loss": 3.062154531478882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25515,
        "tokens": 13377208320,
        "learning_rate": 9.441505632729806e-05,
        "gradient_norm": 0.42004159092903137,
        "train_loss": 2.992866277694702,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25516,
        "tokens": 13377732608,
        "learning_rate": 9.440106280777312e-05,
        "gradient_norm": 0.44341620802879333,
        "train_loss": 3.047424793243408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25517,
        "tokens": 13378256896,
        "learning_rate": 9.438707194020792e-05,
        "gradient_norm": 0.417877197265625,
        "train_loss": 3.013448476791382,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25518,
        "tokens": 13378781184,
        "learning_rate": 9.437308372475989e-05,
        "gradient_norm": 0.4104832708835602,
        "train_loss": 2.9951369762420654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25519,
        "tokens": 13379305472,
        "learning_rate": 9.43590981615865e-05,
        "gradient_norm": 0.5119514465332031,
        "train_loss": 3.043550491333008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25520,
        "tokens": 13379829760,
        "learning_rate": 9.434511525084526e-05,
        "gradient_norm": 0.42850467562675476,
        "train_loss": 3.0376782417297363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25521,
        "tokens": 13380354048,
        "learning_rate": 9.433113499269344e-05,
        "gradient_norm": 0.43805810809135437,
        "train_loss": 3.0736827850341797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25522,
        "tokens": 13380878336,
        "learning_rate": 9.431715738728852e-05,
        "gradient_norm": 0.4377821087837219,
        "train_loss": 3.020472288131714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25523,
        "tokens": 13381402624,
        "learning_rate": 9.430318243478774e-05,
        "gradient_norm": 0.4316500425338745,
        "train_loss": 3.0465986728668213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25524,
        "tokens": 13381926912,
        "learning_rate": 9.428921013534848e-05,
        "gradient_norm": 0.3798426687717438,
        "train_loss": 2.9954936504364014,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25525,
        "tokens": 13382451200,
        "learning_rate": 9.427524048912793e-05,
        "gradient_norm": 0.40582358837127686,
        "train_loss": 3.0189061164855957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25526,
        "tokens": 13382975488,
        "learning_rate": 9.426127349628345e-05,
        "gradient_norm": 0.4492037296295166,
        "train_loss": 3.0354669094085693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25527,
        "tokens": 13383499776,
        "learning_rate": 9.424730915697214e-05,
        "gradient_norm": 0.40598419308662415,
        "train_loss": 2.9894485473632812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25528,
        "tokens": 13384024064,
        "learning_rate": 9.42333474713513e-05,
        "gradient_norm": 0.4309149980545044,
        "train_loss": 3.061983585357666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25529,
        "tokens": 13384548352,
        "learning_rate": 9.421938843957795e-05,
        "gradient_norm": 0.4254130423069,
        "train_loss": 3.0525412559509277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25530,
        "tokens": 13385072640,
        "learning_rate": 9.420543206180927e-05,
        "gradient_norm": 0.48997125029563904,
        "train_loss": 3.012690544128418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25531,
        "tokens": 13385596928,
        "learning_rate": 9.41914783382025e-05,
        "gradient_norm": 0.4620647132396698,
        "train_loss": 3.0397205352783203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25532,
        "tokens": 13386121216,
        "learning_rate": 9.417752726891449e-05,
        "gradient_norm": 0.4026256501674652,
        "train_loss": 3.027329444885254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25533,
        "tokens": 13386645504,
        "learning_rate": 9.416357885410243e-05,
        "gradient_norm": 0.45903289318084717,
        "train_loss": 3.0403313636779785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25534,
        "tokens": 13387169792,
        "learning_rate": 9.414963309392317e-05,
        "gradient_norm": 0.4838463366031647,
        "train_loss": 3.009425401687622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25535,
        "tokens": 13387694080,
        "learning_rate": 9.413568998853391e-05,
        "gradient_norm": 0.4250286817550659,
        "train_loss": 3.0425984859466553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25536,
        "tokens": 13388218368,
        "learning_rate": 9.412174953809139e-05,
        "gradient_norm": 0.469664603471756,
        "train_loss": 3.0605151653289795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25537,
        "tokens": 13388742656,
        "learning_rate": 9.410781174275264e-05,
        "gradient_norm": 0.41869014501571655,
        "train_loss": 2.991927146911621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25538,
        "tokens": 13389266944,
        "learning_rate": 9.409387660267449e-05,
        "gradient_norm": 0.4616432189941406,
        "train_loss": 2.935591697692871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25539,
        "tokens": 13389791232,
        "learning_rate": 9.407994411801386e-05,
        "gradient_norm": 0.42517879605293274,
        "train_loss": 3.027111530303955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25540,
        "tokens": 13390315520,
        "learning_rate": 9.406601428892752e-05,
        "gradient_norm": 0.4578199088573456,
        "train_loss": 3.063300132751465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25541,
        "tokens": 13390839808,
        "learning_rate": 9.405208711557231e-05,
        "gradient_norm": 0.4115258753299713,
        "train_loss": 3.012220859527588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25542,
        "tokens": 13391364096,
        "learning_rate": 9.403816259810493e-05,
        "gradient_norm": 0.45146626234054565,
        "train_loss": 3.016956329345703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25543,
        "tokens": 13391888384,
        "learning_rate": 9.402424073668222e-05,
        "gradient_norm": 0.4303911030292511,
        "train_loss": 3.024543046951294,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25544,
        "tokens": 13392412672,
        "learning_rate": 9.401032153146079e-05,
        "gradient_norm": 0.4558393657207489,
        "train_loss": 3.010199785232544,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25545,
        "tokens": 13392936960,
        "learning_rate": 9.39964049825974e-05,
        "gradient_norm": 0.406158983707428,
        "train_loss": 3.0462937355041504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25546,
        "tokens": 13393461248,
        "learning_rate": 9.39824910902486e-05,
        "gradient_norm": 0.5074630975723267,
        "train_loss": 3.0296759605407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25547,
        "tokens": 13393985536,
        "learning_rate": 9.396857985457113e-05,
        "gradient_norm": 0.38637080788612366,
        "train_loss": 3.043287515640259,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25548,
        "tokens": 13394509824,
        "learning_rate": 9.395467127572147e-05,
        "gradient_norm": 0.46014952659606934,
        "train_loss": 3.036430597305298,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25549,
        "tokens": 13395034112,
        "learning_rate": 9.394076535385626e-05,
        "gradient_norm": 0.46023792028427124,
        "train_loss": 3.0614142417907715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25550,
        "tokens": 13395558400,
        "learning_rate": 9.392686208913194e-05,
        "gradient_norm": 0.42077913880348206,
        "train_loss": 3.0073466300964355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25551,
        "tokens": 13396082688,
        "learning_rate": 9.39129614817051e-05,
        "gradient_norm": 0.4371350407600403,
        "train_loss": 3.083301544189453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25552,
        "tokens": 13396606976,
        "learning_rate": 9.389906353173215e-05,
        "gradient_norm": 0.39840802550315857,
        "train_loss": 3.0120739936828613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25553,
        "tokens": 13397131264,
        "learning_rate": 9.38851682393695e-05,
        "gradient_norm": 0.4061969518661499,
        "train_loss": 3.025926113128662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25554,
        "tokens": 13397655552,
        "learning_rate": 9.387127560477371e-05,
        "gradient_norm": 0.40255239605903625,
        "train_loss": 2.9697961807250977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25555,
        "tokens": 13398179840,
        "learning_rate": 9.385738562810096e-05,
        "gradient_norm": 0.44346103072166443,
        "train_loss": 3.088564872741699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25556,
        "tokens": 13398704128,
        "learning_rate": 9.384349830950778e-05,
        "gradient_norm": 0.37314486503601074,
        "train_loss": 2.9983761310577393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25557,
        "tokens": 13399228416,
        "learning_rate": 9.382961364915032e-05,
        "gradient_norm": 0.4022488594055176,
        "train_loss": 3.05680251121521,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25558,
        "tokens": 13399752704,
        "learning_rate": 9.381573164718505e-05,
        "gradient_norm": 0.4223455488681793,
        "train_loss": 3.044154644012451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25559,
        "tokens": 13400276992,
        "learning_rate": 9.380185230376805e-05,
        "gradient_norm": 0.403355211019516,
        "train_loss": 3.022399425506592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25560,
        "tokens": 13400801280,
        "learning_rate": 9.378797561905569e-05,
        "gradient_norm": 0.45321938395500183,
        "train_loss": 3.0622506141662598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25561,
        "tokens": 13401325568,
        "learning_rate": 9.377410159320402e-05,
        "gradient_norm": 0.43270379304885864,
        "train_loss": 3.0215067863464355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25562,
        "tokens": 13401849856,
        "learning_rate": 9.37602302263694e-05,
        "gradient_norm": 0.4562729299068451,
        "train_loss": 2.9707536697387695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25563,
        "tokens": 13402374144,
        "learning_rate": 9.374636151870781e-05,
        "gradient_norm": 0.4631553888320923,
        "train_loss": 2.9932873249053955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25564,
        "tokens": 13402898432,
        "learning_rate": 9.373249547037547e-05,
        "gradient_norm": 0.39512133598327637,
        "train_loss": 3.020277976989746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25565,
        "tokens": 13403422720,
        "learning_rate": 9.371863208152834e-05,
        "gradient_norm": 0.4974302053451538,
        "train_loss": 2.999209403991699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25566,
        "tokens": 13403947008,
        "learning_rate": 9.370477135232263e-05,
        "gradient_norm": 0.3827509880065918,
        "train_loss": 3.051407814025879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25567,
        "tokens": 13404471296,
        "learning_rate": 9.369091328291416e-05,
        "gradient_norm": 0.48136067390441895,
        "train_loss": 2.9755992889404297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25568,
        "tokens": 13404995584,
        "learning_rate": 9.367705787345912e-05,
        "gradient_norm": 0.45893394947052,
        "train_loss": 3.0713465213775635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25569,
        "tokens": 13405519872,
        "learning_rate": 9.36632051241133e-05,
        "gradient_norm": 0.3751450181007385,
        "train_loss": 2.9785947799682617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25570,
        "tokens": 13406044160,
        "learning_rate": 9.364935503503272e-05,
        "gradient_norm": 0.4256117343902588,
        "train_loss": 2.9827375411987305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25571,
        "tokens": 13406568448,
        "learning_rate": 9.363550760637334e-05,
        "gradient_norm": 0.433176726102829,
        "train_loss": 3.0004913806915283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25572,
        "tokens": 13407092736,
        "learning_rate": 9.362166283829085e-05,
        "gradient_norm": 0.4454103112220764,
        "train_loss": 3.028252124786377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25573,
        "tokens": 13407617024,
        "learning_rate": 9.36078207309413e-05,
        "gradient_norm": 0.40573009848594666,
        "train_loss": 3.0718908309936523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25574,
        "tokens": 13408141312,
        "learning_rate": 9.359398128448033e-05,
        "gradient_norm": 0.38559022545814514,
        "train_loss": 3.076201915740967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25575,
        "tokens": 13408665600,
        "learning_rate": 9.358014449906386e-05,
        "gradient_norm": 0.4976494014263153,
        "train_loss": 2.958592653274536,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25576,
        "tokens": 13409189888,
        "learning_rate": 9.356631037484749e-05,
        "gradient_norm": 0.4079597294330597,
        "train_loss": 2.9520843029022217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25577,
        "tokens": 13409714176,
        "learning_rate": 9.355247891198708e-05,
        "gradient_norm": 0.4384623169898987,
        "train_loss": 3.054412364959717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25578,
        "tokens": 13410238464,
        "learning_rate": 9.353865011063821e-05,
        "gradient_norm": 0.4240519404411316,
        "train_loss": 3.029104232788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25579,
        "tokens": 13410762752,
        "learning_rate": 9.352482397095659e-05,
        "gradient_norm": 0.4203105866909027,
        "train_loss": 3.0301764011383057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25580,
        "tokens": 13411287040,
        "learning_rate": 9.351100049309789e-05,
        "gradient_norm": 0.42687150835990906,
        "train_loss": 3.080237627029419,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25581,
        "tokens": 13411811328,
        "learning_rate": 9.349717967721763e-05,
        "gradient_norm": 0.4186684191226959,
        "train_loss": 3.0479724407196045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25582,
        "tokens": 13412335616,
        "learning_rate": 9.34833615234715e-05,
        "gradient_norm": 0.4097520709037781,
        "train_loss": 2.9486985206604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25583,
        "tokens": 13412859904,
        "learning_rate": 9.346954603201487e-05,
        "gradient_norm": 0.4295652508735657,
        "train_loss": 3.0067925453186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25584,
        "tokens": 13413384192,
        "learning_rate": 9.345573320300342e-05,
        "gradient_norm": 0.41879716515541077,
        "train_loss": 3.048004388809204,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25585,
        "tokens": 13413908480,
        "learning_rate": 9.344192303659247e-05,
        "gradient_norm": 0.38271600008010864,
        "train_loss": 3.0269696712493896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25586,
        "tokens": 13414432768,
        "learning_rate": 9.342811553293763e-05,
        "gradient_norm": 0.43003055453300476,
        "train_loss": 3.021737575531006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25587,
        "tokens": 13414957056,
        "learning_rate": 9.341431069219418e-05,
        "gradient_norm": 0.4074442386627197,
        "train_loss": 3.0070419311523438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25588,
        "tokens": 13415481344,
        "learning_rate": 9.340050851451765e-05,
        "gradient_norm": 0.41280707716941833,
        "train_loss": 2.9874391555786133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25589,
        "tokens": 13416005632,
        "learning_rate": 9.338670900006325e-05,
        "gradient_norm": 0.3983844220638275,
        "train_loss": 2.9883668422698975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25590,
        "tokens": 13416529920,
        "learning_rate": 9.337291214898637e-05,
        "gradient_norm": 0.4058811366558075,
        "train_loss": 3.030144691467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25591,
        "tokens": 13417054208,
        "learning_rate": 9.335911796144241e-05,
        "gradient_norm": 0.43376243114471436,
        "train_loss": 3.056506395339966,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25592,
        "tokens": 13417578496,
        "learning_rate": 9.334532643758651e-05,
        "gradient_norm": 0.5403767824172974,
        "train_loss": 3.059868812561035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25593,
        "tokens": 13418102784,
        "learning_rate": 9.3331537577574e-05,
        "gradient_norm": 0.4495534598827362,
        "train_loss": 3.0021846294403076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25594,
        "tokens": 13418627072,
        "learning_rate": 9.331775138155999e-05,
        "gradient_norm": 0.44414064288139343,
        "train_loss": 2.982515573501587,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25595,
        "tokens": 13419151360,
        "learning_rate": 9.330396784969977e-05,
        "gradient_norm": 0.4160473644733429,
        "train_loss": 3.0226566791534424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25596,
        "tokens": 13419675648,
        "learning_rate": 9.329018698214842e-05,
        "gradient_norm": 0.4785630702972412,
        "train_loss": 3.011484146118164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25597,
        "tokens": 13420199936,
        "learning_rate": 9.32764087790611e-05,
        "gradient_norm": 0.4352201223373413,
        "train_loss": 3.090510606765747,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25598,
        "tokens": 13420724224,
        "learning_rate": 9.326263324059283e-05,
        "gradient_norm": 0.4305066764354706,
        "train_loss": 3.021613836288452,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25599,
        "tokens": 13421248512,
        "learning_rate": 9.324886036689872e-05,
        "gradient_norm": 0.4804674983024597,
        "train_loss": 3.039811611175537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25600,
        "tokens": 13421772800,
        "learning_rate": 9.32350901581339e-05,
        "gradient_norm": 0.41633206605911255,
        "train_loss": 2.996089458465576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25601,
        "tokens": 13422297088,
        "learning_rate": 9.322132261445319e-05,
        "gradient_norm": 0.461903840303421,
        "train_loss": 3.0356857776641846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25602,
        "tokens": 13422821376,
        "learning_rate": 9.32075577360117e-05,
        "gradient_norm": 0.41221943497657776,
        "train_loss": 3.01792049407959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25603,
        "tokens": 13423345664,
        "learning_rate": 9.319379552296429e-05,
        "gradient_norm": 0.42024797201156616,
        "train_loss": 2.9426920413970947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25604,
        "tokens": 13423869952,
        "learning_rate": 9.318003597546593e-05,
        "gradient_norm": 0.4560532867908478,
        "train_loss": 3.0390257835388184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25605,
        "tokens": 13424394240,
        "learning_rate": 9.316627909367141e-05,
        "gradient_norm": 0.45016124844551086,
        "train_loss": 3.008737564086914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25606,
        "tokens": 13424918528,
        "learning_rate": 9.31525248777357e-05,
        "gradient_norm": 0.48296165466308594,
        "train_loss": 3.051701068878174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25607,
        "tokens": 13425442816,
        "learning_rate": 9.31387733278135e-05,
        "gradient_norm": 0.4156089425086975,
        "train_loss": 2.949838638305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25608,
        "tokens": 13425967104,
        "learning_rate": 9.312502444405973e-05,
        "gradient_norm": 0.4689897894859314,
        "train_loss": 3.0663585662841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25609,
        "tokens": 13426491392,
        "learning_rate": 9.311127822662902e-05,
        "gradient_norm": 0.46542325615882874,
        "train_loss": 3.0534400939941406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25610,
        "tokens": 13427015680,
        "learning_rate": 9.309753467567616e-05,
        "gradient_norm": 0.4318961203098297,
        "train_loss": 2.995476245880127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25611,
        "tokens": 13427539968,
        "learning_rate": 9.30837937913559e-05,
        "gradient_norm": 0.40891504287719727,
        "train_loss": 3.0190985202789307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25612,
        "tokens": 13428064256,
        "learning_rate": 9.307005557382282e-05,
        "gradient_norm": 0.4972734749317169,
        "train_loss": 3.0549263954162598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25613,
        "tokens": 13428588544,
        "learning_rate": 9.305632002323165e-05,
        "gradient_norm": 0.45569005608558655,
        "train_loss": 3.0244362354278564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25614,
        "tokens": 13429112832,
        "learning_rate": 9.304258713973694e-05,
        "gradient_norm": 0.4266139268875122,
        "train_loss": 2.983132839202881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25615,
        "tokens": 13429637120,
        "learning_rate": 9.302885692349331e-05,
        "gradient_norm": 0.5881922245025635,
        "train_loss": 3.0801570415496826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25616,
        "tokens": 13430161408,
        "learning_rate": 9.301512937465525e-05,
        "gradient_norm": 0.4564536213874817,
        "train_loss": 3.0687246322631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25617,
        "tokens": 13430685696,
        "learning_rate": 9.300140449337735e-05,
        "gradient_norm": 0.4524252116680145,
        "train_loss": 3.0117173194885254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25618,
        "tokens": 13431209984,
        "learning_rate": 9.298768227981402e-05,
        "gradient_norm": 0.6283663511276245,
        "train_loss": 3.0758681297302246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25619,
        "tokens": 13431734272,
        "learning_rate": 9.297396273411977e-05,
        "gradient_norm": 0.42965301871299744,
        "train_loss": 3.0486068725585938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25620,
        "tokens": 13432258560,
        "learning_rate": 9.296024585644908e-05,
        "gradient_norm": 0.4408576786518097,
        "train_loss": 2.9869537353515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25621,
        "tokens": 13432782848,
        "learning_rate": 9.294653164695628e-05,
        "gradient_norm": 0.47369372844696045,
        "train_loss": 3.0489602088928223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25622,
        "tokens": 13433307136,
        "learning_rate": 9.29328201057958e-05,
        "gradient_norm": 0.48528528213500977,
        "train_loss": 3.0389280319213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25623,
        "tokens": 13433831424,
        "learning_rate": 9.291911123312184e-05,
        "gradient_norm": 0.5090382099151611,
        "train_loss": 3.0317564010620117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25624,
        "tokens": 13434355712,
        "learning_rate": 9.290540502908894e-05,
        "gradient_norm": 0.4677876830101013,
        "train_loss": 3.0265846252441406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25625,
        "tokens": 13434880000,
        "learning_rate": 9.289170149385114e-05,
        "gradient_norm": 0.5051057934761047,
        "train_loss": 3.0673508644104004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25626,
        "tokens": 13435404288,
        "learning_rate": 9.287800062756288e-05,
        "gradient_norm": 0.4546203315258026,
        "train_loss": 2.9837331771850586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25627,
        "tokens": 13435928576,
        "learning_rate": 9.286430243037825e-05,
        "gradient_norm": 0.4967162013053894,
        "train_loss": 2.938126802444458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25628,
        "tokens": 13436452864,
        "learning_rate": 9.285060690245156e-05,
        "gradient_norm": 0.4682343900203705,
        "train_loss": 3.005436420440674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25629,
        "tokens": 13436977152,
        "learning_rate": 9.283691404393684e-05,
        "gradient_norm": 0.43179094791412354,
        "train_loss": 3.036919593811035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25630,
        "tokens": 13437501440,
        "learning_rate": 9.282322385498827e-05,
        "gradient_norm": 0.4374425411224365,
        "train_loss": 2.975654125213623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25631,
        "tokens": 13438025728,
        "learning_rate": 9.280953633576002e-05,
        "gradient_norm": 0.4736679792404175,
        "train_loss": 2.94455623626709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25632,
        "tokens": 13438550016,
        "learning_rate": 9.279585148640606e-05,
        "gradient_norm": 0.4053971767425537,
        "train_loss": 2.987851858139038,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25633,
        "tokens": 13439074304,
        "learning_rate": 9.278216930708053e-05,
        "gradient_norm": 0.4250567555427551,
        "train_loss": 3.000530958175659,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25634,
        "tokens": 13439598592,
        "learning_rate": 9.276848979793732e-05,
        "gradient_norm": 0.4035409092903137,
        "train_loss": 3.013108253479004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25635,
        "tokens": 13440122880,
        "learning_rate": 9.275481295913054e-05,
        "gradient_norm": 0.45018503069877625,
        "train_loss": 3.025114059448242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25636,
        "tokens": 13440647168,
        "learning_rate": 9.274113879081403e-05,
        "gradient_norm": 0.4682033956050873,
        "train_loss": 3.1074705123901367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25637,
        "tokens": 13441171456,
        "learning_rate": 9.272746729314178e-05,
        "gradient_norm": 0.5561700463294983,
        "train_loss": 3.062154769897461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25638,
        "tokens": 13441695744,
        "learning_rate": 9.271379846626762e-05,
        "gradient_norm": 0.45885223150253296,
        "train_loss": 3.070542812347412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25639,
        "tokens": 13442220032,
        "learning_rate": 9.270013231034542e-05,
        "gradient_norm": 0.46331587433815,
        "train_loss": 2.9876036643981934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25640,
        "tokens": 13442744320,
        "learning_rate": 9.268646882552911e-05,
        "gradient_norm": 0.4730900526046753,
        "train_loss": 3.0388903617858887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25641,
        "tokens": 13443268608,
        "learning_rate": 9.267280801197238e-05,
        "gradient_norm": 0.4369983673095703,
        "train_loss": 3.017164945602417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25642,
        "tokens": 13443792896,
        "learning_rate": 9.265914986982904e-05,
        "gradient_norm": 0.45777347683906555,
        "train_loss": 3.0307705402374268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25643,
        "tokens": 13444317184,
        "learning_rate": 9.264549439925278e-05,
        "gradient_norm": 0.4062749743461609,
        "train_loss": 2.998103141784668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25644,
        "tokens": 13444841472,
        "learning_rate": 9.263184160039742e-05,
        "gradient_norm": 0.3811080753803253,
        "train_loss": 3.003382444381714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25645,
        "tokens": 13445365760,
        "learning_rate": 9.261819147341651e-05,
        "gradient_norm": 0.45526060461997986,
        "train_loss": 3.0590171813964844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25646,
        "tokens": 13445890048,
        "learning_rate": 9.26045440184638e-05,
        "gradient_norm": 0.424998015165329,
        "train_loss": 3.0812249183654785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25647,
        "tokens": 13446414336,
        "learning_rate": 9.25908992356928e-05,
        "gradient_norm": 0.4487331509590149,
        "train_loss": 2.997570276260376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25648,
        "tokens": 13446938624,
        "learning_rate": 9.257725712525725e-05,
        "gradient_norm": 0.43136534094810486,
        "train_loss": 2.9752790927886963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25649,
        "tokens": 13447462912,
        "learning_rate": 9.256361768731059e-05,
        "gradient_norm": 0.40492114424705505,
        "train_loss": 3.0579187870025635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25650,
        "tokens": 13447987200,
        "learning_rate": 9.254998092200641e-05,
        "gradient_norm": 0.4198688864707947,
        "train_loss": 2.945204257965088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25651,
        "tokens": 13448511488,
        "learning_rate": 9.253634682949813e-05,
        "gradient_norm": 0.44876059889793396,
        "train_loss": 3.006289482116699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25652,
        "tokens": 13449035776,
        "learning_rate": 9.252271540993932e-05,
        "gradient_norm": 0.4247756004333496,
        "train_loss": 3.051206111907959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25653,
        "tokens": 13449560064,
        "learning_rate": 9.250908666348336e-05,
        "gradient_norm": 0.40956804156303406,
        "train_loss": 2.9952869415283203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25654,
        "tokens": 13450084352,
        "learning_rate": 9.249546059028369e-05,
        "gradient_norm": 0.44556641578674316,
        "train_loss": 2.947612762451172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25655,
        "tokens": 13450608640,
        "learning_rate": 9.248183719049362e-05,
        "gradient_norm": 0.4314119517803192,
        "train_loss": 3.070345878601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25656,
        "tokens": 13451132928,
        "learning_rate": 9.246821646426658e-05,
        "gradient_norm": 0.40297427773475647,
        "train_loss": 3.009775161743164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25657,
        "tokens": 13451657216,
        "learning_rate": 9.245459841175581e-05,
        "gradient_norm": 0.4190976619720459,
        "train_loss": 2.968453884124756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25658,
        "tokens": 13452181504,
        "learning_rate": 9.244098303311471e-05,
        "gradient_norm": 0.39826372265815735,
        "train_loss": 3.059666156768799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25659,
        "tokens": 13452705792,
        "learning_rate": 9.242737032849643e-05,
        "gradient_norm": 0.4325776994228363,
        "train_loss": 2.971379280090332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25660,
        "tokens": 13453230080,
        "learning_rate": 9.241376029805426e-05,
        "gradient_norm": 0.4467635154724121,
        "train_loss": 2.988798141479492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25661,
        "tokens": 13453754368,
        "learning_rate": 9.240015294194136e-05,
        "gradient_norm": 0.4263540506362915,
        "train_loss": 2.9671106338500977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25662,
        "tokens": 13454278656,
        "learning_rate": 9.238654826031094e-05,
        "gradient_norm": 0.4317203164100647,
        "train_loss": 3.022399425506592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25663,
        "tokens": 13454802944,
        "learning_rate": 9.237294625331605e-05,
        "gradient_norm": 0.4674902856349945,
        "train_loss": 3.0078611373901367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25664,
        "tokens": 13455327232,
        "learning_rate": 9.235934692110992e-05,
        "gradient_norm": 0.4419771432876587,
        "train_loss": 3.0109214782714844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25665,
        "tokens": 13455851520,
        "learning_rate": 9.234575026384554e-05,
        "gradient_norm": 0.41901475191116333,
        "train_loss": 3.025538206100464,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25666,
        "tokens": 13456375808,
        "learning_rate": 9.233215628167602e-05,
        "gradient_norm": 0.4500681161880493,
        "train_loss": 2.9982128143310547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25667,
        "tokens": 13456900096,
        "learning_rate": 9.23185649747543e-05,
        "gradient_norm": 0.4205080568790436,
        "train_loss": 2.999497890472412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25668,
        "tokens": 13457424384,
        "learning_rate": 9.230497634323344e-05,
        "gradient_norm": 0.4260980784893036,
        "train_loss": 3.019120216369629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25669,
        "tokens": 13457948672,
        "learning_rate": 9.229139038726631e-05,
        "gradient_norm": 0.4254148602485657,
        "train_loss": 3.073152542114258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25670,
        "tokens": 13458472960,
        "learning_rate": 9.227780710700591e-05,
        "gradient_norm": 0.4198475480079651,
        "train_loss": 3.0558745861053467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25671,
        "tokens": 13458997248,
        "learning_rate": 9.226422650260519e-05,
        "gradient_norm": 0.3980812728404999,
        "train_loss": 3.019639015197754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25672,
        "tokens": 13459521536,
        "learning_rate": 9.225064857421687e-05,
        "gradient_norm": 0.4368080794811249,
        "train_loss": 3.0332369804382324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25673,
        "tokens": 13460045824,
        "learning_rate": 9.223707332199393e-05,
        "gradient_norm": 0.38710907101631165,
        "train_loss": 3.042428493499756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25674,
        "tokens": 13460570112,
        "learning_rate": 9.222350074608903e-05,
        "gradient_norm": 0.3904429078102112,
        "train_loss": 3.0228514671325684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25675,
        "tokens": 13461094400,
        "learning_rate": 9.22099308466551e-05,
        "gradient_norm": 0.4012618362903595,
        "train_loss": 3.044477939605713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25676,
        "tokens": 13461618688,
        "learning_rate": 9.219636362384475e-05,
        "gradient_norm": 0.37837499380111694,
        "train_loss": 3.033076286315918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25677,
        "tokens": 13462142976,
        "learning_rate": 9.218279907781082e-05,
        "gradient_norm": 0.40537548065185547,
        "train_loss": 3.009068012237549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25678,
        "tokens": 13462667264,
        "learning_rate": 9.216923720870588e-05,
        "gradient_norm": 0.38546568155288696,
        "train_loss": 3.0299878120422363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25679,
        "tokens": 13463191552,
        "learning_rate": 9.215567801668261e-05,
        "gradient_norm": 0.43745195865631104,
        "train_loss": 3.0359044075012207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25680,
        "tokens": 13463715840,
        "learning_rate": 9.214212150189375e-05,
        "gradient_norm": 0.3976803421974182,
        "train_loss": 3.0387024879455566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25681,
        "tokens": 13464240128,
        "learning_rate": 9.212856766449173e-05,
        "gradient_norm": 0.45526987314224243,
        "train_loss": 3.1179513931274414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25682,
        "tokens": 13464764416,
        "learning_rate": 9.211501650462928e-05,
        "gradient_norm": 0.47709739208221436,
        "train_loss": 2.9974684715270996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25683,
        "tokens": 13465288704,
        "learning_rate": 9.210146802245877e-05,
        "gradient_norm": 0.40021437406539917,
        "train_loss": 3.0341763496398926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25684,
        "tokens": 13465812992,
        "learning_rate": 9.208792221813285e-05,
        "gradient_norm": 0.4661608636379242,
        "train_loss": 3.011570930480957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25685,
        "tokens": 13466337280,
        "learning_rate": 9.207437909180389e-05,
        "gradient_norm": 0.37170302867889404,
        "train_loss": 3.0383119583129883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25686,
        "tokens": 13466861568,
        "learning_rate": 9.20608386436244e-05,
        "gradient_norm": 0.5028712749481201,
        "train_loss": 3.0037147998809814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25687,
        "tokens": 13467385856,
        "learning_rate": 9.204730087374673e-05,
        "gradient_norm": 0.40105995535850525,
        "train_loss": 3.0756492614746094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25688,
        "tokens": 13467910144,
        "learning_rate": 9.203376578232338e-05,
        "gradient_norm": 0.3994086980819702,
        "train_loss": 2.9807519912719727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25689,
        "tokens": 13468434432,
        "learning_rate": 9.202023336950656e-05,
        "gradient_norm": 0.42668017745018005,
        "train_loss": 2.9931750297546387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25690,
        "tokens": 13468958720,
        "learning_rate": 9.200670363544864e-05,
        "gradient_norm": 0.424032986164093,
        "train_loss": 3.025599241256714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25691,
        "tokens": 13469483008,
        "learning_rate": 9.199317658030201e-05,
        "gradient_norm": 0.4761771857738495,
        "train_loss": 3.0068774223327637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25692,
        "tokens": 13470007296,
        "learning_rate": 9.197965220421882e-05,
        "gradient_norm": 0.39005064964294434,
        "train_loss": 3.0129318237304688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25693,
        "tokens": 13470531584,
        "learning_rate": 9.196613050735138e-05,
        "gradient_norm": 0.4384605288505554,
        "train_loss": 2.9787983894348145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25694,
        "tokens": 13471055872,
        "learning_rate": 9.195261148985181e-05,
        "gradient_norm": 0.4057341516017914,
        "train_loss": 3.0731663703918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25695,
        "tokens": 13471580160,
        "learning_rate": 9.193909515187239e-05,
        "gradient_norm": 0.4398065507411957,
        "train_loss": 3.0170021057128906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25696,
        "tokens": 13472104448,
        "learning_rate": 9.192558149356513e-05,
        "gradient_norm": 0.4500887989997864,
        "train_loss": 3.02877140045166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25697,
        "tokens": 13472628736,
        "learning_rate": 9.191207051508231e-05,
        "gradient_norm": 0.42935875058174133,
        "train_loss": 3.053515911102295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25698,
        "tokens": 13473153024,
        "learning_rate": 9.189856221657583e-05,
        "gradient_norm": 0.43238362669944763,
        "train_loss": 3.0019116401672363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25699,
        "tokens": 13473677312,
        "learning_rate": 9.188505659819785e-05,
        "gradient_norm": 0.40006953477859497,
        "train_loss": 3.0453128814697266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25700,
        "tokens": 13474201600,
        "learning_rate": 9.187155366010042e-05,
        "gradient_norm": 0.4248473048210144,
        "train_loss": 3.0009403228759766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25701,
        "tokens": 13474725888,
        "learning_rate": 9.185805340243544e-05,
        "gradient_norm": 0.43962785601615906,
        "train_loss": 3.0381393432617188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25702,
        "tokens": 13475250176,
        "learning_rate": 9.184455582535498e-05,
        "gradient_norm": 0.38649871945381165,
        "train_loss": 3.0112366676330566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25703,
        "tokens": 13475774464,
        "learning_rate": 9.183106092901087e-05,
        "gradient_norm": 0.40018898248672485,
        "train_loss": 3.0342273712158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25704,
        "tokens": 13476298752,
        "learning_rate": 9.18175687135551e-05,
        "gradient_norm": 0.38962122797966003,
        "train_loss": 2.9906797409057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25705,
        "tokens": 13476823040,
        "learning_rate": 9.180407917913942e-05,
        "gradient_norm": 0.45813247561454773,
        "train_loss": 3.0622305870056152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25706,
        "tokens": 13477347328,
        "learning_rate": 9.179059232591584e-05,
        "gradient_norm": 0.40215957164764404,
        "train_loss": 3.048654079437256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25707,
        "tokens": 13477871616,
        "learning_rate": 9.177710815403599e-05,
        "gradient_norm": 0.42937812209129333,
        "train_loss": 3.036886692047119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25708,
        "tokens": 13478395904,
        "learning_rate": 9.176362666365179e-05,
        "gradient_norm": 0.41046491265296936,
        "train_loss": 3.04443359375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25709,
        "tokens": 13478920192,
        "learning_rate": 9.175014785491492e-05,
        "gradient_norm": 0.45034411549568176,
        "train_loss": 3.0493857860565186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25710,
        "tokens": 13479444480,
        "learning_rate": 9.173667172797712e-05,
        "gradient_norm": 0.4323207139968872,
        "train_loss": 2.976853132247925,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25711,
        "tokens": 13479968768,
        "learning_rate": 9.172319828299011e-05,
        "gradient_norm": 0.41194379329681396,
        "train_loss": 3.0287489891052246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25712,
        "tokens": 13480493056,
        "learning_rate": 9.170972752010548e-05,
        "gradient_norm": 0.4154747724533081,
        "train_loss": 2.9283323287963867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25713,
        "tokens": 13481017344,
        "learning_rate": 9.169625943947497e-05,
        "gradient_norm": 0.4530858099460602,
        "train_loss": 3.023350715637207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25714,
        "tokens": 13481541632,
        "learning_rate": 9.168279404125004e-05,
        "gradient_norm": 0.4138953387737274,
        "train_loss": 2.9928579330444336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25715,
        "tokens": 13482065920,
        "learning_rate": 9.166933132558241e-05,
        "gradient_norm": 0.38324519991874695,
        "train_loss": 3.0402817726135254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25716,
        "tokens": 13482590208,
        "learning_rate": 9.165587129262346e-05,
        "gradient_norm": 0.4535887539386749,
        "train_loss": 3.0609750747680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25717,
        "tokens": 13483114496,
        "learning_rate": 9.164241394252486e-05,
        "gradient_norm": 0.43554258346557617,
        "train_loss": 3.001570701599121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25718,
        "tokens": 13483638784,
        "learning_rate": 9.162895927543797e-05,
        "gradient_norm": 0.42437663674354553,
        "train_loss": 3.0021345615386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25719,
        "tokens": 13484163072,
        "learning_rate": 9.161550729151424e-05,
        "gradient_norm": 0.42031049728393555,
        "train_loss": 3.038267135620117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25720,
        "tokens": 13484687360,
        "learning_rate": 9.160205799090522e-05,
        "gradient_norm": 0.4100446403026581,
        "train_loss": 3.010092258453369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25721,
        "tokens": 13485211648,
        "learning_rate": 9.158861137376213e-05,
        "gradient_norm": 0.41927775740623474,
        "train_loss": 3.000502109527588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25722,
        "tokens": 13485735936,
        "learning_rate": 9.157516744023647e-05,
        "gradient_norm": 0.352295458316803,
        "train_loss": 3.0180115699768066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25723,
        "tokens": 13486260224,
        "learning_rate": 9.156172619047945e-05,
        "gradient_norm": 0.37718039751052856,
        "train_loss": 3.0219130516052246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25724,
        "tokens": 13486784512,
        "learning_rate": 9.154828762464249e-05,
        "gradient_norm": 0.4193655848503113,
        "train_loss": 2.995173454284668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25725,
        "tokens": 13487308800,
        "learning_rate": 9.153485174287672e-05,
        "gradient_norm": 0.41972556710243225,
        "train_loss": 3.0435571670532227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25726,
        "tokens": 13487833088,
        "learning_rate": 9.15214185453335e-05,
        "gradient_norm": 0.3983555734157562,
        "train_loss": 3.033024311065674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25727,
        "tokens": 13488357376,
        "learning_rate": 9.150798803216393e-05,
        "gradient_norm": 0.43221625685691833,
        "train_loss": 2.988900661468506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25728,
        "tokens": 13488881664,
        "learning_rate": 9.14945602035193e-05,
        "gradient_norm": 0.38048267364501953,
        "train_loss": 3.0163214206695557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25729,
        "tokens": 13489405952,
        "learning_rate": 9.148113505955067e-05,
        "gradient_norm": 0.44758424162864685,
        "train_loss": 3.0214977264404297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25730,
        "tokens": 13489930240,
        "learning_rate": 9.146771260040915e-05,
        "gradient_norm": 0.4135258197784424,
        "train_loss": 2.944885730743408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25731,
        "tokens": 13490454528,
        "learning_rate": 9.145429282624595e-05,
        "gradient_norm": 0.4389341175556183,
        "train_loss": 3.0231223106384277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25732,
        "tokens": 13490978816,
        "learning_rate": 9.144087573721196e-05,
        "gradient_norm": 0.45203250646591187,
        "train_loss": 3.034572124481201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25733,
        "tokens": 13491503104,
        "learning_rate": 9.142746133345835e-05,
        "gradient_norm": 0.4180145263671875,
        "train_loss": 3.0014467239379883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25734,
        "tokens": 13492027392,
        "learning_rate": 9.1414049615136e-05,
        "gradient_norm": 0.43596869707107544,
        "train_loss": 3.0366485118865967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25735,
        "tokens": 13492551680,
        "learning_rate": 9.140064058239596e-05,
        "gradient_norm": 0.3825925588607788,
        "train_loss": 3.0215134620666504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25736,
        "tokens": 13493075968,
        "learning_rate": 9.138723423538911e-05,
        "gradient_norm": 0.419088214635849,
        "train_loss": 2.992063522338867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25737,
        "tokens": 13493600256,
        "learning_rate": 9.137383057426641e-05,
        "gradient_norm": 0.413970410823822,
        "train_loss": 3.014336585998535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25738,
        "tokens": 13494124544,
        "learning_rate": 9.136042959917865e-05,
        "gradient_norm": 0.388426810503006,
        "train_loss": 3.038036346435547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25739,
        "tokens": 13494648832,
        "learning_rate": 9.134703131027674e-05,
        "gradient_norm": 0.4410724341869354,
        "train_loss": 3.0877132415771484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25740,
        "tokens": 13495173120,
        "learning_rate": 9.133363570771152e-05,
        "gradient_norm": 0.511172890663147,
        "train_loss": 3.045248508453369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25741,
        "tokens": 13495697408,
        "learning_rate": 9.132024279163368e-05,
        "gradient_norm": 0.45517498254776,
        "train_loss": 2.9870171546936035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25742,
        "tokens": 13496221696,
        "learning_rate": 9.130685256219408e-05,
        "gradient_norm": 0.4515349268913269,
        "train_loss": 3.017944812774658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25743,
        "tokens": 13496745984,
        "learning_rate": 9.129346501954337e-05,
        "gradient_norm": 0.4347591996192932,
        "train_loss": 3.037679672241211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25744,
        "tokens": 13497270272,
        "learning_rate": 9.128008016383231e-05,
        "gradient_norm": 0.44449469447135925,
        "train_loss": 3.021350145339966,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25745,
        "tokens": 13497794560,
        "learning_rate": 9.126669799521146e-05,
        "gradient_norm": 0.43554508686065674,
        "train_loss": 2.984013319015503,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25746,
        "tokens": 13498318848,
        "learning_rate": 9.125331851383156e-05,
        "gradient_norm": 0.41488903760910034,
        "train_loss": 3.026805877685547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25747,
        "tokens": 13498843136,
        "learning_rate": 9.123994171984311e-05,
        "gradient_norm": 0.5112196207046509,
        "train_loss": 3.027066707611084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25748,
        "tokens": 13499367424,
        "learning_rate": 9.122656761339679e-05,
        "gradient_norm": 0.4332015812397003,
        "train_loss": 2.987938404083252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25749,
        "tokens": 13499891712,
        "learning_rate": 9.121319619464303e-05,
        "gradient_norm": 0.41542354226112366,
        "train_loss": 3.0448429584503174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25750,
        "tokens": 13500416000,
        "learning_rate": 9.11998274637325e-05,
        "gradient_norm": 0.42508020997047424,
        "train_loss": 3.061443328857422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25751,
        "tokens": 13500940288,
        "learning_rate": 9.11864614208155e-05,
        "gradient_norm": 0.41183191537857056,
        "train_loss": 3.058795928955078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25752,
        "tokens": 13501464576,
        "learning_rate": 9.11730980660426e-05,
        "gradient_norm": 0.4276471734046936,
        "train_loss": 3.0039615631103516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25753,
        "tokens": 13501988864,
        "learning_rate": 9.115973739956418e-05,
        "gradient_norm": 0.43845245242118835,
        "train_loss": 2.981022357940674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25754,
        "tokens": 13502513152,
        "learning_rate": 9.114637942153066e-05,
        "gradient_norm": 0.3842538595199585,
        "train_loss": 3.0275962352752686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25755,
        "tokens": 13503037440,
        "learning_rate": 9.11330241320923e-05,
        "gradient_norm": 0.42542895674705505,
        "train_loss": 3.0050079822540283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25756,
        "tokens": 13503561728,
        "learning_rate": 9.111967153139963e-05,
        "gradient_norm": 0.40547922253608704,
        "train_loss": 3.0276899337768555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25757,
        "tokens": 13504086016,
        "learning_rate": 9.110632161960271e-05,
        "gradient_norm": 0.42823871970176697,
        "train_loss": 3.0699076652526855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25758,
        "tokens": 13504610304,
        "learning_rate": 9.109297439685196e-05,
        "gradient_norm": 0.4273689389228821,
        "train_loss": 3.0451860427856445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25759,
        "tokens": 13505134592,
        "learning_rate": 9.107962986329765e-05,
        "gradient_norm": 0.4141576886177063,
        "train_loss": 3.060932159423828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25760,
        "tokens": 13505658880,
        "learning_rate": 9.106628801908987e-05,
        "gradient_norm": 0.45647168159484863,
        "train_loss": 3.0428390502929688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25761,
        "tokens": 13506183168,
        "learning_rate": 9.10529488643789e-05,
        "gradient_norm": 0.38772308826446533,
        "train_loss": 3.0228443145751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25762,
        "tokens": 13506707456,
        "learning_rate": 9.103961239931479e-05,
        "gradient_norm": 0.4432354271411896,
        "train_loss": 3.0293869972229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25763,
        "tokens": 13507231744,
        "learning_rate": 9.102627862404776e-05,
        "gradient_norm": 0.4144847095012665,
        "train_loss": 3.022725820541382,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25764,
        "tokens": 13507756032,
        "learning_rate": 9.101294753872781e-05,
        "gradient_norm": 0.4258767068386078,
        "train_loss": 3.039216995239258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25765,
        "tokens": 13508280320,
        "learning_rate": 9.09996191435051e-05,
        "gradient_norm": 0.404109925031662,
        "train_loss": 3.0215163230895996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25766,
        "tokens": 13508804608,
        "learning_rate": 9.098629343852954e-05,
        "gradient_norm": 0.4138212502002716,
        "train_loss": 3.0354294776916504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25767,
        "tokens": 13509328896,
        "learning_rate": 9.097297042395126e-05,
        "gradient_norm": 0.41384807229042053,
        "train_loss": 3.026385545730591,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25768,
        "tokens": 13509853184,
        "learning_rate": 9.095965009992006e-05,
        "gradient_norm": 0.432718425989151,
        "train_loss": 2.9940414428710938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25769,
        "tokens": 13510377472,
        "learning_rate": 9.094633246658605e-05,
        "gradient_norm": 0.4242897927761078,
        "train_loss": 3.0654101371765137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25770,
        "tokens": 13510901760,
        "learning_rate": 9.0933017524099e-05,
        "gradient_norm": 0.4117763340473175,
        "train_loss": 3.0172369480133057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25771,
        "tokens": 13511426048,
        "learning_rate": 9.091970527260888e-05,
        "gradient_norm": 0.4541771113872528,
        "train_loss": 3.049013614654541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25772,
        "tokens": 13511950336,
        "learning_rate": 9.090639571226547e-05,
        "gradient_norm": 0.4633735120296478,
        "train_loss": 3.042590618133545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25773,
        "tokens": 13512474624,
        "learning_rate": 9.089308884321866e-05,
        "gradient_norm": 0.4446977972984314,
        "train_loss": 3.004946231842041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25774,
        "tokens": 13512998912,
        "learning_rate": 9.087978466561813e-05,
        "gradient_norm": 0.4790245592594147,
        "train_loss": 2.9976165294647217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25775,
        "tokens": 13513523200,
        "learning_rate": 9.086648317961376e-05,
        "gradient_norm": 0.42108190059661865,
        "train_loss": 2.9916725158691406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25776,
        "tokens": 13514047488,
        "learning_rate": 9.085318438535513e-05,
        "gradient_norm": 0.41904428601264954,
        "train_loss": 2.9971375465393066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25777,
        "tokens": 13514571776,
        "learning_rate": 9.083988828299209e-05,
        "gradient_norm": 0.39509907364845276,
        "train_loss": 2.9624876976013184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25778,
        "tokens": 13515096064,
        "learning_rate": 9.082659487267418e-05,
        "gradient_norm": 0.45750370621681213,
        "train_loss": 3.0425777435302734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25779,
        "tokens": 13515620352,
        "learning_rate": 9.081330415455106e-05,
        "gradient_norm": 0.4370482861995697,
        "train_loss": 3.126412868499756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25780,
        "tokens": 13516144640,
        "learning_rate": 9.08000161287724e-05,
        "gradient_norm": 0.39994561672210693,
        "train_loss": 2.9957168102264404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25781,
        "tokens": 13516668928,
        "learning_rate": 9.078673079548772e-05,
        "gradient_norm": 0.4450156092643738,
        "train_loss": 3.012478828430176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25782,
        "tokens": 13517193216,
        "learning_rate": 9.077344815484659e-05,
        "gradient_norm": 0.38164758682250977,
        "train_loss": 3.0443644523620605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25783,
        "tokens": 13517717504,
        "learning_rate": 9.076016820699845e-05,
        "gradient_norm": 0.469442218542099,
        "train_loss": 2.9986252784729004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25784,
        "tokens": 13518241792,
        "learning_rate": 9.07468909520929e-05,
        "gradient_norm": 0.4415256679058075,
        "train_loss": 3.0374698638916016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25785,
        "tokens": 13518766080,
        "learning_rate": 9.07336163902793e-05,
        "gradient_norm": 0.45339420437812805,
        "train_loss": 3.064580202102661,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25786,
        "tokens": 13519290368,
        "learning_rate": 9.072034452170711e-05,
        "gradient_norm": 0.37287434935569763,
        "train_loss": 3.041330337524414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25787,
        "tokens": 13519814656,
        "learning_rate": 9.070707534652571e-05,
        "gradient_norm": 0.45158568024635315,
        "train_loss": 2.9574098587036133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25788,
        "tokens": 13520338944,
        "learning_rate": 9.069380886488448e-05,
        "gradient_norm": 0.4342428147792816,
        "train_loss": 3.008856773376465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25789,
        "tokens": 13520863232,
        "learning_rate": 9.068054507693268e-05,
        "gradient_norm": 0.4083455204963684,
        "train_loss": 3.042468786239624,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25790,
        "tokens": 13521387520,
        "learning_rate": 9.066728398281969e-05,
        "gradient_norm": 0.393898069858551,
        "train_loss": 3.0337886810302734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25791,
        "tokens": 13521911808,
        "learning_rate": 9.065402558269478e-05,
        "gradient_norm": 0.40244823694229126,
        "train_loss": 3.046837091445923,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25792,
        "tokens": 13522436096,
        "learning_rate": 9.064076987670713e-05,
        "gradient_norm": 0.4445702135562897,
        "train_loss": 2.9882240295410156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25793,
        "tokens": 13522960384,
        "learning_rate": 9.062751686500602e-05,
        "gradient_norm": 0.41697826981544495,
        "train_loss": 3.04304838180542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25794,
        "tokens": 13523484672,
        "learning_rate": 9.061426654774055e-05,
        "gradient_norm": 0.41726168990135193,
        "train_loss": 2.985389471054077,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25795,
        "tokens": 13524008960,
        "learning_rate": 9.060101892505997e-05,
        "gradient_norm": 0.39219778776168823,
        "train_loss": 2.971559524536133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25796,
        "tokens": 13524533248,
        "learning_rate": 9.058777399711327e-05,
        "gradient_norm": 0.46036893129348755,
        "train_loss": 2.9341249465942383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25797,
        "tokens": 13525057536,
        "learning_rate": 9.057453176404968e-05,
        "gradient_norm": 0.4230318069458008,
        "train_loss": 3.000901937484741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25798,
        "tokens": 13525581824,
        "learning_rate": 9.056129222601814e-05,
        "gradient_norm": 0.4594217836856842,
        "train_loss": 3.0160608291625977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25799,
        "tokens": 13526106112,
        "learning_rate": 9.05480553831677e-05,
        "gradient_norm": 0.4225079119205475,
        "train_loss": 3.019275665283203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25800,
        "tokens": 13526630400,
        "learning_rate": 9.053482123564746e-05,
        "gradient_norm": 0.4498630166053772,
        "train_loss": 3.014308452606201,
        "val_loss": 2.974642753601074,
        "hellaswag_acc": 0.28570008277893066,
        "hellaswag_acc_norm": 0.29924318194389343
    },
    {
        "step": 25801,
        "tokens": 13527154688,
        "learning_rate": 9.052158978360624e-05,
        "gradient_norm": 0.4093860685825348,
        "train_loss": 2.9882688522338867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25802,
        "tokens": 13527678976,
        "learning_rate": 9.05083610271931e-05,
        "gradient_norm": 0.4227351248264313,
        "train_loss": 3.0251588821411133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25803,
        "tokens": 13528203264,
        "learning_rate": 9.049513496655683e-05,
        "gradient_norm": 0.38349226117134094,
        "train_loss": 3.007063865661621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25804,
        "tokens": 13528727552,
        "learning_rate": 9.048191160184645e-05,
        "gradient_norm": 0.4242318272590637,
        "train_loss": 3.021653413772583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25805,
        "tokens": 13529251840,
        "learning_rate": 9.046869093321063e-05,
        "gradient_norm": 0.4468555450439453,
        "train_loss": 3.063648223876953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25806,
        "tokens": 13529776128,
        "learning_rate": 9.045547296079835e-05,
        "gradient_norm": 0.40284213423728943,
        "train_loss": 3.0281105041503906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25807,
        "tokens": 13530300416,
        "learning_rate": 9.044225768475827e-05,
        "gradient_norm": 0.4568409025669098,
        "train_loss": 3.0089497566223145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25808,
        "tokens": 13530824704,
        "learning_rate": 9.042904510523926e-05,
        "gradient_norm": 0.4249914586544037,
        "train_loss": 2.996673583984375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25809,
        "tokens": 13531348992,
        "learning_rate": 9.04158352223899e-05,
        "gradient_norm": 0.42180904746055603,
        "train_loss": 2.9918642044067383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25810,
        "tokens": 13531873280,
        "learning_rate": 9.040262803635898e-05,
        "gradient_norm": 0.4511186182498932,
        "train_loss": 3.045821189880371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25811,
        "tokens": 13532397568,
        "learning_rate": 9.038942354729518e-05,
        "gradient_norm": 0.42062297463417053,
        "train_loss": 3.1071503162384033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25812,
        "tokens": 13532921856,
        "learning_rate": 9.037622175534708e-05,
        "gradient_norm": 0.39625489711761475,
        "train_loss": 3.065175771713257,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25813,
        "tokens": 13533446144,
        "learning_rate": 9.036302266066335e-05,
        "gradient_norm": 0.4322799742221832,
        "train_loss": 3.030433177947998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25814,
        "tokens": 13533970432,
        "learning_rate": 9.034982626339245e-05,
        "gradient_norm": 0.4238520562648773,
        "train_loss": 2.9881539344787598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25815,
        "tokens": 13534494720,
        "learning_rate": 9.033663256368302e-05,
        "gradient_norm": 0.4525706171989441,
        "train_loss": 3.0988903045654297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25816,
        "tokens": 13535019008,
        "learning_rate": 9.032344156168352e-05,
        "gradient_norm": 0.44066673517227173,
        "train_loss": 3.0109879970550537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25817,
        "tokens": 13535543296,
        "learning_rate": 9.031025325754251e-05,
        "gradient_norm": 0.437136709690094,
        "train_loss": 3.0199708938598633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25818,
        "tokens": 13536067584,
        "learning_rate": 9.02970676514083e-05,
        "gradient_norm": 0.4063623249530792,
        "train_loss": 3.003079652786255,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25819,
        "tokens": 13536591872,
        "learning_rate": 9.028388474342937e-05,
        "gradient_norm": 0.4237661063671112,
        "train_loss": 3.0226173400878906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25820,
        "tokens": 13537116160,
        "learning_rate": 9.027070453375424e-05,
        "gradient_norm": 0.46955808997154236,
        "train_loss": 2.9980082511901855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25821,
        "tokens": 13537640448,
        "learning_rate": 9.025752702253108e-05,
        "gradient_norm": 0.3781518042087555,
        "train_loss": 2.9825572967529297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25822,
        "tokens": 13538164736,
        "learning_rate": 9.024435220990836e-05,
        "gradient_norm": 0.3865082263946533,
        "train_loss": 3.031538963317871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25823,
        "tokens": 13538689024,
        "learning_rate": 9.023118009603425e-05,
        "gradient_norm": 0.47797730565071106,
        "train_loss": 3.098605155944824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25824,
        "tokens": 13539213312,
        "learning_rate": 9.021801068105718e-05,
        "gradient_norm": 0.40605005621910095,
        "train_loss": 3.046720027923584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25825,
        "tokens": 13539737600,
        "learning_rate": 9.020484396512518e-05,
        "gradient_norm": 0.4392816126346588,
        "train_loss": 2.9847183227539062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25826,
        "tokens": 13540261888,
        "learning_rate": 9.019167994838668e-05,
        "gradient_norm": 0.456352174282074,
        "train_loss": 3.059485912322998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25827,
        "tokens": 13540786176,
        "learning_rate": 9.017851863098967e-05,
        "gradient_norm": 0.42746517062187195,
        "train_loss": 3.0375633239746094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25828,
        "tokens": 13541310464,
        "learning_rate": 9.016536001308246e-05,
        "gradient_norm": 0.4164533317089081,
        "train_loss": 3.040619373321533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25829,
        "tokens": 13541834752,
        "learning_rate": 9.0152204094813e-05,
        "gradient_norm": 0.4314422607421875,
        "train_loss": 3.0126256942749023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25830,
        "tokens": 13542359040,
        "learning_rate": 9.013905087632946e-05,
        "gradient_norm": 0.4180222153663635,
        "train_loss": 2.996204376220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25831,
        "tokens": 13542883328,
        "learning_rate": 9.012590035777996e-05,
        "gradient_norm": 0.4502371847629547,
        "train_loss": 3.0790796279907227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25832,
        "tokens": 13543407616,
        "learning_rate": 9.011275253931243e-05,
        "gradient_norm": 0.43103909492492676,
        "train_loss": 2.9731502532958984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25833,
        "tokens": 13543931904,
        "learning_rate": 9.009960742107495e-05,
        "gradient_norm": 0.47100719809532166,
        "train_loss": 3.0435802936553955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25834,
        "tokens": 13544456192,
        "learning_rate": 9.008646500321537e-05,
        "gradient_norm": 0.4322054386138916,
        "train_loss": 3.0297751426696777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25835,
        "tokens": 13544980480,
        "learning_rate": 9.007332528588172e-05,
        "gradient_norm": 0.4532046616077423,
        "train_loss": 2.9914321899414062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25836,
        "tokens": 13545504768,
        "learning_rate": 9.006018826922182e-05,
        "gradient_norm": 0.44376444816589355,
        "train_loss": 3.052246570587158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25837,
        "tokens": 13546029056,
        "learning_rate": 9.004705395338367e-05,
        "gradient_norm": 0.4968399703502655,
        "train_loss": 3.0359864234924316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25838,
        "tokens": 13546553344,
        "learning_rate": 9.003392233851497e-05,
        "gradient_norm": 0.4154989719390869,
        "train_loss": 2.9717376232147217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25839,
        "tokens": 13547077632,
        "learning_rate": 9.002079342476359e-05,
        "gradient_norm": 0.46225371956825256,
        "train_loss": 3.0154294967651367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25840,
        "tokens": 13547601920,
        "learning_rate": 9.000766721227738e-05,
        "gradient_norm": 0.4490237832069397,
        "train_loss": 2.9856576919555664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25841,
        "tokens": 13548126208,
        "learning_rate": 8.9994543701204e-05,
        "gradient_norm": 0.4498468339443207,
        "train_loss": 3.052027940750122,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25842,
        "tokens": 13548650496,
        "learning_rate": 8.998142289169122e-05,
        "gradient_norm": 0.4568846523761749,
        "train_loss": 3.00689697265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25843,
        "tokens": 13549174784,
        "learning_rate": 8.99683047838867e-05,
        "gradient_norm": 0.4166269302368164,
        "train_loss": 3.004944324493408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25844,
        "tokens": 13549699072,
        "learning_rate": 8.995518937793815e-05,
        "gradient_norm": 0.4755963683128357,
        "train_loss": 3.047391176223755,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25845,
        "tokens": 13550223360,
        "learning_rate": 8.994207667399314e-05,
        "gradient_norm": 0.4733540713787079,
        "train_loss": 3.0561890602111816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25846,
        "tokens": 13550747648,
        "learning_rate": 8.992896667219933e-05,
        "gradient_norm": 0.46246811747550964,
        "train_loss": 3.0646791458129883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25847,
        "tokens": 13551271936,
        "learning_rate": 8.991585937270418e-05,
        "gradient_norm": 0.46439483761787415,
        "train_loss": 3.059802532196045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25848,
        "tokens": 13551796224,
        "learning_rate": 8.990275477565534e-05,
        "gradient_norm": 0.5863133668899536,
        "train_loss": 2.911228656768799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25849,
        "tokens": 13552320512,
        "learning_rate": 8.988965288120033e-05,
        "gradient_norm": 0.40571290254592896,
        "train_loss": 3.0813684463500977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25850,
        "tokens": 13552844800,
        "learning_rate": 8.987655368948652e-05,
        "gradient_norm": 0.45334872603416443,
        "train_loss": 3.0005717277526855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25851,
        "tokens": 13553369088,
        "learning_rate": 8.986345720066149e-05,
        "gradient_norm": 0.4803072214126587,
        "train_loss": 3.0422439575195312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25852,
        "tokens": 13553893376,
        "learning_rate": 8.985036341487252e-05,
        "gradient_norm": 0.43557533621788025,
        "train_loss": 3.0315446853637695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25853,
        "tokens": 13554417664,
        "learning_rate": 8.983727233226712e-05,
        "gradient_norm": 0.4773980677127838,
        "train_loss": 2.995687246322632,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25854,
        "tokens": 13554941952,
        "learning_rate": 8.982418395299255e-05,
        "gradient_norm": 0.49244892597198486,
        "train_loss": 3.0566210746765137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25855,
        "tokens": 13555466240,
        "learning_rate": 8.981109827719622e-05,
        "gradient_norm": 0.4845229685306549,
        "train_loss": 3.019176959991455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25856,
        "tokens": 13555990528,
        "learning_rate": 8.979801530502534e-05,
        "gradient_norm": 0.4812524616718292,
        "train_loss": 2.9802355766296387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25857,
        "tokens": 13556514816,
        "learning_rate": 8.978493503662723e-05,
        "gradient_norm": 0.42307355999946594,
        "train_loss": 3.0104241371154785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25858,
        "tokens": 13557039104,
        "learning_rate": 8.97718574721491e-05,
        "gradient_norm": 0.4831482470035553,
        "train_loss": 3.107125759124756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25859,
        "tokens": 13557563392,
        "learning_rate": 8.97587826117382e-05,
        "gradient_norm": 0.4437788724899292,
        "train_loss": 3.013796806335449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25860,
        "tokens": 13558087680,
        "learning_rate": 8.974571045554162e-05,
        "gradient_norm": 0.45965155959129333,
        "train_loss": 2.9835286140441895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25861,
        "tokens": 13558611968,
        "learning_rate": 8.973264100370662e-05,
        "gradient_norm": 0.445709764957428,
        "train_loss": 2.978188991546631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25862,
        "tokens": 13559136256,
        "learning_rate": 8.971957425638017e-05,
        "gradient_norm": 0.4303508698940277,
        "train_loss": 3.007366418838501,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25863,
        "tokens": 13559660544,
        "learning_rate": 8.970651021370951e-05,
        "gradient_norm": 0.42184537649154663,
        "train_loss": 2.997619867324829,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25864,
        "tokens": 13560184832,
        "learning_rate": 8.969344887584155e-05,
        "gradient_norm": 0.3983668386936188,
        "train_loss": 2.968263626098633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25865,
        "tokens": 13560709120,
        "learning_rate": 8.968039024292342e-05,
        "gradient_norm": 0.4458528757095337,
        "train_loss": 2.9606003761291504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25866,
        "tokens": 13561233408,
        "learning_rate": 8.9667334315102e-05,
        "gradient_norm": 0.4148845970630646,
        "train_loss": 3.052607536315918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25867,
        "tokens": 13561757696,
        "learning_rate": 8.965428109252438e-05,
        "gradient_norm": 0.43276655673980713,
        "train_loss": 3.0579380989074707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25868,
        "tokens": 13562281984,
        "learning_rate": 8.964123057533738e-05,
        "gradient_norm": 0.41961562633514404,
        "train_loss": 2.996945858001709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25869,
        "tokens": 13562806272,
        "learning_rate": 8.962818276368799e-05,
        "gradient_norm": 0.4461112916469574,
        "train_loss": 3.056293487548828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25870,
        "tokens": 13563330560,
        "learning_rate": 8.961513765772299e-05,
        "gradient_norm": 0.40904635190963745,
        "train_loss": 3.013145685195923,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25871,
        "tokens": 13563854848,
        "learning_rate": 8.960209525758929e-05,
        "gradient_norm": 0.39556124806404114,
        "train_loss": 2.9872756004333496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25872,
        "tokens": 13564379136,
        "learning_rate": 8.958905556343365e-05,
        "gradient_norm": 0.406779944896698,
        "train_loss": 3.0295262336730957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25873,
        "tokens": 13564903424,
        "learning_rate": 8.957601857540289e-05,
        "gradient_norm": 0.4376262128353119,
        "train_loss": 3.04272198677063,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25874,
        "tokens": 13565427712,
        "learning_rate": 8.956298429364371e-05,
        "gradient_norm": 0.45970335602760315,
        "train_loss": 3.068161964416504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25875,
        "tokens": 13565952000,
        "learning_rate": 8.954995271830291e-05,
        "gradient_norm": 0.4051361083984375,
        "train_loss": 3.0553159713745117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25876,
        "tokens": 13566476288,
        "learning_rate": 8.953692384952706e-05,
        "gradient_norm": 0.4281514883041382,
        "train_loss": 3.022759437561035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25877,
        "tokens": 13567000576,
        "learning_rate": 8.952389768746294e-05,
        "gradient_norm": 0.41658151149749756,
        "train_loss": 3.0486197471618652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25878,
        "tokens": 13567524864,
        "learning_rate": 8.951087423225705e-05,
        "gradient_norm": 0.43565282225608826,
        "train_loss": 3.0253562927246094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25879,
        "tokens": 13568049152,
        "learning_rate": 8.949785348405603e-05,
        "gradient_norm": 0.4629741907119751,
        "train_loss": 3.084920883178711,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25880,
        "tokens": 13568573440,
        "learning_rate": 8.948483544300655e-05,
        "gradient_norm": 0.4742944538593292,
        "train_loss": 3.0184059143066406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25881,
        "tokens": 13569097728,
        "learning_rate": 8.947182010925499e-05,
        "gradient_norm": 0.45336613059043884,
        "train_loss": 3.013251781463623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25882,
        "tokens": 13569622016,
        "learning_rate": 8.945880748294795e-05,
        "gradient_norm": 0.4219718873500824,
        "train_loss": 3.0363948345184326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25883,
        "tokens": 13570146304,
        "learning_rate": 8.944579756423184e-05,
        "gradient_norm": 0.46927061676979065,
        "train_loss": 3.0929067134857178,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25884,
        "tokens": 13570670592,
        "learning_rate": 8.943279035325319e-05,
        "gradient_norm": 0.4508621394634247,
        "train_loss": 3.0106306076049805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25885,
        "tokens": 13571194880,
        "learning_rate": 8.941978585015831e-05,
        "gradient_norm": 0.41082099080085754,
        "train_loss": 3.0667080879211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25886,
        "tokens": 13571719168,
        "learning_rate": 8.940678405509368e-05,
        "gradient_norm": 0.4308634400367737,
        "train_loss": 3.0269575119018555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25887,
        "tokens": 13572243456,
        "learning_rate": 8.939378496820555e-05,
        "gradient_norm": 0.423400342464447,
        "train_loss": 3.036588430404663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25888,
        "tokens": 13572767744,
        "learning_rate": 8.93807885896403e-05,
        "gradient_norm": 0.4252820312976837,
        "train_loss": 2.979705810546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25889,
        "tokens": 13573292032,
        "learning_rate": 8.936779491954428e-05,
        "gradient_norm": 0.40028196573257446,
        "train_loss": 3.0541763305664062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25890,
        "tokens": 13573816320,
        "learning_rate": 8.935480395806361e-05,
        "gradient_norm": 0.4197807312011719,
        "train_loss": 2.9853076934814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25891,
        "tokens": 13574340608,
        "learning_rate": 8.934181570534463e-05,
        "gradient_norm": 0.45480310916900635,
        "train_loss": 3.0294582843780518,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25892,
        "tokens": 13574864896,
        "learning_rate": 8.932883016153347e-05,
        "gradient_norm": 0.3783235251903534,
        "train_loss": 3.0424225330352783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25893,
        "tokens": 13575389184,
        "learning_rate": 8.931584732677639e-05,
        "gradient_norm": 0.45115941762924194,
        "train_loss": 2.991410255432129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25894,
        "tokens": 13575913472,
        "learning_rate": 8.93028672012194e-05,
        "gradient_norm": 0.441552072763443,
        "train_loss": 3.041983127593994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25895,
        "tokens": 13576437760,
        "learning_rate": 8.928988978500874e-05,
        "gradient_norm": 0.42048919200897217,
        "train_loss": 2.9975340366363525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25896,
        "tokens": 13576962048,
        "learning_rate": 8.927691507829037e-05,
        "gradient_norm": 0.46085283160209656,
        "train_loss": 3.025482177734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25897,
        "tokens": 13577486336,
        "learning_rate": 8.926394308121047e-05,
        "gradient_norm": 0.4403838813304901,
        "train_loss": 3.0770139694213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25898,
        "tokens": 13578010624,
        "learning_rate": 8.925097379391486e-05,
        "gradient_norm": 0.46472910046577454,
        "train_loss": 3.1551661491394043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25899,
        "tokens": 13578534912,
        "learning_rate": 8.923800721654968e-05,
        "gradient_norm": 0.446225643157959,
        "train_loss": 3.054396867752075,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25900,
        "tokens": 13579059200,
        "learning_rate": 8.922504334926092e-05,
        "gradient_norm": 0.43925711512565613,
        "train_loss": 3.0435943603515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25901,
        "tokens": 13579583488,
        "learning_rate": 8.921208219219436e-05,
        "gradient_norm": 0.4473995864391327,
        "train_loss": 3.0155704021453857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25902,
        "tokens": 13580107776,
        "learning_rate": 8.9199123745496e-05,
        "gradient_norm": 0.38947048783302307,
        "train_loss": 3.060304641723633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25903,
        "tokens": 13580632064,
        "learning_rate": 8.918616800931163e-05,
        "gradient_norm": 0.4106016159057617,
        "train_loss": 2.9669718742370605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25904,
        "tokens": 13581156352,
        "learning_rate": 8.917321498378716e-05,
        "gradient_norm": 0.40583857893943787,
        "train_loss": 3.019756317138672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25905,
        "tokens": 13581680640,
        "learning_rate": 8.916026466906831e-05,
        "gradient_norm": 0.50423663854599,
        "train_loss": 3.034965753555298,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25906,
        "tokens": 13582204928,
        "learning_rate": 8.914731706530095e-05,
        "gradient_norm": 0.4300660192966461,
        "train_loss": 2.959944009780884,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25907,
        "tokens": 13582729216,
        "learning_rate": 8.913437217263073e-05,
        "gradient_norm": 0.49064329266548157,
        "train_loss": 2.995901584625244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25908,
        "tokens": 13583253504,
        "learning_rate": 8.912142999120339e-05,
        "gradient_norm": 0.46309903264045715,
        "train_loss": 3.068291187286377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25909,
        "tokens": 13583777792,
        "learning_rate": 8.910849052116466e-05,
        "gradient_norm": 0.4573638439178467,
        "train_loss": 3.025022268295288,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25910,
        "tokens": 13584302080,
        "learning_rate": 8.90955537626601e-05,
        "gradient_norm": 0.46400755643844604,
        "train_loss": 2.978010654449463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25911,
        "tokens": 13584826368,
        "learning_rate": 8.908261971583544e-05,
        "gradient_norm": 0.42133936285972595,
        "train_loss": 2.9975719451904297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25912,
        "tokens": 13585350656,
        "learning_rate": 8.906968838083614e-05,
        "gradient_norm": 0.5884218811988831,
        "train_loss": 3.096578598022461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25913,
        "tokens": 13585874944,
        "learning_rate": 8.905675975780788e-05,
        "gradient_norm": 0.40824002027511597,
        "train_loss": 3.0222740173339844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25914,
        "tokens": 13586399232,
        "learning_rate": 8.90438338468961e-05,
        "gradient_norm": 0.42199403047561646,
        "train_loss": 3.084801435470581,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25915,
        "tokens": 13586923520,
        "learning_rate": 8.903091064824637e-05,
        "gradient_norm": 0.5265493392944336,
        "train_loss": 3.0347228050231934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25916,
        "tokens": 13587447808,
        "learning_rate": 8.901799016200406e-05,
        "gradient_norm": 0.44820383191108704,
        "train_loss": 3.0023460388183594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25917,
        "tokens": 13587972096,
        "learning_rate": 8.900507238831471e-05,
        "gradient_norm": 0.49529847502708435,
        "train_loss": 3.121121883392334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25918,
        "tokens": 13588496384,
        "learning_rate": 8.899215732732362e-05,
        "gradient_norm": 0.4077754020690918,
        "train_loss": 3.0395960807800293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25919,
        "tokens": 13589020672,
        "learning_rate": 8.897924497917623e-05,
        "gradient_norm": 0.4419976770877838,
        "train_loss": 3.0103566646575928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25920,
        "tokens": 13589544960,
        "learning_rate": 8.896633534401795e-05,
        "gradient_norm": 0.4642115831375122,
        "train_loss": 3.0167245864868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25921,
        "tokens": 13590069248,
        "learning_rate": 8.895342842199394e-05,
        "gradient_norm": 0.40208256244659424,
        "train_loss": 2.9883689880371094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25922,
        "tokens": 13590593536,
        "learning_rate": 8.894052421324962e-05,
        "gradient_norm": 0.4441966414451599,
        "train_loss": 3.0129075050354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25923,
        "tokens": 13591117824,
        "learning_rate": 8.892762271793017e-05,
        "gradient_norm": 0.4643685817718506,
        "train_loss": 3.014995813369751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25924,
        "tokens": 13591642112,
        "learning_rate": 8.891472393618084e-05,
        "gradient_norm": 0.4030888080596924,
        "train_loss": 3.0109479427337646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25925,
        "tokens": 13592166400,
        "learning_rate": 8.890182786814679e-05,
        "gradient_norm": 0.38860857486724854,
        "train_loss": 2.943730115890503,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25926,
        "tokens": 13592690688,
        "learning_rate": 8.888893451397325e-05,
        "gradient_norm": 0.4903014302253723,
        "train_loss": 3.01428484916687,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25927,
        "tokens": 13593214976,
        "learning_rate": 8.887604387380526e-05,
        "gradient_norm": 0.5687763690948486,
        "train_loss": 3.0791983604431152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25928,
        "tokens": 13593739264,
        "learning_rate": 8.886315594778795e-05,
        "gradient_norm": 0.4998738467693329,
        "train_loss": 3.039381265640259,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25929,
        "tokens": 13594263552,
        "learning_rate": 8.885027073606645e-05,
        "gradient_norm": 0.4612797796726227,
        "train_loss": 2.982023239135742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25930,
        "tokens": 13594787840,
        "learning_rate": 8.883738823878571e-05,
        "gradient_norm": 0.5058470964431763,
        "train_loss": 3.060128688812256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25931,
        "tokens": 13595312128,
        "learning_rate": 8.882450845609085e-05,
        "gradient_norm": 0.44496583938598633,
        "train_loss": 3.0865793228149414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25932,
        "tokens": 13595836416,
        "learning_rate": 8.88116313881267e-05,
        "gradient_norm": 0.4556008577346802,
        "train_loss": 3.0068979263305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25933,
        "tokens": 13596360704,
        "learning_rate": 8.879875703503838e-05,
        "gradient_norm": 0.4940786361694336,
        "train_loss": 3.1174943447113037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25934,
        "tokens": 13596884992,
        "learning_rate": 8.878588539697064e-05,
        "gradient_norm": 0.43024227023124695,
        "train_loss": 3.0091099739074707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25935,
        "tokens": 13597409280,
        "learning_rate": 8.877301647406847e-05,
        "gradient_norm": 0.45685383677482605,
        "train_loss": 3.051370143890381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25936,
        "tokens": 13597933568,
        "learning_rate": 8.876015026647668e-05,
        "gradient_norm": 0.43755674362182617,
        "train_loss": 2.985179901123047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25937,
        "tokens": 13598457856,
        "learning_rate": 8.874728677434016e-05,
        "gradient_norm": 0.42400017380714417,
        "train_loss": 2.992543935775757,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25938,
        "tokens": 13598982144,
        "learning_rate": 8.873442599780361e-05,
        "gradient_norm": 0.4025351405143738,
        "train_loss": 3.015514850616455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25939,
        "tokens": 13599506432,
        "learning_rate": 8.872156793701181e-05,
        "gradient_norm": 0.4602767527103424,
        "train_loss": 2.987431526184082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25940,
        "tokens": 13600030720,
        "learning_rate": 8.870871259210962e-05,
        "gradient_norm": 0.4767555892467499,
        "train_loss": 3.0978522300720215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25941,
        "tokens": 13600555008,
        "learning_rate": 8.869585996324156e-05,
        "gradient_norm": 0.4194428026676178,
        "train_loss": 2.9596879482269287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25942,
        "tokens": 13601079296,
        "learning_rate": 8.868301005055242e-05,
        "gradient_norm": 0.49363207817077637,
        "train_loss": 3.0831336975097656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25943,
        "tokens": 13601603584,
        "learning_rate": 8.86701628541868e-05,
        "gradient_norm": 0.4513389468193054,
        "train_loss": 2.9979424476623535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25944,
        "tokens": 13602127872,
        "learning_rate": 8.865731837428938e-05,
        "gradient_norm": 0.4171331822872162,
        "train_loss": 2.9625089168548584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25945,
        "tokens": 13602652160,
        "learning_rate": 8.864447661100462e-05,
        "gradient_norm": 0.5015800595283508,
        "train_loss": 3.046471357345581,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25946,
        "tokens": 13603176448,
        "learning_rate": 8.863163756447718e-05,
        "gradient_norm": 0.5186845660209656,
        "train_loss": 2.9690520763397217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25947,
        "tokens": 13603700736,
        "learning_rate": 8.86188012348515e-05,
        "gradient_norm": 0.43613573908805847,
        "train_loss": 3.0297255516052246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25948,
        "tokens": 13604225024,
        "learning_rate": 8.860596762227206e-05,
        "gradient_norm": 0.44539836049079895,
        "train_loss": 3.026759147644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25949,
        "tokens": 13604749312,
        "learning_rate": 8.859313672688342e-05,
        "gradient_norm": 0.44207650423049927,
        "train_loss": 3.016188383102417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25950,
        "tokens": 13605273600,
        "learning_rate": 8.858030854882993e-05,
        "gradient_norm": 0.42552292346954346,
        "train_loss": 3.0063891410827637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25951,
        "tokens": 13605797888,
        "learning_rate": 8.856748308825604e-05,
        "gradient_norm": 0.40277522802352905,
        "train_loss": 2.97244930267334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25952,
        "tokens": 13606322176,
        "learning_rate": 8.855466034530602e-05,
        "gradient_norm": 0.4587725102901459,
        "train_loss": 3.0227439403533936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25953,
        "tokens": 13606846464,
        "learning_rate": 8.854184032012433e-05,
        "gradient_norm": 0.4499698877334595,
        "train_loss": 3.014024257659912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25954,
        "tokens": 13607370752,
        "learning_rate": 8.852902301285516e-05,
        "gradient_norm": 0.46990588307380676,
        "train_loss": 2.984915256500244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25955,
        "tokens": 13607895040,
        "learning_rate": 8.851620842364289e-05,
        "gradient_norm": 0.4049963653087616,
        "train_loss": 2.999440908432007,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25956,
        "tokens": 13608419328,
        "learning_rate": 8.850339655263164e-05,
        "gradient_norm": 0.451980322599411,
        "train_loss": 3.0758779048919678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25957,
        "tokens": 13608943616,
        "learning_rate": 8.849058739996579e-05,
        "gradient_norm": 0.40847718715667725,
        "train_loss": 3.049532890319824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25958,
        "tokens": 13609467904,
        "learning_rate": 8.847778096578933e-05,
        "gradient_norm": 0.4526614546775818,
        "train_loss": 3.0323731899261475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25959,
        "tokens": 13609992192,
        "learning_rate": 8.846497725024659e-05,
        "gradient_norm": 0.4658319056034088,
        "train_loss": 3.0619888305664062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25960,
        "tokens": 13610516480,
        "learning_rate": 8.845217625348155e-05,
        "gradient_norm": 0.42855745553970337,
        "train_loss": 3.014805555343628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25961,
        "tokens": 13611040768,
        "learning_rate": 8.843937797563844e-05,
        "gradient_norm": 0.48750239610671997,
        "train_loss": 2.9986014366149902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25962,
        "tokens": 13611565056,
        "learning_rate": 8.842658241686114e-05,
        "gradient_norm": 0.40391406416893005,
        "train_loss": 2.990525484085083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25963,
        "tokens": 13612089344,
        "learning_rate": 8.841378957729381e-05,
        "gradient_norm": 0.47569653391838074,
        "train_loss": 3.0340797901153564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25964,
        "tokens": 13612613632,
        "learning_rate": 8.840099945708049e-05,
        "gradient_norm": 0.4343578815460205,
        "train_loss": 3.0242667198181152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25965,
        "tokens": 13613137920,
        "learning_rate": 8.838821205636502e-05,
        "gradient_norm": 0.39209219813346863,
        "train_loss": 3.026947498321533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25966,
        "tokens": 13613662208,
        "learning_rate": 8.837542737529148e-05,
        "gradient_norm": 0.45889782905578613,
        "train_loss": 3.0057008266448975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25967,
        "tokens": 13614186496,
        "learning_rate": 8.836264541400362e-05,
        "gradient_norm": 0.38813072443008423,
        "train_loss": 3.007962942123413,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25968,
        "tokens": 13614710784,
        "learning_rate": 8.834986617264541e-05,
        "gradient_norm": 0.4090173542499542,
        "train_loss": 3.0024495124816895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25969,
        "tokens": 13615235072,
        "learning_rate": 8.833708965136068e-05,
        "gradient_norm": 0.4606247842311859,
        "train_loss": 2.9971280097961426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25970,
        "tokens": 13615759360,
        "learning_rate": 8.832431585029327e-05,
        "gradient_norm": 0.3810718357563019,
        "train_loss": 2.984935998916626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25971,
        "tokens": 13616283648,
        "learning_rate": 8.831154476958692e-05,
        "gradient_norm": 0.45361363887786865,
        "train_loss": 3.070948362350464,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25972,
        "tokens": 13616807936,
        "learning_rate": 8.829877640938543e-05,
        "gradient_norm": 0.3939327597618103,
        "train_loss": 3.0537376403808594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25973,
        "tokens": 13617332224,
        "learning_rate": 8.828601076983247e-05,
        "gradient_norm": 0.39940178394317627,
        "train_loss": 2.9288315773010254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25974,
        "tokens": 13617856512,
        "learning_rate": 8.827324785107182e-05,
        "gradient_norm": 0.4043661653995514,
        "train_loss": 3.0828280448913574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25975,
        "tokens": 13618380800,
        "learning_rate": 8.826048765324699e-05,
        "gradient_norm": 0.4660295248031616,
        "train_loss": 3.0163934230804443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25976,
        "tokens": 13618905088,
        "learning_rate": 8.824773017650182e-05,
        "gradient_norm": 0.40702712535858154,
        "train_loss": 3.0301787853240967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25977,
        "tokens": 13619429376,
        "learning_rate": 8.823497542097969e-05,
        "gradient_norm": 0.46733590960502625,
        "train_loss": 3.07673978805542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25978,
        "tokens": 13619953664,
        "learning_rate": 8.822222338682435e-05,
        "gradient_norm": 0.41113990545272827,
        "train_loss": 2.9561126232147217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25979,
        "tokens": 13620477952,
        "learning_rate": 8.820947407417923e-05,
        "gradient_norm": 0.418389230966568,
        "train_loss": 3.006948471069336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25980,
        "tokens": 13621002240,
        "learning_rate": 8.819672748318791e-05,
        "gradient_norm": 0.409844309091568,
        "train_loss": 3.0416452884674072,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25981,
        "tokens": 13621526528,
        "learning_rate": 8.818398361399382e-05,
        "gradient_norm": 0.4170173406600952,
        "train_loss": 2.9954006671905518,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25982,
        "tokens": 13622050816,
        "learning_rate": 8.817124246674046e-05,
        "gradient_norm": 0.44588610529899597,
        "train_loss": 3.021143913269043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25983,
        "tokens": 13622575104,
        "learning_rate": 8.815850404157115e-05,
        "gradient_norm": 0.40114203095436096,
        "train_loss": 3.0086405277252197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25984,
        "tokens": 13623099392,
        "learning_rate": 8.814576833862942e-05,
        "gradient_norm": 0.46527349948883057,
        "train_loss": 3.0542540550231934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25985,
        "tokens": 13623623680,
        "learning_rate": 8.813303535805847e-05,
        "gradient_norm": 0.4444916546344757,
        "train_loss": 3.0479736328125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25986,
        "tokens": 13624147968,
        "learning_rate": 8.812030510000176e-05,
        "gradient_norm": 0.40569642186164856,
        "train_loss": 3.0549397468566895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25987,
        "tokens": 13624672256,
        "learning_rate": 8.810757756460248e-05,
        "gradient_norm": 0.4038405418395996,
        "train_loss": 2.977849006652832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25988,
        "tokens": 13625196544,
        "learning_rate": 8.809485275200394e-05,
        "gradient_norm": 0.4309670627117157,
        "train_loss": 3.0406603813171387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25989,
        "tokens": 13625720832,
        "learning_rate": 8.808213066234942e-05,
        "gradient_norm": 0.40563639998435974,
        "train_loss": 3.0195131301879883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25990,
        "tokens": 13626245120,
        "learning_rate": 8.806941129578202e-05,
        "gradient_norm": 0.4270235598087311,
        "train_loss": 3.0114822387695312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25991,
        "tokens": 13626769408,
        "learning_rate": 8.805669465244505e-05,
        "gradient_norm": 0.44435206055641174,
        "train_loss": 3.0230469703674316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25992,
        "tokens": 13627293696,
        "learning_rate": 8.804398073248148e-05,
        "gradient_norm": 0.42390206456184387,
        "train_loss": 3.031423330307007,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25993,
        "tokens": 13627817984,
        "learning_rate": 8.803126953603462e-05,
        "gradient_norm": 0.4573047459125519,
        "train_loss": 2.991323947906494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25994,
        "tokens": 13628342272,
        "learning_rate": 8.801856106324734e-05,
        "gradient_norm": 0.4609243869781494,
        "train_loss": 3.021350383758545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25995,
        "tokens": 13628866560,
        "learning_rate": 8.800585531426285e-05,
        "gradient_norm": 0.4750670790672302,
        "train_loss": 3.0338454246520996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25996,
        "tokens": 13629390848,
        "learning_rate": 8.799315228922409e-05,
        "gradient_norm": 0.46019747853279114,
        "train_loss": 3.0684139728546143,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25997,
        "tokens": 13629915136,
        "learning_rate": 8.79804519882741e-05,
        "gradient_norm": 0.43483737111091614,
        "train_loss": 3.036806583404541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25998,
        "tokens": 13630439424,
        "learning_rate": 8.796775441155576e-05,
        "gradient_norm": 0.45265886187553406,
        "train_loss": 3.062023639678955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 25999,
        "tokens": 13630963712,
        "learning_rate": 8.795505955921208e-05,
        "gradient_norm": 0.4560370445251465,
        "train_loss": 3.021303176879883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26000,
        "tokens": 13631488000,
        "learning_rate": 8.794236743138593e-05,
        "gradient_norm": 0.41133180260658264,
        "train_loss": 3.0057554244995117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26001,
        "tokens": 13632012288,
        "learning_rate": 8.792967802822012e-05,
        "gradient_norm": 0.44372206926345825,
        "train_loss": 2.996375560760498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26002,
        "tokens": 13632536576,
        "learning_rate": 8.791699134985758e-05,
        "gradient_norm": 0.4220465421676636,
        "train_loss": 3.0170788764953613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26003,
        "tokens": 13633060864,
        "learning_rate": 8.790430739644102e-05,
        "gradient_norm": 0.46464642882347107,
        "train_loss": 3.092991828918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26004,
        "tokens": 13633585152,
        "learning_rate": 8.789162616811332e-05,
        "gradient_norm": 0.43553438782691956,
        "train_loss": 2.9902195930480957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26005,
        "tokens": 13634109440,
        "learning_rate": 8.787894766501713e-05,
        "gradient_norm": 0.42663028836250305,
        "train_loss": 3.0054678916931152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26006,
        "tokens": 13634633728,
        "learning_rate": 8.78662718872952e-05,
        "gradient_norm": 0.3903447389602661,
        "train_loss": 3.023804187774658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26007,
        "tokens": 13635158016,
        "learning_rate": 8.78535988350902e-05,
        "gradient_norm": 0.4122278392314911,
        "train_loss": 3.006296157836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26008,
        "tokens": 13635682304,
        "learning_rate": 8.784092850854479e-05,
        "gradient_norm": 0.4479139745235443,
        "train_loss": 3.0099587440490723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26009,
        "tokens": 13636206592,
        "learning_rate": 8.78282609078016e-05,
        "gradient_norm": 0.39714792370796204,
        "train_loss": 3.0841686725616455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26010,
        "tokens": 13636730880,
        "learning_rate": 8.781559603300317e-05,
        "gradient_norm": 0.43496596813201904,
        "train_loss": 3.0422658920288086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26011,
        "tokens": 13637255168,
        "learning_rate": 8.780293388429216e-05,
        "gradient_norm": 0.39133545756340027,
        "train_loss": 3.0318775177001953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26012,
        "tokens": 13637779456,
        "learning_rate": 8.7790274461811e-05,
        "gradient_norm": 0.41869285702705383,
        "train_loss": 2.976259231567383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26013,
        "tokens": 13638303744,
        "learning_rate": 8.777761776570226e-05,
        "gradient_norm": 0.40625712275505066,
        "train_loss": 3.0406603813171387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26014,
        "tokens": 13638828032,
        "learning_rate": 8.776496379610829e-05,
        "gradient_norm": 0.43380728363990784,
        "train_loss": 3.0156500339508057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26015,
        "tokens": 13639352320,
        "learning_rate": 8.775231255317168e-05,
        "gradient_norm": 0.39068087935447693,
        "train_loss": 2.9768619537353516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26016,
        "tokens": 13639876608,
        "learning_rate": 8.773966403703473e-05,
        "gradient_norm": 0.4287324547767639,
        "train_loss": 3.013381004333496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26017,
        "tokens": 13640400896,
        "learning_rate": 8.77270182478399e-05,
        "gradient_norm": 0.39358052611351013,
        "train_loss": 3.0460474491119385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26018,
        "tokens": 13640925184,
        "learning_rate": 8.77143751857294e-05,
        "gradient_norm": 0.4539923667907715,
        "train_loss": 3.0276193618774414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26019,
        "tokens": 13641449472,
        "learning_rate": 8.770173485084563e-05,
        "gradient_norm": 0.4173421561717987,
        "train_loss": 3.051910877227783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26020,
        "tokens": 13641973760,
        "learning_rate": 8.768909724333092e-05,
        "gradient_norm": 0.44261234998703003,
        "train_loss": 3.0148658752441406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26021,
        "tokens": 13642498048,
        "learning_rate": 8.767646236332744e-05,
        "gradient_norm": 0.40725401043891907,
        "train_loss": 3.036904811859131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26022,
        "tokens": 13643022336,
        "learning_rate": 8.766383021097746e-05,
        "gradient_norm": 0.46714067459106445,
        "train_loss": 3.0084924697875977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26023,
        "tokens": 13643546624,
        "learning_rate": 8.765120078642311e-05,
        "gradient_norm": 0.444663405418396,
        "train_loss": 3.014960289001465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26024,
        "tokens": 13644070912,
        "learning_rate": 8.763857408980663e-05,
        "gradient_norm": 0.4518378674983978,
        "train_loss": 3.029599189758301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26025,
        "tokens": 13644595200,
        "learning_rate": 8.76259501212701e-05,
        "gradient_norm": 0.4132455885410309,
        "train_loss": 3.0668067932128906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26026,
        "tokens": 13645119488,
        "learning_rate": 8.761332888095565e-05,
        "gradient_norm": 0.46889951825141907,
        "train_loss": 3.015923500061035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26027,
        "tokens": 13645643776,
        "learning_rate": 8.760071036900528e-05,
        "gradient_norm": 0.48549750447273254,
        "train_loss": 3.086841583251953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26028,
        "tokens": 13646168064,
        "learning_rate": 8.758809458556107e-05,
        "gradient_norm": 0.43013760447502136,
        "train_loss": 2.9795010089874268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26029,
        "tokens": 13646692352,
        "learning_rate": 8.757548153076508e-05,
        "gradient_norm": 0.4529201090335846,
        "train_loss": 3.0048718452453613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26030,
        "tokens": 13647216640,
        "learning_rate": 8.75628712047592e-05,
        "gradient_norm": 0.4030597507953644,
        "train_loss": 3.001232147216797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26031,
        "tokens": 13647740928,
        "learning_rate": 8.755026360768544e-05,
        "gradient_norm": 0.4410310685634613,
        "train_loss": 2.979909896850586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26032,
        "tokens": 13648265216,
        "learning_rate": 8.753765873968564e-05,
        "gradient_norm": 0.40161463618278503,
        "train_loss": 3.0311830043792725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26033,
        "tokens": 13648789504,
        "learning_rate": 8.752505660090178e-05,
        "gradient_norm": 0.44145897030830383,
        "train_loss": 3.041886806488037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26034,
        "tokens": 13649313792,
        "learning_rate": 8.751245719147561e-05,
        "gradient_norm": 0.4380722939968109,
        "train_loss": 3.1111836433410645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26035,
        "tokens": 13649838080,
        "learning_rate": 8.749986051154906e-05,
        "gradient_norm": 0.5012919902801514,
        "train_loss": 3.145071506500244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26036,
        "tokens": 13650362368,
        "learning_rate": 8.748726656126381e-05,
        "gradient_norm": 0.45772987604141235,
        "train_loss": 2.959223985671997,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26037,
        "tokens": 13650886656,
        "learning_rate": 8.747467534076173e-05,
        "gradient_norm": 0.4192562997341156,
        "train_loss": 2.9914140701293945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26038,
        "tokens": 13651410944,
        "learning_rate": 8.746208685018444e-05,
        "gradient_norm": 0.39558884501457214,
        "train_loss": 2.9568512439727783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26039,
        "tokens": 13651935232,
        "learning_rate": 8.744950108967367e-05,
        "gradient_norm": 0.43185529112815857,
        "train_loss": 3.0695576667785645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26040,
        "tokens": 13652459520,
        "learning_rate": 8.743691805937118e-05,
        "gradient_norm": 0.4053005278110504,
        "train_loss": 2.956214666366577,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26041,
        "tokens": 13652983808,
        "learning_rate": 8.74243377594185e-05,
        "gradient_norm": 0.4229283928871155,
        "train_loss": 3.0456323623657227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26042,
        "tokens": 13653508096,
        "learning_rate": 8.741176018995734e-05,
        "gradient_norm": 0.3611075282096863,
        "train_loss": 3.0113511085510254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26043,
        "tokens": 13654032384,
        "learning_rate": 8.739918535112915e-05,
        "gradient_norm": 0.4231751561164856,
        "train_loss": 3.0460100173950195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26044,
        "tokens": 13654556672,
        "learning_rate": 8.738661324307559e-05,
        "gradient_norm": 0.4450266361236572,
        "train_loss": 3.0198001861572266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26045,
        "tokens": 13655080960,
        "learning_rate": 8.737404386593804e-05,
        "gradient_norm": 0.4369511902332306,
        "train_loss": 3.053523063659668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26046,
        "tokens": 13655605248,
        "learning_rate": 8.736147721985817e-05,
        "gradient_norm": 0.4553700387477875,
        "train_loss": 3.094261646270752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26047,
        "tokens": 13656129536,
        "learning_rate": 8.734891330497726e-05,
        "gradient_norm": 0.440818190574646,
        "train_loss": 2.9606969356536865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26048,
        "tokens": 13656653824,
        "learning_rate": 8.733635212143678e-05,
        "gradient_norm": 0.4054151773452759,
        "train_loss": 3.008331537246704,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26049,
        "tokens": 13657178112,
        "learning_rate": 8.732379366937823e-05,
        "gradient_norm": 0.42501741647720337,
        "train_loss": 3.0226335525512695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26050,
        "tokens": 13657702400,
        "learning_rate": 8.731123794894281e-05,
        "gradient_norm": 0.396398663520813,
        "train_loss": 3.068321704864502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26051,
        "tokens": 13658226688,
        "learning_rate": 8.729868496027198e-05,
        "gradient_norm": 0.384012371301651,
        "train_loss": 3.0217604637145996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26052,
        "tokens": 13658750976,
        "learning_rate": 8.728613470350695e-05,
        "gradient_norm": 0.40422558784484863,
        "train_loss": 3.030989170074463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26053,
        "tokens": 13659275264,
        "learning_rate": 8.727358717878909e-05,
        "gradient_norm": 0.39332225918769836,
        "train_loss": 3.012204885482788,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26054,
        "tokens": 13659799552,
        "learning_rate": 8.726104238625949e-05,
        "gradient_norm": 0.36699649691581726,
        "train_loss": 3.00356125831604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26055,
        "tokens": 13660323840,
        "learning_rate": 8.724850032605949e-05,
        "gradient_norm": 0.42680686712265015,
        "train_loss": 2.9856066703796387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26056,
        "tokens": 13660848128,
        "learning_rate": 8.723596099833016e-05,
        "gradient_norm": 0.38927462697029114,
        "train_loss": 3.027616500854492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26057,
        "tokens": 13661372416,
        "learning_rate": 8.722342440321278e-05,
        "gradient_norm": 0.4206763505935669,
        "train_loss": 2.994565010070801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26058,
        "tokens": 13661896704,
        "learning_rate": 8.721089054084834e-05,
        "gradient_norm": 0.3977872133255005,
        "train_loss": 2.9983322620391846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26059,
        "tokens": 13662420992,
        "learning_rate": 8.719835941137797e-05,
        "gradient_norm": 0.4392283856868744,
        "train_loss": 3.004770517349243,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26060,
        "tokens": 13662945280,
        "learning_rate": 8.718583101494273e-05,
        "gradient_norm": 0.4409352242946625,
        "train_loss": 3.047389507293701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26061,
        "tokens": 13663469568,
        "learning_rate": 8.717330535168364e-05,
        "gradient_norm": 0.4447951316833496,
        "train_loss": 3.0327107906341553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26062,
        "tokens": 13663993856,
        "learning_rate": 8.716078242174171e-05,
        "gradient_norm": 0.3926323652267456,
        "train_loss": 2.9906365871429443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26063,
        "tokens": 13664518144,
        "learning_rate": 8.714826222525784e-05,
        "gradient_norm": 0.441998690366745,
        "train_loss": 2.992785930633545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26064,
        "tokens": 13665042432,
        "learning_rate": 8.713574476237304e-05,
        "gradient_norm": 0.4112706184387207,
        "train_loss": 2.989802122116089,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26065,
        "tokens": 13665566720,
        "learning_rate": 8.712323003322816e-05,
        "gradient_norm": 0.4324308931827545,
        "train_loss": 3.0232534408569336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26066,
        "tokens": 13666091008,
        "learning_rate": 8.71107180379641e-05,
        "gradient_norm": 0.4775253236293793,
        "train_loss": 3.043832302093506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26067,
        "tokens": 13666615296,
        "learning_rate": 8.709820877672162e-05,
        "gradient_norm": 0.44593632221221924,
        "train_loss": 2.926814079284668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26068,
        "tokens": 13667139584,
        "learning_rate": 8.708570224964164e-05,
        "gradient_norm": 0.47260385751724243,
        "train_loss": 3.0467958450317383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26069,
        "tokens": 13667663872,
        "learning_rate": 8.707319845686484e-05,
        "gradient_norm": 0.4058011472225189,
        "train_loss": 3.0304574966430664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26070,
        "tokens": 13668188160,
        "learning_rate": 8.706069739853207e-05,
        "gradient_norm": 0.501652181148529,
        "train_loss": 2.9797284603118896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26071,
        "tokens": 13668712448,
        "learning_rate": 8.704819907478392e-05,
        "gradient_norm": 0.42090103030204773,
        "train_loss": 2.9858813285827637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26072,
        "tokens": 13669236736,
        "learning_rate": 8.703570348576118e-05,
        "gradient_norm": 0.47078877687454224,
        "train_loss": 3.0412538051605225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26073,
        "tokens": 13669761024,
        "learning_rate": 8.70232106316044e-05,
        "gradient_norm": 0.44855809211730957,
        "train_loss": 3.0695950984954834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26074,
        "tokens": 13670285312,
        "learning_rate": 8.701072051245433e-05,
        "gradient_norm": 0.4165174067020416,
        "train_loss": 2.9965925216674805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26075,
        "tokens": 13670809600,
        "learning_rate": 8.699823312845145e-05,
        "gradient_norm": 0.40885257720947266,
        "train_loss": 3.052896022796631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26076,
        "tokens": 13671333888,
        "learning_rate": 8.698574847973642e-05,
        "gradient_norm": 0.44306910037994385,
        "train_loss": 3.040393352508545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26077,
        "tokens": 13671858176,
        "learning_rate": 8.697326656644965e-05,
        "gradient_norm": 0.4199284315109253,
        "train_loss": 3.001361846923828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26078,
        "tokens": 13672382464,
        "learning_rate": 8.696078738873175e-05,
        "gradient_norm": 0.46038031578063965,
        "train_loss": 2.8931427001953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26079,
        "tokens": 13672906752,
        "learning_rate": 8.694831094672312e-05,
        "gradient_norm": 0.39438319206237793,
        "train_loss": 3.0299830436706543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26080,
        "tokens": 13673431040,
        "learning_rate": 8.693583724056424e-05,
        "gradient_norm": 0.42990025877952576,
        "train_loss": 3.0244531631469727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26081,
        "tokens": 13673955328,
        "learning_rate": 8.692336627039546e-05,
        "gradient_norm": 0.3971397578716278,
        "train_loss": 3.0383658409118652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26082,
        "tokens": 13674479616,
        "learning_rate": 8.691089803635727e-05,
        "gradient_norm": 0.4198559820652008,
        "train_loss": 3.0115303993225098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26083,
        "tokens": 13675003904,
        "learning_rate": 8.689843253858987e-05,
        "gradient_norm": 0.44344043731689453,
        "train_loss": 3.021636962890625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26084,
        "tokens": 13675528192,
        "learning_rate": 8.68859697772337e-05,
        "gradient_norm": 0.4218646287918091,
        "train_loss": 2.978151321411133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26085,
        "tokens": 13676052480,
        "learning_rate": 8.687350975242891e-05,
        "gradient_norm": 0.4248129725456238,
        "train_loss": 3.0752182006835938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26086,
        "tokens": 13676576768,
        "learning_rate": 8.686105246431594e-05,
        "gradient_norm": 0.4279983341693878,
        "train_loss": 3.0374207496643066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26087,
        "tokens": 13677101056,
        "learning_rate": 8.684859791303482e-05,
        "gradient_norm": 0.48559603095054626,
        "train_loss": 2.9802732467651367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26088,
        "tokens": 13677625344,
        "learning_rate": 8.683614609872583e-05,
        "gradient_norm": 0.4588143527507782,
        "train_loss": 3.073674201965332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26089,
        "tokens": 13678149632,
        "learning_rate": 8.682369702152919e-05,
        "gradient_norm": 0.4056014120578766,
        "train_loss": 3.0155484676361084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26090,
        "tokens": 13678673920,
        "learning_rate": 8.68112506815849e-05,
        "gradient_norm": 0.42171967029571533,
        "train_loss": 2.9879236221313477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26091,
        "tokens": 13679198208,
        "learning_rate": 8.679880707903318e-05,
        "gradient_norm": 0.43384894728660583,
        "train_loss": 3.021270751953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26092,
        "tokens": 13679722496,
        "learning_rate": 8.678636621401402e-05,
        "gradient_norm": 0.43270236253738403,
        "train_loss": 3.0426735877990723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26093,
        "tokens": 13680246784,
        "learning_rate": 8.67739280866675e-05,
        "gradient_norm": 0.4417741000652313,
        "train_loss": 3.0551815032958984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26094,
        "tokens": 13680771072,
        "learning_rate": 8.676149269713354e-05,
        "gradient_norm": 0.42347753047943115,
        "train_loss": 3.0483336448669434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26095,
        "tokens": 13681295360,
        "learning_rate": 8.674906004555229e-05,
        "gradient_norm": 0.43414556980133057,
        "train_loss": 2.9497151374816895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26096,
        "tokens": 13681819648,
        "learning_rate": 8.673663013206352e-05,
        "gradient_norm": 0.4503583014011383,
        "train_loss": 3.061051368713379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26097,
        "tokens": 13682343936,
        "learning_rate": 8.672420295680724e-05,
        "gradient_norm": 0.4540550410747528,
        "train_loss": 3.134507656097412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26098,
        "tokens": 13682868224,
        "learning_rate": 8.671177851992327e-05,
        "gradient_norm": 0.4566026031970978,
        "train_loss": 3.062253713607788,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26099,
        "tokens": 13683392512,
        "learning_rate": 8.669935682155152e-05,
        "gradient_norm": 0.5144352316856384,
        "train_loss": 2.987759590148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26100,
        "tokens": 13683916800,
        "learning_rate": 8.668693786183182e-05,
        "gradient_norm": 0.43580567836761475,
        "train_loss": 3.1016671657562256,
        "val_loss": 2.973191261291504,
        "hellaswag_acc": 0.28460466861724854,
        "hellaswag_acc_norm": 0.29854610562324524
    },
    {
        "step": 26101,
        "tokens": 13684441088,
        "learning_rate": 8.667452164090387e-05,
        "gradient_norm": 0.4564107060432434,
        "train_loss": 3.004049777984619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26102,
        "tokens": 13684965376,
        "learning_rate": 8.666210815890756e-05,
        "gradient_norm": 0.4860322177410126,
        "train_loss": 2.9480879306793213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26103,
        "tokens": 13685489664,
        "learning_rate": 8.664969741598253e-05,
        "gradient_norm": 0.4875839054584503,
        "train_loss": 2.975865364074707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26104,
        "tokens": 13686013952,
        "learning_rate": 8.663728941226849e-05,
        "gradient_norm": 0.4237024486064911,
        "train_loss": 2.961890697479248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26105,
        "tokens": 13686538240,
        "learning_rate": 8.662488414790509e-05,
        "gradient_norm": 0.4841850697994232,
        "train_loss": 3.005392551422119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26106,
        "tokens": 13687062528,
        "learning_rate": 8.661248162303208e-05,
        "gradient_norm": 0.4507165849208832,
        "train_loss": 3.0220584869384766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26107,
        "tokens": 13687586816,
        "learning_rate": 8.660008183778887e-05,
        "gradient_norm": 0.4125593304634094,
        "train_loss": 2.9744763374328613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26108,
        "tokens": 13688111104,
        "learning_rate": 8.658768479231518e-05,
        "gradient_norm": 0.3999864459037781,
        "train_loss": 2.978548288345337,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26109,
        "tokens": 13688635392,
        "learning_rate": 8.657529048675058e-05,
        "gradient_norm": 0.40777191519737244,
        "train_loss": 2.951395034790039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26110,
        "tokens": 13689159680,
        "learning_rate": 8.656289892123445e-05,
        "gradient_norm": 0.4354006052017212,
        "train_loss": 2.96391224861145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26111,
        "tokens": 13689683968,
        "learning_rate": 8.65505100959064e-05,
        "gradient_norm": 0.41412466764450073,
        "train_loss": 3.0286402702331543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26112,
        "tokens": 13690208256,
        "learning_rate": 8.653812401090578e-05,
        "gradient_norm": 0.40856117010116577,
        "train_loss": 2.9012067317962646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26113,
        "tokens": 13690732544,
        "learning_rate": 8.65257406663721e-05,
        "gradient_norm": 0.4444901943206787,
        "train_loss": 3.0137743949890137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26114,
        "tokens": 13691256832,
        "learning_rate": 8.651336006244465e-05,
        "gradient_norm": 0.430338978767395,
        "train_loss": 2.9573776721954346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26115,
        "tokens": 13691781120,
        "learning_rate": 8.650098219926292e-05,
        "gradient_norm": 0.4697825014591217,
        "train_loss": 3.001868724822998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26116,
        "tokens": 13692305408,
        "learning_rate": 8.64886070769661e-05,
        "gradient_norm": 0.41384243965148926,
        "train_loss": 2.9892609119415283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26117,
        "tokens": 13692829696,
        "learning_rate": 8.647623469569361e-05,
        "gradient_norm": 0.44733133912086487,
        "train_loss": 2.9901108741760254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26118,
        "tokens": 13693353984,
        "learning_rate": 8.646386505558462e-05,
        "gradient_norm": 0.43963128328323364,
        "train_loss": 2.9609601497650146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26119,
        "tokens": 13693878272,
        "learning_rate": 8.645149815677838e-05,
        "gradient_norm": 0.41098886728286743,
        "train_loss": 2.940178632736206,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26120,
        "tokens": 13694402560,
        "learning_rate": 8.643913399941418e-05,
        "gradient_norm": 0.41693249344825745,
        "train_loss": 2.984910488128662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26121,
        "tokens": 13694926848,
        "learning_rate": 8.642677258363106e-05,
        "gradient_norm": 0.38680917024612427,
        "train_loss": 2.9747018814086914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26122,
        "tokens": 13695451136,
        "learning_rate": 8.641441390956834e-05,
        "gradient_norm": 0.39965343475341797,
        "train_loss": 2.963010787963867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26123,
        "tokens": 13695975424,
        "learning_rate": 8.640205797736495e-05,
        "gradient_norm": 0.40996262431144714,
        "train_loss": 3.0117783546447754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26124,
        "tokens": 13696499712,
        "learning_rate": 8.638970478716009e-05,
        "gradient_norm": 0.38553398847579956,
        "train_loss": 2.955753803253174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26125,
        "tokens": 13697024000,
        "learning_rate": 8.637735433909273e-05,
        "gradient_norm": 0.45390164852142334,
        "train_loss": 3.0064282417297363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26126,
        "tokens": 13697548288,
        "learning_rate": 8.636500663330198e-05,
        "gradient_norm": 0.409775972366333,
        "train_loss": 2.966294050216675,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26127,
        "tokens": 13698072576,
        "learning_rate": 8.635266166992671e-05,
        "gradient_norm": 0.3789407014846802,
        "train_loss": 2.9648380279541016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26128,
        "tokens": 13698596864,
        "learning_rate": 8.634031944910599e-05,
        "gradient_norm": 0.3801110088825226,
        "train_loss": 2.985142946243286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26129,
        "tokens": 13699121152,
        "learning_rate": 8.632797997097873e-05,
        "gradient_norm": 0.40992993116378784,
        "train_loss": 2.9230880737304688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26130,
        "tokens": 13699645440,
        "learning_rate": 8.631564323568375e-05,
        "gradient_norm": 0.44100421667099,
        "train_loss": 3.0447776317596436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26131,
        "tokens": 13700169728,
        "learning_rate": 8.630330924336001e-05,
        "gradient_norm": 0.4342179596424103,
        "train_loss": 2.961790084838867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26132,
        "tokens": 13700694016,
        "learning_rate": 8.629097799414627e-05,
        "gradient_norm": 0.371366411447525,
        "train_loss": 2.9800286293029785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26133,
        "tokens": 13701218304,
        "learning_rate": 8.627864948818139e-05,
        "gradient_norm": 0.4296392798423767,
        "train_loss": 2.970813274383545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26134,
        "tokens": 13701742592,
        "learning_rate": 8.62663237256041e-05,
        "gradient_norm": 0.40980497002601624,
        "train_loss": 3.045389175415039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26135,
        "tokens": 13702266880,
        "learning_rate": 8.625400070655316e-05,
        "gradient_norm": 0.44614940881729126,
        "train_loss": 2.991335153579712,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26136,
        "tokens": 13702791168,
        "learning_rate": 8.624168043116725e-05,
        "gradient_norm": 0.4148791432380676,
        "train_loss": 2.996222496032715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26137,
        "tokens": 13703315456,
        "learning_rate": 8.622936289958516e-05,
        "gradient_norm": 0.4228346347808838,
        "train_loss": 3.02995228767395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26138,
        "tokens": 13703839744,
        "learning_rate": 8.62170481119454e-05,
        "gradient_norm": 0.43267822265625,
        "train_loss": 2.9984164237976074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26139,
        "tokens": 13704364032,
        "learning_rate": 8.620473606838661e-05,
        "gradient_norm": 0.4345438778400421,
        "train_loss": 3.0656723976135254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26140,
        "tokens": 13704888320,
        "learning_rate": 8.619242676904747e-05,
        "gradient_norm": 0.435219943523407,
        "train_loss": 2.964439868927002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26141,
        "tokens": 13705412608,
        "learning_rate": 8.618012021406646e-05,
        "gradient_norm": 0.4133129119873047,
        "train_loss": 2.9691038131713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26142,
        "tokens": 13705936896,
        "learning_rate": 8.616781640358217e-05,
        "gradient_norm": 0.42702269554138184,
        "train_loss": 3.054506778717041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26143,
        "tokens": 13706461184,
        "learning_rate": 8.615551533773298e-05,
        "gradient_norm": 0.45113062858581543,
        "train_loss": 2.9604361057281494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26144,
        "tokens": 13706985472,
        "learning_rate": 8.61432170166575e-05,
        "gradient_norm": 0.41598832607269287,
        "train_loss": 2.9479570388793945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26145,
        "tokens": 13707509760,
        "learning_rate": 8.613092144049402e-05,
        "gradient_norm": 0.47498270869255066,
        "train_loss": 3.023016929626465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26146,
        "tokens": 13708034048,
        "learning_rate": 8.611862860938108e-05,
        "gradient_norm": 0.6022548675537109,
        "train_loss": 3.0289673805236816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26147,
        "tokens": 13708558336,
        "learning_rate": 8.610633852345691e-05,
        "gradient_norm": 0.45172053575515747,
        "train_loss": 3.017789840698242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26148,
        "tokens": 13709082624,
        "learning_rate": 8.609405118285992e-05,
        "gradient_norm": 0.5144304633140564,
        "train_loss": 2.9888715744018555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26149,
        "tokens": 13709606912,
        "learning_rate": 8.60817665877285e-05,
        "gradient_norm": 0.48129886388778687,
        "train_loss": 2.96205472946167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26150,
        "tokens": 13710131200,
        "learning_rate": 8.606948473820076e-05,
        "gradient_norm": 0.47252094745635986,
        "train_loss": 3.0248210430145264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26151,
        "tokens": 13710655488,
        "learning_rate": 8.60572056344151e-05,
        "gradient_norm": 0.45623156428337097,
        "train_loss": 3.0144615173339844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26152,
        "tokens": 13711179776,
        "learning_rate": 8.604492927650964e-05,
        "gradient_norm": 0.5172259211540222,
        "train_loss": 3.0213370323181152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26153,
        "tokens": 13711704064,
        "learning_rate": 8.603265566462263e-05,
        "gradient_norm": 0.44874149560928345,
        "train_loss": 2.954771041870117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26154,
        "tokens": 13712228352,
        "learning_rate": 8.602038479889215e-05,
        "gradient_norm": 0.5347630977630615,
        "train_loss": 2.975825309753418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26155,
        "tokens": 13712752640,
        "learning_rate": 8.600811667945644e-05,
        "gradient_norm": 0.45052945613861084,
        "train_loss": 3.025973320007324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26156,
        "tokens": 13713276928,
        "learning_rate": 8.599585130645344e-05,
        "gradient_norm": 0.6020421385765076,
        "train_loss": 3.111125946044922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26157,
        "tokens": 13713801216,
        "learning_rate": 8.598358868002135e-05,
        "gradient_norm": 0.45064419507980347,
        "train_loss": 3.033529281616211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26158,
        "tokens": 13714325504,
        "learning_rate": 8.597132880029809e-05,
        "gradient_norm": 0.4949171841144562,
        "train_loss": 2.9871115684509277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26159,
        "tokens": 13714849792,
        "learning_rate": 8.595907166742173e-05,
        "gradient_norm": 0.4170933663845062,
        "train_loss": 2.9550278186798096,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26160,
        "tokens": 13715374080,
        "learning_rate": 8.594681728153025e-05,
        "gradient_norm": 0.46640661358833313,
        "train_loss": 2.9697611331939697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26161,
        "tokens": 13715898368,
        "learning_rate": 8.593456564276153e-05,
        "gradient_norm": 0.49736759066581726,
        "train_loss": 3.0193839073181152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26162,
        "tokens": 13716422656,
        "learning_rate": 8.592231675125354e-05,
        "gradient_norm": 0.4366634488105774,
        "train_loss": 2.9993839263916016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26163,
        "tokens": 13716946944,
        "learning_rate": 8.59100706071441e-05,
        "gradient_norm": 0.4631129205226898,
        "train_loss": 3.010662317276001,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26164,
        "tokens": 13717471232,
        "learning_rate": 8.589782721057113e-05,
        "gradient_norm": 0.42562583088874817,
        "train_loss": 2.968064308166504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26165,
        "tokens": 13717995520,
        "learning_rate": 8.588558656167233e-05,
        "gradient_norm": 0.4884924590587616,
        "train_loss": 2.951493740081787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26166,
        "tokens": 13718519808,
        "learning_rate": 8.587334866058563e-05,
        "gradient_norm": 0.4290698766708374,
        "train_loss": 2.968841552734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26167,
        "tokens": 13719044096,
        "learning_rate": 8.586111350744862e-05,
        "gradient_norm": 0.40504536032676697,
        "train_loss": 2.965331554412842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26168,
        "tokens": 13719568384,
        "learning_rate": 8.584888110239913e-05,
        "gradient_norm": 0.4740713834762573,
        "train_loss": 2.9502835273742676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26169,
        "tokens": 13720092672,
        "learning_rate": 8.583665144557486e-05,
        "gradient_norm": 0.44473201036453247,
        "train_loss": 2.998413562774658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26170,
        "tokens": 13720616960,
        "learning_rate": 8.582442453711337e-05,
        "gradient_norm": 0.4079974591732025,
        "train_loss": 3.0143532752990723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26171,
        "tokens": 13721141248,
        "learning_rate": 8.581220037715242e-05,
        "gradient_norm": 0.45612969994544983,
        "train_loss": 2.9486405849456787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26172,
        "tokens": 13721665536,
        "learning_rate": 8.57999789658295e-05,
        "gradient_norm": 0.42550569772720337,
        "train_loss": 2.968484878540039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26173,
        "tokens": 13722189824,
        "learning_rate": 8.578776030328226e-05,
        "gradient_norm": 0.46508800983428955,
        "train_loss": 2.962432622909546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26174,
        "tokens": 13722714112,
        "learning_rate": 8.577554438964815e-05,
        "gradient_norm": 0.40619853138923645,
        "train_loss": 3.014160394668579,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26175,
        "tokens": 13723238400,
        "learning_rate": 8.576333122506476e-05,
        "gradient_norm": 0.42154520750045776,
        "train_loss": 2.991201400756836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26176,
        "tokens": 13723762688,
        "learning_rate": 8.575112080966949e-05,
        "gradient_norm": 0.4022020399570465,
        "train_loss": 3.0232596397399902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26177,
        "tokens": 13724286976,
        "learning_rate": 8.573891314359988e-05,
        "gradient_norm": 0.4390195608139038,
        "train_loss": 3.0032424926757812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26178,
        "tokens": 13724811264,
        "learning_rate": 8.572670822699322e-05,
        "gradient_norm": 0.46309345960617065,
        "train_loss": 3.034142017364502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26179,
        "tokens": 13725335552,
        "learning_rate": 8.571450605998699e-05,
        "gradient_norm": 0.4195539355278015,
        "train_loss": 2.99857497215271,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26180,
        "tokens": 13725859840,
        "learning_rate": 8.570230664271847e-05,
        "gradient_norm": 0.4133837819099426,
        "train_loss": 3.0289511680603027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26181,
        "tokens": 13726384128,
        "learning_rate": 8.569010997532504e-05,
        "gradient_norm": 0.44931739568710327,
        "train_loss": 3.000756025314331,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26182,
        "tokens": 13726908416,
        "learning_rate": 8.567791605794398e-05,
        "gradient_norm": 0.4203079640865326,
        "train_loss": 3.01892352104187,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26183,
        "tokens": 13727432704,
        "learning_rate": 8.566572489071252e-05,
        "gradient_norm": 0.4306231141090393,
        "train_loss": 3.000849962234497,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26184,
        "tokens": 13727956992,
        "learning_rate": 8.565353647376786e-05,
        "gradient_norm": 0.4737986922264099,
        "train_loss": 3.02449369430542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26185,
        "tokens": 13728481280,
        "learning_rate": 8.564135080724727e-05,
        "gradient_norm": 0.4212707281112671,
        "train_loss": 3.046398162841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26186,
        "tokens": 13729005568,
        "learning_rate": 8.562916789128783e-05,
        "gradient_norm": 0.4557379186153412,
        "train_loss": 3.021846294403076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26187,
        "tokens": 13729529856,
        "learning_rate": 8.561698772602681e-05,
        "gradient_norm": 0.43354201316833496,
        "train_loss": 2.9682438373565674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26188,
        "tokens": 13730054144,
        "learning_rate": 8.560481031160113e-05,
        "gradient_norm": 0.4627954363822937,
        "train_loss": 2.995478868484497,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26189,
        "tokens": 13730578432,
        "learning_rate": 8.559263564814803e-05,
        "gradient_norm": 0.45557910203933716,
        "train_loss": 2.980107307434082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26190,
        "tokens": 13731102720,
        "learning_rate": 8.558046373580441e-05,
        "gradient_norm": 0.41168928146362305,
        "train_loss": 2.9767093658447266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26191,
        "tokens": 13731627008,
        "learning_rate": 8.556829457470742e-05,
        "gradient_norm": 0.465454638004303,
        "train_loss": 3.00590181350708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26192,
        "tokens": 13732151296,
        "learning_rate": 8.555612816499391e-05,
        "gradient_norm": 0.38937753438949585,
        "train_loss": 2.991433620452881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26193,
        "tokens": 13732675584,
        "learning_rate": 8.554396450680094e-05,
        "gradient_norm": 0.39062708616256714,
        "train_loss": 2.961691379547119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26194,
        "tokens": 13733199872,
        "learning_rate": 8.55318036002653e-05,
        "gradient_norm": 0.43527334928512573,
        "train_loss": 3.0006942749023438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26195,
        "tokens": 13733724160,
        "learning_rate": 8.551964544552402e-05,
        "gradient_norm": 0.3757266700267792,
        "train_loss": 2.95344877243042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26196,
        "tokens": 13734248448,
        "learning_rate": 8.550749004271381e-05,
        "gradient_norm": 0.41588833928108215,
        "train_loss": 2.96256685256958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26197,
        "tokens": 13734772736,
        "learning_rate": 8.549533739197164e-05,
        "gradient_norm": 0.3962533473968506,
        "train_loss": 2.9967732429504395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26198,
        "tokens": 13735297024,
        "learning_rate": 8.548318749343416e-05,
        "gradient_norm": 0.40348687767982483,
        "train_loss": 2.9930648803710938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26199,
        "tokens": 13735821312,
        "learning_rate": 8.547104034723821e-05,
        "gradient_norm": 0.41977792978286743,
        "train_loss": 2.9903764724731445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26200,
        "tokens": 13736345600,
        "learning_rate": 8.545889595352058e-05,
        "gradient_norm": 0.3898429274559021,
        "train_loss": 2.991157054901123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26201,
        "tokens": 13736869888,
        "learning_rate": 8.544675431241783e-05,
        "gradient_norm": 0.408568799495697,
        "train_loss": 2.9995522499084473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26202,
        "tokens": 13737394176,
        "learning_rate": 8.543461542406678e-05,
        "gradient_norm": 0.4425782263278961,
        "train_loss": 3.019542694091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26203,
        "tokens": 13737918464,
        "learning_rate": 8.542247928860395e-05,
        "gradient_norm": 0.42853328585624695,
        "train_loss": 2.980027198791504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26204,
        "tokens": 13738442752,
        "learning_rate": 8.5410345906166e-05,
        "gradient_norm": 0.4270685613155365,
        "train_loss": 2.9855473041534424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26205,
        "tokens": 13738967040,
        "learning_rate": 8.539821527688947e-05,
        "gradient_norm": 0.41053861379623413,
        "train_loss": 2.975374698638916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26206,
        "tokens": 13739491328,
        "learning_rate": 8.538608740091097e-05,
        "gradient_norm": 0.41772836446762085,
        "train_loss": 3.035275936126709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26207,
        "tokens": 13740015616,
        "learning_rate": 8.537396227836693e-05,
        "gradient_norm": 0.4314669370651245,
        "train_loss": 2.9687576293945312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26208,
        "tokens": 13740539904,
        "learning_rate": 8.536183990939388e-05,
        "gradient_norm": 0.49881497025489807,
        "train_loss": 2.9897100925445557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26209,
        "tokens": 13741064192,
        "learning_rate": 8.534972029412832e-05,
        "gradient_norm": 0.4088311791419983,
        "train_loss": 3.01552677154541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26210,
        "tokens": 13741588480,
        "learning_rate": 8.533760343270658e-05,
        "gradient_norm": 0.5222034454345703,
        "train_loss": 2.987192392349243,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26211,
        "tokens": 13742112768,
        "learning_rate": 8.532548932526514e-05,
        "gradient_norm": 0.46147194504737854,
        "train_loss": 3.031057357788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26212,
        "tokens": 13742637056,
        "learning_rate": 8.531337797194026e-05,
        "gradient_norm": 0.4279957115650177,
        "train_loss": 2.951169490814209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26213,
        "tokens": 13743161344,
        "learning_rate": 8.530126937286836e-05,
        "gradient_norm": 0.5147266387939453,
        "train_loss": 2.998838186264038,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26214,
        "tokens": 13743685632,
        "learning_rate": 8.528916352818567e-05,
        "gradient_norm": 0.4106804132461548,
        "train_loss": 2.9838171005249023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26215,
        "tokens": 13744209920,
        "learning_rate": 8.527706043802853e-05,
        "gradient_norm": 0.5054542422294617,
        "train_loss": 2.96299409866333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26216,
        "tokens": 13744734208,
        "learning_rate": 8.526496010253307e-05,
        "gradient_norm": 0.420205295085907,
        "train_loss": 2.9667022228240967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26217,
        "tokens": 13745258496,
        "learning_rate": 8.525286252183556e-05,
        "gradient_norm": 0.5103363394737244,
        "train_loss": 2.9291248321533203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26218,
        "tokens": 13745782784,
        "learning_rate": 8.52407676960722e-05,
        "gradient_norm": 0.4817614257335663,
        "train_loss": 2.947521686553955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26219,
        "tokens": 13746307072,
        "learning_rate": 8.522867562537908e-05,
        "gradient_norm": 0.45091933012008667,
        "train_loss": 2.978844404220581,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26220,
        "tokens": 13746831360,
        "learning_rate": 8.521658630989235e-05,
        "gradient_norm": 0.48029136657714844,
        "train_loss": 2.9803762435913086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26221,
        "tokens": 13747355648,
        "learning_rate": 8.520449974974803e-05,
        "gradient_norm": 0.4799787700176239,
        "train_loss": 2.956667900085449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26222,
        "tokens": 13747879936,
        "learning_rate": 8.51924159450823e-05,
        "gradient_norm": 0.47931918501853943,
        "train_loss": 3.008176803588867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26223,
        "tokens": 13748404224,
        "learning_rate": 8.5180334896031e-05,
        "gradient_norm": 0.4728288948535919,
        "train_loss": 2.966486692428589,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26224,
        "tokens": 13748928512,
        "learning_rate": 8.516825660273026e-05,
        "gradient_norm": 0.459091454744339,
        "train_loss": 2.963611602783203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26225,
        "tokens": 13749452800,
        "learning_rate": 8.515618106531592e-05,
        "gradient_norm": 0.42703771591186523,
        "train_loss": 3.000945568084717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26226,
        "tokens": 13749977088,
        "learning_rate": 8.514410828392406e-05,
        "gradient_norm": 0.4351988732814789,
        "train_loss": 2.9904162883758545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26227,
        "tokens": 13750501376,
        "learning_rate": 8.51320382586904e-05,
        "gradient_norm": 0.40810808539390564,
        "train_loss": 3.020232677459717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26228,
        "tokens": 13751025664,
        "learning_rate": 8.511997098975088e-05,
        "gradient_norm": 0.4171578884124756,
        "train_loss": 2.9677300453186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26229,
        "tokens": 13751549952,
        "learning_rate": 8.510790647724142e-05,
        "gradient_norm": 0.38408711552619934,
        "train_loss": 2.952981948852539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26230,
        "tokens": 13752074240,
        "learning_rate": 8.509584472129766e-05,
        "gradient_norm": 0.42153382301330566,
        "train_loss": 2.974644184112549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26231,
        "tokens": 13752598528,
        "learning_rate": 8.508378572205552e-05,
        "gradient_norm": 0.4148230254650116,
        "train_loss": 3.006457805633545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26232,
        "tokens": 13753122816,
        "learning_rate": 8.507172947965058e-05,
        "gradient_norm": 0.4394828677177429,
        "train_loss": 2.992295742034912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26233,
        "tokens": 13753647104,
        "learning_rate": 8.505967599421873e-05,
        "gradient_norm": 0.4499765932559967,
        "train_loss": 3.0285329818725586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26234,
        "tokens": 13754171392,
        "learning_rate": 8.504762526589548e-05,
        "gradient_norm": 0.4506288170814514,
        "train_loss": 3.0291428565979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26235,
        "tokens": 13754695680,
        "learning_rate": 8.50355772948166e-05,
        "gradient_norm": 0.4392242729663849,
        "train_loss": 3.014707088470459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26236,
        "tokens": 13755219968,
        "learning_rate": 8.50235320811176e-05,
        "gradient_norm": 0.3880646228790283,
        "train_loss": 2.9585742950439453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26237,
        "tokens": 13755744256,
        "learning_rate": 8.501148962493412e-05,
        "gradient_norm": 0.44554081559181213,
        "train_loss": 3.034996509552002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26238,
        "tokens": 13756268544,
        "learning_rate": 8.499944992640176e-05,
        "gradient_norm": 0.4140806496143341,
        "train_loss": 2.9918806552886963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26239,
        "tokens": 13756792832,
        "learning_rate": 8.498741298565597e-05,
        "gradient_norm": 0.4780256152153015,
        "train_loss": 3.043344497680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26240,
        "tokens": 13757317120,
        "learning_rate": 8.49753788028323e-05,
        "gradient_norm": 0.414303719997406,
        "train_loss": 2.967268943786621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26241,
        "tokens": 13757841408,
        "learning_rate": 8.49633473780661e-05,
        "gradient_norm": 0.3915875256061554,
        "train_loss": 2.9962499141693115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26242,
        "tokens": 13758365696,
        "learning_rate": 8.495131871149294e-05,
        "gradient_norm": 0.4275773763656616,
        "train_loss": 2.9876708984375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26243,
        "tokens": 13758889984,
        "learning_rate": 8.493929280324809e-05,
        "gradient_norm": 0.4413827657699585,
        "train_loss": 2.9628734588623047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26244,
        "tokens": 13759414272,
        "learning_rate": 8.492726965346702e-05,
        "gradient_norm": 0.42484721541404724,
        "train_loss": 3.054624319076538,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26245,
        "tokens": 13759938560,
        "learning_rate": 8.491524926228498e-05,
        "gradient_norm": 0.4160427451133728,
        "train_loss": 3.002863645553589,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26246,
        "tokens": 13760462848,
        "learning_rate": 8.490323162983736e-05,
        "gradient_norm": 0.41774171590805054,
        "train_loss": 3.035191774368286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26247,
        "tokens": 13760987136,
        "learning_rate": 8.489121675625934e-05,
        "gradient_norm": 0.42959991097450256,
        "train_loss": 3.0104970932006836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26248,
        "tokens": 13761511424,
        "learning_rate": 8.487920464168623e-05,
        "gradient_norm": 0.4453066885471344,
        "train_loss": 2.916684627532959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26249,
        "tokens": 13762035712,
        "learning_rate": 8.486719528625325e-05,
        "gradient_norm": 0.40545275807380676,
        "train_loss": 2.941737174987793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26250,
        "tokens": 13762560000,
        "learning_rate": 8.485518869009552e-05,
        "gradient_norm": 0.45565280318260193,
        "train_loss": 3.05501651763916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26251,
        "tokens": 13763084288,
        "learning_rate": 8.484318485334827e-05,
        "gradient_norm": 0.4701361358165741,
        "train_loss": 3.0310170650482178,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26252,
        "tokens": 13763608576,
        "learning_rate": 8.483118377614651e-05,
        "gradient_norm": 0.4079608619213104,
        "train_loss": 3.017078399658203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26253,
        "tokens": 13764132864,
        "learning_rate": 8.481918545862544e-05,
        "gradient_norm": 0.43011003732681274,
        "train_loss": 2.9876580238342285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26254,
        "tokens": 13764657152,
        "learning_rate": 8.480718990092004e-05,
        "gradient_norm": 0.5010287165641785,
        "train_loss": 3.027540683746338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26255,
        "tokens": 13765181440,
        "learning_rate": 8.479519710316536e-05,
        "gradient_norm": 0.41137850284576416,
        "train_loss": 3.0052249431610107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26256,
        "tokens": 13765705728,
        "learning_rate": 8.478320706549639e-05,
        "gradient_norm": 0.4127049446105957,
        "train_loss": 3.0339982509613037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26257,
        "tokens": 13766230016,
        "learning_rate": 8.477121978804805e-05,
        "gradient_norm": 0.418661892414093,
        "train_loss": 2.984574556350708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26258,
        "tokens": 13766754304,
        "learning_rate": 8.475923527095539e-05,
        "gradient_norm": 0.3945865333080292,
        "train_loss": 2.9912867546081543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26259,
        "tokens": 13767278592,
        "learning_rate": 8.474725351435321e-05,
        "gradient_norm": 0.42498770356178284,
        "train_loss": 2.960735321044922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26260,
        "tokens": 13767802880,
        "learning_rate": 8.473527451837641e-05,
        "gradient_norm": 0.38667747378349304,
        "train_loss": 3.0063889026641846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26261,
        "tokens": 13768327168,
        "learning_rate": 8.47232982831598e-05,
        "gradient_norm": 0.37347736954689026,
        "train_loss": 2.9767985343933105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26262,
        "tokens": 13768851456,
        "learning_rate": 8.471132480883827e-05,
        "gradient_norm": 0.374866783618927,
        "train_loss": 3.005155563354492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26263,
        "tokens": 13769375744,
        "learning_rate": 8.469935409554649e-05,
        "gradient_norm": 0.3867321312427521,
        "train_loss": 3.0141539573669434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26264,
        "tokens": 13769900032,
        "learning_rate": 8.468738614341931e-05,
        "gradient_norm": 0.3780810236930847,
        "train_loss": 2.9241902828216553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26265,
        "tokens": 13770424320,
        "learning_rate": 8.467542095259132e-05,
        "gradient_norm": 0.4050110876560211,
        "train_loss": 3.012848377227783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26266,
        "tokens": 13770948608,
        "learning_rate": 8.466345852319732e-05,
        "gradient_norm": 0.4094342589378357,
        "train_loss": 3.002054214477539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26267,
        "tokens": 13771472896,
        "learning_rate": 8.465149885537189e-05,
        "gradient_norm": 0.367337167263031,
        "train_loss": 3.0122649669647217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26268,
        "tokens": 13771997184,
        "learning_rate": 8.463954194924965e-05,
        "gradient_norm": 0.4393385052680969,
        "train_loss": 3.0361084938049316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26269,
        "tokens": 13772521472,
        "learning_rate": 8.462758780496527e-05,
        "gradient_norm": 0.41010141372680664,
        "train_loss": 2.973062038421631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26270,
        "tokens": 13773045760,
        "learning_rate": 8.46156364226532e-05,
        "gradient_norm": 0.4006088674068451,
        "train_loss": 2.987535238265991,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26271,
        "tokens": 13773570048,
        "learning_rate": 8.460368780244808e-05,
        "gradient_norm": 0.39585399627685547,
        "train_loss": 2.9538040161132812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26272,
        "tokens": 13774094336,
        "learning_rate": 8.459174194448429e-05,
        "gradient_norm": 0.44501036405563354,
        "train_loss": 3.003994941711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26273,
        "tokens": 13774618624,
        "learning_rate": 8.457979884889642e-05,
        "gradient_norm": 0.4357404112815857,
        "train_loss": 3.0050368309020996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26274,
        "tokens": 13775142912,
        "learning_rate": 8.456785851581878e-05,
        "gradient_norm": 0.44369804859161377,
        "train_loss": 2.96768856048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26275,
        "tokens": 13775667200,
        "learning_rate": 8.455592094538589e-05,
        "gradient_norm": 0.49650290608406067,
        "train_loss": 3.044956684112549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26276,
        "tokens": 13776191488,
        "learning_rate": 8.4543986137732e-05,
        "gradient_norm": 0.507655680179596,
        "train_loss": 2.9727251529693604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26277,
        "tokens": 13776715776,
        "learning_rate": 8.453205409299156e-05,
        "gradient_norm": 0.4803884029388428,
        "train_loss": 3.059450149536133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26278,
        "tokens": 13777240064,
        "learning_rate": 8.45201248112988e-05,
        "gradient_norm": 0.4426090717315674,
        "train_loss": 2.9918527603149414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26279,
        "tokens": 13777764352,
        "learning_rate": 8.450819829278807e-05,
        "gradient_norm": 0.4724529981613159,
        "train_loss": 2.9601430892944336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26280,
        "tokens": 13778288640,
        "learning_rate": 8.449627453759356e-05,
        "gradient_norm": 0.46518605947494507,
        "train_loss": 3.0470991134643555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26281,
        "tokens": 13778812928,
        "learning_rate": 8.448435354584954e-05,
        "gradient_norm": 0.42198309302330017,
        "train_loss": 3.0150504112243652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26282,
        "tokens": 13779337216,
        "learning_rate": 8.447243531769013e-05,
        "gradient_norm": 0.47416195273399353,
        "train_loss": 2.985105276107788,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26283,
        "tokens": 13779861504,
        "learning_rate": 8.446051985324953e-05,
        "gradient_norm": 0.44387662410736084,
        "train_loss": 2.9714086055755615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26284,
        "tokens": 13780385792,
        "learning_rate": 8.444860715266182e-05,
        "gradient_norm": 0.4240413308143616,
        "train_loss": 2.909010410308838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26285,
        "tokens": 13780910080,
        "learning_rate": 8.44366972160612e-05,
        "gradient_norm": 0.4016154110431671,
        "train_loss": 2.996307373046875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26286,
        "tokens": 13781434368,
        "learning_rate": 8.442479004358157e-05,
        "gradient_norm": 0.46981608867645264,
        "train_loss": 2.9216721057891846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26287,
        "tokens": 13781958656,
        "learning_rate": 8.441288563535712e-05,
        "gradient_norm": 0.44403907656669617,
        "train_loss": 2.9904775619506836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26288,
        "tokens": 13782482944,
        "learning_rate": 8.440098399152172e-05,
        "gradient_norm": 0.4009685516357422,
        "train_loss": 2.9901623725891113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26289,
        "tokens": 13783007232,
        "learning_rate": 8.438908511220944e-05,
        "gradient_norm": 0.4210880994796753,
        "train_loss": 3.015939235687256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26290,
        "tokens": 13783531520,
        "learning_rate": 8.43771889975541e-05,
        "gradient_norm": 0.3921178877353668,
        "train_loss": 2.9823575019836426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26291,
        "tokens": 13784055808,
        "learning_rate": 8.436529564768974e-05,
        "gradient_norm": 0.4133188724517822,
        "train_loss": 3.038964033126831,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26292,
        "tokens": 13784580096,
        "learning_rate": 8.435340506275012e-05,
        "gradient_norm": 0.3989528715610504,
        "train_loss": 3.040780544281006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26293,
        "tokens": 13785104384,
        "learning_rate": 8.434151724286918e-05,
        "gradient_norm": 0.4308573603630066,
        "train_loss": 2.939457893371582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26294,
        "tokens": 13785628672,
        "learning_rate": 8.432963218818066e-05,
        "gradient_norm": 0.4148843586444855,
        "train_loss": 3.0644097328186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26295,
        "tokens": 13786152960,
        "learning_rate": 8.431774989881837e-05,
        "gradient_norm": 0.38083383440971375,
        "train_loss": 3.080995798110962,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26296,
        "tokens": 13786677248,
        "learning_rate": 8.430587037491603e-05,
        "gradient_norm": 0.4113282263278961,
        "train_loss": 3.0314090251922607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26297,
        "tokens": 13787201536,
        "learning_rate": 8.429399361660738e-05,
        "gradient_norm": 0.44120410084724426,
        "train_loss": 2.971442699432373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26298,
        "tokens": 13787725824,
        "learning_rate": 8.428211962402618e-05,
        "gradient_norm": 0.4008139371871948,
        "train_loss": 3.022575855255127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26299,
        "tokens": 13788250112,
        "learning_rate": 8.427024839730596e-05,
        "gradient_norm": 0.4710656404495239,
        "train_loss": 3.0535080432891846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26300,
        "tokens": 13788774400,
        "learning_rate": 8.425837993658045e-05,
        "gradient_norm": 0.37481653690338135,
        "train_loss": 3.0610508918762207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26301,
        "tokens": 13789298688,
        "learning_rate": 8.424651424198312e-05,
        "gradient_norm": 0.4847239851951599,
        "train_loss": 3.103679656982422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26302,
        "tokens": 13789822976,
        "learning_rate": 8.423465131364772e-05,
        "gradient_norm": 0.45799797773361206,
        "train_loss": 3.0343918800354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26303,
        "tokens": 13790347264,
        "learning_rate": 8.422279115170759e-05,
        "gradient_norm": 0.4272083640098572,
        "train_loss": 3.0378637313842773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26304,
        "tokens": 13790871552,
        "learning_rate": 8.421093375629637e-05,
        "gradient_norm": 0.4583640992641449,
        "train_loss": 3.0021748542785645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26305,
        "tokens": 13791395840,
        "learning_rate": 8.419907912754742e-05,
        "gradient_norm": 0.41455134749412537,
        "train_loss": 3.0085501670837402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26306,
        "tokens": 13791920128,
        "learning_rate": 8.418722726559428e-05,
        "gradient_norm": 0.46736493706703186,
        "train_loss": 3.0005059242248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26307,
        "tokens": 13792444416,
        "learning_rate": 8.417537817057026e-05,
        "gradient_norm": 0.47593027353286743,
        "train_loss": 3.0614514350891113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26308,
        "tokens": 13792968704,
        "learning_rate": 8.41635318426088e-05,
        "gradient_norm": 0.4434455633163452,
        "train_loss": 3.024409532546997,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26309,
        "tokens": 13793492992,
        "learning_rate": 8.415168828184328e-05,
        "gradient_norm": 0.4474791884422302,
        "train_loss": 3.022956371307373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26310,
        "tokens": 13794017280,
        "learning_rate": 8.41398474884069e-05,
        "gradient_norm": 0.4698891043663025,
        "train_loss": 3.0644402503967285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26311,
        "tokens": 13794541568,
        "learning_rate": 8.41280094624331e-05,
        "gradient_norm": 0.3983200788497925,
        "train_loss": 2.9998607635498047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26312,
        "tokens": 13795065856,
        "learning_rate": 8.411617420405495e-05,
        "gradient_norm": 0.46433284878730774,
        "train_loss": 3.0067434310913086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26313,
        "tokens": 13795590144,
        "learning_rate": 8.410434171340584e-05,
        "gradient_norm": 0.3828771710395813,
        "train_loss": 2.966212511062622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26314,
        "tokens": 13796114432,
        "learning_rate": 8.40925119906188e-05,
        "gradient_norm": 0.44786831736564636,
        "train_loss": 2.9814300537109375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26315,
        "tokens": 13796638720,
        "learning_rate": 8.408068503582713e-05,
        "gradient_norm": 0.4596070945262909,
        "train_loss": 3.105370044708252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26316,
        "tokens": 13797163008,
        "learning_rate": 8.406886084916387e-05,
        "gradient_norm": 0.4385586678981781,
        "train_loss": 3.0133419036865234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26317,
        "tokens": 13797687296,
        "learning_rate": 8.405703943076211e-05,
        "gradient_norm": 0.4429176151752472,
        "train_loss": 3.022393226623535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26318,
        "tokens": 13798211584,
        "learning_rate": 8.4045220780755e-05,
        "gradient_norm": 0.5093629360198975,
        "train_loss": 3.1247549057006836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26319,
        "tokens": 13798735872,
        "learning_rate": 8.40334048992755e-05,
        "gradient_norm": 0.44730332493782043,
        "train_loss": 3.0376925468444824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26320,
        "tokens": 13799260160,
        "learning_rate": 8.402159178645669e-05,
        "gradient_norm": 0.5789135098457336,
        "train_loss": 3.0168120861053467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26321,
        "tokens": 13799784448,
        "learning_rate": 8.400978144243138e-05,
        "gradient_norm": 0.42128971219062805,
        "train_loss": 2.98825740814209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26322,
        "tokens": 13800308736,
        "learning_rate": 8.399797386733271e-05,
        "gradient_norm": 0.43542298674583435,
        "train_loss": 3.0032269954681396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26323,
        "tokens": 13800833024,
        "learning_rate": 8.398616906129343e-05,
        "gradient_norm": 0.3963404595851898,
        "train_loss": 3.0620150566101074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26324,
        "tokens": 13801357312,
        "learning_rate": 8.397436702444653e-05,
        "gradient_norm": 0.3820956349372864,
        "train_loss": 3.06785249710083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26325,
        "tokens": 13801881600,
        "learning_rate": 8.396256775692475e-05,
        "gradient_norm": 0.46847519278526306,
        "train_loss": 3.024569511413574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26326,
        "tokens": 13802405888,
        "learning_rate": 8.395077125886102e-05,
        "gradient_norm": 0.41794562339782715,
        "train_loss": 2.9712395668029785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26327,
        "tokens": 13802930176,
        "learning_rate": 8.393897753038802e-05,
        "gradient_norm": 0.4141707718372345,
        "train_loss": 2.9933114051818848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26328,
        "tokens": 13803454464,
        "learning_rate": 8.392718657163855e-05,
        "gradient_norm": 0.44324731826782227,
        "train_loss": 3.0009584426879883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26329,
        "tokens": 13803978752,
        "learning_rate": 8.391539838274538e-05,
        "gradient_norm": 0.4176427721977234,
        "train_loss": 3.050004482269287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26330,
        "tokens": 13804503040,
        "learning_rate": 8.390361296384112e-05,
        "gradient_norm": 0.3893578052520752,
        "train_loss": 2.976665496826172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26331,
        "tokens": 13805027328,
        "learning_rate": 8.389183031505852e-05,
        "gradient_norm": 0.42379313707351685,
        "train_loss": 3.0624847412109375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26332,
        "tokens": 13805551616,
        "learning_rate": 8.388005043653006e-05,
        "gradient_norm": 0.4399833083152771,
        "train_loss": 3.0511813163757324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26333,
        "tokens": 13806075904,
        "learning_rate": 8.38682733283885e-05,
        "gradient_norm": 0.38526007533073425,
        "train_loss": 2.986110210418701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26334,
        "tokens": 13806600192,
        "learning_rate": 8.38564989907663e-05,
        "gradient_norm": 0.4312315285205841,
        "train_loss": 2.9905943870544434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26335,
        "tokens": 13807124480,
        "learning_rate": 8.384472742379606e-05,
        "gradient_norm": 0.4450635313987732,
        "train_loss": 2.9469947814941406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26336,
        "tokens": 13807648768,
        "learning_rate": 8.38329586276102e-05,
        "gradient_norm": 0.40673863887786865,
        "train_loss": 3.0786404609680176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26337,
        "tokens": 13808173056,
        "learning_rate": 8.382119260234126e-05,
        "gradient_norm": 0.3990556299686432,
        "train_loss": 3.024134635925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26338,
        "tokens": 13808697344,
        "learning_rate": 8.380942934812171e-05,
        "gradient_norm": 0.5230458378791809,
        "train_loss": 2.9786064624786377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26339,
        "tokens": 13809221632,
        "learning_rate": 8.379766886508387e-05,
        "gradient_norm": 0.4194796085357666,
        "train_loss": 3.073883295059204,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26340,
        "tokens": 13809745920,
        "learning_rate": 8.378591115336021e-05,
        "gradient_norm": 0.49003806710243225,
        "train_loss": 2.9536173343658447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26341,
        "tokens": 13810270208,
        "learning_rate": 8.3774156213083e-05,
        "gradient_norm": 0.47392305731773376,
        "train_loss": 3.040377140045166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26342,
        "tokens": 13810794496,
        "learning_rate": 8.376240404438462e-05,
        "gradient_norm": 0.43651312589645386,
        "train_loss": 3.0478978157043457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26343,
        "tokens": 13811318784,
        "learning_rate": 8.375065464739728e-05,
        "gradient_norm": 0.39918938279151917,
        "train_loss": 3.0181000232696533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26344,
        "tokens": 13811843072,
        "learning_rate": 8.373890802225335e-05,
        "gradient_norm": 0.4260566234588623,
        "train_loss": 2.9926671981811523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26345,
        "tokens": 13812367360,
        "learning_rate": 8.372716416908494e-05,
        "gradient_norm": 0.45124468207359314,
        "train_loss": 3.012254238128662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26346,
        "tokens": 13812891648,
        "learning_rate": 8.37154230880243e-05,
        "gradient_norm": 0.40486735105514526,
        "train_loss": 2.9868547916412354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26347,
        "tokens": 13813415936,
        "learning_rate": 8.370368477920354e-05,
        "gradient_norm": 0.411773145198822,
        "train_loss": 3.082693576812744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26348,
        "tokens": 13813940224,
        "learning_rate": 8.369194924275482e-05,
        "gradient_norm": 0.4598846733570099,
        "train_loss": 3.094940185546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26349,
        "tokens": 13814464512,
        "learning_rate": 8.36802164788103e-05,
        "gradient_norm": 0.3954020142555237,
        "train_loss": 3.0379419326782227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26350,
        "tokens": 13814988800,
        "learning_rate": 8.366848648750192e-05,
        "gradient_norm": 0.37738683819770813,
        "train_loss": 3.020092487335205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26351,
        "tokens": 13815513088,
        "learning_rate": 8.365675926896184e-05,
        "gradient_norm": 0.4215031862258911,
        "train_loss": 2.9932608604431152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26352,
        "tokens": 13816037376,
        "learning_rate": 8.364503482332199e-05,
        "gradient_norm": 0.4187382459640503,
        "train_loss": 3.014984607696533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26353,
        "tokens": 13816561664,
        "learning_rate": 8.363331315071439e-05,
        "gradient_norm": 0.4528140127658844,
        "train_loss": 3.0265581607818604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26354,
        "tokens": 13817085952,
        "learning_rate": 8.36215942512709e-05,
        "gradient_norm": 0.4223802983760834,
        "train_loss": 2.9943625926971436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26355,
        "tokens": 13817610240,
        "learning_rate": 8.360987812512354e-05,
        "gradient_norm": 0.4492310583591461,
        "train_loss": 3.016589879989624,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26356,
        "tokens": 13818134528,
        "learning_rate": 8.359816477240408e-05,
        "gradient_norm": 0.45815572142601013,
        "train_loss": 2.960322856903076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26357,
        "tokens": 13818658816,
        "learning_rate": 8.358645419324443e-05,
        "gradient_norm": 0.4243304133415222,
        "train_loss": 3.0756993293762207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26358,
        "tokens": 13819183104,
        "learning_rate": 8.357474638777644e-05,
        "gradient_norm": 0.4189898669719696,
        "train_loss": 2.986363649368286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26359,
        "tokens": 13819707392,
        "learning_rate": 8.356304135613182e-05,
        "gradient_norm": 0.42887556552886963,
        "train_loss": 3.067443609237671,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26360,
        "tokens": 13820231680,
        "learning_rate": 8.35513390984424e-05,
        "gradient_norm": 0.47600919008255005,
        "train_loss": 2.994503974914551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26361,
        "tokens": 13820755968,
        "learning_rate": 8.353963961483983e-05,
        "gradient_norm": 0.39511638879776,
        "train_loss": 3.0376930236816406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26362,
        "tokens": 13821280256,
        "learning_rate": 8.352794290545588e-05,
        "gradient_norm": 0.4230480194091797,
        "train_loss": 3.002598762512207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26363,
        "tokens": 13821804544,
        "learning_rate": 8.351624897042214e-05,
        "gradient_norm": 0.4134984314441681,
        "train_loss": 3.035367965698242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26364,
        "tokens": 13822328832,
        "learning_rate": 8.350455780987027e-05,
        "gradient_norm": 0.40872931480407715,
        "train_loss": 3.0433449745178223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26365,
        "tokens": 13822853120,
        "learning_rate": 8.349286942393185e-05,
        "gradient_norm": 0.4227413535118103,
        "train_loss": 3.0568935871124268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26366,
        "tokens": 13823377408,
        "learning_rate": 8.348118381273849e-05,
        "gradient_norm": 0.43787020444869995,
        "train_loss": 3.0032315254211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26367,
        "tokens": 13823901696,
        "learning_rate": 8.346950097642167e-05,
        "gradient_norm": 0.4055112898349762,
        "train_loss": 3.0161776542663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26368,
        "tokens": 13824425984,
        "learning_rate": 8.345782091511293e-05,
        "gradient_norm": 0.42418208718299866,
        "train_loss": 3.0222935676574707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26369,
        "tokens": 13824950272,
        "learning_rate": 8.344614362894377e-05,
        "gradient_norm": 0.39410680532455444,
        "train_loss": 3.0300545692443848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26370,
        "tokens": 13825474560,
        "learning_rate": 8.343446911804556e-05,
        "gradient_norm": 0.39505359530448914,
        "train_loss": 3.0369362831115723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26371,
        "tokens": 13825998848,
        "learning_rate": 8.34227973825498e-05,
        "gradient_norm": 0.40574201941490173,
        "train_loss": 3.0428335666656494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26372,
        "tokens": 13826523136,
        "learning_rate": 8.341112842258778e-05,
        "gradient_norm": 0.3889943063259125,
        "train_loss": 3.007801055908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26373,
        "tokens": 13827047424,
        "learning_rate": 8.339946223829093e-05,
        "gradient_norm": 0.3932938277721405,
        "train_loss": 3.0073022842407227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26374,
        "tokens": 13827571712,
        "learning_rate": 8.338779882979049e-05,
        "gradient_norm": 0.40410006046295166,
        "train_loss": 2.997919797897339,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26375,
        "tokens": 13828096000,
        "learning_rate": 8.337613819721783e-05,
        "gradient_norm": 0.4084997773170471,
        "train_loss": 2.9677867889404297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26376,
        "tokens": 13828620288,
        "learning_rate": 8.33644803407041e-05,
        "gradient_norm": 0.37144237756729126,
        "train_loss": 3.021069049835205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26377,
        "tokens": 13829144576,
        "learning_rate": 8.335282526038058e-05,
        "gradient_norm": 0.39046868681907654,
        "train_loss": 3.0363786220550537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26378,
        "tokens": 13829668864,
        "learning_rate": 8.334117295637854e-05,
        "gradient_norm": 0.45199155807495117,
        "train_loss": 3.044856309890747,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26379,
        "tokens": 13830193152,
        "learning_rate": 8.332952342882898e-05,
        "gradient_norm": 0.456866592168808,
        "train_loss": 3.0373992919921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26380,
        "tokens": 13830717440,
        "learning_rate": 8.33178766778632e-05,
        "gradient_norm": 0.40306103229522705,
        "train_loss": 3.0761799812316895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26381,
        "tokens": 13831241728,
        "learning_rate": 8.330623270361216e-05,
        "gradient_norm": 0.4229659140110016,
        "train_loss": 3.031825065612793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26382,
        "tokens": 13831766016,
        "learning_rate": 8.329459150620702e-05,
        "gradient_norm": 0.43692272901535034,
        "train_loss": 3.023986577987671,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26383,
        "tokens": 13832290304,
        "learning_rate": 8.328295308577874e-05,
        "gradient_norm": 0.4091450870037079,
        "train_loss": 2.998366355895996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26384,
        "tokens": 13832814592,
        "learning_rate": 8.327131744245841e-05,
        "gradient_norm": 0.4256334602832794,
        "train_loss": 3.0636348724365234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26385,
        "tokens": 13833338880,
        "learning_rate": 8.32596845763769e-05,
        "gradient_norm": 0.4076801538467407,
        "train_loss": 2.9890635013580322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26386,
        "tokens": 13833863168,
        "learning_rate": 8.324805448766526e-05,
        "gradient_norm": 0.40846481919288635,
        "train_loss": 3.0262789726257324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26387,
        "tokens": 13834387456,
        "learning_rate": 8.323642717645431e-05,
        "gradient_norm": 0.44767823815345764,
        "train_loss": 3.0140388011932373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26388,
        "tokens": 13834911744,
        "learning_rate": 8.322480264287502e-05,
        "gradient_norm": 0.41449451446533203,
        "train_loss": 3.0613574981689453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26389,
        "tokens": 13835436032,
        "learning_rate": 8.321318088705813e-05,
        "gradient_norm": 0.3856227695941925,
        "train_loss": 2.9983272552490234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26390,
        "tokens": 13835960320,
        "learning_rate": 8.320156190913457e-05,
        "gradient_norm": 0.4797214865684509,
        "train_loss": 3.018733024597168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26391,
        "tokens": 13836484608,
        "learning_rate": 8.318994570923504e-05,
        "gradient_norm": 0.4068543016910553,
        "train_loss": 3.095508575439453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26392,
        "tokens": 13837008896,
        "learning_rate": 8.317833228749035e-05,
        "gradient_norm": 0.4418530762195587,
        "train_loss": 3.0300726890563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26393,
        "tokens": 13837533184,
        "learning_rate": 8.316672164403119e-05,
        "gradient_norm": 0.4529319405555725,
        "train_loss": 3.055386543273926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26394,
        "tokens": 13838057472,
        "learning_rate": 8.315511377898828e-05,
        "gradient_norm": 0.43418172001838684,
        "train_loss": 3.08689022064209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26395,
        "tokens": 13838581760,
        "learning_rate": 8.314350869249222e-05,
        "gradient_norm": 0.44979119300842285,
        "train_loss": 3.0388545989990234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26396,
        "tokens": 13839106048,
        "learning_rate": 8.313190638467376e-05,
        "gradient_norm": 0.40990006923675537,
        "train_loss": 2.995784044265747,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26397,
        "tokens": 13839630336,
        "learning_rate": 8.312030685566336e-05,
        "gradient_norm": 0.426231324672699,
        "train_loss": 3.069344997406006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26398,
        "tokens": 13840154624,
        "learning_rate": 8.310871010559167e-05,
        "gradient_norm": 0.42483842372894287,
        "train_loss": 3.0426180362701416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26399,
        "tokens": 13840678912,
        "learning_rate": 8.309711613458918e-05,
        "gradient_norm": 0.4261314570903778,
        "train_loss": 3.012256622314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26400,
        "tokens": 13841203200,
        "learning_rate": 8.308552494278647e-05,
        "gradient_norm": 0.4053385257720947,
        "train_loss": 3.0148797035217285,
        "val_loss": 2.9699597358703613,
        "hellaswag_acc": 0.2867954671382904,
        "hellaswag_acc_norm": 0.29904401302337646
    },
    {
        "step": 26401,
        "tokens": 13841727488,
        "learning_rate": 8.307393653031392e-05,
        "gradient_norm": 0.4090406000614166,
        "train_loss": 3.0087313652038574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26402,
        "tokens": 13842251776,
        "learning_rate": 8.306235089730206e-05,
        "gradient_norm": 0.47544750571250916,
        "train_loss": 2.998682975769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26403,
        "tokens": 13842776064,
        "learning_rate": 8.30507680438812e-05,
        "gradient_norm": 0.44796618819236755,
        "train_loss": 3.0258615016937256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26404,
        "tokens": 13843300352,
        "learning_rate": 8.303918797018182e-05,
        "gradient_norm": 0.37975817918777466,
        "train_loss": 3.0265884399414062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26405,
        "tokens": 13843824640,
        "learning_rate": 8.30276106763342e-05,
        "gradient_norm": 0.46440932154655457,
        "train_loss": 3.0177993774414062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26406,
        "tokens": 13844348928,
        "learning_rate": 8.301603616246872e-05,
        "gradient_norm": 0.42683058977127075,
        "train_loss": 2.9892778396606445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26407,
        "tokens": 13844873216,
        "learning_rate": 8.300446442871556e-05,
        "gradient_norm": 0.4469089210033417,
        "train_loss": 2.990741729736328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26408,
        "tokens": 13845397504,
        "learning_rate": 8.299289547520505e-05,
        "gradient_norm": 0.470920592546463,
        "train_loss": 2.993867874145508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26409,
        "tokens": 13845921792,
        "learning_rate": 8.298132930206745e-05,
        "gradient_norm": 0.4409998059272766,
        "train_loss": 2.9687893390655518,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26410,
        "tokens": 13846446080,
        "learning_rate": 8.296976590943287e-05,
        "gradient_norm": 0.4210543930530548,
        "train_loss": 2.9560747146606445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26411,
        "tokens": 13846970368,
        "learning_rate": 8.295820529743156e-05,
        "gradient_norm": 0.4903559982776642,
        "train_loss": 3.088407039642334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26412,
        "tokens": 13847494656,
        "learning_rate": 8.294664746619351e-05,
        "gradient_norm": 0.43440935015678406,
        "train_loss": 2.98852276802063,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26413,
        "tokens": 13848018944,
        "learning_rate": 8.293509241584899e-05,
        "gradient_norm": 0.42830631136894226,
        "train_loss": 3.0498647689819336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26414,
        "tokens": 13848543232,
        "learning_rate": 8.292354014652792e-05,
        "gradient_norm": 0.41874098777770996,
        "train_loss": 3.0461363792419434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26415,
        "tokens": 13849067520,
        "learning_rate": 8.291199065836043e-05,
        "gradient_norm": 0.43247562646865845,
        "train_loss": 3.0244219303131104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26416,
        "tokens": 13849591808,
        "learning_rate": 8.290044395147646e-05,
        "gradient_norm": 0.44886910915374756,
        "train_loss": 2.986837863922119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26417,
        "tokens": 13850116096,
        "learning_rate": 8.288890002600599e-05,
        "gradient_norm": 0.4196963310241699,
        "train_loss": 3.029029369354248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26418,
        "tokens": 13850640384,
        "learning_rate": 8.287735888207904e-05,
        "gradient_norm": 0.5009365677833557,
        "train_loss": 3.093824625015259,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26419,
        "tokens": 13851164672,
        "learning_rate": 8.286582051982544e-05,
        "gradient_norm": 0.47883716225624084,
        "train_loss": 3.001941204071045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26420,
        "tokens": 13851688960,
        "learning_rate": 8.285428493937512e-05,
        "gradient_norm": 0.4216841757297516,
        "train_loss": 3.0179247856140137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26421,
        "tokens": 13852213248,
        "learning_rate": 8.284275214085782e-05,
        "gradient_norm": 0.47010865807533264,
        "train_loss": 3.0451550483703613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26422,
        "tokens": 13852737536,
        "learning_rate": 8.283122212440351e-05,
        "gradient_norm": 0.42746973037719727,
        "train_loss": 2.990792751312256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26423,
        "tokens": 13853261824,
        "learning_rate": 8.281969489014184e-05,
        "gradient_norm": 0.39379802346229553,
        "train_loss": 3.0183606147766113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26424,
        "tokens": 13853786112,
        "learning_rate": 8.280817043820269e-05,
        "gradient_norm": 0.45743006467819214,
        "train_loss": 3.044234275817871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26425,
        "tokens": 13854310400,
        "learning_rate": 8.279664876871567e-05,
        "gradient_norm": 0.419307142496109,
        "train_loss": 3.05145263671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26426,
        "tokens": 13854834688,
        "learning_rate": 8.278512988181055e-05,
        "gradient_norm": 0.43266454339027405,
        "train_loss": 3.0275826454162598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26427,
        "tokens": 13855358976,
        "learning_rate": 8.277361377761687e-05,
        "gradient_norm": 0.43026959896087646,
        "train_loss": 3.0534629821777344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26428,
        "tokens": 13855883264,
        "learning_rate": 8.27621004562644e-05,
        "gradient_norm": 0.4878700077533722,
        "train_loss": 3.0724844932556152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26429,
        "tokens": 13856407552,
        "learning_rate": 8.27505899178827e-05,
        "gradient_norm": 0.49371659755706787,
        "train_loss": 2.9721546173095703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26430,
        "tokens": 13856931840,
        "learning_rate": 8.273908216260126e-05,
        "gradient_norm": 0.4325968325138092,
        "train_loss": 2.985938549041748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26431,
        "tokens": 13857456128,
        "learning_rate": 8.272757719054972e-05,
        "gradient_norm": 0.4751327931880951,
        "train_loss": 3.060603380203247,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26432,
        "tokens": 13857980416,
        "learning_rate": 8.271607500185749e-05,
        "gradient_norm": 0.4617956578731537,
        "train_loss": 2.966322898864746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26433,
        "tokens": 13858504704,
        "learning_rate": 8.270457559665415e-05,
        "gradient_norm": 0.45825648307800293,
        "train_loss": 3.040731906890869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26434,
        "tokens": 13859028992,
        "learning_rate": 8.269307897506901e-05,
        "gradient_norm": 0.47647106647491455,
        "train_loss": 2.940276622772217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26435,
        "tokens": 13859553280,
        "learning_rate": 8.268158513723159e-05,
        "gradient_norm": 0.48067644238471985,
        "train_loss": 3.04708194732666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26436,
        "tokens": 13860077568,
        "learning_rate": 8.267009408327116e-05,
        "gradient_norm": 0.42234286665916443,
        "train_loss": 3.050992488861084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26437,
        "tokens": 13860601856,
        "learning_rate": 8.265860581331713e-05,
        "gradient_norm": 0.4147994816303253,
        "train_loss": 3.0123519897460938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26438,
        "tokens": 13861126144,
        "learning_rate": 8.26471203274989e-05,
        "gradient_norm": 0.44305500388145447,
        "train_loss": 3.045358896255493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26439,
        "tokens": 13861650432,
        "learning_rate": 8.263563762594557e-05,
        "gradient_norm": 0.42077183723449707,
        "train_loss": 3.012141466140747,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26440,
        "tokens": 13862174720,
        "learning_rate": 8.262415770878656e-05,
        "gradient_norm": 0.4438830614089966,
        "train_loss": 2.9786429405212402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26441,
        "tokens": 13862699008,
        "learning_rate": 8.261268057615094e-05,
        "gradient_norm": 0.3987043797969818,
        "train_loss": 2.9598488807678223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26442,
        "tokens": 13863223296,
        "learning_rate": 8.260120622816802e-05,
        "gradient_norm": 0.4002806544303894,
        "train_loss": 3.009279727935791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26443,
        "tokens": 13863747584,
        "learning_rate": 8.258973466496691e-05,
        "gradient_norm": 0.43560904264450073,
        "train_loss": 3.0200161933898926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26444,
        "tokens": 13864271872,
        "learning_rate": 8.257826588667677e-05,
        "gradient_norm": 0.4775985777378082,
        "train_loss": 3.148688316345215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26445,
        "tokens": 13864796160,
        "learning_rate": 8.25667998934266e-05,
        "gradient_norm": 0.4130268096923828,
        "train_loss": 3.0029542446136475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26446,
        "tokens": 13865320448,
        "learning_rate": 8.25553366853456e-05,
        "gradient_norm": 0.41668447852134705,
        "train_loss": 3.027519702911377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26447,
        "tokens": 13865844736,
        "learning_rate": 8.254387626256269e-05,
        "gradient_norm": 0.46489858627319336,
        "train_loss": 2.993198871612549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26448,
        "tokens": 13866369024,
        "learning_rate": 8.253241862520688e-05,
        "gradient_norm": 0.43468379974365234,
        "train_loss": 2.975417137145996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26449,
        "tokens": 13866893312,
        "learning_rate": 8.252096377340723e-05,
        "gradient_norm": 0.4299575388431549,
        "train_loss": 3.0150985717773438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26450,
        "tokens": 13867417600,
        "learning_rate": 8.25095117072926e-05,
        "gradient_norm": 0.4120805263519287,
        "train_loss": 2.9759292602539062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26451,
        "tokens": 13867941888,
        "learning_rate": 8.2498062426992e-05,
        "gradient_norm": 0.39005789160728455,
        "train_loss": 3.0259785652160645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26452,
        "tokens": 13868466176,
        "learning_rate": 8.248661593263412e-05,
        "gradient_norm": 0.43861883878707886,
        "train_loss": 3.0920422077178955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26453,
        "tokens": 13868990464,
        "learning_rate": 8.2475172224348e-05,
        "gradient_norm": 0.39329832792282104,
        "train_loss": 2.9950740337371826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26454,
        "tokens": 13869514752,
        "learning_rate": 8.246373130226228e-05,
        "gradient_norm": 0.4408256709575653,
        "train_loss": 2.974102020263672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26455,
        "tokens": 13870039040,
        "learning_rate": 8.245229316650587e-05,
        "gradient_norm": 0.42433929443359375,
        "train_loss": 3.001166343688965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26456,
        "tokens": 13870563328,
        "learning_rate": 8.244085781720746e-05,
        "gradient_norm": 0.39640629291534424,
        "train_loss": 2.9681286811828613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26457,
        "tokens": 13871087616,
        "learning_rate": 8.242942525449578e-05,
        "gradient_norm": 0.40506160259246826,
        "train_loss": 3.0385353565216064,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26458,
        "tokens": 13871611904,
        "learning_rate": 8.241799547849957e-05,
        "gradient_norm": 0.40683239698410034,
        "train_loss": 3.0196924209594727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26459,
        "tokens": 13872136192,
        "learning_rate": 8.240656848934738e-05,
        "gradient_norm": 0.4069068133831024,
        "train_loss": 2.983949899673462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26460,
        "tokens": 13872660480,
        "learning_rate": 8.239514428716793e-05,
        "gradient_norm": 0.4004349112510681,
        "train_loss": 3.0525407791137695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26461,
        "tokens": 13873184768,
        "learning_rate": 8.238372287208977e-05,
        "gradient_norm": 0.44810494780540466,
        "train_loss": 3.075812339782715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26462,
        "tokens": 13873709056,
        "learning_rate": 8.237230424424148e-05,
        "gradient_norm": 0.42529332637786865,
        "train_loss": 3.0232791900634766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26463,
        "tokens": 13874233344,
        "learning_rate": 8.236088840375157e-05,
        "gradient_norm": 0.3985349237918854,
        "train_loss": 3.0544447898864746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26464,
        "tokens": 13874757632,
        "learning_rate": 8.234947535074857e-05,
        "gradient_norm": 0.41612547636032104,
        "train_loss": 3.00944447517395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26465,
        "tokens": 13875281920,
        "learning_rate": 8.233806508536088e-05,
        "gradient_norm": 0.43111130595207214,
        "train_loss": 3.0286080837249756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26466,
        "tokens": 13875806208,
        "learning_rate": 8.232665760771706e-05,
        "gradient_norm": 0.43700331449508667,
        "train_loss": 3.007449150085449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26467,
        "tokens": 13876330496,
        "learning_rate": 8.23152529179454e-05,
        "gradient_norm": 0.4399387240409851,
        "train_loss": 3.0206120014190674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26468,
        "tokens": 13876854784,
        "learning_rate": 8.230385101617428e-05,
        "gradient_norm": 0.40802037715911865,
        "train_loss": 3.0503714084625244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26469,
        "tokens": 13877379072,
        "learning_rate": 8.229245190253216e-05,
        "gradient_norm": 0.47115853428840637,
        "train_loss": 3.028778076171875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26470,
        "tokens": 13877903360,
        "learning_rate": 8.228105557714721e-05,
        "gradient_norm": 0.4850626587867737,
        "train_loss": 3.0458176136016846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26471,
        "tokens": 13878427648,
        "learning_rate": 8.226966204014781e-05,
        "gradient_norm": 0.39459022879600525,
        "train_loss": 2.996697425842285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26472,
        "tokens": 13878951936,
        "learning_rate": 8.22582712916621e-05,
        "gradient_norm": 0.49882248044013977,
        "train_loss": 2.992246627807617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26473,
        "tokens": 13879476224,
        "learning_rate": 8.224688333181846e-05,
        "gradient_norm": 0.4095073938369751,
        "train_loss": 3.043464183807373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26474,
        "tokens": 13880000512,
        "learning_rate": 8.223549816074487e-05,
        "gradient_norm": 0.4197902977466583,
        "train_loss": 3.0361275672912598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26475,
        "tokens": 13880524800,
        "learning_rate": 8.22241157785697e-05,
        "gradient_norm": 0.4211815893650055,
        "train_loss": 2.9897024631500244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26476,
        "tokens": 13881049088,
        "learning_rate": 8.22127361854209e-05,
        "gradient_norm": 0.41804051399230957,
        "train_loss": 3.008686065673828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26477,
        "tokens": 13881573376,
        "learning_rate": 8.220135938142664e-05,
        "gradient_norm": 0.4082190692424774,
        "train_loss": 2.9915528297424316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26478,
        "tokens": 13882097664,
        "learning_rate": 8.218998536671499e-05,
        "gradient_norm": 0.46507737040519714,
        "train_loss": 3.091827869415283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26479,
        "tokens": 13882621952,
        "learning_rate": 8.217861414141394e-05,
        "gradient_norm": 0.45278045535087585,
        "train_loss": 3.0753860473632812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26480,
        "tokens": 13883146240,
        "learning_rate": 8.216724570565155e-05,
        "gradient_norm": 0.38478729128837585,
        "train_loss": 3.008509874343872,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26481,
        "tokens": 13883670528,
        "learning_rate": 8.215588005955565e-05,
        "gradient_norm": 0.4388459026813507,
        "train_loss": 3.0732340812683105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26482,
        "tokens": 13884194816,
        "learning_rate": 8.214451720325438e-05,
        "gradient_norm": 0.4414903223514557,
        "train_loss": 3.001305103302002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26483,
        "tokens": 13884719104,
        "learning_rate": 8.213315713687543e-05,
        "gradient_norm": 0.4353099763393402,
        "train_loss": 3.075167179107666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26484,
        "tokens": 13885243392,
        "learning_rate": 8.212179986054682e-05,
        "gradient_norm": 0.5053356289863586,
        "train_loss": 3.0044593811035156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26485,
        "tokens": 13885767680,
        "learning_rate": 8.211044537439631e-05,
        "gradient_norm": 0.3989584445953369,
        "train_loss": 2.954683780670166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26486,
        "tokens": 13886291968,
        "learning_rate": 8.20990936785518e-05,
        "gradient_norm": 0.4358516335487366,
        "train_loss": 3.0064947605133057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26487,
        "tokens": 13886816256,
        "learning_rate": 8.208774477314093e-05,
        "gradient_norm": 0.42094096541404724,
        "train_loss": 3.02058744430542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26488,
        "tokens": 13887340544,
        "learning_rate": 8.207639865829159e-05,
        "gradient_norm": 0.4147021770477295,
        "train_loss": 3.0001771450042725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26489,
        "tokens": 13887864832,
        "learning_rate": 8.206505533413138e-05,
        "gradient_norm": 0.4211888611316681,
        "train_loss": 3.0558648109436035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26490,
        "tokens": 13888389120,
        "learning_rate": 8.205371480078808e-05,
        "gradient_norm": 0.44304996728897095,
        "train_loss": 3.019404888153076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26491,
        "tokens": 13888913408,
        "learning_rate": 8.204237705838923e-05,
        "gradient_norm": 0.39582228660583496,
        "train_loss": 2.991422414779663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26492,
        "tokens": 13889437696,
        "learning_rate": 8.203104210706259e-05,
        "gradient_norm": 0.4131189286708832,
        "train_loss": 3.002058982849121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26493,
        "tokens": 13889961984,
        "learning_rate": 8.201970994693559e-05,
        "gradient_norm": 0.4073899984359741,
        "train_loss": 2.995516300201416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26494,
        "tokens": 13890486272,
        "learning_rate": 8.200838057813593e-05,
        "gradient_norm": 0.3994574546813965,
        "train_loss": 3.0313572883605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26495,
        "tokens": 13891010560,
        "learning_rate": 8.199705400079104e-05,
        "gradient_norm": 0.38353368639945984,
        "train_loss": 3.0469205379486084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26496,
        "tokens": 13891534848,
        "learning_rate": 8.198573021502851e-05,
        "gradient_norm": 0.4765823781490326,
        "train_loss": 2.966773748397827,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26497,
        "tokens": 13892059136,
        "learning_rate": 8.197440922097568e-05,
        "gradient_norm": 0.4038516879081726,
        "train_loss": 3.0356526374816895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26498,
        "tokens": 13892583424,
        "learning_rate": 8.196309101876008e-05,
        "gradient_norm": 0.39653876423835754,
        "train_loss": 3.058619976043701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26499,
        "tokens": 13893107712,
        "learning_rate": 8.195177560850905e-05,
        "gradient_norm": 0.44666650891304016,
        "train_loss": 3.0388715267181396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26500,
        "tokens": 13893632000,
        "learning_rate": 8.194046299035002e-05,
        "gradient_norm": 0.4415660798549652,
        "train_loss": 3.0355677604675293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26501,
        "tokens": 13894156288,
        "learning_rate": 8.192915316441025e-05,
        "gradient_norm": 0.4354044198989868,
        "train_loss": 2.973026990890503,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26502,
        "tokens": 13894680576,
        "learning_rate": 8.191784613081711e-05,
        "gradient_norm": 0.4285907745361328,
        "train_loss": 3.041188955307007,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26503,
        "tokens": 13895204864,
        "learning_rate": 8.190654188969787e-05,
        "gradient_norm": 0.4243208169937134,
        "train_loss": 3.0470008850097656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26504,
        "tokens": 13895729152,
        "learning_rate": 8.189524044117976e-05,
        "gradient_norm": 0.4079597592353821,
        "train_loss": 3.03079891204834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26505,
        "tokens": 13896253440,
        "learning_rate": 8.188394178538995e-05,
        "gradient_norm": 0.4693424701690674,
        "train_loss": 3.013303756713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26506,
        "tokens": 13896777728,
        "learning_rate": 8.187264592245572e-05,
        "gradient_norm": 0.3914794623851776,
        "train_loss": 2.9695210456848145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26507,
        "tokens": 13897302016,
        "learning_rate": 8.186135285250409e-05,
        "gradient_norm": 0.4282265901565552,
        "train_loss": 3.0480148792266846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26508,
        "tokens": 13897826304,
        "learning_rate": 8.185006257566225e-05,
        "gradient_norm": 0.46156254410743713,
        "train_loss": 3.0402464866638184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26509,
        "tokens": 13898350592,
        "learning_rate": 8.183877509205733e-05,
        "gradient_norm": 0.3656103312969208,
        "train_loss": 3.0475034713745117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26510,
        "tokens": 13898874880,
        "learning_rate": 8.182749040181632e-05,
        "gradient_norm": 0.49168816208839417,
        "train_loss": 3.0718116760253906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26511,
        "tokens": 13899399168,
        "learning_rate": 8.181620850506628e-05,
        "gradient_norm": 0.42655396461486816,
        "train_loss": 3.065023183822632,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26512,
        "tokens": 13899923456,
        "learning_rate": 8.180492940193412e-05,
        "gradient_norm": 0.44088831543922424,
        "train_loss": 3.0844345092773438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26513,
        "tokens": 13900447744,
        "learning_rate": 8.179365309254696e-05,
        "gradient_norm": 0.4507313370704651,
        "train_loss": 3.079810380935669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26514,
        "tokens": 13900972032,
        "learning_rate": 8.178237957703153e-05,
        "gradient_norm": 0.39705920219421387,
        "train_loss": 2.9980063438415527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26515,
        "tokens": 13901496320,
        "learning_rate": 8.177110885551491e-05,
        "gradient_norm": 0.4283248782157898,
        "train_loss": 2.987499475479126,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26516,
        "tokens": 13902020608,
        "learning_rate": 8.175984092812384e-05,
        "gradient_norm": 0.4066835641860962,
        "train_loss": 3.0346884727478027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26517,
        "tokens": 13902544896,
        "learning_rate": 8.17485757949852e-05,
        "gradient_norm": 0.42563408613204956,
        "train_loss": 3.072782516479492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26518,
        "tokens": 13903069184,
        "learning_rate": 8.173731345622583e-05,
        "gradient_norm": 0.41112765669822693,
        "train_loss": 2.9717812538146973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26519,
        "tokens": 13903593472,
        "learning_rate": 8.172605391197242e-05,
        "gradient_norm": 0.4054463505744934,
        "train_loss": 2.9699926376342773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26520,
        "tokens": 13904117760,
        "learning_rate": 8.171479716235179e-05,
        "gradient_norm": 0.41033318638801575,
        "train_loss": 2.9749703407287598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26521,
        "tokens": 13904642048,
        "learning_rate": 8.170354320749057e-05,
        "gradient_norm": 0.41525235772132874,
        "train_loss": 3.043426513671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26522,
        "tokens": 13905166336,
        "learning_rate": 8.169229204751551e-05,
        "gradient_norm": 0.4797149896621704,
        "train_loss": 2.9862117767333984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26523,
        "tokens": 13905690624,
        "learning_rate": 8.168104368255323e-05,
        "gradient_norm": 0.4233390688896179,
        "train_loss": 3.032721519470215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26524,
        "tokens": 13906214912,
        "learning_rate": 8.166979811273034e-05,
        "gradient_norm": 0.42142242193222046,
        "train_loss": 2.9873247146606445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26525,
        "tokens": 13906739200,
        "learning_rate": 8.16585553381734e-05,
        "gradient_norm": 0.4377283453941345,
        "train_loss": 2.9963479042053223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26526,
        "tokens": 13907263488,
        "learning_rate": 8.164731535900905e-05,
        "gradient_norm": 0.44313615560531616,
        "train_loss": 3.0269932746887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26527,
        "tokens": 13907787776,
        "learning_rate": 8.163607817536367e-05,
        "gradient_norm": 0.47654399275779724,
        "train_loss": 3.0377891063690186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26528,
        "tokens": 13908312064,
        "learning_rate": 8.162484378736384e-05,
        "gradient_norm": 0.4639336168766022,
        "train_loss": 2.9939093589782715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26529,
        "tokens": 13908836352,
        "learning_rate": 8.161361219513602e-05,
        "gradient_norm": 0.41125860810279846,
        "train_loss": 2.9832205772399902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26530,
        "tokens": 13909360640,
        "learning_rate": 8.16023833988066e-05,
        "gradient_norm": 0.4814595878124237,
        "train_loss": 3.1462550163269043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26531,
        "tokens": 13909884928,
        "learning_rate": 8.159115739850203e-05,
        "gradient_norm": 0.4402320981025696,
        "train_loss": 3.000136137008667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26532,
        "tokens": 13910409216,
        "learning_rate": 8.157993419434857e-05,
        "gradient_norm": 0.41739386320114136,
        "train_loss": 2.9889769554138184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26533,
        "tokens": 13910933504,
        "learning_rate": 8.156871378647268e-05,
        "gradient_norm": 0.41436558961868286,
        "train_loss": 3.0188074111938477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26534,
        "tokens": 13911457792,
        "learning_rate": 8.155749617500056e-05,
        "gradient_norm": 0.4642868936061859,
        "train_loss": 3.024484395980835,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26535,
        "tokens": 13911982080,
        "learning_rate": 8.154628136005855e-05,
        "gradient_norm": 0.4345904290676117,
        "train_loss": 3.0108590126037598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26536,
        "tokens": 13912506368,
        "learning_rate": 8.153506934177276e-05,
        "gradient_norm": 0.426768034696579,
        "train_loss": 2.9930529594421387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26537,
        "tokens": 13913030656,
        "learning_rate": 8.152386012026954e-05,
        "gradient_norm": 0.42008379101753235,
        "train_loss": 2.9515066146850586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26538,
        "tokens": 13913554944,
        "learning_rate": 8.151265369567504e-05,
        "gradient_norm": 0.48061153292655945,
        "train_loss": 3.0210366249084473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26539,
        "tokens": 13914079232,
        "learning_rate": 8.150145006811532e-05,
        "gradient_norm": 0.40373289585113525,
        "train_loss": 2.971865653991699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26540,
        "tokens": 13914603520,
        "learning_rate": 8.149024923771659e-05,
        "gradient_norm": 0.42219579219818115,
        "train_loss": 2.9906253814697266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26541,
        "tokens": 13915127808,
        "learning_rate": 8.14790512046048e-05,
        "gradient_norm": 0.4451334476470947,
        "train_loss": 3.017322540283203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26542,
        "tokens": 13915652096,
        "learning_rate": 8.146785596890617e-05,
        "gradient_norm": 0.46871986985206604,
        "train_loss": 2.978964328765869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26543,
        "tokens": 13916176384,
        "learning_rate": 8.145666353074656e-05,
        "gradient_norm": 0.4538569748401642,
        "train_loss": 3.0509862899780273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26544,
        "tokens": 13916700672,
        "learning_rate": 8.144547389025205e-05,
        "gradient_norm": 0.41912397742271423,
        "train_loss": 2.913588523864746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26545,
        "tokens": 13917224960,
        "learning_rate": 8.143428704754854e-05,
        "gradient_norm": 0.4386776387691498,
        "train_loss": 3.041773796081543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26546,
        "tokens": 13917749248,
        "learning_rate": 8.142310300276202e-05,
        "gradient_norm": 0.4428853392601013,
        "train_loss": 3.0194976329803467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26547,
        "tokens": 13918273536,
        "learning_rate": 8.141192175601826e-05,
        "gradient_norm": 0.40499284863471985,
        "train_loss": 3.0156772136688232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26548,
        "tokens": 13918797824,
        "learning_rate": 8.140074330744324e-05,
        "gradient_norm": 0.4488081634044647,
        "train_loss": 3.0503413677215576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26549,
        "tokens": 13919322112,
        "learning_rate": 8.138956765716275e-05,
        "gradient_norm": 0.43958041071891785,
        "train_loss": 3.015378952026367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26550,
        "tokens": 13919846400,
        "learning_rate": 8.137839480530254e-05,
        "gradient_norm": 0.3753739893436432,
        "train_loss": 2.9802231788635254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26551,
        "tokens": 13920370688,
        "learning_rate": 8.136722475198849e-05,
        "gradient_norm": 0.43525171279907227,
        "train_loss": 3.0283098220825195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26552,
        "tokens": 13920894976,
        "learning_rate": 8.135605749734616e-05,
        "gradient_norm": 0.4242008924484253,
        "train_loss": 2.9606618881225586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26553,
        "tokens": 13921419264,
        "learning_rate": 8.134489304150142e-05,
        "gradient_norm": 0.41315096616744995,
        "train_loss": 3.0196340084075928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26554,
        "tokens": 13921943552,
        "learning_rate": 8.133373138457979e-05,
        "gradient_norm": 0.43281853199005127,
        "train_loss": 3.0202479362487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26555,
        "tokens": 13922467840,
        "learning_rate": 8.132257252670708e-05,
        "gradient_norm": 0.43214112520217896,
        "train_loss": 2.941223621368408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26556,
        "tokens": 13922992128,
        "learning_rate": 8.131141646800871e-05,
        "gradient_norm": 0.41205254197120667,
        "train_loss": 2.9943220615386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26557,
        "tokens": 13923516416,
        "learning_rate": 8.130026320861035e-05,
        "gradient_norm": 0.39823275804519653,
        "train_loss": 3.017916679382324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26558,
        "tokens": 13924040704,
        "learning_rate": 8.12891127486376e-05,
        "gradient_norm": 0.5540871620178223,
        "train_loss": 3.0947821140289307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26559,
        "tokens": 13924564992,
        "learning_rate": 8.127796508821587e-05,
        "gradient_norm": 0.5679736733436584,
        "train_loss": 2.9635746479034424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26560,
        "tokens": 13925089280,
        "learning_rate": 8.126682022747072e-05,
        "gradient_norm": 0.5346247553825378,
        "train_loss": 2.9996070861816406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26561,
        "tokens": 13925613568,
        "learning_rate": 8.125567816652751e-05,
        "gradient_norm": 0.43098685145378113,
        "train_loss": 2.9640681743621826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26562,
        "tokens": 13926137856,
        "learning_rate": 8.124453890551178e-05,
        "gradient_norm": 0.4617134928703308,
        "train_loss": 3.033607006072998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26563,
        "tokens": 13926662144,
        "learning_rate": 8.12334024445488e-05,
        "gradient_norm": 0.5412704348564148,
        "train_loss": 3.0477135181427,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26564,
        "tokens": 13927186432,
        "learning_rate": 8.122226878376398e-05,
        "gradient_norm": 0.47550562024116516,
        "train_loss": 2.9986119270324707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26565,
        "tokens": 13927710720,
        "learning_rate": 8.121113792328261e-05,
        "gradient_norm": 0.4311259686946869,
        "train_loss": 2.989351749420166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26566,
        "tokens": 13928235008,
        "learning_rate": 8.120000986323007e-05,
        "gradient_norm": 0.4423099756240845,
        "train_loss": 3.008852958679199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26567,
        "tokens": 13928759296,
        "learning_rate": 8.11888846037315e-05,
        "gradient_norm": 0.43595972657203674,
        "train_loss": 3.052790641784668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26568,
        "tokens": 13929283584,
        "learning_rate": 8.117776214491216e-05,
        "gradient_norm": 0.38274675607681274,
        "train_loss": 3.0698418617248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26569,
        "tokens": 13929807872,
        "learning_rate": 8.116664248689736e-05,
        "gradient_norm": 0.4220424294471741,
        "train_loss": 3.0386414527893066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26570,
        "tokens": 13930332160,
        "learning_rate": 8.11555256298121e-05,
        "gradient_norm": 0.441301554441452,
        "train_loss": 3.0384740829467773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26571,
        "tokens": 13930856448,
        "learning_rate": 8.114441157378164e-05,
        "gradient_norm": 0.4005579352378845,
        "train_loss": 2.9722321033477783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26572,
        "tokens": 13931380736,
        "learning_rate": 8.1133300318931e-05,
        "gradient_norm": 0.3727891743183136,
        "train_loss": 2.981569528579712,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26573,
        "tokens": 13931905024,
        "learning_rate": 8.112219186538533e-05,
        "gradient_norm": 0.45553892850875854,
        "train_loss": 2.9811110496520996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26574,
        "tokens": 13932429312,
        "learning_rate": 8.111108621326959e-05,
        "gradient_norm": 0.402940034866333,
        "train_loss": 3.041512966156006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26575,
        "tokens": 13932953600,
        "learning_rate": 8.109998336270885e-05,
        "gradient_norm": 0.4402298033237457,
        "train_loss": 3.018113613128662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26576,
        "tokens": 13933477888,
        "learning_rate": 8.108888331382801e-05,
        "gradient_norm": 0.40589314699172974,
        "train_loss": 3.0015339851379395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26577,
        "tokens": 13934002176,
        "learning_rate": 8.107778606675206e-05,
        "gradient_norm": 0.3816702365875244,
        "train_loss": 3.0265183448791504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26578,
        "tokens": 13934526464,
        "learning_rate": 8.106669162160599e-05,
        "gradient_norm": 0.43314439058303833,
        "train_loss": 3.034029483795166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26579,
        "tokens": 13935050752,
        "learning_rate": 8.105559997851455e-05,
        "gradient_norm": 0.42661720514297485,
        "train_loss": 3.0182290077209473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26580,
        "tokens": 13935575040,
        "learning_rate": 8.104451113760268e-05,
        "gradient_norm": 0.3846484422683716,
        "train_loss": 3.0183093547821045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26581,
        "tokens": 13936099328,
        "learning_rate": 8.103342509899514e-05,
        "gradient_norm": 0.4155287742614746,
        "train_loss": 3.001314163208008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26582,
        "tokens": 13936623616,
        "learning_rate": 8.102234186281678e-05,
        "gradient_norm": 0.4058823883533478,
        "train_loss": 3.0038375854492188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26583,
        "tokens": 13937147904,
        "learning_rate": 8.10112614291923e-05,
        "gradient_norm": 0.3978433907032013,
        "train_loss": 2.9951114654541016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26584,
        "tokens": 13937672192,
        "learning_rate": 8.100018379824648e-05,
        "gradient_norm": 0.43254002928733826,
        "train_loss": 3.0067033767700195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26585,
        "tokens": 13938196480,
        "learning_rate": 8.098910897010392e-05,
        "gradient_norm": 0.5135152339935303,
        "train_loss": 3.0210494995117188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26586,
        "tokens": 13938720768,
        "learning_rate": 8.097803694488934e-05,
        "gradient_norm": 0.4124474823474884,
        "train_loss": 2.9572196006774902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26587,
        "tokens": 13939245056,
        "learning_rate": 8.096696772272743e-05,
        "gradient_norm": 0.42513906955718994,
        "train_loss": 3.054176092147827,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26588,
        "tokens": 13939769344,
        "learning_rate": 8.095590130374266e-05,
        "gradient_norm": 0.5263155698776245,
        "train_loss": 3.0381040573120117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26589,
        "tokens": 13940293632,
        "learning_rate": 8.094483768805971e-05,
        "gradient_norm": 0.43219420313835144,
        "train_loss": 3.008418560028076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26590,
        "tokens": 13940817920,
        "learning_rate": 8.093377687580302e-05,
        "gradient_norm": 0.45983392000198364,
        "train_loss": 2.9651412963867188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26591,
        "tokens": 13941342208,
        "learning_rate": 8.092271886709719e-05,
        "gradient_norm": 0.4510374069213867,
        "train_loss": 3.0018539428710938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26592,
        "tokens": 13941866496,
        "learning_rate": 8.091166366206663e-05,
        "gradient_norm": 0.4515651762485504,
        "train_loss": 3.0777618885040283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26593,
        "tokens": 13942390784,
        "learning_rate": 8.090061126083581e-05,
        "gradient_norm": 0.412173867225647,
        "train_loss": 3.0349440574645996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26594,
        "tokens": 13942915072,
        "learning_rate": 8.088956166352906e-05,
        "gradient_norm": 0.4874996840953827,
        "train_loss": 3.0414161682128906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26595,
        "tokens": 13943439360,
        "learning_rate": 8.087851487027088e-05,
        "gradient_norm": 0.4485415518283844,
        "train_loss": 2.980288505554199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26596,
        "tokens": 13943963648,
        "learning_rate": 8.086747088118552e-05,
        "gradient_norm": 0.4256742298603058,
        "train_loss": 3.019256353378296,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26597,
        "tokens": 13944487936,
        "learning_rate": 8.085642969639736e-05,
        "gradient_norm": 0.44237247109413147,
        "train_loss": 2.9303975105285645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26598,
        "tokens": 13945012224,
        "learning_rate": 8.08453913160306e-05,
        "gradient_norm": 0.4185948967933655,
        "train_loss": 3.046358108520508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26599,
        "tokens": 13945536512,
        "learning_rate": 8.08343557402096e-05,
        "gradient_norm": 0.499565452337265,
        "train_loss": 2.964885711669922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26600,
        "tokens": 13946060800,
        "learning_rate": 8.082332296905842e-05,
        "gradient_norm": 0.41756585240364075,
        "train_loss": 3.032970666885376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26601,
        "tokens": 13946585088,
        "learning_rate": 8.081229300270146e-05,
        "gradient_norm": 0.5026689171791077,
        "train_loss": 3.0286850929260254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26602,
        "tokens": 13947109376,
        "learning_rate": 8.080126584126269e-05,
        "gradient_norm": 0.5005159974098206,
        "train_loss": 3.037346363067627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26603,
        "tokens": 13947633664,
        "learning_rate": 8.079024148486633e-05,
        "gradient_norm": 0.4599277079105377,
        "train_loss": 3.0160419940948486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26604,
        "tokens": 13948157952,
        "learning_rate": 8.077921993363645e-05,
        "gradient_norm": 0.5209545493125916,
        "train_loss": 2.9535205364227295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26605,
        "tokens": 13948682240,
        "learning_rate": 8.076820118769711e-05,
        "gradient_norm": 0.5878691077232361,
        "train_loss": 3.0439281463623047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26606,
        "tokens": 13949206528,
        "learning_rate": 8.075718524717235e-05,
        "gradient_norm": 0.44322410225868225,
        "train_loss": 3.0297510623931885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26607,
        "tokens": 13949730816,
        "learning_rate": 8.074617211218617e-05,
        "gradient_norm": 0.482589989900589,
        "train_loss": 3.028491973876953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26608,
        "tokens": 13950255104,
        "learning_rate": 8.073516178286249e-05,
        "gradient_norm": 0.45809072256088257,
        "train_loss": 3.0154173374176025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26609,
        "tokens": 13950779392,
        "learning_rate": 8.072415425932532e-05,
        "gradient_norm": 0.4366389214992523,
        "train_loss": 3.018775224685669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26610,
        "tokens": 13951303680,
        "learning_rate": 8.071314954169848e-05,
        "gradient_norm": 0.45092713832855225,
        "train_loss": 3.016965627670288,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26611,
        "tokens": 13951827968,
        "learning_rate": 8.070214763010592e-05,
        "gradient_norm": 0.43564265966415405,
        "train_loss": 2.9718308448791504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26612,
        "tokens": 13952352256,
        "learning_rate": 8.069114852467142e-05,
        "gradient_norm": 0.420733779668808,
        "train_loss": 3.024331569671631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26613,
        "tokens": 13952876544,
        "learning_rate": 8.068015222551887e-05,
        "gradient_norm": 0.39896833896636963,
        "train_loss": 3.0151662826538086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26614,
        "tokens": 13953400832,
        "learning_rate": 8.066915873277192e-05,
        "gradient_norm": 0.41788163781166077,
        "train_loss": 2.981372356414795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26615,
        "tokens": 13953925120,
        "learning_rate": 8.065816804655444e-05,
        "gradient_norm": 0.4147022068500519,
        "train_loss": 3.0323705673217773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26616,
        "tokens": 13954449408,
        "learning_rate": 8.064718016699007e-05,
        "gradient_norm": 0.4486028552055359,
        "train_loss": 3.0292601585388184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26617,
        "tokens": 13954973696,
        "learning_rate": 8.063619509420249e-05,
        "gradient_norm": 0.4255002737045288,
        "train_loss": 3.025834560394287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26618,
        "tokens": 13955497984,
        "learning_rate": 8.062521282831543e-05,
        "gradient_norm": 0.41000860929489136,
        "train_loss": 3.010911703109741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26619,
        "tokens": 13956022272,
        "learning_rate": 8.06142333694524e-05,
        "gradient_norm": 0.43460214138031006,
        "train_loss": 2.976673126220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26620,
        "tokens": 13956546560,
        "learning_rate": 8.060325671773708e-05,
        "gradient_norm": 0.4848204553127289,
        "train_loss": 3.115138053894043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26621,
        "tokens": 13957070848,
        "learning_rate": 8.059228287329295e-05,
        "gradient_norm": 0.43141910433769226,
        "train_loss": 3.0506978034973145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26622,
        "tokens": 13957595136,
        "learning_rate": 8.05813118362436e-05,
        "gradient_norm": 0.49954140186309814,
        "train_loss": 3.0257062911987305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26623,
        "tokens": 13958119424,
        "learning_rate": 8.05703436067125e-05,
        "gradient_norm": 0.49853602051734924,
        "train_loss": 3.0704240798950195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26624,
        "tokens": 13958643712,
        "learning_rate": 8.05593781848231e-05,
        "gradient_norm": 0.4446786642074585,
        "train_loss": 2.995896577835083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26625,
        "tokens": 13959168000,
        "learning_rate": 8.054841557069879e-05,
        "gradient_norm": 0.40115898847579956,
        "train_loss": 3.0542964935302734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26626,
        "tokens": 13959692288,
        "learning_rate": 8.053745576446304e-05,
        "gradient_norm": 0.44608256220817566,
        "train_loss": 3.022026538848877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26627,
        "tokens": 13960216576,
        "learning_rate": 8.052649876623921e-05,
        "gradient_norm": 0.45127978920936584,
        "train_loss": 2.993156671524048,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26628,
        "tokens": 13960740864,
        "learning_rate": 8.051554457615058e-05,
        "gradient_norm": 0.41015625,
        "train_loss": 2.9827799797058105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26629,
        "tokens": 13961265152,
        "learning_rate": 8.050459319432054e-05,
        "gradient_norm": 0.4406113028526306,
        "train_loss": 3.0305652618408203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26630,
        "tokens": 13961789440,
        "learning_rate": 8.049364462087223e-05,
        "gradient_norm": 0.3922134339809418,
        "train_loss": 2.9846768379211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26631,
        "tokens": 13962313728,
        "learning_rate": 8.048269885592904e-05,
        "gradient_norm": 0.375455379486084,
        "train_loss": 2.971247673034668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26632,
        "tokens": 13962838016,
        "learning_rate": 8.047175589961406e-05,
        "gradient_norm": 0.4240287244319916,
        "train_loss": 3.032527446746826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26633,
        "tokens": 13963362304,
        "learning_rate": 8.046081575205057e-05,
        "gradient_norm": 0.3888838589191437,
        "train_loss": 2.997446298599243,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26634,
        "tokens": 13963886592,
        "learning_rate": 8.044987841336158e-05,
        "gradient_norm": 0.39114058017730713,
        "train_loss": 3.0512802600860596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26635,
        "tokens": 13964410880,
        "learning_rate": 8.043894388367034e-05,
        "gradient_norm": 0.39733949303627014,
        "train_loss": 3.02994441986084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26636,
        "tokens": 13964935168,
        "learning_rate": 8.042801216309984e-05,
        "gradient_norm": 0.3935701847076416,
        "train_loss": 2.9641408920288086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26637,
        "tokens": 13965459456,
        "learning_rate": 8.041708325177312e-05,
        "gradient_norm": 0.39822283387184143,
        "train_loss": 3.009922981262207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26638,
        "tokens": 13965983744,
        "learning_rate": 8.040615714981335e-05,
        "gradient_norm": 0.40062886476516724,
        "train_loss": 3.0112760066986084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26639,
        "tokens": 13966508032,
        "learning_rate": 8.039523385734333e-05,
        "gradient_norm": 0.41595345735549927,
        "train_loss": 3.069108486175537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26640,
        "tokens": 13967032320,
        "learning_rate": 8.038431337448613e-05,
        "gradient_norm": 0.4260813593864441,
        "train_loss": 2.9640305042266846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26641,
        "tokens": 13967556608,
        "learning_rate": 8.037339570136462e-05,
        "gradient_norm": 0.44833534955978394,
        "train_loss": 3.049121856689453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26642,
        "tokens": 13968080896,
        "learning_rate": 8.03624808381017e-05,
        "gradient_norm": 0.411237508058548,
        "train_loss": 2.9745101928710938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26643,
        "tokens": 13968605184,
        "learning_rate": 8.035156878482024e-05,
        "gradient_norm": 0.46424591541290283,
        "train_loss": 3.0090723037719727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26644,
        "tokens": 13969129472,
        "learning_rate": 8.034065954164312e-05,
        "gradient_norm": 0.4290046691894531,
        "train_loss": 3.061944007873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26645,
        "tokens": 13969653760,
        "learning_rate": 8.032975310869303e-05,
        "gradient_norm": 0.4368130564689636,
        "train_loss": 3.0015170574188232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26646,
        "tokens": 13970178048,
        "learning_rate": 8.031884948609277e-05,
        "gradient_norm": 0.4481775164604187,
        "train_loss": 3.00480318069458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26647,
        "tokens": 13970702336,
        "learning_rate": 8.030794867396515e-05,
        "gradient_norm": 0.40476495027542114,
        "train_loss": 3.0390825271606445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26648,
        "tokens": 13971226624,
        "learning_rate": 8.029705067243278e-05,
        "gradient_norm": 0.39594176411628723,
        "train_loss": 3.009294033050537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26649,
        "tokens": 13971750912,
        "learning_rate": 8.028615548161841e-05,
        "gradient_norm": 0.41475364565849304,
        "train_loss": 3.0052967071533203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26650,
        "tokens": 13972275200,
        "learning_rate": 8.02752631016446e-05,
        "gradient_norm": 0.40517958998680115,
        "train_loss": 3.0092127323150635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26651,
        "tokens": 13972799488,
        "learning_rate": 8.026437353263404e-05,
        "gradient_norm": 0.40820130705833435,
        "train_loss": 2.9941868782043457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26652,
        "tokens": 13973323776,
        "learning_rate": 8.025348677470918e-05,
        "gradient_norm": 0.39235588908195496,
        "train_loss": 2.997683048248291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26653,
        "tokens": 13973848064,
        "learning_rate": 8.024260282799273e-05,
        "gradient_norm": 0.4111843407154083,
        "train_loss": 3.009023427963257,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26654,
        "tokens": 13974372352,
        "learning_rate": 8.023172169260705e-05,
        "gradient_norm": 0.4284253418445587,
        "train_loss": 3.0167694091796875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26655,
        "tokens": 13974896640,
        "learning_rate": 8.022084336867472e-05,
        "gradient_norm": 0.45193883776664734,
        "train_loss": 2.957656145095825,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26656,
        "tokens": 13975420928,
        "learning_rate": 8.020996785631812e-05,
        "gradient_norm": 0.49178922176361084,
        "train_loss": 3.095710277557373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26657,
        "tokens": 13975945216,
        "learning_rate": 8.019909515565973e-05,
        "gradient_norm": 0.46299684047698975,
        "train_loss": 3.0522584915161133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26658,
        "tokens": 13976469504,
        "learning_rate": 8.018822526682193e-05,
        "gradient_norm": 0.42583850026130676,
        "train_loss": 2.9901695251464844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26659,
        "tokens": 13976993792,
        "learning_rate": 8.017735818992701e-05,
        "gradient_norm": 0.4178602397441864,
        "train_loss": 3.021364212036133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26660,
        "tokens": 13977518080,
        "learning_rate": 8.016649392509737e-05,
        "gradient_norm": 0.40425002574920654,
        "train_loss": 3.023390531539917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26661,
        "tokens": 13978042368,
        "learning_rate": 8.015563247245526e-05,
        "gradient_norm": 0.48365944623947144,
        "train_loss": 3.044412136077881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26662,
        "tokens": 13978566656,
        "learning_rate": 8.014477383212296e-05,
        "gradient_norm": 0.4528084099292755,
        "train_loss": 3.019166946411133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26663,
        "tokens": 13979090944,
        "learning_rate": 8.013391800422262e-05,
        "gradient_norm": 0.4203915596008301,
        "train_loss": 2.9844322204589844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26664,
        "tokens": 13979615232,
        "learning_rate": 8.012306498887659e-05,
        "gradient_norm": 0.4585570693016052,
        "train_loss": 3.094453811645508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26665,
        "tokens": 13980139520,
        "learning_rate": 8.011221478620687e-05,
        "gradient_norm": 0.4005773067474365,
        "train_loss": 2.9601364135742188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26666,
        "tokens": 13980663808,
        "learning_rate": 8.010136739633567e-05,
        "gradient_norm": 0.4341404438018799,
        "train_loss": 3.0727529525756836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26667,
        "tokens": 13981188096,
        "learning_rate": 8.009052281938512e-05,
        "gradient_norm": 0.43755871057510376,
        "train_loss": 3.0230460166931152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26668,
        "tokens": 13981712384,
        "learning_rate": 8.007968105547725e-05,
        "gradient_norm": 0.4096042513847351,
        "train_loss": 3.0240540504455566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26669,
        "tokens": 13982236672,
        "learning_rate": 8.006884210473411e-05,
        "gradient_norm": 0.42275309562683105,
        "train_loss": 3.0417447090148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26670,
        "tokens": 13982760960,
        "learning_rate": 8.005800596727765e-05,
        "gradient_norm": 0.4345061779022217,
        "train_loss": 3.0397324562072754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26671,
        "tokens": 13983285248,
        "learning_rate": 8.004717264322995e-05,
        "gradient_norm": 0.4399729073047638,
        "train_loss": 3.0166516304016113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26672,
        "tokens": 13983809536,
        "learning_rate": 8.003634213271288e-05,
        "gradient_norm": 0.40460240840911865,
        "train_loss": 3.029466152191162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26673,
        "tokens": 13984333824,
        "learning_rate": 8.002551443584839e-05,
        "gradient_norm": 0.4137563705444336,
        "train_loss": 2.9571666717529297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26674,
        "tokens": 13984858112,
        "learning_rate": 8.001468955275827e-05,
        "gradient_norm": 0.43168556690216064,
        "train_loss": 3.0273494720458984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26675,
        "tokens": 13985382400,
        "learning_rate": 8.00038674835645e-05,
        "gradient_norm": 0.4350070655345917,
        "train_loss": 3.0569405555725098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26676,
        "tokens": 13985906688,
        "learning_rate": 7.99930482283888e-05,
        "gradient_norm": 0.38907352089881897,
        "train_loss": 3.012425422668457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26677,
        "tokens": 13986430976,
        "learning_rate": 7.998223178735295e-05,
        "gradient_norm": 0.4160878360271454,
        "train_loss": 2.998918056488037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26678,
        "tokens": 13986955264,
        "learning_rate": 7.997141816057882e-05,
        "gradient_norm": 0.4052022695541382,
        "train_loss": 3.0332894325256348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26679,
        "tokens": 13987479552,
        "learning_rate": 7.996060734818796e-05,
        "gradient_norm": 0.396663635969162,
        "train_loss": 3.0053157806396484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26680,
        "tokens": 13988003840,
        "learning_rate": 7.994979935030221e-05,
        "gradient_norm": 0.4026038944721222,
        "train_loss": 3.1187572479248047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26681,
        "tokens": 13988528128,
        "learning_rate": 7.993899416704314e-05,
        "gradient_norm": 0.410900354385376,
        "train_loss": 3.0590131282806396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26682,
        "tokens": 13989052416,
        "learning_rate": 7.992819179853242e-05,
        "gradient_norm": 0.42862260341644287,
        "train_loss": 3.018904209136963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26683,
        "tokens": 13989576704,
        "learning_rate": 7.991739224489158e-05,
        "gradient_norm": 0.4058911204338074,
        "train_loss": 3.0302374362945557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26684,
        "tokens": 13990100992,
        "learning_rate": 7.990659550624229e-05,
        "gradient_norm": 0.4005540609359741,
        "train_loss": 3.0158803462982178,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26685,
        "tokens": 13990625280,
        "learning_rate": 7.989580158270597e-05,
        "gradient_norm": 0.4158768355846405,
        "train_loss": 3.0250067710876465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26686,
        "tokens": 13991149568,
        "learning_rate": 7.988501047440415e-05,
        "gradient_norm": 0.4067319333553314,
        "train_loss": 3.004765510559082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26687,
        "tokens": 13991673856,
        "learning_rate": 7.987422218145837e-05,
        "gradient_norm": 0.4086046814918518,
        "train_loss": 3.064182758331299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26688,
        "tokens": 13992198144,
        "learning_rate": 7.986343670398996e-05,
        "gradient_norm": 0.4351135194301605,
        "train_loss": 3.0131566524505615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26689,
        "tokens": 13992722432,
        "learning_rate": 7.98526540421204e-05,
        "gradient_norm": 0.39144209027290344,
        "train_loss": 3.006901741027832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26690,
        "tokens": 13993246720,
        "learning_rate": 7.984187419597101e-05,
        "gradient_norm": 0.42138731479644775,
        "train_loss": 3.0933141708374023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26691,
        "tokens": 13993771008,
        "learning_rate": 7.983109716566321e-05,
        "gradient_norm": 0.4422271251678467,
        "train_loss": 3.0616586208343506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26692,
        "tokens": 13994295296,
        "learning_rate": 7.982032295131819e-05,
        "gradient_norm": 0.4621312618255615,
        "train_loss": 3.0745859146118164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26693,
        "tokens": 13994819584,
        "learning_rate": 7.980955155305736e-05,
        "gradient_norm": 0.4343280494213104,
        "train_loss": 2.983625888824463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26694,
        "tokens": 13995343872,
        "learning_rate": 7.979878297100182e-05,
        "gradient_norm": 0.4105197787284851,
        "train_loss": 2.9749374389648438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26695,
        "tokens": 13995868160,
        "learning_rate": 7.978801720527292e-05,
        "gradient_norm": 0.44706472754478455,
        "train_loss": 3.0336709022521973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26696,
        "tokens": 13996392448,
        "learning_rate": 7.977725425599178e-05,
        "gradient_norm": 0.42531076073646545,
        "train_loss": 3.0131940841674805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26697,
        "tokens": 13996916736,
        "learning_rate": 7.976649412327953e-05,
        "gradient_norm": 0.4515247941017151,
        "train_loss": 3.0344276428222656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26698,
        "tokens": 13997441024,
        "learning_rate": 7.975573680725731e-05,
        "gradient_norm": 0.4002705514431,
        "train_loss": 3.0785133838653564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26699,
        "tokens": 13997965312,
        "learning_rate": 7.974498230804625e-05,
        "gradient_norm": 0.40766671299934387,
        "train_loss": 3.0306668281555176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26700,
        "tokens": 13998489600,
        "learning_rate": 7.973423062576732e-05,
        "gradient_norm": 0.4700823426246643,
        "train_loss": 2.972787857055664,
        "val_loss": 2.9688477516174316,
        "hellaswag_acc": 0.2868950366973877,
        "hellaswag_acc_norm": 0.29725152254104614
    },
    {
        "step": 26701,
        "tokens": 13999013888,
        "learning_rate": 7.972348176054164e-05,
        "gradient_norm": 0.42106643319129944,
        "train_loss": 3.0122780799865723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26702,
        "tokens": 13999538176,
        "learning_rate": 7.971273571249009e-05,
        "gradient_norm": 0.4094094932079315,
        "train_loss": 3.0101122856140137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26703,
        "tokens": 14000062464,
        "learning_rate": 7.970199248173375e-05,
        "gradient_norm": 0.4703146815299988,
        "train_loss": 3.049103260040283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26704,
        "tokens": 14000586752,
        "learning_rate": 7.969125206839343e-05,
        "gradient_norm": 0.42946916818618774,
        "train_loss": 3.0053634643554688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26705,
        "tokens": 14001111040,
        "learning_rate": 7.968051447259014e-05,
        "gradient_norm": 0.4906401038169861,
        "train_loss": 2.996476173400879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26706,
        "tokens": 14001635328,
        "learning_rate": 7.966977969444465e-05,
        "gradient_norm": 0.4102400541305542,
        "train_loss": 3.065215587615967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26707,
        "tokens": 14002159616,
        "learning_rate": 7.965904773407787e-05,
        "gradient_norm": 0.4236813485622406,
        "train_loss": 2.9833555221557617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26708,
        "tokens": 14002683904,
        "learning_rate": 7.964831859161052e-05,
        "gradient_norm": 0.41901031136512756,
        "train_loss": 3.0600171089172363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26709,
        "tokens": 14003208192,
        "learning_rate": 7.963759226716346e-05,
        "gradient_norm": 0.43534091114997864,
        "train_loss": 2.9815855026245117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26710,
        "tokens": 14003732480,
        "learning_rate": 7.962686876085735e-05,
        "gradient_norm": 0.3905898630619049,
        "train_loss": 3.017120838165283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26711,
        "tokens": 14004256768,
        "learning_rate": 7.961614807281297e-05,
        "gradient_norm": 0.3897523283958435,
        "train_loss": 3.0179476737976074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26712,
        "tokens": 14004781056,
        "learning_rate": 7.960543020315089e-05,
        "gradient_norm": 0.4134816527366638,
        "train_loss": 3.0552079677581787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26713,
        "tokens": 14005305344,
        "learning_rate": 7.95947151519919e-05,
        "gradient_norm": 0.39384713768959045,
        "train_loss": 3.019606590270996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26714,
        "tokens": 14005829632,
        "learning_rate": 7.958400291945647e-05,
        "gradient_norm": 0.44960817694664,
        "train_loss": 3.015636682510376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26715,
        "tokens": 14006353920,
        "learning_rate": 7.957329350566527e-05,
        "gradient_norm": 0.44512560963630676,
        "train_loss": 3.003624439239502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26716,
        "tokens": 14006878208,
        "learning_rate": 7.95625869107388e-05,
        "gradient_norm": 0.4220534861087799,
        "train_loss": 3.0101308822631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26717,
        "tokens": 14007402496,
        "learning_rate": 7.955188313479758e-05,
        "gradient_norm": 0.41650697588920593,
        "train_loss": 2.979491710662842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26718,
        "tokens": 14007926784,
        "learning_rate": 7.954118217796214e-05,
        "gradient_norm": 0.39065977931022644,
        "train_loss": 3.0004546642303467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26719,
        "tokens": 14008451072,
        "learning_rate": 7.953048404035285e-05,
        "gradient_norm": 0.37827566266059875,
        "train_loss": 2.971618175506592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26720,
        "tokens": 14008975360,
        "learning_rate": 7.951978872209025e-05,
        "gradient_norm": 0.3927966356277466,
        "train_loss": 3.034916639328003,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26721,
        "tokens": 14009499648,
        "learning_rate": 7.95090962232946e-05,
        "gradient_norm": 0.3920604884624481,
        "train_loss": 2.963932991027832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26722,
        "tokens": 14010023936,
        "learning_rate": 7.949840654408636e-05,
        "gradient_norm": 0.40445476770401,
        "train_loss": 3.029723644256592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26723,
        "tokens": 14010548224,
        "learning_rate": 7.948771968458576e-05,
        "gradient_norm": 0.4089777171611786,
        "train_loss": 3.062497138977051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26724,
        "tokens": 14011072512,
        "learning_rate": 7.947703564491321e-05,
        "gradient_norm": 0.4328942596912384,
        "train_loss": 3.034073829650879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26725,
        "tokens": 14011596800,
        "learning_rate": 7.946635442518885e-05,
        "gradient_norm": 0.37827157974243164,
        "train_loss": 3.0300540924072266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26726,
        "tokens": 14012121088,
        "learning_rate": 7.945567602553299e-05,
        "gradient_norm": 0.4328024685382843,
        "train_loss": 3.0164272785186768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26727,
        "tokens": 14012645376,
        "learning_rate": 7.944500044606584e-05,
        "gradient_norm": 0.44109827280044556,
        "train_loss": 3.035454750061035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26728,
        "tokens": 14013169664,
        "learning_rate": 7.943432768690747e-05,
        "gradient_norm": 0.4187363386154175,
        "train_loss": 3.021483898162842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26729,
        "tokens": 14013693952,
        "learning_rate": 7.942365774817815e-05,
        "gradient_norm": 0.396417498588562,
        "train_loss": 3.0141448974609375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26730,
        "tokens": 14014218240,
        "learning_rate": 7.941299062999789e-05,
        "gradient_norm": 0.44190967082977295,
        "train_loss": 3.0094590187072754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26731,
        "tokens": 14014742528,
        "learning_rate": 7.94023263324868e-05,
        "gradient_norm": 0.4054330885410309,
        "train_loss": 3.0529732704162598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26732,
        "tokens": 14015266816,
        "learning_rate": 7.939166485576486e-05,
        "gradient_norm": 0.4229172170162201,
        "train_loss": 3.0553526878356934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26733,
        "tokens": 14015791104,
        "learning_rate": 7.938100619995218e-05,
        "gradient_norm": 0.4345357120037079,
        "train_loss": 3.0316100120544434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26734,
        "tokens": 14016315392,
        "learning_rate": 7.937035036516862e-05,
        "gradient_norm": 0.41117188334465027,
        "train_loss": 2.9950857162475586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26735,
        "tokens": 14016839680,
        "learning_rate": 7.935969735153425e-05,
        "gradient_norm": 0.3975157141685486,
        "train_loss": 3.0505237579345703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26736,
        "tokens": 14017363968,
        "learning_rate": 7.934904715916884e-05,
        "gradient_norm": 0.44218674302101135,
        "train_loss": 3.0367751121520996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26737,
        "tokens": 14017888256,
        "learning_rate": 7.933839978819237e-05,
        "gradient_norm": 0.5982822179794312,
        "train_loss": 3.0513315200805664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26738,
        "tokens": 14018412544,
        "learning_rate": 7.93277552387247e-05,
        "gradient_norm": 0.47126948833465576,
        "train_loss": 2.993366241455078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26739,
        "tokens": 14018936832,
        "learning_rate": 7.93171135108856e-05,
        "gradient_norm": 0.5359792113304138,
        "train_loss": 3.036776065826416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26740,
        "tokens": 14019461120,
        "learning_rate": 7.93064746047949e-05,
        "gradient_norm": 0.4033326208591461,
        "train_loss": 3.0159316062927246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26741,
        "tokens": 14019985408,
        "learning_rate": 7.929583852057228e-05,
        "gradient_norm": 0.46338456869125366,
        "train_loss": 3.0003089904785156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26742,
        "tokens": 14020509696,
        "learning_rate": 7.928520525833756e-05,
        "gradient_norm": 0.415127694606781,
        "train_loss": 3.022916316986084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26743,
        "tokens": 14021033984,
        "learning_rate": 7.927457481821034e-05,
        "gradient_norm": 0.47510603070259094,
        "train_loss": 2.9892282485961914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26744,
        "tokens": 14021558272,
        "learning_rate": 7.926394720031034e-05,
        "gradient_norm": 0.5111426711082458,
        "train_loss": 3.032987117767334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26745,
        "tokens": 14022082560,
        "learning_rate": 7.925332240475712e-05,
        "gradient_norm": 0.45489412546157837,
        "train_loss": 3.019834518432617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26746,
        "tokens": 14022606848,
        "learning_rate": 7.924270043167033e-05,
        "gradient_norm": 0.47493183612823486,
        "train_loss": 3.0247509479522705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26747,
        "tokens": 14023131136,
        "learning_rate": 7.923208128116958e-05,
        "gradient_norm": 0.42821064591407776,
        "train_loss": 3.0280799865722656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26748,
        "tokens": 14023655424,
        "learning_rate": 7.922146495337427e-05,
        "gradient_norm": 0.4248586595058441,
        "train_loss": 3.0321238040924072,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26749,
        "tokens": 14024179712,
        "learning_rate": 7.921085144840405e-05,
        "gradient_norm": 0.4193735718727112,
        "train_loss": 2.9817278385162354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26750,
        "tokens": 14024704000,
        "learning_rate": 7.920024076637828e-05,
        "gradient_norm": 0.4402318298816681,
        "train_loss": 3.0150740146636963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26751,
        "tokens": 14025228288,
        "learning_rate": 7.918963290741643e-05,
        "gradient_norm": 0.5025085806846619,
        "train_loss": 3.0403637886047363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26752,
        "tokens": 14025752576,
        "learning_rate": 7.91790278716379e-05,
        "gradient_norm": 0.40728995203971863,
        "train_loss": 3.024894952774048,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26753,
        "tokens": 14026276864,
        "learning_rate": 7.91684256591621e-05,
        "gradient_norm": 0.4813965857028961,
        "train_loss": 3.0201358795166016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26754,
        "tokens": 14026801152,
        "learning_rate": 7.915782627010827e-05,
        "gradient_norm": 0.43671914935112,
        "train_loss": 3.003122568130493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26755,
        "tokens": 14027325440,
        "learning_rate": 7.914722970459587e-05,
        "gradient_norm": 0.4365004897117615,
        "train_loss": 3.041210651397705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26756,
        "tokens": 14027849728,
        "learning_rate": 7.913663596274404e-05,
        "gradient_norm": 0.4181695580482483,
        "train_loss": 2.9734935760498047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26757,
        "tokens": 14028374016,
        "learning_rate": 7.91260450446721e-05,
        "gradient_norm": 0.44886305928230286,
        "train_loss": 3.0160319805145264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26758,
        "tokens": 14028898304,
        "learning_rate": 7.911545695049924e-05,
        "gradient_norm": 0.442374587059021,
        "train_loss": 3.048085927963257,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26759,
        "tokens": 14029422592,
        "learning_rate": 7.910487168034464e-05,
        "gradient_norm": 0.4226973056793213,
        "train_loss": 3.058195114135742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26760,
        "tokens": 14029946880,
        "learning_rate": 7.909428923432749e-05,
        "gradient_norm": 0.42634275555610657,
        "train_loss": 3.0408425331115723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26761,
        "tokens": 14030471168,
        "learning_rate": 7.908370961256684e-05,
        "gradient_norm": 0.39042550325393677,
        "train_loss": 3.044187545776367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26762,
        "tokens": 14030995456,
        "learning_rate": 7.907313281518185e-05,
        "gradient_norm": 0.48314276337623596,
        "train_loss": 2.9827353954315186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26763,
        "tokens": 14031519744,
        "learning_rate": 7.906255884229149e-05,
        "gradient_norm": 0.4628811180591583,
        "train_loss": 3.0481786727905273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26764,
        "tokens": 14032044032,
        "learning_rate": 7.905198769401491e-05,
        "gradient_norm": 0.4516841769218445,
        "train_loss": 3.0506577491760254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26765,
        "tokens": 14032568320,
        "learning_rate": 7.904141937047094e-05,
        "gradient_norm": 0.4867503046989441,
        "train_loss": 3.0701897144317627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26766,
        "tokens": 14033092608,
        "learning_rate": 7.903085387177864e-05,
        "gradient_norm": 0.435199499130249,
        "train_loss": 3.036480188369751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26767,
        "tokens": 14033616896,
        "learning_rate": 7.902029119805696e-05,
        "gradient_norm": 0.5063809156417847,
        "train_loss": 3.0529532432556152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26768,
        "tokens": 14034141184,
        "learning_rate": 7.900973134942472e-05,
        "gradient_norm": 0.4027939438819885,
        "train_loss": 3.036550998687744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26769,
        "tokens": 14034665472,
        "learning_rate": 7.899917432600087e-05,
        "gradient_norm": 0.40737542510032654,
        "train_loss": 2.976288318634033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26770,
        "tokens": 14035189760,
        "learning_rate": 7.898862012790414e-05,
        "gradient_norm": 0.40870073437690735,
        "train_loss": 3.0130867958068848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26771,
        "tokens": 14035714048,
        "learning_rate": 7.897806875525342e-05,
        "gradient_norm": 0.39151039719581604,
        "train_loss": 2.9654994010925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26772,
        "tokens": 14036238336,
        "learning_rate": 7.896752020816741e-05,
        "gradient_norm": 0.3974139988422394,
        "train_loss": 2.967698574066162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26773,
        "tokens": 14036762624,
        "learning_rate": 7.895697448676494e-05,
        "gradient_norm": 0.3939994275569916,
        "train_loss": 2.9513297080993652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26774,
        "tokens": 14037286912,
        "learning_rate": 7.89464315911646e-05,
        "gradient_norm": 0.3724880814552307,
        "train_loss": 3.0194082260131836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26775,
        "tokens": 14037811200,
        "learning_rate": 7.893589152148512e-05,
        "gradient_norm": 0.4016648232936859,
        "train_loss": 2.9966683387756348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26776,
        "tokens": 14038335488,
        "learning_rate": 7.892535427784516e-05,
        "gradient_norm": 0.40631186962127686,
        "train_loss": 3.0390217304229736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26777,
        "tokens": 14038859776,
        "learning_rate": 7.891481986036326e-05,
        "gradient_norm": 0.3851724863052368,
        "train_loss": 3.0064988136291504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26778,
        "tokens": 14039384064,
        "learning_rate": 7.890428826915811e-05,
        "gradient_norm": 0.3939705193042755,
        "train_loss": 3.061619997024536,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26779,
        "tokens": 14039908352,
        "learning_rate": 7.889375950434817e-05,
        "gradient_norm": 0.39859598875045776,
        "train_loss": 3.0226292610168457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26780,
        "tokens": 14040432640,
        "learning_rate": 7.888323356605202e-05,
        "gradient_norm": 0.39621856808662415,
        "train_loss": 3.034597396850586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26781,
        "tokens": 14040956928,
        "learning_rate": 7.887271045438804e-05,
        "gradient_norm": 0.4149843156337738,
        "train_loss": 3.084101438522339,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26782,
        "tokens": 14041481216,
        "learning_rate": 7.886219016947479e-05,
        "gradient_norm": 0.4035970866680145,
        "train_loss": 2.976517677307129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26783,
        "tokens": 14042005504,
        "learning_rate": 7.885167271143062e-05,
        "gradient_norm": 0.44813111424446106,
        "train_loss": 3.0988118648529053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26784,
        "tokens": 14042529792,
        "learning_rate": 7.884115808037395e-05,
        "gradient_norm": 0.43161290884017944,
        "train_loss": 2.974940776824951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26785,
        "tokens": 14043054080,
        "learning_rate": 7.883064627642307e-05,
        "gradient_norm": 0.3809923529624939,
        "train_loss": 3.0121655464172363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26786,
        "tokens": 14043578368,
        "learning_rate": 7.88201372996964e-05,
        "gradient_norm": 0.4658255875110626,
        "train_loss": 3.0110273361206055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26787,
        "tokens": 14044102656,
        "learning_rate": 7.880963115031221e-05,
        "gradient_norm": 0.42119625210762024,
        "train_loss": 2.993786334991455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26788,
        "tokens": 14044626944,
        "learning_rate": 7.87991278283887e-05,
        "gradient_norm": 0.41493532061576843,
        "train_loss": 2.998453140258789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26789,
        "tokens": 14045151232,
        "learning_rate": 7.878862733404416e-05,
        "gradient_norm": 0.49436941742897034,
        "train_loss": 3.0078117847442627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26790,
        "tokens": 14045675520,
        "learning_rate": 7.877812966739674e-05,
        "gradient_norm": 0.4559488892555237,
        "train_loss": 3.0006189346313477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26791,
        "tokens": 14046199808,
        "learning_rate": 7.876763482856468e-05,
        "gradient_norm": 0.4477519690990448,
        "train_loss": 3.013065814971924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26792,
        "tokens": 14046724096,
        "learning_rate": 7.875714281766598e-05,
        "gradient_norm": 0.4472035765647888,
        "train_loss": 3.002426862716675,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26793,
        "tokens": 14047248384,
        "learning_rate": 7.874665363481891e-05,
        "gradient_norm": 0.431559294462204,
        "train_loss": 3.039813995361328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26794,
        "tokens": 14047772672,
        "learning_rate": 7.873616728014137e-05,
        "gradient_norm": 0.4131188690662384,
        "train_loss": 3.1016812324523926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26795,
        "tokens": 14048296960,
        "learning_rate": 7.872568375375154e-05,
        "gradient_norm": 0.4194933772087097,
        "train_loss": 3.055182456970215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26796,
        "tokens": 14048821248,
        "learning_rate": 7.87152030557673e-05,
        "gradient_norm": 0.5114495754241943,
        "train_loss": 3.0855627059936523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26797,
        "tokens": 14049345536,
        "learning_rate": 7.870472518630669e-05,
        "gradient_norm": 0.45789358019828796,
        "train_loss": 2.9885730743408203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26798,
        "tokens": 14049869824,
        "learning_rate": 7.86942501454877e-05,
        "gradient_norm": 0.5043416023254395,
        "train_loss": 3.0177226066589355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26799,
        "tokens": 14050394112,
        "learning_rate": 7.868377793342812e-05,
        "gradient_norm": 0.5471951961517334,
        "train_loss": 2.9832842350006104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26800,
        "tokens": 14050918400,
        "learning_rate": 7.867330855024596e-05,
        "gradient_norm": 0.4257696568965912,
        "train_loss": 2.9879238605499268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26801,
        "tokens": 14051442688,
        "learning_rate": 7.866284199605894e-05,
        "gradient_norm": 0.4202464520931244,
        "train_loss": 3.0089144706726074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26802,
        "tokens": 14051966976,
        "learning_rate": 7.865237827098499e-05,
        "gradient_norm": 0.4434296190738678,
        "train_loss": 3.033766269683838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26803,
        "tokens": 14052491264,
        "learning_rate": 7.864191737514179e-05,
        "gradient_norm": 0.40223097801208496,
        "train_loss": 3.036353588104248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26804,
        "tokens": 14053015552,
        "learning_rate": 7.863145930864716e-05,
        "gradient_norm": 0.4253595173358917,
        "train_loss": 2.983269214630127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26805,
        "tokens": 14053539840,
        "learning_rate": 7.862100407161875e-05,
        "gradient_norm": 0.4294949769973755,
        "train_loss": 3.033338785171509,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26806,
        "tokens": 14054064128,
        "learning_rate": 7.861055166417437e-05,
        "gradient_norm": 0.4087836742401123,
        "train_loss": 3.045499086380005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26807,
        "tokens": 14054588416,
        "learning_rate": 7.860010208643153e-05,
        "gradient_norm": 0.44690999388694763,
        "train_loss": 2.993701457977295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26808,
        "tokens": 14055112704,
        "learning_rate": 7.858965533850795e-05,
        "gradient_norm": 0.43188899755477905,
        "train_loss": 3.000096321105957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26809,
        "tokens": 14055636992,
        "learning_rate": 7.857921142052118e-05,
        "gradient_norm": 0.4158342778682709,
        "train_loss": 3.046872854232788,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26810,
        "tokens": 14056161280,
        "learning_rate": 7.856877033258881e-05,
        "gradient_norm": 0.38921278715133667,
        "train_loss": 3.017963171005249,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26811,
        "tokens": 14056685568,
        "learning_rate": 7.85583320748283e-05,
        "gradient_norm": 0.4025317430496216,
        "train_loss": 2.9966113567352295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26812,
        "tokens": 14057209856,
        "learning_rate": 7.854789664735725e-05,
        "gradient_norm": 0.4226044714450836,
        "train_loss": 3.0208420753479004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26813,
        "tokens": 14057734144,
        "learning_rate": 7.853746405029301e-05,
        "gradient_norm": 0.4310150146484375,
        "train_loss": 3.065227746963501,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26814,
        "tokens": 14058258432,
        "learning_rate": 7.852703428375313e-05,
        "gradient_norm": 0.38581612706184387,
        "train_loss": 3.0252628326416016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26815,
        "tokens": 14058782720,
        "learning_rate": 7.851660734785492e-05,
        "gradient_norm": 0.4144517183303833,
        "train_loss": 3.0690131187438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26816,
        "tokens": 14059307008,
        "learning_rate": 7.850618324271577e-05,
        "gradient_norm": 0.45077672600746155,
        "train_loss": 3.017475128173828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26817,
        "tokens": 14059831296,
        "learning_rate": 7.8495761968453e-05,
        "gradient_norm": 0.3883688449859619,
        "train_loss": 3.0527472496032715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26818,
        "tokens": 14060355584,
        "learning_rate": 7.848534352518398e-05,
        "gradient_norm": 0.4132940173149109,
        "train_loss": 3.0153963565826416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26819,
        "tokens": 14060879872,
        "learning_rate": 7.847492791302591e-05,
        "gradient_norm": 0.45404958724975586,
        "train_loss": 3.020765781402588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26820,
        "tokens": 14061404160,
        "learning_rate": 7.846451513209609e-05,
        "gradient_norm": 0.44504213333129883,
        "train_loss": 3.033837080001831,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26821,
        "tokens": 14061928448,
        "learning_rate": 7.845410518251167e-05,
        "gradient_norm": 0.44648048281669617,
        "train_loss": 3.0080742835998535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26822,
        "tokens": 14062452736,
        "learning_rate": 7.844369806438991e-05,
        "gradient_norm": 0.4337843060493469,
        "train_loss": 3.0299224853515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26823,
        "tokens": 14062977024,
        "learning_rate": 7.843329377784782e-05,
        "gradient_norm": 0.4503738582134247,
        "train_loss": 2.996899127960205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26824,
        "tokens": 14063501312,
        "learning_rate": 7.842289232300265e-05,
        "gradient_norm": 0.4195750951766968,
        "train_loss": 3.027423858642578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26825,
        "tokens": 14064025600,
        "learning_rate": 7.841249369997139e-05,
        "gradient_norm": 0.4672755300998688,
        "train_loss": 3.0751638412475586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26826,
        "tokens": 14064549888,
        "learning_rate": 7.840209790887113e-05,
        "gradient_norm": 0.4207472503185272,
        "train_loss": 3.0081281661987305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26827,
        "tokens": 14065074176,
        "learning_rate": 7.839170494981891e-05,
        "gradient_norm": 0.46011868119239807,
        "train_loss": 2.967212200164795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26828,
        "tokens": 14065598464,
        "learning_rate": 7.838131482293167e-05,
        "gradient_norm": 0.4341871738433838,
        "train_loss": 3.064133882522583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26829,
        "tokens": 14066122752,
        "learning_rate": 7.837092752832643e-05,
        "gradient_norm": 0.4254235625267029,
        "train_loss": 3.0394954681396484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26830,
        "tokens": 14066647040,
        "learning_rate": 7.836054306612e-05,
        "gradient_norm": 0.4068586230278015,
        "train_loss": 3.044013023376465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26831,
        "tokens": 14067171328,
        "learning_rate": 7.835016143642936e-05,
        "gradient_norm": 0.4270329475402832,
        "train_loss": 2.9863646030426025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26832,
        "tokens": 14067695616,
        "learning_rate": 7.833978263937134e-05,
        "gradient_norm": 0.4571346640586853,
        "train_loss": 3.090867042541504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26833,
        "tokens": 14068219904,
        "learning_rate": 7.83294066750628e-05,
        "gradient_norm": 0.38421866297721863,
        "train_loss": 3.0327911376953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26834,
        "tokens": 14068744192,
        "learning_rate": 7.831903354362044e-05,
        "gradient_norm": 0.45268869400024414,
        "train_loss": 3.0692391395568848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26835,
        "tokens": 14069268480,
        "learning_rate": 7.830866324516114e-05,
        "gradient_norm": 0.47670313715934753,
        "train_loss": 3.0884053707122803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26836,
        "tokens": 14069792768,
        "learning_rate": 7.829829577980153e-05,
        "gradient_norm": 0.4066125154495239,
        "train_loss": 2.9712696075439453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26837,
        "tokens": 14070317056,
        "learning_rate": 7.828793114765837e-05,
        "gradient_norm": 0.4098292589187622,
        "train_loss": 3.007646083831787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26838,
        "tokens": 14070841344,
        "learning_rate": 7.827756934884834e-05,
        "gradient_norm": 0.4601973295211792,
        "train_loss": 2.9914236068725586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26839,
        "tokens": 14071365632,
        "learning_rate": 7.826721038348803e-05,
        "gradient_norm": 0.44279101490974426,
        "train_loss": 3.014525890350342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26840,
        "tokens": 14071889920,
        "learning_rate": 7.825685425169409e-05,
        "gradient_norm": 0.3946564495563507,
        "train_loss": 3.015153408050537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26841,
        "tokens": 14072414208,
        "learning_rate": 7.8246500953583e-05,
        "gradient_norm": 0.5798772573471069,
        "train_loss": 2.9629950523376465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26842,
        "tokens": 14072938496,
        "learning_rate": 7.823615048927142e-05,
        "gradient_norm": 0.4585973024368286,
        "train_loss": 3.0100584030151367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26843,
        "tokens": 14073462784,
        "learning_rate": 7.822580285887574e-05,
        "gradient_norm": 0.4449993073940277,
        "train_loss": 3.036684989929199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26844,
        "tokens": 14073987072,
        "learning_rate": 7.821545806251256e-05,
        "gradient_norm": 0.41483715176582336,
        "train_loss": 2.9979398250579834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26845,
        "tokens": 14074511360,
        "learning_rate": 7.82051161002982e-05,
        "gradient_norm": 0.4784294068813324,
        "train_loss": 3.0069570541381836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26846,
        "tokens": 14075035648,
        "learning_rate": 7.819477697234915e-05,
        "gradient_norm": 0.40532949566841125,
        "train_loss": 2.972982883453369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26847,
        "tokens": 14075559936,
        "learning_rate": 7.818444067878178e-05,
        "gradient_norm": 0.47706446051597595,
        "train_loss": 3.027074098587036,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26848,
        "tokens": 14076084224,
        "learning_rate": 7.81741072197124e-05,
        "gradient_norm": 0.44289302825927734,
        "train_loss": 3.0105512142181396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26849,
        "tokens": 14076608512,
        "learning_rate": 7.81637765952574e-05,
        "gradient_norm": 0.4679073989391327,
        "train_loss": 2.981812000274658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26850,
        "tokens": 14077132800,
        "learning_rate": 7.815344880553296e-05,
        "gradient_norm": 0.5402916669845581,
        "train_loss": 2.995969772338867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26851,
        "tokens": 14077657088,
        "learning_rate": 7.814312385065545e-05,
        "gradient_norm": 0.4750385284423828,
        "train_loss": 3.0174553394317627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26852,
        "tokens": 14078181376,
        "learning_rate": 7.813280173074096e-05,
        "gradient_norm": 0.45687660574913025,
        "train_loss": 2.9971652030944824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26853,
        "tokens": 14078705664,
        "learning_rate": 7.812248244590581e-05,
        "gradient_norm": 0.4768542945384979,
        "train_loss": 3.06850004196167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26854,
        "tokens": 14079229952,
        "learning_rate": 7.811216599626605e-05,
        "gradient_norm": 0.45563122630119324,
        "train_loss": 3.008674144744873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26855,
        "tokens": 14079754240,
        "learning_rate": 7.810185238193788e-05,
        "gradient_norm": 0.4615201950073242,
        "train_loss": 2.979806900024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26856,
        "tokens": 14080278528,
        "learning_rate": 7.80915416030373e-05,
        "gradient_norm": 0.48045265674591064,
        "train_loss": 3.081455945968628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26857,
        "tokens": 14080802816,
        "learning_rate": 7.808123365968046e-05,
        "gradient_norm": 0.4063946008682251,
        "train_loss": 3.0014610290527344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26858,
        "tokens": 14081327104,
        "learning_rate": 7.807092855198342e-05,
        "gradient_norm": 0.4726535379886627,
        "train_loss": 3.0568928718566895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26859,
        "tokens": 14081851392,
        "learning_rate": 7.806062628006204e-05,
        "gradient_norm": 0.48646390438079834,
        "train_loss": 3.0225305557250977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26860,
        "tokens": 14082375680,
        "learning_rate": 7.805032684403242e-05,
        "gradient_norm": 0.4611749053001404,
        "train_loss": 3.0410280227661133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26861,
        "tokens": 14082899968,
        "learning_rate": 7.80400302440104e-05,
        "gradient_norm": 0.44007474184036255,
        "train_loss": 3.0282559394836426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26862,
        "tokens": 14083424256,
        "learning_rate": 7.802973648011192e-05,
        "gradient_norm": 0.4349062740802765,
        "train_loss": 3.0281145572662354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26863,
        "tokens": 14083948544,
        "learning_rate": 7.801944555245284e-05,
        "gradient_norm": 0.45160531997680664,
        "train_loss": 3.038130760192871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26864,
        "tokens": 14084472832,
        "learning_rate": 7.800915746114905e-05,
        "gradient_norm": 0.3994204103946686,
        "train_loss": 3.010450839996338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26865,
        "tokens": 14084997120,
        "learning_rate": 7.799887220631624e-05,
        "gradient_norm": 0.4633049964904785,
        "train_loss": 3.091074228286743,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26866,
        "tokens": 14085521408,
        "learning_rate": 7.798858978807026e-05,
        "gradient_norm": 0.390953004360199,
        "train_loss": 3.0117151737213135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26867,
        "tokens": 14086045696,
        "learning_rate": 7.797831020652689e-05,
        "gradient_norm": 0.41507771611213684,
        "train_loss": 3.0187642574310303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26868,
        "tokens": 14086569984,
        "learning_rate": 7.796803346180174e-05,
        "gradient_norm": 0.4556448459625244,
        "train_loss": 3.0321803092956543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26869,
        "tokens": 14087094272,
        "learning_rate": 7.795775955401057e-05,
        "gradient_norm": 0.42531055212020874,
        "train_loss": 3.0314488410949707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26870,
        "tokens": 14087618560,
        "learning_rate": 7.794748848326899e-05,
        "gradient_norm": 0.3913457691669464,
        "train_loss": 3.0194292068481445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26871,
        "tokens": 14088142848,
        "learning_rate": 7.793722024969265e-05,
        "gradient_norm": 0.42661982774734497,
        "train_loss": 3.004202365875244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26872,
        "tokens": 14088667136,
        "learning_rate": 7.792695485339703e-05,
        "gradient_norm": 0.4030587375164032,
        "train_loss": 2.9974541664123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26873,
        "tokens": 14089191424,
        "learning_rate": 7.791669229449781e-05,
        "gradient_norm": 0.4136367738246918,
        "train_loss": 2.9793896675109863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26874,
        "tokens": 14089715712,
        "learning_rate": 7.79064325731104e-05,
        "gradient_norm": 0.4357254207134247,
        "train_loss": 2.998523712158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26875,
        "tokens": 14090240000,
        "learning_rate": 7.789617568935041e-05,
        "gradient_norm": 0.3917175531387329,
        "train_loss": 3.0166609287261963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26876,
        "tokens": 14090764288,
        "learning_rate": 7.788592164333313e-05,
        "gradient_norm": 0.4419316351413727,
        "train_loss": 3.039285659790039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26877,
        "tokens": 14091288576,
        "learning_rate": 7.78756704351741e-05,
        "gradient_norm": 0.3798648416996002,
        "train_loss": 3.0245141983032227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26878,
        "tokens": 14091812864,
        "learning_rate": 7.78654220649887e-05,
        "gradient_norm": 0.4140660762786865,
        "train_loss": 3.025404453277588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26879,
        "tokens": 14092337152,
        "learning_rate": 7.785517653289225e-05,
        "gradient_norm": 0.4243161976337433,
        "train_loss": 3.04219388961792,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26880,
        "tokens": 14092861440,
        "learning_rate": 7.784493383900011e-05,
        "gradient_norm": 0.38042229413986206,
        "train_loss": 3.0571060180664062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26881,
        "tokens": 14093385728,
        "learning_rate": 7.783469398342754e-05,
        "gradient_norm": 0.534102201461792,
        "train_loss": 3.0888614654541016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26882,
        "tokens": 14093910016,
        "learning_rate": 7.782445696628989e-05,
        "gradient_norm": 0.4314451813697815,
        "train_loss": 3.004335403442383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26883,
        "tokens": 14094434304,
        "learning_rate": 7.781422278770224e-05,
        "gradient_norm": 0.439363569021225,
        "train_loss": 3.0029845237731934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26884,
        "tokens": 14094958592,
        "learning_rate": 7.780399144777993e-05,
        "gradient_norm": 0.40788474678993225,
        "train_loss": 2.976658821105957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26885,
        "tokens": 14095482880,
        "learning_rate": 7.779376294663799e-05,
        "gradient_norm": 0.46093931794166565,
        "train_loss": 3.105012893676758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26886,
        "tokens": 14096007168,
        "learning_rate": 7.778353728439167e-05,
        "gradient_norm": 0.4211394190788269,
        "train_loss": 3.015937328338623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26887,
        "tokens": 14096531456,
        "learning_rate": 7.777331446115605e-05,
        "gradient_norm": 0.3767772614955902,
        "train_loss": 3.056874990463257,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26888,
        "tokens": 14097055744,
        "learning_rate": 7.776309447704615e-05,
        "gradient_norm": 0.42297831177711487,
        "train_loss": 2.976207733154297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26889,
        "tokens": 14097580032,
        "learning_rate": 7.775287733217709e-05,
        "gradient_norm": 0.39627352356910706,
        "train_loss": 2.986422538757324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26890,
        "tokens": 14098104320,
        "learning_rate": 7.774266302666379e-05,
        "gradient_norm": 0.4541141390800476,
        "train_loss": 3.0825722217559814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26891,
        "tokens": 14098628608,
        "learning_rate": 7.77324515606213e-05,
        "gradient_norm": 0.4182616174221039,
        "train_loss": 2.983670949935913,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26892,
        "tokens": 14099152896,
        "learning_rate": 7.77222429341645e-05,
        "gradient_norm": 0.3878621757030487,
        "train_loss": 3.0344200134277344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26893,
        "tokens": 14099677184,
        "learning_rate": 7.771203714740838e-05,
        "gradient_norm": 0.47685685753822327,
        "train_loss": 2.9727017879486084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26894,
        "tokens": 14100201472,
        "learning_rate": 7.770183420046768e-05,
        "gradient_norm": 0.452874094247818,
        "train_loss": 2.9648680686950684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26895,
        "tokens": 14100725760,
        "learning_rate": 7.769163409345741e-05,
        "gradient_norm": 0.4168039560317993,
        "train_loss": 3.0356686115264893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26896,
        "tokens": 14101250048,
        "learning_rate": 7.768143682649226e-05,
        "gradient_norm": 0.4903419017791748,
        "train_loss": 3.0036942958831787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26897,
        "tokens": 14101774336,
        "learning_rate": 7.767124239968704e-05,
        "gradient_norm": 0.43900594115257263,
        "train_loss": 3.0157411098480225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26898,
        "tokens": 14102298624,
        "learning_rate": 7.766105081315658e-05,
        "gradient_norm": 0.41393396258354187,
        "train_loss": 3.003958225250244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26899,
        "tokens": 14102822912,
        "learning_rate": 7.765086206701551e-05,
        "gradient_norm": 0.4368285834789276,
        "train_loss": 3.067197799682617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26900,
        "tokens": 14103347200,
        "learning_rate": 7.76406761613786e-05,
        "gradient_norm": 0.4566492438316345,
        "train_loss": 3.0123038291931152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26901,
        "tokens": 14103871488,
        "learning_rate": 7.76304930963604e-05,
        "gradient_norm": 0.4315578043460846,
        "train_loss": 3.0920839309692383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26902,
        "tokens": 14104395776,
        "learning_rate": 7.762031287207564e-05,
        "gradient_norm": 0.4491308331489563,
        "train_loss": 3.013415813446045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26903,
        "tokens": 14104920064,
        "learning_rate": 7.761013548863877e-05,
        "gradient_norm": 0.3846505582332611,
        "train_loss": 3.003403902053833,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26904,
        "tokens": 14105444352,
        "learning_rate": 7.759996094616452e-05,
        "gradient_norm": 0.4116436243057251,
        "train_loss": 3.019981861114502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26905,
        "tokens": 14105968640,
        "learning_rate": 7.758978924476731e-05,
        "gradient_norm": 0.43174034357070923,
        "train_loss": 3.014404535293579,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26906,
        "tokens": 14106492928,
        "learning_rate": 7.757962038456166e-05,
        "gradient_norm": 0.39528968930244446,
        "train_loss": 2.9892172813415527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26907,
        "tokens": 14107017216,
        "learning_rate": 7.7569454365662e-05,
        "gradient_norm": 0.3985327482223511,
        "train_loss": 2.9767870903015137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26908,
        "tokens": 14107541504,
        "learning_rate": 7.755929118818285e-05,
        "gradient_norm": 0.4133421778678894,
        "train_loss": 2.9954047203063965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26909,
        "tokens": 14108065792,
        "learning_rate": 7.75491308522385e-05,
        "gradient_norm": 0.4002281725406647,
        "train_loss": 3.0308589935302734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26910,
        "tokens": 14108590080,
        "learning_rate": 7.753897335794341e-05,
        "gradient_norm": 0.4088412821292877,
        "train_loss": 3.015505790710449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26911,
        "tokens": 14109114368,
        "learning_rate": 7.752881870541185e-05,
        "gradient_norm": 0.4163372218608856,
        "train_loss": 3.0599489212036133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26912,
        "tokens": 14109638656,
        "learning_rate": 7.751866689475818e-05,
        "gradient_norm": 0.3987974226474762,
        "train_loss": 3.0263266563415527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26913,
        "tokens": 14110162944,
        "learning_rate": 7.75085179260966e-05,
        "gradient_norm": 0.4371742904186249,
        "train_loss": 3.012608051300049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26914,
        "tokens": 14110687232,
        "learning_rate": 7.749837179954143e-05,
        "gradient_norm": 0.4203720986843109,
        "train_loss": 3.022465944290161,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26915,
        "tokens": 14111211520,
        "learning_rate": 7.748822851520679e-05,
        "gradient_norm": 0.3870091438293457,
        "train_loss": 3.0155279636383057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26916,
        "tokens": 14111735808,
        "learning_rate": 7.747808807320695e-05,
        "gradient_norm": 0.40387144684791565,
        "train_loss": 3.047410011291504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26917,
        "tokens": 14112260096,
        "learning_rate": 7.746795047365598e-05,
        "gradient_norm": 0.43127989768981934,
        "train_loss": 3.0210719108581543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26918,
        "tokens": 14112784384,
        "learning_rate": 7.745781571666803e-05,
        "gradient_norm": 0.39971211552619934,
        "train_loss": 3.0318191051483154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26919,
        "tokens": 14113308672,
        "learning_rate": 7.744768380235714e-05,
        "gradient_norm": 0.42312726378440857,
        "train_loss": 3.0484330654144287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26920,
        "tokens": 14113832960,
        "learning_rate": 7.743755473083743e-05,
        "gradient_norm": 0.45097774267196655,
        "train_loss": 3.010999917984009,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26921,
        "tokens": 14114357248,
        "learning_rate": 7.742742850222282e-05,
        "gradient_norm": 0.4304884076118469,
        "train_loss": 2.982055187225342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26922,
        "tokens": 14114881536,
        "learning_rate": 7.741730511662738e-05,
        "gradient_norm": 0.41239047050476074,
        "train_loss": 3.0038435459136963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26923,
        "tokens": 14115405824,
        "learning_rate": 7.740718457416497e-05,
        "gradient_norm": 0.3803670406341553,
        "train_loss": 2.9823555946350098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26924,
        "tokens": 14115930112,
        "learning_rate": 7.739706687494962e-05,
        "gradient_norm": 0.4012856185436249,
        "train_loss": 3.0264363288879395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26925,
        "tokens": 14116454400,
        "learning_rate": 7.738695201909512e-05,
        "gradient_norm": 0.41999995708465576,
        "train_loss": 2.995547294616699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26926,
        "tokens": 14116978688,
        "learning_rate": 7.737684000671538e-05,
        "gradient_norm": 0.395725280046463,
        "train_loss": 3.001288414001465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26927,
        "tokens": 14117502976,
        "learning_rate": 7.736673083792423e-05,
        "gradient_norm": 0.425313264131546,
        "train_loss": 3.1120448112487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26928,
        "tokens": 14118027264,
        "learning_rate": 7.735662451283539e-05,
        "gradient_norm": 0.4435729682445526,
        "train_loss": 3.0379419326782227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26929,
        "tokens": 14118551552,
        "learning_rate": 7.734652103156273e-05,
        "gradient_norm": 0.41261953115463257,
        "train_loss": 3.066000461578369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26930,
        "tokens": 14119075840,
        "learning_rate": 7.733642039421988e-05,
        "gradient_norm": 0.41600286960601807,
        "train_loss": 2.9809837341308594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26931,
        "tokens": 14119600128,
        "learning_rate": 7.732632260092058e-05,
        "gradient_norm": 0.4207402169704437,
        "train_loss": 3.006901741027832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26932,
        "tokens": 14120124416,
        "learning_rate": 7.73162276517785e-05,
        "gradient_norm": 0.39927002787590027,
        "train_loss": 3.0425453186035156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26933,
        "tokens": 14120648704,
        "learning_rate": 7.730613554690726e-05,
        "gradient_norm": 0.3988037407398224,
        "train_loss": 3.061467409133911,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26934,
        "tokens": 14121172992,
        "learning_rate": 7.72960462864204e-05,
        "gradient_norm": 0.42323875427246094,
        "train_loss": 3.0422515869140625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26935,
        "tokens": 14121697280,
        "learning_rate": 7.728595987043162e-05,
        "gradient_norm": 0.4014054536819458,
        "train_loss": 3.058757781982422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26936,
        "tokens": 14122221568,
        "learning_rate": 7.727587629905431e-05,
        "gradient_norm": 0.4265792667865753,
        "train_loss": 2.999912738800049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26937,
        "tokens": 14122745856,
        "learning_rate": 7.726579557240204e-05,
        "gradient_norm": 0.397273451089859,
        "train_loss": 2.999094247817993,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26938,
        "tokens": 14123270144,
        "learning_rate": 7.725571769058833e-05,
        "gradient_norm": 0.4074220359325409,
        "train_loss": 3.01412296295166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26939,
        "tokens": 14123794432,
        "learning_rate": 7.724564265372655e-05,
        "gradient_norm": 0.5284110903739929,
        "train_loss": 3.065955400466919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26940,
        "tokens": 14124318720,
        "learning_rate": 7.723557046193012e-05,
        "gradient_norm": 0.3897498846054077,
        "train_loss": 3.0264816284179688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26941,
        "tokens": 14124843008,
        "learning_rate": 7.722550111531242e-05,
        "gradient_norm": 0.4330631196498871,
        "train_loss": 3.052402973175049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26942,
        "tokens": 14125367296,
        "learning_rate": 7.721543461398686e-05,
        "gradient_norm": 0.40373703837394714,
        "train_loss": 3.049039363861084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26943,
        "tokens": 14125891584,
        "learning_rate": 7.72053709580666e-05,
        "gradient_norm": 0.4247143566608429,
        "train_loss": 3.0531625747680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26944,
        "tokens": 14126415872,
        "learning_rate": 7.719531014766507e-05,
        "gradient_norm": 0.4418547451496124,
        "train_loss": 3.1032557487487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26945,
        "tokens": 14126940160,
        "learning_rate": 7.718525218289543e-05,
        "gradient_norm": 0.40126439929008484,
        "train_loss": 2.9897844791412354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26946,
        "tokens": 14127464448,
        "learning_rate": 7.717519706387087e-05,
        "gradient_norm": 0.4279755651950836,
        "train_loss": 2.9941463470458984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26947,
        "tokens": 14127988736,
        "learning_rate": 7.71651447907047e-05,
        "gradient_norm": 0.41569969058036804,
        "train_loss": 3.0470402240753174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26948,
        "tokens": 14128513024,
        "learning_rate": 7.715509536350995e-05,
        "gradient_norm": 0.4115636646747589,
        "train_loss": 3.0937271118164062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26949,
        "tokens": 14129037312,
        "learning_rate": 7.71450487823998e-05,
        "gradient_norm": 0.3834177851676941,
        "train_loss": 3.021350383758545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26950,
        "tokens": 14129561600,
        "learning_rate": 7.71350050474873e-05,
        "gradient_norm": 0.41919443011283875,
        "train_loss": 2.989899158477783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26951,
        "tokens": 14130085888,
        "learning_rate": 7.712496415888557e-05,
        "gradient_norm": 0.387756884098053,
        "train_loss": 2.9861745834350586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26952,
        "tokens": 14130610176,
        "learning_rate": 7.711492611670753e-05,
        "gradient_norm": 0.41964471340179443,
        "train_loss": 2.9712934494018555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26953,
        "tokens": 14131134464,
        "learning_rate": 7.710489092106624e-05,
        "gradient_norm": 0.41081109642982483,
        "train_loss": 3.012984275817871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26954,
        "tokens": 14131658752,
        "learning_rate": 7.709485857207465e-05,
        "gradient_norm": 0.41641682386398315,
        "train_loss": 2.9985501766204834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26955,
        "tokens": 14132183040,
        "learning_rate": 7.708482906984565e-05,
        "gradient_norm": 0.4362306296825409,
        "train_loss": 2.986477851867676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26956,
        "tokens": 14132707328,
        "learning_rate": 7.70748024144922e-05,
        "gradient_norm": 0.408097505569458,
        "train_loss": 3.011895179748535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26957,
        "tokens": 14133231616,
        "learning_rate": 7.706477860612713e-05,
        "gradient_norm": 0.4399414360523224,
        "train_loss": 2.9467873573303223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26958,
        "tokens": 14133755904,
        "learning_rate": 7.705475764486328e-05,
        "gradient_norm": 0.4079802334308624,
        "train_loss": 3.001671314239502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26959,
        "tokens": 14134280192,
        "learning_rate": 7.70447395308134e-05,
        "gradient_norm": 0.42495977878570557,
        "train_loss": 3.0164794921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26960,
        "tokens": 14134804480,
        "learning_rate": 7.703472426409033e-05,
        "gradient_norm": 0.45013508200645447,
        "train_loss": 3.0301969051361084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26961,
        "tokens": 14135328768,
        "learning_rate": 7.702471184480675e-05,
        "gradient_norm": 0.42235252261161804,
        "train_loss": 2.9875526428222656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26962,
        "tokens": 14135853056,
        "learning_rate": 7.70147022730754e-05,
        "gradient_norm": 0.40791767835617065,
        "train_loss": 3.0022964477539062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26963,
        "tokens": 14136377344,
        "learning_rate": 7.700469554900889e-05,
        "gradient_norm": 0.4256579577922821,
        "train_loss": 2.9816462993621826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26964,
        "tokens": 14136901632,
        "learning_rate": 7.699469167271993e-05,
        "gradient_norm": 0.3881504237651825,
        "train_loss": 2.9981276988983154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26965,
        "tokens": 14137425920,
        "learning_rate": 7.698469064432108e-05,
        "gradient_norm": 0.43729105591773987,
        "train_loss": 3.0555691719055176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26966,
        "tokens": 14137950208,
        "learning_rate": 7.697469246392493e-05,
        "gradient_norm": 0.3877210021018982,
        "train_loss": 3.044045925140381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26967,
        "tokens": 14138474496,
        "learning_rate": 7.696469713164406e-05,
        "gradient_norm": 0.41099897027015686,
        "train_loss": 3.014519214630127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26968,
        "tokens": 14138998784,
        "learning_rate": 7.695470464759086e-05,
        "gradient_norm": 0.4201677739620209,
        "train_loss": 3.0251731872558594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26969,
        "tokens": 14139523072,
        "learning_rate": 7.694471501187795e-05,
        "gradient_norm": 0.47895219922065735,
        "train_loss": 3.0590715408325195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26970,
        "tokens": 14140047360,
        "learning_rate": 7.693472822461767e-05,
        "gradient_norm": 0.4280981421470642,
        "train_loss": 3.0412378311157227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26971,
        "tokens": 14140571648,
        "learning_rate": 7.692474428592254e-05,
        "gradient_norm": 0.4636949598789215,
        "train_loss": 3.0032732486724854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26972,
        "tokens": 14141095936,
        "learning_rate": 7.691476319590482e-05,
        "gradient_norm": 0.4668734669685364,
        "train_loss": 3.046651601791382,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26973,
        "tokens": 14141620224,
        "learning_rate": 7.690478495467698e-05,
        "gradient_norm": 0.4422958195209503,
        "train_loss": 3.0049357414245605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26974,
        "tokens": 14142144512,
        "learning_rate": 7.689480956235121e-05,
        "gradient_norm": 0.42997249960899353,
        "train_loss": 3.0528817176818848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26975,
        "tokens": 14142668800,
        "learning_rate": 7.68848370190399e-05,
        "gradient_norm": 0.4472199082374573,
        "train_loss": 3.0114312171936035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26976,
        "tokens": 14143193088,
        "learning_rate": 7.687486732485526e-05,
        "gradient_norm": 0.4115287661552429,
        "train_loss": 3.049424648284912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26977,
        "tokens": 14143717376,
        "learning_rate": 7.68649004799095e-05,
        "gradient_norm": 0.40733519196510315,
        "train_loss": 2.99082612991333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26978,
        "tokens": 14144241664,
        "learning_rate": 7.685493648431487e-05,
        "gradient_norm": 0.3958817720413208,
        "train_loss": 3.006850242614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26979,
        "tokens": 14144765952,
        "learning_rate": 7.684497533818343e-05,
        "gradient_norm": 0.4191233515739441,
        "train_loss": 3.062697410583496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26980,
        "tokens": 14145290240,
        "learning_rate": 7.683501704162743e-05,
        "gradient_norm": 0.3844693899154663,
        "train_loss": 3.0515050888061523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26981,
        "tokens": 14145814528,
        "learning_rate": 7.68250615947588e-05,
        "gradient_norm": 0.4285905659198761,
        "train_loss": 2.9986300468444824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26982,
        "tokens": 14146338816,
        "learning_rate": 7.681510899768977e-05,
        "gradient_norm": 0.44622012972831726,
        "train_loss": 2.983945369720459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26983,
        "tokens": 14146863104,
        "learning_rate": 7.680515925053226e-05,
        "gradient_norm": 0.39392343163490295,
        "train_loss": 3.0194082260131836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26984,
        "tokens": 14147387392,
        "learning_rate": 7.67952123533983e-05,
        "gradient_norm": 0.4725426733493805,
        "train_loss": 3.069758892059326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26985,
        "tokens": 14147911680,
        "learning_rate": 7.678526830639983e-05,
        "gradient_norm": 0.4674626290798187,
        "train_loss": 3.009002208709717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26986,
        "tokens": 14148435968,
        "learning_rate": 7.677532710964883e-05,
        "gradient_norm": 0.4069764316082001,
        "train_loss": 3.0185296535491943,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26987,
        "tokens": 14148960256,
        "learning_rate": 7.676538876325718e-05,
        "gradient_norm": 0.4215916395187378,
        "train_loss": 3.055428981781006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26988,
        "tokens": 14149484544,
        "learning_rate": 7.675545326733674e-05,
        "gradient_norm": 0.45509567856788635,
        "train_loss": 3.0168657302856445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26989,
        "tokens": 14150008832,
        "learning_rate": 7.674552062199935e-05,
        "gradient_norm": 0.4198165237903595,
        "train_loss": 3.0364601612091064,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26990,
        "tokens": 14150533120,
        "learning_rate": 7.67355908273568e-05,
        "gradient_norm": 0.38564321398735046,
        "train_loss": 3.068687915802002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26991,
        "tokens": 14151057408,
        "learning_rate": 7.67256638835209e-05,
        "gradient_norm": 0.41099783778190613,
        "train_loss": 2.987818717956543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26992,
        "tokens": 14151581696,
        "learning_rate": 7.671573979060336e-05,
        "gradient_norm": 0.39782607555389404,
        "train_loss": 3.0463757514953613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26993,
        "tokens": 14152105984,
        "learning_rate": 7.670581854871591e-05,
        "gradient_norm": 0.41295087337493896,
        "train_loss": 3.0051984786987305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26994,
        "tokens": 14152630272,
        "learning_rate": 7.669590015797017e-05,
        "gradient_norm": 0.41898593306541443,
        "train_loss": 3.054649829864502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26995,
        "tokens": 14153154560,
        "learning_rate": 7.668598461847784e-05,
        "gradient_norm": 0.40230298042297363,
        "train_loss": 2.957925796508789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26996,
        "tokens": 14153678848,
        "learning_rate": 7.667607193035056e-05,
        "gradient_norm": 0.4445829689502716,
        "train_loss": 3.0705904960632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26997,
        "tokens": 14154203136,
        "learning_rate": 7.666616209369983e-05,
        "gradient_norm": 0.4494219422340393,
        "train_loss": 3.0156209468841553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26998,
        "tokens": 14154727424,
        "learning_rate": 7.665625510863726e-05,
        "gradient_norm": 0.43885523080825806,
        "train_loss": 3.090545415878296,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 26999,
        "tokens": 14155251712,
        "learning_rate": 7.66463509752743e-05,
        "gradient_norm": 0.44237396121025085,
        "train_loss": 2.9867422580718994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27000,
        "tokens": 14155776000,
        "learning_rate": 7.66364496937225e-05,
        "gradient_norm": 0.3999965190887451,
        "train_loss": 3.038365364074707,
        "val_loss": 2.9676671028137207,
        "hellaswag_acc": 0.28530174493789673,
        "hellaswag_acc_norm": 0.2981477677822113
    },
    {
        "step": 27001,
        "tokens": 14156300288,
        "learning_rate": 7.662655126409329e-05,
        "gradient_norm": 0.4304250180721283,
        "train_loss": 2.986146926879883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27002,
        "tokens": 14156824576,
        "learning_rate": 7.661665568649808e-05,
        "gradient_norm": 0.4158187210559845,
        "train_loss": 2.999401092529297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27003,
        "tokens": 14157348864,
        "learning_rate": 7.660676296104823e-05,
        "gradient_norm": 0.408433198928833,
        "train_loss": 3.056555986404419,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27004,
        "tokens": 14157873152,
        "learning_rate": 7.659687308785517e-05,
        "gradient_norm": 0.41476497054100037,
        "train_loss": 3.042562961578369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27005,
        "tokens": 14158397440,
        "learning_rate": 7.658698606703017e-05,
        "gradient_norm": 0.3842887282371521,
        "train_loss": 3.01466703414917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27006,
        "tokens": 14158921728,
        "learning_rate": 7.65771018986845e-05,
        "gradient_norm": 0.4170819818973541,
        "train_loss": 3.066822052001953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27007,
        "tokens": 14159446016,
        "learning_rate": 7.656722058292947e-05,
        "gradient_norm": 0.3935735821723938,
        "train_loss": 3.000594139099121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27008,
        "tokens": 14159970304,
        "learning_rate": 7.655734211987627e-05,
        "gradient_norm": 0.46728792786598206,
        "train_loss": 2.997819423675537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27009,
        "tokens": 14160494592,
        "learning_rate": 7.654746650963615e-05,
        "gradient_norm": 0.4159090220928192,
        "train_loss": 3.028805732727051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27010,
        "tokens": 14161018880,
        "learning_rate": 7.653759375232017e-05,
        "gradient_norm": 0.46492794156074524,
        "train_loss": 3.0029053688049316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27011,
        "tokens": 14161543168,
        "learning_rate": 7.65277238480396e-05,
        "gradient_norm": 0.40946975350379944,
        "train_loss": 2.9977967739105225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27012,
        "tokens": 14162067456,
        "learning_rate": 7.651785679690538e-05,
        "gradient_norm": 0.45610177516937256,
        "train_loss": 3.031816005706787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27013,
        "tokens": 14162591744,
        "learning_rate": 7.650799259902869e-05,
        "gradient_norm": 0.41422685980796814,
        "train_loss": 3.059598207473755,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27014,
        "tokens": 14163116032,
        "learning_rate": 7.649813125452053e-05,
        "gradient_norm": 0.4183356761932373,
        "train_loss": 2.9994912147521973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27015,
        "tokens": 14163640320,
        "learning_rate": 7.64882727634919e-05,
        "gradient_norm": 0.42487969994544983,
        "train_loss": 3.046018123626709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27016,
        "tokens": 14164164608,
        "learning_rate": 7.647841712605376e-05,
        "gradient_norm": 0.400195449590683,
        "train_loss": 2.980372667312622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27017,
        "tokens": 14164688896,
        "learning_rate": 7.64685643423171e-05,
        "gradient_norm": 0.43382561206817627,
        "train_loss": 3.012383460998535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27018,
        "tokens": 14165213184,
        "learning_rate": 7.645871441239273e-05,
        "gradient_norm": 0.41170206665992737,
        "train_loss": 3.004179000854492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27019,
        "tokens": 14165737472,
        "learning_rate": 7.644886733639162e-05,
        "gradient_norm": 0.4260779321193695,
        "train_loss": 3.006155490875244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27020,
        "tokens": 14166261760,
        "learning_rate": 7.643902311442452e-05,
        "gradient_norm": 0.39517849683761597,
        "train_loss": 3.0550472736358643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27021,
        "tokens": 14166786048,
        "learning_rate": 7.642918174660234e-05,
        "gradient_norm": 0.4200632572174072,
        "train_loss": 3.0032620429992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27022,
        "tokens": 14167310336,
        "learning_rate": 7.641934323303574e-05,
        "gradient_norm": 0.4093576967716217,
        "train_loss": 2.997250556945801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27023,
        "tokens": 14167834624,
        "learning_rate": 7.64095075738356e-05,
        "gradient_norm": 0.44428199529647827,
        "train_loss": 3.0715885162353516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27024,
        "tokens": 14168358912,
        "learning_rate": 7.63996747691125e-05,
        "gradient_norm": 0.40433982014656067,
        "train_loss": 3.028879404067993,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27025,
        "tokens": 14168883200,
        "learning_rate": 7.638984481897723e-05,
        "gradient_norm": 0.4249102473258972,
        "train_loss": 2.901118516921997,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27026,
        "tokens": 14169407488,
        "learning_rate": 7.638001772354037e-05,
        "gradient_norm": 0.4431091547012329,
        "train_loss": 2.9905786514282227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27027,
        "tokens": 14169931776,
        "learning_rate": 7.637019348291257e-05,
        "gradient_norm": 0.41981035470962524,
        "train_loss": 3.0278215408325195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27028,
        "tokens": 14170456064,
        "learning_rate": 7.636037209720435e-05,
        "gradient_norm": 0.4665500521659851,
        "train_loss": 2.9822120666503906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27029,
        "tokens": 14170980352,
        "learning_rate": 7.635055356652637e-05,
        "gradient_norm": 0.44752299785614014,
        "train_loss": 2.9955849647521973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27030,
        "tokens": 14171504640,
        "learning_rate": 7.634073789098905e-05,
        "gradient_norm": 0.41585907340049744,
        "train_loss": 3.0103418827056885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27031,
        "tokens": 14172028928,
        "learning_rate": 7.633092507070296e-05,
        "gradient_norm": 0.4276343584060669,
        "train_loss": 2.9731664657592773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27032,
        "tokens": 14172553216,
        "learning_rate": 7.63211151057785e-05,
        "gradient_norm": 0.4092371463775635,
        "train_loss": 3.0973801612854004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27033,
        "tokens": 14173077504,
        "learning_rate": 7.63113079963261e-05,
        "gradient_norm": 0.40524476766586304,
        "train_loss": 3.043487787246704,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27034,
        "tokens": 14173601792,
        "learning_rate": 7.630150374245614e-05,
        "gradient_norm": 0.5185102224349976,
        "train_loss": 3.122967004776001,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27035,
        "tokens": 14174126080,
        "learning_rate": 7.629170234427901e-05,
        "gradient_norm": 0.4382702708244324,
        "train_loss": 3.014106273651123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27036,
        "tokens": 14174650368,
        "learning_rate": 7.628190380190506e-05,
        "gradient_norm": 0.4262436330318451,
        "train_loss": 3.043323516845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27037,
        "tokens": 14175174656,
        "learning_rate": 7.62721081154445e-05,
        "gradient_norm": 0.44942647218704224,
        "train_loss": 3.0195701122283936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27038,
        "tokens": 14175698944,
        "learning_rate": 7.62623152850077e-05,
        "gradient_norm": 0.3963082730770111,
        "train_loss": 3.0467429161071777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27039,
        "tokens": 14176223232,
        "learning_rate": 7.625252531070478e-05,
        "gradient_norm": 0.4131753444671631,
        "train_loss": 2.962758779525757,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27040,
        "tokens": 14176747520,
        "learning_rate": 7.624273819264604e-05,
        "gradient_norm": 0.40233927965164185,
        "train_loss": 3.0238494873046875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27041,
        "tokens": 14177271808,
        "learning_rate": 7.623295393094156e-05,
        "gradient_norm": 0.40338411927223206,
        "train_loss": 3.005871057510376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27042,
        "tokens": 14177796096,
        "learning_rate": 7.622317252570153e-05,
        "gradient_norm": 0.4481317698955536,
        "train_loss": 3.0656702518463135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27043,
        "tokens": 14178320384,
        "learning_rate": 7.621339397703602e-05,
        "gradient_norm": 0.4125446379184723,
        "train_loss": 2.972618818283081,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27044,
        "tokens": 14178844672,
        "learning_rate": 7.620361828505514e-05,
        "gradient_norm": 0.41743960976600647,
        "train_loss": 3.054079055786133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27045,
        "tokens": 14179368960,
        "learning_rate": 7.61938454498689e-05,
        "gradient_norm": 0.3852371275424957,
        "train_loss": 3.003737688064575,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27046,
        "tokens": 14179893248,
        "learning_rate": 7.618407547158726e-05,
        "gradient_norm": 0.42658013105392456,
        "train_loss": 2.96575665473938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27047,
        "tokens": 14180417536,
        "learning_rate": 7.617430835032029e-05,
        "gradient_norm": 0.3974902629852295,
        "train_loss": 3.011841297149658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27048,
        "tokens": 14180941824,
        "learning_rate": 7.616454408617786e-05,
        "gradient_norm": 0.413909375667572,
        "train_loss": 2.9773473739624023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27049,
        "tokens": 14181466112,
        "learning_rate": 7.615478267926992e-05,
        "gradient_norm": 0.4746316373348236,
        "train_loss": 3.0129401683807373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27050,
        "tokens": 14181990400,
        "learning_rate": 7.614502412970629e-05,
        "gradient_norm": 0.3910626769065857,
        "train_loss": 3.0095479488372803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27051,
        "tokens": 14182514688,
        "learning_rate": 7.613526843759691e-05,
        "gradient_norm": 0.3883329927921295,
        "train_loss": 3.011540651321411,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27052,
        "tokens": 14183038976,
        "learning_rate": 7.612551560305147e-05,
        "gradient_norm": 0.41679954528808594,
        "train_loss": 3.0752453804016113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27053,
        "tokens": 14183563264,
        "learning_rate": 7.611576562617986e-05,
        "gradient_norm": 0.4292467534542084,
        "train_loss": 3.0282511711120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27054,
        "tokens": 14184087552,
        "learning_rate": 7.610601850709175e-05,
        "gradient_norm": 0.43302974104881287,
        "train_loss": 3.0522241592407227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27055,
        "tokens": 14184611840,
        "learning_rate": 7.60962742458969e-05,
        "gradient_norm": 0.3929217755794525,
        "train_loss": 3.0141122341156006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27056,
        "tokens": 14185136128,
        "learning_rate": 7.608653284270501e-05,
        "gradient_norm": 0.4363133907318115,
        "train_loss": 3.02927827835083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27057,
        "tokens": 14185660416,
        "learning_rate": 7.607679429762565e-05,
        "gradient_norm": 0.36406514048576355,
        "train_loss": 2.990023136138916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27058,
        "tokens": 14186184704,
        "learning_rate": 7.606705861076856e-05,
        "gradient_norm": 0.37795957922935486,
        "train_loss": 3.0080695152282715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27059,
        "tokens": 14186708992,
        "learning_rate": 7.60573257822432e-05,
        "gradient_norm": 0.42026129364967346,
        "train_loss": 3.0204052925109863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27060,
        "tokens": 14187233280,
        "learning_rate": 7.604759581215924e-05,
        "gradient_norm": 0.4227248430252075,
        "train_loss": 2.992623805999756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27061,
        "tokens": 14187757568,
        "learning_rate": 7.603786870062609e-05,
        "gradient_norm": 0.3969065546989441,
        "train_loss": 3.017475128173828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27062,
        "tokens": 14188281856,
        "learning_rate": 7.602814444775337e-05,
        "gradient_norm": 0.38196036219596863,
        "train_loss": 3.04648756980896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27063,
        "tokens": 14188806144,
        "learning_rate": 7.601842305365042e-05,
        "gradient_norm": 0.39069172739982605,
        "train_loss": 3.0288033485412598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27064,
        "tokens": 14189330432,
        "learning_rate": 7.600870451842673e-05,
        "gradient_norm": 0.3899804651737213,
        "train_loss": 2.985060691833496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27065,
        "tokens": 14189854720,
        "learning_rate": 7.599898884219168e-05,
        "gradient_norm": 0.39535126090049744,
        "train_loss": 2.996915102005005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27066,
        "tokens": 14190379008,
        "learning_rate": 7.598927602505459e-05,
        "gradient_norm": 0.37550708651542664,
        "train_loss": 3.0001087188720703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27067,
        "tokens": 14190903296,
        "learning_rate": 7.59795660671249e-05,
        "gradient_norm": 0.40493547916412354,
        "train_loss": 3.01330304145813,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27068,
        "tokens": 14191427584,
        "learning_rate": 7.596985896851177e-05,
        "gradient_norm": 0.38892513513565063,
        "train_loss": 3.021796941757202,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27069,
        "tokens": 14191951872,
        "learning_rate": 7.59601547293246e-05,
        "gradient_norm": 0.36887189745903015,
        "train_loss": 2.9924540519714355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27070,
        "tokens": 14192476160,
        "learning_rate": 7.59504533496725e-05,
        "gradient_norm": 0.4071723222732544,
        "train_loss": 2.978095531463623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27071,
        "tokens": 14193000448,
        "learning_rate": 7.59407548296648e-05,
        "gradient_norm": 0.42465999722480774,
        "train_loss": 3.016887664794922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27072,
        "tokens": 14193524736,
        "learning_rate": 7.593105916941054e-05,
        "gradient_norm": 0.4133242666721344,
        "train_loss": 2.9901034832000732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27073,
        "tokens": 14194049024,
        "learning_rate": 7.592136636901892e-05,
        "gradient_norm": 0.4201730191707611,
        "train_loss": 3.0207679271698,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27074,
        "tokens": 14194573312,
        "learning_rate": 7.591167642859905e-05,
        "gradient_norm": 0.45198166370391846,
        "train_loss": 3.02020263671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27075,
        "tokens": 14195097600,
        "learning_rate": 7.590198934825998e-05,
        "gradient_norm": 0.4188266396522522,
        "train_loss": 2.9801831245422363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27076,
        "tokens": 14195621888,
        "learning_rate": 7.589230512811079e-05,
        "gradient_norm": 0.5074537992477417,
        "train_loss": 3.0693624019622803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27077,
        "tokens": 14196146176,
        "learning_rate": 7.588262376826042e-05,
        "gradient_norm": 0.4111267924308777,
        "train_loss": 3.014035701751709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27078,
        "tokens": 14196670464,
        "learning_rate": 7.587294526881791e-05,
        "gradient_norm": 0.3998531997203827,
        "train_loss": 3.035320281982422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27079,
        "tokens": 14197194752,
        "learning_rate": 7.586326962989217e-05,
        "gradient_norm": 0.4940393567085266,
        "train_loss": 2.9885871410369873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27080,
        "tokens": 14197719040,
        "learning_rate": 7.585359685159214e-05,
        "gradient_norm": 0.4198552370071411,
        "train_loss": 3.043285608291626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27081,
        "tokens": 14198243328,
        "learning_rate": 7.584392693402664e-05,
        "gradient_norm": 0.4328995943069458,
        "train_loss": 2.9687178134918213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27082,
        "tokens": 14198767616,
        "learning_rate": 7.58342598773046e-05,
        "gradient_norm": 0.4381738007068634,
        "train_loss": 3.064541816711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27083,
        "tokens": 14199291904,
        "learning_rate": 7.582459568153475e-05,
        "gradient_norm": 0.39080753922462463,
        "train_loss": 3.002492904663086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27084,
        "tokens": 14199816192,
        "learning_rate": 7.581493434682596e-05,
        "gradient_norm": 0.41983968019485474,
        "train_loss": 3.019761085510254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27085,
        "tokens": 14200340480,
        "learning_rate": 7.580527587328688e-05,
        "gradient_norm": 0.4466162323951721,
        "train_loss": 3.015562057495117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27086,
        "tokens": 14200864768,
        "learning_rate": 7.579562026102629e-05,
        "gradient_norm": 0.43682143092155457,
        "train_loss": 3.0080742835998535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27087,
        "tokens": 14201389056,
        "learning_rate": 7.57859675101529e-05,
        "gradient_norm": 0.3985852003097534,
        "train_loss": 3.050828695297241,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27088,
        "tokens": 14201913344,
        "learning_rate": 7.57763176207753e-05,
        "gradient_norm": 0.418798565864563,
        "train_loss": 3.0619759559631348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27089,
        "tokens": 14202437632,
        "learning_rate": 7.57666705930022e-05,
        "gradient_norm": 0.3794887363910675,
        "train_loss": 2.9522814750671387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27090,
        "tokens": 14202961920,
        "learning_rate": 7.575702642694207e-05,
        "gradient_norm": 0.47575753927230835,
        "train_loss": 3.0254721641540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27091,
        "tokens": 14203486208,
        "learning_rate": 7.574738512270358e-05,
        "gradient_norm": 0.43746015429496765,
        "train_loss": 2.9956815242767334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27092,
        "tokens": 14204010496,
        "learning_rate": 7.573774668039518e-05,
        "gradient_norm": 0.41542547941207886,
        "train_loss": 3.0183043479919434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27093,
        "tokens": 14204534784,
        "learning_rate": 7.572811110012539e-05,
        "gradient_norm": 0.4504733383655548,
        "train_loss": 3.027086019515991,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27094,
        "tokens": 14205059072,
        "learning_rate": 7.571847838200264e-05,
        "gradient_norm": 0.4527190625667572,
        "train_loss": 3.001457691192627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27095,
        "tokens": 14205583360,
        "learning_rate": 7.57088485261354e-05,
        "gradient_norm": 0.4229501783847809,
        "train_loss": 3.0616512298583984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27096,
        "tokens": 14206107648,
        "learning_rate": 7.569922153263208e-05,
        "gradient_norm": 0.4282473623752594,
        "train_loss": 3.03975772857666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27097,
        "tokens": 14206631936,
        "learning_rate": 7.568959740160097e-05,
        "gradient_norm": 0.39732369780540466,
        "train_loss": 2.997098445892334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27098,
        "tokens": 14207156224,
        "learning_rate": 7.56799761331505e-05,
        "gradient_norm": 0.40981361269950867,
        "train_loss": 2.952650785446167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27099,
        "tokens": 14207680512,
        "learning_rate": 7.567035772738887e-05,
        "gradient_norm": 0.45053571462631226,
        "train_loss": 3.0316524505615234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27100,
        "tokens": 14208204800,
        "learning_rate": 7.566074218442445e-05,
        "gradient_norm": 0.39359575510025024,
        "train_loss": 3.006697177886963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27101,
        "tokens": 14208729088,
        "learning_rate": 7.565112950436537e-05,
        "gradient_norm": 0.40024277567863464,
        "train_loss": 2.990368366241455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27102,
        "tokens": 14209253376,
        "learning_rate": 7.564151968731991e-05,
        "gradient_norm": 0.4308854639530182,
        "train_loss": 3.016199827194214,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27103,
        "tokens": 14209777664,
        "learning_rate": 7.56319127333962e-05,
        "gradient_norm": 0.4055299162864685,
        "train_loss": 3.0111160278320312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27104,
        "tokens": 14210301952,
        "learning_rate": 7.56223086427024e-05,
        "gradient_norm": 0.3818776309490204,
        "train_loss": 3.0041427612304688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27105,
        "tokens": 14210826240,
        "learning_rate": 7.561270741534659e-05,
        "gradient_norm": 0.4254147708415985,
        "train_loss": 3.0173473358154297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27106,
        "tokens": 14211350528,
        "learning_rate": 7.560310905143684e-05,
        "gradient_norm": 0.39642733335494995,
        "train_loss": 3.0013718605041504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27107,
        "tokens": 14211874816,
        "learning_rate": 7.559351355108126e-05,
        "gradient_norm": 0.4030502140522003,
        "train_loss": 3.011338949203491,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27108,
        "tokens": 14212399104,
        "learning_rate": 7.558392091438778e-05,
        "gradient_norm": 0.39976760745048523,
        "train_loss": 3.0287625789642334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27109,
        "tokens": 14212923392,
        "learning_rate": 7.557433114146443e-05,
        "gradient_norm": 0.41510847210884094,
        "train_loss": 3.023610830307007,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27110,
        "tokens": 14213447680,
        "learning_rate": 7.556474423241911e-05,
        "gradient_norm": 0.4230039715766907,
        "train_loss": 2.986976146697998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27111,
        "tokens": 14213971968,
        "learning_rate": 7.555516018735979e-05,
        "gradient_norm": 0.4488975405693054,
        "train_loss": 2.9559736251831055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27112,
        "tokens": 14214496256,
        "learning_rate": 7.554557900639426e-05,
        "gradient_norm": 0.4137305021286011,
        "train_loss": 3.01774263381958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27113,
        "tokens": 14215020544,
        "learning_rate": 7.553600068963048e-05,
        "gradient_norm": 0.46989479660987854,
        "train_loss": 3.0602169036865234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27114,
        "tokens": 14215544832,
        "learning_rate": 7.552642523717615e-05,
        "gradient_norm": 0.4284338653087616,
        "train_loss": 2.986785888671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27115,
        "tokens": 14216069120,
        "learning_rate": 7.551685264913919e-05,
        "gradient_norm": 0.43478918075561523,
        "train_loss": 3.0248665809631348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27116,
        "tokens": 14216593408,
        "learning_rate": 7.55072829256272e-05,
        "gradient_norm": 0.42542555928230286,
        "train_loss": 3.0544824600219727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27117,
        "tokens": 14217117696,
        "learning_rate": 7.549771606674802e-05,
        "gradient_norm": 0.46245554089546204,
        "train_loss": 3.049041748046875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27118,
        "tokens": 14217641984,
        "learning_rate": 7.548815207260927e-05,
        "gradient_norm": 0.4938127398490906,
        "train_loss": 3.1247076988220215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27119,
        "tokens": 14218166272,
        "learning_rate": 7.547859094331866e-05,
        "gradient_norm": 0.46718746423721313,
        "train_loss": 3.0322020053863525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27120,
        "tokens": 14218690560,
        "learning_rate": 7.546903267898374e-05,
        "gradient_norm": 0.4743618965148926,
        "train_loss": 3.0525479316711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27121,
        "tokens": 14219214848,
        "learning_rate": 7.545947727971217e-05,
        "gradient_norm": 0.448544442653656,
        "train_loss": 3.028536319732666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27122,
        "tokens": 14219739136,
        "learning_rate": 7.544992474561144e-05,
        "gradient_norm": 0.44400060176849365,
        "train_loss": 3.038983106613159,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27123,
        "tokens": 14220263424,
        "learning_rate": 7.544037507678916e-05,
        "gradient_norm": 0.44156959652900696,
        "train_loss": 3.0198986530303955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27124,
        "tokens": 14220787712,
        "learning_rate": 7.543082827335271e-05,
        "gradient_norm": 0.40661516785621643,
        "train_loss": 2.9966607093811035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27125,
        "tokens": 14221312000,
        "learning_rate": 7.542128433540968e-05,
        "gradient_norm": 0.42852169275283813,
        "train_loss": 3.0480713844299316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27126,
        "tokens": 14221836288,
        "learning_rate": 7.54117432630674e-05,
        "gradient_norm": 0.42684048414230347,
        "train_loss": 3.0138282775878906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27127,
        "tokens": 14222360576,
        "learning_rate": 7.540220505643333e-05,
        "gradient_norm": 0.42933809757232666,
        "train_loss": 2.9838738441467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27128,
        "tokens": 14222884864,
        "learning_rate": 7.539266971561475e-05,
        "gradient_norm": 0.4494793713092804,
        "train_loss": 3.0074918270111084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27129,
        "tokens": 14223409152,
        "learning_rate": 7.538313724071911e-05,
        "gradient_norm": 0.4108365476131439,
        "train_loss": 3.029231548309326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27130,
        "tokens": 14223933440,
        "learning_rate": 7.537360763185362e-05,
        "gradient_norm": 0.4545725882053375,
        "train_loss": 3.0697250366210938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27131,
        "tokens": 14224457728,
        "learning_rate": 7.536408088912559e-05,
        "gradient_norm": 0.45428037643432617,
        "train_loss": 3.0083184242248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27132,
        "tokens": 14224982016,
        "learning_rate": 7.53545570126422e-05,
        "gradient_norm": 0.4630100727081299,
        "train_loss": 3.02827787399292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27133,
        "tokens": 14225506304,
        "learning_rate": 7.534503600251075e-05,
        "gradient_norm": 0.42441949248313904,
        "train_loss": 2.959320068359375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27134,
        "tokens": 14226030592,
        "learning_rate": 7.533551785883833e-05,
        "gradient_norm": 0.4671333134174347,
        "train_loss": 3.007779836654663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27135,
        "tokens": 14226554880,
        "learning_rate": 7.532600258173209e-05,
        "gradient_norm": 0.4345174729824066,
        "train_loss": 2.9893910884857178,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27136,
        "tokens": 14227079168,
        "learning_rate": 7.531649017129916e-05,
        "gradient_norm": 0.5199301838874817,
        "train_loss": 3.027226448059082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27137,
        "tokens": 14227603456,
        "learning_rate": 7.53069806276466e-05,
        "gradient_norm": 0.4723026752471924,
        "train_loss": 2.8782260417938232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27138,
        "tokens": 14228127744,
        "learning_rate": 7.529747395088148e-05,
        "gradient_norm": 0.42547154426574707,
        "train_loss": 2.993825912475586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27139,
        "tokens": 14228652032,
        "learning_rate": 7.528797014111078e-05,
        "gradient_norm": 0.4063272476196289,
        "train_loss": 2.9942939281463623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27140,
        "tokens": 14229176320,
        "learning_rate": 7.527846919844149e-05,
        "gradient_norm": 0.4257737398147583,
        "train_loss": 3.01482892036438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27141,
        "tokens": 14229700608,
        "learning_rate": 7.526897112298052e-05,
        "gradient_norm": 0.452932208776474,
        "train_loss": 2.985110282897949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27142,
        "tokens": 14230224896,
        "learning_rate": 7.525947591483484e-05,
        "gradient_norm": 0.3924298882484436,
        "train_loss": 2.9729673862457275,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27143,
        "tokens": 14230749184,
        "learning_rate": 7.524998357411125e-05,
        "gradient_norm": 0.4480036199092865,
        "train_loss": 3.052732229232788,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27144,
        "tokens": 14231273472,
        "learning_rate": 7.524049410091671e-05,
        "gradient_norm": 0.4054979979991913,
        "train_loss": 2.997560739517212,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27145,
        "tokens": 14231797760,
        "learning_rate": 7.523100749535792e-05,
        "gradient_norm": 0.4839310348033905,
        "train_loss": 3.057441234588623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27146,
        "tokens": 14232322048,
        "learning_rate": 7.522152375754172e-05,
        "gradient_norm": 0.46578821539878845,
        "train_loss": 2.9115347862243652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27147,
        "tokens": 14232846336,
        "learning_rate": 7.521204288757493e-05,
        "gradient_norm": 0.46942996978759766,
        "train_loss": 3.0232021808624268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27148,
        "tokens": 14233370624,
        "learning_rate": 7.520256488556412e-05,
        "gradient_norm": 0.43936508893966675,
        "train_loss": 3.0185136795043945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27149,
        "tokens": 14233894912,
        "learning_rate": 7.519308975161612e-05,
        "gradient_norm": 0.39227616786956787,
        "train_loss": 2.9824023246765137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27150,
        "tokens": 14234419200,
        "learning_rate": 7.518361748583747e-05,
        "gradient_norm": 0.4391155540943146,
        "train_loss": 3.0214507579803467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27151,
        "tokens": 14234943488,
        "learning_rate": 7.517414808833488e-05,
        "gradient_norm": 0.41682571172714233,
        "train_loss": 3.0018906593322754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27152,
        "tokens": 14235467776,
        "learning_rate": 7.516468155921487e-05,
        "gradient_norm": 0.4338666498661041,
        "train_loss": 3.055135726928711,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27153,
        "tokens": 14235992064,
        "learning_rate": 7.515521789858409e-05,
        "gradient_norm": 0.47792911529541016,
        "train_loss": 3.043257236480713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27154,
        "tokens": 14236516352,
        "learning_rate": 7.514575710654894e-05,
        "gradient_norm": 0.4890628457069397,
        "train_loss": 3.01220703125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27155,
        "tokens": 14237040640,
        "learning_rate": 7.513629918321597e-05,
        "gradient_norm": 0.41271117329597473,
        "train_loss": 3.059623956680298,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27156,
        "tokens": 14237564928,
        "learning_rate": 7.512684412869171e-05,
        "gradient_norm": 0.40044257044792175,
        "train_loss": 3.005715847015381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27157,
        "tokens": 14238089216,
        "learning_rate": 7.511739194308247e-05,
        "gradient_norm": 0.44003865122795105,
        "train_loss": 3.0704054832458496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27158,
        "tokens": 14238613504,
        "learning_rate": 7.510794262649473e-05,
        "gradient_norm": 0.40903547406196594,
        "train_loss": 3.01956844329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27159,
        "tokens": 14239137792,
        "learning_rate": 7.50984961790348e-05,
        "gradient_norm": 0.47288182377815247,
        "train_loss": 3.022904872894287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27160,
        "tokens": 14239662080,
        "learning_rate": 7.50890526008091e-05,
        "gradient_norm": 0.4386920630931854,
        "train_loss": 3.0685672760009766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27161,
        "tokens": 14240186368,
        "learning_rate": 7.507961189192381e-05,
        "gradient_norm": 0.4338007867336273,
        "train_loss": 3.020270824432373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27162,
        "tokens": 14240710656,
        "learning_rate": 7.50701740524853e-05,
        "gradient_norm": 0.42308518290519714,
        "train_loss": 3.033608913421631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27163,
        "tokens": 14241234944,
        "learning_rate": 7.50607390825997e-05,
        "gradient_norm": 0.492522269487381,
        "train_loss": 2.9687442779541016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27164,
        "tokens": 14241759232,
        "learning_rate": 7.505130698237333e-05,
        "gradient_norm": 0.39061301946640015,
        "train_loss": 2.973680019378662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27165,
        "tokens": 14242283520,
        "learning_rate": 7.504187775191228e-05,
        "gradient_norm": 0.5833048224449158,
        "train_loss": 3.004998207092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27166,
        "tokens": 14242807808,
        "learning_rate": 7.503245139132269e-05,
        "gradient_norm": 0.4645426571369171,
        "train_loss": 3.0582618713378906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27167,
        "tokens": 14243332096,
        "learning_rate": 7.50230279007107e-05,
        "gradient_norm": 0.4430720806121826,
        "train_loss": 3.041168212890625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27168,
        "tokens": 14243856384,
        "learning_rate": 7.501360728018238e-05,
        "gradient_norm": 0.40684956312179565,
        "train_loss": 3.044818878173828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27169,
        "tokens": 14244380672,
        "learning_rate": 7.500418952984377e-05,
        "gradient_norm": 0.4229850769042969,
        "train_loss": 2.9948251247406006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27170,
        "tokens": 14244904960,
        "learning_rate": 7.49947746498008e-05,
        "gradient_norm": 0.5305711627006531,
        "train_loss": 3.1075408458709717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27171,
        "tokens": 14245429248,
        "learning_rate": 7.498536264015959e-05,
        "gradient_norm": 0.4299214780330658,
        "train_loss": 3.0486605167388916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27172,
        "tokens": 14245953536,
        "learning_rate": 7.497595350102597e-05,
        "gradient_norm": 0.4345932900905609,
        "train_loss": 3.0246741771698,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27173,
        "tokens": 14246477824,
        "learning_rate": 7.49665472325059e-05,
        "gradient_norm": 0.43466198444366455,
        "train_loss": 3.025499105453491,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27174,
        "tokens": 14247002112,
        "learning_rate": 7.495714383470524e-05,
        "gradient_norm": 0.4191673994064331,
        "train_loss": 3.0773539543151855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27175,
        "tokens": 14247526400,
        "learning_rate": 7.494774330772983e-05,
        "gradient_norm": 0.43290624022483826,
        "train_loss": 3.0489516258239746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27176,
        "tokens": 14248050688,
        "learning_rate": 7.493834565168553e-05,
        "gradient_norm": 0.4120687246322632,
        "train_loss": 3.0012259483337402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27177,
        "tokens": 14248574976,
        "learning_rate": 7.492895086667808e-05,
        "gradient_norm": 0.40224704146385193,
        "train_loss": 3.0689520835876465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27178,
        "tokens": 14249099264,
        "learning_rate": 7.491955895281325e-05,
        "gradient_norm": 0.4204586446285248,
        "train_loss": 3.001505136489868,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27179,
        "tokens": 14249623552,
        "learning_rate": 7.491016991019674e-05,
        "gradient_norm": 0.41358497738838196,
        "train_loss": 3.0690531730651855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27180,
        "tokens": 14250147840,
        "learning_rate": 7.490078373893427e-05,
        "gradient_norm": 0.40856650471687317,
        "train_loss": 3.0130136013031006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27181,
        "tokens": 14250672128,
        "learning_rate": 7.489140043913142e-05,
        "gradient_norm": 0.4228276312351227,
        "train_loss": 3.063542366027832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27182,
        "tokens": 14251196416,
        "learning_rate": 7.488202001089392e-05,
        "gradient_norm": 0.40791425108909607,
        "train_loss": 2.9991700649261475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27183,
        "tokens": 14251720704,
        "learning_rate": 7.487264245432726e-05,
        "gradient_norm": 0.4259307384490967,
        "train_loss": 3.035905361175537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27184,
        "tokens": 14252244992,
        "learning_rate": 7.486326776953706e-05,
        "gradient_norm": 0.46323496103286743,
        "train_loss": 3.002103090286255,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27185,
        "tokens": 14252769280,
        "learning_rate": 7.485389595662878e-05,
        "gradient_norm": 0.437296062707901,
        "train_loss": 3.0242276191711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27186,
        "tokens": 14253293568,
        "learning_rate": 7.484452701570796e-05,
        "gradient_norm": 0.4287015497684479,
        "train_loss": 3.0098798274993896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27187,
        "tokens": 14253817856,
        "learning_rate": 7.483516094688007e-05,
        "gradient_norm": 0.38685402274131775,
        "train_loss": 2.999751567840576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27188,
        "tokens": 14254342144,
        "learning_rate": 7.482579775025046e-05,
        "gradient_norm": 0.5016672611236572,
        "train_loss": 3.0435750484466553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27189,
        "tokens": 14254866432,
        "learning_rate": 7.481643742592465e-05,
        "gradient_norm": 0.40889772772789,
        "train_loss": 3.0225424766540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27190,
        "tokens": 14255390720,
        "learning_rate": 7.48070799740079e-05,
        "gradient_norm": 0.4236467778682709,
        "train_loss": 2.9962728023529053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27191,
        "tokens": 14255915008,
        "learning_rate": 7.479772539460557e-05,
        "gradient_norm": 0.4192586839199066,
        "train_loss": 2.9659013748168945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27192,
        "tokens": 14256439296,
        "learning_rate": 7.478837368782296e-05,
        "gradient_norm": 0.47628143429756165,
        "train_loss": 3.13157320022583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27193,
        "tokens": 14256963584,
        "learning_rate": 7.477902485376535e-05,
        "gradient_norm": 0.5069445967674255,
        "train_loss": 3.0154051780700684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27194,
        "tokens": 14257487872,
        "learning_rate": 7.476967889253793e-05,
        "gradient_norm": 0.48777875304222107,
        "train_loss": 2.9987683296203613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27195,
        "tokens": 14258012160,
        "learning_rate": 7.476033580424591e-05,
        "gradient_norm": 0.5026259422302246,
        "train_loss": 3.0171871185302734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27196,
        "tokens": 14258536448,
        "learning_rate": 7.475099558899452e-05,
        "gradient_norm": 0.38972631096839905,
        "train_loss": 2.9614226818084717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27197,
        "tokens": 14259060736,
        "learning_rate": 7.474165824688882e-05,
        "gradient_norm": 0.45284897089004517,
        "train_loss": 3.004318952560425,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27198,
        "tokens": 14259585024,
        "learning_rate": 7.473232377803397e-05,
        "gradient_norm": 0.4455624520778656,
        "train_loss": 2.985875129699707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27199,
        "tokens": 14260109312,
        "learning_rate": 7.4722992182535e-05,
        "gradient_norm": 0.3997514545917511,
        "train_loss": 3.0362629890441895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27200,
        "tokens": 14260633600,
        "learning_rate": 7.471366346049699e-05,
        "gradient_norm": 0.38532882928848267,
        "train_loss": 2.998147487640381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27201,
        "tokens": 14261157888,
        "learning_rate": 7.470433761202488e-05,
        "gradient_norm": 0.40641698241233826,
        "train_loss": 3.0476465225219727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27202,
        "tokens": 14261682176,
        "learning_rate": 7.46950146372237e-05,
        "gradient_norm": 0.4144938588142395,
        "train_loss": 3.0072333812713623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27203,
        "tokens": 14262206464,
        "learning_rate": 7.468569453619839e-05,
        "gradient_norm": 0.39548459649086,
        "train_loss": 3.0421385765075684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27204,
        "tokens": 14262730752,
        "learning_rate": 7.467637730905385e-05,
        "gradient_norm": 0.36944258213043213,
        "train_loss": 2.9688830375671387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27205,
        "tokens": 14263255040,
        "learning_rate": 7.46670629558949e-05,
        "gradient_norm": 0.43226534128189087,
        "train_loss": 2.9949779510498047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27206,
        "tokens": 14263779328,
        "learning_rate": 7.465775147682647e-05,
        "gradient_norm": 0.42227238416671753,
        "train_loss": 3.046855926513672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27207,
        "tokens": 14264303616,
        "learning_rate": 7.464844287195338e-05,
        "gradient_norm": 0.4109715223312378,
        "train_loss": 2.9889135360717773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27208,
        "tokens": 14264827904,
        "learning_rate": 7.46391371413803e-05,
        "gradient_norm": 0.45954152941703796,
        "train_loss": 3.01186466217041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27209,
        "tokens": 14265352192,
        "learning_rate": 7.46298342852121e-05,
        "gradient_norm": 0.4261236786842346,
        "train_loss": 3.0155539512634277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27210,
        "tokens": 14265876480,
        "learning_rate": 7.46205343035534e-05,
        "gradient_norm": 0.4126073718070984,
        "train_loss": 2.960728168487549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27211,
        "tokens": 14266400768,
        "learning_rate": 7.461123719650898e-05,
        "gradient_norm": 0.4165205657482147,
        "train_loss": 3.011219024658203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27212,
        "tokens": 14266925056,
        "learning_rate": 7.460194296418338e-05,
        "gradient_norm": 0.441072553396225,
        "train_loss": 3.0265536308288574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27213,
        "tokens": 14267449344,
        "learning_rate": 7.459265160668134e-05,
        "gradient_norm": 0.4506080746650696,
        "train_loss": 3.0534372329711914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27214,
        "tokens": 14267973632,
        "learning_rate": 7.458336312410728e-05,
        "gradient_norm": 0.4197240173816681,
        "train_loss": 3.0065670013427734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27215,
        "tokens": 14268497920,
        "learning_rate": 7.457407751656591e-05,
        "gradient_norm": 0.4655112326145172,
        "train_loss": 2.95750093460083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27216,
        "tokens": 14269022208,
        "learning_rate": 7.456479478416173e-05,
        "gradient_norm": 0.3975456655025482,
        "train_loss": 2.999152898788452,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27217,
        "tokens": 14269546496,
        "learning_rate": 7.455551492699913e-05,
        "gradient_norm": 0.4319497048854828,
        "train_loss": 3.0108442306518555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27218,
        "tokens": 14270070784,
        "learning_rate": 7.45462379451827e-05,
        "gradient_norm": 0.4384850561618805,
        "train_loss": 3.033820629119873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27219,
        "tokens": 14270595072,
        "learning_rate": 7.453696383881672e-05,
        "gradient_norm": 0.4094902575016022,
        "train_loss": 3.032216787338257,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27220,
        "tokens": 14271119360,
        "learning_rate": 7.452769260800571e-05,
        "gradient_norm": 0.41065675020217896,
        "train_loss": 3.0132827758789062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27221,
        "tokens": 14271643648,
        "learning_rate": 7.451842425285391e-05,
        "gradient_norm": 0.40717941522598267,
        "train_loss": 3.03701114654541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27222,
        "tokens": 14272167936,
        "learning_rate": 7.45091587734658e-05,
        "gradient_norm": 0.398750364780426,
        "train_loss": 2.99599552154541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27223,
        "tokens": 14272692224,
        "learning_rate": 7.449989616994551e-05,
        "gradient_norm": 0.43099433183670044,
        "train_loss": 3.0940752029418945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27224,
        "tokens": 14273216512,
        "learning_rate": 7.449063644239743e-05,
        "gradient_norm": 0.42531707882881165,
        "train_loss": 3.007153272628784,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27225,
        "tokens": 14273740800,
        "learning_rate": 7.44813795909257e-05,
        "gradient_norm": 0.3762599527835846,
        "train_loss": 3.0243287086486816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27226,
        "tokens": 14274265088,
        "learning_rate": 7.447212561563457e-05,
        "gradient_norm": 0.4378886818885803,
        "train_loss": 2.98575758934021,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27227,
        "tokens": 14274789376,
        "learning_rate": 7.446287451662819e-05,
        "gradient_norm": 0.4043641984462738,
        "train_loss": 3.0139713287353516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27228,
        "tokens": 14275313664,
        "learning_rate": 7.44536262940107e-05,
        "gradient_norm": 0.3738459348678589,
        "train_loss": 3.0324113368988037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27229,
        "tokens": 14275837952,
        "learning_rate": 7.444438094788617e-05,
        "gradient_norm": 0.4118918180465698,
        "train_loss": 2.9962120056152344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27230,
        "tokens": 14276362240,
        "learning_rate": 7.443513847835872e-05,
        "gradient_norm": 0.3826696276664734,
        "train_loss": 3.0020463466644287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27231,
        "tokens": 14276886528,
        "learning_rate": 7.442589888553233e-05,
        "gradient_norm": 0.4604782164096832,
        "train_loss": 3.0609636306762695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27232,
        "tokens": 14277410816,
        "learning_rate": 7.441666216951106e-05,
        "gradient_norm": 0.42596742510795593,
        "train_loss": 3.0044426918029785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27233,
        "tokens": 14277935104,
        "learning_rate": 7.440742833039881e-05,
        "gradient_norm": 0.4095737636089325,
        "train_loss": 2.9827232360839844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27234,
        "tokens": 14278459392,
        "learning_rate": 7.439819736829959e-05,
        "gradient_norm": 0.4202219843864441,
        "train_loss": 2.9852418899536133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27235,
        "tokens": 14278983680,
        "learning_rate": 7.438896928331726e-05,
        "gradient_norm": 0.4809858202934265,
        "train_loss": 2.9390339851379395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27236,
        "tokens": 14279507968,
        "learning_rate": 7.437974407555573e-05,
        "gradient_norm": 0.501518964767456,
        "train_loss": 3.0925824642181396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27237,
        "tokens": 14280032256,
        "learning_rate": 7.437052174511878e-05,
        "gradient_norm": 0.4320662319660187,
        "train_loss": 3.0384891033172607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27238,
        "tokens": 14280556544,
        "learning_rate": 7.43613022921103e-05,
        "gradient_norm": 0.46066710352897644,
        "train_loss": 3.0123214721679688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27239,
        "tokens": 14281080832,
        "learning_rate": 7.4352085716634e-05,
        "gradient_norm": 0.4268200993537903,
        "train_loss": 3.0045790672302246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27240,
        "tokens": 14281605120,
        "learning_rate": 7.434287201879365e-05,
        "gradient_norm": 0.3905380070209503,
        "train_loss": 3.029552936553955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27241,
        "tokens": 14282129408,
        "learning_rate": 7.433366119869296e-05,
        "gradient_norm": 0.40365684032440186,
        "train_loss": 3.0209169387817383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27242,
        "tokens": 14282653696,
        "learning_rate": 7.432445325643563e-05,
        "gradient_norm": 0.4367743730545044,
        "train_loss": 3.0226168632507324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27243,
        "tokens": 14283177984,
        "learning_rate": 7.431524819212525e-05,
        "gradient_norm": 0.4030603766441345,
        "train_loss": 3.0567755699157715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27244,
        "tokens": 14283702272,
        "learning_rate": 7.43060460058655e-05,
        "gradient_norm": 0.4341239631175995,
        "train_loss": 3.039177894592285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27245,
        "tokens": 14284226560,
        "learning_rate": 7.429684669775993e-05,
        "gradient_norm": 0.4521614909172058,
        "train_loss": 3.0298283100128174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27246,
        "tokens": 14284750848,
        "learning_rate": 7.428765026791206e-05,
        "gradient_norm": 0.4591032862663269,
        "train_loss": 3.0377986431121826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27247,
        "tokens": 14285275136,
        "learning_rate": 7.42784567164255e-05,
        "gradient_norm": 0.43188145756721497,
        "train_loss": 2.980013370513916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27248,
        "tokens": 14285799424,
        "learning_rate": 7.42692660434036e-05,
        "gradient_norm": 0.4346882700920105,
        "train_loss": 3.0049028396606445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27249,
        "tokens": 14286323712,
        "learning_rate": 7.426007824894997e-05,
        "gradient_norm": 0.48870912194252014,
        "train_loss": 3.0391907691955566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27250,
        "tokens": 14286848000,
        "learning_rate": 7.425089333316789e-05,
        "gradient_norm": 0.41684508323669434,
        "train_loss": 3.042741060256958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27251,
        "tokens": 14287372288,
        "learning_rate": 7.424171129616083e-05,
        "gradient_norm": 0.44398263096809387,
        "train_loss": 3.000457286834717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27252,
        "tokens": 14287896576,
        "learning_rate": 7.42325321380321e-05,
        "gradient_norm": 0.4368138313293457,
        "train_loss": 3.0321197509765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27253,
        "tokens": 14288420864,
        "learning_rate": 7.422335585888508e-05,
        "gradient_norm": 0.4626345634460449,
        "train_loss": 2.9743361473083496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27254,
        "tokens": 14288945152,
        "learning_rate": 7.421418245882298e-05,
        "gradient_norm": 0.44041159749031067,
        "train_loss": 3.0471248626708984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27255,
        "tokens": 14289469440,
        "learning_rate": 7.420501193794911e-05,
        "gradient_norm": 0.47397857904434204,
        "train_loss": 3.038914918899536,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27256,
        "tokens": 14289993728,
        "learning_rate": 7.419584429636671e-05,
        "gradient_norm": 0.46525001525878906,
        "train_loss": 2.9914395809173584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27257,
        "tokens": 14290518016,
        "learning_rate": 7.418667953417892e-05,
        "gradient_norm": 0.46434593200683594,
        "train_loss": 2.972348690032959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27258,
        "tokens": 14291042304,
        "learning_rate": 7.417751765148897e-05,
        "gradient_norm": 0.42286500334739685,
        "train_loss": 2.980300188064575,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27259,
        "tokens": 14291566592,
        "learning_rate": 7.416835864839992e-05,
        "gradient_norm": 0.4354761838912964,
        "train_loss": 3.054698944091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27260,
        "tokens": 14292090880,
        "learning_rate": 7.415920252501493e-05,
        "gradient_norm": 0.4811365008354187,
        "train_loss": 3.102123498916626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27261,
        "tokens": 14292615168,
        "learning_rate": 7.415004928143696e-05,
        "gradient_norm": 0.46215930581092834,
        "train_loss": 2.9929327964782715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27262,
        "tokens": 14293139456,
        "learning_rate": 7.414089891776919e-05,
        "gradient_norm": 0.41924890875816345,
        "train_loss": 3.0501856803894043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27263,
        "tokens": 14293663744,
        "learning_rate": 7.413175143411449e-05,
        "gradient_norm": 0.43598026037216187,
        "train_loss": 2.9830479621887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27264,
        "tokens": 14294188032,
        "learning_rate": 7.412260683057593e-05,
        "gradient_norm": 0.43832552433013916,
        "train_loss": 2.946840286254883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27265,
        "tokens": 14294712320,
        "learning_rate": 7.411346510725632e-05,
        "gradient_norm": 0.44353702664375305,
        "train_loss": 3.032543420791626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27266,
        "tokens": 14295236608,
        "learning_rate": 7.410432626425866e-05,
        "gradient_norm": 0.4481636583805084,
        "train_loss": 2.9489312171936035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27267,
        "tokens": 14295760896,
        "learning_rate": 7.40951903016858e-05,
        "gradient_norm": 0.4331396520137787,
        "train_loss": 2.9827513694763184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27268,
        "tokens": 14296285184,
        "learning_rate": 7.408605721964053e-05,
        "gradient_norm": 0.4018695652484894,
        "train_loss": 3.025723457336426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27269,
        "tokens": 14296809472,
        "learning_rate": 7.407692701822575e-05,
        "gradient_norm": 0.4316357672214508,
        "train_loss": 2.9803857803344727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27270,
        "tokens": 14297333760,
        "learning_rate": 7.406779969754414e-05,
        "gradient_norm": 0.4435647428035736,
        "train_loss": 2.9980454444885254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27271,
        "tokens": 14297858048,
        "learning_rate": 7.40586752576985e-05,
        "gradient_norm": 0.4065385162830353,
        "train_loss": 2.996473789215088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27272,
        "tokens": 14298382336,
        "learning_rate": 7.404955369879144e-05,
        "gradient_norm": 0.38980481028556824,
        "train_loss": 3.022045612335205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27273,
        "tokens": 14298906624,
        "learning_rate": 7.404043502092578e-05,
        "gradient_norm": 0.4127637445926666,
        "train_loss": 3.0013208389282227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27274,
        "tokens": 14299430912,
        "learning_rate": 7.403131922420402e-05,
        "gradient_norm": 0.4098723530769348,
        "train_loss": 3.0288093090057373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27275,
        "tokens": 14299955200,
        "learning_rate": 7.40222063087289e-05,
        "gradient_norm": 0.4019598066806793,
        "train_loss": 3.0351152420043945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27276,
        "tokens": 14300479488,
        "learning_rate": 7.401309627460291e-05,
        "gradient_norm": 0.4312311112880707,
        "train_loss": 3.0715231895446777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27277,
        "tokens": 14301003776,
        "learning_rate": 7.400398912192857e-05,
        "gradient_norm": 0.40246543288230896,
        "train_loss": 3.0630390644073486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27278,
        "tokens": 14301528064,
        "learning_rate": 7.399488485080849e-05,
        "gradient_norm": 0.4161036014556885,
        "train_loss": 2.970832586288452,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27279,
        "tokens": 14302052352,
        "learning_rate": 7.39857834613451e-05,
        "gradient_norm": 0.41203173995018005,
        "train_loss": 3.0945749282836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27280,
        "tokens": 14302576640,
        "learning_rate": 7.397668495364086e-05,
        "gradient_norm": 0.41702139377593994,
        "train_loss": 3.0212814807891846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27281,
        "tokens": 14303100928,
        "learning_rate": 7.39675893277981e-05,
        "gradient_norm": 0.39939582347869873,
        "train_loss": 3.044710636138916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27282,
        "tokens": 14303625216,
        "learning_rate": 7.395849658391936e-05,
        "gradient_norm": 0.45568183064460754,
        "train_loss": 2.9959945678710938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27283,
        "tokens": 14304149504,
        "learning_rate": 7.394940672210686e-05,
        "gradient_norm": 0.40357068181037903,
        "train_loss": 3.0077147483825684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27284,
        "tokens": 14304673792,
        "learning_rate": 7.3940319742463e-05,
        "gradient_norm": 0.40364736318588257,
        "train_loss": 3.0031232833862305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27285,
        "tokens": 14305198080,
        "learning_rate": 7.393123564508998e-05,
        "gradient_norm": 0.44223934412002563,
        "train_loss": 2.9827170372009277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27286,
        "tokens": 14305722368,
        "learning_rate": 7.39221544300901e-05,
        "gradient_norm": 0.36768966913223267,
        "train_loss": 3.0206246376037598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27287,
        "tokens": 14306246656,
        "learning_rate": 7.391307609756564e-05,
        "gradient_norm": 0.4089410603046417,
        "train_loss": 2.9877490997314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27288,
        "tokens": 14306770944,
        "learning_rate": 7.390400064761865e-05,
        "gradient_norm": 0.42778220772743225,
        "train_loss": 2.9707376956939697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27289,
        "tokens": 14307295232,
        "learning_rate": 7.389492808035144e-05,
        "gradient_norm": 0.36249521374702454,
        "train_loss": 2.9791083335876465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27290,
        "tokens": 14307819520,
        "learning_rate": 7.3885858395866e-05,
        "gradient_norm": 0.4076440930366516,
        "train_loss": 3.006946086883545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27291,
        "tokens": 14308343808,
        "learning_rate": 7.387679159426451e-05,
        "gradient_norm": 0.38700732588768005,
        "train_loss": 2.979302406311035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27292,
        "tokens": 14308868096,
        "learning_rate": 7.386772767564897e-05,
        "gradient_norm": 0.37869390845298767,
        "train_loss": 2.986280918121338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27293,
        "tokens": 14309392384,
        "learning_rate": 7.385866664012148e-05,
        "gradient_norm": 0.41791093349456787,
        "train_loss": 3.042717456817627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27294,
        "tokens": 14309916672,
        "learning_rate": 7.384960848778393e-05,
        "gradient_norm": 0.39780277013778687,
        "train_loss": 2.967107057571411,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27295,
        "tokens": 14310440960,
        "learning_rate": 7.384055321873835e-05,
        "gradient_norm": 0.3981674313545227,
        "train_loss": 2.995612144470215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27296,
        "tokens": 14310965248,
        "learning_rate": 7.383150083308669e-05,
        "gradient_norm": 0.39526134729385376,
        "train_loss": 3.043532609939575,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27297,
        "tokens": 14311489536,
        "learning_rate": 7.38224513309308e-05,
        "gradient_norm": 0.39151912927627563,
        "train_loss": 2.987971782684326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27298,
        "tokens": 14312013824,
        "learning_rate": 7.381340471237253e-05,
        "gradient_norm": 0.4382164180278778,
        "train_loss": 3.0343308448791504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27299,
        "tokens": 14312538112,
        "learning_rate": 7.380436097751372e-05,
        "gradient_norm": 0.40362346172332764,
        "train_loss": 3.0501575469970703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27300,
        "tokens": 14313062400,
        "learning_rate": 7.379532012645625e-05,
        "gradient_norm": 0.41335785388946533,
        "train_loss": 3.028426170349121,
        "val_loss": 2.9660844802856445,
        "hellaswag_acc": 0.2849034070968628,
        "hellaswag_acc_norm": 0.29854610562324524
    },
    {
        "step": 27301,
        "tokens": 14313586688,
        "learning_rate": 7.378628215930176e-05,
        "gradient_norm": 0.42627301812171936,
        "train_loss": 3.0659942626953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27302,
        "tokens": 14314110976,
        "learning_rate": 7.37772470761521e-05,
        "gradient_norm": 0.4568210542201996,
        "train_loss": 3.049048662185669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27303,
        "tokens": 14314635264,
        "learning_rate": 7.376821487710884e-05,
        "gradient_norm": 0.414749413728714,
        "train_loss": 2.9821126461029053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27304,
        "tokens": 14315159552,
        "learning_rate": 7.37591855622738e-05,
        "gradient_norm": 0.43190062046051025,
        "train_loss": 2.971100091934204,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27305,
        "tokens": 14315683840,
        "learning_rate": 7.375015913174847e-05,
        "gradient_norm": 0.4241313934326172,
        "train_loss": 2.999682664871216,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27306,
        "tokens": 14316208128,
        "learning_rate": 7.374113558563454e-05,
        "gradient_norm": 0.4290364384651184,
        "train_loss": 3.0510597229003906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27307,
        "tokens": 14316732416,
        "learning_rate": 7.37321149240336e-05,
        "gradient_norm": 0.445968359708786,
        "train_loss": 3.069484233856201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27308,
        "tokens": 14317256704,
        "learning_rate": 7.372309714704709e-05,
        "gradient_norm": 0.4791586399078369,
        "train_loss": 2.9786951541900635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27309,
        "tokens": 14317780992,
        "learning_rate": 7.371408225477665e-05,
        "gradient_norm": 0.4199642837047577,
        "train_loss": 3.0310652256011963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27310,
        "tokens": 14318305280,
        "learning_rate": 7.370507024732365e-05,
        "gradient_norm": 0.42778900265693665,
        "train_loss": 3.1131937503814697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27311,
        "tokens": 14318829568,
        "learning_rate": 7.369606112478956e-05,
        "gradient_norm": 0.387013703584671,
        "train_loss": 3.045027256011963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27312,
        "tokens": 14319353856,
        "learning_rate": 7.36870548872758e-05,
        "gradient_norm": 0.4017248749732971,
        "train_loss": 3.0266380310058594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27313,
        "tokens": 14319878144,
        "learning_rate": 7.367805153488376e-05,
        "gradient_norm": 0.4131791293621063,
        "train_loss": 3.0349087715148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27314,
        "tokens": 14320402432,
        "learning_rate": 7.366905106771472e-05,
        "gradient_norm": 0.38594579696655273,
        "train_loss": 2.9787256717681885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27315,
        "tokens": 14320926720,
        "learning_rate": 7.366005348587005e-05,
        "gradient_norm": 0.3996308445930481,
        "train_loss": 3.0112905502319336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27316,
        "tokens": 14321451008,
        "learning_rate": 7.365105878945103e-05,
        "gradient_norm": 0.40225622057914734,
        "train_loss": 2.9523138999938965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27317,
        "tokens": 14321975296,
        "learning_rate": 7.364206697855887e-05,
        "gradient_norm": 0.4376544654369354,
        "train_loss": 3.044174909591675,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27318,
        "tokens": 14322499584,
        "learning_rate": 7.363307805329483e-05,
        "gradient_norm": 0.41935718059539795,
        "train_loss": 3.012758255004883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27319,
        "tokens": 14323023872,
        "learning_rate": 7.362409201376005e-05,
        "gradient_norm": 0.4160796105861664,
        "train_loss": 3.020209789276123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27320,
        "tokens": 14323548160,
        "learning_rate": 7.361510886005571e-05,
        "gradient_norm": 0.43333542346954346,
        "train_loss": 3.019287109375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27321,
        "tokens": 14324072448,
        "learning_rate": 7.360612859228289e-05,
        "gradient_norm": 0.4042033553123474,
        "train_loss": 2.9652228355407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27322,
        "tokens": 14324596736,
        "learning_rate": 7.359715121054271e-05,
        "gradient_norm": 0.48737573623657227,
        "train_loss": 2.980625867843628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27323,
        "tokens": 14325121024,
        "learning_rate": 7.358817671493618e-05,
        "gradient_norm": 0.4266098737716675,
        "train_loss": 2.9849226474761963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27324,
        "tokens": 14325645312,
        "learning_rate": 7.35792051055644e-05,
        "gradient_norm": 0.4286505877971649,
        "train_loss": 3.0040059089660645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27325,
        "tokens": 14326169600,
        "learning_rate": 7.357023638252826e-05,
        "gradient_norm": 0.41148120164871216,
        "train_loss": 2.9996628761291504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27326,
        "tokens": 14326693888,
        "learning_rate": 7.356127054592878e-05,
        "gradient_norm": 0.3932592272758484,
        "train_loss": 2.9853363037109375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27327,
        "tokens": 14327218176,
        "learning_rate": 7.355230759586683e-05,
        "gradient_norm": 0.456861674785614,
        "train_loss": 2.9895105361938477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27328,
        "tokens": 14327742464,
        "learning_rate": 7.35433475324434e-05,
        "gradient_norm": 0.42217400670051575,
        "train_loss": 3.0289711952209473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27329,
        "tokens": 14328266752,
        "learning_rate": 7.353439035575921e-05,
        "gradient_norm": 0.47349923849105835,
        "train_loss": 3.027949810028076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27330,
        "tokens": 14328791040,
        "learning_rate": 7.352543606591517e-05,
        "gradient_norm": 0.44115012884140015,
        "train_loss": 3.0561177730560303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27331,
        "tokens": 14329315328,
        "learning_rate": 7.351648466301203e-05,
        "gradient_norm": 0.40689462423324585,
        "train_loss": 3.059204578399658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27332,
        "tokens": 14329839616,
        "learning_rate": 7.350753614715061e-05,
        "gradient_norm": 0.5088188052177429,
        "train_loss": 3.002739429473877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27333,
        "tokens": 14330363904,
        "learning_rate": 7.349859051843155e-05,
        "gradient_norm": 0.42013654112815857,
        "train_loss": 2.978823661804199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27334,
        "tokens": 14330888192,
        "learning_rate": 7.348964777695563e-05,
        "gradient_norm": 0.40895047783851624,
        "train_loss": 3.0260915756225586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27335,
        "tokens": 14331412480,
        "learning_rate": 7.348070792282344e-05,
        "gradient_norm": 0.5050962567329407,
        "train_loss": 2.9945616722106934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27336,
        "tokens": 14331936768,
        "learning_rate": 7.347177095613567e-05,
        "gradient_norm": 0.41836342215538025,
        "train_loss": 2.984173536300659,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27337,
        "tokens": 14332461056,
        "learning_rate": 7.346283687699286e-05,
        "gradient_norm": 0.45069947838783264,
        "train_loss": 3.0194053649902344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27338,
        "tokens": 14332985344,
        "learning_rate": 7.345390568549565e-05,
        "gradient_norm": 0.45342907309532166,
        "train_loss": 3.0455780029296875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27339,
        "tokens": 14333509632,
        "learning_rate": 7.344497738174448e-05,
        "gradient_norm": 0.4421471953392029,
        "train_loss": 3.0141022205352783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27340,
        "tokens": 14334033920,
        "learning_rate": 7.343605196583988e-05,
        "gradient_norm": 0.47667139768600464,
        "train_loss": 3.0271875858306885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27341,
        "tokens": 14334558208,
        "learning_rate": 7.342712943788238e-05,
        "gradient_norm": 0.4453663229942322,
        "train_loss": 3.0440924167633057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27342,
        "tokens": 14335082496,
        "learning_rate": 7.341820979797234e-05,
        "gradient_norm": 0.44256889820098877,
        "train_loss": 3.0277867317199707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27343,
        "tokens": 14335606784,
        "learning_rate": 7.34092930462102e-05,
        "gradient_norm": 0.41840076446533203,
        "train_loss": 3.043442726135254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27344,
        "tokens": 14336131072,
        "learning_rate": 7.340037918269628e-05,
        "gradient_norm": 0.44470933079719543,
        "train_loss": 3.007262706756592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27345,
        "tokens": 14336655360,
        "learning_rate": 7.339146820753102e-05,
        "gradient_norm": 0.44408708810806274,
        "train_loss": 3.010173797607422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27346,
        "tokens": 14337179648,
        "learning_rate": 7.338256012081458e-05,
        "gradient_norm": 0.4093431234359741,
        "train_loss": 3.0377840995788574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27347,
        "tokens": 14337703936,
        "learning_rate": 7.337365492264737e-05,
        "gradient_norm": 0.4184812307357788,
        "train_loss": 2.9805703163146973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27348,
        "tokens": 14338228224,
        "learning_rate": 7.336475261312952e-05,
        "gradient_norm": 0.45275840163230896,
        "train_loss": 2.977909564971924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27349,
        "tokens": 14338752512,
        "learning_rate": 7.335585319236132e-05,
        "gradient_norm": 0.525657057762146,
        "train_loss": 3.0426928997039795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27350,
        "tokens": 14339276800,
        "learning_rate": 7.334695666044287e-05,
        "gradient_norm": 0.4584384858608246,
        "train_loss": 3.067227840423584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27351,
        "tokens": 14339801088,
        "learning_rate": 7.333806301747439e-05,
        "gradient_norm": 0.509901225566864,
        "train_loss": 3.0389747619628906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27352,
        "tokens": 14340325376,
        "learning_rate": 7.332917226355592e-05,
        "gradient_norm": 0.46994858980178833,
        "train_loss": 2.985522747039795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27353,
        "tokens": 14340849664,
        "learning_rate": 7.332028439878758e-05,
        "gradient_norm": 0.4605761766433716,
        "train_loss": 3.076721668243408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27354,
        "tokens": 14341373952,
        "learning_rate": 7.331139942326938e-05,
        "gradient_norm": 0.4733942747116089,
        "train_loss": 3.065032482147217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27355,
        "tokens": 14341898240,
        "learning_rate": 7.330251733710135e-05,
        "gradient_norm": 0.42211613059043884,
        "train_loss": 2.996345281600952,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27356,
        "tokens": 14342422528,
        "learning_rate": 7.329363814038349e-05,
        "gradient_norm": 0.39601725339889526,
        "train_loss": 3.0079410076141357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27357,
        "tokens": 14342946816,
        "learning_rate": 7.32847618332157e-05,
        "gradient_norm": 0.4794757068157196,
        "train_loss": 2.992865800857544,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27358,
        "tokens": 14343471104,
        "learning_rate": 7.327588841569793e-05,
        "gradient_norm": 0.44701704382896423,
        "train_loss": 3.040372133255005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27359,
        "tokens": 14343995392,
        "learning_rate": 7.326701788793006e-05,
        "gradient_norm": 0.404675155878067,
        "train_loss": 3.00247859954834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27360,
        "tokens": 14344519680,
        "learning_rate": 7.325815025001193e-05,
        "gradient_norm": 0.4651447832584381,
        "train_loss": 3.004086971282959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27361,
        "tokens": 14345043968,
        "learning_rate": 7.324928550204336e-05,
        "gradient_norm": 0.36855369806289673,
        "train_loss": 3.033515453338623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27362,
        "tokens": 14345568256,
        "learning_rate": 7.324042364412412e-05,
        "gradient_norm": 0.43841636180877686,
        "train_loss": 2.9791316986083984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27363,
        "tokens": 14346092544,
        "learning_rate": 7.323156467635395e-05,
        "gradient_norm": 0.43914172053337097,
        "train_loss": 2.996072769165039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27364,
        "tokens": 14346616832,
        "learning_rate": 7.322270859883259e-05,
        "gradient_norm": 0.4538942575454712,
        "train_loss": 2.9895992279052734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27365,
        "tokens": 14347141120,
        "learning_rate": 7.321385541165979e-05,
        "gradient_norm": 0.4337175488471985,
        "train_loss": 3.018122911453247,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27366,
        "tokens": 14347665408,
        "learning_rate": 7.320500511493506e-05,
        "gradient_norm": 0.4207480251789093,
        "train_loss": 3.0064873695373535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27367,
        "tokens": 14348189696,
        "learning_rate": 7.319615770875818e-05,
        "gradient_norm": 0.4303624927997589,
        "train_loss": 3.0007481575012207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27368,
        "tokens": 14348713984,
        "learning_rate": 7.31873131932286e-05,
        "gradient_norm": 0.41180115938186646,
        "train_loss": 3.0078229904174805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27369,
        "tokens": 14349238272,
        "learning_rate": 7.317847156844596e-05,
        "gradient_norm": 0.43462222814559937,
        "train_loss": 2.963503837585449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27370,
        "tokens": 14349762560,
        "learning_rate": 7.316963283450976e-05,
        "gradient_norm": 0.41794443130493164,
        "train_loss": 2.9916744232177734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27371,
        "tokens": 14350286848,
        "learning_rate": 7.316079699151948e-05,
        "gradient_norm": 0.4417995810508728,
        "train_loss": 3.0877647399902344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27372,
        "tokens": 14350811136,
        "learning_rate": 7.315196403957457e-05,
        "gradient_norm": 0.42811617255210876,
        "train_loss": 3.0259218215942383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27373,
        "tokens": 14351335424,
        "learning_rate": 7.314313397877451e-05,
        "gradient_norm": 0.47345927357673645,
        "train_loss": 3.033555746078491,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27374,
        "tokens": 14351859712,
        "learning_rate": 7.313430680921865e-05,
        "gradient_norm": 0.4433918595314026,
        "train_loss": 2.9607491493225098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27375,
        "tokens": 14352384000,
        "learning_rate": 7.312548253100632e-05,
        "gradient_norm": 0.44958212971687317,
        "train_loss": 3.0329504013061523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27376,
        "tokens": 14352908288,
        "learning_rate": 7.311666114423693e-05,
        "gradient_norm": 0.44693151116371155,
        "train_loss": 3.0361571311950684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27377,
        "tokens": 14353432576,
        "learning_rate": 7.310784264900972e-05,
        "gradient_norm": 0.5486565232276917,
        "train_loss": 3.1746020317077637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27378,
        "tokens": 14353956864,
        "learning_rate": 7.309902704542398e-05,
        "gradient_norm": 0.4704955220222473,
        "train_loss": 3.045626163482666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27379,
        "tokens": 14354481152,
        "learning_rate": 7.30902143335789e-05,
        "gradient_norm": 0.43815556168556213,
        "train_loss": 2.9900012016296387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27380,
        "tokens": 14355005440,
        "learning_rate": 7.308140451357372e-05,
        "gradient_norm": 0.4290964603424072,
        "train_loss": 3.024308681488037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27381,
        "tokens": 14355529728,
        "learning_rate": 7.307259758550759e-05,
        "gradient_norm": 0.46116822957992554,
        "train_loss": 3.005164623260498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27382,
        "tokens": 14356054016,
        "learning_rate": 7.306379354947964e-05,
        "gradient_norm": 0.418761283159256,
        "train_loss": 3.0136590003967285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27383,
        "tokens": 14356578304,
        "learning_rate": 7.305499240558896e-05,
        "gradient_norm": 0.47661787271499634,
        "train_loss": 2.9770584106445312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27384,
        "tokens": 14357102592,
        "learning_rate": 7.304619415393462e-05,
        "gradient_norm": 0.47765815258026123,
        "train_loss": 3.0343053340911865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27385,
        "tokens": 14357626880,
        "learning_rate": 7.30373987946157e-05,
        "gradient_norm": 0.4828619956970215,
        "train_loss": 3.0027337074279785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27386,
        "tokens": 14358151168,
        "learning_rate": 7.302860632773117e-05,
        "gradient_norm": 0.40763118863105774,
        "train_loss": 2.969182252883911,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27387,
        "tokens": 14358675456,
        "learning_rate": 7.301981675337999e-05,
        "gradient_norm": 0.4187614321708679,
        "train_loss": 2.9959282875061035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27388,
        "tokens": 14359199744,
        "learning_rate": 7.301103007166107e-05,
        "gradient_norm": 0.45570266246795654,
        "train_loss": 3.0166049003601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27389,
        "tokens": 14359724032,
        "learning_rate": 7.300224628267342e-05,
        "gradient_norm": 0.4508865475654602,
        "train_loss": 3.0094406604766846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27390,
        "tokens": 14360248320,
        "learning_rate": 7.29934653865158e-05,
        "gradient_norm": 0.42480483651161194,
        "train_loss": 2.9630916118621826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27391,
        "tokens": 14360772608,
        "learning_rate": 7.29846873832871e-05,
        "gradient_norm": 0.4771675765514374,
        "train_loss": 2.957028388977051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27392,
        "tokens": 14361296896,
        "learning_rate": 7.29759122730861e-05,
        "gradient_norm": 0.48396041989326477,
        "train_loss": 3.0221304893493652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27393,
        "tokens": 14361821184,
        "learning_rate": 7.296714005601164e-05,
        "gradient_norm": 0.4426306188106537,
        "train_loss": 3.0381340980529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27394,
        "tokens": 14362345472,
        "learning_rate": 7.295837073216238e-05,
        "gradient_norm": 0.4447375237941742,
        "train_loss": 3.013739585876465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27395,
        "tokens": 14362869760,
        "learning_rate": 7.294960430163707e-05,
        "gradient_norm": 0.45722001791000366,
        "train_loss": 3.0380959510803223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27396,
        "tokens": 14363394048,
        "learning_rate": 7.294084076453443e-05,
        "gradient_norm": 0.45160403847694397,
        "train_loss": 3.0689096450805664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27397,
        "tokens": 14363918336,
        "learning_rate": 7.293208012095303e-05,
        "gradient_norm": 0.4302690029144287,
        "train_loss": 3.0132808685302734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27398,
        "tokens": 14364442624,
        "learning_rate": 7.292332237099151e-05,
        "gradient_norm": 0.4438917934894562,
        "train_loss": 3.0113632678985596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27399,
        "tokens": 14364966912,
        "learning_rate": 7.291456751474845e-05,
        "gradient_norm": 0.4639892280101776,
        "train_loss": 3.018333911895752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27400,
        "tokens": 14365491200,
        "learning_rate": 7.290581555232243e-05,
        "gradient_norm": 0.428362637758255,
        "train_loss": 2.975493907928467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27401,
        "tokens": 14366015488,
        "learning_rate": 7.289706648381187e-05,
        "gradient_norm": 0.42680275440216064,
        "train_loss": 3.0276503562927246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27402,
        "tokens": 14366539776,
        "learning_rate": 7.288832030931536e-05,
        "gradient_norm": 0.4328187108039856,
        "train_loss": 3.0178685188293457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27403,
        "tokens": 14367064064,
        "learning_rate": 7.28795770289313e-05,
        "gradient_norm": 0.41210663318634033,
        "train_loss": 2.9805984497070312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27404,
        "tokens": 14367588352,
        "learning_rate": 7.287083664275808e-05,
        "gradient_norm": 0.4187575876712799,
        "train_loss": 3.0355844497680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27405,
        "tokens": 14368112640,
        "learning_rate": 7.286209915089417e-05,
        "gradient_norm": 0.4680269658565521,
        "train_loss": 3.022782802581787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27406,
        "tokens": 14368636928,
        "learning_rate": 7.28533645534378e-05,
        "gradient_norm": 0.4074748754501343,
        "train_loss": 2.998002767562866,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27407,
        "tokens": 14369161216,
        "learning_rate": 7.28446328504874e-05,
        "gradient_norm": 0.4422879219055176,
        "train_loss": 2.972179412841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27408,
        "tokens": 14369685504,
        "learning_rate": 7.283590404214116e-05,
        "gradient_norm": 0.4343894124031067,
        "train_loss": 2.965470314025879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27409,
        "tokens": 14370209792,
        "learning_rate": 7.282717812849744e-05,
        "gradient_norm": 0.4098452031612396,
        "train_loss": 3.0768394470214844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27410,
        "tokens": 14370734080,
        "learning_rate": 7.281845510965438e-05,
        "gradient_norm": 0.4520065188407898,
        "train_loss": 3.058948040008545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27411,
        "tokens": 14371258368,
        "learning_rate": 7.280973498571022e-05,
        "gradient_norm": 0.38486552238464355,
        "train_loss": 2.9843952655792236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27412,
        "tokens": 14371782656,
        "learning_rate": 7.280101775676302e-05,
        "gradient_norm": 0.4473218023777008,
        "train_loss": 2.996670961380005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27413,
        "tokens": 14372306944,
        "learning_rate": 7.279230342291105e-05,
        "gradient_norm": 0.4194168746471405,
        "train_loss": 2.9985463619232178,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27414,
        "tokens": 14372831232,
        "learning_rate": 7.278359198425227e-05,
        "gradient_norm": 0.403469443321228,
        "train_loss": 3.020411252975464,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27415,
        "tokens": 14373355520,
        "learning_rate": 7.27748834408848e-05,
        "gradient_norm": 0.48100546002388,
        "train_loss": 3.023834705352783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27416,
        "tokens": 14373879808,
        "learning_rate": 7.276617779290667e-05,
        "gradient_norm": 0.4355032742023468,
        "train_loss": 3.0996999740600586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27417,
        "tokens": 14374404096,
        "learning_rate": 7.275747504041585e-05,
        "gradient_norm": 0.43992817401885986,
        "train_loss": 2.959545135498047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27418,
        "tokens": 14374928384,
        "learning_rate": 7.274877518351032e-05,
        "gradient_norm": 0.43719053268432617,
        "train_loss": 2.9851958751678467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27419,
        "tokens": 14375452672,
        "learning_rate": 7.274007822228798e-05,
        "gradient_norm": 0.49245885014533997,
        "train_loss": 3.0871174335479736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27420,
        "tokens": 14375976960,
        "learning_rate": 7.273138415684677e-05,
        "gradient_norm": 0.4259825646877289,
        "train_loss": 3.001086473464966,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27421,
        "tokens": 14376501248,
        "learning_rate": 7.27226929872845e-05,
        "gradient_norm": 0.42921432852745056,
        "train_loss": 3.0354485511779785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27422,
        "tokens": 14377025536,
        "learning_rate": 7.271400471369906e-05,
        "gradient_norm": 0.4100300967693329,
        "train_loss": 2.9770708084106445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27423,
        "tokens": 14377549824,
        "learning_rate": 7.270531933618815e-05,
        "gradient_norm": 0.4542240798473358,
        "train_loss": 3.0202536582946777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27424,
        "tokens": 14378074112,
        "learning_rate": 7.269663685484961e-05,
        "gradient_norm": 0.43393296003341675,
        "train_loss": 3.0664379596710205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27425,
        "tokens": 14378598400,
        "learning_rate": 7.268795726978123e-05,
        "gradient_norm": 0.4492189884185791,
        "train_loss": 2.996738910675049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27426,
        "tokens": 14379122688,
        "learning_rate": 7.267928058108055e-05,
        "gradient_norm": 0.4439488649368286,
        "train_loss": 3.0251986980438232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27427,
        "tokens": 14379646976,
        "learning_rate": 7.26706067888454e-05,
        "gradient_norm": 0.4124574065208435,
        "train_loss": 2.9669132232666016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27428,
        "tokens": 14380171264,
        "learning_rate": 7.266193589317329e-05,
        "gradient_norm": 0.4934365749359131,
        "train_loss": 3.0681307315826416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27429,
        "tokens": 14380695552,
        "learning_rate": 7.265326789416192e-05,
        "gradient_norm": 0.4287087619304657,
        "train_loss": 3.03706693649292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27430,
        "tokens": 14381219840,
        "learning_rate": 7.264460279190875e-05,
        "gradient_norm": 0.472684383392334,
        "train_loss": 3.0613455772399902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27431,
        "tokens": 14381744128,
        "learning_rate": 7.263594058651143e-05,
        "gradient_norm": 0.4025608003139496,
        "train_loss": 2.9666712284088135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27432,
        "tokens": 14382268416,
        "learning_rate": 7.262728127806737e-05,
        "gradient_norm": 0.430137574672699,
        "train_loss": 3.0061352252960205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27433,
        "tokens": 14382792704,
        "learning_rate": 7.261862486667414e-05,
        "gradient_norm": 0.3693792521953583,
        "train_loss": 2.9636282920837402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27434,
        "tokens": 14383316992,
        "learning_rate": 7.260997135242907e-05,
        "gradient_norm": 0.46382954716682434,
        "train_loss": 2.9900851249694824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27435,
        "tokens": 14383841280,
        "learning_rate": 7.260132073542965e-05,
        "gradient_norm": 0.42319217324256897,
        "train_loss": 3.0363335609436035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27436,
        "tokens": 14384365568,
        "learning_rate": 7.259267301577318e-05,
        "gradient_norm": 0.4318889379501343,
        "train_loss": 3.0452451705932617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27437,
        "tokens": 14384889856,
        "learning_rate": 7.258402819355706e-05,
        "gradient_norm": 0.41363269090652466,
        "train_loss": 2.952428102493286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27438,
        "tokens": 14385414144,
        "learning_rate": 7.257538626887858e-05,
        "gradient_norm": 0.4202965795993805,
        "train_loss": 3.0300207138061523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27439,
        "tokens": 14385938432,
        "learning_rate": 7.256674724183503e-05,
        "gradient_norm": 0.40729498863220215,
        "train_loss": 2.9977757930755615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27440,
        "tokens": 14386462720,
        "learning_rate": 7.255811111252362e-05,
        "gradient_norm": 0.42270541191101074,
        "train_loss": 2.9808506965637207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27441,
        "tokens": 14386987008,
        "learning_rate": 7.254947788104162e-05,
        "gradient_norm": 0.4187406599521637,
        "train_loss": 3.0513343811035156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27442,
        "tokens": 14387511296,
        "learning_rate": 7.254084754748611e-05,
        "gradient_norm": 0.3958660960197449,
        "train_loss": 2.9851396083831787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27443,
        "tokens": 14388035584,
        "learning_rate": 7.253222011195431e-05,
        "gradient_norm": 0.39880162477493286,
        "train_loss": 3.0146450996398926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27444,
        "tokens": 14388559872,
        "learning_rate": 7.252359557454333e-05,
        "gradient_norm": 0.4320859909057617,
        "train_loss": 2.998861312866211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27445,
        "tokens": 14389084160,
        "learning_rate": 7.251497393535023e-05,
        "gradient_norm": 0.38918736577033997,
        "train_loss": 3.023550510406494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27446,
        "tokens": 14389608448,
        "learning_rate": 7.250635519447205e-05,
        "gradient_norm": 0.623255729675293,
        "train_loss": 3.127610206604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27447,
        "tokens": 14390132736,
        "learning_rate": 7.249773935200584e-05,
        "gradient_norm": 0.4211365580558777,
        "train_loss": 2.997407913208008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27448,
        "tokens": 14390657024,
        "learning_rate": 7.248912640804853e-05,
        "gradient_norm": 0.41990089416503906,
        "train_loss": 3.013692855834961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27449,
        "tokens": 14391181312,
        "learning_rate": 7.248051636269713e-05,
        "gradient_norm": 0.42767995595932007,
        "train_loss": 3.0286030769348145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27450,
        "tokens": 14391705600,
        "learning_rate": 7.24719092160485e-05,
        "gradient_norm": 0.46003904938697815,
        "train_loss": 3.002507448196411,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27451,
        "tokens": 14392229888,
        "learning_rate": 7.246330496819955e-05,
        "gradient_norm": 0.42079415917396545,
        "train_loss": 2.9793999195098877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27452,
        "tokens": 14392754176,
        "learning_rate": 7.245470361924714e-05,
        "gradient_norm": 0.3636847138404846,
        "train_loss": 3.0270657539367676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27453,
        "tokens": 14393278464,
        "learning_rate": 7.244610516928808e-05,
        "gradient_norm": 0.40701058506965637,
        "train_loss": 2.98636531829834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27454,
        "tokens": 14393802752,
        "learning_rate": 7.243750961841914e-05,
        "gradient_norm": 0.4580944776535034,
        "train_loss": 3.012296676635742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27455,
        "tokens": 14394327040,
        "learning_rate": 7.242891696673708e-05,
        "gradient_norm": 0.43277081847190857,
        "train_loss": 3.0123133659362793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27456,
        "tokens": 14394851328,
        "learning_rate": 7.242032721433867e-05,
        "gradient_norm": 0.3939599394798279,
        "train_loss": 2.9943807125091553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27457,
        "tokens": 14395375616,
        "learning_rate": 7.241174036132052e-05,
        "gradient_norm": 0.4219353497028351,
        "train_loss": 3.0082077980041504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27458,
        "tokens": 14395899904,
        "learning_rate": 7.240315640777935e-05,
        "gradient_norm": 0.3994787633419037,
        "train_loss": 2.9971561431884766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27459,
        "tokens": 14396424192,
        "learning_rate": 7.239457535381174e-05,
        "gradient_norm": 0.46343129873275757,
        "train_loss": 3.0410101413726807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27460,
        "tokens": 14396948480,
        "learning_rate": 7.238599719951432e-05,
        "gradient_norm": 0.4028547704219818,
        "train_loss": 2.965512752532959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27461,
        "tokens": 14397472768,
        "learning_rate": 7.237742194498361e-05,
        "gradient_norm": 0.40125054121017456,
        "train_loss": 2.991086959838867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27462,
        "tokens": 14397997056,
        "learning_rate": 7.236884959031619e-05,
        "gradient_norm": 0.415134459733963,
        "train_loss": 3.017315149307251,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27463,
        "tokens": 14398521344,
        "learning_rate": 7.236028013560843e-05,
        "gradient_norm": 0.4175601005554199,
        "train_loss": 3.0595364570617676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27464,
        "tokens": 14399045632,
        "learning_rate": 7.235171358095691e-05,
        "gradient_norm": 0.4141465723514557,
        "train_loss": 3.058076858520508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27465,
        "tokens": 14399569920,
        "learning_rate": 7.234314992645807e-05,
        "gradient_norm": 0.4363738000392914,
        "train_loss": 3.0318429470062256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27466,
        "tokens": 14400094208,
        "learning_rate": 7.23345891722082e-05,
        "gradient_norm": 0.45296308398246765,
        "train_loss": 2.994575023651123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27467,
        "tokens": 14400618496,
        "learning_rate": 7.232603131830374e-05,
        "gradient_norm": 0.4878411889076233,
        "train_loss": 3.0360403060913086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27468,
        "tokens": 14401142784,
        "learning_rate": 7.231747636484098e-05,
        "gradient_norm": 0.4421781897544861,
        "train_loss": 3.0806829929351807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27469,
        "tokens": 14401667072,
        "learning_rate": 7.230892431191627e-05,
        "gradient_norm": 0.47234275937080383,
        "train_loss": 3.026426315307617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27470,
        "tokens": 14402191360,
        "learning_rate": 7.230037515962579e-05,
        "gradient_norm": 0.46454760432243347,
        "train_loss": 2.9946389198303223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27471,
        "tokens": 14402715648,
        "learning_rate": 7.229182890806585e-05,
        "gradient_norm": 0.4168373942375183,
        "train_loss": 3.0049757957458496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27472,
        "tokens": 14403239936,
        "learning_rate": 7.22832855573326e-05,
        "gradient_norm": 0.5434372425079346,
        "train_loss": 3.0287411212921143,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27473,
        "tokens": 14403764224,
        "learning_rate": 7.227474510752224e-05,
        "gradient_norm": 0.4335937201976776,
        "train_loss": 3.0625388622283936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27474,
        "tokens": 14404288512,
        "learning_rate": 7.226620755873089e-05,
        "gradient_norm": 0.4182156026363373,
        "train_loss": 2.9561994075775146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27475,
        "tokens": 14404812800,
        "learning_rate": 7.225767291105462e-05,
        "gradient_norm": 0.4450569748878479,
        "train_loss": 3.0163419246673584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27476,
        "tokens": 14405337088,
        "learning_rate": 7.224914116458954e-05,
        "gradient_norm": 0.45027536153793335,
        "train_loss": 3.0451316833496094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27477,
        "tokens": 14405861376,
        "learning_rate": 7.224061231943165e-05,
        "gradient_norm": 0.42531293630599976,
        "train_loss": 3.080063819885254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27478,
        "tokens": 14406385664,
        "learning_rate": 7.223208637567702e-05,
        "gradient_norm": 0.4270186126232147,
        "train_loss": 3.0594584941864014,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27479,
        "tokens": 14406909952,
        "learning_rate": 7.222356333342155e-05,
        "gradient_norm": 0.41096556186676025,
        "train_loss": 2.981348991394043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27480,
        "tokens": 14407434240,
        "learning_rate": 7.22150431927612e-05,
        "gradient_norm": 0.4228735566139221,
        "train_loss": 3.026736259460449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27481,
        "tokens": 14407958528,
        "learning_rate": 7.220652595379188e-05,
        "gradient_norm": 0.48348867893218994,
        "train_loss": 3.005112886428833,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27482,
        "tokens": 14408482816,
        "learning_rate": 7.219801161660946e-05,
        "gradient_norm": 0.46251899003982544,
        "train_loss": 3.044847011566162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27483,
        "tokens": 14409007104,
        "learning_rate": 7.218950018130975e-05,
        "gradient_norm": 0.4287925362586975,
        "train_loss": 2.992584705352783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27484,
        "tokens": 14409531392,
        "learning_rate": 7.218099164798861e-05,
        "gradient_norm": 0.42892375588417053,
        "train_loss": 3.0390372276306152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27485,
        "tokens": 14410055680,
        "learning_rate": 7.21724860167418e-05,
        "gradient_norm": 0.4394473135471344,
        "train_loss": 3.038173198699951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27486,
        "tokens": 14410579968,
        "learning_rate": 7.216398328766502e-05,
        "gradient_norm": 0.4998721182346344,
        "train_loss": 3.004995346069336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27487,
        "tokens": 14411104256,
        "learning_rate": 7.215548346085404e-05,
        "gradient_norm": 0.464603066444397,
        "train_loss": 2.9822120666503906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27488,
        "tokens": 14411628544,
        "learning_rate": 7.214698653640447e-05,
        "gradient_norm": 0.4662560224533081,
        "train_loss": 2.993863105773926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27489,
        "tokens": 14412152832,
        "learning_rate": 7.213849251441205e-05,
        "gradient_norm": 0.5068689584732056,
        "train_loss": 3.028564453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27490,
        "tokens": 14412677120,
        "learning_rate": 7.213000139497226e-05,
        "gradient_norm": 0.4101168215274811,
        "train_loss": 3.0043785572052,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27491,
        "tokens": 14413201408,
        "learning_rate": 7.21215131781808e-05,
        "gradient_norm": 0.4553050994873047,
        "train_loss": 3.025876522064209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27492,
        "tokens": 14413725696,
        "learning_rate": 7.211302786413313e-05,
        "gradient_norm": 0.41593092679977417,
        "train_loss": 3.0344443321228027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27493,
        "tokens": 14414249984,
        "learning_rate": 7.210454545292484e-05,
        "gradient_norm": 0.4302610754966736,
        "train_loss": 3.035837173461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27494,
        "tokens": 14414774272,
        "learning_rate": 7.20960659446513e-05,
        "gradient_norm": 0.4645904302597046,
        "train_loss": 3.0237345695495605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27495,
        "tokens": 14415298560,
        "learning_rate": 7.208758933940803e-05,
        "gradient_norm": 0.4040919840335846,
        "train_loss": 3.0051393508911133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27496,
        "tokens": 14415822848,
        "learning_rate": 7.207911563729049e-05,
        "gradient_norm": 0.49093225598335266,
        "train_loss": 3.0248780250549316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27497,
        "tokens": 14416347136,
        "learning_rate": 7.207064483839396e-05,
        "gradient_norm": 0.4794151484966278,
        "train_loss": 3.08457088470459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27498,
        "tokens": 14416871424,
        "learning_rate": 7.206217694281389e-05,
        "gradient_norm": 0.41931140422821045,
        "train_loss": 3.023881196975708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27499,
        "tokens": 14417395712,
        "learning_rate": 7.20537119506455e-05,
        "gradient_norm": 0.40055644512176514,
        "train_loss": 3.0511646270751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27500,
        "tokens": 14417920000,
        "learning_rate": 7.204524986198416e-05,
        "gradient_norm": 0.4908553957939148,
        "train_loss": 3.017106533050537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27501,
        "tokens": 14418444288,
        "learning_rate": 7.203679067692504e-05,
        "gradient_norm": 0.41713595390319824,
        "train_loss": 3.052233934402466,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27502,
        "tokens": 14418968576,
        "learning_rate": 7.202833439556347e-05,
        "gradient_norm": 0.437849760055542,
        "train_loss": 3.0038490295410156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27503,
        "tokens": 14419492864,
        "learning_rate": 7.20198810179945e-05,
        "gradient_norm": 0.45227301120758057,
        "train_loss": 2.9859225749969482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27504,
        "tokens": 14420017152,
        "learning_rate": 7.201143054431335e-05,
        "gradient_norm": 0.37313026189804077,
        "train_loss": 3.020965099334717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27505,
        "tokens": 14420541440,
        "learning_rate": 7.200298297461519e-05,
        "gradient_norm": 0.4549720287322998,
        "train_loss": 3.0771989822387695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27506,
        "tokens": 14421065728,
        "learning_rate": 7.199453830899502e-05,
        "gradient_norm": 0.4394209682941437,
        "train_loss": 2.978421688079834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27507,
        "tokens": 14421590016,
        "learning_rate": 7.198609654754795e-05,
        "gradient_norm": 0.4528158903121948,
        "train_loss": 3.0116841793060303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27508,
        "tokens": 14422114304,
        "learning_rate": 7.197765769036897e-05,
        "gradient_norm": 0.43923261761665344,
        "train_loss": 3.089761257171631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27509,
        "tokens": 14422638592,
        "learning_rate": 7.196922173755311e-05,
        "gradient_norm": 0.42012912034988403,
        "train_loss": 3.102379322052002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27510,
        "tokens": 14423162880,
        "learning_rate": 7.196078868919529e-05,
        "gradient_norm": 0.4641774296760559,
        "train_loss": 2.9616522789001465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27511,
        "tokens": 14423687168,
        "learning_rate": 7.195235854539046e-05,
        "gradient_norm": 0.4369613528251648,
        "train_loss": 2.9437613487243652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27512,
        "tokens": 14424211456,
        "learning_rate": 7.194393130623344e-05,
        "gradient_norm": 0.47314104437828064,
        "train_loss": 3.013857364654541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27513,
        "tokens": 14424735744,
        "learning_rate": 7.193550697181923e-05,
        "gradient_norm": 0.42519068717956543,
        "train_loss": 2.955899715423584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27514,
        "tokens": 14425260032,
        "learning_rate": 7.192708554224252e-05,
        "gradient_norm": 0.4449867606163025,
        "train_loss": 3.0161120891571045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27515,
        "tokens": 14425784320,
        "learning_rate": 7.191866701759816e-05,
        "gradient_norm": 0.44507381319999695,
        "train_loss": 3.0155553817749023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27516,
        "tokens": 14426308608,
        "learning_rate": 7.191025139798095e-05,
        "gradient_norm": 0.4346919655799866,
        "train_loss": 3.029374361038208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27517,
        "tokens": 14426832896,
        "learning_rate": 7.190183868348554e-05,
        "gradient_norm": 0.41820085048675537,
        "train_loss": 2.984837532043457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27518,
        "tokens": 14427357184,
        "learning_rate": 7.189342887420668e-05,
        "gradient_norm": 0.6583721041679382,
        "train_loss": 3.117292881011963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27519,
        "tokens": 14427881472,
        "learning_rate": 7.188502197023899e-05,
        "gradient_norm": 0.4573909342288971,
        "train_loss": 3.0115509033203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27520,
        "tokens": 14428405760,
        "learning_rate": 7.187661797167718e-05,
        "gradient_norm": 0.5162099599838257,
        "train_loss": 2.989206314086914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27521,
        "tokens": 14428930048,
        "learning_rate": 7.186821687861574e-05,
        "gradient_norm": 0.4481981098651886,
        "train_loss": 3.003481388092041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27522,
        "tokens": 14429454336,
        "learning_rate": 7.185981869114934e-05,
        "gradient_norm": 0.41800278425216675,
        "train_loss": 2.9731063842773438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27523,
        "tokens": 14429978624,
        "learning_rate": 7.185142340937241e-05,
        "gradient_norm": 0.42164304852485657,
        "train_loss": 3.0121824741363525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27524,
        "tokens": 14430502912,
        "learning_rate": 7.184303103337952e-05,
        "gradient_norm": 0.46596407890319824,
        "train_loss": 3.058741569519043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27525,
        "tokens": 14431027200,
        "learning_rate": 7.183464156326514e-05,
        "gradient_norm": 0.423053503036499,
        "train_loss": 2.973315954208374,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27526,
        "tokens": 14431551488,
        "learning_rate": 7.182625499912365e-05,
        "gradient_norm": 0.42058244347572327,
        "train_loss": 3.0358777046203613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27527,
        "tokens": 14432075776,
        "learning_rate": 7.18178713410495e-05,
        "gradient_norm": 0.48299357295036316,
        "train_loss": 3.038102149963379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27528,
        "tokens": 14432600064,
        "learning_rate": 7.180949058913701e-05,
        "gradient_norm": 0.4294477105140686,
        "train_loss": 3.0457868576049805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27529,
        "tokens": 14433124352,
        "learning_rate": 7.180111274348061e-05,
        "gradient_norm": 0.4434111416339874,
        "train_loss": 3.0581037998199463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27530,
        "tokens": 14433648640,
        "learning_rate": 7.179273780417446e-05,
        "gradient_norm": 0.4412153959274292,
        "train_loss": 3.0136377811431885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27531,
        "tokens": 14434172928,
        "learning_rate": 7.178436577131297e-05,
        "gradient_norm": 0.3992758095264435,
        "train_loss": 2.9314866065979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27532,
        "tokens": 14434697216,
        "learning_rate": 7.177599664499029e-05,
        "gradient_norm": 0.40628647804260254,
        "train_loss": 3.0512218475341797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27533,
        "tokens": 14435221504,
        "learning_rate": 7.176763042530067e-05,
        "gradient_norm": 0.48703956604003906,
        "train_loss": 3.0390896797180176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27534,
        "tokens": 14435745792,
        "learning_rate": 7.175926711233824e-05,
        "gradient_norm": 0.44182446599006653,
        "train_loss": 3.0018577575683594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27535,
        "tokens": 14436270080,
        "learning_rate": 7.175090670619722e-05,
        "gradient_norm": 0.4134608507156372,
        "train_loss": 2.9952385425567627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27536,
        "tokens": 14436794368,
        "learning_rate": 7.174254920697161e-05,
        "gradient_norm": 0.409880131483078,
        "train_loss": 2.9948010444641113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27537,
        "tokens": 14437318656,
        "learning_rate": 7.173419461475556e-05,
        "gradient_norm": 0.4902072846889496,
        "train_loss": 3.021742820739746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27538,
        "tokens": 14437842944,
        "learning_rate": 7.172584292964305e-05,
        "gradient_norm": 0.4202388823032379,
        "train_loss": 2.996497631072998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27539,
        "tokens": 14438367232,
        "learning_rate": 7.171749415172817e-05,
        "gradient_norm": 0.42438575625419617,
        "train_loss": 3.0162882804870605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27540,
        "tokens": 14438891520,
        "learning_rate": 7.17091482811048e-05,
        "gradient_norm": 0.43619871139526367,
        "train_loss": 2.9887402057647705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27541,
        "tokens": 14439415808,
        "learning_rate": 7.170080531786698e-05,
        "gradient_norm": 0.4492378830909729,
        "train_loss": 3.0516576766967773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27542,
        "tokens": 14439940096,
        "learning_rate": 7.169246526210855e-05,
        "gradient_norm": 0.45145383477211,
        "train_loss": 2.991671562194824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27543,
        "tokens": 14440464384,
        "learning_rate": 7.168412811392344e-05,
        "gradient_norm": 0.4308280348777771,
        "train_loss": 3.0496015548706055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27544,
        "tokens": 14440988672,
        "learning_rate": 7.167579387340542e-05,
        "gradient_norm": 0.3787669539451599,
        "train_loss": 2.9817075729370117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27545,
        "tokens": 14441512960,
        "learning_rate": 7.166746254064836e-05,
        "gradient_norm": 0.4176613688468933,
        "train_loss": 3.043130397796631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27546,
        "tokens": 14442037248,
        "learning_rate": 7.165913411574604e-05,
        "gradient_norm": 0.4039546251296997,
        "train_loss": 3.0037529468536377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27547,
        "tokens": 14442561536,
        "learning_rate": 7.16508085987922e-05,
        "gradient_norm": 0.41524213552474976,
        "train_loss": 2.9695849418640137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27548,
        "tokens": 14443085824,
        "learning_rate": 7.164248598988056e-05,
        "gradient_norm": 0.4348931610584259,
        "train_loss": 2.992064952850342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27549,
        "tokens": 14443610112,
        "learning_rate": 7.163416628910477e-05,
        "gradient_norm": 0.42295774817466736,
        "train_loss": 3.027141809463501,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27550,
        "tokens": 14444134400,
        "learning_rate": 7.162584949655851e-05,
        "gradient_norm": 0.4304257333278656,
        "train_loss": 2.961500644683838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27551,
        "tokens": 14444658688,
        "learning_rate": 7.16175356123354e-05,
        "gradient_norm": 0.4888462424278259,
        "train_loss": 3.0332705974578857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27552,
        "tokens": 14445182976,
        "learning_rate": 7.160922463652901e-05,
        "gradient_norm": 0.4075566232204437,
        "train_loss": 2.982633113861084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27553,
        "tokens": 14445707264,
        "learning_rate": 7.160091656923284e-05,
        "gradient_norm": 0.3980350196361542,
        "train_loss": 2.9852230548858643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27554,
        "tokens": 14446231552,
        "learning_rate": 7.159261141054052e-05,
        "gradient_norm": 0.4520050883293152,
        "train_loss": 3.083620548248291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27555,
        "tokens": 14446755840,
        "learning_rate": 7.158430916054544e-05,
        "gradient_norm": 0.438137948513031,
        "train_loss": 3.02984881401062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27556,
        "tokens": 14447280128,
        "learning_rate": 7.15760098193411e-05,
        "gradient_norm": 0.4408641755580902,
        "train_loss": 2.9930615425109863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27557,
        "tokens": 14447804416,
        "learning_rate": 7.156771338702086e-05,
        "gradient_norm": 0.4378993809223175,
        "train_loss": 2.9918551445007324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27558,
        "tokens": 14448328704,
        "learning_rate": 7.15594198636782e-05,
        "gradient_norm": 0.41538313031196594,
        "train_loss": 2.9834883213043213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27559,
        "tokens": 14448852992,
        "learning_rate": 7.155112924940639e-05,
        "gradient_norm": 0.4984210133552551,
        "train_loss": 3.1627767086029053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27560,
        "tokens": 14449377280,
        "learning_rate": 7.154284154429883e-05,
        "gradient_norm": 0.4595773220062256,
        "train_loss": 3.047203779220581,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27561,
        "tokens": 14449901568,
        "learning_rate": 7.153455674844872e-05,
        "gradient_norm": 0.4359724521636963,
        "train_loss": 2.9948971271514893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27562,
        "tokens": 14450425856,
        "learning_rate": 7.152627486194938e-05,
        "gradient_norm": 0.4361346960067749,
        "train_loss": 3.0248939990997314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27563,
        "tokens": 14450950144,
        "learning_rate": 7.1517995884894e-05,
        "gradient_norm": 0.43350496888160706,
        "train_loss": 3.0399580001831055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27564,
        "tokens": 14451474432,
        "learning_rate": 7.150971981737577e-05,
        "gradient_norm": 0.42976900935173035,
        "train_loss": 3.0015649795532227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27565,
        "tokens": 14451998720,
        "learning_rate": 7.15014466594879e-05,
        "gradient_norm": 0.4804401993751526,
        "train_loss": 3.006649971008301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27566,
        "tokens": 14452523008,
        "learning_rate": 7.149317641132343e-05,
        "gradient_norm": 0.40103718638420105,
        "train_loss": 3.0091981887817383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27567,
        "tokens": 14453047296,
        "learning_rate": 7.148490907297553e-05,
        "gradient_norm": 0.4126490354537964,
        "train_loss": 3.0332236289978027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27568,
        "tokens": 14453571584,
        "learning_rate": 7.14766446445372e-05,
        "gradient_norm": 0.4479215443134308,
        "train_loss": 3.0051541328430176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27569,
        "tokens": 14454095872,
        "learning_rate": 7.146838312610155e-05,
        "gradient_norm": 0.41430193185806274,
        "train_loss": 3.016714572906494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27570,
        "tokens": 14454620160,
        "learning_rate": 7.146012451776145e-05,
        "gradient_norm": 0.42112791538238525,
        "train_loss": 3.034092426300049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27571,
        "tokens": 14455144448,
        "learning_rate": 7.145186881960997e-05,
        "gradient_norm": 0.4392484128475189,
        "train_loss": 2.969395637512207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27572,
        "tokens": 14455668736,
        "learning_rate": 7.144361603173996e-05,
        "gradient_norm": 0.4673028886318207,
        "train_loss": 3.0449960231781006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27573,
        "tokens": 14456193024,
        "learning_rate": 7.143536615424439e-05,
        "gradient_norm": 0.4372076094150543,
        "train_loss": 3.0121402740478516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27574,
        "tokens": 14456717312,
        "learning_rate": 7.142711918721604e-05,
        "gradient_norm": 0.3931555449962616,
        "train_loss": 2.929607391357422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27575,
        "tokens": 14457241600,
        "learning_rate": 7.141887513074778e-05,
        "gradient_norm": 0.40953564643859863,
        "train_loss": 3.022526502609253,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27576,
        "tokens": 14457765888,
        "learning_rate": 7.141063398493245e-05,
        "gradient_norm": 0.44507259130477905,
        "train_loss": 3.03621768951416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27577,
        "tokens": 14458290176,
        "learning_rate": 7.140239574986274e-05,
        "gradient_norm": 0.4515109062194824,
        "train_loss": 3.0774006843566895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27578,
        "tokens": 14458814464,
        "learning_rate": 7.139416042563147e-05,
        "gradient_norm": 0.46201851963996887,
        "train_loss": 3.0281503200531006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27579,
        "tokens": 14459338752,
        "learning_rate": 7.138592801233121e-05,
        "gradient_norm": 0.44826120138168335,
        "train_loss": 3.071500778198242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27580,
        "tokens": 14459863040,
        "learning_rate": 7.137769851005477e-05,
        "gradient_norm": 0.4424542486667633,
        "train_loss": 3.0511350631713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27581,
        "tokens": 14460387328,
        "learning_rate": 7.136947191889467e-05,
        "gradient_norm": 0.4449436366558075,
        "train_loss": 2.988837957382202,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27582,
        "tokens": 14460911616,
        "learning_rate": 7.136124823894358e-05,
        "gradient_norm": 0.4448716938495636,
        "train_loss": 3.007002353668213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27583,
        "tokens": 14461435904,
        "learning_rate": 7.135302747029403e-05,
        "gradient_norm": 0.46798524260520935,
        "train_loss": 3.0365610122680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27584,
        "tokens": 14461960192,
        "learning_rate": 7.134480961303854e-05,
        "gradient_norm": 0.48684626817703247,
        "train_loss": 2.991609811782837,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27585,
        "tokens": 14462484480,
        "learning_rate": 7.133659466726969e-05,
        "gradient_norm": 0.4486943185329437,
        "train_loss": 2.988248586654663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27586,
        "tokens": 14463008768,
        "learning_rate": 7.132838263307988e-05,
        "gradient_norm": 0.4304749667644501,
        "train_loss": 3.0075411796569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27587,
        "tokens": 14463533056,
        "learning_rate": 7.132017351056157e-05,
        "gradient_norm": 0.594667911529541,
        "train_loss": 3.114946126937866,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27588,
        "tokens": 14464057344,
        "learning_rate": 7.131196729980713e-05,
        "gradient_norm": 0.49013519287109375,
        "train_loss": 2.995138168334961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27589,
        "tokens": 14464581632,
        "learning_rate": 7.130376400090902e-05,
        "gradient_norm": 0.5345337390899658,
        "train_loss": 3.050344705581665,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27590,
        "tokens": 14465105920,
        "learning_rate": 7.129556361395947e-05,
        "gradient_norm": 0.46234866976737976,
        "train_loss": 2.9810357093811035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27591,
        "tokens": 14465630208,
        "learning_rate": 7.128736613905088e-05,
        "gradient_norm": 0.5351106524467468,
        "train_loss": 3.0286593437194824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27592,
        "tokens": 14466154496,
        "learning_rate": 7.12791715762754e-05,
        "gradient_norm": 0.4675690531730652,
        "train_loss": 3.033129930496216,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27593,
        "tokens": 14466678784,
        "learning_rate": 7.127097992572543e-05,
        "gradient_norm": 0.44210079312324524,
        "train_loss": 3.058159828186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27594,
        "tokens": 14467203072,
        "learning_rate": 7.126279118749304e-05,
        "gradient_norm": 0.5270109176635742,
        "train_loss": 3.042004108428955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27595,
        "tokens": 14467727360,
        "learning_rate": 7.125460536167048e-05,
        "gradient_norm": 0.4804822504520416,
        "train_loss": 3.0362396240234375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27596,
        "tokens": 14468251648,
        "learning_rate": 7.124642244834986e-05,
        "gradient_norm": 0.5096793174743652,
        "train_loss": 3.0343570709228516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27597,
        "tokens": 14468775936,
        "learning_rate": 7.123824244762332e-05,
        "gradient_norm": 0.4856054186820984,
        "train_loss": 3.0145275592803955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27598,
        "tokens": 14469300224,
        "learning_rate": 7.123006535958293e-05,
        "gradient_norm": 0.49458709359169006,
        "train_loss": 2.9841270446777344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27599,
        "tokens": 14469824512,
        "learning_rate": 7.122189118432068e-05,
        "gradient_norm": 0.41588595509529114,
        "train_loss": 2.9491348266601562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27600,
        "tokens": 14470348800,
        "learning_rate": 7.121371992192864e-05,
        "gradient_norm": 0.4940955936908722,
        "train_loss": 3.0105843544006348,
        "val_loss": 2.9655866622924805,
        "hellaswag_acc": 0.2841067612171173,
        "hellaswag_acc_norm": 0.2993427515029907
    },
    {
        "step": 27601,
        "tokens": 14470873088,
        "learning_rate": 7.120555157249877e-05,
        "gradient_norm": 0.4468257427215576,
        "train_loss": 2.984250068664551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27602,
        "tokens": 14471397376,
        "learning_rate": 7.119738613612301e-05,
        "gradient_norm": 0.41292524337768555,
        "train_loss": 3.044468641281128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27603,
        "tokens": 14471921664,
        "learning_rate": 7.118922361289327e-05,
        "gradient_norm": 0.4972517788410187,
        "train_loss": 3.041295289993286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27604,
        "tokens": 14472445952,
        "learning_rate": 7.118106400290144e-05,
        "gradient_norm": 0.464155912399292,
        "train_loss": 3.064786911010742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27605,
        "tokens": 14472970240,
        "learning_rate": 7.117290730623935e-05,
        "gradient_norm": 0.454007089138031,
        "train_loss": 2.9798176288604736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27606,
        "tokens": 14473494528,
        "learning_rate": 7.116475352299881e-05,
        "gradient_norm": 0.44444456696510315,
        "train_loss": 2.977097272872925,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27607,
        "tokens": 14474018816,
        "learning_rate": 7.115660265327168e-05,
        "gradient_norm": 0.4080337584018707,
        "train_loss": 3.036144733428955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27608,
        "tokens": 14474543104,
        "learning_rate": 7.114845469714958e-05,
        "gradient_norm": 0.37896040081977844,
        "train_loss": 3.017606496810913,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27609,
        "tokens": 14475067392,
        "learning_rate": 7.114030965472435e-05,
        "gradient_norm": 0.45709851384162903,
        "train_loss": 3.0085229873657227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27610,
        "tokens": 14475591680,
        "learning_rate": 7.113216752608756e-05,
        "gradient_norm": 0.43260908126831055,
        "train_loss": 3.088322162628174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27611,
        "tokens": 14476115968,
        "learning_rate": 7.112402831133093e-05,
        "gradient_norm": 0.40150558948516846,
        "train_loss": 3.01656174659729,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27612,
        "tokens": 14476640256,
        "learning_rate": 7.111589201054605e-05,
        "gradient_norm": 0.4614991247653961,
        "train_loss": 3.0134336948394775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27613,
        "tokens": 14477164544,
        "learning_rate": 7.110775862382452e-05,
        "gradient_norm": 0.3925579786300659,
        "train_loss": 2.9922051429748535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27614,
        "tokens": 14477688832,
        "learning_rate": 7.109962815125786e-05,
        "gradient_norm": 0.3991413116455078,
        "train_loss": 3.0333728790283203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27615,
        "tokens": 14478213120,
        "learning_rate": 7.109150059293763e-05,
        "gradient_norm": 0.42456313967704773,
        "train_loss": 3.0432815551757812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27616,
        "tokens": 14478737408,
        "learning_rate": 7.108337594895533e-05,
        "gradient_norm": 0.41887563467025757,
        "train_loss": 3.062865972518921,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27617,
        "tokens": 14479261696,
        "learning_rate": 7.107525421940233e-05,
        "gradient_norm": 0.378017395734787,
        "train_loss": 3.013885021209717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27618,
        "tokens": 14479785984,
        "learning_rate": 7.106713540437015e-05,
        "gradient_norm": 0.4097640812397003,
        "train_loss": 3.0353479385375977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27619,
        "tokens": 14480310272,
        "learning_rate": 7.10590195039501e-05,
        "gradient_norm": 0.39871281385421753,
        "train_loss": 3.005657196044922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27620,
        "tokens": 14480834560,
        "learning_rate": 7.10509065182336e-05,
        "gradient_norm": 0.3721935749053955,
        "train_loss": 3.0575523376464844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27621,
        "tokens": 14481358848,
        "learning_rate": 7.104279644731188e-05,
        "gradient_norm": 0.4010765552520752,
        "train_loss": 2.9810867309570312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27622,
        "tokens": 14481883136,
        "learning_rate": 7.103468929127632e-05,
        "gradient_norm": 0.3821936249732971,
        "train_loss": 3.022806167602539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27623,
        "tokens": 14482407424,
        "learning_rate": 7.102658505021812e-05,
        "gradient_norm": 0.3730444610118866,
        "train_loss": 3.0101470947265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27624,
        "tokens": 14482931712,
        "learning_rate": 7.101848372422854e-05,
        "gradient_norm": 0.4252470135688782,
        "train_loss": 3.049839973449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27625,
        "tokens": 14483456000,
        "learning_rate": 7.101038531339875e-05,
        "gradient_norm": 0.42583876848220825,
        "train_loss": 3.0887351036071777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27626,
        "tokens": 14483980288,
        "learning_rate": 7.100228981781991e-05,
        "gradient_norm": 0.44474565982818604,
        "train_loss": 3.0491952896118164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27627,
        "tokens": 14484504576,
        "learning_rate": 7.099419723758315e-05,
        "gradient_norm": 0.5002515912055969,
        "train_loss": 3.1982736587524414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27628,
        "tokens": 14485028864,
        "learning_rate": 7.098610757277954e-05,
        "gradient_norm": 0.4571704864501953,
        "train_loss": 2.9869384765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27629,
        "tokens": 14485553152,
        "learning_rate": 7.097802082350023e-05,
        "gradient_norm": 0.4698992371559143,
        "train_loss": 3.0231807231903076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27630,
        "tokens": 14486077440,
        "learning_rate": 7.096993698983611e-05,
        "gradient_norm": 0.47400984168052673,
        "train_loss": 2.977591037750244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27631,
        "tokens": 14486601728,
        "learning_rate": 7.096185607187825e-05,
        "gradient_norm": 0.4325539171695709,
        "train_loss": 3.0103743076324463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27632,
        "tokens": 14487126016,
        "learning_rate": 7.095377806971757e-05,
        "gradient_norm": 0.4559556543827057,
        "train_loss": 2.9882380962371826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27633,
        "tokens": 14487650304,
        "learning_rate": 7.094570298344509e-05,
        "gradient_norm": 0.4368274211883545,
        "train_loss": 3.003695487976074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27634,
        "tokens": 14488174592,
        "learning_rate": 7.09376308131516e-05,
        "gradient_norm": 0.38977500796318054,
        "train_loss": 2.965820550918579,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27635,
        "tokens": 14488698880,
        "learning_rate": 7.0929561558928e-05,
        "gradient_norm": 0.4225994646549225,
        "train_loss": 3.0556631088256836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27636,
        "tokens": 14489223168,
        "learning_rate": 7.092149522086515e-05,
        "gradient_norm": 0.4791269898414612,
        "train_loss": 3.0581865310668945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27637,
        "tokens": 14489747456,
        "learning_rate": 7.091343179905379e-05,
        "gradient_norm": 0.47651907801628113,
        "train_loss": 3.0265321731567383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27638,
        "tokens": 14490271744,
        "learning_rate": 7.090537129358477e-05,
        "gradient_norm": 0.39608100056648254,
        "train_loss": 2.98753023147583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27639,
        "tokens": 14490796032,
        "learning_rate": 7.089731370454872e-05,
        "gradient_norm": 0.43105724453926086,
        "train_loss": 2.9959182739257812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27640,
        "tokens": 14491320320,
        "learning_rate": 7.088925903203641e-05,
        "gradient_norm": 0.43929195404052734,
        "train_loss": 3.0073413848876953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27641,
        "tokens": 14491844608,
        "learning_rate": 7.088120727613846e-05,
        "gradient_norm": 0.3927457332611084,
        "train_loss": 3.0428805351257324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27642,
        "tokens": 14492368896,
        "learning_rate": 7.087315843694554e-05,
        "gradient_norm": 0.46226564049720764,
        "train_loss": 2.9746437072753906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27643,
        "tokens": 14492893184,
        "learning_rate": 7.08651125145482e-05,
        "gradient_norm": 0.4113404154777527,
        "train_loss": 3.067443370819092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27644,
        "tokens": 14493417472,
        "learning_rate": 7.085706950903709e-05,
        "gradient_norm": 0.390146404504776,
        "train_loss": 3.040466547012329,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27645,
        "tokens": 14493941760,
        "learning_rate": 7.084902942050264e-05,
        "gradient_norm": 0.40311217308044434,
        "train_loss": 2.969330310821533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27646,
        "tokens": 14494466048,
        "learning_rate": 7.084099224903545e-05,
        "gradient_norm": 0.39789944887161255,
        "train_loss": 2.9796018600463867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27647,
        "tokens": 14494990336,
        "learning_rate": 7.083295799472588e-05,
        "gradient_norm": 0.4210287630558014,
        "train_loss": 3.0467276573181152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27648,
        "tokens": 14495514624,
        "learning_rate": 7.082492665766451e-05,
        "gradient_norm": 0.4234682023525238,
        "train_loss": 3.0329859256744385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27649,
        "tokens": 14496038912,
        "learning_rate": 7.081689823794161e-05,
        "gradient_norm": 0.4360261559486389,
        "train_loss": 2.9970390796661377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27650,
        "tokens": 14496563200,
        "learning_rate": 7.080887273564759e-05,
        "gradient_norm": 0.44999051094055176,
        "train_loss": 3.0323362350463867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27651,
        "tokens": 14497087488,
        "learning_rate": 7.080085015087281e-05,
        "gradient_norm": 0.4149591028690338,
        "train_loss": 2.980192184448242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27652,
        "tokens": 14497611776,
        "learning_rate": 7.07928304837076e-05,
        "gradient_norm": 0.47585317492485046,
        "train_loss": 2.9951040744781494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27653,
        "tokens": 14498136064,
        "learning_rate": 7.078481373424213e-05,
        "gradient_norm": 0.44499093294143677,
        "train_loss": 3.0381956100463867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27654,
        "tokens": 14498660352,
        "learning_rate": 7.077679990256675e-05,
        "gradient_norm": 0.402150958776474,
        "train_loss": 3.0137667655944824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27655,
        "tokens": 14499184640,
        "learning_rate": 7.076878898877158e-05,
        "gradient_norm": 0.4492785632610321,
        "train_loss": 3.1159701347351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27656,
        "tokens": 14499708928,
        "learning_rate": 7.076078099294689e-05,
        "gradient_norm": 0.44073861837387085,
        "train_loss": 2.977884531021118,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27657,
        "tokens": 14500233216,
        "learning_rate": 7.075277591518268e-05,
        "gradient_norm": 0.4471462666988373,
        "train_loss": 2.989616870880127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27658,
        "tokens": 14500757504,
        "learning_rate": 7.07447737555692e-05,
        "gradient_norm": 0.4242575466632843,
        "train_loss": 3.044938802719116,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27659,
        "tokens": 14501281792,
        "learning_rate": 7.073677451419643e-05,
        "gradient_norm": 0.41972336173057556,
        "train_loss": 3.018146276473999,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27660,
        "tokens": 14501806080,
        "learning_rate": 7.072877819115448e-05,
        "gradient_norm": 0.43395957350730896,
        "train_loss": 2.986319065093994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27661,
        "tokens": 14502330368,
        "learning_rate": 7.072078478653327e-05,
        "gradient_norm": 0.42639634013175964,
        "train_loss": 3.042903423309326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27662,
        "tokens": 14502854656,
        "learning_rate": 7.071279430042285e-05,
        "gradient_norm": 0.3889763057231903,
        "train_loss": 3.0046355724334717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27663,
        "tokens": 14503378944,
        "learning_rate": 7.070480673291313e-05,
        "gradient_norm": 0.43000179529190063,
        "train_loss": 3.046189546585083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27664,
        "tokens": 14503903232,
        "learning_rate": 7.069682208409402e-05,
        "gradient_norm": 0.8463119268417358,
        "train_loss": 3.3332443237304688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27665,
        "tokens": 14504427520,
        "learning_rate": 7.068884035405546e-05,
        "gradient_norm": 0.46041905879974365,
        "train_loss": 2.9947872161865234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27666,
        "tokens": 14504951808,
        "learning_rate": 7.06808615428872e-05,
        "gradient_norm": 0.554006814956665,
        "train_loss": 2.997619152069092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27667,
        "tokens": 14505476096,
        "learning_rate": 7.06728856506791e-05,
        "gradient_norm": 0.497234046459198,
        "train_loss": 2.987391471862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27668,
        "tokens": 14506000384,
        "learning_rate": 7.066491267752093e-05,
        "gradient_norm": 0.4552012085914612,
        "train_loss": 3.0165605545043945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27669,
        "tokens": 14506524672,
        "learning_rate": 7.065694262350247e-05,
        "gradient_norm": 0.4737066924571991,
        "train_loss": 3.0007736682891846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27670,
        "tokens": 14507048960,
        "learning_rate": 7.064897548871336e-05,
        "gradient_norm": 0.4750686585903168,
        "train_loss": 2.9693007469177246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27671,
        "tokens": 14507573248,
        "learning_rate": 7.064101127324333e-05,
        "gradient_norm": 0.43632975220680237,
        "train_loss": 3.028500556945801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27672,
        "tokens": 14508097536,
        "learning_rate": 7.0633049977182e-05,
        "gradient_norm": 0.4610375761985779,
        "train_loss": 3.0221164226531982,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27673,
        "tokens": 14508621824,
        "learning_rate": 7.062509160061905e-05,
        "gradient_norm": 0.47212743759155273,
        "train_loss": 2.9735372066497803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27674,
        "tokens": 14509146112,
        "learning_rate": 7.061713614364397e-05,
        "gradient_norm": 0.4874289333820343,
        "train_loss": 3.0530667304992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27675,
        "tokens": 14509670400,
        "learning_rate": 7.060918360634634e-05,
        "gradient_norm": 0.4327579438686371,
        "train_loss": 3.0316786766052246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27676,
        "tokens": 14510194688,
        "learning_rate": 7.060123398881575e-05,
        "gradient_norm": 0.44284847378730774,
        "train_loss": 3.011387348175049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27677,
        "tokens": 14510718976,
        "learning_rate": 7.059328729114157e-05,
        "gradient_norm": 0.4183346927165985,
        "train_loss": 3.003481388092041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27678,
        "tokens": 14511243264,
        "learning_rate": 7.058534351341331e-05,
        "gradient_norm": 0.42741233110427856,
        "train_loss": 3.012913465499878,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27679,
        "tokens": 14511767552,
        "learning_rate": 7.057740265572037e-05,
        "gradient_norm": 0.4425885081291199,
        "train_loss": 3.038578748703003,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27680,
        "tokens": 14512291840,
        "learning_rate": 7.056946471815219e-05,
        "gradient_norm": 0.4256400763988495,
        "train_loss": 3.0623459815979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27681,
        "tokens": 14512816128,
        "learning_rate": 7.056152970079803e-05,
        "gradient_norm": 0.4619761109352112,
        "train_loss": 3.069493055343628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27682,
        "tokens": 14513340416,
        "learning_rate": 7.055359760374726e-05,
        "gradient_norm": 0.47273194789886475,
        "train_loss": 3.027132987976074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27683,
        "tokens": 14513864704,
        "learning_rate": 7.054566842708916e-05,
        "gradient_norm": 0.4402603805065155,
        "train_loss": 3.0360984802246094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27684,
        "tokens": 14514388992,
        "learning_rate": 7.053774217091296e-05,
        "gradient_norm": 0.4070426821708679,
        "train_loss": 3.0277657508850098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27685,
        "tokens": 14514913280,
        "learning_rate": 7.052981883530791e-05,
        "gradient_norm": 0.41905516386032104,
        "train_loss": 3.0462474822998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27686,
        "tokens": 14515437568,
        "learning_rate": 7.052189842036318e-05,
        "gradient_norm": 0.39436689019203186,
        "train_loss": 3.0332305431365967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27687,
        "tokens": 14515961856,
        "learning_rate": 7.051398092616798e-05,
        "gradient_norm": 0.4132949709892273,
        "train_loss": 3.0092320442199707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27688,
        "tokens": 14516486144,
        "learning_rate": 7.050606635281133e-05,
        "gradient_norm": 0.409608393907547,
        "train_loss": 2.951977252960205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27689,
        "tokens": 14517010432,
        "learning_rate": 7.04981547003824e-05,
        "gradient_norm": 0.4012795686721802,
        "train_loss": 3.025498867034912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27690,
        "tokens": 14517534720,
        "learning_rate": 7.049024596897022e-05,
        "gradient_norm": 0.38321030139923096,
        "train_loss": 2.988860607147217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27691,
        "tokens": 14518059008,
        "learning_rate": 7.04823401586638e-05,
        "gradient_norm": 0.4495389759540558,
        "train_loss": 3.0609092712402344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27692,
        "tokens": 14518583296,
        "learning_rate": 7.047443726955213e-05,
        "gradient_norm": 0.38360005617141724,
        "train_loss": 3.0275299549102783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27693,
        "tokens": 14519107584,
        "learning_rate": 7.046653730172416e-05,
        "gradient_norm": 0.5007620453834534,
        "train_loss": 3.023106098175049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27694,
        "tokens": 14519631872,
        "learning_rate": 7.045864025526884e-05,
        "gradient_norm": 0.4375123381614685,
        "train_loss": 3.0719971656799316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27695,
        "tokens": 14520156160,
        "learning_rate": 7.045074613027506e-05,
        "gradient_norm": 0.42191529273986816,
        "train_loss": 2.999647378921509,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27696,
        "tokens": 14520680448,
        "learning_rate": 7.044285492683168e-05,
        "gradient_norm": 0.39007601141929626,
        "train_loss": 3.011573314666748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27697,
        "tokens": 14521204736,
        "learning_rate": 7.04349666450275e-05,
        "gradient_norm": 0.404979944229126,
        "train_loss": 3.056666135787964,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27698,
        "tokens": 14521729024,
        "learning_rate": 7.042708128495134e-05,
        "gradient_norm": 0.42381736636161804,
        "train_loss": 2.9931678771972656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27699,
        "tokens": 14522253312,
        "learning_rate": 7.041919884669192e-05,
        "gradient_norm": 0.37776750326156616,
        "train_loss": 3.053858995437622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27700,
        "tokens": 14522777600,
        "learning_rate": 7.041131933033802e-05,
        "gradient_norm": 0.44151121377944946,
        "train_loss": 3.0049703121185303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27701,
        "tokens": 14523301888,
        "learning_rate": 7.040344273597827e-05,
        "gradient_norm": 0.4142351448535919,
        "train_loss": 3.0282931327819824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27702,
        "tokens": 14523826176,
        "learning_rate": 7.039556906370141e-05,
        "gradient_norm": 0.41990524530410767,
        "train_loss": 3.0622010231018066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27703,
        "tokens": 14524350464,
        "learning_rate": 7.0387698313596e-05,
        "gradient_norm": 0.44254738092422485,
        "train_loss": 2.985797166824341,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27704,
        "tokens": 14524874752,
        "learning_rate": 7.037983048575064e-05,
        "gradient_norm": 0.4688940644264221,
        "train_loss": 3.067564010620117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27705,
        "tokens": 14525399040,
        "learning_rate": 7.037196558025397e-05,
        "gradient_norm": 0.4814820885658264,
        "train_loss": 2.968541383743286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27706,
        "tokens": 14525923328,
        "learning_rate": 7.036410359719441e-05,
        "gradient_norm": 0.4301764965057373,
        "train_loss": 3.040347099304199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27707,
        "tokens": 14526447616,
        "learning_rate": 7.035624453666055e-05,
        "gradient_norm": 0.4408825635910034,
        "train_loss": 3.0072925090789795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27708,
        "tokens": 14526971904,
        "learning_rate": 7.03483883987408e-05,
        "gradient_norm": 0.42511141300201416,
        "train_loss": 3.0358428955078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27709,
        "tokens": 14527496192,
        "learning_rate": 7.034053518352362e-05,
        "gradient_norm": 0.4559909701347351,
        "train_loss": 3.026400566101074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27710,
        "tokens": 14528020480,
        "learning_rate": 7.033268489109734e-05,
        "gradient_norm": 0.37348857522010803,
        "train_loss": 3.0629830360412598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27711,
        "tokens": 14528544768,
        "learning_rate": 7.032483752155042e-05,
        "gradient_norm": 0.45069292187690735,
        "train_loss": 2.9802932739257812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27712,
        "tokens": 14529069056,
        "learning_rate": 7.031699307497112e-05,
        "gradient_norm": 0.4193098843097687,
        "train_loss": 3.0372538566589355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27713,
        "tokens": 14529593344,
        "learning_rate": 7.030915155144775e-05,
        "gradient_norm": 0.39325061440467834,
        "train_loss": 3.010995388031006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27714,
        "tokens": 14530117632,
        "learning_rate": 7.030131295106864e-05,
        "gradient_norm": 0.5104729533195496,
        "train_loss": 3.016092538833618,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27715,
        "tokens": 14530641920,
        "learning_rate": 7.029347727392196e-05,
        "gradient_norm": 0.41958922147750854,
        "train_loss": 3.0465245246887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27716,
        "tokens": 14531166208,
        "learning_rate": 7.028564452009594e-05,
        "gradient_norm": 0.4606965482234955,
        "train_loss": 2.9750142097473145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27717,
        "tokens": 14531690496,
        "learning_rate": 7.02778146896787e-05,
        "gradient_norm": 0.44384390115737915,
        "train_loss": 3.020155668258667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27718,
        "tokens": 14532214784,
        "learning_rate": 7.026998778275843e-05,
        "gradient_norm": 0.3698827624320984,
        "train_loss": 3.0363759994506836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27719,
        "tokens": 14532739072,
        "learning_rate": 7.026216379942319e-05,
        "gradient_norm": 0.4328007400035858,
        "train_loss": 3.0147852897644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27720,
        "tokens": 14533263360,
        "learning_rate": 7.025434273976109e-05,
        "gradient_norm": 0.4544123411178589,
        "train_loss": 3.0437088012695312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27721,
        "tokens": 14533787648,
        "learning_rate": 7.024652460386013e-05,
        "gradient_norm": 0.40667420625686646,
        "train_loss": 2.9837217330932617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27722,
        "tokens": 14534311936,
        "learning_rate": 7.023870939180834e-05,
        "gradient_norm": 0.4002161920070648,
        "train_loss": 3.002432107925415,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27723,
        "tokens": 14534836224,
        "learning_rate": 7.023089710369367e-05,
        "gradient_norm": 0.4407549500465393,
        "train_loss": 3.0299391746520996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27724,
        "tokens": 14535360512,
        "learning_rate": 7.022308773960402e-05,
        "gradient_norm": 0.47710081934928894,
        "train_loss": 3.0773162841796875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27725,
        "tokens": 14535884800,
        "learning_rate": 7.021528129962742e-05,
        "gradient_norm": 0.46233752369880676,
        "train_loss": 3.069425106048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27726,
        "tokens": 14536409088,
        "learning_rate": 7.02074777838516e-05,
        "gradient_norm": 0.4468024671077728,
        "train_loss": 3.0065107345581055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27727,
        "tokens": 14536933376,
        "learning_rate": 7.019967719236448e-05,
        "gradient_norm": 0.4308779537677765,
        "train_loss": 3.0071895122528076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27728,
        "tokens": 14537457664,
        "learning_rate": 7.019187952525382e-05,
        "gradient_norm": 0.41886284947395325,
        "train_loss": 3.021350383758545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27729,
        "tokens": 14537981952,
        "learning_rate": 7.018408478260745e-05,
        "gradient_norm": 0.43761196732521057,
        "train_loss": 3.030017852783203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27730,
        "tokens": 14538506240,
        "learning_rate": 7.017629296451306e-05,
        "gradient_norm": 0.47511163353919983,
        "train_loss": 2.9438836574554443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27731,
        "tokens": 14539030528,
        "learning_rate": 7.016850407105837e-05,
        "gradient_norm": 0.45378854870796204,
        "train_loss": 2.9514360427856445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27732,
        "tokens": 14539554816,
        "learning_rate": 7.016071810233104e-05,
        "gradient_norm": 0.47329819202423096,
        "train_loss": 3.028243064880371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27733,
        "tokens": 14540079104,
        "learning_rate": 7.015293505841872e-05,
        "gradient_norm": 0.4260288178920746,
        "train_loss": 2.9983997344970703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27734,
        "tokens": 14540603392,
        "learning_rate": 7.014515493940907e-05,
        "gradient_norm": 0.42324548959732056,
        "train_loss": 3.0274181365966797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27735,
        "tokens": 14541127680,
        "learning_rate": 7.01373777453896e-05,
        "gradient_norm": 0.43756023049354553,
        "train_loss": 3.0272445678710938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27736,
        "tokens": 14541651968,
        "learning_rate": 7.012960347644787e-05,
        "gradient_norm": 0.42014414072036743,
        "train_loss": 3.0057454109191895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27737,
        "tokens": 14542176256,
        "learning_rate": 7.012183213267136e-05,
        "gradient_norm": 0.4028068482875824,
        "train_loss": 3.0186500549316406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27738,
        "tokens": 14542700544,
        "learning_rate": 7.011406371414763e-05,
        "gradient_norm": 0.3660590350627899,
        "train_loss": 3.016174077987671,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27739,
        "tokens": 14543224832,
        "learning_rate": 7.010629822096402e-05,
        "gradient_norm": 0.39792516827583313,
        "train_loss": 3.0360610485076904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27740,
        "tokens": 14543749120,
        "learning_rate": 7.0098535653208e-05,
        "gradient_norm": 0.386841744184494,
        "train_loss": 2.9787445068359375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27741,
        "tokens": 14544273408,
        "learning_rate": 7.009077601096697e-05,
        "gradient_norm": 0.37377727031707764,
        "train_loss": 2.9895517826080322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27742,
        "tokens": 14544797696,
        "learning_rate": 7.008301929432823e-05,
        "gradient_norm": 0.4807163178920746,
        "train_loss": 3.045287609100342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27743,
        "tokens": 14545321984,
        "learning_rate": 7.007526550337906e-05,
        "gradient_norm": 0.3819146156311035,
        "train_loss": 3.0458741188049316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27744,
        "tokens": 14545846272,
        "learning_rate": 7.006751463820681e-05,
        "gradient_norm": 0.43028563261032104,
        "train_loss": 2.9920363426208496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27745,
        "tokens": 14546370560,
        "learning_rate": 7.005976669889869e-05,
        "gradient_norm": 0.4369170665740967,
        "train_loss": 3.060086250305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27746,
        "tokens": 14546894848,
        "learning_rate": 7.005202168554195e-05,
        "gradient_norm": 0.436535507440567,
        "train_loss": 2.9885945320129395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27747,
        "tokens": 14547419136,
        "learning_rate": 7.00442795982237e-05,
        "gradient_norm": 0.40590208768844604,
        "train_loss": 3.046513080596924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27748,
        "tokens": 14547943424,
        "learning_rate": 7.003654043703116e-05,
        "gradient_norm": 0.3719848692417145,
        "train_loss": 3.021650791168213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27749,
        "tokens": 14548467712,
        "learning_rate": 7.002880420205139e-05,
        "gradient_norm": 0.5044216513633728,
        "train_loss": 3.0398311614990234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27750,
        "tokens": 14548992000,
        "learning_rate": 7.002107089337148e-05,
        "gradient_norm": 0.600836455821991,
        "train_loss": 3.0281128883361816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27751,
        "tokens": 14549516288,
        "learning_rate": 7.001334051107853e-05,
        "gradient_norm": 0.4398258328437805,
        "train_loss": 2.933566093444824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27752,
        "tokens": 14550040576,
        "learning_rate": 7.000561305525949e-05,
        "gradient_norm": 0.47344815731048584,
        "train_loss": 2.979661464691162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27753,
        "tokens": 14550564864,
        "learning_rate": 6.999788852600135e-05,
        "gradient_norm": 0.44719746708869934,
        "train_loss": 3.0097289085388184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27754,
        "tokens": 14551089152,
        "learning_rate": 6.99901669233911e-05,
        "gradient_norm": 0.44334203004837036,
        "train_loss": 3.030345916748047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27755,
        "tokens": 14551613440,
        "learning_rate": 6.998244824751564e-05,
        "gradient_norm": 0.4231473207473755,
        "train_loss": 3.0922884941101074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27756,
        "tokens": 14552137728,
        "learning_rate": 6.997473249846182e-05,
        "gradient_norm": 0.4589250981807709,
        "train_loss": 2.9897255897521973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27757,
        "tokens": 14552662016,
        "learning_rate": 6.996701967631653e-05,
        "gradient_norm": 0.43050506711006165,
        "train_loss": 2.99680233001709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27758,
        "tokens": 14553186304,
        "learning_rate": 6.995930978116655e-05,
        "gradient_norm": 0.4140649139881134,
        "train_loss": 3.051760673522949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27759,
        "tokens": 14553710592,
        "learning_rate": 6.995160281309872e-05,
        "gradient_norm": 0.4475500285625458,
        "train_loss": 2.9805831909179688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27760,
        "tokens": 14554234880,
        "learning_rate": 6.994389877219975e-05,
        "gradient_norm": 0.4354063868522644,
        "train_loss": 2.9923269748687744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27761,
        "tokens": 14554759168,
        "learning_rate": 6.993619765855638e-05,
        "gradient_norm": 0.4337924122810364,
        "train_loss": 2.9825081825256348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27762,
        "tokens": 14555283456,
        "learning_rate": 6.992849947225525e-05,
        "gradient_norm": 0.4103383719921112,
        "train_loss": 2.982065439224243,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27763,
        "tokens": 14555807744,
        "learning_rate": 6.992080421338308e-05,
        "gradient_norm": 0.4672882854938507,
        "train_loss": 3.0352420806884766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27764,
        "tokens": 14556332032,
        "learning_rate": 6.991311188202641e-05,
        "gradient_norm": 0.4399890899658203,
        "train_loss": 3.031566619873047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27765,
        "tokens": 14556856320,
        "learning_rate": 6.990542247827193e-05,
        "gradient_norm": 0.4452960789203644,
        "train_loss": 2.9842703342437744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27766,
        "tokens": 14557380608,
        "learning_rate": 6.989773600220609e-05,
        "gradient_norm": 0.43828147649765015,
        "train_loss": 3.0026235580444336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27767,
        "tokens": 14557904896,
        "learning_rate": 6.98900524539155e-05,
        "gradient_norm": 0.4501991868019104,
        "train_loss": 2.9646658897399902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27768,
        "tokens": 14558429184,
        "learning_rate": 6.988237183348653e-05,
        "gradient_norm": 0.4576902687549591,
        "train_loss": 3.0080442428588867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27769,
        "tokens": 14558953472,
        "learning_rate": 6.987469414100581e-05,
        "gradient_norm": 0.4423985183238983,
        "train_loss": 2.9777257442474365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27770,
        "tokens": 14559477760,
        "learning_rate": 6.986701937655959e-05,
        "gradient_norm": 0.43068256974220276,
        "train_loss": 3.01967191696167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27771,
        "tokens": 14560002048,
        "learning_rate": 6.985934754023438e-05,
        "gradient_norm": 0.4076860845088959,
        "train_loss": 3.0208773612976074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27772,
        "tokens": 14560526336,
        "learning_rate": 6.985167863211642e-05,
        "gradient_norm": 0.420604407787323,
        "train_loss": 3.007267475128174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27773,
        "tokens": 14561050624,
        "learning_rate": 6.984401265229211e-05,
        "gradient_norm": 0.3972039520740509,
        "train_loss": 3.00966215133667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27774,
        "tokens": 14561574912,
        "learning_rate": 6.98363496008478e-05,
        "gradient_norm": 0.4397677481174469,
        "train_loss": 3.025559425354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27775,
        "tokens": 14562099200,
        "learning_rate": 6.982868947786962e-05,
        "gradient_norm": 0.4027286767959595,
        "train_loss": 3.0307295322418213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27776,
        "tokens": 14562623488,
        "learning_rate": 6.98210322834439e-05,
        "gradient_norm": 0.4270254075527191,
        "train_loss": 3.0612077713012695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27777,
        "tokens": 14563147776,
        "learning_rate": 6.981337801765673e-05,
        "gradient_norm": 0.391511470079422,
        "train_loss": 3.0074210166931152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27778,
        "tokens": 14563672064,
        "learning_rate": 6.980572668059437e-05,
        "gradient_norm": 0.4310961365699768,
        "train_loss": 3.005221366882324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27779,
        "tokens": 14564196352,
        "learning_rate": 6.979807827234284e-05,
        "gradient_norm": 0.43026044964790344,
        "train_loss": 3.0247998237609863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27780,
        "tokens": 14564720640,
        "learning_rate": 6.979043279298834e-05,
        "gradient_norm": 0.4024229049682617,
        "train_loss": 3.0418572425842285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27781,
        "tokens": 14565244928,
        "learning_rate": 6.978279024261687e-05,
        "gradient_norm": 0.47355619072914124,
        "train_loss": 2.949748992919922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27782,
        "tokens": 14565769216,
        "learning_rate": 6.977515062131447e-05,
        "gradient_norm": 0.421968936920166,
        "train_loss": 3.051577568054199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27783,
        "tokens": 14566293504,
        "learning_rate": 6.976751392916708e-05,
        "gradient_norm": 0.433104932308197,
        "train_loss": 3.036797046661377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27784,
        "tokens": 14566817792,
        "learning_rate": 6.975988016626074e-05,
        "gradient_norm": 0.3911905288696289,
        "train_loss": 2.965240955352783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27785,
        "tokens": 14567342080,
        "learning_rate": 6.975224933268137e-05,
        "gradient_norm": 0.4490615725517273,
        "train_loss": 2.974091053009033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27786,
        "tokens": 14567866368,
        "learning_rate": 6.97446214285148e-05,
        "gradient_norm": 0.41380083560943604,
        "train_loss": 3.036762237548828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27787,
        "tokens": 14568390656,
        "learning_rate": 6.973699645384698e-05,
        "gradient_norm": 0.3888325095176697,
        "train_loss": 3.0450949668884277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27788,
        "tokens": 14568914944,
        "learning_rate": 6.972937440876366e-05,
        "gradient_norm": 0.42364758253097534,
        "train_loss": 3.033416986465454,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27789,
        "tokens": 14569439232,
        "learning_rate": 6.972175529335067e-05,
        "gradient_norm": 0.4194174110889435,
        "train_loss": 3.0662355422973633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27790,
        "tokens": 14569963520,
        "learning_rate": 6.971413910769375e-05,
        "gradient_norm": 0.3880878984928131,
        "train_loss": 2.9376718997955322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27791,
        "tokens": 14570487808,
        "learning_rate": 6.97065258518787e-05,
        "gradient_norm": 0.39996978640556335,
        "train_loss": 3.0122556686401367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27792,
        "tokens": 14571012096,
        "learning_rate": 6.96989155259911e-05,
        "gradient_norm": 0.42414355278015137,
        "train_loss": 3.012308120727539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27793,
        "tokens": 14571536384,
        "learning_rate": 6.96913081301167e-05,
        "gradient_norm": 0.42914170026779175,
        "train_loss": 3.0124144554138184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27794,
        "tokens": 14572060672,
        "learning_rate": 6.968370366434117e-05,
        "gradient_norm": 0.46802639961242676,
        "train_loss": 2.9886200428009033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27795,
        "tokens": 14572584960,
        "learning_rate": 6.967610212874998e-05,
        "gradient_norm": 0.4045162498950958,
        "train_loss": 2.94272518157959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27796,
        "tokens": 14573109248,
        "learning_rate": 6.966850352342879e-05,
        "gradient_norm": 0.4604523777961731,
        "train_loss": 3.0060887336730957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27797,
        "tokens": 14573633536,
        "learning_rate": 6.966090784846309e-05,
        "gradient_norm": 0.45566657185554504,
        "train_loss": 3.0090484619140625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27798,
        "tokens": 14574157824,
        "learning_rate": 6.965331510393843e-05,
        "gradient_norm": 0.3950772285461426,
        "train_loss": 3.0008764266967773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27799,
        "tokens": 14574682112,
        "learning_rate": 6.964572528994018e-05,
        "gradient_norm": 0.4565322995185852,
        "train_loss": 3.0215654373168945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27800,
        "tokens": 14575206400,
        "learning_rate": 6.96381384065539e-05,
        "gradient_norm": 0.41594403982162476,
        "train_loss": 3.0528640747070312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27801,
        "tokens": 14575730688,
        "learning_rate": 6.963055445386487e-05,
        "gradient_norm": 0.4194297194480896,
        "train_loss": 2.9923272132873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27802,
        "tokens": 14576254976,
        "learning_rate": 6.962297343195855e-05,
        "gradient_norm": 0.4335860311985016,
        "train_loss": 3.0034399032592773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27803,
        "tokens": 14576779264,
        "learning_rate": 6.961539534092019e-05,
        "gradient_norm": 0.38923099637031555,
        "train_loss": 3.016414165496826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27804,
        "tokens": 14577303552,
        "learning_rate": 6.960782018083514e-05,
        "gradient_norm": 0.4110461473464966,
        "train_loss": 3.0145087242126465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27805,
        "tokens": 14577827840,
        "learning_rate": 6.960024795178867e-05,
        "gradient_norm": 0.41233137249946594,
        "train_loss": 2.990478515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27806,
        "tokens": 14578352128,
        "learning_rate": 6.959267865386602e-05,
        "gradient_norm": 0.4154711961746216,
        "train_loss": 3.056837558746338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27807,
        "tokens": 14578876416,
        "learning_rate": 6.958511228715239e-05,
        "gradient_norm": 0.4426180422306061,
        "train_loss": 2.888929843902588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27808,
        "tokens": 14579400704,
        "learning_rate": 6.957754885173288e-05,
        "gradient_norm": 0.45129573345184326,
        "train_loss": 3.099151134490967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27809,
        "tokens": 14579924992,
        "learning_rate": 6.956998834769275e-05,
        "gradient_norm": 0.451865553855896,
        "train_loss": 3.0251104831695557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27810,
        "tokens": 14580449280,
        "learning_rate": 6.956243077511698e-05,
        "gradient_norm": 0.4344675838947296,
        "train_loss": 3.035217046737671,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27811,
        "tokens": 14580973568,
        "learning_rate": 6.955487613409074e-05,
        "gradient_norm": 0.43853771686553955,
        "train_loss": 3.0441670417785645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27812,
        "tokens": 14581497856,
        "learning_rate": 6.954732442469897e-05,
        "gradient_norm": 0.5236154794692993,
        "train_loss": 3.098170757293701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27813,
        "tokens": 14582022144,
        "learning_rate": 6.953977564702675e-05,
        "gradient_norm": 0.47671839594841003,
        "train_loss": 3.0247013568878174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27814,
        "tokens": 14582546432,
        "learning_rate": 6.953222980115906e-05,
        "gradient_norm": 0.4949716329574585,
        "train_loss": 3.0235238075256348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27815,
        "tokens": 14583070720,
        "learning_rate": 6.952468688718077e-05,
        "gradient_norm": 0.46768665313720703,
        "train_loss": 3.03293514251709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27816,
        "tokens": 14583595008,
        "learning_rate": 6.951714690517683e-05,
        "gradient_norm": 0.4913460910320282,
        "train_loss": 3.113224983215332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27817,
        "tokens": 14584119296,
        "learning_rate": 6.950960985523208e-05,
        "gradient_norm": 0.4764682352542877,
        "train_loss": 3.0298964977264404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27818,
        "tokens": 14584643584,
        "learning_rate": 6.950207573743142e-05,
        "gradient_norm": 0.4688216745853424,
        "train_loss": 2.974813461303711,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27819,
        "tokens": 14585167872,
        "learning_rate": 6.949454455185959e-05,
        "gradient_norm": 0.4835810959339142,
        "train_loss": 3.0474891662597656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27820,
        "tokens": 14585692160,
        "learning_rate": 6.94870162986014e-05,
        "gradient_norm": 0.44812265038490295,
        "train_loss": 3.024338960647583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27821,
        "tokens": 14586216448,
        "learning_rate": 6.94794909777416e-05,
        "gradient_norm": 0.44493696093559265,
        "train_loss": 3.103703737258911,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27822,
        "tokens": 14586740736,
        "learning_rate": 6.947196858936487e-05,
        "gradient_norm": 0.4527011513710022,
        "train_loss": 2.9560189247131348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27823,
        "tokens": 14587265024,
        "learning_rate": 6.946444913355584e-05,
        "gradient_norm": 0.48366081714630127,
        "train_loss": 2.959740161895752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27824,
        "tokens": 14587789312,
        "learning_rate": 6.945693261039923e-05,
        "gradient_norm": 0.460316926240921,
        "train_loss": 2.9729065895080566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27825,
        "tokens": 14588313600,
        "learning_rate": 6.944941901997962e-05,
        "gradient_norm": 0.4460389018058777,
        "train_loss": 3.0166876316070557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27826,
        "tokens": 14588837888,
        "learning_rate": 6.94419083623816e-05,
        "gradient_norm": 0.46577683091163635,
        "train_loss": 2.969944953918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27827,
        "tokens": 14589362176,
        "learning_rate": 6.94344006376897e-05,
        "gradient_norm": 0.41889843344688416,
        "train_loss": 3.033924102783203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27828,
        "tokens": 14589886464,
        "learning_rate": 6.942689584598838e-05,
        "gradient_norm": 0.4370720684528351,
        "train_loss": 3.0510072708129883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27829,
        "tokens": 14590410752,
        "learning_rate": 6.941939398736222e-05,
        "gradient_norm": 0.43193021416664124,
        "train_loss": 3.00642991065979,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27830,
        "tokens": 14590935040,
        "learning_rate": 6.941189506189556e-05,
        "gradient_norm": 0.44040778279304504,
        "train_loss": 3.006107807159424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27831,
        "tokens": 14591459328,
        "learning_rate": 6.940439906967288e-05,
        "gradient_norm": 0.4401102066040039,
        "train_loss": 3.0248301029205322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27832,
        "tokens": 14591983616,
        "learning_rate": 6.939690601077851e-05,
        "gradient_norm": 0.4328807294368744,
        "train_loss": 3.000941276550293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27833,
        "tokens": 14592507904,
        "learning_rate": 6.938941588529678e-05,
        "gradient_norm": 0.42266780138015747,
        "train_loss": 3.0049819946289062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27834,
        "tokens": 14593032192,
        "learning_rate": 6.938192869331209e-05,
        "gradient_norm": 0.46143996715545654,
        "train_loss": 2.960146427154541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27835,
        "tokens": 14593556480,
        "learning_rate": 6.937444443490864e-05,
        "gradient_norm": 0.400716096162796,
        "train_loss": 3.0235354900360107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27836,
        "tokens": 14594080768,
        "learning_rate": 6.936696311017072e-05,
        "gradient_norm": 0.42422863841056824,
        "train_loss": 2.9979703426361084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27837,
        "tokens": 14594605056,
        "learning_rate": 6.935948471918247e-05,
        "gradient_norm": 0.39117002487182617,
        "train_loss": 3.033228874206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27838,
        "tokens": 14595129344,
        "learning_rate": 6.935200926202815e-05,
        "gradient_norm": 0.4297741949558258,
        "train_loss": 3.011017322540283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27839,
        "tokens": 14595653632,
        "learning_rate": 6.934453673879186e-05,
        "gradient_norm": 0.40595266222953796,
        "train_loss": 3.0731866359710693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27840,
        "tokens": 14596177920,
        "learning_rate": 6.933706714955776e-05,
        "gradient_norm": 0.423422634601593,
        "train_loss": 3.006298065185547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27841,
        "tokens": 14596702208,
        "learning_rate": 6.932960049440984e-05,
        "gradient_norm": 0.4607192575931549,
        "train_loss": 3.02858829498291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27842,
        "tokens": 14597226496,
        "learning_rate": 6.932213677343225e-05,
        "gradient_norm": 0.4046412706375122,
        "train_loss": 2.968752145767212,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27843,
        "tokens": 14597750784,
        "learning_rate": 6.93146759867089e-05,
        "gradient_norm": 0.3969288766384125,
        "train_loss": 3.007378101348877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27844,
        "tokens": 14598275072,
        "learning_rate": 6.930721813432383e-05,
        "gradient_norm": 0.4373728632926941,
        "train_loss": 3.0553174018859863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27845,
        "tokens": 14598799360,
        "learning_rate": 6.929976321636102e-05,
        "gradient_norm": 0.43401575088500977,
        "train_loss": 2.978078603744507,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27846,
        "tokens": 14599323648,
        "learning_rate": 6.929231123290433e-05,
        "gradient_norm": 0.43165889382362366,
        "train_loss": 3.0430493354797363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27847,
        "tokens": 14599847936,
        "learning_rate": 6.928486218403767e-05,
        "gradient_norm": 0.37757256627082825,
        "train_loss": 3.028225898742676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27848,
        "tokens": 14600372224,
        "learning_rate": 6.927741606984486e-05,
        "gradient_norm": 0.4149346351623535,
        "train_loss": 3.0198798179626465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27849,
        "tokens": 14600896512,
        "learning_rate": 6.926997289040974e-05,
        "gradient_norm": 0.42073872685432434,
        "train_loss": 3.024379253387451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27850,
        "tokens": 14601420800,
        "learning_rate": 6.926253264581607e-05,
        "gradient_norm": 0.38396134972572327,
        "train_loss": 3.031068801879883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27851,
        "tokens": 14601945088,
        "learning_rate": 6.925509533614765e-05,
        "gradient_norm": 0.3864690959453583,
        "train_loss": 3.0219922065734863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27852,
        "tokens": 14602469376,
        "learning_rate": 6.92476609614881e-05,
        "gradient_norm": 0.4066965878009796,
        "train_loss": 3.0693469047546387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27853,
        "tokens": 14602993664,
        "learning_rate": 6.924022952192121e-05,
        "gradient_norm": 0.4033447206020355,
        "train_loss": 2.996180295944214,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27854,
        "tokens": 14603517952,
        "learning_rate": 6.923280101753056e-05,
        "gradient_norm": 0.4224763810634613,
        "train_loss": 2.957247734069824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27855,
        "tokens": 14604042240,
        "learning_rate": 6.922537544839979e-05,
        "gradient_norm": 0.39587634801864624,
        "train_loss": 3.0201706886291504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27856,
        "tokens": 14604566528,
        "learning_rate": 6.92179528146125e-05,
        "gradient_norm": 0.41079238057136536,
        "train_loss": 3.0664100646972656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27857,
        "tokens": 14605090816,
        "learning_rate": 6.921053311625222e-05,
        "gradient_norm": 0.431401789188385,
        "train_loss": 3.0151755809783936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27858,
        "tokens": 14605615104,
        "learning_rate": 6.920311635340247e-05,
        "gradient_norm": 0.43726110458374023,
        "train_loss": 2.9733242988586426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27859,
        "tokens": 14606139392,
        "learning_rate": 6.919570252614674e-05,
        "gradient_norm": 0.46529650688171387,
        "train_loss": 3.062312602996826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27860,
        "tokens": 14606663680,
        "learning_rate": 6.918829163456845e-05,
        "gradient_norm": 0.4436759352684021,
        "train_loss": 3.0554840564727783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27861,
        "tokens": 14607187968,
        "learning_rate": 6.918088367875109e-05,
        "gradient_norm": 0.3935569226741791,
        "train_loss": 2.9576544761657715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27862,
        "tokens": 14607712256,
        "learning_rate": 6.917347865877796e-05,
        "gradient_norm": 0.40356579422950745,
        "train_loss": 2.9942095279693604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27863,
        "tokens": 14608236544,
        "learning_rate": 6.916607657473251e-05,
        "gradient_norm": 0.4627711772918701,
        "train_loss": 2.971257209777832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27864,
        "tokens": 14608760832,
        "learning_rate": 6.915867742669797e-05,
        "gradient_norm": 0.42825788259506226,
        "train_loss": 3.0092697143554688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27865,
        "tokens": 14609285120,
        "learning_rate": 6.915128121475767e-05,
        "gradient_norm": 0.42896783351898193,
        "train_loss": 3.0008180141448975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27866,
        "tokens": 14609809408,
        "learning_rate": 6.914388793899484e-05,
        "gradient_norm": 0.4196702241897583,
        "train_loss": 3.0042927265167236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27867,
        "tokens": 14610333696,
        "learning_rate": 6.913649759949275e-05,
        "gradient_norm": 0.40925997495651245,
        "train_loss": 2.98819637298584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27868,
        "tokens": 14610857984,
        "learning_rate": 6.912911019633453e-05,
        "gradient_norm": 0.41775116324424744,
        "train_loss": 3.056478977203369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27869,
        "tokens": 14611382272,
        "learning_rate": 6.912172572960337e-05,
        "gradient_norm": 0.4727447032928467,
        "train_loss": 2.9471540451049805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27870,
        "tokens": 14611906560,
        "learning_rate": 6.911434419938236e-05,
        "gradient_norm": 0.4544343054294586,
        "train_loss": 3.012615203857422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27871,
        "tokens": 14612430848,
        "learning_rate": 6.910696560575466e-05,
        "gradient_norm": 0.49734413623809814,
        "train_loss": 3.0772929191589355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27872,
        "tokens": 14612955136,
        "learning_rate": 6.909958994880323e-05,
        "gradient_norm": 0.4623405933380127,
        "train_loss": 3.0423712730407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27873,
        "tokens": 14613479424,
        "learning_rate": 6.90922172286111e-05,
        "gradient_norm": 0.4587973356246948,
        "train_loss": 3.035342216491699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27874,
        "tokens": 14614003712,
        "learning_rate": 6.908484744526136e-05,
        "gradient_norm": 0.43495383858680725,
        "train_loss": 3.0025997161865234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27875,
        "tokens": 14614528000,
        "learning_rate": 6.907748059883687e-05,
        "gradient_norm": 0.43506568670272827,
        "train_loss": 3.127556800842285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27876,
        "tokens": 14615052288,
        "learning_rate": 6.907011668942062e-05,
        "gradient_norm": 0.4260323643684387,
        "train_loss": 3.0468215942382812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27877,
        "tokens": 14615576576,
        "learning_rate": 6.906275571709543e-05,
        "gradient_norm": 0.4479510486125946,
        "train_loss": 2.997553586959839,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27878,
        "tokens": 14616100864,
        "learning_rate": 6.90553976819442e-05,
        "gradient_norm": 0.412332147359848,
        "train_loss": 3.007715940475464,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27879,
        "tokens": 14616625152,
        "learning_rate": 6.904804258404975e-05,
        "gradient_norm": 0.447483092546463,
        "train_loss": 2.9942703247070312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27880,
        "tokens": 14617149440,
        "learning_rate": 6.904069042349488e-05,
        "gradient_norm": 0.42256760597229004,
        "train_loss": 3.0182881355285645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27881,
        "tokens": 14617673728,
        "learning_rate": 6.903334120036228e-05,
        "gradient_norm": 0.42535796761512756,
        "train_loss": 3.0302212238311768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27882,
        "tokens": 14618198016,
        "learning_rate": 6.902599491473478e-05,
        "gradient_norm": 0.3930394649505615,
        "train_loss": 3.0184974670410156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27883,
        "tokens": 14618722304,
        "learning_rate": 6.9018651566695e-05,
        "gradient_norm": 0.39427343010902405,
        "train_loss": 3.0457091331481934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27884,
        "tokens": 14619246592,
        "learning_rate": 6.901131115632559e-05,
        "gradient_norm": 0.4277452826499939,
        "train_loss": 3.0433602333068848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27885,
        "tokens": 14619770880,
        "learning_rate": 6.900397368370927e-05,
        "gradient_norm": 0.38649293780326843,
        "train_loss": 2.984555721282959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27886,
        "tokens": 14620295168,
        "learning_rate": 6.899663914892851e-05,
        "gradient_norm": 0.42262154817581177,
        "train_loss": 2.974429130554199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27887,
        "tokens": 14620819456,
        "learning_rate": 6.898930755206598e-05,
        "gradient_norm": 0.43265777826309204,
        "train_loss": 2.9913625717163086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27888,
        "tokens": 14621343744,
        "learning_rate": 6.89819788932041e-05,
        "gradient_norm": 0.4716396629810333,
        "train_loss": 3.0897202491760254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27889,
        "tokens": 14621868032,
        "learning_rate": 6.897465317242544e-05,
        "gradient_norm": 0.40239936113357544,
        "train_loss": 3.029033660888672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27890,
        "tokens": 14622392320,
        "learning_rate": 6.896733038981242e-05,
        "gradient_norm": 0.42301616072654724,
        "train_loss": 3.080448627471924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27891,
        "tokens": 14622916608,
        "learning_rate": 6.896001054544751e-05,
        "gradient_norm": 0.43004414439201355,
        "train_loss": 3.0334279537200928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27892,
        "tokens": 14623440896,
        "learning_rate": 6.895269363941304e-05,
        "gradient_norm": 0.3858872056007385,
        "train_loss": 3.0037975311279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27893,
        "tokens": 14623965184,
        "learning_rate": 6.894537967179141e-05,
        "gradient_norm": 0.42401063442230225,
        "train_loss": 3.0415215492248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27894,
        "tokens": 14624489472,
        "learning_rate": 6.893806864266498e-05,
        "gradient_norm": 0.4258408546447754,
        "train_loss": 3.0391478538513184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27895,
        "tokens": 14625013760,
        "learning_rate": 6.893076055211597e-05,
        "gradient_norm": 0.48567456007003784,
        "train_loss": 3.0500996112823486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27896,
        "tokens": 14625538048,
        "learning_rate": 6.892345540022673e-05,
        "gradient_norm": 0.42274200916290283,
        "train_loss": 2.973851442337036,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27897,
        "tokens": 14626062336,
        "learning_rate": 6.891615318707938e-05,
        "gradient_norm": 0.4971000850200653,
        "train_loss": 3.0641534328460693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27898,
        "tokens": 14626586624,
        "learning_rate": 6.890885391275622e-05,
        "gradient_norm": 0.422382116317749,
        "train_loss": 2.989271402359009,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27899,
        "tokens": 14627110912,
        "learning_rate": 6.890155757733936e-05,
        "gradient_norm": 0.420587420463562,
        "train_loss": 3.0448288917541504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27900,
        "tokens": 14627635200,
        "learning_rate": 6.889426418091093e-05,
        "gradient_norm": 0.4520307183265686,
        "train_loss": 3.035175323486328,
        "val_loss": 2.964456081390381,
        "hellaswag_acc": 0.2849034070968628,
        "hellaswag_acc_norm": 0.2989444136619568
    },
    {
        "step": 27901,
        "tokens": 14628159488,
        "learning_rate": 6.888697372355305e-05,
        "gradient_norm": 0.4426092803478241,
        "train_loss": 3.0422277450561523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27902,
        "tokens": 14628683776,
        "learning_rate": 6.887968620534777e-05,
        "gradient_norm": 0.4558774530887604,
        "train_loss": 3.0217838287353516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27903,
        "tokens": 14629208064,
        "learning_rate": 6.887240162637708e-05,
        "gradient_norm": 0.38156288862228394,
        "train_loss": 3.0665855407714844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27904,
        "tokens": 14629732352,
        "learning_rate": 6.8865119986723e-05,
        "gradient_norm": 0.3973136842250824,
        "train_loss": 3.0315301418304443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27905,
        "tokens": 14630256640,
        "learning_rate": 6.885784128646755e-05,
        "gradient_norm": 0.44208821654319763,
        "train_loss": 3.0472137928009033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27906,
        "tokens": 14630780928,
        "learning_rate": 6.885056552569259e-05,
        "gradient_norm": 0.38612091541290283,
        "train_loss": 3.0044612884521484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27907,
        "tokens": 14631305216,
        "learning_rate": 6.884329270448011e-05,
        "gradient_norm": 0.3867538571357727,
        "train_loss": 3.0184473991394043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27908,
        "tokens": 14631829504,
        "learning_rate": 6.883602282291183e-05,
        "gradient_norm": 0.4212157428264618,
        "train_loss": 3.0646204948425293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27909,
        "tokens": 14632353792,
        "learning_rate": 6.88287558810697e-05,
        "gradient_norm": 0.44821006059646606,
        "train_loss": 3.047451972961426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27910,
        "tokens": 14632878080,
        "learning_rate": 6.882149187903547e-05,
        "gradient_norm": 0.39230215549468994,
        "train_loss": 3.0385067462921143,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27911,
        "tokens": 14633402368,
        "learning_rate": 6.881423081689096e-05,
        "gradient_norm": 0.42183899879455566,
        "train_loss": 2.970640182495117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27912,
        "tokens": 14633926656,
        "learning_rate": 6.880697269471781e-05,
        "gradient_norm": 0.49094054102897644,
        "train_loss": 3.0547916889190674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27913,
        "tokens": 14634450944,
        "learning_rate": 6.879971751259776e-05,
        "gradient_norm": 0.42077192664146423,
        "train_loss": 2.989988327026367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27914,
        "tokens": 14634975232,
        "learning_rate": 6.879246527061251e-05,
        "gradient_norm": 0.3885713219642639,
        "train_loss": 2.9662551879882812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27915,
        "tokens": 14635499520,
        "learning_rate": 6.878521596884367e-05,
        "gradient_norm": 0.4008883535861969,
        "train_loss": 2.994953155517578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27916,
        "tokens": 14636023808,
        "learning_rate": 6.877796960737285e-05,
        "gradient_norm": 0.4263816475868225,
        "train_loss": 2.99061918258667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27917,
        "tokens": 14636548096,
        "learning_rate": 6.877072618628157e-05,
        "gradient_norm": 0.4405721127986908,
        "train_loss": 3.009617805480957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27918,
        "tokens": 14637072384,
        "learning_rate": 6.876348570565143e-05,
        "gradient_norm": 0.412799209356308,
        "train_loss": 3.021681308746338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27919,
        "tokens": 14637596672,
        "learning_rate": 6.875624816556387e-05,
        "gradient_norm": 0.42363351583480835,
        "train_loss": 3.066445827484131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27920,
        "tokens": 14638120960,
        "learning_rate": 6.87490135661004e-05,
        "gradient_norm": 0.4159126281738281,
        "train_loss": 3.009575843811035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27921,
        "tokens": 14638645248,
        "learning_rate": 6.874178190734243e-05,
        "gradient_norm": 0.41274476051330566,
        "train_loss": 3.023306131362915,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27922,
        "tokens": 14639169536,
        "learning_rate": 6.873455318937138e-05,
        "gradient_norm": 0.4131115972995758,
        "train_loss": 3.0234851837158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27923,
        "tokens": 14639693824,
        "learning_rate": 6.872732741226861e-05,
        "gradient_norm": 0.36819988489151,
        "train_loss": 3.009038209915161,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27924,
        "tokens": 14640218112,
        "learning_rate": 6.872010457611545e-05,
        "gradient_norm": 0.37234026193618774,
        "train_loss": 2.9944558143615723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27925,
        "tokens": 14640742400,
        "learning_rate": 6.871288468099322e-05,
        "gradient_norm": 0.4450454115867615,
        "train_loss": 2.9922306537628174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27926,
        "tokens": 14641266688,
        "learning_rate": 6.870566772698314e-05,
        "gradient_norm": 0.40980634093284607,
        "train_loss": 2.965099811553955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27927,
        "tokens": 14641790976,
        "learning_rate": 6.869845371416652e-05,
        "gradient_norm": 0.43212202191352844,
        "train_loss": 3.0055947303771973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27928,
        "tokens": 14642315264,
        "learning_rate": 6.869124264262448e-05,
        "gradient_norm": 0.42593905329704285,
        "train_loss": 3.019674777984619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27929,
        "tokens": 14642839552,
        "learning_rate": 6.868403451243831e-05,
        "gradient_norm": 0.577954113483429,
        "train_loss": 3.0546975135803223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27930,
        "tokens": 14643363840,
        "learning_rate": 6.8676829323689e-05,
        "gradient_norm": 0.45748263597488403,
        "train_loss": 2.98392391204834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27931,
        "tokens": 14643888128,
        "learning_rate": 6.866962707645777e-05,
        "gradient_norm": 0.5221619606018066,
        "train_loss": 2.9979562759399414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27932,
        "tokens": 14644412416,
        "learning_rate": 6.866242777082561e-05,
        "gradient_norm": 0.47155794501304626,
        "train_loss": 3.001884937286377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27933,
        "tokens": 14644936704,
        "learning_rate": 6.865523140687359e-05,
        "gradient_norm": 0.4953084886074066,
        "train_loss": 3.03458833694458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27934,
        "tokens": 14645460992,
        "learning_rate": 6.864803798468275e-05,
        "gradient_norm": 0.4576849639415741,
        "train_loss": 3.0219926834106445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27935,
        "tokens": 14645985280,
        "learning_rate": 6.864084750433397e-05,
        "gradient_norm": 0.47924110293388367,
        "train_loss": 3.039161205291748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27936,
        "tokens": 14646509568,
        "learning_rate": 6.86336599659083e-05,
        "gradient_norm": 0.4586602747440338,
        "train_loss": 3.000394582748413,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27937,
        "tokens": 14647033856,
        "learning_rate": 6.862647536948658e-05,
        "gradient_norm": 0.42099547386169434,
        "train_loss": 2.985133647918701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27938,
        "tokens": 14647558144,
        "learning_rate": 6.861929371514967e-05,
        "gradient_norm": 0.40701717138290405,
        "train_loss": 3.0099380016326904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27939,
        "tokens": 14648082432,
        "learning_rate": 6.861211500297843e-05,
        "gradient_norm": 0.4443708658218384,
        "train_loss": 3.0001466274261475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27940,
        "tokens": 14648606720,
        "learning_rate": 6.860493923305371e-05,
        "gradient_norm": 0.5013041496276855,
        "train_loss": 3.195695161819458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27941,
        "tokens": 14649131008,
        "learning_rate": 6.859776640545618e-05,
        "gradient_norm": 0.4781269133090973,
        "train_loss": 2.946317195892334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27942,
        "tokens": 14649655296,
        "learning_rate": 6.859059652026666e-05,
        "gradient_norm": 0.4375019073486328,
        "train_loss": 3.0430893898010254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27943,
        "tokens": 14650179584,
        "learning_rate": 6.858342957756581e-05,
        "gradient_norm": 0.4624289572238922,
        "train_loss": 3.050046920776367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27944,
        "tokens": 14650703872,
        "learning_rate": 6.857626557743433e-05,
        "gradient_norm": 0.4214124381542206,
        "train_loss": 2.995900869369507,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27945,
        "tokens": 14651228160,
        "learning_rate": 6.856910451995287e-05,
        "gradient_norm": 0.4612763226032257,
        "train_loss": 2.9756357669830322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27946,
        "tokens": 14651752448,
        "learning_rate": 6.8561946405202e-05,
        "gradient_norm": 0.4335744380950928,
        "train_loss": 3.0176010131835938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27947,
        "tokens": 14652276736,
        "learning_rate": 6.855479123326236e-05,
        "gradient_norm": 0.4371967017650604,
        "train_loss": 3.017648220062256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27948,
        "tokens": 14652801024,
        "learning_rate": 6.85476390042144e-05,
        "gradient_norm": 0.4121040403842926,
        "train_loss": 3.0374083518981934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27949,
        "tokens": 14653325312,
        "learning_rate": 6.85404897181387e-05,
        "gradient_norm": 0.3785122334957123,
        "train_loss": 2.9912619590759277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27950,
        "tokens": 14653849600,
        "learning_rate": 6.853334337511568e-05,
        "gradient_norm": 0.39743831753730774,
        "train_loss": 2.966485023498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27951,
        "tokens": 14654373888,
        "learning_rate": 6.852619997522585e-05,
        "gradient_norm": 0.4258696436882019,
        "train_loss": 2.983731746673584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27952,
        "tokens": 14654898176,
        "learning_rate": 6.851905951854951e-05,
        "gradient_norm": 0.4195575714111328,
        "train_loss": 2.995684862136841,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27953,
        "tokens": 14655422464,
        "learning_rate": 6.851192200516717e-05,
        "gradient_norm": 0.3953217566013336,
        "train_loss": 3.0302820205688477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27954,
        "tokens": 14655946752,
        "learning_rate": 6.850478743515905e-05,
        "gradient_norm": 0.41907140612602234,
        "train_loss": 3.080350399017334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27955,
        "tokens": 14656471040,
        "learning_rate": 6.849765580860552e-05,
        "gradient_norm": 0.5711882710456848,
        "train_loss": 3.0927605628967285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27956,
        "tokens": 14656995328,
        "learning_rate": 6.849052712558685e-05,
        "gradient_norm": 0.47028201818466187,
        "train_loss": 3.011348247528076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27957,
        "tokens": 14657519616,
        "learning_rate": 6.848340138618326e-05,
        "gradient_norm": 0.6075536012649536,
        "train_loss": 3.0484042167663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27958,
        "tokens": 14658043904,
        "learning_rate": 6.8476278590475e-05,
        "gradient_norm": 0.47361433506011963,
        "train_loss": 3.045750141143799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27959,
        "tokens": 14658568192,
        "learning_rate": 6.84691587385422e-05,
        "gradient_norm": 0.43887263536453247,
        "train_loss": 3.0224905014038086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27960,
        "tokens": 14659092480,
        "learning_rate": 6.846204183046507e-05,
        "gradient_norm": 0.40728455781936646,
        "train_loss": 3.0293750762939453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27961,
        "tokens": 14659616768,
        "learning_rate": 6.845492786632364e-05,
        "gradient_norm": 0.4072933793067932,
        "train_loss": 3.0514774322509766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27962,
        "tokens": 14660141056,
        "learning_rate": 6.844781684619804e-05,
        "gradient_norm": 0.46308329701423645,
        "train_loss": 2.9911980628967285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27963,
        "tokens": 14660665344,
        "learning_rate": 6.844070877016828e-05,
        "gradient_norm": 0.42814141511917114,
        "train_loss": 2.991344928741455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27964,
        "tokens": 14661189632,
        "learning_rate": 6.843360363831438e-05,
        "gradient_norm": 0.44962745904922485,
        "train_loss": 3.049234390258789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27965,
        "tokens": 14661713920,
        "learning_rate": 6.842650145071632e-05,
        "gradient_norm": 0.42890846729278564,
        "train_loss": 2.98829984664917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27966,
        "tokens": 14662238208,
        "learning_rate": 6.841940220745408e-05,
        "gradient_norm": 0.43808668851852417,
        "train_loss": 3.0045437812805176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27967,
        "tokens": 14662762496,
        "learning_rate": 6.841230590860748e-05,
        "gradient_norm": 0.41333815455436707,
        "train_loss": 3.0055832862854004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27968,
        "tokens": 14663286784,
        "learning_rate": 6.840521255425651e-05,
        "gradient_norm": 0.4233570992946625,
        "train_loss": 3.0352354049682617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27969,
        "tokens": 14663811072,
        "learning_rate": 6.839812214448095e-05,
        "gradient_norm": 0.4262252748012543,
        "train_loss": 3.001253128051758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27970,
        "tokens": 14664335360,
        "learning_rate": 6.83910346793606e-05,
        "gradient_norm": 0.44492146372795105,
        "train_loss": 2.9738926887512207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27971,
        "tokens": 14664859648,
        "learning_rate": 6.838395015897525e-05,
        "gradient_norm": 0.4292099177837372,
        "train_loss": 3.058356761932373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27972,
        "tokens": 14665383936,
        "learning_rate": 6.83768685834047e-05,
        "gradient_norm": 0.4596565067768097,
        "train_loss": 3.1304402351379395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27973,
        "tokens": 14665908224,
        "learning_rate": 6.836978995272858e-05,
        "gradient_norm": 0.45987802743911743,
        "train_loss": 3.0428624153137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27974,
        "tokens": 14666432512,
        "learning_rate": 6.836271426702661e-05,
        "gradient_norm": 0.4526523947715759,
        "train_loss": 3.014860153198242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27975,
        "tokens": 14666956800,
        "learning_rate": 6.83556415263784e-05,
        "gradient_norm": 0.46188104152679443,
        "train_loss": 3.04436993598938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27976,
        "tokens": 14667481088,
        "learning_rate": 6.834857173086365e-05,
        "gradient_norm": 0.49195781350135803,
        "train_loss": 3.0745224952697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27977,
        "tokens": 14668005376,
        "learning_rate": 6.834150488056185e-05,
        "gradient_norm": 0.443219393491745,
        "train_loss": 2.99330472946167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27978,
        "tokens": 14668529664,
        "learning_rate": 6.833444097555258e-05,
        "gradient_norm": 0.45959097146987915,
        "train_loss": 3.0311267375946045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27979,
        "tokens": 14669053952,
        "learning_rate": 6.832738001591537e-05,
        "gradient_norm": 0.4742325246334076,
        "train_loss": 3.0016884803771973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27980,
        "tokens": 14669578240,
        "learning_rate": 6.832032200172967e-05,
        "gradient_norm": 0.4181949198246002,
        "train_loss": 3.0126776695251465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27981,
        "tokens": 14670102528,
        "learning_rate": 6.831326693307492e-05,
        "gradient_norm": 0.4574693441390991,
        "train_loss": 3.028752326965332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27982,
        "tokens": 14670626816,
        "learning_rate": 6.830621481003057e-05,
        "gradient_norm": 0.42086121439933777,
        "train_loss": 3.0210862159729004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27983,
        "tokens": 14671151104,
        "learning_rate": 6.829916563267598e-05,
        "gradient_norm": 0.3945341110229492,
        "train_loss": 3.015324115753174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27984,
        "tokens": 14671675392,
        "learning_rate": 6.829211940109049e-05,
        "gradient_norm": 0.4713849425315857,
        "train_loss": 3.0159170627593994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27985,
        "tokens": 14672199680,
        "learning_rate": 6.828507611535343e-05,
        "gradient_norm": 0.4218013882637024,
        "train_loss": 3.042823314666748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27986,
        "tokens": 14672723968,
        "learning_rate": 6.827803577554408e-05,
        "gradient_norm": 0.36431658267974854,
        "train_loss": 2.9514341354370117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27987,
        "tokens": 14673248256,
        "learning_rate": 6.82709983817417e-05,
        "gradient_norm": 0.3933638632297516,
        "train_loss": 2.9994609355926514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27988,
        "tokens": 14673772544,
        "learning_rate": 6.826396393402543e-05,
        "gradient_norm": 0.39362701773643494,
        "train_loss": 3.0091075897216797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27989,
        "tokens": 14674296832,
        "learning_rate": 6.825693243247458e-05,
        "gradient_norm": 0.4682977795600891,
        "train_loss": 3.08099365234375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27990,
        "tokens": 14674821120,
        "learning_rate": 6.824990387716818e-05,
        "gradient_norm": 0.40588992834091187,
        "train_loss": 2.990936756134033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27991,
        "tokens": 14675345408,
        "learning_rate": 6.82428782681854e-05,
        "gradient_norm": 0.3651728332042694,
        "train_loss": 3.0662405490875244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27992,
        "tokens": 14675869696,
        "learning_rate": 6.823585560560531e-05,
        "gradient_norm": 0.41937676072120667,
        "train_loss": 2.9777145385742188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27993,
        "tokens": 14676393984,
        "learning_rate": 6.822883588950696e-05,
        "gradient_norm": 0.3959907591342926,
        "train_loss": 3.004648208618164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27994,
        "tokens": 14676918272,
        "learning_rate": 6.822181911996937e-05,
        "gradient_norm": 0.3991717994213104,
        "train_loss": 3.0455613136291504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27995,
        "tokens": 14677442560,
        "learning_rate": 6.821480529707155e-05,
        "gradient_norm": 0.43799829483032227,
        "train_loss": 3.035881996154785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27996,
        "tokens": 14677966848,
        "learning_rate": 6.820779442089238e-05,
        "gradient_norm": 0.3877284824848175,
        "train_loss": 2.9958975315093994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27997,
        "tokens": 14678491136,
        "learning_rate": 6.820078649151084e-05,
        "gradient_norm": 0.4067113399505615,
        "train_loss": 2.983558177947998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27998,
        "tokens": 14679015424,
        "learning_rate": 6.81937815090058e-05,
        "gradient_norm": 0.43904468417167664,
        "train_loss": 2.9856433868408203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 27999,
        "tokens": 14679539712,
        "learning_rate": 6.818677947345606e-05,
        "gradient_norm": 0.39841771125793457,
        "train_loss": 3.036442279815674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28000,
        "tokens": 14680064000,
        "learning_rate": 6.817978038494053e-05,
        "gradient_norm": 0.4072396755218506,
        "train_loss": 2.9785971641540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28001,
        "tokens": 14680588288,
        "learning_rate": 6.81727842435379e-05,
        "gradient_norm": 0.41141077876091003,
        "train_loss": 3.006897211074829,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28002,
        "tokens": 14681112576,
        "learning_rate": 6.816579104932698e-05,
        "gradient_norm": 0.4295293390750885,
        "train_loss": 3.0136709213256836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28003,
        "tokens": 14681636864,
        "learning_rate": 6.815880080238642e-05,
        "gradient_norm": 0.4303509294986725,
        "train_loss": 3.0223898887634277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28004,
        "tokens": 14682161152,
        "learning_rate": 6.815181350279499e-05,
        "gradient_norm": 0.43598678708076477,
        "train_loss": 3.0178165435791016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28005,
        "tokens": 14682685440,
        "learning_rate": 6.814482915063131e-05,
        "gradient_norm": 0.40623992681503296,
        "train_loss": 2.950023651123047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28006,
        "tokens": 14683209728,
        "learning_rate": 6.813784774597395e-05,
        "gradient_norm": 0.4578477144241333,
        "train_loss": 2.966522216796875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28007,
        "tokens": 14683734016,
        "learning_rate": 6.813086928890159e-05,
        "gradient_norm": 0.42580679059028625,
        "train_loss": 3.0200514793395996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28008,
        "tokens": 14684258304,
        "learning_rate": 6.812389377949269e-05,
        "gradient_norm": 0.4146776497364044,
        "train_loss": 2.988368272781372,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28009,
        "tokens": 14684782592,
        "learning_rate": 6.811692121782581e-05,
        "gradient_norm": 0.40597212314605713,
        "train_loss": 2.9775052070617676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28010,
        "tokens": 14685306880,
        "learning_rate": 6.810995160397942e-05,
        "gradient_norm": 0.41427984833717346,
        "train_loss": 2.9929704666137695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28011,
        "tokens": 14685831168,
        "learning_rate": 6.810298493803199e-05,
        "gradient_norm": 0.4161913990974426,
        "train_loss": 2.9835705757141113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28012,
        "tokens": 14686355456,
        "learning_rate": 6.809602122006191e-05,
        "gradient_norm": 0.3698825538158417,
        "train_loss": 3.0350852012634277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28013,
        "tokens": 14686879744,
        "learning_rate": 6.808906045014759e-05,
        "gradient_norm": 0.4390990138053894,
        "train_loss": 2.979498863220215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28014,
        "tokens": 14687404032,
        "learning_rate": 6.80821026283674e-05,
        "gradient_norm": 0.41492241621017456,
        "train_loss": 3.03824520111084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28015,
        "tokens": 14687928320,
        "learning_rate": 6.80751477547996e-05,
        "gradient_norm": 0.45132219791412354,
        "train_loss": 3.1017096042633057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28016,
        "tokens": 14688452608,
        "learning_rate": 6.806819582952253e-05,
        "gradient_norm": 0.42943426966667175,
        "train_loss": 2.954343318939209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28017,
        "tokens": 14688976896,
        "learning_rate": 6.806124685261438e-05,
        "gradient_norm": 0.38947948813438416,
        "train_loss": 3.022082805633545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28018,
        "tokens": 14689501184,
        "learning_rate": 6.805430082415349e-05,
        "gradient_norm": 0.4908640682697296,
        "train_loss": 3.0143837928771973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28019,
        "tokens": 14690025472,
        "learning_rate": 6.80473577442179e-05,
        "gradient_norm": 0.43827590346336365,
        "train_loss": 2.9645609855651855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28020,
        "tokens": 14690549760,
        "learning_rate": 6.804041761288587e-05,
        "gradient_norm": 0.48254287242889404,
        "train_loss": 3.0530190467834473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28021,
        "tokens": 14691074048,
        "learning_rate": 6.803348043023545e-05,
        "gradient_norm": 0.451377809047699,
        "train_loss": 2.9928174018859863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28022,
        "tokens": 14691598336,
        "learning_rate": 6.80265461963448e-05,
        "gradient_norm": 0.3889649510383606,
        "train_loss": 2.967506170272827,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28023,
        "tokens": 14692122624,
        "learning_rate": 6.801961491129189e-05,
        "gradient_norm": 0.5202662944793701,
        "train_loss": 2.9784445762634277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28024,
        "tokens": 14692646912,
        "learning_rate": 6.801268657515479e-05,
        "gradient_norm": 0.43658751249313354,
        "train_loss": 2.9764087200164795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28025,
        "tokens": 14693171200,
        "learning_rate": 6.800576118801149e-05,
        "gradient_norm": 0.42237207293510437,
        "train_loss": 3.012366771697998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28026,
        "tokens": 14693695488,
        "learning_rate": 6.799883874993993e-05,
        "gradient_norm": 0.5029869675636292,
        "train_loss": 3.0444247722625732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28027,
        "tokens": 14694219776,
        "learning_rate": 6.799191926101803e-05,
        "gradient_norm": 0.4304904043674469,
        "train_loss": 2.9935660362243652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28028,
        "tokens": 14694744064,
        "learning_rate": 6.798500272132366e-05,
        "gradient_norm": 0.44399207830429077,
        "train_loss": 2.993166923522949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28029,
        "tokens": 14695268352,
        "learning_rate": 6.797808913093475e-05,
        "gradient_norm": 0.4924252927303314,
        "train_loss": 3.010632038116455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28030,
        "tokens": 14695792640,
        "learning_rate": 6.7971178489929e-05,
        "gradient_norm": 0.38433533906936646,
        "train_loss": 3.016927719116211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28031,
        "tokens": 14696316928,
        "learning_rate": 6.796427079838432e-05,
        "gradient_norm": 0.40847721695899963,
        "train_loss": 2.9974381923675537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28032,
        "tokens": 14696841216,
        "learning_rate": 6.795736605637837e-05,
        "gradient_norm": 0.4479253590106964,
        "train_loss": 3.027076244354248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28033,
        "tokens": 14697365504,
        "learning_rate": 6.79504642639889e-05,
        "gradient_norm": 0.4369574785232544,
        "train_loss": 3.0789942741394043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28034,
        "tokens": 14697889792,
        "learning_rate": 6.794356542129366e-05,
        "gradient_norm": 0.5181044936180115,
        "train_loss": 3.0243258476257324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28035,
        "tokens": 14698414080,
        "learning_rate": 6.793666952837021e-05,
        "gradient_norm": 0.42789942026138306,
        "train_loss": 3.0254616737365723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28036,
        "tokens": 14698938368,
        "learning_rate": 6.792977658529625e-05,
        "gradient_norm": 0.4490537941455841,
        "train_loss": 3.013800621032715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28037,
        "tokens": 14699462656,
        "learning_rate": 6.79228865921493e-05,
        "gradient_norm": 0.4253884553909302,
        "train_loss": 3.0496764183044434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28038,
        "tokens": 14699986944,
        "learning_rate": 6.791599954900698e-05,
        "gradient_norm": 0.41546830534935,
        "train_loss": 3.0136849880218506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28039,
        "tokens": 14700511232,
        "learning_rate": 6.790911545594673e-05,
        "gradient_norm": 0.5240618586540222,
        "train_loss": 3.0125927925109863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28040,
        "tokens": 14701035520,
        "learning_rate": 6.790223431304615e-05,
        "gradient_norm": 0.46821728348731995,
        "train_loss": 3.021216869354248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28041,
        "tokens": 14701559808,
        "learning_rate": 6.789535612038259e-05,
        "gradient_norm": 0.4670097231864929,
        "train_loss": 3.004699230194092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28042,
        "tokens": 14702084096,
        "learning_rate": 6.788848087803357e-05,
        "gradient_norm": 0.43444156646728516,
        "train_loss": 2.993602752685547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28043,
        "tokens": 14702608384,
        "learning_rate": 6.788160858607637e-05,
        "gradient_norm": 0.42264512181282043,
        "train_loss": 3.032496929168701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28044,
        "tokens": 14703132672,
        "learning_rate": 6.787473924458843e-05,
        "gradient_norm": 0.41671374440193176,
        "train_loss": 2.9962635040283203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28045,
        "tokens": 14703656960,
        "learning_rate": 6.786787285364707e-05,
        "gradient_norm": 0.49966299533843994,
        "train_loss": 3.077827215194702,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28046,
        "tokens": 14704181248,
        "learning_rate": 6.786100941332952e-05,
        "gradient_norm": 0.4918495714664459,
        "train_loss": 2.990818977355957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28047,
        "tokens": 14704705536,
        "learning_rate": 6.785414892371311e-05,
        "gradient_norm": 0.41581276059150696,
        "train_loss": 3.004462480545044,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28048,
        "tokens": 14705229824,
        "learning_rate": 6.784729138487497e-05,
        "gradient_norm": 0.3991580903530121,
        "train_loss": 3.0074970722198486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28049,
        "tokens": 14705754112,
        "learning_rate": 6.784043679689241e-05,
        "gradient_norm": 0.46748143434524536,
        "train_loss": 3.000659942626953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28050,
        "tokens": 14706278400,
        "learning_rate": 6.78335851598425e-05,
        "gradient_norm": 0.4106663763523102,
        "train_loss": 3.011734962463379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28051,
        "tokens": 14706802688,
        "learning_rate": 6.782673647380239e-05,
        "gradient_norm": 0.4003392159938812,
        "train_loss": 3.0032100677490234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28052,
        "tokens": 14707326976,
        "learning_rate": 6.781989073884917e-05,
        "gradient_norm": 0.4185207188129425,
        "train_loss": 2.9658150672912598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28053,
        "tokens": 14707851264,
        "learning_rate": 6.781304795505985e-05,
        "gradient_norm": 0.4444192349910736,
        "train_loss": 3.01706600189209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28054,
        "tokens": 14708375552,
        "learning_rate": 6.780620812251158e-05,
        "gradient_norm": 0.4005626142024994,
        "train_loss": 3.039952278137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28055,
        "tokens": 14708899840,
        "learning_rate": 6.77993712412812e-05,
        "gradient_norm": 0.49596336483955383,
        "train_loss": 3.0343122482299805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28056,
        "tokens": 14709424128,
        "learning_rate": 6.77925373114458e-05,
        "gradient_norm": 0.4388042390346527,
        "train_loss": 3.0200698375701904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28057,
        "tokens": 14709948416,
        "learning_rate": 6.77857063330822e-05,
        "gradient_norm": 0.45763474702835083,
        "train_loss": 3.031256675720215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28058,
        "tokens": 14710472704,
        "learning_rate": 6.777887830626736e-05,
        "gradient_norm": 0.4210130274295807,
        "train_loss": 2.946519136428833,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28059,
        "tokens": 14710996992,
        "learning_rate": 6.777205323107809e-05,
        "gradient_norm": 0.42652180790901184,
        "train_loss": 3.0503172874450684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28060,
        "tokens": 14711521280,
        "learning_rate": 6.776523110759127e-05,
        "gradient_norm": 0.40739205479621887,
        "train_loss": 3.0064871311187744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28061,
        "tokens": 14712045568,
        "learning_rate": 6.775841193588361e-05,
        "gradient_norm": 0.3996366858482361,
        "train_loss": 2.9777884483337402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28062,
        "tokens": 14712569856,
        "learning_rate": 6.775159571603196e-05,
        "gradient_norm": 0.43347489833831787,
        "train_loss": 3.0615108013153076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28063,
        "tokens": 14713094144,
        "learning_rate": 6.774478244811295e-05,
        "gradient_norm": 0.46835049986839294,
        "train_loss": 3.050612688064575,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28064,
        "tokens": 14713618432,
        "learning_rate": 6.773797213220338e-05,
        "gradient_norm": 0.40028756856918335,
        "train_loss": 3.001859188079834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28065,
        "tokens": 14714142720,
        "learning_rate": 6.77311647683798e-05,
        "gradient_norm": 0.4281523525714874,
        "train_loss": 2.9800291061401367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28066,
        "tokens": 14714667008,
        "learning_rate": 6.772436035671893e-05,
        "gradient_norm": 0.4507312774658203,
        "train_loss": 2.980607032775879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28067,
        "tokens": 14715191296,
        "learning_rate": 6.77175588972973e-05,
        "gradient_norm": 0.38558048009872437,
        "train_loss": 3.0350944995880127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28068,
        "tokens": 14715715584,
        "learning_rate": 6.77107603901915e-05,
        "gradient_norm": 0.4320526123046875,
        "train_loss": 3.0262537002563477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28069,
        "tokens": 14716239872,
        "learning_rate": 6.770396483547804e-05,
        "gradient_norm": 0.4137277603149414,
        "train_loss": 3.0405874252319336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28070,
        "tokens": 14716764160,
        "learning_rate": 6.769717223323344e-05,
        "gradient_norm": 0.44193318486213684,
        "train_loss": 3.0082497596740723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28071,
        "tokens": 14717288448,
        "learning_rate": 6.769038258353406e-05,
        "gradient_norm": 0.41448265314102173,
        "train_loss": 2.9965810775756836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28072,
        "tokens": 14717812736,
        "learning_rate": 6.768359588645647e-05,
        "gradient_norm": 0.41787245869636536,
        "train_loss": 3.0196003913879395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28073,
        "tokens": 14718337024,
        "learning_rate": 6.767681214207699e-05,
        "gradient_norm": 0.44802042841911316,
        "train_loss": 2.9931368827819824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28074,
        "tokens": 14718861312,
        "learning_rate": 6.767003135047196e-05,
        "gradient_norm": 0.4658157229423523,
        "train_loss": 3.0420284271240234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28075,
        "tokens": 14719385600,
        "learning_rate": 6.766325351171773e-05,
        "gradient_norm": 0.3806076943874359,
        "train_loss": 3.0191545486450195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28076,
        "tokens": 14719909888,
        "learning_rate": 6.765647862589062e-05,
        "gradient_norm": 0.41862624883651733,
        "train_loss": 2.9768760204315186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28077,
        "tokens": 14720434176,
        "learning_rate": 6.764970669306682e-05,
        "gradient_norm": 0.4319721460342407,
        "train_loss": 2.9793701171875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28078,
        "tokens": 14720958464,
        "learning_rate": 6.764293771332264e-05,
        "gradient_norm": 0.5175637006759644,
        "train_loss": 3.0323963165283203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28079,
        "tokens": 14721482752,
        "learning_rate": 6.76361716867342e-05,
        "gradient_norm": 0.40237492322921753,
        "train_loss": 2.9817864894866943,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28080,
        "tokens": 14722007040,
        "learning_rate": 6.762940861337772e-05,
        "gradient_norm": 0.46328380703926086,
        "train_loss": 2.986325740814209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28081,
        "tokens": 14722531328,
        "learning_rate": 6.762264849332928e-05,
        "gradient_norm": 0.413636177778244,
        "train_loss": 2.9777607917785645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28082,
        "tokens": 14723055616,
        "learning_rate": 6.761589132666499e-05,
        "gradient_norm": 0.4351523220539093,
        "train_loss": 2.9892146587371826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28083,
        "tokens": 14723579904,
        "learning_rate": 6.760913711346092e-05,
        "gradient_norm": 0.4109768867492676,
        "train_loss": 2.9797418117523193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28084,
        "tokens": 14724104192,
        "learning_rate": 6.760238585379308e-05,
        "gradient_norm": 0.4359055459499359,
        "train_loss": 3.0485458374023438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28085,
        "tokens": 14724628480,
        "learning_rate": 6.759563754773751e-05,
        "gradient_norm": 0.393392950296402,
        "train_loss": 3.008495330810547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28086,
        "tokens": 14725152768,
        "learning_rate": 6.75888921953701e-05,
        "gradient_norm": 0.3971787095069885,
        "train_loss": 3.0299861431121826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28087,
        "tokens": 14725677056,
        "learning_rate": 6.758214979676686e-05,
        "gradient_norm": 0.4346538782119751,
        "train_loss": 3.0251426696777344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28088,
        "tokens": 14726201344,
        "learning_rate": 6.757541035200356e-05,
        "gradient_norm": 0.4254758358001709,
        "train_loss": 2.961223602294922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28089,
        "tokens": 14726725632,
        "learning_rate": 6.756867386115622e-05,
        "gradient_norm": 0.47611111402511597,
        "train_loss": 3.042715549468994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28090,
        "tokens": 14727249920,
        "learning_rate": 6.756194032430053e-05,
        "gradient_norm": 0.42286619544029236,
        "train_loss": 3.0193209648132324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28091,
        "tokens": 14727774208,
        "learning_rate": 6.755520974151238e-05,
        "gradient_norm": 0.4226510524749756,
        "train_loss": 2.997140407562256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28092,
        "tokens": 14728298496,
        "learning_rate": 6.754848211286745e-05,
        "gradient_norm": 0.4207138121128082,
        "train_loss": 3.0041842460632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28093,
        "tokens": 14728822784,
        "learning_rate": 6.75417574384415e-05,
        "gradient_norm": 0.40666985511779785,
        "train_loss": 3.0500807762145996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28094,
        "tokens": 14729347072,
        "learning_rate": 6.753503571831025e-05,
        "gradient_norm": 0.3999134302139282,
        "train_loss": 2.986159563064575,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28095,
        "tokens": 14729871360,
        "learning_rate": 6.752831695254937e-05,
        "gradient_norm": 0.42113184928894043,
        "train_loss": 3.023467540740967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28096,
        "tokens": 14730395648,
        "learning_rate": 6.752160114123444e-05,
        "gradient_norm": 0.4008042812347412,
        "train_loss": 2.9763987064361572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28097,
        "tokens": 14730919936,
        "learning_rate": 6.751488828444106e-05,
        "gradient_norm": 0.3935225009918213,
        "train_loss": 3.0352044105529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28098,
        "tokens": 14731444224,
        "learning_rate": 6.750817838224484e-05,
        "gradient_norm": 0.4148689806461334,
        "train_loss": 3.029517412185669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28099,
        "tokens": 14731968512,
        "learning_rate": 6.750147143472126e-05,
        "gradient_norm": 0.4169101417064667,
        "train_loss": 2.960850238800049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28100,
        "tokens": 14732492800,
        "learning_rate": 6.749476744194586e-05,
        "gradient_norm": 0.40164798498153687,
        "train_loss": 2.9690868854522705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28101,
        "tokens": 14733017088,
        "learning_rate": 6.748806640399403e-05,
        "gradient_norm": 0.44527891278266907,
        "train_loss": 2.985917091369629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28102,
        "tokens": 14733541376,
        "learning_rate": 6.748136832094126e-05,
        "gradient_norm": 0.4379740357398987,
        "train_loss": 2.945964813232422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28103,
        "tokens": 14734065664,
        "learning_rate": 6.747467319286293e-05,
        "gradient_norm": 0.4564628303050995,
        "train_loss": 3.0413148403167725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28104,
        "tokens": 14734589952,
        "learning_rate": 6.74679810198344e-05,
        "gradient_norm": 0.38394513726234436,
        "train_loss": 2.9952311515808105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28105,
        "tokens": 14735114240,
        "learning_rate": 6.746129180193102e-05,
        "gradient_norm": 0.4415885806083679,
        "train_loss": 3.0344972610473633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28106,
        "tokens": 14735638528,
        "learning_rate": 6.745460553922801e-05,
        "gradient_norm": 0.4003835618495941,
        "train_loss": 3.025332450866699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28107,
        "tokens": 14736162816,
        "learning_rate": 6.744792223180074e-05,
        "gradient_norm": 0.4037229120731354,
        "train_loss": 2.9990925788879395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28108,
        "tokens": 14736687104,
        "learning_rate": 6.744124187972436e-05,
        "gradient_norm": 0.4489976763725281,
        "train_loss": 3.030722141265869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28109,
        "tokens": 14737211392,
        "learning_rate": 6.743456448307409e-05,
        "gradient_norm": 0.3974427580833435,
        "train_loss": 3.047549247741699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28110,
        "tokens": 14737735680,
        "learning_rate": 6.742789004192508e-05,
        "gradient_norm": 0.5006216764450073,
        "train_loss": 3.036389112472534,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28111,
        "tokens": 14738259968,
        "learning_rate": 6.742121855635252e-05,
        "gradient_norm": 0.39167386293411255,
        "train_loss": 3.0538089275360107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28112,
        "tokens": 14738784256,
        "learning_rate": 6.741455002643143e-05,
        "gradient_norm": 0.4009009003639221,
        "train_loss": 3.026247501373291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28113,
        "tokens": 14739308544,
        "learning_rate": 6.740788445223686e-05,
        "gradient_norm": 0.4392753839492798,
        "train_loss": 3.0335075855255127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28114,
        "tokens": 14739832832,
        "learning_rate": 6.740122183384394e-05,
        "gradient_norm": 0.4543875455856323,
        "train_loss": 2.99686598777771,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28115,
        "tokens": 14740357120,
        "learning_rate": 6.739456217132755e-05,
        "gradient_norm": 0.4165200889110565,
        "train_loss": 2.9333996772766113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28116,
        "tokens": 14740881408,
        "learning_rate": 6.738790546476279e-05,
        "gradient_norm": 0.43636012077331543,
        "train_loss": 3.0434064865112305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28117,
        "tokens": 14741405696,
        "learning_rate": 6.738125171422445e-05,
        "gradient_norm": 0.4207910895347595,
        "train_loss": 3.038571834564209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28118,
        "tokens": 14741929984,
        "learning_rate": 6.73746009197875e-05,
        "gradient_norm": 0.46166786551475525,
        "train_loss": 3.0281572341918945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28119,
        "tokens": 14742454272,
        "learning_rate": 6.736795308152678e-05,
        "gradient_norm": 0.4317476451396942,
        "train_loss": 3.039316177368164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28120,
        "tokens": 14742978560,
        "learning_rate": 6.736130819951716e-05,
        "gradient_norm": 0.44007930159568787,
        "train_loss": 3.0295629501342773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28121,
        "tokens": 14743502848,
        "learning_rate": 6.735466627383334e-05,
        "gradient_norm": 0.4288259446620941,
        "train_loss": 3.0238213539123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28122,
        "tokens": 14744027136,
        "learning_rate": 6.734802730455017e-05,
        "gradient_norm": 0.47017350792884827,
        "train_loss": 3.003141403198242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28123,
        "tokens": 14744551424,
        "learning_rate": 6.73413912917424e-05,
        "gradient_norm": 0.430949866771698,
        "train_loss": 3.0579299926757812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28124,
        "tokens": 14745075712,
        "learning_rate": 6.733475823548464e-05,
        "gradient_norm": 0.4307735860347748,
        "train_loss": 3.01485013961792,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28125,
        "tokens": 14745600000,
        "learning_rate": 6.732812813585162e-05,
        "gradient_norm": 0.4313562512397766,
        "train_loss": 3.0440235137939453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28126,
        "tokens": 14746124288,
        "learning_rate": 6.732150099291792e-05,
        "gradient_norm": 0.43588221073150635,
        "train_loss": 2.9743080139160156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28127,
        "tokens": 14746648576,
        "learning_rate": 6.73148768067582e-05,
        "gradient_norm": 0.39939242601394653,
        "train_loss": 2.996642589569092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28128,
        "tokens": 14747172864,
        "learning_rate": 6.730825557744696e-05,
        "gradient_norm": 0.4069429636001587,
        "train_loss": 3.0092461109161377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28129,
        "tokens": 14747697152,
        "learning_rate": 6.730163730505877e-05,
        "gradient_norm": 0.4123748242855072,
        "train_loss": 2.975161075592041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28130,
        "tokens": 14748221440,
        "learning_rate": 6.72950219896681e-05,
        "gradient_norm": 0.4272063970565796,
        "train_loss": 3.0471112728118896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28131,
        "tokens": 14748745728,
        "learning_rate": 6.728840963134947e-05,
        "gradient_norm": 0.47262781858444214,
        "train_loss": 3.0341620445251465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28132,
        "tokens": 14749270016,
        "learning_rate": 6.728180023017722e-05,
        "gradient_norm": 0.4123210906982422,
        "train_loss": 3.0047707557678223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28133,
        "tokens": 14749794304,
        "learning_rate": 6.72751937862258e-05,
        "gradient_norm": 0.44811612367630005,
        "train_loss": 2.9955224990844727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28134,
        "tokens": 14750318592,
        "learning_rate": 6.72685902995696e-05,
        "gradient_norm": 0.4422987401485443,
        "train_loss": 2.9722962379455566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28135,
        "tokens": 14750842880,
        "learning_rate": 6.726198977028287e-05,
        "gradient_norm": 0.44045692682266235,
        "train_loss": 3.0053999423980713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28136,
        "tokens": 14751367168,
        "learning_rate": 6.725539219844002e-05,
        "gradient_norm": 0.43047693371772766,
        "train_loss": 3.0711185932159424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28137,
        "tokens": 14751891456,
        "learning_rate": 6.724879758411517e-05,
        "gradient_norm": 0.45042815804481506,
        "train_loss": 3.051713466644287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28138,
        "tokens": 14752415744,
        "learning_rate": 6.72422059273827e-05,
        "gradient_norm": 0.44916558265686035,
        "train_loss": 3.0088605880737305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28139,
        "tokens": 14752940032,
        "learning_rate": 6.723561722831672e-05,
        "gradient_norm": 0.4355144202709198,
        "train_loss": 3.0358309745788574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28140,
        "tokens": 14753464320,
        "learning_rate": 6.722903148699142e-05,
        "gradient_norm": 0.42541390657424927,
        "train_loss": 2.9767937660217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28141,
        "tokens": 14753988608,
        "learning_rate": 6.72224487034809e-05,
        "gradient_norm": 0.43403369188308716,
        "train_loss": 3.0284080505371094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28142,
        "tokens": 14754512896,
        "learning_rate": 6.72158688778593e-05,
        "gradient_norm": 0.4424324035644531,
        "train_loss": 3.0084359645843506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28143,
        "tokens": 14755037184,
        "learning_rate": 6.720929201020063e-05,
        "gradient_norm": 0.4449436366558075,
        "train_loss": 3.008707284927368,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28144,
        "tokens": 14755561472,
        "learning_rate": 6.720271810057898e-05,
        "gradient_norm": 0.4963035583496094,
        "train_loss": 3.0526933670043945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28145,
        "tokens": 14756085760,
        "learning_rate": 6.719614714906836e-05,
        "gradient_norm": 0.40680891275405884,
        "train_loss": 3.044725179672241,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28146,
        "tokens": 14756610048,
        "learning_rate": 6.718957915574265e-05,
        "gradient_norm": 0.4691627025604248,
        "train_loss": 3.004424810409546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28147,
        "tokens": 14757134336,
        "learning_rate": 6.718301412067586e-05,
        "gradient_norm": 0.4142168462276459,
        "train_loss": 3.0030159950256348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28148,
        "tokens": 14757658624,
        "learning_rate": 6.717645204394181e-05,
        "gradient_norm": 0.4370027184486389,
        "train_loss": 3.031039237976074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28149,
        "tokens": 14758182912,
        "learning_rate": 6.716989292561445e-05,
        "gradient_norm": 0.4286794364452362,
        "train_loss": 3.0471386909484863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28150,
        "tokens": 14758707200,
        "learning_rate": 6.716333676576756e-05,
        "gradient_norm": 0.5332731604576111,
        "train_loss": 3.1202762126922607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28151,
        "tokens": 14759231488,
        "learning_rate": 6.715678356447496e-05,
        "gradient_norm": 0.46170753240585327,
        "train_loss": 3.053954601287842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28152,
        "tokens": 14759755776,
        "learning_rate": 6.715023332181038e-05,
        "gradient_norm": 0.4904274642467499,
        "train_loss": 3.031667709350586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28153,
        "tokens": 14760280064,
        "learning_rate": 6.714368603784759e-05,
        "gradient_norm": 0.44316399097442627,
        "train_loss": 2.9560742378234863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28154,
        "tokens": 14760804352,
        "learning_rate": 6.713714171266027e-05,
        "gradient_norm": 0.4125097095966339,
        "train_loss": 3.0294086933135986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28155,
        "tokens": 14761328640,
        "learning_rate": 6.71306003463221e-05,
        "gradient_norm": 0.43815523386001587,
        "train_loss": 3.032602071762085,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28156,
        "tokens": 14761852928,
        "learning_rate": 6.712406193890667e-05,
        "gradient_norm": 0.42367708683013916,
        "train_loss": 3.045563220977783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28157,
        "tokens": 14762377216,
        "learning_rate": 6.711752649048763e-05,
        "gradient_norm": 0.44015538692474365,
        "train_loss": 2.992648124694824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28158,
        "tokens": 14762901504,
        "learning_rate": 6.711099400113853e-05,
        "gradient_norm": 0.3931390941143036,
        "train_loss": 2.9377059936523438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28159,
        "tokens": 14763425792,
        "learning_rate": 6.710446447093287e-05,
        "gradient_norm": 0.5245026350021362,
        "train_loss": 2.981203556060791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28160,
        "tokens": 14763950080,
        "learning_rate": 6.709793789994418e-05,
        "gradient_norm": 0.46353399753570557,
        "train_loss": 3.052211284637451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28161,
        "tokens": 14764474368,
        "learning_rate": 6.709141428824589e-05,
        "gradient_norm": 0.43114954233169556,
        "train_loss": 3.025857925415039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28162,
        "tokens": 14764998656,
        "learning_rate": 6.708489363591147e-05,
        "gradient_norm": 0.4895492196083069,
        "train_loss": 3.0095176696777344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28163,
        "tokens": 14765522944,
        "learning_rate": 6.707837594301433e-05,
        "gradient_norm": 0.4214778542518616,
        "train_loss": 2.9862773418426514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28164,
        "tokens": 14766047232,
        "learning_rate": 6.707186120962776e-05,
        "gradient_norm": 0.4564674496650696,
        "train_loss": 3.0483202934265137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28165,
        "tokens": 14766571520,
        "learning_rate": 6.706534943582519e-05,
        "gradient_norm": 0.4270226061344147,
        "train_loss": 2.9937167167663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28166,
        "tokens": 14767095808,
        "learning_rate": 6.705884062167984e-05,
        "gradient_norm": 0.42554399371147156,
        "train_loss": 3.011082649230957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28167,
        "tokens": 14767620096,
        "learning_rate": 6.705233476726505e-05,
        "gradient_norm": 0.42333823442459106,
        "train_loss": 2.9754862785339355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28168,
        "tokens": 14768144384,
        "learning_rate": 6.704583187265394e-05,
        "gradient_norm": 0.47511157393455505,
        "train_loss": 3.0358662605285645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28169,
        "tokens": 14768668672,
        "learning_rate": 6.703933193791982e-05,
        "gradient_norm": 0.4573119282722473,
        "train_loss": 3.008415937423706,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28170,
        "tokens": 14769192960,
        "learning_rate": 6.703283496313577e-05,
        "gradient_norm": 0.42561206221580505,
        "train_loss": 3.016672372817993,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28171,
        "tokens": 14769717248,
        "learning_rate": 6.7026340948375e-05,
        "gradient_norm": 0.3963811993598938,
        "train_loss": 3.031524419784546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28172,
        "tokens": 14770241536,
        "learning_rate": 6.701984989371055e-05,
        "gradient_norm": 0.42902565002441406,
        "train_loss": 2.9649415016174316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28173,
        "tokens": 14770765824,
        "learning_rate": 6.70133617992155e-05,
        "gradient_norm": 0.4072532057762146,
        "train_loss": 2.992323875427246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28174,
        "tokens": 14771290112,
        "learning_rate": 6.700687666496289e-05,
        "gradient_norm": 0.41009268164634705,
        "train_loss": 2.996199131011963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28175,
        "tokens": 14771814400,
        "learning_rate": 6.70003944910257e-05,
        "gradient_norm": 0.42069104313850403,
        "train_loss": 2.9712157249450684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28176,
        "tokens": 14772338688,
        "learning_rate": 6.69939152774769e-05,
        "gradient_norm": 0.38921022415161133,
        "train_loss": 3.0543980598449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28177,
        "tokens": 14772862976,
        "learning_rate": 6.698743902438946e-05,
        "gradient_norm": 0.43932366371154785,
        "train_loss": 3.061718225479126,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28178,
        "tokens": 14773387264,
        "learning_rate": 6.698096573183624e-05,
        "gradient_norm": 0.48228204250335693,
        "train_loss": 2.9720888137817383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28179,
        "tokens": 14773911552,
        "learning_rate": 6.697449539989012e-05,
        "gradient_norm": 0.4255344569683075,
        "train_loss": 2.99015736579895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28180,
        "tokens": 14774435840,
        "learning_rate": 6.69680280286239e-05,
        "gradient_norm": 0.4293818771839142,
        "train_loss": 3.0295605659484863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28181,
        "tokens": 14774960128,
        "learning_rate": 6.696156361811039e-05,
        "gradient_norm": 0.4414960443973541,
        "train_loss": 2.963961124420166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28182,
        "tokens": 14775484416,
        "learning_rate": 6.695510216842239e-05,
        "gradient_norm": 0.403001070022583,
        "train_loss": 3.0065016746520996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28183,
        "tokens": 14776008704,
        "learning_rate": 6.694864367963261e-05,
        "gradient_norm": 0.45351293683052063,
        "train_loss": 2.9738264083862305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28184,
        "tokens": 14776532992,
        "learning_rate": 6.694218815181373e-05,
        "gradient_norm": 0.4617599844932556,
        "train_loss": 2.9871249198913574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28185,
        "tokens": 14777057280,
        "learning_rate": 6.693573558503849e-05,
        "gradient_norm": 0.423318088054657,
        "train_loss": 3.0236740112304688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28186,
        "tokens": 14777581568,
        "learning_rate": 6.692928597937939e-05,
        "gradient_norm": 0.4500706195831299,
        "train_loss": 3.017761707305908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28187,
        "tokens": 14778105856,
        "learning_rate": 6.692283933490916e-05,
        "gradient_norm": 0.4115191400051117,
        "train_loss": 3.0190892219543457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28188,
        "tokens": 14778630144,
        "learning_rate": 6.691639565170028e-05,
        "gradient_norm": 0.44187405705451965,
        "train_loss": 2.9738430976867676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28189,
        "tokens": 14779154432,
        "learning_rate": 6.690995492982531e-05,
        "gradient_norm": 0.45396798849105835,
        "train_loss": 2.956984043121338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28190,
        "tokens": 14779678720,
        "learning_rate": 6.690351716935674e-05,
        "gradient_norm": 0.42760372161865234,
        "train_loss": 2.9867730140686035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28191,
        "tokens": 14780203008,
        "learning_rate": 6.689708237036707e-05,
        "gradient_norm": 0.4271651804447174,
        "train_loss": 3.053232431411743,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28192,
        "tokens": 14780727296,
        "learning_rate": 6.689065053292866e-05,
        "gradient_norm": 0.3898358643054962,
        "train_loss": 2.962005615234375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28193,
        "tokens": 14781251584,
        "learning_rate": 6.688422165711397e-05,
        "gradient_norm": 0.42793008685112,
        "train_loss": 3.028250217437744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28194,
        "tokens": 14781775872,
        "learning_rate": 6.687779574299539e-05,
        "gradient_norm": 0.45827531814575195,
        "train_loss": 2.9428870677948,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28195,
        "tokens": 14782300160,
        "learning_rate": 6.687137279064516e-05,
        "gradient_norm": 0.402152955532074,
        "train_loss": 2.990584135055542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28196,
        "tokens": 14782824448,
        "learning_rate": 6.686495280013564e-05,
        "gradient_norm": 0.48229536414146423,
        "train_loss": 3.002142906188965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28197,
        "tokens": 14783348736,
        "learning_rate": 6.685853577153908e-05,
        "gradient_norm": 0.42209750413894653,
        "train_loss": 3.0037894248962402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28198,
        "tokens": 14783873024,
        "learning_rate": 6.685212170492773e-05,
        "gradient_norm": 0.40595775842666626,
        "train_loss": 2.946406841278076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28199,
        "tokens": 14784397312,
        "learning_rate": 6.684571060037375e-05,
        "gradient_norm": 0.4640960395336151,
        "train_loss": 2.9716758728027344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28200,
        "tokens": 14784921600,
        "learning_rate": 6.683930245794935e-05,
        "gradient_norm": 0.3941858112812042,
        "train_loss": 2.9779272079467773,
        "val_loss": 2.962921142578125,
        "hellaswag_acc": 0.2844054698944092,
        "hellaswag_acc_norm": 0.29904401302337646
    },
    {
        "step": 28201,
        "tokens": 14785445888,
        "learning_rate": 6.683289727772663e-05,
        "gradient_norm": 0.4037233591079712,
        "train_loss": 2.9687533378601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28202,
        "tokens": 14785970176,
        "learning_rate": 6.682649505977766e-05,
        "gradient_norm": 0.42623957991600037,
        "train_loss": 2.993734121322632,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28203,
        "tokens": 14786494464,
        "learning_rate": 6.682009580417463e-05,
        "gradient_norm": 0.4522998034954071,
        "train_loss": 2.995213508605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28204,
        "tokens": 14787018752,
        "learning_rate": 6.68136995109894e-05,
        "gradient_norm": 0.45523887872695923,
        "train_loss": 2.9498729705810547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28205,
        "tokens": 14787543040,
        "learning_rate": 6.680730618029412e-05,
        "gradient_norm": 0.46713748574256897,
        "train_loss": 3.009772777557373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28206,
        "tokens": 14788067328,
        "learning_rate": 6.680091581216063e-05,
        "gradient_norm": 0.45205509662628174,
        "train_loss": 2.982910633087158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28207,
        "tokens": 14788591616,
        "learning_rate": 6.679452840666094e-05,
        "gradient_norm": 0.42514824867248535,
        "train_loss": 2.942124128341675,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28208,
        "tokens": 14789115904,
        "learning_rate": 6.678814396386692e-05,
        "gradient_norm": 0.38964125514030457,
        "train_loss": 2.926011085510254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28209,
        "tokens": 14789640192,
        "learning_rate": 6.67817624838505e-05,
        "gradient_norm": 0.4451252818107605,
        "train_loss": 2.979828357696533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28210,
        "tokens": 14790164480,
        "learning_rate": 6.677538396668337e-05,
        "gradient_norm": 0.42239615321159363,
        "train_loss": 2.9416534900665283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28211,
        "tokens": 14790688768,
        "learning_rate": 6.676900841243745e-05,
        "gradient_norm": 0.3995344638824463,
        "train_loss": 2.9519481658935547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28212,
        "tokens": 14791213056,
        "learning_rate": 6.676263582118446e-05,
        "gradient_norm": 0.4604710638523102,
        "train_loss": 3.017232894897461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28213,
        "tokens": 14791737344,
        "learning_rate": 6.675626619299614e-05,
        "gradient_norm": 0.4343688189983368,
        "train_loss": 2.973829746246338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28214,
        "tokens": 14792261632,
        "learning_rate": 6.67498995279442e-05,
        "gradient_norm": 0.4380156397819519,
        "train_loss": 2.97735595703125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28215,
        "tokens": 14792785920,
        "learning_rate": 6.674353582610025e-05,
        "gradient_norm": 0.6305148005485535,
        "train_loss": 3.0403008460998535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28216,
        "tokens": 14793310208,
        "learning_rate": 6.673717508753602e-05,
        "gradient_norm": 0.424250066280365,
        "train_loss": 2.95932674407959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28217,
        "tokens": 14793834496,
        "learning_rate": 6.673081731232301e-05,
        "gradient_norm": 0.47873449325561523,
        "train_loss": 3.0025410652160645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28218,
        "tokens": 14794358784,
        "learning_rate": 6.672446250053282e-05,
        "gradient_norm": 0.6392480731010437,
        "train_loss": 3.1043262481689453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28219,
        "tokens": 14794883072,
        "learning_rate": 6.6718110652237e-05,
        "gradient_norm": 0.42501360177993774,
        "train_loss": 2.947201728820801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28220,
        "tokens": 14795407360,
        "learning_rate": 6.671176176750704e-05,
        "gradient_norm": 0.4514446258544922,
        "train_loss": 2.9516992568969727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28221,
        "tokens": 14795931648,
        "learning_rate": 6.670541584641438e-05,
        "gradient_norm": 0.43195590376853943,
        "train_loss": 2.9656805992126465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28222,
        "tokens": 14796455936,
        "learning_rate": 6.669907288903048e-05,
        "gradient_norm": 0.44786685705184937,
        "train_loss": 2.985856056213379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28223,
        "tokens": 14796980224,
        "learning_rate": 6.669273289542675e-05,
        "gradient_norm": 0.4128483235836029,
        "train_loss": 2.9601383209228516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28224,
        "tokens": 14797504512,
        "learning_rate": 6.668639586567449e-05,
        "gradient_norm": 0.41223442554473877,
        "train_loss": 2.9932751655578613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28225,
        "tokens": 14798028800,
        "learning_rate": 6.668006179984513e-05,
        "gradient_norm": 0.4641549587249756,
        "train_loss": 3.016024351119995,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28226,
        "tokens": 14798553088,
        "learning_rate": 6.667373069800986e-05,
        "gradient_norm": 0.42294856905937195,
        "train_loss": 2.990354061126709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28227,
        "tokens": 14799077376,
        "learning_rate": 6.666740256024002e-05,
        "gradient_norm": 0.44158095121383667,
        "train_loss": 2.9594345092773438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28228,
        "tokens": 14799601664,
        "learning_rate": 6.666107738660681e-05,
        "gradient_norm": 0.41749268770217896,
        "train_loss": 2.993600845336914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28229,
        "tokens": 14800125952,
        "learning_rate": 6.665475517718142e-05,
        "gradient_norm": 0.4389192461967468,
        "train_loss": 2.932797431945801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28230,
        "tokens": 14800650240,
        "learning_rate": 6.664843593203503e-05,
        "gradient_norm": 0.3995057940483093,
        "train_loss": 2.9958319664001465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28231,
        "tokens": 14801174528,
        "learning_rate": 6.66421196512388e-05,
        "gradient_norm": 0.4147954285144806,
        "train_loss": 3.0158700942993164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28232,
        "tokens": 14801698816,
        "learning_rate": 6.663580633486378e-05,
        "gradient_norm": 0.42819684743881226,
        "train_loss": 2.988673448562622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28233,
        "tokens": 14802223104,
        "learning_rate": 6.662949598298105e-05,
        "gradient_norm": 0.42459309101104736,
        "train_loss": 2.9743781089782715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28234,
        "tokens": 14802747392,
        "learning_rate": 6.662318859566166e-05,
        "gradient_norm": 0.4463260769844055,
        "train_loss": 3.015265464782715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28235,
        "tokens": 14803271680,
        "learning_rate": 6.661688417297656e-05,
        "gradient_norm": 0.4288792312145233,
        "train_loss": 2.999074697494507,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28236,
        "tokens": 14803795968,
        "learning_rate": 6.66105827149968e-05,
        "gradient_norm": 0.4320867657661438,
        "train_loss": 2.9677090644836426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28237,
        "tokens": 14804320256,
        "learning_rate": 6.660428422179318e-05,
        "gradient_norm": 0.4482136070728302,
        "train_loss": 2.9460887908935547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28238,
        "tokens": 14804844544,
        "learning_rate": 6.65979886934367e-05,
        "gradient_norm": 0.4082498252391815,
        "train_loss": 2.969818592071533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28239,
        "tokens": 14805368832,
        "learning_rate": 6.659169612999822e-05,
        "gradient_norm": 0.4677639901638031,
        "train_loss": 2.9648098945617676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28240,
        "tokens": 14805893120,
        "learning_rate": 6.658540653154854e-05,
        "gradient_norm": 0.4372364282608032,
        "train_loss": 3.0131783485412598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28241,
        "tokens": 14806417408,
        "learning_rate": 6.657911989815845e-05,
        "gradient_norm": 0.4234464764595032,
        "train_loss": 2.9536309242248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28242,
        "tokens": 14806941696,
        "learning_rate": 6.657283622989872e-05,
        "gradient_norm": 0.48200076818466187,
        "train_loss": 3.048738956451416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28243,
        "tokens": 14807465984,
        "learning_rate": 6.656655552684012e-05,
        "gradient_norm": 0.42964887619018555,
        "train_loss": 2.9358463287353516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28244,
        "tokens": 14807990272,
        "learning_rate": 6.656027778905328e-05,
        "gradient_norm": 0.40832528471946716,
        "train_loss": 2.983137607574463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28245,
        "tokens": 14808514560,
        "learning_rate": 6.655400301660892e-05,
        "gradient_norm": 0.48981285095214844,
        "train_loss": 3.009974956512451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28246,
        "tokens": 14809038848,
        "learning_rate": 6.654773120957764e-05,
        "gradient_norm": 0.46209222078323364,
        "train_loss": 2.9637932777404785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28247,
        "tokens": 14809563136,
        "learning_rate": 6.654146236803008e-05,
        "gradient_norm": 0.40915676951408386,
        "train_loss": 3.014707565307617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28248,
        "tokens": 14810087424,
        "learning_rate": 6.653519649203672e-05,
        "gradient_norm": 0.40701889991760254,
        "train_loss": 2.945028305053711,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28249,
        "tokens": 14810611712,
        "learning_rate": 6.652893358166817e-05,
        "gradient_norm": 0.42242923378944397,
        "train_loss": 3.0103700160980225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28250,
        "tokens": 14811136000,
        "learning_rate": 6.652267363699488e-05,
        "gradient_norm": 0.3944515585899353,
        "train_loss": 3.011854887008667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28251,
        "tokens": 14811660288,
        "learning_rate": 6.651641665808737e-05,
        "gradient_norm": 0.4517096281051636,
        "train_loss": 2.9966182708740234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28252,
        "tokens": 14812184576,
        "learning_rate": 6.651016264501602e-05,
        "gradient_norm": 0.40648797154426575,
        "train_loss": 2.9585824012756348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28253,
        "tokens": 14812708864,
        "learning_rate": 6.650391159785121e-05,
        "gradient_norm": 0.39724001288414,
        "train_loss": 2.9777824878692627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28254,
        "tokens": 14813233152,
        "learning_rate": 6.649766351666335e-05,
        "gradient_norm": 0.41600921750068665,
        "train_loss": 2.973578929901123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28255,
        "tokens": 14813757440,
        "learning_rate": 6.649141840152274e-05,
        "gradient_norm": 0.41357117891311646,
        "train_loss": 2.983553171157837,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28256,
        "tokens": 14814281728,
        "learning_rate": 6.648517625249972e-05,
        "gradient_norm": 0.4563141465187073,
        "train_loss": 2.942352056503296,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28257,
        "tokens": 14814806016,
        "learning_rate": 6.647893706966448e-05,
        "gradient_norm": 0.4151478409767151,
        "train_loss": 2.9391379356384277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28258,
        "tokens": 14815330304,
        "learning_rate": 6.647270085308731e-05,
        "gradient_norm": 0.6975781917572021,
        "train_loss": 3.040337085723877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28259,
        "tokens": 14815854592,
        "learning_rate": 6.646646760283839e-05,
        "gradient_norm": 0.45731642842292786,
        "train_loss": 2.9920358657836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28260,
        "tokens": 14816378880,
        "learning_rate": 6.646023731898788e-05,
        "gradient_norm": 0.4932510256767273,
        "train_loss": 2.955948829650879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28261,
        "tokens": 14816903168,
        "learning_rate": 6.64540100016059e-05,
        "gradient_norm": 0.4769365191459656,
        "train_loss": 3.041837215423584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28262,
        "tokens": 14817427456,
        "learning_rate": 6.644778565076254e-05,
        "gradient_norm": 0.44912445545196533,
        "train_loss": 3.0357744693756104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28263,
        "tokens": 14817951744,
        "learning_rate": 6.644156426652794e-05,
        "gradient_norm": 0.4770549535751343,
        "train_loss": 2.953989028930664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28264,
        "tokens": 14818476032,
        "learning_rate": 6.643534584897199e-05,
        "gradient_norm": 0.4105663597583771,
        "train_loss": 2.9401817321777344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28265,
        "tokens": 14819000320,
        "learning_rate": 6.642913039816482e-05,
        "gradient_norm": 0.4194051921367645,
        "train_loss": 2.974717378616333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28266,
        "tokens": 14819524608,
        "learning_rate": 6.642291791417632e-05,
        "gradient_norm": 0.4301110804080963,
        "train_loss": 3.0384907722473145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28267,
        "tokens": 14820048896,
        "learning_rate": 6.641670839707645e-05,
        "gradient_norm": 0.39924755692481995,
        "train_loss": 3.028280735015869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28268,
        "tokens": 14820573184,
        "learning_rate": 6.641050184693507e-05,
        "gradient_norm": 0.4457674026489258,
        "train_loss": 2.9694342613220215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28269,
        "tokens": 14821097472,
        "learning_rate": 6.640429826382208e-05,
        "gradient_norm": 0.44028493762016296,
        "train_loss": 2.965823173522949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28270,
        "tokens": 14821621760,
        "learning_rate": 6.63980976478073e-05,
        "gradient_norm": 0.4389299154281616,
        "train_loss": 2.979501247406006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28271,
        "tokens": 14822146048,
        "learning_rate": 6.639189999896051e-05,
        "gradient_norm": 0.397870808839798,
        "train_loss": 3.033170700073242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28272,
        "tokens": 14822670336,
        "learning_rate": 6.638570531735148e-05,
        "gradient_norm": 0.3974287211894989,
        "train_loss": 2.9692258834838867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28273,
        "tokens": 14823194624,
        "learning_rate": 6.637951360304992e-05,
        "gradient_norm": 0.4568078815937042,
        "train_loss": 2.992633581161499,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28274,
        "tokens": 14823718912,
        "learning_rate": 6.637332485612558e-05,
        "gradient_norm": 0.4722384810447693,
        "train_loss": 2.952731132507324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28275,
        "tokens": 14824243200,
        "learning_rate": 6.636713907664809e-05,
        "gradient_norm": 0.459139347076416,
        "train_loss": 2.997545003890991,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28276,
        "tokens": 14824767488,
        "learning_rate": 6.636095626468703e-05,
        "gradient_norm": 0.4649587869644165,
        "train_loss": 3.0484838485717773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28277,
        "tokens": 14825291776,
        "learning_rate": 6.63547764203121e-05,
        "gradient_norm": 0.44596928358078003,
        "train_loss": 2.977397918701172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28278,
        "tokens": 14825816064,
        "learning_rate": 6.634859954359275e-05,
        "gradient_norm": 0.4858030378818512,
        "train_loss": 2.9585933685302734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28279,
        "tokens": 14826340352,
        "learning_rate": 6.634242563459861e-05,
        "gradient_norm": 0.4216209352016449,
        "train_loss": 2.9952831268310547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28280,
        "tokens": 14826864640,
        "learning_rate": 6.633625469339908e-05,
        "gradient_norm": 0.4211661219596863,
        "train_loss": 2.9617958068847656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28281,
        "tokens": 14827388928,
        "learning_rate": 6.633008672006372e-05,
        "gradient_norm": 0.4416431188583374,
        "train_loss": 2.9794845581054688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28282,
        "tokens": 14827913216,
        "learning_rate": 6.632392171466186e-05,
        "gradient_norm": 0.42053303122520447,
        "train_loss": 2.983618974685669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28283,
        "tokens": 14828437504,
        "learning_rate": 6.631775967726299e-05,
        "gradient_norm": 0.44678041338920593,
        "train_loss": 2.9746174812316895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28284,
        "tokens": 14828961792,
        "learning_rate": 6.631160060793639e-05,
        "gradient_norm": 0.4420791566371918,
        "train_loss": 3.006897449493408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28285,
        "tokens": 14829486080,
        "learning_rate": 6.630544450675143e-05,
        "gradient_norm": 0.3806459605693817,
        "train_loss": 2.972109317779541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28286,
        "tokens": 14830010368,
        "learning_rate": 6.629929137377738e-05,
        "gradient_norm": 0.4434790313243866,
        "train_loss": 2.9991934299468994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28287,
        "tokens": 14830534656,
        "learning_rate": 6.629314120908357e-05,
        "gradient_norm": 0.4586654603481293,
        "train_loss": 2.9532318115234375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28288,
        "tokens": 14831058944,
        "learning_rate": 6.62869940127391e-05,
        "gradient_norm": 0.39233389496803284,
        "train_loss": 2.991307258605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28289,
        "tokens": 14831583232,
        "learning_rate": 6.62808497848133e-05,
        "gradient_norm": 0.44499439001083374,
        "train_loss": 2.951019763946533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28290,
        "tokens": 14832107520,
        "learning_rate": 6.627470852537523e-05,
        "gradient_norm": 0.4219900369644165,
        "train_loss": 3.004426956176758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28291,
        "tokens": 14832631808,
        "learning_rate": 6.626857023449409e-05,
        "gradient_norm": 0.3955106735229492,
        "train_loss": 3.0119776725769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28292,
        "tokens": 14833156096,
        "learning_rate": 6.626243491223891e-05,
        "gradient_norm": 0.3991796374320984,
        "train_loss": 3.0658864974975586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28293,
        "tokens": 14833680384,
        "learning_rate": 6.625630255867878e-05,
        "gradient_norm": 0.4125005304813385,
        "train_loss": 3.0133209228515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28294,
        "tokens": 14834204672,
        "learning_rate": 6.625017317388278e-05,
        "gradient_norm": 0.46165040135383606,
        "train_loss": 2.9716291427612305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28295,
        "tokens": 14834728960,
        "learning_rate": 6.62440467579198e-05,
        "gradient_norm": 0.43048036098480225,
        "train_loss": 3.0411972999572754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28296,
        "tokens": 14835253248,
        "learning_rate": 6.623792331085889e-05,
        "gradient_norm": 0.4499448239803314,
        "train_loss": 2.9831714630126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28297,
        "tokens": 14835777536,
        "learning_rate": 6.62318028327689e-05,
        "gradient_norm": 0.4385674297809601,
        "train_loss": 2.9729552268981934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28298,
        "tokens": 14836301824,
        "learning_rate": 6.622568532371882e-05,
        "gradient_norm": 0.4199357330799103,
        "train_loss": 2.9543399810791016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28299,
        "tokens": 14836826112,
        "learning_rate": 6.62195707837774e-05,
        "gradient_norm": 0.39676475524902344,
        "train_loss": 3.0069968700408936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28300,
        "tokens": 14837350400,
        "learning_rate": 6.621345921301359e-05,
        "gradient_norm": 0.43658968806266785,
        "train_loss": 2.952012062072754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28301,
        "tokens": 14837874688,
        "learning_rate": 6.620735061149605e-05,
        "gradient_norm": 0.41571417450904846,
        "train_loss": 2.938457727432251,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28302,
        "tokens": 14838398976,
        "learning_rate": 6.620124497929362e-05,
        "gradient_norm": 0.38231131434440613,
        "train_loss": 2.993739128112793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28303,
        "tokens": 14838923264,
        "learning_rate": 6.619514231647505e-05,
        "gradient_norm": 0.427839457988739,
        "train_loss": 3.0085649490356445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28304,
        "tokens": 14839447552,
        "learning_rate": 6.618904262310894e-05,
        "gradient_norm": 0.4195989668369293,
        "train_loss": 2.9722442626953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28305,
        "tokens": 14839971840,
        "learning_rate": 6.618294589926405e-05,
        "gradient_norm": 0.43956342339515686,
        "train_loss": 3.035277843475342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28306,
        "tokens": 14840496128,
        "learning_rate": 6.617685214500892e-05,
        "gradient_norm": 0.446123331785202,
        "train_loss": 2.984236240386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28307,
        "tokens": 14841020416,
        "learning_rate": 6.617076136041223e-05,
        "gradient_norm": 0.42321816086769104,
        "train_loss": 2.9299914836883545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28308,
        "tokens": 14841544704,
        "learning_rate": 6.616467354554245e-05,
        "gradient_norm": 0.40090444684028625,
        "train_loss": 2.951761245727539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28309,
        "tokens": 14842068992,
        "learning_rate": 6.615858870046815e-05,
        "gradient_norm": 0.41180184483528137,
        "train_loss": 2.9754176139831543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28310,
        "tokens": 14842593280,
        "learning_rate": 6.615250682525783e-05,
        "gradient_norm": 0.36981630325317383,
        "train_loss": 3.0195040702819824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28311,
        "tokens": 14843117568,
        "learning_rate": 6.614642791997995e-05,
        "gradient_norm": 0.40728044509887695,
        "train_loss": 2.9704344272613525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28312,
        "tokens": 14843641856,
        "learning_rate": 6.614035198470291e-05,
        "gradient_norm": 0.3859426975250244,
        "train_loss": 2.9654788970947266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28313,
        "tokens": 14844166144,
        "learning_rate": 6.613427901949513e-05,
        "gradient_norm": 0.44149863719940186,
        "train_loss": 3.027174472808838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28314,
        "tokens": 14844690432,
        "learning_rate": 6.612820902442497e-05,
        "gradient_norm": 0.41088253259658813,
        "train_loss": 2.9805593490600586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28315,
        "tokens": 14845214720,
        "learning_rate": 6.612214199956073e-05,
        "gradient_norm": 0.41579297184944153,
        "train_loss": 2.9390716552734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28316,
        "tokens": 14845739008,
        "learning_rate": 6.61160779449707e-05,
        "gradient_norm": 0.5131116509437561,
        "train_loss": 3.006096839904785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28317,
        "tokens": 14846263296,
        "learning_rate": 6.611001686072316e-05,
        "gradient_norm": 0.440215528011322,
        "train_loss": 2.9838647842407227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28318,
        "tokens": 14846787584,
        "learning_rate": 6.610395874688635e-05,
        "gradient_norm": 0.4658701717853546,
        "train_loss": 3.003805160522461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28319,
        "tokens": 14847311872,
        "learning_rate": 6.60979036035284e-05,
        "gradient_norm": 0.433719277381897,
        "train_loss": 2.9584481716156006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28320,
        "tokens": 14847836160,
        "learning_rate": 6.609185143071757e-05,
        "gradient_norm": 0.43838974833488464,
        "train_loss": 2.9944376945495605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28321,
        "tokens": 14848360448,
        "learning_rate": 6.608580222852185e-05,
        "gradient_norm": 0.42980173230171204,
        "train_loss": 2.999803066253662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28322,
        "tokens": 14848884736,
        "learning_rate": 6.607975599700945e-05,
        "gradient_norm": 0.42677009105682373,
        "train_loss": 3.002223491668701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28323,
        "tokens": 14849409024,
        "learning_rate": 6.607371273624836e-05,
        "gradient_norm": 0.4127281904220581,
        "train_loss": 3.0024306774139404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28324,
        "tokens": 14849933312,
        "learning_rate": 6.606767244630662e-05,
        "gradient_norm": 0.4330415427684784,
        "train_loss": 2.995290756225586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28325,
        "tokens": 14850457600,
        "learning_rate": 6.606163512725227e-05,
        "gradient_norm": 0.45405691862106323,
        "train_loss": 2.9900646209716797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28326,
        "tokens": 14850981888,
        "learning_rate": 6.605560077915315e-05,
        "gradient_norm": 0.43195146322250366,
        "train_loss": 3.0202736854553223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28327,
        "tokens": 14851506176,
        "learning_rate": 6.604956940207732e-05,
        "gradient_norm": 0.4187399446964264,
        "train_loss": 2.9586260318756104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28328,
        "tokens": 14852030464,
        "learning_rate": 6.604354099609259e-05,
        "gradient_norm": 0.41085711121559143,
        "train_loss": 2.960684299468994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28329,
        "tokens": 14852554752,
        "learning_rate": 6.603751556126685e-05,
        "gradient_norm": 0.4049140512943268,
        "train_loss": 2.9271240234375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28330,
        "tokens": 14853079040,
        "learning_rate": 6.603149309766789e-05,
        "gradient_norm": 0.4267748296260834,
        "train_loss": 2.979243755340576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28331,
        "tokens": 14853603328,
        "learning_rate": 6.602547360536354e-05,
        "gradient_norm": 0.41769567131996155,
        "train_loss": 3.00905442237854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28332,
        "tokens": 14854127616,
        "learning_rate": 6.601945708442152e-05,
        "gradient_norm": 0.37977686524391174,
        "train_loss": 2.948458194732666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28333,
        "tokens": 14854651904,
        "learning_rate": 6.601344353490957e-05,
        "gradient_norm": 0.500138521194458,
        "train_loss": 3.066103458404541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28334,
        "tokens": 14855176192,
        "learning_rate": 6.60074329568954e-05,
        "gradient_norm": 0.501172661781311,
        "train_loss": 2.994311809539795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28335,
        "tokens": 14855700480,
        "learning_rate": 6.600142535044662e-05,
        "gradient_norm": 0.4154842495918274,
        "train_loss": 2.955443859100342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28336,
        "tokens": 14856224768,
        "learning_rate": 6.59954207156309e-05,
        "gradient_norm": 0.4481887221336365,
        "train_loss": 2.990673065185547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28337,
        "tokens": 14856749056,
        "learning_rate": 6.598941905251581e-05,
        "gradient_norm": 0.4144912660121918,
        "train_loss": 2.9464495182037354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28338,
        "tokens": 14857273344,
        "learning_rate": 6.598342036116891e-05,
        "gradient_norm": 0.43708881735801697,
        "train_loss": 2.913358688354492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28339,
        "tokens": 14857797632,
        "learning_rate": 6.597742464165772e-05,
        "gradient_norm": 0.43807360529899597,
        "train_loss": 2.950989246368408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28340,
        "tokens": 14858321920,
        "learning_rate": 6.597143189404972e-05,
        "gradient_norm": 0.41344958543777466,
        "train_loss": 3.007152795791626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28341,
        "tokens": 14858846208,
        "learning_rate": 6.596544211841238e-05,
        "gradient_norm": 0.4262094795703888,
        "train_loss": 2.9736404418945312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28342,
        "tokens": 14859370496,
        "learning_rate": 6.59594553148131e-05,
        "gradient_norm": 0.4366835951805115,
        "train_loss": 2.9527134895324707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28343,
        "tokens": 14859894784,
        "learning_rate": 6.595347148331932e-05,
        "gradient_norm": 0.3938222825527191,
        "train_loss": 3.00051212310791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28344,
        "tokens": 14860419072,
        "learning_rate": 6.594749062399831e-05,
        "gradient_norm": 0.43873122334480286,
        "train_loss": 3.0218749046325684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28345,
        "tokens": 14860943360,
        "learning_rate": 6.594151273691748e-05,
        "gradient_norm": 0.4731961488723755,
        "train_loss": 3.0071325302124023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28346,
        "tokens": 14861467648,
        "learning_rate": 6.593553782214405e-05,
        "gradient_norm": 0.42145365476608276,
        "train_loss": 3.0197737216949463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28347,
        "tokens": 14861991936,
        "learning_rate": 6.592956587974536e-05,
        "gradient_norm": 0.49705570936203003,
        "train_loss": 3.03085994720459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28348,
        "tokens": 14862516224,
        "learning_rate": 6.592359690978855e-05,
        "gradient_norm": 0.41901448369026184,
        "train_loss": 2.988572120666504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28349,
        "tokens": 14863040512,
        "learning_rate": 6.591763091234084e-05,
        "gradient_norm": 0.42842844128608704,
        "train_loss": 3.0145199298858643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28350,
        "tokens": 14863564800,
        "learning_rate": 6.591166788746937e-05,
        "gradient_norm": 0.414975106716156,
        "train_loss": 2.988132953643799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28351,
        "tokens": 14864089088,
        "learning_rate": 6.590570783524128e-05,
        "gradient_norm": 0.3881780207157135,
        "train_loss": 2.985787868499756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28352,
        "tokens": 14864613376,
        "learning_rate": 6.589975075572363e-05,
        "gradient_norm": 0.39620187878608704,
        "train_loss": 2.9900410175323486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28353,
        "tokens": 14865137664,
        "learning_rate": 6.58937966489835e-05,
        "gradient_norm": 0.4165397882461548,
        "train_loss": 2.986842155456543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28354,
        "tokens": 14865661952,
        "learning_rate": 6.588784551508796e-05,
        "gradient_norm": 0.4056258797645569,
        "train_loss": 2.9899189472198486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28355,
        "tokens": 14866186240,
        "learning_rate": 6.588189735410387e-05,
        "gradient_norm": 0.4398646056652069,
        "train_loss": 2.985476493835449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28356,
        "tokens": 14866710528,
        "learning_rate": 6.587595216609832e-05,
        "gradient_norm": 0.4116615056991577,
        "train_loss": 2.9699532985687256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28357,
        "tokens": 14867234816,
        "learning_rate": 6.58700099511381e-05,
        "gradient_norm": 0.40520915389060974,
        "train_loss": 2.982264518737793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28358,
        "tokens": 14867759104,
        "learning_rate": 6.586407070929025e-05,
        "gradient_norm": 0.4030427038669586,
        "train_loss": 2.999959945678711,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28359,
        "tokens": 14868283392,
        "learning_rate": 6.585813444062147e-05,
        "gradient_norm": 0.4326976239681244,
        "train_loss": 2.9771640300750732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28360,
        "tokens": 14868807680,
        "learning_rate": 6.585220114519867e-05,
        "gradient_norm": 0.46639859676361084,
        "train_loss": 2.918771505355835,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28361,
        "tokens": 14869331968,
        "learning_rate": 6.584627082308861e-05,
        "gradient_norm": 0.39508941769599915,
        "train_loss": 2.9390549659729004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28362,
        "tokens": 14869856256,
        "learning_rate": 6.584034347435804e-05,
        "gradient_norm": 0.43329760432243347,
        "train_loss": 2.995138168334961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28363,
        "tokens": 14870380544,
        "learning_rate": 6.58344190990737e-05,
        "gradient_norm": 0.4193711578845978,
        "train_loss": 2.9406943321228027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28364,
        "tokens": 14870904832,
        "learning_rate": 6.582849769730226e-05,
        "gradient_norm": 0.42156580090522766,
        "train_loss": 2.9753899574279785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28365,
        "tokens": 14871429120,
        "learning_rate": 6.58225792691104e-05,
        "gradient_norm": 0.4551367163658142,
        "train_loss": 2.9676690101623535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28366,
        "tokens": 14871953408,
        "learning_rate": 6.581666381456469e-05,
        "gradient_norm": 0.42305877804756165,
        "train_loss": 2.931532859802246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28367,
        "tokens": 14872477696,
        "learning_rate": 6.581075133373176e-05,
        "gradient_norm": 0.4206780791282654,
        "train_loss": 2.9578747749328613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28368,
        "tokens": 14873001984,
        "learning_rate": 6.580484182667812e-05,
        "gradient_norm": 0.45830297470092773,
        "train_loss": 2.9852232933044434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28369,
        "tokens": 14873526272,
        "learning_rate": 6.579893529347034e-05,
        "gradient_norm": 0.46096545457839966,
        "train_loss": 3.112710952758789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28370,
        "tokens": 14874050560,
        "learning_rate": 6.579303173417486e-05,
        "gradient_norm": 0.4599824547767639,
        "train_loss": 2.998687982559204,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28371,
        "tokens": 14874574848,
        "learning_rate": 6.578713114885817e-05,
        "gradient_norm": 0.4980214536190033,
        "train_loss": 2.992522716522217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28372,
        "tokens": 14875099136,
        "learning_rate": 6.578123353758662e-05,
        "gradient_norm": 0.4508342742919922,
        "train_loss": 2.9741580486297607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28373,
        "tokens": 14875623424,
        "learning_rate": 6.577533890042668e-05,
        "gradient_norm": 0.5438829064369202,
        "train_loss": 3.0763967037200928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28374,
        "tokens": 14876147712,
        "learning_rate": 6.576944723744467e-05,
        "gradient_norm": 0.40207794308662415,
        "train_loss": 2.929551362991333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28375,
        "tokens": 14876672000,
        "learning_rate": 6.576355854870689e-05,
        "gradient_norm": 0.47477036714553833,
        "train_loss": 3.005236864089966,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28376,
        "tokens": 14877196288,
        "learning_rate": 6.575767283427965e-05,
        "gradient_norm": 0.4792955815792084,
        "train_loss": 3.0022356510162354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28377,
        "tokens": 14877720576,
        "learning_rate": 6.575179009422918e-05,
        "gradient_norm": 0.40171265602111816,
        "train_loss": 2.975337028503418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28378,
        "tokens": 14878244864,
        "learning_rate": 6.574591032862173e-05,
        "gradient_norm": 0.42531487345695496,
        "train_loss": 2.9628026485443115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28379,
        "tokens": 14878769152,
        "learning_rate": 6.574003353752343e-05,
        "gradient_norm": 0.4382827579975128,
        "train_loss": 2.951794147491455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28380,
        "tokens": 14879293440,
        "learning_rate": 6.573415972100047e-05,
        "gradient_norm": 0.4274848997592926,
        "train_loss": 3.015627861022949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28381,
        "tokens": 14879817728,
        "learning_rate": 6.572828887911898e-05,
        "gradient_norm": 0.42528799176216125,
        "train_loss": 3.0120084285736084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28382,
        "tokens": 14880342016,
        "learning_rate": 6.572242101194501e-05,
        "gradient_norm": 0.4647883474826813,
        "train_loss": 2.9430785179138184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28383,
        "tokens": 14880866304,
        "learning_rate": 6.57165561195446e-05,
        "gradient_norm": 0.45283788442611694,
        "train_loss": 2.943063974380493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28384,
        "tokens": 14881390592,
        "learning_rate": 6.571069420198381e-05,
        "gradient_norm": 0.46245425939559937,
        "train_loss": 2.9838995933532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28385,
        "tokens": 14881914880,
        "learning_rate": 6.570483525932859e-05,
        "gradient_norm": 0.4368824064731598,
        "train_loss": 3.00034236907959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28386,
        "tokens": 14882439168,
        "learning_rate": 6.569897929164491e-05,
        "gradient_norm": 0.43457600474357605,
        "train_loss": 3.016702651977539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28387,
        "tokens": 14882963456,
        "learning_rate": 6.569312629899867e-05,
        "gradient_norm": 0.4890490770339966,
        "train_loss": 3.026643753051758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28388,
        "tokens": 14883487744,
        "learning_rate": 6.568727628145576e-05,
        "gradient_norm": 0.4358004927635193,
        "train_loss": 2.97977614402771,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28389,
        "tokens": 14884012032,
        "learning_rate": 6.568142923908205e-05,
        "gradient_norm": 0.4609867036342621,
        "train_loss": 3.118467092514038,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28390,
        "tokens": 14884536320,
        "learning_rate": 6.567558517194333e-05,
        "gradient_norm": 0.4560677707195282,
        "train_loss": 2.972179889678955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28391,
        "tokens": 14885060608,
        "learning_rate": 6.566974408010535e-05,
        "gradient_norm": 0.5254693031311035,
        "train_loss": 3.16030216217041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28392,
        "tokens": 14885584896,
        "learning_rate": 6.566390596363397e-05,
        "gradient_norm": 0.46125897765159607,
        "train_loss": 3.0461606979370117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28393,
        "tokens": 14886109184,
        "learning_rate": 6.565807082259475e-05,
        "gradient_norm": 0.46668824553489685,
        "train_loss": 3.008513927459717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28394,
        "tokens": 14886633472,
        "learning_rate": 6.56522386570535e-05,
        "gradient_norm": 0.45684143900871277,
        "train_loss": 3.001445770263672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28395,
        "tokens": 14887157760,
        "learning_rate": 6.564640946707581e-05,
        "gradient_norm": 0.4251984655857086,
        "train_loss": 2.9992103576660156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28396,
        "tokens": 14887682048,
        "learning_rate": 6.564058325272731e-05,
        "gradient_norm": 0.5466936826705933,
        "train_loss": 2.950345039367676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28397,
        "tokens": 14888206336,
        "learning_rate": 6.563476001407358e-05,
        "gradient_norm": 0.4392596483230591,
        "train_loss": 3.0419604778289795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28398,
        "tokens": 14888730624,
        "learning_rate": 6.562893975118018e-05,
        "gradient_norm": 0.4472000002861023,
        "train_loss": 2.9729762077331543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28399,
        "tokens": 14889254912,
        "learning_rate": 6.562312246411259e-05,
        "gradient_norm": 0.47649458050727844,
        "train_loss": 3.0555226802825928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28400,
        "tokens": 14889779200,
        "learning_rate": 6.561730815293633e-05,
        "gradient_norm": 0.4664281904697418,
        "train_loss": 3.010077476501465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28401,
        "tokens": 14890303488,
        "learning_rate": 6.56114968177168e-05,
        "gradient_norm": 0.45651763677597046,
        "train_loss": 3.000255584716797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28402,
        "tokens": 14890827776,
        "learning_rate": 6.560568845851946e-05,
        "gradient_norm": 0.4213988184928894,
        "train_loss": 3.016847848892212,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28403,
        "tokens": 14891352064,
        "learning_rate": 6.559988307540968e-05,
        "gradient_norm": 0.4682188332080841,
        "train_loss": 3.028552770614624,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28404,
        "tokens": 14891876352,
        "learning_rate": 6.559408066845276e-05,
        "gradient_norm": 0.4427725374698639,
        "train_loss": 2.9976046085357666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28405,
        "tokens": 14892400640,
        "learning_rate": 6.55882812377141e-05,
        "gradient_norm": 0.39666250348091125,
        "train_loss": 3.0199203491210938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28406,
        "tokens": 14892924928,
        "learning_rate": 6.55824847832589e-05,
        "gradient_norm": 0.464273601770401,
        "train_loss": 2.98382830619812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28407,
        "tokens": 14893449216,
        "learning_rate": 6.557669130515247e-05,
        "gradient_norm": 0.4294910728931427,
        "train_loss": 3.0242505073547363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28408,
        "tokens": 14893973504,
        "learning_rate": 6.557090080345997e-05,
        "gradient_norm": 0.4201638996601105,
        "train_loss": 2.9548187255859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28409,
        "tokens": 14894497792,
        "learning_rate": 6.55651132782466e-05,
        "gradient_norm": 0.44188570976257324,
        "train_loss": 2.9864068031311035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28410,
        "tokens": 14895022080,
        "learning_rate": 6.555932872957752e-05,
        "gradient_norm": 0.40834763646125793,
        "train_loss": 3.050917625427246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28411,
        "tokens": 14895546368,
        "learning_rate": 6.555354715751782e-05,
        "gradient_norm": 0.45570510625839233,
        "train_loss": 2.9747157096862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28412,
        "tokens": 14896070656,
        "learning_rate": 6.55477685621326e-05,
        "gradient_norm": 0.4192441403865814,
        "train_loss": 2.999985694885254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28413,
        "tokens": 14896594944,
        "learning_rate": 6.554199294348686e-05,
        "gradient_norm": 0.41485223174095154,
        "train_loss": 3.0436394214630127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28414,
        "tokens": 14897119232,
        "learning_rate": 6.553622030164568e-05,
        "gradient_norm": 0.43577295541763306,
        "train_loss": 2.976632595062256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28415,
        "tokens": 14897643520,
        "learning_rate": 6.553045063667399e-05,
        "gradient_norm": 0.45663151144981384,
        "train_loss": 3.047865390777588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28416,
        "tokens": 14898167808,
        "learning_rate": 6.552468394863674e-05,
        "gradient_norm": 0.4053300619125366,
        "train_loss": 2.9759912490844727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28417,
        "tokens": 14898692096,
        "learning_rate": 6.551892023759886e-05,
        "gradient_norm": 0.5253217220306396,
        "train_loss": 2.9911484718322754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28418,
        "tokens": 14899216384,
        "learning_rate": 6.551315950362524e-05,
        "gradient_norm": 0.46311983466148376,
        "train_loss": 3.040407657623291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28419,
        "tokens": 14899740672,
        "learning_rate": 6.550740174678064e-05,
        "gradient_norm": 0.45879971981048584,
        "train_loss": 3.029512643814087,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28420,
        "tokens": 14900264960,
        "learning_rate": 6.550164696713e-05,
        "gradient_norm": 0.4307102560997009,
        "train_loss": 3.0045320987701416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28421,
        "tokens": 14900789248,
        "learning_rate": 6.549589516473797e-05,
        "gradient_norm": 0.4426250755786896,
        "train_loss": 3.0002670288085938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28422,
        "tokens": 14901313536,
        "learning_rate": 6.549014633966938e-05,
        "gradient_norm": 0.4717124104499817,
        "train_loss": 3.024528980255127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28423,
        "tokens": 14901837824,
        "learning_rate": 6.548440049198894e-05,
        "gradient_norm": 0.4115002751350403,
        "train_loss": 3.043647289276123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28424,
        "tokens": 14902362112,
        "learning_rate": 6.547865762176124e-05,
        "gradient_norm": 0.4306076169013977,
        "train_loss": 3.018535852432251,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28425,
        "tokens": 14902886400,
        "learning_rate": 6.547291772905105e-05,
        "gradient_norm": 0.49613508582115173,
        "train_loss": 3.0286049842834473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28426,
        "tokens": 14903410688,
        "learning_rate": 6.546718081392286e-05,
        "gradient_norm": 0.4000299572944641,
        "train_loss": 3.000044822692871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28427,
        "tokens": 14903934976,
        "learning_rate": 6.546144687644133e-05,
        "gradient_norm": 0.3900628685951233,
        "train_loss": 3.0308914184570312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28428,
        "tokens": 14904459264,
        "learning_rate": 6.545571591667096e-05,
        "gradient_norm": 0.4153907001018524,
        "train_loss": 2.970008611679077,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28429,
        "tokens": 14904983552,
        "learning_rate": 6.544998793467628e-05,
        "gradient_norm": 0.3983839154243469,
        "train_loss": 2.9740710258483887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28430,
        "tokens": 14905507840,
        "learning_rate": 6.544426293052171e-05,
        "gradient_norm": 0.40510398149490356,
        "train_loss": 3.056177854537964,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28431,
        "tokens": 14906032128,
        "learning_rate": 6.54385409042718e-05,
        "gradient_norm": 0.3931325376033783,
        "train_loss": 3.0173401832580566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28432,
        "tokens": 14906556416,
        "learning_rate": 6.543282185599083e-05,
        "gradient_norm": 0.4018460810184479,
        "train_loss": 3.028940439224243,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28433,
        "tokens": 14907080704,
        "learning_rate": 6.542710578574328e-05,
        "gradient_norm": 0.3979763388633728,
        "train_loss": 2.979285717010498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28434,
        "tokens": 14907604992,
        "learning_rate": 6.542139269359349e-05,
        "gradient_norm": 0.39556312561035156,
        "train_loss": 2.9875965118408203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28435,
        "tokens": 14908129280,
        "learning_rate": 6.541568257960567e-05,
        "gradient_norm": 0.46738696098327637,
        "train_loss": 3.0035595893859863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28436,
        "tokens": 14908653568,
        "learning_rate": 6.54099754438442e-05,
        "gradient_norm": 0.4957435131072998,
        "train_loss": 3.077085018157959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28437,
        "tokens": 14909177856,
        "learning_rate": 6.540427128637325e-05,
        "gradient_norm": 0.4247971773147583,
        "train_loss": 3.0308351516723633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28438,
        "tokens": 14909702144,
        "learning_rate": 6.539857010725708e-05,
        "gradient_norm": 0.48398205637931824,
        "train_loss": 3.0169124603271484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28439,
        "tokens": 14910226432,
        "learning_rate": 6.53928719065598e-05,
        "gradient_norm": 0.3879006803035736,
        "train_loss": 3.02095365524292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28440,
        "tokens": 14910750720,
        "learning_rate": 6.538717668434562e-05,
        "gradient_norm": 0.44760119915008545,
        "train_loss": 3.0325417518615723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28441,
        "tokens": 14911275008,
        "learning_rate": 6.53814844406786e-05,
        "gradient_norm": 0.4457760751247406,
        "train_loss": 3.0077872276306152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28442,
        "tokens": 14911799296,
        "learning_rate": 6.537579517562282e-05,
        "gradient_norm": 0.41512569785118103,
        "train_loss": 3.0320425033569336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28443,
        "tokens": 14912323584,
        "learning_rate": 6.537010888924236e-05,
        "gradient_norm": 0.4688990116119385,
        "train_loss": 2.9916152954101562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28444,
        "tokens": 14912847872,
        "learning_rate": 6.536442558160116e-05,
        "gradient_norm": 0.39691439270973206,
        "train_loss": 3.001749038696289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28445,
        "tokens": 14913372160,
        "learning_rate": 6.535874525276325e-05,
        "gradient_norm": 0.5243772268295288,
        "train_loss": 3.0650787353515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28446,
        "tokens": 14913896448,
        "learning_rate": 6.535306790279252e-05,
        "gradient_norm": 0.42265164852142334,
        "train_loss": 2.9835453033447266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28447,
        "tokens": 14914420736,
        "learning_rate": 6.534739353175293e-05,
        "gradient_norm": 0.4308497905731201,
        "train_loss": 3.0193018913269043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28448,
        "tokens": 14914945024,
        "learning_rate": 6.534172213970831e-05,
        "gradient_norm": 0.44115301966667175,
        "train_loss": 3.0138869285583496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28449,
        "tokens": 14915469312,
        "learning_rate": 6.533605372672252e-05,
        "gradient_norm": 0.40445175766944885,
        "train_loss": 3.046846389770508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28450,
        "tokens": 14915993600,
        "learning_rate": 6.533038829285933e-05,
        "gradient_norm": 0.44652971625328064,
        "train_loss": 3.0719351768493652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28451,
        "tokens": 14916517888,
        "learning_rate": 6.532472583818258e-05,
        "gradient_norm": 0.43199166655540466,
        "train_loss": 2.9959304332733154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28452,
        "tokens": 14917042176,
        "learning_rate": 6.531906636275595e-05,
        "gradient_norm": 0.5098438858985901,
        "train_loss": 3.052304744720459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28453,
        "tokens": 14917566464,
        "learning_rate": 6.531340986664314e-05,
        "gradient_norm": 0.48248448967933655,
        "train_loss": 3.0007545948028564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28454,
        "tokens": 14918090752,
        "learning_rate": 6.530775634990787e-05,
        "gradient_norm": 0.5201524496078491,
        "train_loss": 3.027902603149414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28455,
        "tokens": 14918615040,
        "learning_rate": 6.530210581261375e-05,
        "gradient_norm": 0.5010000467300415,
        "train_loss": 3.0708625316619873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28456,
        "tokens": 14919139328,
        "learning_rate": 6.529645825482438e-05,
        "gradient_norm": 0.5189855694770813,
        "train_loss": 3.0022621154785156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28457,
        "tokens": 14919663616,
        "learning_rate": 6.529081367660333e-05,
        "gradient_norm": 0.4586276412010193,
        "train_loss": 3.0058043003082275,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28458,
        "tokens": 14920187904,
        "learning_rate": 6.528517207801415e-05,
        "gradient_norm": 0.42119166254997253,
        "train_loss": 2.965721368789673,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28459,
        "tokens": 14920712192,
        "learning_rate": 6.52795334591203e-05,
        "gradient_norm": 0.441631555557251,
        "train_loss": 3.055548667907715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28460,
        "tokens": 14921236480,
        "learning_rate": 6.527389781998532e-05,
        "gradient_norm": 0.48697012662887573,
        "train_loss": 3.017972946166992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28461,
        "tokens": 14921760768,
        "learning_rate": 6.52682651606726e-05,
        "gradient_norm": 0.39409899711608887,
        "train_loss": 3.0289766788482666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28462,
        "tokens": 14922285056,
        "learning_rate": 6.526263548124553e-05,
        "gradient_norm": 0.40539243817329407,
        "train_loss": 3.0394248962402344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28463,
        "tokens": 14922809344,
        "learning_rate": 6.525700878176754e-05,
        "gradient_norm": 0.5302291512489319,
        "train_loss": 2.959153175354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28464,
        "tokens": 14923333632,
        "learning_rate": 6.52513850623019e-05,
        "gradient_norm": 0.43024423718452454,
        "train_loss": 3.0200047492980957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28465,
        "tokens": 14923857920,
        "learning_rate": 6.524576432291196e-05,
        "gradient_norm": 0.4133942723274231,
        "train_loss": 3.0139284133911133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28466,
        "tokens": 14924382208,
        "learning_rate": 6.524014656366093e-05,
        "gradient_norm": 0.4426664710044861,
        "train_loss": 3.0531861782073975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28467,
        "tokens": 14924906496,
        "learning_rate": 6.523453178461212e-05,
        "gradient_norm": 0.5098909735679626,
        "train_loss": 3.0562233924865723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28468,
        "tokens": 14925430784,
        "learning_rate": 6.522891998582868e-05,
        "gradient_norm": 0.4921777844429016,
        "train_loss": 2.988101005554199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28469,
        "tokens": 14925955072,
        "learning_rate": 6.52233111673738e-05,
        "gradient_norm": 0.5601767897605896,
        "train_loss": 3.020885467529297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28470,
        "tokens": 14926479360,
        "learning_rate": 6.521770532931058e-05,
        "gradient_norm": 0.44086822867393494,
        "train_loss": 3.011528491973877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28471,
        "tokens": 14927003648,
        "learning_rate": 6.521210247170214e-05,
        "gradient_norm": 0.5228591561317444,
        "train_loss": 3.036036491394043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28472,
        "tokens": 14927527936,
        "learning_rate": 6.520650259461163e-05,
        "gradient_norm": 0.4220651090145111,
        "train_loss": 3.0082831382751465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28473,
        "tokens": 14928052224,
        "learning_rate": 6.520090569810192e-05,
        "gradient_norm": 0.45943036675453186,
        "train_loss": 3.0243899822235107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28474,
        "tokens": 14928576512,
        "learning_rate": 6.519531178223614e-05,
        "gradient_norm": 0.46285682916641235,
        "train_loss": 2.9805235862731934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28475,
        "tokens": 14929100800,
        "learning_rate": 6.518972084707721e-05,
        "gradient_norm": 0.4256429672241211,
        "train_loss": 3.001147747039795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28476,
        "tokens": 14929625088,
        "learning_rate": 6.518413289268808e-05,
        "gradient_norm": 0.39466172456741333,
        "train_loss": 3.0149035453796387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28477,
        "tokens": 14930149376,
        "learning_rate": 6.51785479191316e-05,
        "gradient_norm": 0.43881306052207947,
        "train_loss": 3.0619802474975586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28478,
        "tokens": 14930673664,
        "learning_rate": 6.517296592647069e-05,
        "gradient_norm": 0.4736360013484955,
        "train_loss": 3.032942295074463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28479,
        "tokens": 14931197952,
        "learning_rate": 6.516738691476816e-05,
        "gradient_norm": 0.43453624844551086,
        "train_loss": 2.965481758117676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28480,
        "tokens": 14931722240,
        "learning_rate": 6.516181088408684e-05,
        "gradient_norm": 0.4363747835159302,
        "train_loss": 3.0050885677337646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28481,
        "tokens": 14932246528,
        "learning_rate": 6.515623783448942e-05,
        "gradient_norm": 0.39893239736557007,
        "train_loss": 3.025611400604248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28482,
        "tokens": 14932770816,
        "learning_rate": 6.515066776603871e-05,
        "gradient_norm": 0.43767473101615906,
        "train_loss": 3.032590627670288,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28483,
        "tokens": 14933295104,
        "learning_rate": 6.514510067879737e-05,
        "gradient_norm": 0.4559701681137085,
        "train_loss": 3.021233558654785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28484,
        "tokens": 14933819392,
        "learning_rate": 6.513953657282808e-05,
        "gradient_norm": 0.4357352554798126,
        "train_loss": 3.030137777328491,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28485,
        "tokens": 14934343680,
        "learning_rate": 6.513397544819347e-05,
        "gradient_norm": 0.40861696004867554,
        "train_loss": 3.0551881790161133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28486,
        "tokens": 14934867968,
        "learning_rate": 6.512841730495612e-05,
        "gradient_norm": 0.42764174938201904,
        "train_loss": 3.0054922103881836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28487,
        "tokens": 14935392256,
        "learning_rate": 6.512286214317859e-05,
        "gradient_norm": 0.4462551474571228,
        "train_loss": 2.968456745147705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28488,
        "tokens": 14935916544,
        "learning_rate": 6.511730996292346e-05,
        "gradient_norm": 0.4331751763820648,
        "train_loss": 2.995490550994873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28489,
        "tokens": 14936440832,
        "learning_rate": 6.511176076425314e-05,
        "gradient_norm": 0.43653079867362976,
        "train_loss": 2.9971580505371094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28490,
        "tokens": 14936965120,
        "learning_rate": 6.510621454723018e-05,
        "gradient_norm": 0.5068749785423279,
        "train_loss": 3.0571701526641846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28491,
        "tokens": 14937489408,
        "learning_rate": 6.510067131191698e-05,
        "gradient_norm": 0.40352967381477356,
        "train_loss": 3.0368566513061523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28492,
        "tokens": 14938013696,
        "learning_rate": 6.50951310583759e-05,
        "gradient_norm": 0.4685700833797455,
        "train_loss": 2.9961538314819336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28493,
        "tokens": 14938537984,
        "learning_rate": 6.508959378666937e-05,
        "gradient_norm": 0.4187426269054413,
        "train_loss": 3.0174155235290527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28494,
        "tokens": 14939062272,
        "learning_rate": 6.508405949685966e-05,
        "gradient_norm": 0.4261679947376251,
        "train_loss": 3.0064187049865723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28495,
        "tokens": 14939586560,
        "learning_rate": 6.507852818900907e-05,
        "gradient_norm": 0.44857680797576904,
        "train_loss": 3.0277462005615234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28496,
        "tokens": 14940110848,
        "learning_rate": 6.507299986317993e-05,
        "gradient_norm": 0.42271506786346436,
        "train_loss": 2.9759349822998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28497,
        "tokens": 14940635136,
        "learning_rate": 6.506747451943436e-05,
        "gradient_norm": 0.4000348150730133,
        "train_loss": 3.067514419555664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28498,
        "tokens": 14941159424,
        "learning_rate": 6.506195215783463e-05,
        "gradient_norm": 0.4521963596343994,
        "train_loss": 3.029876470565796,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28499,
        "tokens": 14941683712,
        "learning_rate": 6.505643277844288e-05,
        "gradient_norm": 0.41549110412597656,
        "train_loss": 3.0466301441192627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28500,
        "tokens": 14942208000,
        "learning_rate": 6.505091638132124e-05,
        "gradient_norm": 0.40934011340141296,
        "train_loss": 2.9936776161193848,
        "val_loss": 2.9608848094940186,
        "hellaswag_acc": 0.2860983908176422,
        "hellaswag_acc_norm": 0.2988448441028595
    },
    {
        "step": 28501,
        "tokens": 14942732288,
        "learning_rate": 6.504540296653182e-05,
        "gradient_norm": 0.47116103768348694,
        "train_loss": 3.016906976699829,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28502,
        "tokens": 14943256576,
        "learning_rate": 6.503989253413664e-05,
        "gradient_norm": 0.3963519334793091,
        "train_loss": 3.0769057273864746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28503,
        "tokens": 14943780864,
        "learning_rate": 6.503438508419778e-05,
        "gradient_norm": 0.45350512862205505,
        "train_loss": 2.970578193664551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28504,
        "tokens": 14944305152,
        "learning_rate": 6.502888061677717e-05,
        "gradient_norm": 0.423931360244751,
        "train_loss": 3.038051128387451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28505,
        "tokens": 14944829440,
        "learning_rate": 6.502337913193684e-05,
        "gradient_norm": 0.3964262902736664,
        "train_loss": 3.0458505153656006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28506,
        "tokens": 14945353728,
        "learning_rate": 6.501788062973864e-05,
        "gradient_norm": 0.4173377752304077,
        "train_loss": 3.025275230407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28507,
        "tokens": 14945878016,
        "learning_rate": 6.501238511024455e-05,
        "gradient_norm": 0.4155873656272888,
        "train_loss": 3.0546884536743164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28508,
        "tokens": 14946402304,
        "learning_rate": 6.500689257351635e-05,
        "gradient_norm": 0.502854585647583,
        "train_loss": 3.0341715812683105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28509,
        "tokens": 14946926592,
        "learning_rate": 6.500140301961593e-05,
        "gradient_norm": 0.4320887625217438,
        "train_loss": 3.040212631225586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28510,
        "tokens": 14947450880,
        "learning_rate": 6.499591644860498e-05,
        "gradient_norm": 0.478378564119339,
        "train_loss": 2.976101875305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28511,
        "tokens": 14947975168,
        "learning_rate": 6.499043286054535e-05,
        "gradient_norm": 0.4678032100200653,
        "train_loss": 3.015918254852295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28512,
        "tokens": 14948499456,
        "learning_rate": 6.498495225549879e-05,
        "gradient_norm": 0.4272831082344055,
        "train_loss": 3.078032970428467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28513,
        "tokens": 14949023744,
        "learning_rate": 6.497947463352689e-05,
        "gradient_norm": 0.4100702106952667,
        "train_loss": 2.995123863220215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28514,
        "tokens": 14949548032,
        "learning_rate": 6.49739999946914e-05,
        "gradient_norm": 0.42511847615242004,
        "train_loss": 3.039426803588867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28515,
        "tokens": 14950072320,
        "learning_rate": 6.49685283390539e-05,
        "gradient_norm": 0.4048541784286499,
        "train_loss": 3.000765323638916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28516,
        "tokens": 14950596608,
        "learning_rate": 6.496305966667596e-05,
        "gradient_norm": 0.42729097604751587,
        "train_loss": 2.974034309387207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28517,
        "tokens": 14951120896,
        "learning_rate": 6.495759397761915e-05,
        "gradient_norm": 0.43004515767097473,
        "train_loss": 3.0373406410217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28518,
        "tokens": 14951645184,
        "learning_rate": 6.495213127194504e-05,
        "gradient_norm": 0.40413954854011536,
        "train_loss": 3.0137622356414795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28519,
        "tokens": 14952169472,
        "learning_rate": 6.494667154971506e-05,
        "gradient_norm": 0.4146522879600525,
        "train_loss": 3.049103260040283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28520,
        "tokens": 14952693760,
        "learning_rate": 6.494121481099069e-05,
        "gradient_norm": 0.4170117974281311,
        "train_loss": 3.051279306411743,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28521,
        "tokens": 14953218048,
        "learning_rate": 6.493576105583336e-05,
        "gradient_norm": 0.41064101457595825,
        "train_loss": 2.99465274810791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28522,
        "tokens": 14953742336,
        "learning_rate": 6.493031028430445e-05,
        "gradient_norm": 0.46410810947418213,
        "train_loss": 3.0431690216064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28523,
        "tokens": 14954266624,
        "learning_rate": 6.492486249646531e-05,
        "gradient_norm": 0.4095485210418701,
        "train_loss": 2.9944920539855957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28524,
        "tokens": 14954790912,
        "learning_rate": 6.491941769237727e-05,
        "gradient_norm": 0.49161073565483093,
        "train_loss": 3.0114035606384277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28525,
        "tokens": 14955315200,
        "learning_rate": 6.491397587210163e-05,
        "gradient_norm": 0.4374525249004364,
        "train_loss": 3.0185627937316895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28526,
        "tokens": 14955839488,
        "learning_rate": 6.49085370356996e-05,
        "gradient_norm": 0.40591543912887573,
        "train_loss": 2.9604077339172363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28527,
        "tokens": 14956363776,
        "learning_rate": 6.490310118323246e-05,
        "gradient_norm": 0.4591977894306183,
        "train_loss": 2.9868884086608887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28528,
        "tokens": 14956888064,
        "learning_rate": 6.489766831476135e-05,
        "gradient_norm": 0.44333216547966003,
        "train_loss": 3.0236268043518066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28529,
        "tokens": 14957412352,
        "learning_rate": 6.489223843034745e-05,
        "gradient_norm": 0.3958144783973694,
        "train_loss": 3.060091972351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28530,
        "tokens": 14957936640,
        "learning_rate": 6.488681153005187e-05,
        "gradient_norm": 0.43499162793159485,
        "train_loss": 3.0150697231292725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28531,
        "tokens": 14958460928,
        "learning_rate": 6.488138761393569e-05,
        "gradient_norm": 0.39410075545310974,
        "train_loss": 2.9661097526550293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28532,
        "tokens": 14958985216,
        "learning_rate": 6.487596668205999e-05,
        "gradient_norm": 0.39686208963394165,
        "train_loss": 3.043278217315674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28533,
        "tokens": 14959509504,
        "learning_rate": 6.487054873448575e-05,
        "gradient_norm": 0.4338566064834595,
        "train_loss": 2.905104637145996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28534,
        "tokens": 14960033792,
        "learning_rate": 6.486513377127399e-05,
        "gradient_norm": 0.4764832854270935,
        "train_loss": 2.973550796508789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28535,
        "tokens": 14960558080,
        "learning_rate": 6.485972179248564e-05,
        "gradient_norm": 0.4352802634239197,
        "train_loss": 3.0090408325195312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28536,
        "tokens": 14961082368,
        "learning_rate": 6.485431279818166e-05,
        "gradient_norm": 0.39328551292419434,
        "train_loss": 3.0292036533355713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28537,
        "tokens": 14961606656,
        "learning_rate": 6.484890678842285e-05,
        "gradient_norm": 0.4567652940750122,
        "train_loss": 2.99863338470459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28538,
        "tokens": 14962130944,
        "learning_rate": 6.484350376327017e-05,
        "gradient_norm": 0.515838623046875,
        "train_loss": 2.999990940093994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28539,
        "tokens": 14962655232,
        "learning_rate": 6.483810372278434e-05,
        "gradient_norm": 0.44961461424827576,
        "train_loss": 2.9957094192504883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28540,
        "tokens": 14963179520,
        "learning_rate": 6.483270666702618e-05,
        "gradient_norm": 0.44247666001319885,
        "train_loss": 3.020141124725342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28541,
        "tokens": 14963703808,
        "learning_rate": 6.482731259605646e-05,
        "gradient_norm": 0.46113646030426025,
        "train_loss": 3.0191590785980225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28542,
        "tokens": 14964228096,
        "learning_rate": 6.482192150993589e-05,
        "gradient_norm": 0.40802374482154846,
        "train_loss": 3.002870559692383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28543,
        "tokens": 14964752384,
        "learning_rate": 6.481653340872513e-05,
        "gradient_norm": 0.4437510371208191,
        "train_loss": 3.0496482849121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28544,
        "tokens": 14965276672,
        "learning_rate": 6.481114829248485e-05,
        "gradient_norm": 0.44685614109039307,
        "train_loss": 2.9964709281921387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28545,
        "tokens": 14965800960,
        "learning_rate": 6.480576616127569e-05,
        "gradient_norm": 0.4503980278968811,
        "train_loss": 3.0092787742614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28546,
        "tokens": 14966325248,
        "learning_rate": 6.480038701515819e-05,
        "gradient_norm": 0.43440142273902893,
        "train_loss": 3.0045864582061768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28547,
        "tokens": 14966849536,
        "learning_rate": 6.479501085419292e-05,
        "gradient_norm": 0.4656972885131836,
        "train_loss": 2.9407269954681396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28548,
        "tokens": 14967373824,
        "learning_rate": 6.478963767844036e-05,
        "gradient_norm": 0.38762757182121277,
        "train_loss": 2.987785816192627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28549,
        "tokens": 14967898112,
        "learning_rate": 6.478426748796106e-05,
        "gradient_norm": 0.450131893157959,
        "train_loss": 2.9423775672912598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28550,
        "tokens": 14968422400,
        "learning_rate": 6.477890028281537e-05,
        "gradient_norm": 0.443208247423172,
        "train_loss": 2.9684736728668213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28551,
        "tokens": 14968946688,
        "learning_rate": 6.477353606306381e-05,
        "gradient_norm": 0.44368433952331543,
        "train_loss": 3.051185131072998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28552,
        "tokens": 14969470976,
        "learning_rate": 6.476817482876674e-05,
        "gradient_norm": 0.41114941239356995,
        "train_loss": 2.974055767059326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28553,
        "tokens": 14969995264,
        "learning_rate": 6.476281657998443e-05,
        "gradient_norm": 0.4983789026737213,
        "train_loss": 3.0455660820007324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28554,
        "tokens": 14970519552,
        "learning_rate": 6.475746131677728e-05,
        "gradient_norm": 0.4259956479072571,
        "train_loss": 3.005977153778076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28555,
        "tokens": 14971043840,
        "learning_rate": 6.475210903920553e-05,
        "gradient_norm": 0.5077090859413147,
        "train_loss": 3.051865577697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28556,
        "tokens": 14971568128,
        "learning_rate": 6.474675974732941e-05,
        "gradient_norm": 0.4596654176712036,
        "train_loss": 3.0579094886779785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28557,
        "tokens": 14972092416,
        "learning_rate": 6.474141344120917e-05,
        "gradient_norm": 0.4221014678478241,
        "train_loss": 3.028303623199463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28558,
        "tokens": 14972616704,
        "learning_rate": 6.473607012090498e-05,
        "gradient_norm": 0.4376479387283325,
        "train_loss": 3.0402674674987793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28559,
        "tokens": 14973140992,
        "learning_rate": 6.473072978647698e-05,
        "gradient_norm": 0.44383975863456726,
        "train_loss": 3.043231248855591,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28560,
        "tokens": 14973665280,
        "learning_rate": 6.472539243798531e-05,
        "gradient_norm": 0.416036456823349,
        "train_loss": 3.0435428619384766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28561,
        "tokens": 14974189568,
        "learning_rate": 6.472005807548998e-05,
        "gradient_norm": 0.4697934091091156,
        "train_loss": 3.038907527923584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28562,
        "tokens": 14974713856,
        "learning_rate": 6.471472669905108e-05,
        "gradient_norm": 0.46571099758148193,
        "train_loss": 2.9563169479370117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28563,
        "tokens": 14975238144,
        "learning_rate": 6.470939830872864e-05,
        "gradient_norm": 0.4414108097553253,
        "train_loss": 3.014638900756836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28564,
        "tokens": 14975762432,
        "learning_rate": 6.470407290458258e-05,
        "gradient_norm": 0.4488493800163269,
        "train_loss": 3.018648624420166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28565,
        "tokens": 14976286720,
        "learning_rate": 6.46987504866729e-05,
        "gradient_norm": 0.4760432541370392,
        "train_loss": 3.0098910331726074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28566,
        "tokens": 14976811008,
        "learning_rate": 6.469343105505951e-05,
        "gradient_norm": 0.43365588784217834,
        "train_loss": 3.0064423084259033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28567,
        "tokens": 14977335296,
        "learning_rate": 6.468811460980224e-05,
        "gradient_norm": 0.433353453874588,
        "train_loss": 3.087730646133423,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28568,
        "tokens": 14977859584,
        "learning_rate": 6.468280115096099e-05,
        "gradient_norm": 0.426885724067688,
        "train_loss": 2.9831552505493164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28569,
        "tokens": 14978383872,
        "learning_rate": 6.467749067859551e-05,
        "gradient_norm": 0.4265369474887848,
        "train_loss": 2.9802207946777344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28570,
        "tokens": 14978908160,
        "learning_rate": 6.46721831927656e-05,
        "gradient_norm": 0.4617193639278412,
        "train_loss": 2.9917140007019043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28571,
        "tokens": 14979432448,
        "learning_rate": 6.466687869353103e-05,
        "gradient_norm": 0.4088049530982971,
        "train_loss": 2.9951577186584473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28572,
        "tokens": 14979956736,
        "learning_rate": 6.466157718095148e-05,
        "gradient_norm": 0.39401692152023315,
        "train_loss": 3.0201854705810547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28573,
        "tokens": 14980481024,
        "learning_rate": 6.465627865508662e-05,
        "gradient_norm": 0.4157797694206238,
        "train_loss": 3.014979839324951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28574,
        "tokens": 14981005312,
        "learning_rate": 6.465098311599612e-05,
        "gradient_norm": 0.41528505086898804,
        "train_loss": 3.0077013969421387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28575,
        "tokens": 14981529600,
        "learning_rate": 6.464569056373958e-05,
        "gradient_norm": 0.40289655327796936,
        "train_loss": 3.0153284072875977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28576,
        "tokens": 14982053888,
        "learning_rate": 6.464040099837654e-05,
        "gradient_norm": 0.40070840716362,
        "train_loss": 2.997133731842041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28577,
        "tokens": 14982578176,
        "learning_rate": 6.463511441996656e-05,
        "gradient_norm": 0.4052862823009491,
        "train_loss": 3.0018832683563232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28578,
        "tokens": 14983102464,
        "learning_rate": 6.462983082856921e-05,
        "gradient_norm": 0.44445645809173584,
        "train_loss": 3.002082347869873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28579,
        "tokens": 14983626752,
        "learning_rate": 6.462455022424386e-05,
        "gradient_norm": 0.400640070438385,
        "train_loss": 3.0572853088378906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28580,
        "tokens": 14984151040,
        "learning_rate": 6.461927260705e-05,
        "gradient_norm": 1.1215866804122925,
        "train_loss": 2.979306221008301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28581,
        "tokens": 14984675328,
        "learning_rate": 6.461399797704702e-05,
        "gradient_norm": 0.44416284561157227,
        "train_loss": 3.0522773265838623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28582,
        "tokens": 14985199616,
        "learning_rate": 6.460872633429432e-05,
        "gradient_norm": 0.4295872449874878,
        "train_loss": 3.0821900367736816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28583,
        "tokens": 14985723904,
        "learning_rate": 6.460345767885123e-05,
        "gradient_norm": 0.5117576718330383,
        "train_loss": 2.988096237182617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28584,
        "tokens": 14986248192,
        "learning_rate": 6.459819201077702e-05,
        "gradient_norm": 0.47934970259666443,
        "train_loss": 3.0052828788757324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28585,
        "tokens": 14986772480,
        "learning_rate": 6.459292933013105e-05,
        "gradient_norm": 0.41242605447769165,
        "train_loss": 3.0029006004333496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28586,
        "tokens": 14987296768,
        "learning_rate": 6.458766963697244e-05,
        "gradient_norm": 0.45804303884506226,
        "train_loss": 3.0332984924316406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28587,
        "tokens": 14987821056,
        "learning_rate": 6.458241293136049e-05,
        "gradient_norm": 0.4433920979499817,
        "train_loss": 3.0188047885894775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28588,
        "tokens": 14988345344,
        "learning_rate": 6.457715921335434e-05,
        "gradient_norm": 0.41656142473220825,
        "train_loss": 3.0712311267852783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28589,
        "tokens": 14988869632,
        "learning_rate": 6.457190848301312e-05,
        "gradient_norm": 0.4065210819244385,
        "train_loss": 3.023556709289551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28590,
        "tokens": 14989393920,
        "learning_rate": 6.456666074039587e-05,
        "gradient_norm": 0.44640275835990906,
        "train_loss": 2.989734649658203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28591,
        "tokens": 14989918208,
        "learning_rate": 6.45614159855618e-05,
        "gradient_norm": 0.4447088837623596,
        "train_loss": 3.0817806720733643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28592,
        "tokens": 14990442496,
        "learning_rate": 6.455617421856985e-05,
        "gradient_norm": 0.4203038513660431,
        "train_loss": 3.055677652359009,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28593,
        "tokens": 14990966784,
        "learning_rate": 6.455093543947905e-05,
        "gradient_norm": 0.4232576787471771,
        "train_loss": 3.001025438308716,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28594,
        "tokens": 14991491072,
        "learning_rate": 6.454569964834833e-05,
        "gradient_norm": 0.4223654270172119,
        "train_loss": 3.0409445762634277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28595,
        "tokens": 14992015360,
        "learning_rate": 6.454046684523668e-05,
        "gradient_norm": 0.4260604977607727,
        "train_loss": 2.975633382797241,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28596,
        "tokens": 14992539648,
        "learning_rate": 6.453523703020298e-05,
        "gradient_norm": 0.40319591760635376,
        "train_loss": 2.987761974334717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28597,
        "tokens": 14993063936,
        "learning_rate": 6.453001020330612e-05,
        "gradient_norm": 0.4375472664833069,
        "train_loss": 3.0181539058685303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28598,
        "tokens": 14993588224,
        "learning_rate": 6.452478636460486e-05,
        "gradient_norm": 0.415316104888916,
        "train_loss": 3.0179076194763184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28599,
        "tokens": 14994112512,
        "learning_rate": 6.451956551415811e-05,
        "gradient_norm": 0.4105722904205322,
        "train_loss": 3.036560535430908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28600,
        "tokens": 14994636800,
        "learning_rate": 6.451434765202452e-05,
        "gradient_norm": 0.4288674294948578,
        "train_loss": 3.03214693069458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28601,
        "tokens": 14995161088,
        "learning_rate": 6.450913277826294e-05,
        "gradient_norm": 0.4329315721988678,
        "train_loss": 3.061659336090088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28602,
        "tokens": 14995685376,
        "learning_rate": 6.450392089293198e-05,
        "gradient_norm": 0.37958332896232605,
        "train_loss": 3.006831645965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28603,
        "tokens": 14996209664,
        "learning_rate": 6.449871199609035e-05,
        "gradient_norm": 0.3904438316822052,
        "train_loss": 2.972860813140869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28604,
        "tokens": 14996733952,
        "learning_rate": 6.449350608779666e-05,
        "gradient_norm": 0.4405438005924225,
        "train_loss": 3.0248703956604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28605,
        "tokens": 14997258240,
        "learning_rate": 6.448830316810955e-05,
        "gradient_norm": 0.422371506690979,
        "train_loss": 2.9840078353881836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28606,
        "tokens": 14997782528,
        "learning_rate": 6.448310323708751e-05,
        "gradient_norm": 0.429442435503006,
        "train_loss": 3.0226922035217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28607,
        "tokens": 14998306816,
        "learning_rate": 6.447790629478917e-05,
        "gradient_norm": 0.40271034836769104,
        "train_loss": 2.9819507598876953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28608,
        "tokens": 14998831104,
        "learning_rate": 6.447271234127294e-05,
        "gradient_norm": 0.4673767387866974,
        "train_loss": 3.0489985942840576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28609,
        "tokens": 14999355392,
        "learning_rate": 6.446752137659736e-05,
        "gradient_norm": 0.418036550283432,
        "train_loss": 2.9975571632385254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28610,
        "tokens": 14999879680,
        "learning_rate": 6.446233340082078e-05,
        "gradient_norm": 0.4520733654499054,
        "train_loss": 3.015244245529175,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28611,
        "tokens": 15000403968,
        "learning_rate": 6.445714841400167e-05,
        "gradient_norm": 0.43730390071868896,
        "train_loss": 3.044191837310791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28612,
        "tokens": 15000928256,
        "learning_rate": 6.445196641619835e-05,
        "gradient_norm": 0.3937239348888397,
        "train_loss": 2.9986321926116943,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28613,
        "tokens": 15001452544,
        "learning_rate": 6.444678740746916e-05,
        "gradient_norm": 0.44042709469795227,
        "train_loss": 2.9966378211975098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28614,
        "tokens": 15001976832,
        "learning_rate": 6.444161138787239e-05,
        "gradient_norm": 0.3758721649646759,
        "train_loss": 2.9724130630493164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28615,
        "tokens": 15002501120,
        "learning_rate": 6.443643835746631e-05,
        "gradient_norm": 0.4368732273578644,
        "train_loss": 3.010322093963623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28616,
        "tokens": 15003025408,
        "learning_rate": 6.443126831630916e-05,
        "gradient_norm": 0.4338027238845825,
        "train_loss": 3.017869472503662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28617,
        "tokens": 15003549696,
        "learning_rate": 6.442610126445914e-05,
        "gradient_norm": 0.38766753673553467,
        "train_loss": 3.0676751136779785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28618,
        "tokens": 15004073984,
        "learning_rate": 6.442093720197439e-05,
        "gradient_norm": 0.4329584538936615,
        "train_loss": 3.0128390789031982,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28619,
        "tokens": 15004598272,
        "learning_rate": 6.441577612891301e-05,
        "gradient_norm": 0.3933452069759369,
        "train_loss": 2.996267795562744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28620,
        "tokens": 15005122560,
        "learning_rate": 6.441061804533318e-05,
        "gradient_norm": 0.4341094493865967,
        "train_loss": 3.043771266937256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28621,
        "tokens": 15005646848,
        "learning_rate": 6.440546295129288e-05,
        "gradient_norm": 0.40337875485420227,
        "train_loss": 3.055731773376465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28622,
        "tokens": 15006171136,
        "learning_rate": 6.440031084685017e-05,
        "gradient_norm": 0.38560834527015686,
        "train_loss": 2.9916458129882812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28623,
        "tokens": 15006695424,
        "learning_rate": 6.439516173206303e-05,
        "gradient_norm": 0.4753517508506775,
        "train_loss": 3.1163270473480225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28624,
        "tokens": 15007219712,
        "learning_rate": 6.439001560698945e-05,
        "gradient_norm": 0.465530127286911,
        "train_loss": 3.01106595993042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28625,
        "tokens": 15007744000,
        "learning_rate": 6.438487247168733e-05,
        "gradient_norm": 0.43952226638793945,
        "train_loss": 2.934833288192749,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28626,
        "tokens": 15008268288,
        "learning_rate": 6.437973232621458e-05,
        "gradient_norm": 0.39376893639564514,
        "train_loss": 3.004843235015869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28627,
        "tokens": 15008792576,
        "learning_rate": 6.437459517062903e-05,
        "gradient_norm": 0.4227350056171417,
        "train_loss": 3.056293487548828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28628,
        "tokens": 15009316864,
        "learning_rate": 6.436946100498852e-05,
        "gradient_norm": 0.43018287420272827,
        "train_loss": 3.062349319458008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28629,
        "tokens": 15009841152,
        "learning_rate": 6.436432982935087e-05,
        "gradient_norm": 0.44316452741622925,
        "train_loss": 2.9938838481903076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28630,
        "tokens": 15010365440,
        "learning_rate": 6.435920164377377e-05,
        "gradient_norm": 0.3975168466567993,
        "train_loss": 3.019761562347412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28631,
        "tokens": 15010889728,
        "learning_rate": 6.4354076448315e-05,
        "gradient_norm": 0.43355047702789307,
        "train_loss": 2.991138458251953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28632,
        "tokens": 15011414016,
        "learning_rate": 6.434895424303225e-05,
        "gradient_norm": 0.4081854522228241,
        "train_loss": 2.9867615699768066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28633,
        "tokens": 15011938304,
        "learning_rate": 6.434383502798315e-05,
        "gradient_norm": 0.46538564562797546,
        "train_loss": 3.0212154388427734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28634,
        "tokens": 15012462592,
        "learning_rate": 6.433871880322536e-05,
        "gradient_norm": 0.4148436188697815,
        "train_loss": 2.922588348388672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28635,
        "tokens": 15012986880,
        "learning_rate": 6.43336055688164e-05,
        "gradient_norm": 0.42681998014450073,
        "train_loss": 3.090250015258789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28636,
        "tokens": 15013511168,
        "learning_rate": 6.43284953248139e-05,
        "gradient_norm": 0.4734501838684082,
        "train_loss": 3.060333251953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28637,
        "tokens": 15014035456,
        "learning_rate": 6.432338807127535e-05,
        "gradient_norm": 0.39766010642051697,
        "train_loss": 3.046527624130249,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28638,
        "tokens": 15014559744,
        "learning_rate": 6.431828380825824e-05,
        "gradient_norm": 0.4079981744289398,
        "train_loss": 3.0051679611206055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28639,
        "tokens": 15015084032,
        "learning_rate": 6.431318253582003e-05,
        "gradient_norm": 0.439231812953949,
        "train_loss": 3.030696392059326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28640,
        "tokens": 15015608320,
        "learning_rate": 6.430808425401816e-05,
        "gradient_norm": 0.4121797978878021,
        "train_loss": 3.0520434379577637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28641,
        "tokens": 15016132608,
        "learning_rate": 6.430298896290995e-05,
        "gradient_norm": 0.4178553521633148,
        "train_loss": 2.963074207305908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28642,
        "tokens": 15016656896,
        "learning_rate": 6.429789666255281e-05,
        "gradient_norm": 0.43492716550827026,
        "train_loss": 3.0258753299713135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28643,
        "tokens": 15017181184,
        "learning_rate": 6.429280735300409e-05,
        "gradient_norm": 0.4120059013366699,
        "train_loss": 2.978362560272217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28644,
        "tokens": 15017705472,
        "learning_rate": 6.428772103432098e-05,
        "gradient_norm": 0.38611528277397156,
        "train_loss": 2.972146511077881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28645,
        "tokens": 15018229760,
        "learning_rate": 6.428263770656082e-05,
        "gradient_norm": 0.43739116191864014,
        "train_loss": 2.9879279136657715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28646,
        "tokens": 15018754048,
        "learning_rate": 6.427755736978079e-05,
        "gradient_norm": 0.4781949818134308,
        "train_loss": 3.1128101348876953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28647,
        "tokens": 15019278336,
        "learning_rate": 6.427248002403811e-05,
        "gradient_norm": 0.39109155535697937,
        "train_loss": 2.9863362312316895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28648,
        "tokens": 15019802624,
        "learning_rate": 6.426740566938987e-05,
        "gradient_norm": 0.44177138805389404,
        "train_loss": 2.9734463691711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28649,
        "tokens": 15020326912,
        "learning_rate": 6.426233430589326e-05,
        "gradient_norm": 0.46199917793273926,
        "train_loss": 3.043947219848633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28650,
        "tokens": 15020851200,
        "learning_rate": 6.425726593360529e-05,
        "gradient_norm": 0.44006264209747314,
        "train_loss": 2.988906145095825,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28651,
        "tokens": 15021375488,
        "learning_rate": 6.425220055258305e-05,
        "gradient_norm": 0.39417141675949097,
        "train_loss": 3.0049004554748535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28652,
        "tokens": 15021899776,
        "learning_rate": 6.424713816288358e-05,
        "gradient_norm": 0.47389861941337585,
        "train_loss": 3.009568452835083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28653,
        "tokens": 15022424064,
        "learning_rate": 6.42420787645638e-05,
        "gradient_norm": 0.4221481680870056,
        "train_loss": 3.0423531532287598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28654,
        "tokens": 15022948352,
        "learning_rate": 6.423702235768074e-05,
        "gradient_norm": 0.4430984556674957,
        "train_loss": 2.9703738689422607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28655,
        "tokens": 15023472640,
        "learning_rate": 6.423196894229127e-05,
        "gradient_norm": 0.45428481698036194,
        "train_loss": 3.0698695182800293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28656,
        "tokens": 15023996928,
        "learning_rate": 6.422691851845227e-05,
        "gradient_norm": 0.44288134574890137,
        "train_loss": 3.0091304779052734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28657,
        "tokens": 15024521216,
        "learning_rate": 6.422187108622058e-05,
        "gradient_norm": 0.4158629775047302,
        "train_loss": 3.036855936050415,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28658,
        "tokens": 15025045504,
        "learning_rate": 6.421682664565309e-05,
        "gradient_norm": 0.43266764283180237,
        "train_loss": 2.9945452213287354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28659,
        "tokens": 15025569792,
        "learning_rate": 6.421178519680646e-05,
        "gradient_norm": 0.39564669132232666,
        "train_loss": 3.035470485687256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28660,
        "tokens": 15026094080,
        "learning_rate": 6.420674673973754e-05,
        "gradient_norm": 0.40051424503326416,
        "train_loss": 2.994349479675293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28661,
        "tokens": 15026618368,
        "learning_rate": 6.420171127450298e-05,
        "gradient_norm": 0.39793866872787476,
        "train_loss": 2.9383792877197266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28662,
        "tokens": 15027142656,
        "learning_rate": 6.419667880115948e-05,
        "gradient_norm": 0.4122360348701477,
        "train_loss": 3.0343804359436035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28663,
        "tokens": 15027666944,
        "learning_rate": 6.419164931976372e-05,
        "gradient_norm": 0.4345816671848297,
        "train_loss": 2.985551357269287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28664,
        "tokens": 15028191232,
        "learning_rate": 6.418662283037226e-05,
        "gradient_norm": 0.4077065587043762,
        "train_loss": 2.9599838256835938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28665,
        "tokens": 15028715520,
        "learning_rate": 6.418159933304175e-05,
        "gradient_norm": 0.4118928015232086,
        "train_loss": 3.0254745483398438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28666,
        "tokens": 15029239808,
        "learning_rate": 6.417657882782866e-05,
        "gradient_norm": 0.457746684551239,
        "train_loss": 3.0421886444091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28667,
        "tokens": 15029764096,
        "learning_rate": 6.417156131478954e-05,
        "gradient_norm": 0.38844799995422363,
        "train_loss": 3.0423336029052734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28668,
        "tokens": 15030288384,
        "learning_rate": 6.416654679398083e-05,
        "gradient_norm": 0.43521299958229065,
        "train_loss": 2.9804224967956543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28669,
        "tokens": 15030812672,
        "learning_rate": 6.416153526545904e-05,
        "gradient_norm": 0.3993549048900604,
        "train_loss": 3.0681238174438477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28670,
        "tokens": 15031336960,
        "learning_rate": 6.415652672928054e-05,
        "gradient_norm": 0.4102093577384949,
        "train_loss": 2.9751715660095215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28671,
        "tokens": 15031861248,
        "learning_rate": 6.41515211855017e-05,
        "gradient_norm": 0.4002758264541626,
        "train_loss": 3.04939603805542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28672,
        "tokens": 15032385536,
        "learning_rate": 6.41465186341789e-05,
        "gradient_norm": 0.44131478667259216,
        "train_loss": 3.031132698059082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28673,
        "tokens": 15032909824,
        "learning_rate": 6.414151907536842e-05,
        "gradient_norm": 0.40209686756134033,
        "train_loss": 2.971097469329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28674,
        "tokens": 15033434112,
        "learning_rate": 6.413652250912655e-05,
        "gradient_norm": 0.38755378127098083,
        "train_loss": 3.0124993324279785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28675,
        "tokens": 15033958400,
        "learning_rate": 6.413152893550953e-05,
        "gradient_norm": 0.41991126537323,
        "train_loss": 3.0208940505981445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28676,
        "tokens": 15034482688,
        "learning_rate": 6.412653835457354e-05,
        "gradient_norm": 0.41759175062179565,
        "train_loss": 2.9372289180755615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28677,
        "tokens": 15035006976,
        "learning_rate": 6.412155076637479e-05,
        "gradient_norm": 0.41842353343963623,
        "train_loss": 2.9881725311279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28678,
        "tokens": 15035531264,
        "learning_rate": 6.411656617096942e-05,
        "gradient_norm": 0.46892085671424866,
        "train_loss": 3.047969341278076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28679,
        "tokens": 15036055552,
        "learning_rate": 6.411158456841354e-05,
        "gradient_norm": 0.4025450050830841,
        "train_loss": 3.0394649505615234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28680,
        "tokens": 15036579840,
        "learning_rate": 6.410660595876321e-05,
        "gradient_norm": 0.4101840555667877,
        "train_loss": 3.0769195556640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28681,
        "tokens": 15037104128,
        "learning_rate": 6.410163034207446e-05,
        "gradient_norm": 0.5821174383163452,
        "train_loss": 3.0406737327575684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28682,
        "tokens": 15037628416,
        "learning_rate": 6.40966577184033e-05,
        "gradient_norm": 0.5126891136169434,
        "train_loss": 3.0304160118103027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28683,
        "tokens": 15038152704,
        "learning_rate": 6.409168808780573e-05,
        "gradient_norm": 0.4673379361629486,
        "train_loss": 3.0282318592071533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28684,
        "tokens": 15038676992,
        "learning_rate": 6.408672145033769e-05,
        "gradient_norm": 0.4494434893131256,
        "train_loss": 3.0129494667053223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28685,
        "tokens": 15039201280,
        "learning_rate": 6.408175780605505e-05,
        "gradient_norm": 0.47881019115448,
        "train_loss": 2.948439598083496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28686,
        "tokens": 15039725568,
        "learning_rate": 6.40767971550137e-05,
        "gradient_norm": 0.5119693279266357,
        "train_loss": 2.986945629119873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28687,
        "tokens": 15040249856,
        "learning_rate": 6.40718394972695e-05,
        "gradient_norm": 0.45405715703964233,
        "train_loss": 3.0007357597351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28688,
        "tokens": 15040774144,
        "learning_rate": 6.406688483287822e-05,
        "gradient_norm": 0.5065478682518005,
        "train_loss": 2.9933547973632812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28689,
        "tokens": 15041298432,
        "learning_rate": 6.406193316189565e-05,
        "gradient_norm": 0.43648192286491394,
        "train_loss": 2.948282241821289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28690,
        "tokens": 15041822720,
        "learning_rate": 6.405698448437751e-05,
        "gradient_norm": 0.366908997297287,
        "train_loss": 3.0639514923095703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28691,
        "tokens": 15042347008,
        "learning_rate": 6.405203880037954e-05,
        "gradient_norm": 0.44158682227134705,
        "train_loss": 3.009108066558838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28692,
        "tokens": 15042871296,
        "learning_rate": 6.404709610995736e-05,
        "gradient_norm": 0.4220310151576996,
        "train_loss": 2.9985575675964355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28693,
        "tokens": 15043395584,
        "learning_rate": 6.404215641316666e-05,
        "gradient_norm": 0.41408073902130127,
        "train_loss": 3.051818370819092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28694,
        "tokens": 15043919872,
        "learning_rate": 6.403721971006299e-05,
        "gradient_norm": 0.4599914252758026,
        "train_loss": 2.9952232837677,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28695,
        "tokens": 15044444160,
        "learning_rate": 6.403228600070196e-05,
        "gradient_norm": 0.4120214283466339,
        "train_loss": 2.9582338333129883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28696,
        "tokens": 15044968448,
        "learning_rate": 6.402735528513908e-05,
        "gradient_norm": 0.4359014332294464,
        "train_loss": 3.0275208950042725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28697,
        "tokens": 15045492736,
        "learning_rate": 6.402242756342988e-05,
        "gradient_norm": 0.42089807987213135,
        "train_loss": 3.0117475986480713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28698,
        "tokens": 15046017024,
        "learning_rate": 6.401750283562979e-05,
        "gradient_norm": 0.4501558542251587,
        "train_loss": 3.04202938079834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28699,
        "tokens": 15046541312,
        "learning_rate": 6.401258110179426e-05,
        "gradient_norm": 0.5868268609046936,
        "train_loss": 3.1487717628479004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28700,
        "tokens": 15047065600,
        "learning_rate": 6.400766236197869e-05,
        "gradient_norm": 0.47576239705085754,
        "train_loss": 3.037966728210449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28701,
        "tokens": 15047589888,
        "learning_rate": 6.400274661623847e-05,
        "gradient_norm": 0.4852723777294159,
        "train_loss": 3.0323925018310547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28702,
        "tokens": 15048114176,
        "learning_rate": 6.399783386462887e-05,
        "gradient_norm": 0.5137326121330261,
        "train_loss": 3.0231709480285645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28703,
        "tokens": 15048638464,
        "learning_rate": 6.399292410720527e-05,
        "gradient_norm": 0.44244420528411865,
        "train_loss": 3.0140111446380615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28704,
        "tokens": 15049162752,
        "learning_rate": 6.398801734402288e-05,
        "gradient_norm": 0.4381870627403259,
        "train_loss": 3.0320162773132324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28705,
        "tokens": 15049687040,
        "learning_rate": 6.398311357513695e-05,
        "gradient_norm": 0.43708086013793945,
        "train_loss": 3.043337821960449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28706,
        "tokens": 15050211328,
        "learning_rate": 6.397821280060265e-05,
        "gradient_norm": 0.46147507429122925,
        "train_loss": 3.0429015159606934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28707,
        "tokens": 15050735616,
        "learning_rate": 6.397331502047519e-05,
        "gradient_norm": 0.40202489495277405,
        "train_loss": 3.03812837600708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28708,
        "tokens": 15051259904,
        "learning_rate": 6.396842023480969e-05,
        "gradient_norm": 0.3912425935268402,
        "train_loss": 2.9725167751312256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28709,
        "tokens": 15051784192,
        "learning_rate": 6.396352844366122e-05,
        "gradient_norm": 0.42342597246170044,
        "train_loss": 3.009397506713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28710,
        "tokens": 15052308480,
        "learning_rate": 6.395863964708488e-05,
        "gradient_norm": 0.44107165932655334,
        "train_loss": 3.0701403617858887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28711,
        "tokens": 15052832768,
        "learning_rate": 6.395375384513565e-05,
        "gradient_norm": 0.4502514898777008,
        "train_loss": 3.0146894454956055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28712,
        "tokens": 15053357056,
        "learning_rate": 6.394887103786859e-05,
        "gradient_norm": 0.42668086290359497,
        "train_loss": 3.020235300064087,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28713,
        "tokens": 15053881344,
        "learning_rate": 6.394399122533859e-05,
        "gradient_norm": 0.4235626459121704,
        "train_loss": 2.958306312561035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28714,
        "tokens": 15054405632,
        "learning_rate": 6.393911440760067e-05,
        "gradient_norm": 0.49118801951408386,
        "train_loss": 3.0776586532592773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28715,
        "tokens": 15054929920,
        "learning_rate": 6.393424058470964e-05,
        "gradient_norm": 0.4123191833496094,
        "train_loss": 2.9895145893096924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28716,
        "tokens": 15055454208,
        "learning_rate": 6.392936975672039e-05,
        "gradient_norm": 0.4147859215736389,
        "train_loss": 2.99869966506958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28717,
        "tokens": 15055978496,
        "learning_rate": 6.392450192368773e-05,
        "gradient_norm": 0.4700359106063843,
        "train_loss": 2.9746854305267334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28718,
        "tokens": 15056502784,
        "learning_rate": 6.391963708566651e-05,
        "gradient_norm": 0.4753342866897583,
        "train_loss": 3.0072240829467773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28719,
        "tokens": 15057027072,
        "learning_rate": 6.391477524271143e-05,
        "gradient_norm": 0.44084441661834717,
        "train_loss": 3.0534863471984863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28720,
        "tokens": 15057551360,
        "learning_rate": 6.390991639487726e-05,
        "gradient_norm": 0.4545353353023529,
        "train_loss": 3.0353920459747314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28721,
        "tokens": 15058075648,
        "learning_rate": 6.390506054221865e-05,
        "gradient_norm": 0.4168527126312256,
        "train_loss": 3.0082077980041504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28722,
        "tokens": 15058599936,
        "learning_rate": 6.390020768479027e-05,
        "gradient_norm": 0.4825742542743683,
        "train_loss": 3.0003974437713623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28723,
        "tokens": 15059124224,
        "learning_rate": 6.389535782264678e-05,
        "gradient_norm": 0.4383363425731659,
        "train_loss": 3.099654197692871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28724,
        "tokens": 15059648512,
        "learning_rate": 6.389051095584273e-05,
        "gradient_norm": 0.4038078784942627,
        "train_loss": 3.049576759338379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28725,
        "tokens": 15060172800,
        "learning_rate": 6.388566708443271e-05,
        "gradient_norm": 0.4402199387550354,
        "train_loss": 3.0503835678100586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28726,
        "tokens": 15060697088,
        "learning_rate": 6.38808262084712e-05,
        "gradient_norm": 0.42821696400642395,
        "train_loss": 3.004387855529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28727,
        "tokens": 15061221376,
        "learning_rate": 6.387598832801277e-05,
        "gradient_norm": 0.41545793414115906,
        "train_loss": 3.0389938354492188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28728,
        "tokens": 15061745664,
        "learning_rate": 6.387115344311176e-05,
        "gradient_norm": 0.4081592559814453,
        "train_loss": 3.043541669845581,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28729,
        "tokens": 15062269952,
        "learning_rate": 6.38663215538227e-05,
        "gradient_norm": 0.42501866817474365,
        "train_loss": 3.032505989074707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28730,
        "tokens": 15062794240,
        "learning_rate": 6.38614926601999e-05,
        "gradient_norm": 0.43089455366134644,
        "train_loss": 3.026843547821045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28731,
        "tokens": 15063318528,
        "learning_rate": 6.385666676229778e-05,
        "gradient_norm": 0.42550987005233765,
        "train_loss": 2.9957194328308105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28732,
        "tokens": 15063842816,
        "learning_rate": 6.385184386017062e-05,
        "gradient_norm": 0.4017775058746338,
        "train_loss": 3.0286166667938232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28733,
        "tokens": 15064367104,
        "learning_rate": 6.384702395387271e-05,
        "gradient_norm": 0.6514347791671753,
        "train_loss": 3.146329164505005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28734,
        "tokens": 15064891392,
        "learning_rate": 6.384220704345834e-05,
        "gradient_norm": 0.47414928674697876,
        "train_loss": 3.0357418060302734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28735,
        "tokens": 15065415680,
        "learning_rate": 6.383739312898167e-05,
        "gradient_norm": 0.4279158413410187,
        "train_loss": 3.012124538421631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28736,
        "tokens": 15065939968,
        "learning_rate": 6.383258221049696e-05,
        "gradient_norm": 0.4647851586341858,
        "train_loss": 3.028212785720825,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28737,
        "tokens": 15066464256,
        "learning_rate": 6.382777428805828e-05,
        "gradient_norm": 0.47589853405952454,
        "train_loss": 3.0476531982421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28738,
        "tokens": 15066988544,
        "learning_rate": 6.382296936171984e-05,
        "gradient_norm": 0.44297298789024353,
        "train_loss": 3.0296568870544434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28739,
        "tokens": 15067512832,
        "learning_rate": 6.381816743153565e-05,
        "gradient_norm": 0.4231075942516327,
        "train_loss": 3.033438205718994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28740,
        "tokens": 15068037120,
        "learning_rate": 6.381336849755981e-05,
        "gradient_norm": 0.470579594373703,
        "train_loss": 3.01204252243042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28741,
        "tokens": 15068561408,
        "learning_rate": 6.380857255984629e-05,
        "gradient_norm": 0.7629186511039734,
        "train_loss": 3.2567076683044434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28742,
        "tokens": 15069085696,
        "learning_rate": 6.38037796184491e-05,
        "gradient_norm": 0.4065723419189453,
        "train_loss": 3.0460920333862305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28743,
        "tokens": 15069609984,
        "learning_rate": 6.379898967342224e-05,
        "gradient_norm": 0.44586431980133057,
        "train_loss": 3.016786575317383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28744,
        "tokens": 15070134272,
        "learning_rate": 6.37942027248195e-05,
        "gradient_norm": 0.4617357552051544,
        "train_loss": 3.0020253658294678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28745,
        "tokens": 15070658560,
        "learning_rate": 6.37894187726949e-05,
        "gradient_norm": 0.46269363164901733,
        "train_loss": 3.0196175575256348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28746,
        "tokens": 15071182848,
        "learning_rate": 6.378463781710223e-05,
        "gradient_norm": 0.4720579981803894,
        "train_loss": 3.0632452964782715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28747,
        "tokens": 15071707136,
        "learning_rate": 6.37798598580953e-05,
        "gradient_norm": 0.4571981430053711,
        "train_loss": 3.0031397342681885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28748,
        "tokens": 15072231424,
        "learning_rate": 6.377508489572788e-05,
        "gradient_norm": 0.42247432470321655,
        "train_loss": 3.0291974544525146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28749,
        "tokens": 15072755712,
        "learning_rate": 6.377031293005378e-05,
        "gradient_norm": 0.42302069067955017,
        "train_loss": 2.992013454437256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28750,
        "tokens": 15073280000,
        "learning_rate": 6.376554396112665e-05,
        "gradient_norm": 0.42057013511657715,
        "train_loss": 3.0034096240997314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28751,
        "tokens": 15073804288,
        "learning_rate": 6.376077798900018e-05,
        "gradient_norm": 0.42738497257232666,
        "train_loss": 3.033442497253418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28752,
        "tokens": 15074328576,
        "learning_rate": 6.375601501372803e-05,
        "gradient_norm": 0.4627281129360199,
        "train_loss": 3.0465447902679443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28753,
        "tokens": 15074852864,
        "learning_rate": 6.375125503536383e-05,
        "gradient_norm": 0.4036159813404083,
        "train_loss": 2.9773292541503906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28754,
        "tokens": 15075377152,
        "learning_rate": 6.374649805396113e-05,
        "gradient_norm": 0.3937157094478607,
        "train_loss": 3.0425007343292236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28755,
        "tokens": 15075901440,
        "learning_rate": 6.374174406957348e-05,
        "gradient_norm": 0.4000786542892456,
        "train_loss": 2.9889369010925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28756,
        "tokens": 15076425728,
        "learning_rate": 6.373699308225445e-05,
        "gradient_norm": 0.43080613017082214,
        "train_loss": 3.0419600009918213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28757,
        "tokens": 15076950016,
        "learning_rate": 6.37322450920574e-05,
        "gradient_norm": 0.4150693416595459,
        "train_loss": 3.0499014854431152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28758,
        "tokens": 15077474304,
        "learning_rate": 6.372750009903591e-05,
        "gradient_norm": 0.4690706431865692,
        "train_loss": 2.979365348815918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28759,
        "tokens": 15077998592,
        "learning_rate": 6.372275810324325e-05,
        "gradient_norm": 0.4643577039241791,
        "train_loss": 2.987074851989746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28760,
        "tokens": 15078522880,
        "learning_rate": 6.371801910473292e-05,
        "gradient_norm": 0.42593124508857727,
        "train_loss": 2.9844844341278076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28761,
        "tokens": 15079047168,
        "learning_rate": 6.37132831035582e-05,
        "gradient_norm": 0.4317391514778137,
        "train_loss": 2.941075325012207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28762,
        "tokens": 15079571456,
        "learning_rate": 6.370855009977241e-05,
        "gradient_norm": 0.3983551561832428,
        "train_loss": 3.0635037422180176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28763,
        "tokens": 15080095744,
        "learning_rate": 6.370382009342886e-05,
        "gradient_norm": 0.3916373550891876,
        "train_loss": 2.9902124404907227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28764,
        "tokens": 15080620032,
        "learning_rate": 6.369909308458073e-05,
        "gradient_norm": 0.4149634838104248,
        "train_loss": 2.997070789337158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28765,
        "tokens": 15081144320,
        "learning_rate": 6.369436907328126e-05,
        "gradient_norm": 0.39393267035484314,
        "train_loss": 3.0238752365112305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28766,
        "tokens": 15081668608,
        "learning_rate": 6.368964805958362e-05,
        "gradient_norm": 0.4238921105861664,
        "train_loss": 3.0698461532592773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28767,
        "tokens": 15082192896,
        "learning_rate": 6.368493004354098e-05,
        "gradient_norm": 0.4986599087715149,
        "train_loss": 3.116716146469116,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28768,
        "tokens": 15082717184,
        "learning_rate": 6.368021502520641e-05,
        "gradient_norm": 0.42709848284721375,
        "train_loss": 3.0267586708068848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 28769,
        "tokens": 15083241472,
        "learning_rate": 6.367550300463301e-05,
        "gradient_norm": 0.4316890239715576,
        "train_loss": 3.1025590896606445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    }
]