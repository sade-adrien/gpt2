[
    {
        "step": 15161,
        "tokens": 7948730368,
        "learning_rate": 0.0003402956590745824,
        "gradient_norm": 0.3110346794128418,
        "train_loss": 3.1035428047180176,
        "val_loss": 3.0762484073638916,
        "hellaswag_acc": 0.28211510181427,
        "hellaswag_acc_norm": 0.2914758026599884
    },
    {
        "step": 15162,
        "tokens": 7949254656,
        "learning_rate": 0.00034026703407644354,
        "gradient_norm": 0.2909014821052551,
        "train_loss": 3.1569530963897705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15163,
        "tokens": 7949778944,
        "learning_rate": 0.0003402384089627363,
        "gradient_norm": 0.34018194675445557,
        "train_loss": 3.0922250747680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15164,
        "tokens": 7950303232,
        "learning_rate": 0.0003402097837337832,
        "gradient_norm": 0.2874945104122162,
        "train_loss": 3.0673532485961914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15165,
        "tokens": 7950827520,
        "learning_rate": 0.00034018115838990617,
        "gradient_norm": 0.3265642523765564,
        "train_loss": 3.091482162475586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15166,
        "tokens": 7951351808,
        "learning_rate": 0.00034015253293142754,
        "gradient_norm": 0.29979005455970764,
        "train_loss": 3.0680434703826904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15167,
        "tokens": 7951876096,
        "learning_rate": 0.00034012390735866944,
        "gradient_norm": 0.31561145186424255,
        "train_loss": 3.1043055057525635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15168,
        "tokens": 7952400384,
        "learning_rate": 0.0003400952816719542,
        "gradient_norm": 0.3011340796947479,
        "train_loss": 3.0944995880126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15169,
        "tokens": 7952924672,
        "learning_rate": 0.0003400666558716039,
        "gradient_norm": 0.35048907995224,
        "train_loss": 3.131399154663086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15170,
        "tokens": 7953448960,
        "learning_rate": 0.0003400380299579409,
        "gradient_norm": 0.2832714319229126,
        "train_loss": 3.055121898651123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15171,
        "tokens": 7953973248,
        "learning_rate": 0.00034000940393128735,
        "gradient_norm": 0.3440222442150116,
        "train_loss": 3.1610894203186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15172,
        "tokens": 7954497536,
        "learning_rate": 0.00033998077779196547,
        "gradient_norm": 0.33468854427337646,
        "train_loss": 3.1394407749176025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15173,
        "tokens": 7955021824,
        "learning_rate": 0.00033995215154029754,
        "gradient_norm": 0.30571305751800537,
        "train_loss": 3.1163296699523926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15174,
        "tokens": 7955546112,
        "learning_rate": 0.00033992352517660566,
        "gradient_norm": 0.3299710154533386,
        "train_loss": 3.112006187438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15175,
        "tokens": 7956070400,
        "learning_rate": 0.0003398948987012122,
        "gradient_norm": 0.326352596282959,
        "train_loss": 3.144115447998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15176,
        "tokens": 7956594688,
        "learning_rate": 0.0003398662721144393,
        "gradient_norm": 0.3261159062385559,
        "train_loss": 3.1343541145324707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15177,
        "tokens": 7957118976,
        "learning_rate": 0.0003398376454166092,
        "gradient_norm": 0.3404512107372284,
        "train_loss": 3.149381160736084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15178,
        "tokens": 7957643264,
        "learning_rate": 0.00033980901860804414,
        "gradient_norm": 0.3104759752750397,
        "train_loss": 3.1069934368133545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15179,
        "tokens": 7958167552,
        "learning_rate": 0.0003397803916890664,
        "gradient_norm": 0.32926425337791443,
        "train_loss": 3.098222255706787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15180,
        "tokens": 7958691840,
        "learning_rate": 0.00033975176465999814,
        "gradient_norm": 0.3044302761554718,
        "train_loss": 3.0948541164398193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15181,
        "tokens": 7959216128,
        "learning_rate": 0.0003397231375211616,
        "gradient_norm": 0.33117300271987915,
        "train_loss": 3.070394992828369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15182,
        "tokens": 7959740416,
        "learning_rate": 0.000339694510272879,
        "gradient_norm": 0.3334874212741852,
        "train_loss": 3.107058525085449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15183,
        "tokens": 7960264704,
        "learning_rate": 0.00033966588291547257,
        "gradient_norm": 0.4287455677986145,
        "train_loss": 3.1130595207214355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15184,
        "tokens": 7960788992,
        "learning_rate": 0.00033963725544926466,
        "gradient_norm": 0.4001893997192383,
        "train_loss": 3.150773048400879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15185,
        "tokens": 7961313280,
        "learning_rate": 0.00033960862787457745,
        "gradient_norm": 0.34821245074272156,
        "train_loss": 3.0699539184570312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15186,
        "tokens": 7961837568,
        "learning_rate": 0.00033958000019173305,
        "gradient_norm": 0.3372342884540558,
        "train_loss": 3.0965161323547363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15187,
        "tokens": 7962361856,
        "learning_rate": 0.0003395513724010539,
        "gradient_norm": 0.33588606119155884,
        "train_loss": 3.120948314666748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15188,
        "tokens": 7962886144,
        "learning_rate": 0.00033952274450286206,
        "gradient_norm": 0.361654132604599,
        "train_loss": 3.096360206604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15189,
        "tokens": 7963410432,
        "learning_rate": 0.00033949411649747993,
        "gradient_norm": 0.28444185853004456,
        "train_loss": 3.098893642425537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15190,
        "tokens": 7963934720,
        "learning_rate": 0.0003394654883852296,
        "gradient_norm": 0.3349205553531647,
        "train_loss": 3.1144533157348633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15191,
        "tokens": 7964459008,
        "learning_rate": 0.0003394368601664335,
        "gradient_norm": 0.2802223861217499,
        "train_loss": 3.1339855194091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15192,
        "tokens": 7964983296,
        "learning_rate": 0.00033940823184141366,
        "gradient_norm": 0.3366372287273407,
        "train_loss": 3.071369171142578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15193,
        "tokens": 7965507584,
        "learning_rate": 0.00033937960341049253,
        "gradient_norm": 0.31099000573158264,
        "train_loss": 3.066039800643921,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15194,
        "tokens": 7966031872,
        "learning_rate": 0.0003393509748739923,
        "gradient_norm": 0.3140978217124939,
        "train_loss": 3.1129915714263916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15195,
        "tokens": 7966556160,
        "learning_rate": 0.0003393223462322351,
        "gradient_norm": 0.2947978973388672,
        "train_loss": 3.082585096359253,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15196,
        "tokens": 7967080448,
        "learning_rate": 0.0003392937174855433,
        "gradient_norm": 0.2878948152065277,
        "train_loss": 3.1344730854034424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15197,
        "tokens": 7967604736,
        "learning_rate": 0.0003392650886342392,
        "gradient_norm": 0.3147738575935364,
        "train_loss": 3.1475300788879395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15198,
        "tokens": 7968129024,
        "learning_rate": 0.00033923645967864495,
        "gradient_norm": 0.27805447578430176,
        "train_loss": 3.122745990753174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15199,
        "tokens": 7968653312,
        "learning_rate": 0.0003392078306190828,
        "gradient_norm": 0.3050709664821625,
        "train_loss": 3.118532419204712,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15200,
        "tokens": 7969177600,
        "learning_rate": 0.00033917920145587504,
        "gradient_norm": 0.2843673527240753,
        "train_loss": 3.117520332336426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15201,
        "tokens": 7969701888,
        "learning_rate": 0.0003391505721893439,
        "gradient_norm": 0.2852212190628052,
        "train_loss": 3.0901174545288086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15202,
        "tokens": 7970226176,
        "learning_rate": 0.0003391219428198117,
        "gradient_norm": 0.3048762083053589,
        "train_loss": 3.1295523643493652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15203,
        "tokens": 7970750464,
        "learning_rate": 0.0003390933133476007,
        "gradient_norm": 0.2664462625980377,
        "train_loss": 3.1051502227783203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15204,
        "tokens": 7971274752,
        "learning_rate": 0.000339064683773033,
        "gradient_norm": 0.3152540922164917,
        "train_loss": 3.11899995803833,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15205,
        "tokens": 7971799040,
        "learning_rate": 0.00033903605409643114,
        "gradient_norm": 0.28705403208732605,
        "train_loss": 3.09102201461792,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15206,
        "tokens": 7972323328,
        "learning_rate": 0.00033900742431811716,
        "gradient_norm": 0.31139451265335083,
        "train_loss": 3.196937084197998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15207,
        "tokens": 7972847616,
        "learning_rate": 0.00033897879443841336,
        "gradient_norm": 0.28720369935035706,
        "train_loss": 3.0721888542175293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15208,
        "tokens": 7973371904,
        "learning_rate": 0.00033895016445764203,
        "gradient_norm": 0.31911081075668335,
        "train_loss": 3.2080817222595215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15209,
        "tokens": 7973896192,
        "learning_rate": 0.0003389215343761255,
        "gradient_norm": 0.3952793776988983,
        "train_loss": 3.068985939025879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15210,
        "tokens": 7974420480,
        "learning_rate": 0.0003388929041941859,
        "gradient_norm": 0.3516595661640167,
        "train_loss": 3.104827404022217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15211,
        "tokens": 7974944768,
        "learning_rate": 0.00033886427391214565,
        "gradient_norm": 0.3345606327056885,
        "train_loss": 3.0730230808258057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15212,
        "tokens": 7975469056,
        "learning_rate": 0.0003388356435303269,
        "gradient_norm": 0.35178834199905396,
        "train_loss": 3.115382671356201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15213,
        "tokens": 7975993344,
        "learning_rate": 0.000338807013049052,
        "gradient_norm": 0.33738720417022705,
        "train_loss": 3.1277313232421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15214,
        "tokens": 7976517632,
        "learning_rate": 0.00033877838246864316,
        "gradient_norm": 0.3007920980453491,
        "train_loss": 3.114168405532837,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15215,
        "tokens": 7977041920,
        "learning_rate": 0.00033874975178942277,
        "gradient_norm": 0.31693634390830994,
        "train_loss": 3.1488654613494873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15216,
        "tokens": 7977566208,
        "learning_rate": 0.00033872112101171296,
        "gradient_norm": 0.2988033592700958,
        "train_loss": 3.0939829349517822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15217,
        "tokens": 7978090496,
        "learning_rate": 0.000338692490135836,
        "gradient_norm": 0.28582045435905457,
        "train_loss": 3.099405288696289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15218,
        "tokens": 7978614784,
        "learning_rate": 0.0003386638591621143,
        "gradient_norm": 0.32253000140190125,
        "train_loss": 3.070401906967163,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15219,
        "tokens": 7979139072,
        "learning_rate": 0.00033863522809087003,
        "gradient_norm": 0.3041906952857971,
        "train_loss": 3.087494373321533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15220,
        "tokens": 7979663360,
        "learning_rate": 0.0003386065969224256,
        "gradient_norm": 0.3147096037864685,
        "train_loss": 3.1272659301757812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15221,
        "tokens": 7980187648,
        "learning_rate": 0.0003385779656571031,
        "gradient_norm": 0.3175480365753174,
        "train_loss": 3.137331008911133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15222,
        "tokens": 7980711936,
        "learning_rate": 0.00033854933429522486,
        "gradient_norm": 0.373291015625,
        "train_loss": 3.2514874935150146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15223,
        "tokens": 7981236224,
        "learning_rate": 0.00033852070283711325,
        "gradient_norm": 0.38828980922698975,
        "train_loss": 3.069075107574463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15224,
        "tokens": 7981760512,
        "learning_rate": 0.00033849207128309057,
        "gradient_norm": 0.32933714985847473,
        "train_loss": 3.116710901260376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15225,
        "tokens": 7982284800,
        "learning_rate": 0.000338463439633479,
        "gradient_norm": 0.33212095499038696,
        "train_loss": 3.116513252258301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15226,
        "tokens": 7982809088,
        "learning_rate": 0.00033843480788860083,
        "gradient_norm": 0.33917608857154846,
        "train_loss": 3.100954294204712,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15227,
        "tokens": 7983333376,
        "learning_rate": 0.00033840617604877845,
        "gradient_norm": 0.3658008873462677,
        "train_loss": 3.1171116828918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15228,
        "tokens": 7983857664,
        "learning_rate": 0.000338377544114334,
        "gradient_norm": 0.35066068172454834,
        "train_loss": 3.11881160736084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15229,
        "tokens": 7984381952,
        "learning_rate": 0.0003383489120855899,
        "gradient_norm": 0.3623082935810089,
        "train_loss": 3.0815672874450684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15230,
        "tokens": 7984906240,
        "learning_rate": 0.00033832027996286845,
        "gradient_norm": 0.37446993589401245,
        "train_loss": 3.104987382888794,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15231,
        "tokens": 7985430528,
        "learning_rate": 0.0003382916477464918,
        "gradient_norm": 0.3493821918964386,
        "train_loss": 3.1252827644348145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15232,
        "tokens": 7985954816,
        "learning_rate": 0.00033826301543678233,
        "gradient_norm": 0.3478783667087555,
        "train_loss": 3.081676721572876,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15233,
        "tokens": 7986479104,
        "learning_rate": 0.00033823438303406234,
        "gradient_norm": 0.3165680170059204,
        "train_loss": 3.0503740310668945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15234,
        "tokens": 7987003392,
        "learning_rate": 0.000338205750538654,
        "gradient_norm": 0.3634053170681,
        "train_loss": 3.0515518188476562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15235,
        "tokens": 7987527680,
        "learning_rate": 0.00033817711795087986,
        "gradient_norm": 0.29312703013420105,
        "train_loss": 3.126894474029541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15236,
        "tokens": 7988051968,
        "learning_rate": 0.000338148485271062,
        "gradient_norm": 0.34316137433052063,
        "train_loss": 3.103531837463379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15237,
        "tokens": 7988576256,
        "learning_rate": 0.00033811985249952275,
        "gradient_norm": 0.306233674287796,
        "train_loss": 3.0814199447631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15238,
        "tokens": 7989100544,
        "learning_rate": 0.00033809121963658447,
        "gradient_norm": 0.30150920152664185,
        "train_loss": 3.1254403591156006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15239,
        "tokens": 7989624832,
        "learning_rate": 0.00033806258668256947,
        "gradient_norm": 0.30802199244499207,
        "train_loss": 3.108011484146118,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15240,
        "tokens": 7990149120,
        "learning_rate": 0.0003380339536377999,
        "gradient_norm": 0.29055607318878174,
        "train_loss": 3.1988537311553955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15241,
        "tokens": 7990673408,
        "learning_rate": 0.00033800532050259826,
        "gradient_norm": 0.3522915244102478,
        "train_loss": 3.0952792167663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15242,
        "tokens": 7991197696,
        "learning_rate": 0.0003379766872772867,
        "gradient_norm": 0.26961055397987366,
        "train_loss": 3.103100299835205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15243,
        "tokens": 7991721984,
        "learning_rate": 0.0003379480539621876,
        "gradient_norm": 0.3242338001728058,
        "train_loss": 3.088655471801758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15244,
        "tokens": 7992246272,
        "learning_rate": 0.00033791942055762323,
        "gradient_norm": 0.2832890748977661,
        "train_loss": 3.1030380725860596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15245,
        "tokens": 7992770560,
        "learning_rate": 0.000337890787063916,
        "gradient_norm": 0.341307133436203,
        "train_loss": 3.158036947250366,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15246,
        "tokens": 7993294848,
        "learning_rate": 0.000337862153481388,
        "gradient_norm": 0.2877214550971985,
        "train_loss": 3.09248423576355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15247,
        "tokens": 7993819136,
        "learning_rate": 0.00033783351981036175,
        "gradient_norm": 0.31753987073898315,
        "train_loss": 3.094825267791748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15248,
        "tokens": 7994343424,
        "learning_rate": 0.00033780488605115945,
        "gradient_norm": 0.3224203884601593,
        "train_loss": 3.112107515335083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15249,
        "tokens": 7994867712,
        "learning_rate": 0.0003377762522041034,
        "gradient_norm": 0.3221660554409027,
        "train_loss": 3.1365156173706055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15250,
        "tokens": 7995392000,
        "learning_rate": 0.000337747618269516,
        "gradient_norm": 0.30903348326683044,
        "train_loss": 3.1474714279174805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15251,
        "tokens": 7995916288,
        "learning_rate": 0.0003377189842477195,
        "gradient_norm": 0.31614255905151367,
        "train_loss": 3.1161279678344727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15252,
        "tokens": 7996440576,
        "learning_rate": 0.00033769035013903607,
        "gradient_norm": 0.3199191093444824,
        "train_loss": 3.112692356109619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15253,
        "tokens": 7996964864,
        "learning_rate": 0.00033766171594378825,
        "gradient_norm": 0.33540618419647217,
        "train_loss": 3.0675296783447266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15254,
        "tokens": 7997489152,
        "learning_rate": 0.00033763308166229823,
        "gradient_norm": 0.3695123791694641,
        "train_loss": 3.155179262161255,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15255,
        "tokens": 7998013440,
        "learning_rate": 0.00033760444729488844,
        "gradient_norm": 0.33070653676986694,
        "train_loss": 3.0804905891418457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15256,
        "tokens": 7998537728,
        "learning_rate": 0.0003375758128418811,
        "gradient_norm": 0.33281904458999634,
        "train_loss": 3.1053318977355957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15257,
        "tokens": 7999062016,
        "learning_rate": 0.00033754717830359856,
        "gradient_norm": 0.29169830679893494,
        "train_loss": 3.1085309982299805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15258,
        "tokens": 7999586304,
        "learning_rate": 0.0003375185436803631,
        "gradient_norm": 0.3432205319404602,
        "train_loss": 3.0796642303466797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15259,
        "tokens": 8000110592,
        "learning_rate": 0.000337489908972497,
        "gradient_norm": 0.3459024131298065,
        "train_loss": 3.110657215118408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15260,
        "tokens": 8000634880,
        "learning_rate": 0.0003374612741803227,
        "gradient_norm": 0.30037638545036316,
        "train_loss": 3.1416759490966797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15261,
        "tokens": 8001159168,
        "learning_rate": 0.00033743263930416243,
        "gradient_norm": 0.33537963032722473,
        "train_loss": 3.1223602294921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15262,
        "tokens": 8001683456,
        "learning_rate": 0.0003374040043443385,
        "gradient_norm": 0.2793135941028595,
        "train_loss": 3.1291985511779785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15263,
        "tokens": 8002207744,
        "learning_rate": 0.00033737536930117336,
        "gradient_norm": 0.31136980652809143,
        "train_loss": 3.044055461883545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15264,
        "tokens": 8002732032,
        "learning_rate": 0.00033734673417498923,
        "gradient_norm": 0.28739383816719055,
        "train_loss": 3.1276822090148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15265,
        "tokens": 8003256320,
        "learning_rate": 0.0003373180989661084,
        "gradient_norm": 0.2814570963382721,
        "train_loss": 3.0939674377441406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15266,
        "tokens": 8003780608,
        "learning_rate": 0.0003372894636748533,
        "gradient_norm": 0.3109213411808014,
        "train_loss": 3.057419776916504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15267,
        "tokens": 8004304896,
        "learning_rate": 0.00033726082830154615,
        "gradient_norm": 0.29987624287605286,
        "train_loss": 3.053061008453369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15268,
        "tokens": 8004829184,
        "learning_rate": 0.0003372321928465093,
        "gradient_norm": 0.28796663880348206,
        "train_loss": 3.118617534637451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15269,
        "tokens": 8005353472,
        "learning_rate": 0.0003372035573100652,
        "gradient_norm": 0.3207767903804779,
        "train_loss": 3.1493172645568848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15270,
        "tokens": 8005877760,
        "learning_rate": 0.000337174921692536,
        "gradient_norm": 0.2955422103404999,
        "train_loss": 3.0234580039978027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15271,
        "tokens": 8006402048,
        "learning_rate": 0.00033714628599424416,
        "gradient_norm": 0.3417680859565735,
        "train_loss": 3.11545467376709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15272,
        "tokens": 8006926336,
        "learning_rate": 0.0003371176502155119,
        "gradient_norm": 0.29900476336479187,
        "train_loss": 3.110264301300049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15273,
        "tokens": 8007450624,
        "learning_rate": 0.00033708901435666164,
        "gradient_norm": 0.3086017370223999,
        "train_loss": 3.1005940437316895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15274,
        "tokens": 8007974912,
        "learning_rate": 0.00033706037841801576,
        "gradient_norm": 0.2868609130382538,
        "train_loss": 3.099766254425049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15275,
        "tokens": 8008499200,
        "learning_rate": 0.00033703174239989645,
        "gradient_norm": 0.3238776922225952,
        "train_loss": 3.068035125732422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15276,
        "tokens": 8009023488,
        "learning_rate": 0.00033700310630262615,
        "gradient_norm": 0.2840365767478943,
        "train_loss": 3.123286247253418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15277,
        "tokens": 8009547776,
        "learning_rate": 0.00033697447012652715,
        "gradient_norm": 0.34841054677963257,
        "train_loss": 3.059152126312256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15278,
        "tokens": 8010072064,
        "learning_rate": 0.0003369458338719218,
        "gradient_norm": 0.27476176619529724,
        "train_loss": 3.079746961593628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15279,
        "tokens": 8010596352,
        "learning_rate": 0.0003369171975391324,
        "gradient_norm": 0.30653443932533264,
        "train_loss": 3.145379066467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15280,
        "tokens": 8011120640,
        "learning_rate": 0.0003368885611284814,
        "gradient_norm": 0.2850874662399292,
        "train_loss": 3.046753406524658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15281,
        "tokens": 8011644928,
        "learning_rate": 0.000336859924640291,
        "gradient_norm": 0.2912698984146118,
        "train_loss": 3.093550682067871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15282,
        "tokens": 8012169216,
        "learning_rate": 0.00033683128807488356,
        "gradient_norm": 0.312220960855484,
        "train_loss": 3.061800956726074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15283,
        "tokens": 8012693504,
        "learning_rate": 0.0003368026514325815,
        "gradient_norm": 0.31181710958480835,
        "train_loss": 3.1416664123535156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15284,
        "tokens": 8013217792,
        "learning_rate": 0.0003367740147137071,
        "gradient_norm": 0.32527807354927063,
        "train_loss": 3.121856451034546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15285,
        "tokens": 8013742080,
        "learning_rate": 0.00033674537791858277,
        "gradient_norm": 0.3277167081832886,
        "train_loss": 3.084266185760498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15286,
        "tokens": 8014266368,
        "learning_rate": 0.0003367167410475307,
        "gradient_norm": 0.3216552138328552,
        "train_loss": 3.112255096435547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15287,
        "tokens": 8014790656,
        "learning_rate": 0.00033668810410087346,
        "gradient_norm": 0.34314849972724915,
        "train_loss": 3.0832622051239014,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15288,
        "tokens": 8015314944,
        "learning_rate": 0.00033665946707893326,
        "gradient_norm": 0.34432798624038696,
        "train_loss": 3.085200786590576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15289,
        "tokens": 8015839232,
        "learning_rate": 0.00033663082998203236,
        "gradient_norm": 0.31896039843559265,
        "train_loss": 3.1067862510681152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15290,
        "tokens": 8016363520,
        "learning_rate": 0.00033660219281049324,
        "gradient_norm": 0.3579792082309723,
        "train_loss": 3.0841846466064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15291,
        "tokens": 8016887808,
        "learning_rate": 0.00033657355556463824,
        "gradient_norm": 0.3164311647415161,
        "train_loss": 3.0538480281829834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15292,
        "tokens": 8017412096,
        "learning_rate": 0.0003365449182447896,
        "gradient_norm": 0.32711780071258545,
        "train_loss": 3.1241402626037598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15293,
        "tokens": 8017936384,
        "learning_rate": 0.00033651628085126984,
        "gradient_norm": 0.32245975732803345,
        "train_loss": 3.072375535964966,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15294,
        "tokens": 8018460672,
        "learning_rate": 0.0003364876433844012,
        "gradient_norm": 0.32177361845970154,
        "train_loss": 3.1318697929382324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15295,
        "tokens": 8018984960,
        "learning_rate": 0.000336459005844506,
        "gradient_norm": 0.3193958103656769,
        "train_loss": 3.0307445526123047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15296,
        "tokens": 8019509248,
        "learning_rate": 0.00033643036823190664,
        "gradient_norm": 0.31787219643592834,
        "train_loss": 3.0960423946380615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15297,
        "tokens": 8020033536,
        "learning_rate": 0.00033640173054692553,
        "gradient_norm": 0.29434871673583984,
        "train_loss": 3.1426849365234375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15298,
        "tokens": 8020557824,
        "learning_rate": 0.00033637309278988493,
        "gradient_norm": 0.32953011989593506,
        "train_loss": 3.064774513244629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15299,
        "tokens": 8021082112,
        "learning_rate": 0.00033634445496110723,
        "gradient_norm": 0.28732970356941223,
        "train_loss": 3.1082522869110107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15300,
        "tokens": 8021606400,
        "learning_rate": 0.0003363158170609148,
        "gradient_norm": 0.2997782528400421,
        "train_loss": 3.1007626056671143,
        "val_loss": 3.0726609230041504,
        "hellaswag_acc": 0.2803226709365845,
        "hellaswag_acc_norm": 0.29107749462127686
    },
    {
        "step": 15301,
        "tokens": 8022130688,
        "learning_rate": 0.00033628717908962995,
        "gradient_norm": 0.2955686151981354,
        "train_loss": 3.133575439453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15302,
        "tokens": 8022654976,
        "learning_rate": 0.000336258541047575,
        "gradient_norm": 0.30512893199920654,
        "train_loss": 3.10494327545166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15303,
        "tokens": 8023179264,
        "learning_rate": 0.0003362299029350724,
        "gradient_norm": 0.2931418716907501,
        "train_loss": 3.0881662368774414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15304,
        "tokens": 8023703552,
        "learning_rate": 0.0003362012647524445,
        "gradient_norm": 0.2873494327068329,
        "train_loss": 3.1273789405822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15305,
        "tokens": 8024227840,
        "learning_rate": 0.0003361726265000137,
        "gradient_norm": 0.2932302951812744,
        "train_loss": 3.0882158279418945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15306,
        "tokens": 8024752128,
        "learning_rate": 0.00033614398817810224,
        "gradient_norm": 0.3266833424568176,
        "train_loss": 3.1584746837615967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15307,
        "tokens": 8025276416,
        "learning_rate": 0.00033611534978703257,
        "gradient_norm": 0.327010840177536,
        "train_loss": 3.196382522583008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15308,
        "tokens": 8025800704,
        "learning_rate": 0.00033608671132712696,
        "gradient_norm": 0.2897050380706787,
        "train_loss": 3.149207353591919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15309,
        "tokens": 8026324992,
        "learning_rate": 0.00033605807279870784,
        "gradient_norm": 0.34079569578170776,
        "train_loss": 3.1511757373809814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15310,
        "tokens": 8026849280,
        "learning_rate": 0.00033602943420209757,
        "gradient_norm": 0.3100281059741974,
        "train_loss": 3.093733549118042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15311,
        "tokens": 8027373568,
        "learning_rate": 0.0003360007955376185,
        "gradient_norm": 0.3202269375324249,
        "train_loss": 3.1075868606567383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15312,
        "tokens": 8027897856,
        "learning_rate": 0.00033597215680559295,
        "gradient_norm": 0.348984032869339,
        "train_loss": 3.07295823097229,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15313,
        "tokens": 8028422144,
        "learning_rate": 0.0003359435180063434,
        "gradient_norm": 0.3072529137134552,
        "train_loss": 3.12312912940979,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15314,
        "tokens": 8028946432,
        "learning_rate": 0.0003359148791401921,
        "gradient_norm": 0.34093451499938965,
        "train_loss": 3.096714735031128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15315,
        "tokens": 8029470720,
        "learning_rate": 0.0003358862402074615,
        "gradient_norm": 0.30532586574554443,
        "train_loss": 3.124948740005493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15316,
        "tokens": 8029995008,
        "learning_rate": 0.0003358576012084739,
        "gradient_norm": 0.3342145085334778,
        "train_loss": 3.134481906890869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15317,
        "tokens": 8030519296,
        "learning_rate": 0.0003358289621435517,
        "gradient_norm": 0.316863089799881,
        "train_loss": 3.1367921829223633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15318,
        "tokens": 8031043584,
        "learning_rate": 0.0003358003230130173,
        "gradient_norm": 0.32165029644966125,
        "train_loss": 3.1003808975219727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15319,
        "tokens": 8031567872,
        "learning_rate": 0.00033577168381719304,
        "gradient_norm": 0.31696775555610657,
        "train_loss": 3.046598434448242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15320,
        "tokens": 8032092160,
        "learning_rate": 0.0003357430445564012,
        "gradient_norm": 0.2918691039085388,
        "train_loss": 3.1483209133148193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15321,
        "tokens": 8032616448,
        "learning_rate": 0.0003357144052309643,
        "gradient_norm": 0.3047002851963043,
        "train_loss": 3.0909423828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15322,
        "tokens": 8033140736,
        "learning_rate": 0.0003356857658412046,
        "gradient_norm": 0.2885085642337799,
        "train_loss": 3.0997865200042725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15323,
        "tokens": 8033665024,
        "learning_rate": 0.0003356571263874445,
        "gradient_norm": 0.2886572480201721,
        "train_loss": 3.0651297569274902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15324,
        "tokens": 8034189312,
        "learning_rate": 0.0003356284868700065,
        "gradient_norm": 0.3274001479148865,
        "train_loss": 3.1465811729431152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15325,
        "tokens": 8034713600,
        "learning_rate": 0.00033559984728921276,
        "gradient_norm": 0.26054564118385315,
        "train_loss": 3.0373239517211914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15326,
        "tokens": 8035237888,
        "learning_rate": 0.0003355712076453858,
        "gradient_norm": 0.32095545530319214,
        "train_loss": 3.1098031997680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15327,
        "tokens": 8035762176,
        "learning_rate": 0.000335542567938848,
        "gradient_norm": 0.27204471826553345,
        "train_loss": 3.1523258686065674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15328,
        "tokens": 8036286464,
        "learning_rate": 0.0003355139281699217,
        "gradient_norm": 0.2979492247104645,
        "train_loss": 3.067934989929199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15329,
        "tokens": 8036810752,
        "learning_rate": 0.0003354852883389292,
        "gradient_norm": 0.2997676134109497,
        "train_loss": 3.1249806880950928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15330,
        "tokens": 8037335040,
        "learning_rate": 0.00033545664844619294,
        "gradient_norm": 0.30614370107650757,
        "train_loss": 3.109137535095215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15331,
        "tokens": 8037859328,
        "learning_rate": 0.0003354280084920353,
        "gradient_norm": 0.29206016659736633,
        "train_loss": 3.097015857696533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15332,
        "tokens": 8038383616,
        "learning_rate": 0.0003353993684767786,
        "gradient_norm": 0.29885542392730713,
        "train_loss": 3.1297693252563477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15333,
        "tokens": 8038907904,
        "learning_rate": 0.0003353707284007454,
        "gradient_norm": 0.2843479514122009,
        "train_loss": 3.1108694076538086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15334,
        "tokens": 8039432192,
        "learning_rate": 0.0003353420882642579,
        "gradient_norm": 0.326196551322937,
        "train_loss": 3.169424533843994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15335,
        "tokens": 8039956480,
        "learning_rate": 0.00033531344806763855,
        "gradient_norm": 0.2880862355232239,
        "train_loss": 3.111417293548584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15336,
        "tokens": 8040480768,
        "learning_rate": 0.00033528480781120967,
        "gradient_norm": 0.3074468672275543,
        "train_loss": 3.1319453716278076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15337,
        "tokens": 8041005056,
        "learning_rate": 0.00033525616749529376,
        "gradient_norm": 0.29018858075141907,
        "train_loss": 3.0255160331726074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15338,
        "tokens": 8041529344,
        "learning_rate": 0.0003352275271202131,
        "gradient_norm": 0.32247379422187805,
        "train_loss": 3.0604286193847656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15339,
        "tokens": 8042053632,
        "learning_rate": 0.0003351988866862901,
        "gradient_norm": 0.28676638007164,
        "train_loss": 3.0946407318115234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15340,
        "tokens": 8042577920,
        "learning_rate": 0.0003351702461938472,
        "gradient_norm": 0.326343297958374,
        "train_loss": 3.1223597526550293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15341,
        "tokens": 8043102208,
        "learning_rate": 0.0003351416056432067,
        "gradient_norm": 0.3151206374168396,
        "train_loss": 3.1009488105773926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15342,
        "tokens": 8043626496,
        "learning_rate": 0.000335112965034691,
        "gradient_norm": 0.3101927638053894,
        "train_loss": 3.1490349769592285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15343,
        "tokens": 8044150784,
        "learning_rate": 0.0003350843243686225,
        "gradient_norm": 0.3221699297428131,
        "train_loss": 3.084890604019165,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15344,
        "tokens": 8044675072,
        "learning_rate": 0.00033505568364532363,
        "gradient_norm": 0.33238235116004944,
        "train_loss": 3.066035032272339,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15345,
        "tokens": 8045199360,
        "learning_rate": 0.00033502704286511673,
        "gradient_norm": 0.3080245554447174,
        "train_loss": 3.0479650497436523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15346,
        "tokens": 8045723648,
        "learning_rate": 0.00033499840202832424,
        "gradient_norm": 0.3130560517311096,
        "train_loss": 3.1099236011505127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15347,
        "tokens": 8046247936,
        "learning_rate": 0.00033496976113526843,
        "gradient_norm": 0.3332047164440155,
        "train_loss": 3.0774693489074707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15348,
        "tokens": 8046772224,
        "learning_rate": 0.00033494112018627175,
        "gradient_norm": 0.2979264557361603,
        "train_loss": 3.1357617378234863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15349,
        "tokens": 8047296512,
        "learning_rate": 0.0003349124791816567,
        "gradient_norm": 0.3520645201206207,
        "train_loss": 3.0975942611694336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15350,
        "tokens": 8047820800,
        "learning_rate": 0.00033488383812174547,
        "gradient_norm": 0.30045244097709656,
        "train_loss": 3.1174120903015137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15351,
        "tokens": 8048345088,
        "learning_rate": 0.00033485519700686054,
        "gradient_norm": 0.3342539370059967,
        "train_loss": 3.1513161659240723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15352,
        "tokens": 8048869376,
        "learning_rate": 0.0003348265558373244,
        "gradient_norm": 0.3092212677001953,
        "train_loss": 3.1102943420410156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15353,
        "tokens": 8049393664,
        "learning_rate": 0.0003347979146134593,
        "gradient_norm": 0.3340755105018616,
        "train_loss": 3.150115728378296,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15354,
        "tokens": 8049917952,
        "learning_rate": 0.00033476927333558773,
        "gradient_norm": 0.3381889760494232,
        "train_loss": 3.1195743083953857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15355,
        "tokens": 8050442240,
        "learning_rate": 0.00033474063200403205,
        "gradient_norm": 0.3198096454143524,
        "train_loss": 3.106678009033203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15356,
        "tokens": 8050966528,
        "learning_rate": 0.00033471199061911464,
        "gradient_norm": 0.3660908341407776,
        "train_loss": 3.1676788330078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15357,
        "tokens": 8051490816,
        "learning_rate": 0.00033468334918115785,
        "gradient_norm": 0.32504549622535706,
        "train_loss": 3.0657565593719482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15358,
        "tokens": 8052015104,
        "learning_rate": 0.0003346547076904842,
        "gradient_norm": 0.3221770226955414,
        "train_loss": 3.1921041011810303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15359,
        "tokens": 8052539392,
        "learning_rate": 0.0003346260661474159,
        "gradient_norm": 0.3271856904029846,
        "train_loss": 3.0879077911376953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15360,
        "tokens": 8053063680,
        "learning_rate": 0.0003345974245522756,
        "gradient_norm": 0.28952184319496155,
        "train_loss": 3.089679718017578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15361,
        "tokens": 8053587968,
        "learning_rate": 0.00033456878290538547,
        "gradient_norm": 0.328722208738327,
        "train_loss": 3.045994758605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15362,
        "tokens": 8054112256,
        "learning_rate": 0.000334540141207068,
        "gradient_norm": 0.27053725719451904,
        "train_loss": 3.116231918334961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15363,
        "tokens": 8054636544,
        "learning_rate": 0.0003345114994576456,
        "gradient_norm": 0.3224177360534668,
        "train_loss": 3.145197629928589,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15364,
        "tokens": 8055160832,
        "learning_rate": 0.00033448285765744066,
        "gradient_norm": 0.2881374955177307,
        "train_loss": 3.120539665222168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15365,
        "tokens": 8055685120,
        "learning_rate": 0.0003344542158067756,
        "gradient_norm": 0.34269583225250244,
        "train_loss": 3.154329299926758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15366,
        "tokens": 8056209408,
        "learning_rate": 0.0003344255739059727,
        "gradient_norm": 0.315600723028183,
        "train_loss": 3.1167516708374023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15367,
        "tokens": 8056733696,
        "learning_rate": 0.0003343969319553545,
        "gradient_norm": 0.32340940833091736,
        "train_loss": 3.095461368560791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15368,
        "tokens": 8057257984,
        "learning_rate": 0.0003343682899552434,
        "gradient_norm": 0.3231428861618042,
        "train_loss": 3.1031746864318848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15369,
        "tokens": 8057782272,
        "learning_rate": 0.00033433964790596164,
        "gradient_norm": 0.32083913683891296,
        "train_loss": 3.0897345542907715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15370,
        "tokens": 8058306560,
        "learning_rate": 0.00033431100580783176,
        "gradient_norm": 0.32037121057510376,
        "train_loss": 3.031569480895996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15371,
        "tokens": 8058830848,
        "learning_rate": 0.0003342823636611762,
        "gradient_norm": 0.3348386287689209,
        "train_loss": 3.118269443511963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15372,
        "tokens": 8059355136,
        "learning_rate": 0.00033425372146631726,
        "gradient_norm": 0.2936163544654846,
        "train_loss": 3.0629217624664307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15373,
        "tokens": 8059879424,
        "learning_rate": 0.00033422507922357736,
        "gradient_norm": 0.28677231073379517,
        "train_loss": 3.0596160888671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15374,
        "tokens": 8060403712,
        "learning_rate": 0.00033419643693327893,
        "gradient_norm": 0.2930864691734314,
        "train_loss": 3.1069984436035156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15375,
        "tokens": 8060928000,
        "learning_rate": 0.0003341677945957444,
        "gradient_norm": 0.31217122077941895,
        "train_loss": 3.155494213104248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15376,
        "tokens": 8061452288,
        "learning_rate": 0.0003341391522112962,
        "gradient_norm": 0.2851426899433136,
        "train_loss": 3.093757152557373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15377,
        "tokens": 8061976576,
        "learning_rate": 0.00033411050978025657,
        "gradient_norm": 0.339895635843277,
        "train_loss": 3.110877513885498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15378,
        "tokens": 8062500864,
        "learning_rate": 0.0003340818673029481,
        "gradient_norm": 0.3106703460216522,
        "train_loss": 3.0594234466552734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15379,
        "tokens": 8063025152,
        "learning_rate": 0.00033405322477969313,
        "gradient_norm": 0.34054896235466003,
        "train_loss": 3.121201515197754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15380,
        "tokens": 8063549440,
        "learning_rate": 0.00033402458221081405,
        "gradient_norm": 0.30852341651916504,
        "train_loss": 3.1296582221984863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15381,
        "tokens": 8064073728,
        "learning_rate": 0.0003339959395966332,
        "gradient_norm": 0.3275374472141266,
        "train_loss": 3.1225051879882812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15382,
        "tokens": 8064598016,
        "learning_rate": 0.00033396729693747315,
        "gradient_norm": 0.28539177775382996,
        "train_loss": 3.0951104164123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15383,
        "tokens": 8065122304,
        "learning_rate": 0.0003339386542336563,
        "gradient_norm": 0.3290731608867645,
        "train_loss": 3.085585117340088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15384,
        "tokens": 8065646592,
        "learning_rate": 0.00033391001148550486,
        "gradient_norm": 0.2870793342590332,
        "train_loss": 3.1460161209106445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15385,
        "tokens": 8066170880,
        "learning_rate": 0.0003338813686933414,
        "gradient_norm": 0.3523917496204376,
        "train_loss": 3.0948193073272705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15386,
        "tokens": 8066695168,
        "learning_rate": 0.0003338527258574883,
        "gradient_norm": 0.28855225443840027,
        "train_loss": 3.1111977100372314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15387,
        "tokens": 8067219456,
        "learning_rate": 0.000333824082978268,
        "gradient_norm": 0.3307308852672577,
        "train_loss": 3.1231279373168945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15388,
        "tokens": 8067743744,
        "learning_rate": 0.0003337954400560028,
        "gradient_norm": 0.29293614625930786,
        "train_loss": 3.1704001426696777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15389,
        "tokens": 8068268032,
        "learning_rate": 0.00033376679709101525,
        "gradient_norm": 0.3492126166820526,
        "train_loss": 3.1456761360168457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15390,
        "tokens": 8068792320,
        "learning_rate": 0.0003337381540836278,
        "gradient_norm": 0.2841205596923828,
        "train_loss": 3.064274787902832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15391,
        "tokens": 8069316608,
        "learning_rate": 0.00033370951103416265,
        "gradient_norm": 0.3014019727706909,
        "train_loss": 3.0647010803222656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15392,
        "tokens": 8069840896,
        "learning_rate": 0.00033368086794294233,
        "gradient_norm": 0.27573952078819275,
        "train_loss": 3.1005301475524902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15393,
        "tokens": 8070365184,
        "learning_rate": 0.00033365222481028924,
        "gradient_norm": 0.31438174843788147,
        "train_loss": 3.096045732498169,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15394,
        "tokens": 8070889472,
        "learning_rate": 0.0003336235816365259,
        "gradient_norm": 0.2890251576900482,
        "train_loss": 3.116513252258301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15395,
        "tokens": 8071413760,
        "learning_rate": 0.0003335949384219745,
        "gradient_norm": 0.2889237701892853,
        "train_loss": 3.0664761066436768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15396,
        "tokens": 8071938048,
        "learning_rate": 0.0003335662951669577,
        "gradient_norm": 0.28556501865386963,
        "train_loss": 3.0744495391845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15397,
        "tokens": 8072462336,
        "learning_rate": 0.0003335376518717977,
        "gradient_norm": 0.316946804523468,
        "train_loss": 3.117856979370117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15398,
        "tokens": 8072986624,
        "learning_rate": 0.0003335090085368171,
        "gradient_norm": 0.3012259900569916,
        "train_loss": 3.1709437370300293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15399,
        "tokens": 8073510912,
        "learning_rate": 0.0003334803651623383,
        "gradient_norm": 0.30461350083351135,
        "train_loss": 3.1288232803344727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15400,
        "tokens": 8074035200,
        "learning_rate": 0.0003334517217486835,
        "gradient_norm": 0.29868200421333313,
        "train_loss": 3.1413776874542236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15401,
        "tokens": 8074559488,
        "learning_rate": 0.0003334230782961753,
        "gradient_norm": 0.3255228102207184,
        "train_loss": 3.0726447105407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15402,
        "tokens": 8075083776,
        "learning_rate": 0.0003333944348051361,
        "gradient_norm": 0.306100457906723,
        "train_loss": 3.0428223609924316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15403,
        "tokens": 8075608064,
        "learning_rate": 0.00033336579127588836,
        "gradient_norm": 0.36443719267845154,
        "train_loss": 3.1788058280944824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15404,
        "tokens": 8076132352,
        "learning_rate": 0.00033333714770875436,
        "gradient_norm": 0.3038978576660156,
        "train_loss": 3.118142604827881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15405,
        "tokens": 8076656640,
        "learning_rate": 0.00033330850410405666,
        "gradient_norm": 0.3896782696247101,
        "train_loss": 3.1419105529785156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15406,
        "tokens": 8077180928,
        "learning_rate": 0.00033327986046211765,
        "gradient_norm": 0.3177175521850586,
        "train_loss": 3.101311445236206,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15407,
        "tokens": 8077705216,
        "learning_rate": 0.0003332512167832597,
        "gradient_norm": 0.41487398743629456,
        "train_loss": 3.0962471961975098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15408,
        "tokens": 8078229504,
        "learning_rate": 0.0003332225730678052,
        "gradient_norm": 0.31731128692626953,
        "train_loss": 3.099289655685425,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15409,
        "tokens": 8078753792,
        "learning_rate": 0.00033319392931607664,
        "gradient_norm": 0.32991787791252136,
        "train_loss": 3.111281394958496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15410,
        "tokens": 8079278080,
        "learning_rate": 0.00033316528552839646,
        "gradient_norm": 0.31302163004875183,
        "train_loss": 3.1060194969177246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15411,
        "tokens": 8079802368,
        "learning_rate": 0.00033313664170508695,
        "gradient_norm": 0.3083849549293518,
        "train_loss": 3.102302074432373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15412,
        "tokens": 8080326656,
        "learning_rate": 0.00033310799784647073,
        "gradient_norm": 0.2810806334018707,
        "train_loss": 3.094119071960449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15413,
        "tokens": 8080850944,
        "learning_rate": 0.00033307935395287007,
        "gradient_norm": 0.2847054898738861,
        "train_loss": 3.094604015350342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15414,
        "tokens": 8081375232,
        "learning_rate": 0.0003330507100246075,
        "gradient_norm": 0.27879106998443604,
        "train_loss": 3.104220390319824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15415,
        "tokens": 8081899520,
        "learning_rate": 0.00033302206606200535,
        "gradient_norm": 0.27659040689468384,
        "train_loss": 3.111264705657959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15416,
        "tokens": 8082423808,
        "learning_rate": 0.00033299342206538613,
        "gradient_norm": 0.2727591097354889,
        "train_loss": 3.1312613487243652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15417,
        "tokens": 8082948096,
        "learning_rate": 0.0003329647780350722,
        "gradient_norm": 0.29120099544525146,
        "train_loss": 3.1433136463165283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15418,
        "tokens": 8083472384,
        "learning_rate": 0.0003329361339713859,
        "gradient_norm": 0.30415213108062744,
        "train_loss": 3.0933661460876465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15419,
        "tokens": 8083996672,
        "learning_rate": 0.00033290748987464987,
        "gradient_norm": 0.3018726706504822,
        "train_loss": 3.116948366165161,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15420,
        "tokens": 8084520960,
        "learning_rate": 0.00033287884574518633,
        "gradient_norm": 0.2884630560874939,
        "train_loss": 3.1442880630493164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15421,
        "tokens": 8085045248,
        "learning_rate": 0.0003328502015833178,
        "gradient_norm": 0.28628718852996826,
        "train_loss": 3.13273024559021,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15422,
        "tokens": 8085569536,
        "learning_rate": 0.0003328215573893667,
        "gradient_norm": 0.2817147374153137,
        "train_loss": 3.092288017272949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15423,
        "tokens": 8086093824,
        "learning_rate": 0.00033279291316365547,
        "gradient_norm": 0.29237934947013855,
        "train_loss": 3.073146343231201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15424,
        "tokens": 8086618112,
        "learning_rate": 0.00033276426890650653,
        "gradient_norm": 0.30406638979911804,
        "train_loss": 3.0933070182800293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15425,
        "tokens": 8087142400,
        "learning_rate": 0.00033273562461824235,
        "gradient_norm": 0.29834336042404175,
        "train_loss": 3.081247329711914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15426,
        "tokens": 8087666688,
        "learning_rate": 0.00033270698029918525,
        "gradient_norm": 0.29475221037864685,
        "train_loss": 3.154193878173828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15427,
        "tokens": 8088190976,
        "learning_rate": 0.0003326783359496577,
        "gradient_norm": 0.3087981045246124,
        "train_loss": 3.118204355239868,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15428,
        "tokens": 8088715264,
        "learning_rate": 0.00033264969156998213,
        "gradient_norm": 0.3097371459007263,
        "train_loss": 3.086009979248047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15429,
        "tokens": 8089239552,
        "learning_rate": 0.00033262104716048105,
        "gradient_norm": 0.29844385385513306,
        "train_loss": 3.1187591552734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15430,
        "tokens": 8089763840,
        "learning_rate": 0.00033259240272147676,
        "gradient_norm": 0.31009724736213684,
        "train_loss": 3.0725955963134766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15431,
        "tokens": 8090288128,
        "learning_rate": 0.0003325637582532917,
        "gradient_norm": 0.2791065275669098,
        "train_loss": 3.096966028213501,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15432,
        "tokens": 8090812416,
        "learning_rate": 0.00033253511375624836,
        "gradient_norm": 0.30352455377578735,
        "train_loss": 3.106369972229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15433,
        "tokens": 8091336704,
        "learning_rate": 0.0003325064692306693,
        "gradient_norm": 0.27473101019859314,
        "train_loss": 3.0639829635620117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15434,
        "tokens": 8091860992,
        "learning_rate": 0.00033247782467687667,
        "gradient_norm": 0.29498857259750366,
        "train_loss": 3.08561372756958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15435,
        "tokens": 8092385280,
        "learning_rate": 0.00033244918009519306,
        "gradient_norm": 0.3167640268802643,
        "train_loss": 3.0593953132629395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15436,
        "tokens": 8092909568,
        "learning_rate": 0.00033242053548594085,
        "gradient_norm": 0.37294548749923706,
        "train_loss": 3.0216431617736816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15437,
        "tokens": 8093433856,
        "learning_rate": 0.0003323918908494426,
        "gradient_norm": 0.3515309691429138,
        "train_loss": 3.127939462661743,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15438,
        "tokens": 8093958144,
        "learning_rate": 0.0003323632461860205,
        "gradient_norm": 0.3534432649612427,
        "train_loss": 3.155412197113037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15439,
        "tokens": 8094482432,
        "learning_rate": 0.0003323346014959972,
        "gradient_norm": 0.33784863352775574,
        "train_loss": 3.114863872528076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15440,
        "tokens": 8095006720,
        "learning_rate": 0.00033230595677969505,
        "gradient_norm": 0.31822261214256287,
        "train_loss": 3.055633544921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15441,
        "tokens": 8095531008,
        "learning_rate": 0.0003322773120374365,
        "gradient_norm": 0.3086976408958435,
        "train_loss": 3.113905906677246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15442,
        "tokens": 8096055296,
        "learning_rate": 0.00033224866726954387,
        "gradient_norm": 0.3730148375034332,
        "train_loss": 3.142310380935669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15443,
        "tokens": 8096579584,
        "learning_rate": 0.0003322200224763398,
        "gradient_norm": 0.3581947684288025,
        "train_loss": 3.1494617462158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15444,
        "tokens": 8097103872,
        "learning_rate": 0.00033219137765814653,
        "gradient_norm": 0.3061777651309967,
        "train_loss": 3.12174654006958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15445,
        "tokens": 8097628160,
        "learning_rate": 0.00033216273281528664,
        "gradient_norm": 0.3178941309452057,
        "train_loss": 3.039422035217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15446,
        "tokens": 8098152448,
        "learning_rate": 0.0003321340879480824,
        "gradient_norm": 0.3270883560180664,
        "train_loss": 3.1953883171081543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15447,
        "tokens": 8098676736,
        "learning_rate": 0.0003321054430568564,
        "gradient_norm": 0.3179742395877838,
        "train_loss": 3.117725372314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15448,
        "tokens": 8099201024,
        "learning_rate": 0.000332076798141931,
        "gradient_norm": 0.3234119117259979,
        "train_loss": 3.0978333950042725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15449,
        "tokens": 8099725312,
        "learning_rate": 0.0003320481532036287,
        "gradient_norm": 0.33274951577186584,
        "train_loss": 3.088395118713379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15450,
        "tokens": 8100249600,
        "learning_rate": 0.0003320195082422718,
        "gradient_norm": 0.3052355647087097,
        "train_loss": 3.082240104675293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15451,
        "tokens": 8100773888,
        "learning_rate": 0.00033199086325818287,
        "gradient_norm": 0.33184006810188293,
        "train_loss": 3.1037611961364746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15452,
        "tokens": 8101298176,
        "learning_rate": 0.0003319622182516842,
        "gradient_norm": 0.29980596899986267,
        "train_loss": 3.1243014335632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15453,
        "tokens": 8101822464,
        "learning_rate": 0.0003319335732230984,
        "gradient_norm": 0.3437916040420532,
        "train_loss": 3.114285945892334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15454,
        "tokens": 8102346752,
        "learning_rate": 0.00033190492817274786,
        "gradient_norm": 0.29939547181129456,
        "train_loss": 3.1258225440979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15455,
        "tokens": 8102871040,
        "learning_rate": 0.00033187628310095494,
        "gradient_norm": 0.3394247591495514,
        "train_loss": 3.1138417720794678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15456,
        "tokens": 8103395328,
        "learning_rate": 0.0003318476380080421,
        "gradient_norm": 0.30646127462387085,
        "train_loss": 3.0572714805603027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15457,
        "tokens": 8103919616,
        "learning_rate": 0.00033181899289433186,
        "gradient_norm": 0.3465258777141571,
        "train_loss": 3.0821077823638916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15458,
        "tokens": 8104443904,
        "learning_rate": 0.0003317903477601465,
        "gradient_norm": 0.2810189127922058,
        "train_loss": 3.1022844314575195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15459,
        "tokens": 8104968192,
        "learning_rate": 0.0003317617026058086,
        "gradient_norm": 0.28869935870170593,
        "train_loss": 3.085383892059326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15460,
        "tokens": 8105492480,
        "learning_rate": 0.0003317330574316405,
        "gradient_norm": 0.31510499119758606,
        "train_loss": 3.120065212249756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15461,
        "tokens": 8106016768,
        "learning_rate": 0.0003317044122379646,
        "gradient_norm": 0.2970471680164337,
        "train_loss": 3.13159441947937,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15462,
        "tokens": 8106541056,
        "learning_rate": 0.0003316757670251035,
        "gradient_norm": 0.2964041531085968,
        "train_loss": 3.1280293464660645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15463,
        "tokens": 8107065344,
        "learning_rate": 0.0003316471217933796,
        "gradient_norm": 0.3065732717514038,
        "train_loss": 3.1139204502105713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15464,
        "tokens": 8107589632,
        "learning_rate": 0.00033161847654311524,
        "gradient_norm": 0.28185421228408813,
        "train_loss": 3.0593557357788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15465,
        "tokens": 8108113920,
        "learning_rate": 0.000331589831274633,
        "gradient_norm": 0.3025174140930176,
        "train_loss": 3.0983424186706543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15466,
        "tokens": 8108638208,
        "learning_rate": 0.0003315611859882551,
        "gradient_norm": 0.32077738642692566,
        "train_loss": 3.131181001663208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15467,
        "tokens": 8109162496,
        "learning_rate": 0.0003315325406843042,
        "gradient_norm": 0.2882489264011383,
        "train_loss": 3.073075294494629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15468,
        "tokens": 8109686784,
        "learning_rate": 0.0003315038953631026,
        "gradient_norm": 0.2934964895248413,
        "train_loss": 3.1021878719329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15469,
        "tokens": 8110211072,
        "learning_rate": 0.00033147525002497275,
        "gradient_norm": 0.30378296971321106,
        "train_loss": 3.1226229667663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15470,
        "tokens": 8110735360,
        "learning_rate": 0.00033144660467023716,
        "gradient_norm": 0.2860387861728668,
        "train_loss": 3.06174373626709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15471,
        "tokens": 8111259648,
        "learning_rate": 0.00033141795929921816,
        "gradient_norm": 0.3101729452610016,
        "train_loss": 3.1412415504455566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15472,
        "tokens": 8111783936,
        "learning_rate": 0.00033138931391223835,
        "gradient_norm": 0.2832200825214386,
        "train_loss": 3.114008903503418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15473,
        "tokens": 8112308224,
        "learning_rate": 0.00033136066850962006,
        "gradient_norm": 0.3020983636379242,
        "train_loss": 3.146974563598633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15474,
        "tokens": 8112832512,
        "learning_rate": 0.0003313320230916858,
        "gradient_norm": 0.308187872171402,
        "train_loss": 3.115093469619751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15475,
        "tokens": 8113356800,
        "learning_rate": 0.00033130337765875786,
        "gradient_norm": 0.29691281914711,
        "train_loss": 3.139106273651123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15476,
        "tokens": 8113881088,
        "learning_rate": 0.00033127473221115884,
        "gradient_norm": 0.3036709725856781,
        "train_loss": 3.161914587020874,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15477,
        "tokens": 8114405376,
        "learning_rate": 0.0003312460867492111,
        "gradient_norm": 0.3078465759754181,
        "train_loss": 3.1075081825256348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15478,
        "tokens": 8114929664,
        "learning_rate": 0.0003312174412732371,
        "gradient_norm": 0.29361799359321594,
        "train_loss": 3.0957841873168945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15479,
        "tokens": 8115453952,
        "learning_rate": 0.0003311887957835593,
        "gradient_norm": 0.28972816467285156,
        "train_loss": 3.101365327835083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15480,
        "tokens": 8115978240,
        "learning_rate": 0.0003311601502805001,
        "gradient_norm": 0.30993443727493286,
        "train_loss": 3.0490427017211914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15481,
        "tokens": 8116502528,
        "learning_rate": 0.0003311315047643819,
        "gradient_norm": 0.31608331203460693,
        "train_loss": 3.0879805088043213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15482,
        "tokens": 8117026816,
        "learning_rate": 0.0003311028592355273,
        "gradient_norm": 0.3122197687625885,
        "train_loss": 3.168480396270752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15483,
        "tokens": 8117551104,
        "learning_rate": 0.0003310742136942586,
        "gradient_norm": 0.35940226912498474,
        "train_loss": 3.185511589050293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15484,
        "tokens": 8118075392,
        "learning_rate": 0.00033104556814089834,
        "gradient_norm": 0.30617573857307434,
        "train_loss": 3.149245262145996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15485,
        "tokens": 8118599680,
        "learning_rate": 0.00033101692257576893,
        "gradient_norm": 0.3237614035606384,
        "train_loss": 3.1051383018493652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15486,
        "tokens": 8119123968,
        "learning_rate": 0.00033098827699919273,
        "gradient_norm": 0.30775511264801025,
        "train_loss": 3.1202688217163086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15487,
        "tokens": 8119648256,
        "learning_rate": 0.00033095963141149224,
        "gradient_norm": 0.3157329261302948,
        "train_loss": 3.0535874366760254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15488,
        "tokens": 8120172544,
        "learning_rate": 0.0003309309858129899,
        "gradient_norm": 0.30904650688171387,
        "train_loss": 3.0849270820617676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15489,
        "tokens": 8120696832,
        "learning_rate": 0.0003309023402040081,
        "gradient_norm": 0.3134489357471466,
        "train_loss": 3.048860549926758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15490,
        "tokens": 8121221120,
        "learning_rate": 0.0003308736945848694,
        "gradient_norm": 0.31708890199661255,
        "train_loss": 3.1462626457214355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15491,
        "tokens": 8121745408,
        "learning_rate": 0.0003308450489558962,
        "gradient_norm": 0.3102779686450958,
        "train_loss": 3.0688788890838623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15492,
        "tokens": 8122269696,
        "learning_rate": 0.0003308164033174109,
        "gradient_norm": 0.32586345076560974,
        "train_loss": 3.103242874145508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15493,
        "tokens": 8122793984,
        "learning_rate": 0.00033078775766973595,
        "gradient_norm": 0.3281331956386566,
        "train_loss": 3.13023042678833,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15494,
        "tokens": 8123318272,
        "learning_rate": 0.0003307591120131939,
        "gradient_norm": 0.3378869891166687,
        "train_loss": 3.045170783996582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15495,
        "tokens": 8123842560,
        "learning_rate": 0.00033073046634810694,
        "gradient_norm": 0.3311387896537781,
        "train_loss": 3.081115245819092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15496,
        "tokens": 8124366848,
        "learning_rate": 0.00033070182067479774,
        "gradient_norm": 0.2963722348213196,
        "train_loss": 3.1845593452453613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15497,
        "tokens": 8124891136,
        "learning_rate": 0.00033067317499358865,
        "gradient_norm": 0.31990954279899597,
        "train_loss": 3.058034896850586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15498,
        "tokens": 8125415424,
        "learning_rate": 0.0003306445293048022,
        "gradient_norm": 0.2753346562385559,
        "train_loss": 3.1478652954101562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15499,
        "tokens": 8125939712,
        "learning_rate": 0.00033061588360876074,
        "gradient_norm": 0.30331116914749146,
        "train_loss": 3.1027801036834717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15500,
        "tokens": 8126464000,
        "learning_rate": 0.00033058723790578673,
        "gradient_norm": 0.28535568714141846,
        "train_loss": 3.178194522857666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15501,
        "tokens": 8126988288,
        "learning_rate": 0.0003305585921962026,
        "gradient_norm": 0.27356353402137756,
        "train_loss": 3.093613624572754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15502,
        "tokens": 8127512576,
        "learning_rate": 0.00033052994648033083,
        "gradient_norm": 0.36563244462013245,
        "train_loss": 3.1284523010253906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15503,
        "tokens": 8128036864,
        "learning_rate": 0.0003305013007584939,
        "gradient_norm": 0.29920369386672974,
        "train_loss": 3.0999929904937744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15504,
        "tokens": 8128561152,
        "learning_rate": 0.00033047265503101413,
        "gradient_norm": 0.28509706258773804,
        "train_loss": 3.093916893005371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15505,
        "tokens": 8129085440,
        "learning_rate": 0.0003304440092982141,
        "gradient_norm": 0.3005754351615906,
        "train_loss": 3.0846614837646484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15506,
        "tokens": 8129609728,
        "learning_rate": 0.0003304153635604162,
        "gradient_norm": 0.29122981429100037,
        "train_loss": 3.1601428985595703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15507,
        "tokens": 8130134016,
        "learning_rate": 0.0003303867178179428,
        "gradient_norm": 0.29405897855758667,
        "train_loss": 3.069855213165283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15508,
        "tokens": 8130658304,
        "learning_rate": 0.0003303580720711165,
        "gradient_norm": 0.28368815779685974,
        "train_loss": 3.0968732833862305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15509,
        "tokens": 8131182592,
        "learning_rate": 0.00033032942632025956,
        "gradient_norm": 0.2696828246116638,
        "train_loss": 3.069901466369629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15510,
        "tokens": 8131706880,
        "learning_rate": 0.00033030078056569455,
        "gradient_norm": 0.3064562976360321,
        "train_loss": 3.1001639366149902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15511,
        "tokens": 8132231168,
        "learning_rate": 0.00033027213480774385,
        "gradient_norm": 0.2998511493206024,
        "train_loss": 3.135918617248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15512,
        "tokens": 8132755456,
        "learning_rate": 0.00033024348904672995,
        "gradient_norm": 0.28911662101745605,
        "train_loss": 3.0979509353637695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15513,
        "tokens": 8133279744,
        "learning_rate": 0.0003302148432829753,
        "gradient_norm": 0.2826698422431946,
        "train_loss": 3.097351551055908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15514,
        "tokens": 8133804032,
        "learning_rate": 0.00033018619751680234,
        "gradient_norm": 0.27645885944366455,
        "train_loss": 3.0807228088378906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15515,
        "tokens": 8134328320,
        "learning_rate": 0.0003301575517485335,
        "gradient_norm": 0.29435646533966064,
        "train_loss": 3.0537915229797363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15516,
        "tokens": 8134852608,
        "learning_rate": 0.00033012890597849113,
        "gradient_norm": 0.3014584481716156,
        "train_loss": 3.0738754272460938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15517,
        "tokens": 8135376896,
        "learning_rate": 0.0003301002602069978,
        "gradient_norm": 0.3036406338214874,
        "train_loss": 3.0732364654541016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15518,
        "tokens": 8135901184,
        "learning_rate": 0.000330071614434376,
        "gradient_norm": 0.31662270426750183,
        "train_loss": 3.0973961353302,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15519,
        "tokens": 8136425472,
        "learning_rate": 0.00033004296866094807,
        "gradient_norm": 0.31254586577415466,
        "train_loss": 3.0812935829162598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15520,
        "tokens": 8136949760,
        "learning_rate": 0.0003300143228870364,
        "gradient_norm": 0.3194674551486969,
        "train_loss": 3.1220004558563232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15521,
        "tokens": 8137474048,
        "learning_rate": 0.00032998567711296355,
        "gradient_norm": 0.3273378610610962,
        "train_loss": 3.0581583976745605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15522,
        "tokens": 8137998336,
        "learning_rate": 0.0003299570313390519,
        "gradient_norm": 0.3214511573314667,
        "train_loss": 3.1286234855651855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15523,
        "tokens": 8138522624,
        "learning_rate": 0.000329928385565624,
        "gradient_norm": 0.35091888904571533,
        "train_loss": 3.1292078495025635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15524,
        "tokens": 8139046912,
        "learning_rate": 0.00032989973979300207,
        "gradient_norm": 0.3357543647289276,
        "train_loss": 3.1335554122924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15525,
        "tokens": 8139571200,
        "learning_rate": 0.0003298710940215088,
        "gradient_norm": 0.36529359221458435,
        "train_loss": 3.1988463401794434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15526,
        "tokens": 8140095488,
        "learning_rate": 0.00032984244825146644,
        "gradient_norm": 0.353592187166214,
        "train_loss": 3.0966479778289795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15527,
        "tokens": 8140619776,
        "learning_rate": 0.0003298138024831975,
        "gradient_norm": 0.30344071984291077,
        "train_loss": 3.100374221801758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15528,
        "tokens": 8141144064,
        "learning_rate": 0.0003297851567170246,
        "gradient_norm": 0.3483946621417999,
        "train_loss": 3.107667922973633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15529,
        "tokens": 8141668352,
        "learning_rate": 0.0003297565109532699,
        "gradient_norm": 0.33998268842697144,
        "train_loss": 3.068206787109375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15530,
        "tokens": 8142192640,
        "learning_rate": 0.0003297278651922561,
        "gradient_norm": 0.39174625277519226,
        "train_loss": 3.1733269691467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15531,
        "tokens": 8142716928,
        "learning_rate": 0.0003296992194343054,
        "gradient_norm": 0.3517475724220276,
        "train_loss": 3.1217191219329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15532,
        "tokens": 8143241216,
        "learning_rate": 0.00032967057367974044,
        "gradient_norm": 0.40862715244293213,
        "train_loss": 3.1037282943725586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15533,
        "tokens": 8143765504,
        "learning_rate": 0.00032964192792888345,
        "gradient_norm": 0.3280991017818451,
        "train_loss": 3.1494688987731934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15534,
        "tokens": 8144289792,
        "learning_rate": 0.00032961328218205716,
        "gradient_norm": 0.3861156404018402,
        "train_loss": 3.1516761779785156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15535,
        "tokens": 8144814080,
        "learning_rate": 0.00032958463643958377,
        "gradient_norm": 0.3258592486381531,
        "train_loss": 3.1436052322387695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15536,
        "tokens": 8145338368,
        "learning_rate": 0.0003295559907017858,
        "gradient_norm": 0.3770614266395569,
        "train_loss": 3.1290457248687744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15537,
        "tokens": 8145862656,
        "learning_rate": 0.0003295273449689858,
        "gradient_norm": 0.34021222591400146,
        "train_loss": 3.155386447906494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15538,
        "tokens": 8146386944,
        "learning_rate": 0.000329498699241506,
        "gradient_norm": 0.34077906608581543,
        "train_loss": 3.1092119216918945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15539,
        "tokens": 8146911232,
        "learning_rate": 0.0003294700535196691,
        "gradient_norm": 0.296026349067688,
        "train_loss": 3.0324482917785645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15540,
        "tokens": 8147435520,
        "learning_rate": 0.0003294414078037973,
        "gradient_norm": 0.34488773345947266,
        "train_loss": 3.0555977821350098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15541,
        "tokens": 8147959808,
        "learning_rate": 0.00032941276209421327,
        "gradient_norm": 0.30561378598213196,
        "train_loss": 3.0913398265838623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15542,
        "tokens": 8148484096,
        "learning_rate": 0.00032938411639123915,
        "gradient_norm": 0.3402818739414215,
        "train_loss": 3.0978586673736572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15543,
        "tokens": 8149008384,
        "learning_rate": 0.0003293554706951978,
        "gradient_norm": 0.32855018973350525,
        "train_loss": 3.1269288063049316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15544,
        "tokens": 8149532672,
        "learning_rate": 0.00032932682500641123,
        "gradient_norm": 0.3215126395225525,
        "train_loss": 3.131943702697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15545,
        "tokens": 8150056960,
        "learning_rate": 0.00032929817932520226,
        "gradient_norm": 0.34244659543037415,
        "train_loss": 3.1370320320129395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15546,
        "tokens": 8150581248,
        "learning_rate": 0.00032926953365189295,
        "gradient_norm": 1.6706104278564453,
        "train_loss": 2.8695602416992188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15547,
        "tokens": 8151105536,
        "learning_rate": 0.00032924088798680606,
        "gradient_norm": 0.4114045798778534,
        "train_loss": 3.1192893981933594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15548,
        "tokens": 8151629824,
        "learning_rate": 0.000329212242330264,
        "gradient_norm": 0.3511497676372528,
        "train_loss": 3.124093532562256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15549,
        "tokens": 8152154112,
        "learning_rate": 0.000329183596682589,
        "gradient_norm": 0.3517296612262726,
        "train_loss": 3.086635112762451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15550,
        "tokens": 8152678400,
        "learning_rate": 0.0003291549510441037,
        "gradient_norm": 0.3812650740146637,
        "train_loss": 3.1266226768493652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15551,
        "tokens": 8153202688,
        "learning_rate": 0.0003291263054151305,
        "gradient_norm": 0.32552778720855713,
        "train_loss": 3.1304993629455566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15552,
        "tokens": 8153726976,
        "learning_rate": 0.0003290976597959918,
        "gradient_norm": 0.3964124023914337,
        "train_loss": 3.0863163471221924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15553,
        "tokens": 8154251264,
        "learning_rate": 0.00032906901418701005,
        "gradient_norm": 0.332072913646698,
        "train_loss": 3.126769542694092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15554,
        "tokens": 8154775552,
        "learning_rate": 0.0003290403685885077,
        "gradient_norm": 0.3560897707939148,
        "train_loss": 3.1327762603759766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15555,
        "tokens": 8155299840,
        "learning_rate": 0.00032901172300080727,
        "gradient_norm": 0.3638046383857727,
        "train_loss": 3.095226287841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15556,
        "tokens": 8155824128,
        "learning_rate": 0.00032898307742423096,
        "gradient_norm": 0.34837543964385986,
        "train_loss": 3.0928573608398438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15557,
        "tokens": 8156348416,
        "learning_rate": 0.0003289544318591016,
        "gradient_norm": 0.3564063012599945,
        "train_loss": 3.1359481811523438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15558,
        "tokens": 8156872704,
        "learning_rate": 0.00032892578630574126,
        "gradient_norm": 0.279045432806015,
        "train_loss": 3.116403818130493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15559,
        "tokens": 8157396992,
        "learning_rate": 0.0003288971407644726,
        "gradient_norm": 0.32703250646591187,
        "train_loss": 3.1742734909057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15560,
        "tokens": 8157921280,
        "learning_rate": 0.00032886849523561793,
        "gradient_norm": 0.29851290583610535,
        "train_loss": 3.063821315765381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15561,
        "tokens": 8158445568,
        "learning_rate": 0.0003288398497194999,
        "gradient_norm": 0.2930644452571869,
        "train_loss": 3.1160759925842285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15562,
        "tokens": 8158969856,
        "learning_rate": 0.0003288112042164406,
        "gradient_norm": 0.29736632108688354,
        "train_loss": 3.106736421585083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15563,
        "tokens": 8159494144,
        "learning_rate": 0.00032878255872676284,
        "gradient_norm": 0.28260567784309387,
        "train_loss": 3.087386131286621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15564,
        "tokens": 8160018432,
        "learning_rate": 0.00032875391325078884,
        "gradient_norm": 0.27458399534225464,
        "train_loss": 3.1125333309173584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15565,
        "tokens": 8160542720,
        "learning_rate": 0.00032872526778884116,
        "gradient_norm": 0.26843151450157166,
        "train_loss": 3.082289457321167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15566,
        "tokens": 8161067008,
        "learning_rate": 0.00032869662234124203,
        "gradient_norm": 0.3126584589481354,
        "train_loss": 3.123073101043701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15567,
        "tokens": 8161591296,
        "learning_rate": 0.0003286679769083141,
        "gradient_norm": 0.28739696741104126,
        "train_loss": 3.1099488735198975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15568,
        "tokens": 8162115584,
        "learning_rate": 0.00032863933149037983,
        "gradient_norm": 0.2991214394569397,
        "train_loss": 3.0645761489868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15569,
        "tokens": 8162639872,
        "learning_rate": 0.00032861068608776154,
        "gradient_norm": 0.30538466572761536,
        "train_loss": 3.11584210395813,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15570,
        "tokens": 8163164160,
        "learning_rate": 0.0003285820407007817,
        "gradient_norm": 0.30307868123054504,
        "train_loss": 3.199198007583618,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15571,
        "tokens": 8163688448,
        "learning_rate": 0.0003285533953297627,
        "gradient_norm": 0.3295307755470276,
        "train_loss": 3.0850353240966797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15572,
        "tokens": 8164212736,
        "learning_rate": 0.0003285247499750272,
        "gradient_norm": 0.29063910245895386,
        "train_loss": 3.0510456562042236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15573,
        "tokens": 8164737024,
        "learning_rate": 0.00032849610463689735,
        "gradient_norm": 0.3110077679157257,
        "train_loss": 3.1306614875793457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15574,
        "tokens": 8165261312,
        "learning_rate": 0.0003284674593156958,
        "gradient_norm": 0.3143670856952667,
        "train_loss": 3.1329715251922607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15575,
        "tokens": 8165785600,
        "learning_rate": 0.0003284388140117448,
        "gradient_norm": 0.309688538312912,
        "train_loss": 3.1295599937438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15576,
        "tokens": 8166309888,
        "learning_rate": 0.0003284101687253669,
        "gradient_norm": 0.29890871047973633,
        "train_loss": 3.1026711463928223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15577,
        "tokens": 8166834176,
        "learning_rate": 0.00032838152345688465,
        "gradient_norm": 0.318877249956131,
        "train_loss": 3.0993874073028564,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15578,
        "tokens": 8167358464,
        "learning_rate": 0.0003283528782066203,
        "gradient_norm": 0.3361530601978302,
        "train_loss": 3.0920486450195312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15579,
        "tokens": 8167882752,
        "learning_rate": 0.0003283242329748964,
        "gradient_norm": 0.3438936173915863,
        "train_loss": 3.0634255409240723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15580,
        "tokens": 8168407040,
        "learning_rate": 0.0003282955877620352,
        "gradient_norm": 0.3606683611869812,
        "train_loss": 3.135585308074951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15581,
        "tokens": 8168931328,
        "learning_rate": 0.0003282669425683595,
        "gradient_norm": 0.3359644114971161,
        "train_loss": 3.147409439086914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15582,
        "tokens": 8169455616,
        "learning_rate": 0.00032823829739419137,
        "gradient_norm": 0.3708833158016205,
        "train_loss": 3.07759428024292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15583,
        "tokens": 8169979904,
        "learning_rate": 0.0003282096522398535,
        "gradient_norm": 0.3419432044029236,
        "train_loss": 3.1226139068603516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15584,
        "tokens": 8170504192,
        "learning_rate": 0.0003281810071056681,
        "gradient_norm": 0.3189815282821655,
        "train_loss": 3.113342761993408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15585,
        "tokens": 8171028480,
        "learning_rate": 0.00032815236199195785,
        "gradient_norm": 0.327357679605484,
        "train_loss": 3.0911855697631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15586,
        "tokens": 8171552768,
        "learning_rate": 0.000328123716899045,
        "gradient_norm": 0.3309783935546875,
        "train_loss": 3.1096949577331543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15587,
        "tokens": 8172077056,
        "learning_rate": 0.00032809507182725203,
        "gradient_norm": 0.3217671811580658,
        "train_loss": 3.0982911586761475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15588,
        "tokens": 8172601344,
        "learning_rate": 0.0003280664267769015,
        "gradient_norm": 0.34182798862457275,
        "train_loss": 3.0878264904022217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15589,
        "tokens": 8173125632,
        "learning_rate": 0.0003280377817483156,
        "gradient_norm": 0.32228314876556396,
        "train_loss": 3.0890603065490723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15590,
        "tokens": 8173649920,
        "learning_rate": 0.0003280091367418171,
        "gradient_norm": 0.3148607909679413,
        "train_loss": 3.124213218688965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15591,
        "tokens": 8174174208,
        "learning_rate": 0.0003279804917577281,
        "gradient_norm": 0.3419041633605957,
        "train_loss": 3.100680351257324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15592,
        "tokens": 8174698496,
        "learning_rate": 0.0003279518467963713,
        "gradient_norm": 0.3249906003475189,
        "train_loss": 3.077274799346924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15593,
        "tokens": 8175222784,
        "learning_rate": 0.00032792320185806887,
        "gradient_norm": 0.32603031396865845,
        "train_loss": 3.1278724670410156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15594,
        "tokens": 8175747072,
        "learning_rate": 0.0003278945569431436,
        "gradient_norm": 0.2966916263103485,
        "train_loss": 3.112151622772217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15595,
        "tokens": 8176271360,
        "learning_rate": 0.0003278659120519175,
        "gradient_norm": 0.3315960764884949,
        "train_loss": 3.1167635917663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15596,
        "tokens": 8176795648,
        "learning_rate": 0.00032783726718471336,
        "gradient_norm": 0.2891421616077423,
        "train_loss": 3.1159510612487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15597,
        "tokens": 8177319936,
        "learning_rate": 0.00032780862234185336,
        "gradient_norm": 0.33602410554885864,
        "train_loss": 3.1138339042663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15598,
        "tokens": 8177844224,
        "learning_rate": 0.00032777997752366016,
        "gradient_norm": 0.294398695230484,
        "train_loss": 3.034254312515259,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15599,
        "tokens": 8178368512,
        "learning_rate": 0.000327751332730456,
        "gradient_norm": 0.3112950325012207,
        "train_loss": 3.066384792327881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15600,
        "tokens": 8178892800,
        "learning_rate": 0.00032772268796256345,
        "gradient_norm": 0.30927574634552,
        "train_loss": 3.0842299461364746,
        "val_loss": 3.0699329376220703,
        "hellaswag_acc": 0.2797251343727112,
        "hellaswag_acc_norm": 0.290081650018692
    },
    {
        "step": 15601,
        "tokens": 8179417088,
        "learning_rate": 0.0003276940432203049,
        "gradient_norm": 0.309736043214798,
        "train_loss": 3.0975847244262695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15602,
        "tokens": 8179941376,
        "learning_rate": 0.00032766539850400273,
        "gradient_norm": 0.31210488080978394,
        "train_loss": 3.1047050952911377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15603,
        "tokens": 8180465664,
        "learning_rate": 0.0003276367538139794,
        "gradient_norm": 0.3033566474914551,
        "train_loss": 3.086782932281494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15604,
        "tokens": 8180989952,
        "learning_rate": 0.00032760810915055736,
        "gradient_norm": 0.31072986125946045,
        "train_loss": 3.0904300212860107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15605,
        "tokens": 8181514240,
        "learning_rate": 0.00032757946451405904,
        "gradient_norm": 0.3472561538219452,
        "train_loss": 3.1371006965637207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15606,
        "tokens": 8182038528,
        "learning_rate": 0.0003275508199048069,
        "gradient_norm": 0.2975385785102844,
        "train_loss": 3.1322126388549805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15607,
        "tokens": 8182562816,
        "learning_rate": 0.0003275221753231232,
        "gradient_norm": 0.35320886969566345,
        "train_loss": 3.1413543224334717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15608,
        "tokens": 8183087104,
        "learning_rate": 0.00032749353076933066,
        "gradient_norm": 0.31141403317451477,
        "train_loss": 3.125999927520752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15609,
        "tokens": 8183611392,
        "learning_rate": 0.0003274648862437514,
        "gradient_norm": 0.31319504976272583,
        "train_loss": 3.071852445602417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15610,
        "tokens": 8184135680,
        "learning_rate": 0.0003274362417467082,
        "gradient_norm": 0.29773253202438354,
        "train_loss": 3.058055877685547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15611,
        "tokens": 8184659968,
        "learning_rate": 0.0003274075972785232,
        "gradient_norm": 0.35497844219207764,
        "train_loss": 3.065189838409424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15612,
        "tokens": 8185184256,
        "learning_rate": 0.00032737895283951895,
        "gradient_norm": 0.3145357668399811,
        "train_loss": 3.1122922897338867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15613,
        "tokens": 8185708544,
        "learning_rate": 0.00032735030843001776,
        "gradient_norm": 0.312027245759964,
        "train_loss": 3.0689942836761475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15614,
        "tokens": 8186232832,
        "learning_rate": 0.00032732166405034227,
        "gradient_norm": 0.30444642901420593,
        "train_loss": 3.174760341644287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15615,
        "tokens": 8186757120,
        "learning_rate": 0.0003272930197008147,
        "gradient_norm": 0.3199392557144165,
        "train_loss": 3.091923713684082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15616,
        "tokens": 8187281408,
        "learning_rate": 0.00032726437538175754,
        "gradient_norm": 0.33409368991851807,
        "train_loss": 3.0652265548706055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15617,
        "tokens": 8187805696,
        "learning_rate": 0.00032723573109349336,
        "gradient_norm": 0.3110884130001068,
        "train_loss": 3.133253574371338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15618,
        "tokens": 8188329984,
        "learning_rate": 0.00032720708683634436,
        "gradient_norm": 0.30002617835998535,
        "train_loss": 3.0377917289733887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15619,
        "tokens": 8188854272,
        "learning_rate": 0.0003271784426106332,
        "gradient_norm": 0.3269573450088501,
        "train_loss": 3.1515626907348633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15620,
        "tokens": 8189378560,
        "learning_rate": 0.00032714979841668205,
        "gradient_norm": 0.3364119827747345,
        "train_loss": 3.1346516609191895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15621,
        "tokens": 8189902848,
        "learning_rate": 0.0003271211542548136,
        "gradient_norm": 0.2969166338443756,
        "train_loss": 3.0077133178710938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15622,
        "tokens": 8190427136,
        "learning_rate": 0.0003270925101253501,
        "gradient_norm": 0.3205215334892273,
        "train_loss": 3.1117172241210938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15623,
        "tokens": 8190951424,
        "learning_rate": 0.00032706386602861405,
        "gradient_norm": 0.31248828768730164,
        "train_loss": 3.101330280303955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15624,
        "tokens": 8191475712,
        "learning_rate": 0.00032703522196492776,
        "gradient_norm": 0.3116108179092407,
        "train_loss": 3.1056337356567383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15625,
        "tokens": 8192000000,
        "learning_rate": 0.00032700657793461387,
        "gradient_norm": 0.3310701847076416,
        "train_loss": 3.120579242706299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15626,
        "tokens": 8192524288,
        "learning_rate": 0.00032697793393799454,
        "gradient_norm": 0.32330095767974854,
        "train_loss": 3.126269817352295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15627,
        "tokens": 8193048576,
        "learning_rate": 0.0003269492899753924,
        "gradient_norm": 0.3361155688762665,
        "train_loss": 3.0612826347351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15628,
        "tokens": 8193572864,
        "learning_rate": 0.0003269206460471298,
        "gradient_norm": 0.30277737975120544,
        "train_loss": 3.1213037967681885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15629,
        "tokens": 8194097152,
        "learning_rate": 0.00032689200215352916,
        "gradient_norm": 0.3323499262332916,
        "train_loss": 3.031768321990967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15630,
        "tokens": 8194621440,
        "learning_rate": 0.00032686335829491294,
        "gradient_norm": 0.29541200399398804,
        "train_loss": 3.0254058837890625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15631,
        "tokens": 8195145728,
        "learning_rate": 0.00032683471447160343,
        "gradient_norm": 0.32938605546951294,
        "train_loss": 3.0083439350128174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15632,
        "tokens": 8195670016,
        "learning_rate": 0.0003268060706839233,
        "gradient_norm": 0.3389850854873657,
        "train_loss": 3.0496299266815186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15633,
        "tokens": 8196194304,
        "learning_rate": 0.0003267774269321947,
        "gradient_norm": 0.30872660875320435,
        "train_loss": 3.050854444503784,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15634,
        "tokens": 8196718592,
        "learning_rate": 0.00032674878321674035,
        "gradient_norm": 0.33425527811050415,
        "train_loss": 3.085972785949707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15635,
        "tokens": 8197242880,
        "learning_rate": 0.0003267201395378823,
        "gradient_norm": 0.28092432022094727,
        "train_loss": 3.1116318702697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15636,
        "tokens": 8197767168,
        "learning_rate": 0.00032669149589594317,
        "gradient_norm": 0.33313530683517456,
        "train_loss": 3.1368160247802734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15637,
        "tokens": 8198291456,
        "learning_rate": 0.0003266628522912455,
        "gradient_norm": 0.3190983235836029,
        "train_loss": 3.045665979385376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15638,
        "tokens": 8198815744,
        "learning_rate": 0.0003266342087241115,
        "gradient_norm": 0.3084002137184143,
        "train_loss": 3.093397617340088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15639,
        "tokens": 8199340032,
        "learning_rate": 0.00032660556519486383,
        "gradient_norm": 0.30370423197746277,
        "train_loss": 3.0392072200775146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15640,
        "tokens": 8199864320,
        "learning_rate": 0.00032657692170382456,
        "gradient_norm": 0.29984498023986816,
        "train_loss": 3.090949058532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15641,
        "tokens": 8200388608,
        "learning_rate": 0.0003265482782513165,
        "gradient_norm": 0.3276965916156769,
        "train_loss": 3.0485410690307617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15642,
        "tokens": 8200912896,
        "learning_rate": 0.00032651963483766166,
        "gradient_norm": 0.2887009084224701,
        "train_loss": 3.0465590953826904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15643,
        "tokens": 8201437184,
        "learning_rate": 0.00032649099146318285,
        "gradient_norm": 0.3005233108997345,
        "train_loss": 3.100648880004883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15644,
        "tokens": 8201961472,
        "learning_rate": 0.0003264623481282022,
        "gradient_norm": 0.30341649055480957,
        "train_loss": 3.143629312515259,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15645,
        "tokens": 8202485760,
        "learning_rate": 0.0003264337048330423,
        "gradient_norm": 0.2950660288333893,
        "train_loss": 3.1001362800598145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15646,
        "tokens": 8203010048,
        "learning_rate": 0.0003264050615780254,
        "gradient_norm": 0.31430962681770325,
        "train_loss": 3.140756607055664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15647,
        "tokens": 8203534336,
        "learning_rate": 0.0003263764183634741,
        "gradient_norm": 0.2922278642654419,
        "train_loss": 3.069796323776245,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15648,
        "tokens": 8204058624,
        "learning_rate": 0.00032634777518971065,
        "gradient_norm": 0.3121984899044037,
        "train_loss": 3.040797710418701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15649,
        "tokens": 8204582912,
        "learning_rate": 0.0003263191320570576,
        "gradient_norm": 0.2946387827396393,
        "train_loss": 3.0315475463867188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15650,
        "tokens": 8205107200,
        "learning_rate": 0.0003262904889658373,
        "gradient_norm": 0.33226025104522705,
        "train_loss": 3.1049845218658447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15651,
        "tokens": 8205631488,
        "learning_rate": 0.00032626184591637216,
        "gradient_norm": 0.2965199053287506,
        "train_loss": 3.0508861541748047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15652,
        "tokens": 8206155776,
        "learning_rate": 0.00032623320290898464,
        "gradient_norm": 0.3239562213420868,
        "train_loss": 3.0826311111450195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15653,
        "tokens": 8206680064,
        "learning_rate": 0.00032620455994399706,
        "gradient_norm": 0.2999842166900635,
        "train_loss": 3.1098618507385254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15654,
        "tokens": 8207204352,
        "learning_rate": 0.00032617591702173193,
        "gradient_norm": 0.3013496398925781,
        "train_loss": 3.1077733039855957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15655,
        "tokens": 8207728640,
        "learning_rate": 0.00032614727414251164,
        "gradient_norm": 0.308114230632782,
        "train_loss": 3.110077381134033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15656,
        "tokens": 8208252928,
        "learning_rate": 0.00032611863130665845,
        "gradient_norm": 0.2952161133289337,
        "train_loss": 3.092662811279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15657,
        "tokens": 8208777216,
        "learning_rate": 0.0003260899885144951,
        "gradient_norm": 0.2923438847064972,
        "train_loss": 3.0687756538391113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15658,
        "tokens": 8209301504,
        "learning_rate": 0.0003260613457663436,
        "gradient_norm": 0.3311062157154083,
        "train_loss": 3.0766396522521973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15659,
        "tokens": 8209825792,
        "learning_rate": 0.00032603270306252673,
        "gradient_norm": 0.3203240633010864,
        "train_loss": 3.124880790710449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15660,
        "tokens": 8210350080,
        "learning_rate": 0.0003260040604033667,
        "gradient_norm": 0.3015439212322235,
        "train_loss": 3.0007505416870117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15661,
        "tokens": 8210874368,
        "learning_rate": 0.00032597541778918595,
        "gradient_norm": 0.34854012727737427,
        "train_loss": 3.1078691482543945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15662,
        "tokens": 8211398656,
        "learning_rate": 0.00032594677522030676,
        "gradient_norm": 0.30546998977661133,
        "train_loss": 3.050720691680908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15663,
        "tokens": 8211922944,
        "learning_rate": 0.0003259181326970519,
        "gradient_norm": 0.3495771288871765,
        "train_loss": 3.0163049697875977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15664,
        "tokens": 8212447232,
        "learning_rate": 0.0003258894902197433,
        "gradient_norm": 0.30141401290893555,
        "train_loss": 3.0304455757141113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15665,
        "tokens": 8212971520,
        "learning_rate": 0.0003258608477887038,
        "gradient_norm": 0.3431496322154999,
        "train_loss": 3.1198697090148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15666,
        "tokens": 8213495808,
        "learning_rate": 0.0003258322054042555,
        "gradient_norm": 0.3217290937900543,
        "train_loss": 3.1023435592651367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15667,
        "tokens": 8214020096,
        "learning_rate": 0.0003258035630667209,
        "gradient_norm": 0.3156617283821106,
        "train_loss": 3.0490458011627197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15668,
        "tokens": 8214544384,
        "learning_rate": 0.00032577492077642253,
        "gradient_norm": 0.3205612301826477,
        "train_loss": 3.096552848815918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15669,
        "tokens": 8215068672,
        "learning_rate": 0.00032574627853368263,
        "gradient_norm": 0.3081446588039398,
        "train_loss": 3.056643009185791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15670,
        "tokens": 8215592960,
        "learning_rate": 0.00032571763633882376,
        "gradient_norm": 0.3315213620662689,
        "train_loss": 3.1402010917663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15671,
        "tokens": 8216117248,
        "learning_rate": 0.00032568899419216813,
        "gradient_norm": 0.3015074133872986,
        "train_loss": 3.0877163410186768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15672,
        "tokens": 8216641536,
        "learning_rate": 0.0003256603520940383,
        "gradient_norm": 0.3243245780467987,
        "train_loss": 3.0336809158325195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15673,
        "tokens": 8217165824,
        "learning_rate": 0.00032563171004475655,
        "gradient_norm": 0.2947077751159668,
        "train_loss": 3.050410747528076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15674,
        "tokens": 8217690112,
        "learning_rate": 0.0003256030680446455,
        "gradient_norm": 0.3144989013671875,
        "train_loss": 3.071708917617798,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15675,
        "tokens": 8218214400,
        "learning_rate": 0.0003255744260940272,
        "gradient_norm": 0.2810405194759369,
        "train_loss": 3.1010818481445312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15676,
        "tokens": 8218738688,
        "learning_rate": 0.0003255457841932243,
        "gradient_norm": 0.30834856629371643,
        "train_loss": 3.08180570602417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15677,
        "tokens": 8219262976,
        "learning_rate": 0.0003255171423425593,
        "gradient_norm": 0.28283318877220154,
        "train_loss": 3.0397558212280273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15678,
        "tokens": 8219787264,
        "learning_rate": 0.0003254885005423542,
        "gradient_norm": 0.3188382089138031,
        "train_loss": 3.1378331184387207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15679,
        "tokens": 8220311552,
        "learning_rate": 0.00032545985879293195,
        "gradient_norm": 0.29912087321281433,
        "train_loss": 3.0251922607421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15680,
        "tokens": 8220835840,
        "learning_rate": 0.0003254312170946144,
        "gradient_norm": 0.2752455770969391,
        "train_loss": 3.0359997749328613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15681,
        "tokens": 8221360128,
        "learning_rate": 0.0003254025754477244,
        "gradient_norm": 0.3227265179157257,
        "train_loss": 3.1126084327697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15682,
        "tokens": 8221884416,
        "learning_rate": 0.00032537393385258397,
        "gradient_norm": 0.3114990293979645,
        "train_loss": 3.0582215785980225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15683,
        "tokens": 8222408704,
        "learning_rate": 0.0003253452923095158,
        "gradient_norm": 0.32254377007484436,
        "train_loss": 3.1031110286712646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15684,
        "tokens": 8222932992,
        "learning_rate": 0.00032531665081884204,
        "gradient_norm": 0.3141108751296997,
        "train_loss": 3.0812854766845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15685,
        "tokens": 8223457280,
        "learning_rate": 0.00032528800938088536,
        "gradient_norm": 0.3132834732532501,
        "train_loss": 3.0373523235321045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15686,
        "tokens": 8223981568,
        "learning_rate": 0.0003252593679959679,
        "gradient_norm": 0.3408870995044708,
        "train_loss": 3.093683958053589,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15687,
        "tokens": 8224505856,
        "learning_rate": 0.00032523072666441216,
        "gradient_norm": 0.2941311299800873,
        "train_loss": 3.102785110473633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15688,
        "tokens": 8225030144,
        "learning_rate": 0.00032520208538654063,
        "gradient_norm": 0.2928909957408905,
        "train_loss": 3.0954763889312744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15689,
        "tokens": 8225554432,
        "learning_rate": 0.0003251734441626755,
        "gradient_norm": 0.29305499792099,
        "train_loss": 3.049447536468506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15690,
        "tokens": 8226078720,
        "learning_rate": 0.0003251448029931394,
        "gradient_norm": 0.30699461698532104,
        "train_loss": 3.0805160999298096,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15691,
        "tokens": 8226603008,
        "learning_rate": 0.0003251161618782545,
        "gradient_norm": 0.31119000911712646,
        "train_loss": 3.0952181816101074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15692,
        "tokens": 8227127296,
        "learning_rate": 0.0003250875208183433,
        "gradient_norm": 0.31928765773773193,
        "train_loss": 3.0701849460601807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15693,
        "tokens": 8227651584,
        "learning_rate": 0.00032505887981372814,
        "gradient_norm": 0.3439914584159851,
        "train_loss": 3.06835675239563,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15694,
        "tokens": 8228175872,
        "learning_rate": 0.00032503023886473157,
        "gradient_norm": 0.3216313421726227,
        "train_loss": 3.043788194656372,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15695,
        "tokens": 8228700160,
        "learning_rate": 0.0003250015979716757,
        "gradient_norm": 0.2842000722885132,
        "train_loss": 2.9540939331054688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15696,
        "tokens": 8229224448,
        "learning_rate": 0.0003249729571348832,
        "gradient_norm": 0.3204960823059082,
        "train_loss": 3.04740047454834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15697,
        "tokens": 8229748736,
        "learning_rate": 0.00032494431635467626,
        "gradient_norm": 0.31022214889526367,
        "train_loss": 3.0327324867248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15698,
        "tokens": 8230273024,
        "learning_rate": 0.0003249156756313774,
        "gradient_norm": 0.3125746250152588,
        "train_loss": 3.1379382610321045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15699,
        "tokens": 8230797312,
        "learning_rate": 0.0003248870349653089,
        "gradient_norm": 0.29719918966293335,
        "train_loss": 3.0879547595977783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15700,
        "tokens": 8231321600,
        "learning_rate": 0.00032485839435679323,
        "gradient_norm": 0.31915509700775146,
        "train_loss": 3.0522141456604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15701,
        "tokens": 8231845888,
        "learning_rate": 0.0003248297538061527,
        "gradient_norm": 0.2874755859375,
        "train_loss": 3.069974422454834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15702,
        "tokens": 8232370176,
        "learning_rate": 0.0003248011133137098,
        "gradient_norm": 0.30594703555107117,
        "train_loss": 3.062990188598633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15703,
        "tokens": 8232894464,
        "learning_rate": 0.0003247724728797868,
        "gradient_norm": 0.294736385345459,
        "train_loss": 3.046721935272217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15704,
        "tokens": 8233418752,
        "learning_rate": 0.0003247438325047061,
        "gradient_norm": 0.30533456802368164,
        "train_loss": 3.0676050186157227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15705,
        "tokens": 8233943040,
        "learning_rate": 0.0003247151921887902,
        "gradient_norm": 0.30259594321250916,
        "train_loss": 3.0732507705688477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15706,
        "tokens": 8234467328,
        "learning_rate": 0.0003246865519323614,
        "gradient_norm": 0.3192526400089264,
        "train_loss": 3.070598602294922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15707,
        "tokens": 8234991616,
        "learning_rate": 0.000324657911735742,
        "gradient_norm": 0.322630375623703,
        "train_loss": 3.1302201747894287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15708,
        "tokens": 8235515904,
        "learning_rate": 0.00032462927159925453,
        "gradient_norm": 0.3215499222278595,
        "train_loss": 3.0711357593536377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15709,
        "tokens": 8236040192,
        "learning_rate": 0.0003246006315232213,
        "gradient_norm": 0.3152255713939667,
        "train_loss": 3.104391098022461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15710,
        "tokens": 8236564480,
        "learning_rate": 0.00032457199150796466,
        "gradient_norm": 0.3165898621082306,
        "train_loss": 3.131615161895752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15711,
        "tokens": 8237088768,
        "learning_rate": 0.000324543351553807,
        "gradient_norm": 0.31625035405158997,
        "train_loss": 3.0779547691345215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15712,
        "tokens": 8237613056,
        "learning_rate": 0.00032451471166107076,
        "gradient_norm": 0.36423003673553467,
        "train_loss": 3.0195565223693848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15713,
        "tokens": 8238137344,
        "learning_rate": 0.00032448607183007826,
        "gradient_norm": 0.31275323033332825,
        "train_loss": 3.1062276363372803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15714,
        "tokens": 8238661632,
        "learning_rate": 0.00032445743206115194,
        "gradient_norm": 0.3621513843536377,
        "train_loss": 3.113328456878662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15715,
        "tokens": 8239185920,
        "learning_rate": 0.0003244287923546141,
        "gradient_norm": 0.3174845576286316,
        "train_loss": 3.094907283782959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15716,
        "tokens": 8239710208,
        "learning_rate": 0.0003244001527107871,
        "gradient_norm": 0.34773945808410645,
        "train_loss": 3.061201572418213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15717,
        "tokens": 8240234496,
        "learning_rate": 0.00032437151312999347,
        "gradient_norm": 0.2932009696960449,
        "train_loss": 3.1397864818573,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15718,
        "tokens": 8240758784,
        "learning_rate": 0.0003243428736125553,
        "gradient_norm": 0.33898410201072693,
        "train_loss": 3.0694761276245117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15719,
        "tokens": 8241283072,
        "learning_rate": 0.0003243142341587953,
        "gradient_norm": 0.3055543005466461,
        "train_loss": 3.146702289581299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15720,
        "tokens": 8241807360,
        "learning_rate": 0.0003242855947690356,
        "gradient_norm": 0.3728179335594177,
        "train_loss": 3.136380672454834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15721,
        "tokens": 8242331648,
        "learning_rate": 0.0003242569554435988,
        "gradient_norm": 0.32590657472610474,
        "train_loss": 3.071712017059326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15722,
        "tokens": 8242855936,
        "learning_rate": 0.0003242283161828069,
        "gradient_norm": 0.29780662059783936,
        "train_loss": 3.0487396717071533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15723,
        "tokens": 8243380224,
        "learning_rate": 0.0003241996769869827,
        "gradient_norm": 0.339568555355072,
        "train_loss": 3.0733654499053955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15724,
        "tokens": 8243904512,
        "learning_rate": 0.00032417103785644817,
        "gradient_norm": 0.2947080731391907,
        "train_loss": 3.060335159301758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15725,
        "tokens": 8244428800,
        "learning_rate": 0.0003241423987915259,
        "gradient_norm": 0.33351394534111023,
        "train_loss": 3.116614818572998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15726,
        "tokens": 8244953088,
        "learning_rate": 0.0003241137597925384,
        "gradient_norm": 0.31086376309394836,
        "train_loss": 3.0383987426757812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15727,
        "tokens": 8245477376,
        "learning_rate": 0.0003240851208598078,
        "gradient_norm": 0.3360910415649414,
        "train_loss": 3.058651924133301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15728,
        "tokens": 8246001664,
        "learning_rate": 0.00032405648199365655,
        "gradient_norm": 0.32986485958099365,
        "train_loss": 3.102451801300049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15729,
        "tokens": 8246525952,
        "learning_rate": 0.0003240278431944069,
        "gradient_norm": 0.3311765789985657,
        "train_loss": 3.110704183578491,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15730,
        "tokens": 8247050240,
        "learning_rate": 0.0003239992044623815,
        "gradient_norm": 0.32973480224609375,
        "train_loss": 3.1164023876190186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15731,
        "tokens": 8247574528,
        "learning_rate": 0.0003239705657979023,
        "gradient_norm": 0.31449979543685913,
        "train_loss": 3.1012890338897705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15732,
        "tokens": 8248098816,
        "learning_rate": 0.0003239419272012921,
        "gradient_norm": 0.308960884809494,
        "train_loss": 3.1281626224517822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15733,
        "tokens": 8248623104,
        "learning_rate": 0.00032391328867287293,
        "gradient_norm": 0.3056269586086273,
        "train_loss": 3.1416497230529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15734,
        "tokens": 8249147392,
        "learning_rate": 0.00032388465021296743,
        "gradient_norm": 0.31199437379837036,
        "train_loss": 3.1282639503479004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15735,
        "tokens": 8249671680,
        "learning_rate": 0.00032385601182189765,
        "gradient_norm": 0.3516731858253479,
        "train_loss": 3.2412445545196533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15736,
        "tokens": 8250195968,
        "learning_rate": 0.00032382737349998615,
        "gradient_norm": 0.3130870759487152,
        "train_loss": 3.07012939453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15737,
        "tokens": 8250720256,
        "learning_rate": 0.00032379873524755536,
        "gradient_norm": 0.30940383672714233,
        "train_loss": 3.083566188812256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15738,
        "tokens": 8251244544,
        "learning_rate": 0.0003237700970649274,
        "gradient_norm": 0.2932395339012146,
        "train_loss": 3.115893840789795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15739,
        "tokens": 8251768832,
        "learning_rate": 0.0003237414589524249,
        "gradient_norm": 0.31735700368881226,
        "train_loss": 3.0717129707336426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15740,
        "tokens": 8252293120,
        "learning_rate": 0.00032371282091037,
        "gradient_norm": 0.5283472537994385,
        "train_loss": 3.097227096557617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15741,
        "tokens": 8252817408,
        "learning_rate": 0.0003236841829390852,
        "gradient_norm": 0.5402923822402954,
        "train_loss": 3.1129071712493896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15742,
        "tokens": 8253341696,
        "learning_rate": 0.00032365554503889266,
        "gradient_norm": 0.3554961085319519,
        "train_loss": 3.0737075805664062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15743,
        "tokens": 8253865984,
        "learning_rate": 0.00032362690721011506,
        "gradient_norm": 0.4300013482570648,
        "train_loss": 3.1291089057922363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15744,
        "tokens": 8254390272,
        "learning_rate": 0.0003235982694530744,
        "gradient_norm": 0.401147723197937,
        "train_loss": 3.0863471031188965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15745,
        "tokens": 8254914560,
        "learning_rate": 0.0003235696317680932,
        "gradient_norm": 0.3696106970310211,
        "train_loss": 3.0532851219177246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15746,
        "tokens": 8255438848,
        "learning_rate": 0.0003235409941554939,
        "gradient_norm": 0.359993577003479,
        "train_loss": 3.0591132640838623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15747,
        "tokens": 8255963136,
        "learning_rate": 0.0003235123566155987,
        "gradient_norm": 0.3648752272129059,
        "train_loss": 3.032618522644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15748,
        "tokens": 8256487424,
        "learning_rate": 0.0003234837191487301,
        "gradient_norm": 0.3066219091415405,
        "train_loss": 3.0919148921966553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15749,
        "tokens": 8257011712,
        "learning_rate": 0.00032345508175521024,
        "gradient_norm": 0.3407250940799713,
        "train_loss": 3.092545509338379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15750,
        "tokens": 8257536000,
        "learning_rate": 0.00032342644443536175,
        "gradient_norm": 0.2916162610054016,
        "train_loss": 3.032099723815918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15751,
        "tokens": 8258060288,
        "learning_rate": 0.00032339780718950665,
        "gradient_norm": 0.3218332529067993,
        "train_loss": 3.0464367866516113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15752,
        "tokens": 8258584576,
        "learning_rate": 0.00032336917001796764,
        "gradient_norm": 0.304476261138916,
        "train_loss": 3.0262608528137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15753,
        "tokens": 8259108864,
        "learning_rate": 0.00032334053292106674,
        "gradient_norm": 0.32921311259269714,
        "train_loss": 3.135830879211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15754,
        "tokens": 8259633152,
        "learning_rate": 0.00032331189589912654,
        "gradient_norm": 0.34450405836105347,
        "train_loss": 3.0559306144714355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15755,
        "tokens": 8260157440,
        "learning_rate": 0.00032328325895246917,
        "gradient_norm": 0.31349673867225647,
        "train_loss": 3.0573246479034424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15756,
        "tokens": 8260681728,
        "learning_rate": 0.0003232546220814172,
        "gradient_norm": 0.3056652545928955,
        "train_loss": 3.0716724395751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15757,
        "tokens": 8261206016,
        "learning_rate": 0.00032322598528629283,
        "gradient_norm": 0.311325341463089,
        "train_loss": 3.1087145805358887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15758,
        "tokens": 8261730304,
        "learning_rate": 0.0003231973485674184,
        "gradient_norm": 0.31956401467323303,
        "train_loss": 3.1294162273406982,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15759,
        "tokens": 8262254592,
        "learning_rate": 0.00032316871192511633,
        "gradient_norm": 0.29409465193748474,
        "train_loss": 3.078423023223877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15760,
        "tokens": 8262778880,
        "learning_rate": 0.00032314007535970895,
        "gradient_norm": 0.29380467534065247,
        "train_loss": 3.088913917541504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15761,
        "tokens": 8263303168,
        "learning_rate": 0.00032311143887151856,
        "gradient_norm": 0.3128219544887543,
        "train_loss": 3.102949380874634,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15762,
        "tokens": 8263827456,
        "learning_rate": 0.0003230828024608675,
        "gradient_norm": 0.2783184349536896,
        "train_loss": 3.107215404510498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15763,
        "tokens": 8264351744,
        "learning_rate": 0.0003230541661280781,
        "gradient_norm": 0.3112640678882599,
        "train_loss": 3.0811262130737305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15764,
        "tokens": 8264876032,
        "learning_rate": 0.00032302552987347274,
        "gradient_norm": 0.271180123090744,
        "train_loss": 3.054161548614502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15765,
        "tokens": 8265400320,
        "learning_rate": 0.0003229968936973737,
        "gradient_norm": 0.3307841718196869,
        "train_loss": 3.1521029472351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15766,
        "tokens": 8265924608,
        "learning_rate": 0.00032296825760010344,
        "gradient_norm": 0.33256253600120544,
        "train_loss": 3.114258289337158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15767,
        "tokens": 8266448896,
        "learning_rate": 0.0003229396215819841,
        "gradient_norm": 0.33118489384651184,
        "train_loss": 3.052725315093994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15768,
        "tokens": 8266973184,
        "learning_rate": 0.00032291098564333825,
        "gradient_norm": 0.3495071232318878,
        "train_loss": 3.0477676391601562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15769,
        "tokens": 8267497472,
        "learning_rate": 0.00032288234978448797,
        "gradient_norm": 0.28591984510421753,
        "train_loss": 2.999699115753174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15770,
        "tokens": 8268021760,
        "learning_rate": 0.0003228537140057558,
        "gradient_norm": 0.3267756402492523,
        "train_loss": 3.0686066150665283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15771,
        "tokens": 8268546048,
        "learning_rate": 0.00032282507830746387,
        "gradient_norm": 0.32147496938705444,
        "train_loss": 3.058102607727051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15772,
        "tokens": 8269070336,
        "learning_rate": 0.0003227964426899348,
        "gradient_norm": 0.3400053083896637,
        "train_loss": 3.1298704147338867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15773,
        "tokens": 8269594624,
        "learning_rate": 0.0003227678071534906,
        "gradient_norm": 0.2946917712688446,
        "train_loss": 3.0533547401428223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15774,
        "tokens": 8270118912,
        "learning_rate": 0.00032273917169845385,
        "gradient_norm": 0.2967430651187897,
        "train_loss": 3.0323314666748047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15775,
        "tokens": 8270643200,
        "learning_rate": 0.00032271053632514665,
        "gradient_norm": 0.2916059195995331,
        "train_loss": 3.0514795780181885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15776,
        "tokens": 8271167488,
        "learning_rate": 0.0003226819010338915,
        "gradient_norm": 0.30919766426086426,
        "train_loss": 3.080277681350708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15777,
        "tokens": 8271691776,
        "learning_rate": 0.0003226532658250107,
        "gradient_norm": 0.3040107488632202,
        "train_loss": 3.0998733043670654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15778,
        "tokens": 8272216064,
        "learning_rate": 0.00032262463069882653,
        "gradient_norm": 0.3247179388999939,
        "train_loss": 3.058227777481079,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15779,
        "tokens": 8272740352,
        "learning_rate": 0.00032259599565566144,
        "gradient_norm": 0.2922999858856201,
        "train_loss": 3.0570566654205322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15780,
        "tokens": 8273264640,
        "learning_rate": 0.00032256736069583746,
        "gradient_norm": 0.33230939507484436,
        "train_loss": 3.1625378131866455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15781,
        "tokens": 8273788928,
        "learning_rate": 0.0003225387258196773,
        "gradient_norm": 0.3000350892543793,
        "train_loss": 3.02754282951355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15782,
        "tokens": 8274313216,
        "learning_rate": 0.00032251009102750295,
        "gradient_norm": 0.3045148551464081,
        "train_loss": 3.086268663406372,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15783,
        "tokens": 8274837504,
        "learning_rate": 0.0003224814563196369,
        "gradient_norm": 0.2928713858127594,
        "train_loss": 3.026702404022217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15784,
        "tokens": 8275361792,
        "learning_rate": 0.0003224528216964014,
        "gradient_norm": 0.31840378046035767,
        "train_loss": 3.0504703521728516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15785,
        "tokens": 8275886080,
        "learning_rate": 0.0003224241871581188,
        "gradient_norm": 0.3810994625091553,
        "train_loss": 3.059457540512085,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15786,
        "tokens": 8276410368,
        "learning_rate": 0.00032239555270511145,
        "gradient_norm": 0.29196155071258545,
        "train_loss": 3.0119500160217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15787,
        "tokens": 8276934656,
        "learning_rate": 0.0003223669183377016,
        "gradient_norm": 0.3130491077899933,
        "train_loss": 3.0439014434814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15788,
        "tokens": 8277458944,
        "learning_rate": 0.0003223382840562117,
        "gradient_norm": 0.30258142948150635,
        "train_loss": 3.0673458576202393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15789,
        "tokens": 8277983232,
        "learning_rate": 0.0003223096498609638,
        "gradient_norm": 0.3042493164539337,
        "train_loss": 3.0411481857299805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15790,
        "tokens": 8278507520,
        "learning_rate": 0.00032228101575228056,
        "gradient_norm": 0.2981838583946228,
        "train_loss": 3.163912057876587,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15791,
        "tokens": 8279031808,
        "learning_rate": 0.00032225238173048395,
        "gradient_norm": 0.3251562714576721,
        "train_loss": 3.095227003097534,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15792,
        "tokens": 8279556096,
        "learning_rate": 0.00032222374779589656,
        "gradient_norm": 0.30980244278907776,
        "train_loss": 3.054112195968628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15793,
        "tokens": 8280080384,
        "learning_rate": 0.0003221951139488405,
        "gradient_norm": 0.2927698493003845,
        "train_loss": 3.0164248943328857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15794,
        "tokens": 8280604672,
        "learning_rate": 0.00032216648018963825,
        "gradient_norm": 0.28891807794570923,
        "train_loss": 3.01218318939209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15795,
        "tokens": 8281128960,
        "learning_rate": 0.0003221378465186119,
        "gradient_norm": 0.29192861914634705,
        "train_loss": 3.0816879272460938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15796,
        "tokens": 8281653248,
        "learning_rate": 0.00032210921293608386,
        "gradient_norm": 0.2933638393878937,
        "train_loss": 3.109386444091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15797,
        "tokens": 8282177536,
        "learning_rate": 0.00032208057944237665,
        "gradient_norm": 0.29795435070991516,
        "train_loss": 3.106966972351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15798,
        "tokens": 8282701824,
        "learning_rate": 0.0003220519460378123,
        "gradient_norm": 0.2965954840183258,
        "train_loss": 3.0753111839294434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15799,
        "tokens": 8283226112,
        "learning_rate": 0.00032202331272271323,
        "gradient_norm": 0.2963680922985077,
        "train_loss": 3.1016016006469727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15800,
        "tokens": 8283750400,
        "learning_rate": 0.00032199467949740163,
        "gradient_norm": 0.28092893958091736,
        "train_loss": 3.0560851097106934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15801,
        "tokens": 8284274688,
        "learning_rate": 0.0003219660463622,
        "gradient_norm": 0.3274025022983551,
        "train_loss": 3.071803331375122,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15802,
        "tokens": 8284798976,
        "learning_rate": 0.00032193741331743047,
        "gradient_norm": 0.2896084487438202,
        "train_loss": 3.074165105819702,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15803,
        "tokens": 8285323264,
        "learning_rate": 0.00032190878036341547,
        "gradient_norm": 0.3123665750026703,
        "train_loss": 3.0865793228149414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15804,
        "tokens": 8285847552,
        "learning_rate": 0.00032188014750047714,
        "gradient_norm": 0.2932773530483246,
        "train_loss": 3.081181049346924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15805,
        "tokens": 8286371840,
        "learning_rate": 0.0003218515147289379,
        "gradient_norm": 0.30334872007369995,
        "train_loss": 2.9953670501708984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15806,
        "tokens": 8286896128,
        "learning_rate": 0.0003218228820491201,
        "gradient_norm": 0.29669389128685,
        "train_loss": 3.065645217895508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15807,
        "tokens": 8287420416,
        "learning_rate": 0.00032179424946134587,
        "gradient_norm": 0.29239726066589355,
        "train_loss": 3.0944719314575195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15808,
        "tokens": 8287944704,
        "learning_rate": 0.0003217656169659376,
        "gradient_norm": 0.3173767626285553,
        "train_loss": 3.013716459274292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15809,
        "tokens": 8288468992,
        "learning_rate": 0.0003217369845632176,
        "gradient_norm": 0.26043128967285156,
        "train_loss": 3.0807504653930664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15810,
        "tokens": 8288993280,
        "learning_rate": 0.00032170835225350813,
        "gradient_norm": 0.2927522659301758,
        "train_loss": 3.0692036151885986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15811,
        "tokens": 8289517568,
        "learning_rate": 0.0003216797200371315,
        "gradient_norm": 0.2750115394592285,
        "train_loss": 3.0775489807128906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15812,
        "tokens": 8290041856,
        "learning_rate": 0.00032165108791440996,
        "gradient_norm": 0.3239035904407501,
        "train_loss": 3.1001129150390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15813,
        "tokens": 8290566144,
        "learning_rate": 0.0003216224558856659,
        "gradient_norm": 0.2983216643333435,
        "train_loss": 3.1463847160339355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15814,
        "tokens": 8291090432,
        "learning_rate": 0.0003215938239512215,
        "gradient_norm": 0.31645381450653076,
        "train_loss": 3.0643815994262695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15815,
        "tokens": 8291614720,
        "learning_rate": 0.00032156519211139906,
        "gradient_norm": 0.3096887469291687,
        "train_loss": 3.1335391998291016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15816,
        "tokens": 8292139008,
        "learning_rate": 0.0003215365603665209,
        "gradient_norm": 0.3312504291534424,
        "train_loss": 3.0949795246124268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15817,
        "tokens": 8292663296,
        "learning_rate": 0.0003215079287169094,
        "gradient_norm": 0.31579768657684326,
        "train_loss": 3.0454349517822266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15818,
        "tokens": 8293187584,
        "learning_rate": 0.0003214792971628866,
        "gradient_norm": 0.34088829159736633,
        "train_loss": 3.1357555389404297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15819,
        "tokens": 8293711872,
        "learning_rate": 0.0003214506657047751,
        "gradient_norm": 0.3226417601108551,
        "train_loss": 3.0633435249328613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15820,
        "tokens": 8294236160,
        "learning_rate": 0.0003214220343428968,
        "gradient_norm": 0.28314852714538574,
        "train_loss": 3.155308723449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15821,
        "tokens": 8294760448,
        "learning_rate": 0.0003213934030775744,
        "gradient_norm": 0.32999733090400696,
        "train_loss": 3.117079257965088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15822,
        "tokens": 8295284736,
        "learning_rate": 0.00032136477190912986,
        "gradient_norm": 0.2986305058002472,
        "train_loss": 3.1250391006469727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15823,
        "tokens": 8295809024,
        "learning_rate": 0.00032133614083788565,
        "gradient_norm": 0.35226568579673767,
        "train_loss": 3.097999095916748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15824,
        "tokens": 8296333312,
        "learning_rate": 0.0003213075098641639,
        "gradient_norm": 0.2790471911430359,
        "train_loss": 3.1461708545684814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15825,
        "tokens": 8296857600,
        "learning_rate": 0.0003212788789882869,
        "gradient_norm": 0.3146822452545166,
        "train_loss": 3.096112012863159,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15826,
        "tokens": 8297381888,
        "learning_rate": 0.0003212502482105772,
        "gradient_norm": 0.2856835126876831,
        "train_loss": 3.1075034141540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15827,
        "tokens": 8297906176,
        "learning_rate": 0.0003212216175313567,
        "gradient_norm": 0.321231871843338,
        "train_loss": 3.0648789405822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15828,
        "tokens": 8298430464,
        "learning_rate": 0.0003211929869509479,
        "gradient_norm": 0.29669007658958435,
        "train_loss": 3.1105809211730957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15829,
        "tokens": 8298954752,
        "learning_rate": 0.000321164356469673,
        "gradient_norm": 0.3093816637992859,
        "train_loss": 3.042300224304199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15830,
        "tokens": 8299479040,
        "learning_rate": 0.0003211357260878543,
        "gradient_norm": 0.32183951139450073,
        "train_loss": 3.0867016315460205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15831,
        "tokens": 8300003328,
        "learning_rate": 0.00032110709580581397,
        "gradient_norm": 0.3180798292160034,
        "train_loss": 3.1108644008636475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15832,
        "tokens": 8300527616,
        "learning_rate": 0.0003210784656238745,
        "gradient_norm": 0.32341688871383667,
        "train_loss": 3.0842809677124023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15833,
        "tokens": 8301051904,
        "learning_rate": 0.0003210498355423579,
        "gradient_norm": 0.32926493883132935,
        "train_loss": 3.0865120887756348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15834,
        "tokens": 8301576192,
        "learning_rate": 0.00032102120556158663,
        "gradient_norm": 0.3433757424354553,
        "train_loss": 3.125669479370117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15835,
        "tokens": 8302100480,
        "learning_rate": 0.0003209925756818828,
        "gradient_norm": 0.322724312543869,
        "train_loss": 3.068471908569336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15836,
        "tokens": 8302624768,
        "learning_rate": 0.00032096394590356875,
        "gradient_norm": 0.29753655195236206,
        "train_loss": 3.1197309494018555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15837,
        "tokens": 8303149056,
        "learning_rate": 0.0003209353162269669,
        "gradient_norm": 0.3023103177547455,
        "train_loss": 3.0862996578216553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15838,
        "tokens": 8303673344,
        "learning_rate": 0.0003209066866523992,
        "gradient_norm": 0.32530999183654785,
        "train_loss": 3.0815582275390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15839,
        "tokens": 8304197632,
        "learning_rate": 0.00032087805718018824,
        "gradient_norm": 0.28078630566596985,
        "train_loss": 3.010812759399414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15840,
        "tokens": 8304721920,
        "learning_rate": 0.000320849427810656,
        "gradient_norm": 0.31733807921409607,
        "train_loss": 3.098461627960205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15841,
        "tokens": 8305246208,
        "learning_rate": 0.00032082079854412496,
        "gradient_norm": 0.3096652925014496,
        "train_loss": 3.1704583168029785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15842,
        "tokens": 8305770496,
        "learning_rate": 0.00032079216938091714,
        "gradient_norm": 0.3125373125076294,
        "train_loss": 3.1333775520324707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15843,
        "tokens": 8306294784,
        "learning_rate": 0.00032076354032135505,
        "gradient_norm": 0.28969821333885193,
        "train_loss": 3.1386208534240723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15844,
        "tokens": 8306819072,
        "learning_rate": 0.0003207349113657607,
        "gradient_norm": 0.2985106110572815,
        "train_loss": 3.138683795928955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15845,
        "tokens": 8307343360,
        "learning_rate": 0.0003207062825144565,
        "gradient_norm": 0.31489551067352295,
        "train_loss": 3.091810703277588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15846,
        "tokens": 8307867648,
        "learning_rate": 0.0003206776537677648,
        "gradient_norm": 0.30987823009490967,
        "train_loss": 3.120217800140381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15847,
        "tokens": 8308391936,
        "learning_rate": 0.00032064902512600756,
        "gradient_norm": 0.28539571166038513,
        "train_loss": 3.104982614517212,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15848,
        "tokens": 8308916224,
        "learning_rate": 0.00032062039658950736,
        "gradient_norm": 0.2918696999549866,
        "train_loss": 3.037665605545044,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15849,
        "tokens": 8309440512,
        "learning_rate": 0.00032059176815858617,
        "gradient_norm": 0.303611159324646,
        "train_loss": 3.0860955715179443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15850,
        "tokens": 8309964800,
        "learning_rate": 0.0003205631398335665,
        "gradient_norm": 0.3034685254096985,
        "train_loss": 3.135040283203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15851,
        "tokens": 8310489088,
        "learning_rate": 0.0003205345116147703,
        "gradient_norm": 0.2879931628704071,
        "train_loss": 3.096355676651001,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15852,
        "tokens": 8311013376,
        "learning_rate": 0.00032050588350252007,
        "gradient_norm": 0.32524967193603516,
        "train_loss": 3.1372861862182617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15853,
        "tokens": 8311537664,
        "learning_rate": 0.0003204772554971378,
        "gradient_norm": 0.3091786503791809,
        "train_loss": 3.1738314628601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15854,
        "tokens": 8312061952,
        "learning_rate": 0.0003204486275989461,
        "gradient_norm": 0.324807345867157,
        "train_loss": 3.183931827545166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15855,
        "tokens": 8312586240,
        "learning_rate": 0.0003204199998082669,
        "gradient_norm": 0.3342052102088928,
        "train_loss": 3.0719499588012695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15856,
        "tokens": 8313110528,
        "learning_rate": 0.00032039137212542255,
        "gradient_norm": 0.33259546756744385,
        "train_loss": 3.0417065620422363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15857,
        "tokens": 8313634816,
        "learning_rate": 0.0003203627445507352,
        "gradient_norm": 0.3081800639629364,
        "train_loss": 3.1151609420776367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15858,
        "tokens": 8314159104,
        "learning_rate": 0.0003203341170845273,
        "gradient_norm": 0.3841612637042999,
        "train_loss": 3.128502607345581,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15859,
        "tokens": 8314683392,
        "learning_rate": 0.00032030548972712095,
        "gradient_norm": 0.3697771430015564,
        "train_loss": 3.1284689903259277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15860,
        "tokens": 8315207680,
        "learning_rate": 0.0003202768624788384,
        "gradient_norm": 0.3183833956718445,
        "train_loss": 3.0732991695404053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15861,
        "tokens": 8315731968,
        "learning_rate": 0.0003202482353400018,
        "gradient_norm": 0.34902721643447876,
        "train_loss": 3.111379623413086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15862,
        "tokens": 8316256256,
        "learning_rate": 0.00032021960831093353,
        "gradient_norm": 0.2997669577598572,
        "train_loss": 3.118967056274414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15863,
        "tokens": 8316780544,
        "learning_rate": 0.00032019098139195575,
        "gradient_norm": 0.32689353823661804,
        "train_loss": 3.061990737915039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15864,
        "tokens": 8317304832,
        "learning_rate": 0.00032016235458339073,
        "gradient_norm": 0.30762889981269836,
        "train_loss": 3.092637062072754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15865,
        "tokens": 8317829120,
        "learning_rate": 0.00032013372788556053,
        "gradient_norm": 0.3103024363517761,
        "train_loss": 3.0889809131622314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15866,
        "tokens": 8318353408,
        "learning_rate": 0.0003201051012987877,
        "gradient_norm": 0.33568042516708374,
        "train_loss": 3.149610996246338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15867,
        "tokens": 8318877696,
        "learning_rate": 0.0003200764748233942,
        "gradient_norm": 0.3023186922073364,
        "train_loss": 3.0945353507995605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15868,
        "tokens": 8319401984,
        "learning_rate": 0.0003200478484597024,
        "gradient_norm": 0.30426087975502014,
        "train_loss": 3.090423583984375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15869,
        "tokens": 8319926272,
        "learning_rate": 0.00032001922220803436,
        "gradient_norm": 0.3157757818698883,
        "train_loss": 3.1331472396850586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15870,
        "tokens": 8320450560,
        "learning_rate": 0.0003199905960687126,
        "gradient_norm": 0.30473601818084717,
        "train_loss": 3.128765106201172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15871,
        "tokens": 8320974848,
        "learning_rate": 0.000319961970042059,
        "gradient_norm": 0.303084135055542,
        "train_loss": 3.0939793586730957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15872,
        "tokens": 8321499136,
        "learning_rate": 0.00031993334412839603,
        "gradient_norm": 0.2743389904499054,
        "train_loss": 3.113424301147461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15873,
        "tokens": 8322023424,
        "learning_rate": 0.00031990471832804573,
        "gradient_norm": 0.27474892139434814,
        "train_loss": 3.0776078701019287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15874,
        "tokens": 8322547712,
        "learning_rate": 0.0003198760926413305,
        "gradient_norm": 0.26881977915763855,
        "train_loss": 3.0708985328674316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15875,
        "tokens": 8323072000,
        "learning_rate": 0.0003198474670685724,
        "gradient_norm": 0.276752233505249,
        "train_loss": 3.070937156677246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15876,
        "tokens": 8323596288,
        "learning_rate": 0.0003198188416100937,
        "gradient_norm": 0.31517964601516724,
        "train_loss": 3.1054835319519043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15877,
        "tokens": 8324120576,
        "learning_rate": 0.0003197902162662167,
        "gradient_norm": 0.3101446330547333,
        "train_loss": 3.08205509185791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15878,
        "tokens": 8324644864,
        "learning_rate": 0.00031976159103726346,
        "gradient_norm": 0.3022288382053375,
        "train_loss": 3.079845666885376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15879,
        "tokens": 8325169152,
        "learning_rate": 0.0003197329659235564,
        "gradient_norm": 0.3176957964897156,
        "train_loss": 3.0599753856658936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15880,
        "tokens": 8325693440,
        "learning_rate": 0.0003197043409254175,
        "gradient_norm": 0.2843775749206543,
        "train_loss": 3.0410685539245605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15881,
        "tokens": 8326217728,
        "learning_rate": 0.0003196757160431692,
        "gradient_norm": 0.30657675862312317,
        "train_loss": 3.0958757400512695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15882,
        "tokens": 8326742016,
        "learning_rate": 0.0003196470912771334,
        "gradient_norm": 0.30300796031951904,
        "train_loss": 3.1435468196868896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15883,
        "tokens": 8327266304,
        "learning_rate": 0.00031961846662763267,
        "gradient_norm": 0.29342055320739746,
        "train_loss": 3.093822479248047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15884,
        "tokens": 8327790592,
        "learning_rate": 0.0003195898420949889,
        "gradient_norm": 0.3305230140686035,
        "train_loss": 3.12286376953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15885,
        "tokens": 8328314880,
        "learning_rate": 0.00031956121767952447,
        "gradient_norm": 0.3072073757648468,
        "train_loss": 3.102451801300049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15886,
        "tokens": 8328839168,
        "learning_rate": 0.00031953259338156164,
        "gradient_norm": 0.3377726078033447,
        "train_loss": 3.0727386474609375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15887,
        "tokens": 8329363456,
        "learning_rate": 0.00031950396920142236,
        "gradient_norm": 0.3622143268585205,
        "train_loss": 3.149857997894287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15888,
        "tokens": 8329887744,
        "learning_rate": 0.00031947534513942913,
        "gradient_norm": 0.3417658507823944,
        "train_loss": 3.147630453109741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15889,
        "tokens": 8330412032,
        "learning_rate": 0.0003194467211959039,
        "gradient_norm": 0.41378095746040344,
        "train_loss": 3.1253466606140137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15890,
        "tokens": 8330936320,
        "learning_rate": 0.00031941809737116915,
        "gradient_norm": 0.3256267309188843,
        "train_loss": 3.0657620429992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15891,
        "tokens": 8331460608,
        "learning_rate": 0.00031938947366554673,
        "gradient_norm": 0.3874032199382782,
        "train_loss": 3.1192331314086914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15892,
        "tokens": 8331984896,
        "learning_rate": 0.0003193608500793591,
        "gradient_norm": 0.29515931010246277,
        "train_loss": 3.1371610164642334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15893,
        "tokens": 8332509184,
        "learning_rate": 0.0003193322266129283,
        "gradient_norm": 0.37161728739738464,
        "train_loss": 3.092299461364746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15894,
        "tokens": 8333033472,
        "learning_rate": 0.00031930360326657667,
        "gradient_norm": 0.2917880117893219,
        "train_loss": 3.1114726066589355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15895,
        "tokens": 8333557760,
        "learning_rate": 0.0003192749800406262,
        "gradient_norm": 0.3687584400177002,
        "train_loss": 3.122624158859253,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15896,
        "tokens": 8334082048,
        "learning_rate": 0.00031924635693539923,
        "gradient_norm": 0.3141612112522125,
        "train_loss": 3.092484474182129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15897,
        "tokens": 8334606336,
        "learning_rate": 0.00031921773395121806,
        "gradient_norm": 0.3743480443954468,
        "train_loss": 3.2499024868011475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15898,
        "tokens": 8335130624,
        "learning_rate": 0.0003191891110884046,
        "gradient_norm": 0.2968961000442505,
        "train_loss": 3.0887818336486816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15899,
        "tokens": 8335654912,
        "learning_rate": 0.00031916048834728126,
        "gradient_norm": 0.31488338112831116,
        "train_loss": 3.12187123298645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15900,
        "tokens": 8336179200,
        "learning_rate": 0.00031913186572817,
        "gradient_norm": 0.34272974729537964,
        "train_loss": 3.0588812828063965,
        "val_loss": 3.0657405853271484,
        "hellaswag_acc": 0.2800239026546478,
        "hellaswag_acc_norm": 0.29038041830062866
    },
    {
        "step": 15901,
        "tokens": 8336703488,
        "learning_rate": 0.0003191032432313933,
        "gradient_norm": 0.31278133392333984,
        "train_loss": 3.104922294616699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15902,
        "tokens": 8337227776,
        "learning_rate": 0.000319074620857273,
        "gradient_norm": 0.3083566427230835,
        "train_loss": 3.1071977615356445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15903,
        "tokens": 8337752064,
        "learning_rate": 0.00031904599860613166,
        "gradient_norm": 0.35693252086639404,
        "train_loss": 3.0688836574554443,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15904,
        "tokens": 8338276352,
        "learning_rate": 0.0003190173764782911,
        "gradient_norm": 0.34880775213241577,
        "train_loss": 3.038438320159912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15905,
        "tokens": 8338800640,
        "learning_rate": 0.0003189887544740737,
        "gradient_norm": 0.35275548696517944,
        "train_loss": 3.094780921936035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15906,
        "tokens": 8339324928,
        "learning_rate": 0.00031896013259380163,
        "gradient_norm": 0.3141692280769348,
        "train_loss": 3.1186342239379883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15907,
        "tokens": 8339849216,
        "learning_rate": 0.00031893151083779703,
        "gradient_norm": 0.278242290019989,
        "train_loss": 3.071136951446533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15908,
        "tokens": 8340373504,
        "learning_rate": 0.00031890288920638206,
        "gradient_norm": 0.3094693720340729,
        "train_loss": 3.108017921447754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15909,
        "tokens": 8340897792,
        "learning_rate": 0.0003188742676998789,
        "gradient_norm": 0.2833409607410431,
        "train_loss": 3.0778136253356934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15910,
        "tokens": 8341422080,
        "learning_rate": 0.00031884564631860974,
        "gradient_norm": 0.3002690076828003,
        "train_loss": 3.0696451663970947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15911,
        "tokens": 8341946368,
        "learning_rate": 0.00031881702506289674,
        "gradient_norm": 0.28153905272483826,
        "train_loss": 3.0819311141967773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15912,
        "tokens": 8342470656,
        "learning_rate": 0.000318788403933062,
        "gradient_norm": 0.292512983083725,
        "train_loss": 3.0816662311553955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15913,
        "tokens": 8342994944,
        "learning_rate": 0.0003187597829294278,
        "gradient_norm": 0.29340192675590515,
        "train_loss": 3.1327972412109375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15914,
        "tokens": 8343519232,
        "learning_rate": 0.0003187311620523163,
        "gradient_norm": 0.2995562255382538,
        "train_loss": 3.086989164352417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15915,
        "tokens": 8344043520,
        "learning_rate": 0.00031870254130204954,
        "gradient_norm": 0.2861860692501068,
        "train_loss": 3.099315643310547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15916,
        "tokens": 8344567808,
        "learning_rate": 0.00031867392067894975,
        "gradient_norm": 0.3010123670101166,
        "train_loss": 3.094299793243408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15917,
        "tokens": 8345092096,
        "learning_rate": 0.0003186453001833391,
        "gradient_norm": 0.29485905170440674,
        "train_loss": 3.0935916900634766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15918,
        "tokens": 8345616384,
        "learning_rate": 0.00031861667981553977,
        "gradient_norm": 0.2770698666572571,
        "train_loss": 3.1381704807281494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15919,
        "tokens": 8346140672,
        "learning_rate": 0.000318588059575874,
        "gradient_norm": 0.29097017645835876,
        "train_loss": 3.0493617057800293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15920,
        "tokens": 8346664960,
        "learning_rate": 0.0003185594394646637,
        "gradient_norm": 0.2818724811077118,
        "train_loss": 3.0678248405456543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15921,
        "tokens": 8347189248,
        "learning_rate": 0.00031853081948223123,
        "gradient_norm": 0.3089410960674286,
        "train_loss": 3.1207427978515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15922,
        "tokens": 8347713536,
        "learning_rate": 0.0003185021996288987,
        "gradient_norm": 0.28708621859550476,
        "train_loss": 3.140498638153076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15923,
        "tokens": 8348237824,
        "learning_rate": 0.00031847357990498823,
        "gradient_norm": 0.3073529303073883,
        "train_loss": 3.0817365646362305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15924,
        "tokens": 8348762112,
        "learning_rate": 0.000318444960310822,
        "gradient_norm": 0.31344249844551086,
        "train_loss": 3.1423726081848145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15925,
        "tokens": 8349286400,
        "learning_rate": 0.00031841634084672207,
        "gradient_norm": 0.29045066237449646,
        "train_loss": 3.095792293548584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15926,
        "tokens": 8349810688,
        "learning_rate": 0.0003183877215130108,
        "gradient_norm": 0.315622478723526,
        "train_loss": 3.0747385025024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15927,
        "tokens": 8350334976,
        "learning_rate": 0.00031835910231001007,
        "gradient_norm": 0.31856343150138855,
        "train_loss": 3.0762505531311035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15928,
        "tokens": 8350859264,
        "learning_rate": 0.00031833048323804227,
        "gradient_norm": 0.29298731684684753,
        "train_loss": 3.0552821159362793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15929,
        "tokens": 8351383552,
        "learning_rate": 0.0003183018642974293,
        "gradient_norm": 0.32030150294303894,
        "train_loss": 3.129847526550293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15930,
        "tokens": 8351907840,
        "learning_rate": 0.00031827324548849357,
        "gradient_norm": 0.3051995635032654,
        "train_loss": 3.1595067977905273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15931,
        "tokens": 8352432128,
        "learning_rate": 0.00031824462681155695,
        "gradient_norm": 0.3324742317199707,
        "train_loss": 3.082159996032715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15932,
        "tokens": 8352956416,
        "learning_rate": 0.00031821600826694184,
        "gradient_norm": 0.33988404273986816,
        "train_loss": 3.0806384086608887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15933,
        "tokens": 8353480704,
        "learning_rate": 0.0003181873898549701,
        "gradient_norm": 0.31091612577438354,
        "train_loss": 3.1314737796783447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15934,
        "tokens": 8354004992,
        "learning_rate": 0.00031815877157596417,
        "gradient_norm": 0.32040515542030334,
        "train_loss": 3.113612651824951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15935,
        "tokens": 8354529280,
        "learning_rate": 0.00031813015343024585,
        "gradient_norm": 0.3480457663536072,
        "train_loss": 3.1145853996276855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15936,
        "tokens": 8355053568,
        "learning_rate": 0.0003181015354181375,
        "gradient_norm": 0.30746009945869446,
        "train_loss": 3.124314785003662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15937,
        "tokens": 8355577856,
        "learning_rate": 0.0003180729175399613,
        "gradient_norm": 0.3324924409389496,
        "train_loss": 3.041142463684082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15938,
        "tokens": 8356102144,
        "learning_rate": 0.00031804429979603914,
        "gradient_norm": 0.33070018887519836,
        "train_loss": 3.0721054077148438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15939,
        "tokens": 8356626432,
        "learning_rate": 0.0003180156821866934,
        "gradient_norm": 0.31664642691612244,
        "train_loss": 3.117116928100586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15940,
        "tokens": 8357150720,
        "learning_rate": 0.0003179870647122461,
        "gradient_norm": 0.3327920138835907,
        "train_loss": 3.080897092819214,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15941,
        "tokens": 8357675008,
        "learning_rate": 0.00031795844737301935,
        "gradient_norm": 0.2803037464618683,
        "train_loss": 3.08848237991333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15942,
        "tokens": 8358199296,
        "learning_rate": 0.0003179298301693352,
        "gradient_norm": 0.3615504205226898,
        "train_loss": 3.106753349304199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15943,
        "tokens": 8358723584,
        "learning_rate": 0.00031790121310151597,
        "gradient_norm": 0.26565057039260864,
        "train_loss": 3.0684304237365723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15944,
        "tokens": 8359247872,
        "learning_rate": 0.00031787259616988356,
        "gradient_norm": 0.35129913687705994,
        "train_loss": 3.136996269226074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15945,
        "tokens": 8359772160,
        "learning_rate": 0.0003178439793747602,
        "gradient_norm": 0.3335261046886444,
        "train_loss": 3.0761280059814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15946,
        "tokens": 8360296448,
        "learning_rate": 0.0003178153627164681,
        "gradient_norm": 0.3534071445465088,
        "train_loss": 3.1351962089538574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15947,
        "tokens": 8360820736,
        "learning_rate": 0.00031778674619532924,
        "gradient_norm": 0.3272167444229126,
        "train_loss": 3.1494414806365967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15948,
        "tokens": 8361345024,
        "learning_rate": 0.0003177581298116658,
        "gradient_norm": 0.3338068425655365,
        "train_loss": 3.0745511054992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15949,
        "tokens": 8361869312,
        "learning_rate": 0.0003177295135657998,
        "gradient_norm": 0.310508668422699,
        "train_loss": 3.061256170272827,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15950,
        "tokens": 8362393600,
        "learning_rate": 0.00031770089745805354,
        "gradient_norm": 0.2843819260597229,
        "train_loss": 3.121415376663208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15951,
        "tokens": 8362917888,
        "learning_rate": 0.0003176722814887489,
        "gradient_norm": 0.2985124886035919,
        "train_loss": 3.118452548980713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15952,
        "tokens": 8363442176,
        "learning_rate": 0.00031764366565820813,
        "gradient_norm": 0.29260504245758057,
        "train_loss": 3.0729994773864746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15953,
        "tokens": 8363966464,
        "learning_rate": 0.00031761504996675327,
        "gradient_norm": 0.3052837550640106,
        "train_loss": 3.102391242980957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15954,
        "tokens": 8364490752,
        "learning_rate": 0.0003175864344147066,
        "gradient_norm": 0.32804974913597107,
        "train_loss": 3.1486520767211914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15955,
        "tokens": 8365015040,
        "learning_rate": 0.0003175578190023899,
        "gradient_norm": 0.29077330231666565,
        "train_loss": 3.086209297180176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15956,
        "tokens": 8365539328,
        "learning_rate": 0.0003175292037301255,
        "gradient_norm": 0.3402920961380005,
        "train_loss": 3.078660726547241,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15957,
        "tokens": 8366063616,
        "learning_rate": 0.00031750058859823555,
        "gradient_norm": 0.29925116896629333,
        "train_loss": 3.0946311950683594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15958,
        "tokens": 8366587904,
        "learning_rate": 0.00031747197360704194,
        "gradient_norm": 0.3108884394168854,
        "train_loss": 3.1805102825164795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15959,
        "tokens": 8367112192,
        "learning_rate": 0.000317443358756867,
        "gradient_norm": 0.31081312894821167,
        "train_loss": 3.0134408473968506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15960,
        "tokens": 8367636480,
        "learning_rate": 0.00031741474404803257,
        "gradient_norm": 0.30778083205223083,
        "train_loss": 3.098647117614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15961,
        "tokens": 8368160768,
        "learning_rate": 0.00031738612948086105,
        "gradient_norm": 0.2857411205768585,
        "train_loss": 3.1271896362304688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15962,
        "tokens": 8368685056,
        "learning_rate": 0.00031735751505567426,
        "gradient_norm": 0.31778770685195923,
        "train_loss": 3.0985076427459717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15963,
        "tokens": 8369209344,
        "learning_rate": 0.0003173289007727945,
        "gradient_norm": 0.27561309933662415,
        "train_loss": 3.0589940547943115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15964,
        "tokens": 8369733632,
        "learning_rate": 0.0003173002866325436,
        "gradient_norm": 0.3064502775669098,
        "train_loss": 3.0575308799743652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15965,
        "tokens": 8370257920,
        "learning_rate": 0.0003172716726352439,
        "gradient_norm": 0.30773162841796875,
        "train_loss": 3.0961642265319824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15966,
        "tokens": 8370782208,
        "learning_rate": 0.00031724305878121735,
        "gradient_norm": 0.311715692281723,
        "train_loss": 3.076341152191162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15967,
        "tokens": 8371306496,
        "learning_rate": 0.0003172144450707861,
        "gradient_norm": 0.30835485458374023,
        "train_loss": 3.1422386169433594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15968,
        "tokens": 8371830784,
        "learning_rate": 0.0003171858315042722,
        "gradient_norm": 0.29175466299057007,
        "train_loss": 3.030714511871338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15969,
        "tokens": 8372355072,
        "learning_rate": 0.0003171572180819978,
        "gradient_norm": 0.28926917910575867,
        "train_loss": 3.1062428951263428,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15970,
        "tokens": 8372879360,
        "learning_rate": 0.00031712860480428485,
        "gradient_norm": 0.28350311517715454,
        "train_loss": 3.0904946327209473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15971,
        "tokens": 8373403648,
        "learning_rate": 0.00031709999167145556,
        "gradient_norm": 0.30078279972076416,
        "train_loss": 3.0997252464294434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15972,
        "tokens": 8373927936,
        "learning_rate": 0.0003170713786838319,
        "gradient_norm": 0.28679782152175903,
        "train_loss": 3.1471283435821533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15973,
        "tokens": 8374452224,
        "learning_rate": 0.00031704276584173597,
        "gradient_norm": 0.30734777450561523,
        "train_loss": 3.067355155944824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15974,
        "tokens": 8374976512,
        "learning_rate": 0.0003170141531454899,
        "gradient_norm": 0.41398248076438904,
        "train_loss": 3.261559009552002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15975,
        "tokens": 8375500800,
        "learning_rate": 0.0003169855405954157,
        "gradient_norm": 0.3560192286968231,
        "train_loss": 3.070770740509033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15976,
        "tokens": 8376025088,
        "learning_rate": 0.0003169569281918354,
        "gradient_norm": 0.3061092793941498,
        "train_loss": 3.0244598388671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15977,
        "tokens": 8376549376,
        "learning_rate": 0.0003169283159350713,
        "gradient_norm": 0.3352029323577881,
        "train_loss": 3.1286566257476807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15978,
        "tokens": 8377073664,
        "learning_rate": 0.0003168997038254451,
        "gradient_norm": 0.3019229471683502,
        "train_loss": 3.088458299636841,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15979,
        "tokens": 8377597952,
        "learning_rate": 0.0003168710918632792,
        "gradient_norm": 0.3279532492160797,
        "train_loss": 3.117759943008423,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15980,
        "tokens": 8378122240,
        "learning_rate": 0.0003168424800488955,
        "gradient_norm": 0.30828532576560974,
        "train_loss": 3.103569746017456,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15981,
        "tokens": 8378646528,
        "learning_rate": 0.00031681386838261613,
        "gradient_norm": 0.3119620680809021,
        "train_loss": 3.0706944465637207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15982,
        "tokens": 8379170816,
        "learning_rate": 0.000316785256864763,
        "gradient_norm": 0.3002319037914276,
        "train_loss": 3.1378142833709717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15983,
        "tokens": 8379695104,
        "learning_rate": 0.0003167566454956584,
        "gradient_norm": 0.29842427372932434,
        "train_loss": 3.113400936126709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15984,
        "tokens": 8380219392,
        "learning_rate": 0.0003167280342756241,
        "gradient_norm": 0.2950786054134369,
        "train_loss": 3.129415512084961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15985,
        "tokens": 8380743680,
        "learning_rate": 0.0003166994232049824,
        "gradient_norm": 0.31277352571487427,
        "train_loss": 3.1214888095855713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15986,
        "tokens": 8381267968,
        "learning_rate": 0.00031667081228405536,
        "gradient_norm": 0.2925463318824768,
        "train_loss": 3.0686838626861572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15987,
        "tokens": 8381792256,
        "learning_rate": 0.0003166422015131648,
        "gradient_norm": 0.3003699481487274,
        "train_loss": 3.1654839515686035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15988,
        "tokens": 8382316544,
        "learning_rate": 0.00031661359089263304,
        "gradient_norm": 0.2889232635498047,
        "train_loss": 3.051985263824463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15989,
        "tokens": 8382840832,
        "learning_rate": 0.0003165849804227819,
        "gradient_norm": 0.2993727922439575,
        "train_loss": 3.0653510093688965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15990,
        "tokens": 8383365120,
        "learning_rate": 0.0003165563701039336,
        "gradient_norm": 0.29460322856903076,
        "train_loss": 3.079225540161133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15991,
        "tokens": 8383889408,
        "learning_rate": 0.00031652775993641006,
        "gradient_norm": 0.29329100251197815,
        "train_loss": 3.117384433746338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15992,
        "tokens": 8384413696,
        "learning_rate": 0.00031649914992053343,
        "gradient_norm": 0.297913521528244,
        "train_loss": 3.0894808769226074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15993,
        "tokens": 8384937984,
        "learning_rate": 0.0003164705400566256,
        "gradient_norm": 0.2913421392440796,
        "train_loss": 3.086759090423584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15994,
        "tokens": 8385462272,
        "learning_rate": 0.00031644193034500886,
        "gradient_norm": 0.28727132081985474,
        "train_loss": 3.1104612350463867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15995,
        "tokens": 8385986560,
        "learning_rate": 0.00031641332078600494,
        "gradient_norm": 0.3162355422973633,
        "train_loss": 3.09421706199646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15996,
        "tokens": 8386510848,
        "learning_rate": 0.00031638471137993604,
        "gradient_norm": 0.4138164818286896,
        "train_loss": 3.10548996925354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15997,
        "tokens": 8387035136,
        "learning_rate": 0.0003163561021271243,
        "gradient_norm": 0.3228437900543213,
        "train_loss": 3.107247829437256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15998,
        "tokens": 8387559424,
        "learning_rate": 0.00031632749302789155,
        "gradient_norm": 0.3319135904312134,
        "train_loss": 3.1275928020477295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 15999,
        "tokens": 8388083712,
        "learning_rate": 0.00031629888408256,
        "gradient_norm": 0.3415372371673584,
        "train_loss": 3.1286873817443848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16000,
        "tokens": 8388608000,
        "learning_rate": 0.0003162702752914514,
        "gradient_norm": 0.35629433393478394,
        "train_loss": 3.033984661102295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16001,
        "tokens": 8389132288,
        "learning_rate": 0.00031624166665488823,
        "gradient_norm": 0.31280338764190674,
        "train_loss": 3.0752739906311035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16002,
        "tokens": 8389656576,
        "learning_rate": 0.00031621305817319204,
        "gradient_norm": 0.31754010915756226,
        "train_loss": 3.1240453720092773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16003,
        "tokens": 8390180864,
        "learning_rate": 0.0003161844498466852,
        "gradient_norm": 0.3159211575984955,
        "train_loss": 3.0767393112182617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16004,
        "tokens": 8390705152,
        "learning_rate": 0.0003161558416756895,
        "gradient_norm": 0.3235042095184326,
        "train_loss": 3.084817409515381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16005,
        "tokens": 8391229440,
        "learning_rate": 0.00031612723366052705,
        "gradient_norm": 0.30674436688423157,
        "train_loss": 3.1017799377441406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16006,
        "tokens": 8391753728,
        "learning_rate": 0.00031609862580152,
        "gradient_norm": 0.30900314450263977,
        "train_loss": 3.0536580085754395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16007,
        "tokens": 8392278016,
        "learning_rate": 0.0003160700180989901,
        "gradient_norm": 0.30361729860305786,
        "train_loss": 3.1187610626220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16008,
        "tokens": 8392802304,
        "learning_rate": 0.00031604141055325966,
        "gradient_norm": 0.3290722370147705,
        "train_loss": 3.097179412841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16009,
        "tokens": 8393326592,
        "learning_rate": 0.0003160128031646504,
        "gradient_norm": 0.31092897057533264,
        "train_loss": 3.0788145065307617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16010,
        "tokens": 8393850880,
        "learning_rate": 0.0003159841959334846,
        "gradient_norm": 0.3188740015029907,
        "train_loss": 3.0905818939208984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16011,
        "tokens": 8394375168,
        "learning_rate": 0.00031595558886008405,
        "gradient_norm": 0.314290314912796,
        "train_loss": 3.1581993103027344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16012,
        "tokens": 8394899456,
        "learning_rate": 0.00031592698194477095,
        "gradient_norm": 0.28722116351127625,
        "train_loss": 3.054953098297119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16013,
        "tokens": 8395423744,
        "learning_rate": 0.0003158983751878671,
        "gradient_norm": 0.32001015543937683,
        "train_loss": 3.1290414333343506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16014,
        "tokens": 8395948032,
        "learning_rate": 0.00031586976858969474,
        "gradient_norm": 0.29622989892959595,
        "train_loss": 3.071261167526245,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16015,
        "tokens": 8396472320,
        "learning_rate": 0.0003158411621505756,
        "gradient_norm": 0.3200169503688812,
        "train_loss": 3.0576367378234863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16016,
        "tokens": 8396996608,
        "learning_rate": 0.0003158125558708319,
        "gradient_norm": 0.3217099905014038,
        "train_loss": 3.0532867908477783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16017,
        "tokens": 8397520896,
        "learning_rate": 0.0003157839497507856,
        "gradient_norm": 0.32065504789352417,
        "train_loss": 3.078767776489258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16018,
        "tokens": 8398045184,
        "learning_rate": 0.00031575534379075864,
        "gradient_norm": 0.311549574136734,
        "train_loss": 3.1257238388061523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16019,
        "tokens": 8398569472,
        "learning_rate": 0.0003157267379910731,
        "gradient_norm": 0.3343021273612976,
        "train_loss": 3.161313533782959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16020,
        "tokens": 8399093760,
        "learning_rate": 0.0003156981323520508,
        "gradient_norm": 0.2770611047744751,
        "train_loss": 3.0806326866149902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16021,
        "tokens": 8399618048,
        "learning_rate": 0.0003156695268740139,
        "gradient_norm": 0.32285553216934204,
        "train_loss": 3.1136317253112793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16022,
        "tokens": 8400142336,
        "learning_rate": 0.0003156409215572844,
        "gradient_norm": 0.2960435748100281,
        "train_loss": 3.132838249206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16023,
        "tokens": 8400666624,
        "learning_rate": 0.0003156123164021842,
        "gradient_norm": 0.3621737062931061,
        "train_loss": 3.0565714836120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16024,
        "tokens": 8401190912,
        "learning_rate": 0.00031558371140903523,
        "gradient_norm": 0.2906806468963623,
        "train_loss": 3.030820369720459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16025,
        "tokens": 8401715200,
        "learning_rate": 0.00031555510657815957,
        "gradient_norm": 0.30715516209602356,
        "train_loss": 3.098543882369995,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16026,
        "tokens": 8402239488,
        "learning_rate": 0.00031552650190987933,
        "gradient_norm": 0.2783864140510559,
        "train_loss": 3.0981831550598145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16027,
        "tokens": 8402763776,
        "learning_rate": 0.0003154978974045162,
        "gradient_norm": 0.29100385308265686,
        "train_loss": 3.0857324600219727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16028,
        "tokens": 8403288064,
        "learning_rate": 0.0003154692930623924,
        "gradient_norm": 0.30690398812294006,
        "train_loss": 3.096250057220459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16029,
        "tokens": 8403812352,
        "learning_rate": 0.00031544068888382976,
        "gradient_norm": 0.3114127814769745,
        "train_loss": 3.106431484222412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16030,
        "tokens": 8404336640,
        "learning_rate": 0.0003154120848691504,
        "gradient_norm": 0.3213930130004883,
        "train_loss": 3.128690242767334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16031,
        "tokens": 8404860928,
        "learning_rate": 0.00031538348101867614,
        "gradient_norm": 0.31736522912979126,
        "train_loss": 3.054075241088867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16032,
        "tokens": 8405385216,
        "learning_rate": 0.0003153548773327291,
        "gradient_norm": 0.3138543367385864,
        "train_loss": 3.092719554901123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16033,
        "tokens": 8405909504,
        "learning_rate": 0.000315326273811631,
        "gradient_norm": 0.3249450922012329,
        "train_loss": 3.050942897796631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16034,
        "tokens": 8406433792,
        "learning_rate": 0.00031529767045570417,
        "gradient_norm": 0.3218585252761841,
        "train_loss": 3.0651068687438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16035,
        "tokens": 8406958080,
        "learning_rate": 0.00031526906726527025,
        "gradient_norm": 0.3000367283821106,
        "train_loss": 3.1022531986236572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16036,
        "tokens": 8407482368,
        "learning_rate": 0.00031524046424065134,
        "gradient_norm": 0.3281286954879761,
        "train_loss": 3.093447685241699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16037,
        "tokens": 8408006656,
        "learning_rate": 0.00031521186138216956,
        "gradient_norm": 0.30207347869873047,
        "train_loss": 3.094660758972168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16038,
        "tokens": 8408530944,
        "learning_rate": 0.00031518325869014653,
        "gradient_norm": 0.3028905391693115,
        "train_loss": 3.0716958045959473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16039,
        "tokens": 8409055232,
        "learning_rate": 0.00031515465616490453,
        "gradient_norm": 0.3130471706390381,
        "train_loss": 3.1046745777130127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16040,
        "tokens": 8409579520,
        "learning_rate": 0.00031512605380676524,
        "gradient_norm": 0.29187846183776855,
        "train_loss": 3.1465001106262207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16041,
        "tokens": 8410103808,
        "learning_rate": 0.00031509745161605095,
        "gradient_norm": 0.32026946544647217,
        "train_loss": 3.149352788925171,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16042,
        "tokens": 8410628096,
        "learning_rate": 0.0003150688495930832,
        "gradient_norm": 0.286895751953125,
        "train_loss": 3.1249539852142334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16043,
        "tokens": 8411152384,
        "learning_rate": 0.00031504024773818434,
        "gradient_norm": 0.32428744435310364,
        "train_loss": 3.1332201957702637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16044,
        "tokens": 8411676672,
        "learning_rate": 0.00031501164605167605,
        "gradient_norm": 0.28215473890304565,
        "train_loss": 3.112612009048462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16045,
        "tokens": 8412200960,
        "learning_rate": 0.0003149830445338803,
        "gradient_norm": 0.299355685710907,
        "train_loss": 3.071697235107422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16046,
        "tokens": 8412725248,
        "learning_rate": 0.0003149544431851193,
        "gradient_norm": 0.29517656564712524,
        "train_loss": 3.096867561340332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16047,
        "tokens": 8413249536,
        "learning_rate": 0.0003149258420057146,
        "gradient_norm": 0.2822783291339874,
        "train_loss": 3.1089706420898438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16048,
        "tokens": 8413773824,
        "learning_rate": 0.0003148972409959885,
        "gradient_norm": 0.3136567771434784,
        "train_loss": 3.119905471801758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16049,
        "tokens": 8414298112,
        "learning_rate": 0.00031486864015626263,
        "gradient_norm": 0.31110092997550964,
        "train_loss": 3.0866904258728027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16050,
        "tokens": 8414822400,
        "learning_rate": 0.00031484003948685925,
        "gradient_norm": 0.2973989248275757,
        "train_loss": 3.097508430480957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16051,
        "tokens": 8415346688,
        "learning_rate": 0.0003148114389880999,
        "gradient_norm": 0.3086351156234741,
        "train_loss": 3.086351156234741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16052,
        "tokens": 8415870976,
        "learning_rate": 0.00031478283866030694,
        "gradient_norm": 0.29975929856300354,
        "train_loss": 3.036421298980713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16053,
        "tokens": 8416395264,
        "learning_rate": 0.000314754238503802,
        "gradient_norm": 0.2901539206504822,
        "train_loss": 3.0762338638305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16054,
        "tokens": 8416919552,
        "learning_rate": 0.0003147256385189072,
        "gradient_norm": 0.3638412654399872,
        "train_loss": 3.1816375255584717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16055,
        "tokens": 8417443840,
        "learning_rate": 0.0003146970387059442,
        "gradient_norm": 0.3586982190608978,
        "train_loss": 3.1199705600738525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16056,
        "tokens": 8417968128,
        "learning_rate": 0.00031466843906523517,
        "gradient_norm": 0.33637863397598267,
        "train_loss": 3.040916919708252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16057,
        "tokens": 8418492416,
        "learning_rate": 0.0003146398395971021,
        "gradient_norm": 0.3044312000274658,
        "train_loss": 3.07399845123291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16058,
        "tokens": 8419016704,
        "learning_rate": 0.00031461124030186664,
        "gradient_norm": 0.3323025107383728,
        "train_loss": 3.1009974479675293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16059,
        "tokens": 8419540992,
        "learning_rate": 0.00031458264117985096,
        "gradient_norm": 0.3275485932826996,
        "train_loss": 3.171279191970825,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16060,
        "tokens": 8420065280,
        "learning_rate": 0.00031455404223137675,
        "gradient_norm": 0.32308951020240784,
        "train_loss": 3.070706605911255,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16061,
        "tokens": 8420589568,
        "learning_rate": 0.00031452544345676617,
        "gradient_norm": 0.33373787999153137,
        "train_loss": 3.115049362182617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16062,
        "tokens": 8421113856,
        "learning_rate": 0.0003144968448563409,
        "gradient_norm": 0.3141646385192871,
        "train_loss": 3.1123876571655273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16063,
        "tokens": 8421638144,
        "learning_rate": 0.0003144682464304231,
        "gradient_norm": 0.3150748312473297,
        "train_loss": 3.1078734397888184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16064,
        "tokens": 8422162432,
        "learning_rate": 0.00031443964817933444,
        "gradient_norm": 0.32573261857032776,
        "train_loss": 3.061734914779663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16065,
        "tokens": 8422686720,
        "learning_rate": 0.00031441105010339697,
        "gradient_norm": 0.3082587420940399,
        "train_loss": 3.0635557174682617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16066,
        "tokens": 8423211008,
        "learning_rate": 0.0003143824522029326,
        "gradient_norm": 0.3253442943096161,
        "train_loss": 3.09187650680542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16067,
        "tokens": 8423735296,
        "learning_rate": 0.0003143538544782631,
        "gradient_norm": 0.3458402752876282,
        "train_loss": 3.0431599617004395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16068,
        "tokens": 8424259584,
        "learning_rate": 0.0003143252569297106,
        "gradient_norm": 0.3074638545513153,
        "train_loss": 3.083890914916992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16069,
        "tokens": 8424783872,
        "learning_rate": 0.0003142966595575968,
        "gradient_norm": 0.3459394872188568,
        "train_loss": 3.1580662727355957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16070,
        "tokens": 8425308160,
        "learning_rate": 0.00031426806236224366,
        "gradient_norm": 0.30592402815818787,
        "train_loss": 3.085693836212158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16071,
        "tokens": 8425832448,
        "learning_rate": 0.0003142394653439731,
        "gradient_norm": 0.3148818612098694,
        "train_loss": 3.1064486503601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16072,
        "tokens": 8426356736,
        "learning_rate": 0.00031421086850310704,
        "gradient_norm": 0.3422726094722748,
        "train_loss": 3.087522506713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16073,
        "tokens": 8426881024,
        "learning_rate": 0.0003141822718399673,
        "gradient_norm": 0.3117032051086426,
        "train_loss": 3.108142375946045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16074,
        "tokens": 8427405312,
        "learning_rate": 0.0003141536753548758,
        "gradient_norm": 0.28897625207901,
        "train_loss": 3.1037509441375732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16075,
        "tokens": 8427929600,
        "learning_rate": 0.0003141250790481545,
        "gradient_norm": 0.2938123941421509,
        "train_loss": 3.1299734115600586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16076,
        "tokens": 8428453888,
        "learning_rate": 0.0003140964829201251,
        "gradient_norm": 0.338358998298645,
        "train_loss": 3.048865556716919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16077,
        "tokens": 8428978176,
        "learning_rate": 0.00031406788697110975,
        "gradient_norm": 0.30303114652633667,
        "train_loss": 3.0818045139312744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16078,
        "tokens": 8429502464,
        "learning_rate": 0.00031403929120143005,
        "gradient_norm": 0.3289026916027069,
        "train_loss": 3.123076915740967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16079,
        "tokens": 8430026752,
        "learning_rate": 0.0003140106956114082,
        "gradient_norm": 0.3378918766975403,
        "train_loss": 3.088587522506714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16080,
        "tokens": 8430551040,
        "learning_rate": 0.00031398210020136574,
        "gradient_norm": 0.3069623112678528,
        "train_loss": 3.0901904106140137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16081,
        "tokens": 8431075328,
        "learning_rate": 0.0003139535049716248,
        "gradient_norm": 0.2918395400047302,
        "train_loss": 3.0980160236358643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16082,
        "tokens": 8431599616,
        "learning_rate": 0.00031392490992250706,
        "gradient_norm": 0.29710647463798523,
        "train_loss": 3.1148157119750977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16083,
        "tokens": 8432123904,
        "learning_rate": 0.00031389631505433465,
        "gradient_norm": 0.3168790936470032,
        "train_loss": 3.080117702484131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16084,
        "tokens": 8432648192,
        "learning_rate": 0.0003138677203674292,
        "gradient_norm": 0.33705270290374756,
        "train_loss": 3.124964952468872,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16085,
        "tokens": 8433172480,
        "learning_rate": 0.00031383912586211256,
        "gradient_norm": 0.33273670077323914,
        "train_loss": 3.057962417602539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16086,
        "tokens": 8433696768,
        "learning_rate": 0.0003138105315387069,
        "gradient_norm": 0.3632538914680481,
        "train_loss": 3.1779866218566895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16087,
        "tokens": 8434221056,
        "learning_rate": 0.00031378193739753374,
        "gradient_norm": 0.3247537314891815,
        "train_loss": 3.1168885231018066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16088,
        "tokens": 8434745344,
        "learning_rate": 0.0003137533434389152,
        "gradient_norm": 0.3378230035305023,
        "train_loss": 3.1064178943634033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16089,
        "tokens": 8435269632,
        "learning_rate": 0.000313724749663173,
        "gradient_norm": 0.32793110609054565,
        "train_loss": 3.0559933185577393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16090,
        "tokens": 8435793920,
        "learning_rate": 0.00031369615607062905,
        "gradient_norm": 0.3407568037509918,
        "train_loss": 3.071035146713257,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16091,
        "tokens": 8436318208,
        "learning_rate": 0.0003136675626616051,
        "gradient_norm": 0.34233152866363525,
        "train_loss": 3.083082675933838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16092,
        "tokens": 8436842496,
        "learning_rate": 0.0003136389694364232,
        "gradient_norm": 0.3023594617843628,
        "train_loss": 3.082016944885254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16093,
        "tokens": 8437366784,
        "learning_rate": 0.000313610376395405,
        "gradient_norm": 0.3244777023792267,
        "train_loss": 3.107041358947754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16094,
        "tokens": 8437891072,
        "learning_rate": 0.0003135817835388724,
        "gradient_norm": 0.2911863625049591,
        "train_loss": 3.0492539405822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16095,
        "tokens": 8438415360,
        "learning_rate": 0.0003135531908671475,
        "gradient_norm": 0.29774367809295654,
        "train_loss": 3.056678295135498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16096,
        "tokens": 8438939648,
        "learning_rate": 0.00031352459838055173,
        "gradient_norm": 0.3039807081222534,
        "train_loss": 3.0785210132598877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16097,
        "tokens": 8439463936,
        "learning_rate": 0.0003134960060794073,
        "gradient_norm": 0.29116272926330566,
        "train_loss": 3.1461894512176514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16098,
        "tokens": 8439988224,
        "learning_rate": 0.00031346741396403574,
        "gradient_norm": 0.32055771350860596,
        "train_loss": 3.1082406044006348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16099,
        "tokens": 8440512512,
        "learning_rate": 0.0003134388220347592,
        "gradient_norm": 0.31005197763442993,
        "train_loss": 3.1183032989501953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16100,
        "tokens": 8441036800,
        "learning_rate": 0.00031341023029189923,
        "gradient_norm": 0.32535868883132935,
        "train_loss": 3.0860342979431152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16101,
        "tokens": 8441561088,
        "learning_rate": 0.0003133816387357779,
        "gradient_norm": 0.3036328852176666,
        "train_loss": 3.094566822052002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16102,
        "tokens": 8442085376,
        "learning_rate": 0.0003133530473667169,
        "gradient_norm": 0.2971867620944977,
        "train_loss": 3.1517834663391113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16103,
        "tokens": 8442609664,
        "learning_rate": 0.0003133244561850381,
        "gradient_norm": 0.3003697991371155,
        "train_loss": 3.1381311416625977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16104,
        "tokens": 8443133952,
        "learning_rate": 0.00031329586519106327,
        "gradient_norm": 0.30676671862602234,
        "train_loss": 3.162209987640381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16105,
        "tokens": 8443658240,
        "learning_rate": 0.00031326727438511434,
        "gradient_norm": 0.28649255633354187,
        "train_loss": 3.0850391387939453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16106,
        "tokens": 8444182528,
        "learning_rate": 0.0003132386837675132,
        "gradient_norm": 0.3142969012260437,
        "train_loss": 3.091485023498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16107,
        "tokens": 8444706816,
        "learning_rate": 0.0003132100933385814,
        "gradient_norm": 0.2821830213069916,
        "train_loss": 3.057239532470703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16108,
        "tokens": 8445231104,
        "learning_rate": 0.0003131815030986411,
        "gradient_norm": 0.3205408751964569,
        "train_loss": 3.092869281768799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16109,
        "tokens": 8445755392,
        "learning_rate": 0.0003131529130480138,
        "gradient_norm": 0.2923419177532196,
        "train_loss": 3.0639076232910156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16110,
        "tokens": 8446279680,
        "learning_rate": 0.0003131243231870216,
        "gradient_norm": 0.3175754249095917,
        "train_loss": 3.103285551071167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16111,
        "tokens": 8446803968,
        "learning_rate": 0.00031309573351598607,
        "gradient_norm": 0.284151554107666,
        "train_loss": 3.088622570037842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16112,
        "tokens": 8447328256,
        "learning_rate": 0.0003130671440352292,
        "gradient_norm": 0.34293657541275024,
        "train_loss": 3.0835063457489014,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16113,
        "tokens": 8447852544,
        "learning_rate": 0.0003130385547450726,
        "gradient_norm": 0.31153014302253723,
        "train_loss": 3.0940003395080566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16114,
        "tokens": 8448376832,
        "learning_rate": 0.00031300996564583835,
        "gradient_norm": 0.3072088956832886,
        "train_loss": 3.0921027660369873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16115,
        "tokens": 8448901120,
        "learning_rate": 0.00031298137673784805,
        "gradient_norm": 0.31486976146698,
        "train_loss": 3.1157450675964355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16116,
        "tokens": 8449425408,
        "learning_rate": 0.0003129527880214236,
        "gradient_norm": 0.3116396367549896,
        "train_loss": 3.0964090824127197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16117,
        "tokens": 8449949696,
        "learning_rate": 0.0003129241994968868,
        "gradient_norm": 0.30766746401786804,
        "train_loss": 3.101095676422119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16118,
        "tokens": 8450473984,
        "learning_rate": 0.00031289561116455933,
        "gradient_norm": 0.34448903799057007,
        "train_loss": 3.069542407989502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16119,
        "tokens": 8450998272,
        "learning_rate": 0.0003128670230247631,
        "gradient_norm": 0.3126079738140106,
        "train_loss": 3.047434091567993,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16120,
        "tokens": 8451522560,
        "learning_rate": 0.00031283843507782,
        "gradient_norm": 0.31132495403289795,
        "train_loss": 3.122358798980713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16121,
        "tokens": 8452046848,
        "learning_rate": 0.0003128098473240516,
        "gradient_norm": 0.32800278067588806,
        "train_loss": 3.0434093475341797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16122,
        "tokens": 8452571136,
        "learning_rate": 0.00031278125976377975,
        "gradient_norm": 0.29366081953048706,
        "train_loss": 3.1447315216064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16123,
        "tokens": 8453095424,
        "learning_rate": 0.0003127526723973264,
        "gradient_norm": 0.3288593590259552,
        "train_loss": 3.0471627712249756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16124,
        "tokens": 8453619712,
        "learning_rate": 0.00031272408522501315,
        "gradient_norm": 0.28595829010009766,
        "train_loss": 3.116157054901123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16125,
        "tokens": 8454144000,
        "learning_rate": 0.00031269549824716183,
        "gradient_norm": 0.30530181527137756,
        "train_loss": 3.0939879417419434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16126,
        "tokens": 8454668288,
        "learning_rate": 0.0003126669114640943,
        "gradient_norm": 0.32223644852638245,
        "train_loss": 3.1320137977600098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16127,
        "tokens": 8455192576,
        "learning_rate": 0.0003126383248761323,
        "gradient_norm": 0.31107795238494873,
        "train_loss": 3.1521501541137695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16128,
        "tokens": 8455716864,
        "learning_rate": 0.00031260973848359756,
        "gradient_norm": 0.317219614982605,
        "train_loss": 3.110419511795044,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16129,
        "tokens": 8456241152,
        "learning_rate": 0.00031258115228681194,
        "gradient_norm": 0.30980101227760315,
        "train_loss": 3.083244800567627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16130,
        "tokens": 8456765440,
        "learning_rate": 0.00031255256628609713,
        "gradient_norm": 0.32653969526290894,
        "train_loss": 3.058357000350952,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16131,
        "tokens": 8457289728,
        "learning_rate": 0.0003125239804817749,
        "gradient_norm": 0.2945926785469055,
        "train_loss": 3.140857219696045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16132,
        "tokens": 8457814016,
        "learning_rate": 0.00031249539487416715,
        "gradient_norm": 0.3142361640930176,
        "train_loss": 3.096522808074951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16133,
        "tokens": 8458338304,
        "learning_rate": 0.00031246680946359545,
        "gradient_norm": 0.2998760938644409,
        "train_loss": 3.077418804168701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16134,
        "tokens": 8458862592,
        "learning_rate": 0.00031243822425038167,
        "gradient_norm": 0.27848726511001587,
        "train_loss": 3.082495927810669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16135,
        "tokens": 8459386880,
        "learning_rate": 0.00031240963923484766,
        "gradient_norm": 0.3145110607147217,
        "train_loss": 3.082573890686035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16136,
        "tokens": 8459911168,
        "learning_rate": 0.000312381054417315,
        "gradient_norm": 0.2964633107185364,
        "train_loss": 3.078183174133301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16137,
        "tokens": 8460435456,
        "learning_rate": 0.0003123524697981056,
        "gradient_norm": 0.2930372953414917,
        "train_loss": 3.0979175567626953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16138,
        "tokens": 8460959744,
        "learning_rate": 0.00031232388537754107,
        "gradient_norm": 0.32132214307785034,
        "train_loss": 3.1163363456726074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16139,
        "tokens": 8461484032,
        "learning_rate": 0.00031229530115594337,
        "gradient_norm": 0.3502422273159027,
        "train_loss": 3.1602158546447754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16140,
        "tokens": 8462008320,
        "learning_rate": 0.000312266717133634,
        "gradient_norm": 0.3516499698162079,
        "train_loss": 3.1214945316314697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16141,
        "tokens": 8462532608,
        "learning_rate": 0.00031223813331093494,
        "gradient_norm": 0.3293931484222412,
        "train_loss": 3.0863423347473145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16142,
        "tokens": 8463056896,
        "learning_rate": 0.0003122095496881677,
        "gradient_norm": 0.31084659695625305,
        "train_loss": 3.139010190963745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16143,
        "tokens": 8463581184,
        "learning_rate": 0.0003121809662656543,
        "gradient_norm": 0.3329315185546875,
        "train_loss": 3.072237491607666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16144,
        "tokens": 8464105472,
        "learning_rate": 0.00031215238304371616,
        "gradient_norm": 0.2895945608615875,
        "train_loss": 3.0984153747558594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16145,
        "tokens": 8464629760,
        "learning_rate": 0.0003121238000226753,
        "gradient_norm": 0.32560020685195923,
        "train_loss": 3.066215991973877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16146,
        "tokens": 8465154048,
        "learning_rate": 0.0003120952172028534,
        "gradient_norm": 0.32246893644332886,
        "train_loss": 3.086432456970215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16147,
        "tokens": 8465678336,
        "learning_rate": 0.00031206663458457207,
        "gradient_norm": 0.3131175637245178,
        "train_loss": 3.0675628185272217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16148,
        "tokens": 8466202624,
        "learning_rate": 0.00031203805216815315,
        "gradient_norm": 0.29490137100219727,
        "train_loss": 3.0624334812164307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16149,
        "tokens": 8466726912,
        "learning_rate": 0.0003120094699539183,
        "gradient_norm": 0.3211541473865509,
        "train_loss": 3.091059684753418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16150,
        "tokens": 8467251200,
        "learning_rate": 0.0003119808879421894,
        "gradient_norm": 0.308161199092865,
        "train_loss": 3.120150089263916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16151,
        "tokens": 8467775488,
        "learning_rate": 0.000311952306133288,
        "gradient_norm": 0.31796538829803467,
        "train_loss": 3.09468412399292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16152,
        "tokens": 8468299776,
        "learning_rate": 0.0003119237245275359,
        "gradient_norm": 0.3157420754432678,
        "train_loss": 3.117006540298462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16153,
        "tokens": 8468824064,
        "learning_rate": 0.0003118951431252548,
        "gradient_norm": 0.3247794806957245,
        "train_loss": 3.0537195205688477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16154,
        "tokens": 8469348352,
        "learning_rate": 0.00031186656192676635,
        "gradient_norm": 0.31278103590011597,
        "train_loss": 3.1374783515930176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16155,
        "tokens": 8469872640,
        "learning_rate": 0.0003118379809323925,
        "gradient_norm": 0.3046947717666626,
        "train_loss": 3.1253695487976074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16156,
        "tokens": 8470396928,
        "learning_rate": 0.00031180940014245473,
        "gradient_norm": 0.325611412525177,
        "train_loss": 3.121840238571167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16157,
        "tokens": 8470921216,
        "learning_rate": 0.0003117808195572749,
        "gradient_norm": 0.3068663477897644,
        "train_loss": 3.1295738220214844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16158,
        "tokens": 8471445504,
        "learning_rate": 0.0003117522391771746,
        "gradient_norm": 0.31036850810050964,
        "train_loss": 3.1087303161621094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16159,
        "tokens": 8471969792,
        "learning_rate": 0.00031172365900247566,
        "gradient_norm": 0.2962203621864319,
        "train_loss": 3.0838401317596436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16160,
        "tokens": 8472494080,
        "learning_rate": 0.0003116950790334996,
        "gradient_norm": 0.35966989398002625,
        "train_loss": 3.161313772201538,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16161,
        "tokens": 8473018368,
        "learning_rate": 0.0003116664992705684,
        "gradient_norm": 0.3907220661640167,
        "train_loss": 3.0826308727264404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16162,
        "tokens": 8473542656,
        "learning_rate": 0.00031163791971400344,
        "gradient_norm": 0.31897786259651184,
        "train_loss": 3.0736865997314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16163,
        "tokens": 8474066944,
        "learning_rate": 0.00031160934036412677,
        "gradient_norm": 0.324201375246048,
        "train_loss": 3.092028856277466,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16164,
        "tokens": 8474591232,
        "learning_rate": 0.0003115807612212597,
        "gradient_norm": 0.31512171030044556,
        "train_loss": 3.1168909072875977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16165,
        "tokens": 8475115520,
        "learning_rate": 0.00031155218228572415,
        "gradient_norm": 0.35510608553886414,
        "train_loss": 3.1226089000701904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16166,
        "tokens": 8475639808,
        "learning_rate": 0.00031152360355784196,
        "gradient_norm": 0.3092941343784332,
        "train_loss": 3.0766305923461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16167,
        "tokens": 8476164096,
        "learning_rate": 0.00031149502503793447,
        "gradient_norm": 0.31335723400115967,
        "train_loss": 3.1087374687194824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16168,
        "tokens": 8476688384,
        "learning_rate": 0.0003114664467263236,
        "gradient_norm": 0.3344672620296478,
        "train_loss": 3.0948638916015625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16169,
        "tokens": 8477212672,
        "learning_rate": 0.00031143786862333094,
        "gradient_norm": 0.3052440285682678,
        "train_loss": 3.153170585632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16170,
        "tokens": 8477736960,
        "learning_rate": 0.00031140929072927834,
        "gradient_norm": 0.3228742778301239,
        "train_loss": 3.069460868835449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16171,
        "tokens": 8478261248,
        "learning_rate": 0.0003113807130444872,
        "gradient_norm": 0.3002149760723114,
        "train_loss": 3.094399929046631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16172,
        "tokens": 8478785536,
        "learning_rate": 0.00031135213556927947,
        "gradient_norm": 0.2923320531845093,
        "train_loss": 3.1343555450439453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16173,
        "tokens": 8479309824,
        "learning_rate": 0.0003113235583039765,
        "gradient_norm": 0.2893039584159851,
        "train_loss": 3.068500518798828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16174,
        "tokens": 8479834112,
        "learning_rate": 0.0003112949812489003,
        "gradient_norm": 0.30260729789733887,
        "train_loss": 3.096792697906494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16175,
        "tokens": 8480358400,
        "learning_rate": 0.00031126640440437244,
        "gradient_norm": 0.29481780529022217,
        "train_loss": 3.1019394397735596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16176,
        "tokens": 8480882688,
        "learning_rate": 0.0003112378277707145,
        "gradient_norm": 0.30574116110801697,
        "train_loss": 3.1091856956481934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16177,
        "tokens": 8481406976,
        "learning_rate": 0.0003112092513482482,
        "gradient_norm": 0.3004301190376282,
        "train_loss": 3.1015076637268066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16178,
        "tokens": 8481931264,
        "learning_rate": 0.0003111806751372952,
        "gradient_norm": 0.3003360331058502,
        "train_loss": 3.156768560409546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16179,
        "tokens": 8482455552,
        "learning_rate": 0.00031115209913817714,
        "gradient_norm": 0.32459312677383423,
        "train_loss": 3.0807318687438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16180,
        "tokens": 8482979840,
        "learning_rate": 0.0003111235233512157,
        "gradient_norm": 0.32191532850265503,
        "train_loss": 3.1264584064483643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16181,
        "tokens": 8483504128,
        "learning_rate": 0.00031109494777673257,
        "gradient_norm": 0.3062163293361664,
        "train_loss": 3.1188037395477295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16182,
        "tokens": 8484028416,
        "learning_rate": 0.00031106637241504935,
        "gradient_norm": 0.29915177822113037,
        "train_loss": 3.072364568710327,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16183,
        "tokens": 8484552704,
        "learning_rate": 0.0003110377972664877,
        "gradient_norm": 0.3282492756843567,
        "train_loss": 3.1062731742858887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16184,
        "tokens": 8485076992,
        "learning_rate": 0.0003110092223313693,
        "gradient_norm": 0.3150818347930908,
        "train_loss": 3.0738816261291504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16185,
        "tokens": 8485601280,
        "learning_rate": 0.0003109806476100157,
        "gradient_norm": 0.3181571364402771,
        "train_loss": 3.106926441192627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16186,
        "tokens": 8486125568,
        "learning_rate": 0.00031095207310274876,
        "gradient_norm": 0.34233930706977844,
        "train_loss": 3.1004793643951416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16187,
        "tokens": 8486649856,
        "learning_rate": 0.0003109234988098899,
        "gradient_norm": 0.3214660882949829,
        "train_loss": 3.1472930908203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16188,
        "tokens": 8487174144,
        "learning_rate": 0.0003108949247317609,
        "gradient_norm": 0.34498390555381775,
        "train_loss": 3.1303465366363525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16189,
        "tokens": 8487698432,
        "learning_rate": 0.0003108663508686832,
        "gradient_norm": 0.3131248950958252,
        "train_loss": 3.0790786743164062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16190,
        "tokens": 8488222720,
        "learning_rate": 0.0003108377772209787,
        "gradient_norm": 0.2926681637763977,
        "train_loss": 3.082310199737549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16191,
        "tokens": 8488747008,
        "learning_rate": 0.0003108092037889688,
        "gradient_norm": 0.3227677643299103,
        "train_loss": 3.0757579803466797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16192,
        "tokens": 8489271296,
        "learning_rate": 0.0003107806305729754,
        "gradient_norm": 0.31528255343437195,
        "train_loss": 3.0931339263916016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16193,
        "tokens": 8489795584,
        "learning_rate": 0.0003107520575733197,
        "gradient_norm": 0.282646507024765,
        "train_loss": 3.05301570892334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16194,
        "tokens": 8490319872,
        "learning_rate": 0.0003107234847903237,
        "gradient_norm": 0.29082566499710083,
        "train_loss": 3.089409828186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16195,
        "tokens": 8490844160,
        "learning_rate": 0.00031069491222430903,
        "gradient_norm": 0.3363819420337677,
        "train_loss": 3.159442901611328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16196,
        "tokens": 8491368448,
        "learning_rate": 0.00031066633987559704,
        "gradient_norm": 0.34950757026672363,
        "train_loss": 3.1034834384918213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16197,
        "tokens": 8491892736,
        "learning_rate": 0.0003106377677445096,
        "gradient_norm": 0.33070462942123413,
        "train_loss": 3.0782556533813477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16198,
        "tokens": 8492417024,
        "learning_rate": 0.00031060919583136815,
        "gradient_norm": 0.32564932107925415,
        "train_loss": 3.1365933418273926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16199,
        "tokens": 8492941312,
        "learning_rate": 0.00031058062413649447,
        "gradient_norm": 0.3297848403453827,
        "train_loss": 3.0806336402893066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16200,
        "tokens": 8493465600,
        "learning_rate": 0.0003105520526602099,
        "gradient_norm": 0.32396164536476135,
        "train_loss": 3.1623730659484863,
        "val_loss": 3.0616583824157715,
        "hellaswag_acc": 0.2816171944141388,
        "hellaswag_acc_norm": 0.2909778952598572
    },
    {
        "step": 16201,
        "tokens": 8493989888,
        "learning_rate": 0.0003105234814028364,
        "gradient_norm": 0.3165873885154724,
        "train_loss": 3.068653106689453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16202,
        "tokens": 8494514176,
        "learning_rate": 0.0003104949103646953,
        "gradient_norm": 0.2943322956562042,
        "train_loss": 3.108016014099121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16203,
        "tokens": 8495038464,
        "learning_rate": 0.0003104663395461083,
        "gradient_norm": 0.31467360258102417,
        "train_loss": 3.0914571285247803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16204,
        "tokens": 8495562752,
        "learning_rate": 0.00031043776894739696,
        "gradient_norm": 0.3248480558395386,
        "train_loss": 3.058506488800049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16205,
        "tokens": 8496087040,
        "learning_rate": 0.00031040919856888295,
        "gradient_norm": 0.2978167235851288,
        "train_loss": 3.1351470947265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16206,
        "tokens": 8496611328,
        "learning_rate": 0.0003103806284108879,
        "gradient_norm": 0.3205081522464752,
        "train_loss": 3.1443090438842773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16207,
        "tokens": 8497135616,
        "learning_rate": 0.0003103520584737332,
        "gradient_norm": 0.30205488204956055,
        "train_loss": 3.125751256942749,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16208,
        "tokens": 8497659904,
        "learning_rate": 0.0003103234887577407,
        "gradient_norm": 0.3436230421066284,
        "train_loss": 3.073823928833008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16209,
        "tokens": 8498184192,
        "learning_rate": 0.00031029491926323175,
        "gradient_norm": 0.3127431869506836,
        "train_loss": 3.1331725120544434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16210,
        "tokens": 8498708480,
        "learning_rate": 0.0003102663499905282,
        "gradient_norm": 0.35223904252052307,
        "train_loss": 3.098552703857422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16211,
        "tokens": 8499232768,
        "learning_rate": 0.0003102377809399513,
        "gradient_norm": 0.32311731576919556,
        "train_loss": 3.1205074787139893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16212,
        "tokens": 8499757056,
        "learning_rate": 0.000310209212111823,
        "gradient_norm": 0.3409883975982666,
        "train_loss": 3.0708062648773193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16213,
        "tokens": 8500281344,
        "learning_rate": 0.00031018064350646455,
        "gradient_norm": 0.3519607484340668,
        "train_loss": 3.0378293991088867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16214,
        "tokens": 8500805632,
        "learning_rate": 0.0003101520751241976,
        "gradient_norm": 0.3158455789089203,
        "train_loss": 3.1165108680725098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16215,
        "tokens": 8501329920,
        "learning_rate": 0.000310123506965344,
        "gradient_norm": 0.33717358112335205,
        "train_loss": 3.0701117515563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16216,
        "tokens": 8501854208,
        "learning_rate": 0.0003100949390302249,
        "gradient_norm": 0.31018370389938354,
        "train_loss": 3.1412553787231445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16217,
        "tokens": 8502378496,
        "learning_rate": 0.0003100663713191622,
        "gradient_norm": 0.32799333333969116,
        "train_loss": 3.1069178581237793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16218,
        "tokens": 8502902784,
        "learning_rate": 0.0003100378038324773,
        "gradient_norm": 0.3416886627674103,
        "train_loss": 3.1072473526000977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16219,
        "tokens": 8503427072,
        "learning_rate": 0.00031000923657049185,
        "gradient_norm": 0.30662471055984497,
        "train_loss": 3.0322978496551514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16220,
        "tokens": 8503951360,
        "learning_rate": 0.00030998066953352726,
        "gradient_norm": 0.3213737905025482,
        "train_loss": 3.086670398712158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16221,
        "tokens": 8504475648,
        "learning_rate": 0.0003099521027219053,
        "gradient_norm": 0.3291127383708954,
        "train_loss": 3.0900559425354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16222,
        "tokens": 8504999936,
        "learning_rate": 0.0003099235361359473,
        "gradient_norm": 0.35732755064964294,
        "train_loss": 3.079245090484619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16223,
        "tokens": 8505524224,
        "learning_rate": 0.0003098949697759751,
        "gradient_norm": 0.3572588860988617,
        "train_loss": 3.0921640396118164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16224,
        "tokens": 8506048512,
        "learning_rate": 0.00030986640364230985,
        "gradient_norm": 0.3282235264778137,
        "train_loss": 3.0560431480407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16225,
        "tokens": 8506572800,
        "learning_rate": 0.00030983783773527344,
        "gradient_norm": 0.30273303389549255,
        "train_loss": 3.0582852363586426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16226,
        "tokens": 8507097088,
        "learning_rate": 0.0003098092720551873,
        "gradient_norm": 0.33788010478019714,
        "train_loss": 3.1045994758605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16227,
        "tokens": 8507621376,
        "learning_rate": 0.00030978070660237297,
        "gradient_norm": 0.2947721481323242,
        "train_loss": 3.147768974304199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16228,
        "tokens": 8508145664,
        "learning_rate": 0.000309752141377152,
        "gradient_norm": 0.33236929774284363,
        "train_loss": 3.0896968841552734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16229,
        "tokens": 8508669952,
        "learning_rate": 0.0003097235763798459,
        "gradient_norm": 0.31165966391563416,
        "train_loss": 3.132826566696167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16230,
        "tokens": 8509194240,
        "learning_rate": 0.0003096950116107763,
        "gradient_norm": 0.3329329192638397,
        "train_loss": 3.122180938720703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16231,
        "tokens": 8509718528,
        "learning_rate": 0.00030966644707026454,
        "gradient_norm": 0.2992382347583771,
        "train_loss": 3.0607385635375977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16232,
        "tokens": 8510242816,
        "learning_rate": 0.0003096378827586323,
        "gradient_norm": 0.3081740438938141,
        "train_loss": 3.0728654861450195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16233,
        "tokens": 8510767104,
        "learning_rate": 0.0003096093186762011,
        "gradient_norm": 0.2828961908817291,
        "train_loss": 3.050748348236084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16234,
        "tokens": 8511291392,
        "learning_rate": 0.00030958075482329236,
        "gradient_norm": 0.3150781989097595,
        "train_loss": 3.1046833992004395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16235,
        "tokens": 8511815680,
        "learning_rate": 0.0003095521912002278,
        "gradient_norm": 0.2708972990512848,
        "train_loss": 3.1306004524230957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16236,
        "tokens": 8512339968,
        "learning_rate": 0.00030952362780732866,
        "gradient_norm": 0.31227561831474304,
        "train_loss": 3.084972381591797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16237,
        "tokens": 8512864256,
        "learning_rate": 0.0003094950646449168,
        "gradient_norm": 0.27334898710250854,
        "train_loss": 3.1313722133636475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16238,
        "tokens": 8513388544,
        "learning_rate": 0.00030946650171331336,
        "gradient_norm": 0.30043354630470276,
        "train_loss": 3.0910282135009766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16239,
        "tokens": 8513912832,
        "learning_rate": 0.0003094379390128402,
        "gradient_norm": 0.30270034074783325,
        "train_loss": 3.249194622039795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16240,
        "tokens": 8514437120,
        "learning_rate": 0.00030940937654381855,
        "gradient_norm": 0.35999682545661926,
        "train_loss": 3.028761386871338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16241,
        "tokens": 8514961408,
        "learning_rate": 0.00030938081430657014,
        "gradient_norm": 0.30537310242652893,
        "train_loss": 3.134780168533325,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16242,
        "tokens": 8515485696,
        "learning_rate": 0.0003093522523014163,
        "gradient_norm": 0.33464139699935913,
        "train_loss": 3.143507957458496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16243,
        "tokens": 8516009984,
        "learning_rate": 0.00030932369052867864,
        "gradient_norm": 0.3691839873790741,
        "train_loss": 3.132498264312744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16244,
        "tokens": 8516534272,
        "learning_rate": 0.00030929512898867853,
        "gradient_norm": 0.33407503366470337,
        "train_loss": 3.0402426719665527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16245,
        "tokens": 8517058560,
        "learning_rate": 0.00030926656768173754,
        "gradient_norm": 0.3425823450088501,
        "train_loss": 3.0484819412231445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16246,
        "tokens": 8517582848,
        "learning_rate": 0.0003092380066081773,
        "gradient_norm": 0.3303498923778534,
        "train_loss": 3.1403448581695557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16247,
        "tokens": 8518107136,
        "learning_rate": 0.0003092094457683191,
        "gradient_norm": 0.37353742122650146,
        "train_loss": 3.065335273742676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16248,
        "tokens": 8518631424,
        "learning_rate": 0.0003091808851624846,
        "gradient_norm": 0.33293673396110535,
        "train_loss": 3.087348222732544,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16249,
        "tokens": 8519155712,
        "learning_rate": 0.000309152324790995,
        "gradient_norm": 0.3533107042312622,
        "train_loss": 3.069334030151367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16250,
        "tokens": 8519680000,
        "learning_rate": 0.0003091237646541722,
        "gradient_norm": 0.3326807916164398,
        "train_loss": 3.1120829582214355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16251,
        "tokens": 8520204288,
        "learning_rate": 0.00030909520475233727,
        "gradient_norm": 0.3395938277244568,
        "train_loss": 3.132154941558838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16252,
        "tokens": 8520728576,
        "learning_rate": 0.000309066645085812,
        "gradient_norm": 0.31899550557136536,
        "train_loss": 3.125946044921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16253,
        "tokens": 8521252864,
        "learning_rate": 0.0003090380856549176,
        "gradient_norm": 0.3040289878845215,
        "train_loss": 3.0610909461975098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16254,
        "tokens": 8521777152,
        "learning_rate": 0.00030900952645997567,
        "gradient_norm": 0.31449419260025024,
        "train_loss": 3.058605909347534,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16255,
        "tokens": 8522301440,
        "learning_rate": 0.00030898096750130784,
        "gradient_norm": 0.3107473850250244,
        "train_loss": 3.080162286758423,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16256,
        "tokens": 8522825728,
        "learning_rate": 0.0003089524087792353,
        "gradient_norm": 0.3046489357948303,
        "train_loss": 3.107133388519287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16257,
        "tokens": 8523350016,
        "learning_rate": 0.00030892385029407973,
        "gradient_norm": 0.3240783214569092,
        "train_loss": 3.1261746883392334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16258,
        "tokens": 8523874304,
        "learning_rate": 0.00030889529204616243,
        "gradient_norm": 0.32084354758262634,
        "train_loss": 3.100621461868286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16259,
        "tokens": 8524398592,
        "learning_rate": 0.00030886673403580494,
        "gradient_norm": 0.3144959807395935,
        "train_loss": 3.1032304763793945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16260,
        "tokens": 8524922880,
        "learning_rate": 0.00030883817626332867,
        "gradient_norm": 0.3397168815135956,
        "train_loss": 3.086808204650879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16261,
        "tokens": 8525447168,
        "learning_rate": 0.0003088096187290552,
        "gradient_norm": 0.3132037818431854,
        "train_loss": 3.138195037841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16262,
        "tokens": 8525971456,
        "learning_rate": 0.00030878106143330576,
        "gradient_norm": 0.34970635175704956,
        "train_loss": 3.0982346534729004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16263,
        "tokens": 8526495744,
        "learning_rate": 0.00030875250437640205,
        "gradient_norm": 0.6270915269851685,
        "train_loss": 3.25070858001709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16264,
        "tokens": 8527020032,
        "learning_rate": 0.00030872394755866527,
        "gradient_norm": 0.44038116931915283,
        "train_loss": 3.1061599254608154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16265,
        "tokens": 8527544320,
        "learning_rate": 0.000308695390980417,
        "gradient_norm": 0.4088039696216583,
        "train_loss": 3.112299680709839,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16266,
        "tokens": 8528068608,
        "learning_rate": 0.00030866683464197877,
        "gradient_norm": 0.3562397360801697,
        "train_loss": 3.0537168979644775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16267,
        "tokens": 8528592896,
        "learning_rate": 0.00030863827854367177,
        "gradient_norm": 0.3579728603363037,
        "train_loss": 3.07045316696167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16268,
        "tokens": 8529117184,
        "learning_rate": 0.0003086097226858177,
        "gradient_norm": 0.3335799276828766,
        "train_loss": 3.074144124984741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16269,
        "tokens": 8529641472,
        "learning_rate": 0.00030858116706873774,
        "gradient_norm": 0.34989336133003235,
        "train_loss": 3.11337947845459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16270,
        "tokens": 8530165760,
        "learning_rate": 0.0003085526116927536,
        "gradient_norm": 0.33688294887542725,
        "train_loss": 3.117900848388672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16271,
        "tokens": 8530690048,
        "learning_rate": 0.0003085240565581864,
        "gradient_norm": 0.3352656066417694,
        "train_loss": 3.0993828773498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16272,
        "tokens": 8531214336,
        "learning_rate": 0.00030849550166535785,
        "gradient_norm": 0.3171979486942291,
        "train_loss": 3.089707374572754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16273,
        "tokens": 8531738624,
        "learning_rate": 0.00030846694701458906,
        "gradient_norm": 0.3329892158508301,
        "train_loss": 3.1490206718444824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16274,
        "tokens": 8532262912,
        "learning_rate": 0.00030843839260620174,
        "gradient_norm": 0.31005600094795227,
        "train_loss": 3.09857439994812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16275,
        "tokens": 8532787200,
        "learning_rate": 0.00030840983844051715,
        "gradient_norm": 0.3239201009273529,
        "train_loss": 3.0952706336975098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16276,
        "tokens": 8533311488,
        "learning_rate": 0.00030838128451785674,
        "gradient_norm": 0.32693564891815186,
        "train_loss": 3.1248812675476074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16277,
        "tokens": 8533835776,
        "learning_rate": 0.000308352730838542,
        "gradient_norm": 0.3858902156352997,
        "train_loss": 3.0804834365844727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16278,
        "tokens": 8534360064,
        "learning_rate": 0.0003083241774028942,
        "gradient_norm": 0.3060016334056854,
        "train_loss": 3.156942844390869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16279,
        "tokens": 8534884352,
        "learning_rate": 0.00030829562421123477,
        "gradient_norm": 0.38423919677734375,
        "train_loss": 3.1183266639709473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16280,
        "tokens": 8535408640,
        "learning_rate": 0.0003082670712638852,
        "gradient_norm": 0.31638041138648987,
        "train_loss": 3.100881338119507,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16281,
        "tokens": 8535932928,
        "learning_rate": 0.00030823851856116684,
        "gradient_norm": 0.3490220606327057,
        "train_loss": 3.052011251449585,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16282,
        "tokens": 8536457216,
        "learning_rate": 0.00030820996610340104,
        "gradient_norm": 0.340903639793396,
        "train_loss": 3.2016496658325195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16283,
        "tokens": 8536981504,
        "learning_rate": 0.0003081814138909092,
        "gradient_norm": 0.36176297068595886,
        "train_loss": 3.0870041847229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16284,
        "tokens": 8537505792,
        "learning_rate": 0.00030815286192401286,
        "gradient_norm": 0.3167528808116913,
        "train_loss": 3.0861682891845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16285,
        "tokens": 8538030080,
        "learning_rate": 0.00030812431020303313,
        "gradient_norm": 0.35302236676216125,
        "train_loss": 3.1173031330108643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16286,
        "tokens": 8538554368,
        "learning_rate": 0.0003080957587282917,
        "gradient_norm": 0.3128497004508972,
        "train_loss": 3.1573987007141113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16287,
        "tokens": 8539078656,
        "learning_rate": 0.00030806720750010974,
        "gradient_norm": 0.38312384486198425,
        "train_loss": 3.1253104209899902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16288,
        "tokens": 8539602944,
        "learning_rate": 0.0003080386565188088,
        "gradient_norm": 0.30116936564445496,
        "train_loss": 3.0929629802703857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16289,
        "tokens": 8540127232,
        "learning_rate": 0.00030801010578471,
        "gradient_norm": 0.32148832082748413,
        "train_loss": 3.0818238258361816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16290,
        "tokens": 8540651520,
        "learning_rate": 0.000307981555298135,
        "gradient_norm": 0.30405181646347046,
        "train_loss": 3.123368740081787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16291,
        "tokens": 8541175808,
        "learning_rate": 0.0003079530050594049,
        "gradient_norm": 0.29232901334762573,
        "train_loss": 3.146271228790283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16292,
        "tokens": 8541700096,
        "learning_rate": 0.0003079244550688414,
        "gradient_norm": 0.32409754395484924,
        "train_loss": 3.0410776138305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16293,
        "tokens": 8542224384,
        "learning_rate": 0.0003078959053267655,
        "gradient_norm": 0.29294657707214355,
        "train_loss": 3.107208251953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16294,
        "tokens": 8542748672,
        "learning_rate": 0.00030786735583349876,
        "gradient_norm": 0.33773088455200195,
        "train_loss": 3.0175423622131348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16295,
        "tokens": 8543272960,
        "learning_rate": 0.00030783880658936263,
        "gradient_norm": 0.32219982147216797,
        "train_loss": 3.078951120376587,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16296,
        "tokens": 8543797248,
        "learning_rate": 0.0003078102575946783,
        "gradient_norm": 0.349086731672287,
        "train_loss": 3.1528568267822266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16297,
        "tokens": 8544321536,
        "learning_rate": 0.0003077817088497672,
        "gradient_norm": 0.37611454725265503,
        "train_loss": 3.1777076721191406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16298,
        "tokens": 8544845824,
        "learning_rate": 0.0003077531603549506,
        "gradient_norm": 0.3046390414237976,
        "train_loss": 3.0619864463806152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16299,
        "tokens": 8545370112,
        "learning_rate": 0.00030772461211054996,
        "gradient_norm": 0.36383897066116333,
        "train_loss": 3.1370837688446045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16300,
        "tokens": 8545894400,
        "learning_rate": 0.00030769606411688654,
        "gradient_norm": 0.2759060263633728,
        "train_loss": 3.0418946743011475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16301,
        "tokens": 8546418688,
        "learning_rate": 0.00030766751637428184,
        "gradient_norm": 0.3742218017578125,
        "train_loss": 3.0929296016693115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16302,
        "tokens": 8546942976,
        "learning_rate": 0.00030763896888305695,
        "gradient_norm": 0.2879343330860138,
        "train_loss": 3.0861639976501465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16303,
        "tokens": 8547467264,
        "learning_rate": 0.0003076104216435334,
        "gradient_norm": 0.3284763991832733,
        "train_loss": 3.1140005588531494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16304,
        "tokens": 8547991552,
        "learning_rate": 0.0003075818746560324,
        "gradient_norm": 0.3256490230560303,
        "train_loss": 3.1068150997161865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16305,
        "tokens": 8548515840,
        "learning_rate": 0.00030755332792087536,
        "gradient_norm": 0.30668920278549194,
        "train_loss": 3.1217057704925537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16306,
        "tokens": 8549040128,
        "learning_rate": 0.00030752478143838367,
        "gradient_norm": 0.33527350425720215,
        "train_loss": 3.1290488243103027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16307,
        "tokens": 8549564416,
        "learning_rate": 0.0003074962352088785,
        "gradient_norm": 0.27692437171936035,
        "train_loss": 3.0758485794067383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16308,
        "tokens": 8550088704,
        "learning_rate": 0.00030746768923268136,
        "gradient_norm": 0.32643961906433105,
        "train_loss": 3.080350875854492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16309,
        "tokens": 8550612992,
        "learning_rate": 0.0003074391435101133,
        "gradient_norm": 0.27140921354293823,
        "train_loss": 3.1012420654296875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16310,
        "tokens": 8551137280,
        "learning_rate": 0.000307410598041496,
        "gradient_norm": 0.3383631408214569,
        "train_loss": 3.1437580585479736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16311,
        "tokens": 8551661568,
        "learning_rate": 0.0003073820528271504,
        "gradient_norm": 0.2804173231124878,
        "train_loss": 3.052030563354492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16312,
        "tokens": 8552185856,
        "learning_rate": 0.00030735350786739816,
        "gradient_norm": 0.29581308364868164,
        "train_loss": 3.1088247299194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16313,
        "tokens": 8552710144,
        "learning_rate": 0.0003073249631625603,
        "gradient_norm": 0.27802011370658875,
        "train_loss": 3.055006980895996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16314,
        "tokens": 8553234432,
        "learning_rate": 0.00030729641871295817,
        "gradient_norm": 0.2720981240272522,
        "train_loss": 3.0691795349121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16315,
        "tokens": 8553758720,
        "learning_rate": 0.0003072678745189133,
        "gradient_norm": 0.2944222092628479,
        "train_loss": 3.139955997467041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16316,
        "tokens": 8554283008,
        "learning_rate": 0.00030723933058074675,
        "gradient_norm": 0.25296279788017273,
        "train_loss": 3.0818862915039062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16317,
        "tokens": 8554807296,
        "learning_rate": 0.00030721078689878,
        "gradient_norm": 0.3207700848579407,
        "train_loss": 3.1280388832092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16318,
        "tokens": 8555331584,
        "learning_rate": 0.00030718224347333413,
        "gradient_norm": 0.29642847180366516,
        "train_loss": 3.094162940979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16319,
        "tokens": 8555855872,
        "learning_rate": 0.00030715370030473066,
        "gradient_norm": 0.2918941378593445,
        "train_loss": 3.092276096343994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16320,
        "tokens": 8556380160,
        "learning_rate": 0.00030712515739329067,
        "gradient_norm": 0.30560317635536194,
        "train_loss": 3.073878765106201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16321,
        "tokens": 8556904448,
        "learning_rate": 0.0003070966147393357,
        "gradient_norm": 0.2990630269050598,
        "train_loss": 3.135549306869507,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16322,
        "tokens": 8557428736,
        "learning_rate": 0.00030706807234318675,
        "gradient_norm": 0.3060612678527832,
        "train_loss": 3.092411518096924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16323,
        "tokens": 8557953024,
        "learning_rate": 0.0003070395302051653,
        "gradient_norm": 0.3175763785839081,
        "train_loss": 3.055727481842041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16324,
        "tokens": 8558477312,
        "learning_rate": 0.00030701098832559246,
        "gradient_norm": 0.3139387369155884,
        "train_loss": 3.0757975578308105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16325,
        "tokens": 8559001600,
        "learning_rate": 0.00030698244670478966,
        "gradient_norm": 0.3052706718444824,
        "train_loss": 3.0605592727661133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16326,
        "tokens": 8559525888,
        "learning_rate": 0.0003069539053430782,
        "gradient_norm": 0.301750510931015,
        "train_loss": 3.0472946166992188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16327,
        "tokens": 8560050176,
        "learning_rate": 0.0003069253642407791,
        "gradient_norm": 0.3646909296512604,
        "train_loss": 3.083545684814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16328,
        "tokens": 8560574464,
        "learning_rate": 0.00030689682339821395,
        "gradient_norm": 0.3171713948249817,
        "train_loss": 3.133389711380005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16329,
        "tokens": 8561098752,
        "learning_rate": 0.0003068682828157037,
        "gradient_norm": 0.3548644185066223,
        "train_loss": 3.144239902496338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16330,
        "tokens": 8561623040,
        "learning_rate": 0.0003068397424935699,
        "gradient_norm": 0.31531575322151184,
        "train_loss": 3.1043553352355957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16331,
        "tokens": 8562147328,
        "learning_rate": 0.00030681120243213354,
        "gradient_norm": 0.3159358501434326,
        "train_loss": 3.123591899871826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16332,
        "tokens": 8562671616,
        "learning_rate": 0.00030678266263171617,
        "gradient_norm": 0.34945595264434814,
        "train_loss": 3.0843899250030518,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16333,
        "tokens": 8563195904,
        "learning_rate": 0.0003067541230926387,
        "gradient_norm": 0.31513747572898865,
        "train_loss": 3.0998477935791016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16334,
        "tokens": 8563720192,
        "learning_rate": 0.0003067255838152226,
        "gradient_norm": 0.34584110975265503,
        "train_loss": 3.087092399597168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16335,
        "tokens": 8564244480,
        "learning_rate": 0.00030669704479978913,
        "gradient_norm": 0.33374181389808655,
        "train_loss": 3.1005382537841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16336,
        "tokens": 8564768768,
        "learning_rate": 0.0003066685060466594,
        "gradient_norm": 0.3450465202331543,
        "train_loss": 3.109104871749878,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16337,
        "tokens": 8565293056,
        "learning_rate": 0.00030663996755615476,
        "gradient_norm": 0.3474930226802826,
        "train_loss": 3.1340627670288086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16338,
        "tokens": 8565817344,
        "learning_rate": 0.0003066114293285964,
        "gradient_norm": 0.2968888282775879,
        "train_loss": 3.103693962097168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16339,
        "tokens": 8566341632,
        "learning_rate": 0.0003065828913643055,
        "gradient_norm": 0.3619409501552582,
        "train_loss": 3.1449763774871826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16340,
        "tokens": 8566865920,
        "learning_rate": 0.00030655435366360345,
        "gradient_norm": 0.2988753020763397,
        "train_loss": 3.100283622741699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16341,
        "tokens": 8567390208,
        "learning_rate": 0.00030652581622681133,
        "gradient_norm": 0.3754798173904419,
        "train_loss": 3.096235752105713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16342,
        "tokens": 8567914496,
        "learning_rate": 0.0003064972790542504,
        "gradient_norm": 0.32948827743530273,
        "train_loss": 3.040719509124756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16343,
        "tokens": 8568438784,
        "learning_rate": 0.00030646874214624193,
        "gradient_norm": 0.36299392580986023,
        "train_loss": 3.1537623405456543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16344,
        "tokens": 8568963072,
        "learning_rate": 0.00030644020550310704,
        "gradient_norm": 0.35212311148643494,
        "train_loss": 3.1257481575012207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16345,
        "tokens": 8569487360,
        "learning_rate": 0.000306411669125167,
        "gradient_norm": 0.3243744671344757,
        "train_loss": 3.1445021629333496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16346,
        "tokens": 8570011648,
        "learning_rate": 0.0003063831330127431,
        "gradient_norm": 0.32980892062187195,
        "train_loss": 3.076704978942871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16347,
        "tokens": 8570535936,
        "learning_rate": 0.00030635459716615637,
        "gradient_norm": 0.3041800260543823,
        "train_loss": 3.0936050415039062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16348,
        "tokens": 8571060224,
        "learning_rate": 0.00030632606158572826,
        "gradient_norm": 0.2955448627471924,
        "train_loss": 3.0921571254730225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16349,
        "tokens": 8571584512,
        "learning_rate": 0.0003062975262717797,
        "gradient_norm": 0.3127877414226532,
        "train_loss": 3.080720901489258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16350,
        "tokens": 8572108800,
        "learning_rate": 0.0003062689912246321,
        "gradient_norm": 0.2672867178916931,
        "train_loss": 3.1349735260009766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16351,
        "tokens": 8572633088,
        "learning_rate": 0.00030624045644460655,
        "gradient_norm": 0.364399254322052,
        "train_loss": 3.0742642879486084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16352,
        "tokens": 8573157376,
        "learning_rate": 0.00030621192193202435,
        "gradient_norm": 0.27616026997566223,
        "train_loss": 3.051548480987549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16353,
        "tokens": 8573681664,
        "learning_rate": 0.0003061833876872065,
        "gradient_norm": 0.3665587604045868,
        "train_loss": 3.1332850456237793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16354,
        "tokens": 8574205952,
        "learning_rate": 0.0003061548537104744,
        "gradient_norm": 0.31647032499313354,
        "train_loss": 3.080906629562378,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16355,
        "tokens": 8574730240,
        "learning_rate": 0.00030612632000214917,
        "gradient_norm": 0.3215673565864563,
        "train_loss": 3.1257529258728027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16356,
        "tokens": 8575254528,
        "learning_rate": 0.0003060977865625519,
        "gradient_norm": 0.26875534653663635,
        "train_loss": 3.0412497520446777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16357,
        "tokens": 8575778816,
        "learning_rate": 0.0003060692533920039,
        "gradient_norm": 0.33336326479911804,
        "train_loss": 3.08804988861084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16358,
        "tokens": 8576303104,
        "learning_rate": 0.0003060407204908262,
        "gradient_norm": 0.2798670530319214,
        "train_loss": 3.07291316986084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16359,
        "tokens": 8576827392,
        "learning_rate": 0.00030601218785934015,
        "gradient_norm": 0.4553944170475006,
        "train_loss": 3.143191337585449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16360,
        "tokens": 8577351680,
        "learning_rate": 0.0003059836554978668,
        "gradient_norm": 0.40440404415130615,
        "train_loss": 3.1474769115448,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16361,
        "tokens": 8577875968,
        "learning_rate": 0.00030595512340672734,
        "gradient_norm": 0.36508747935295105,
        "train_loss": 3.125034809112549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16362,
        "tokens": 8578400256,
        "learning_rate": 0.00030592659158624287,
        "gradient_norm": 0.33892756700515747,
        "train_loss": 3.0798192024230957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16363,
        "tokens": 8578924544,
        "learning_rate": 0.0003058980600367348,
        "gradient_norm": 0.33638790249824524,
        "train_loss": 3.1002655029296875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16364,
        "tokens": 8579448832,
        "learning_rate": 0.0003058695287585239,
        "gradient_norm": 0.31549108028411865,
        "train_loss": 3.1084165573120117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16365,
        "tokens": 8579973120,
        "learning_rate": 0.0003058409977519315,
        "gradient_norm": 0.33042970299720764,
        "train_loss": 3.1211442947387695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16366,
        "tokens": 8580497408,
        "learning_rate": 0.000305812467017279,
        "gradient_norm": 0.3311423659324646,
        "train_loss": 3.0799155235290527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16367,
        "tokens": 8581021696,
        "learning_rate": 0.0003057839365548872,
        "gradient_norm": 0.3535885214805603,
        "train_loss": 3.1589157581329346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16368,
        "tokens": 8581545984,
        "learning_rate": 0.0003057554063650775,
        "gradient_norm": 0.33699947595596313,
        "train_loss": 3.109663963317871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16369,
        "tokens": 8582070272,
        "learning_rate": 0.00030572687644817075,
        "gradient_norm": 0.32234713435173035,
        "train_loss": 3.104621410369873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16370,
        "tokens": 8582594560,
        "learning_rate": 0.0003056983468044884,
        "gradient_norm": 0.3795437514781952,
        "train_loss": 3.0317440032958984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16371,
        "tokens": 8583118848,
        "learning_rate": 0.0003056698174343514,
        "gradient_norm": 0.33165690302848816,
        "train_loss": 3.1271538734436035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16372,
        "tokens": 8583643136,
        "learning_rate": 0.000305641288338081,
        "gradient_norm": 0.40080246329307556,
        "train_loss": 3.0920145511627197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16373,
        "tokens": 8584167424,
        "learning_rate": 0.00030561275951599814,
        "gradient_norm": 0.3781645596027374,
        "train_loss": 3.157681465148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16374,
        "tokens": 8584691712,
        "learning_rate": 0.00030558423096842404,
        "gradient_norm": 0.38071244955062866,
        "train_loss": 3.0818324089050293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16375,
        "tokens": 8585216000,
        "learning_rate": 0.00030555570269568,
        "gradient_norm": 0.3634258806705475,
        "train_loss": 2.996029853820801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16376,
        "tokens": 8585740288,
        "learning_rate": 0.00030552717469808693,
        "gradient_norm": 0.3428124487400055,
        "train_loss": 3.1183385848999023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16377,
        "tokens": 8586264576,
        "learning_rate": 0.0003054986469759661,
        "gradient_norm": 0.35820916295051575,
        "train_loss": 3.1031410694122314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16378,
        "tokens": 8586788864,
        "learning_rate": 0.0003054701195296384,
        "gradient_norm": 0.3306438624858856,
        "train_loss": 3.069572925567627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16379,
        "tokens": 8587313152,
        "learning_rate": 0.00030544159235942523,
        "gradient_norm": 0.30701926350593567,
        "train_loss": 3.1022214889526367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16380,
        "tokens": 8587837440,
        "learning_rate": 0.00030541306546564743,
        "gradient_norm": 0.317554235458374,
        "train_loss": 3.1767303943634033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16381,
        "tokens": 8588361728,
        "learning_rate": 0.0003053845388486263,
        "gradient_norm": 0.3311207592487335,
        "train_loss": 3.0775113105773926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16382,
        "tokens": 8588886016,
        "learning_rate": 0.0003053560125086828,
        "gradient_norm": 0.32565492391586304,
        "train_loss": 3.095339775085449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16383,
        "tokens": 8589410304,
        "learning_rate": 0.0003053274864461382,
        "gradient_norm": 0.3242415487766266,
        "train_loss": 3.0829453468322754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16384,
        "tokens": 8589934592,
        "learning_rate": 0.0003052989606613134,
        "gradient_norm": 0.37342071533203125,
        "train_loss": 3.141188383102417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16385,
        "tokens": 8590458880,
        "learning_rate": 0.00030527043515452955,
        "gradient_norm": 0.35559946298599243,
        "train_loss": 3.064180374145508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16386,
        "tokens": 8590983168,
        "learning_rate": 0.00030524190992610786,
        "gradient_norm": 0.4172815978527069,
        "train_loss": 3.154730796813965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16387,
        "tokens": 8591507456,
        "learning_rate": 0.00030521338497636934,
        "gradient_norm": 0.3093419671058655,
        "train_loss": 3.1145501136779785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16388,
        "tokens": 8592031744,
        "learning_rate": 0.00030518486030563506,
        "gradient_norm": 0.37099146842956543,
        "train_loss": 3.106257915496826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16389,
        "tokens": 8592556032,
        "learning_rate": 0.0003051563359142261,
        "gradient_norm": 0.3180887997150421,
        "train_loss": 3.0396225452423096,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16390,
        "tokens": 8593080320,
        "learning_rate": 0.00030512781180246356,
        "gradient_norm": 0.33478185534477234,
        "train_loss": 3.0858168601989746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16391,
        "tokens": 8593604608,
        "learning_rate": 0.00030509928797066855,
        "gradient_norm": 0.2996201515197754,
        "train_loss": 3.129270076751709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16392,
        "tokens": 8594128896,
        "learning_rate": 0.00030507076441916203,
        "gradient_norm": 0.3271024525165558,
        "train_loss": 3.0885276794433594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16393,
        "tokens": 8594653184,
        "learning_rate": 0.00030504224114826515,
        "gradient_norm": 0.3335723280906677,
        "train_loss": 3.131822109222412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16394,
        "tokens": 8595177472,
        "learning_rate": 0.00030501371815829886,
        "gradient_norm": 0.2969840168952942,
        "train_loss": 3.1157445907592773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16395,
        "tokens": 8595701760,
        "learning_rate": 0.0003049851954495845,
        "gradient_norm": 0.32122698426246643,
        "train_loss": 3.143176317214966,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16396,
        "tokens": 8596226048,
        "learning_rate": 0.0003049566730224428,
        "gradient_norm": 0.2929063141345978,
        "train_loss": 3.1268692016601562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16397,
        "tokens": 8596750336,
        "learning_rate": 0.000304928150877195,
        "gradient_norm": 0.28632652759552,
        "train_loss": 3.1088621616363525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16398,
        "tokens": 8597274624,
        "learning_rate": 0.0003048996290141621,
        "gradient_norm": 0.28775298595428467,
        "train_loss": 3.132503032684326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16399,
        "tokens": 8597798912,
        "learning_rate": 0.0003048711074336653,
        "gradient_norm": 0.2949816584587097,
        "train_loss": 3.062328338623047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16400,
        "tokens": 8598323200,
        "learning_rate": 0.00030484258613602534,
        "gradient_norm": 0.3096942603588104,
        "train_loss": 3.072080612182617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16401,
        "tokens": 8598847488,
        "learning_rate": 0.00030481406512156356,
        "gradient_norm": 0.2949785590171814,
        "train_loss": 3.141575336456299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16402,
        "tokens": 8599371776,
        "learning_rate": 0.0003047855443906007,
        "gradient_norm": 0.3138865530490875,
        "train_loss": 3.147164821624756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16403,
        "tokens": 8599896064,
        "learning_rate": 0.0003047570239434582,
        "gradient_norm": 0.3170110881328583,
        "train_loss": 3.062243938446045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16404,
        "tokens": 8600420352,
        "learning_rate": 0.00030472850378045663,
        "gradient_norm": 0.33422815799713135,
        "train_loss": 3.0712332725524902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16405,
        "tokens": 8600944640,
        "learning_rate": 0.0003046999839019173,
        "gradient_norm": 0.3596447706222534,
        "train_loss": 3.1048288345336914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16406,
        "tokens": 8601468928,
        "learning_rate": 0.0003046714643081613,
        "gradient_norm": 0.2968239486217499,
        "train_loss": 3.0520925521850586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16407,
        "tokens": 8601993216,
        "learning_rate": 0.00030464294499950946,
        "gradient_norm": 0.33505305647850037,
        "train_loss": 3.135568380355835,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16408,
        "tokens": 8602517504,
        "learning_rate": 0.000304614425976283,
        "gradient_norm": 0.29666972160339355,
        "train_loss": 3.1133885383605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16409,
        "tokens": 8603041792,
        "learning_rate": 0.00030458590723880265,
        "gradient_norm": 0.33476901054382324,
        "train_loss": 3.1275248527526855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16410,
        "tokens": 8603566080,
        "learning_rate": 0.00030455738878738977,
        "gradient_norm": 0.2895374894142151,
        "train_loss": 3.0990400314331055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16411,
        "tokens": 8604090368,
        "learning_rate": 0.000304528870622365,
        "gradient_norm": 0.33024483919143677,
        "train_loss": 3.0569827556610107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16412,
        "tokens": 8604614656,
        "learning_rate": 0.0003045003527440497,
        "gradient_norm": 0.29665783047676086,
        "train_loss": 3.0691027641296387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16413,
        "tokens": 8605138944,
        "learning_rate": 0.0003044718351527646,
        "gradient_norm": 0.2804720997810364,
        "train_loss": 3.1202659606933594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16414,
        "tokens": 8605663232,
        "learning_rate": 0.0003044433178488308,
        "gradient_norm": 0.3172847330570221,
        "train_loss": 3.1155457496643066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16415,
        "tokens": 8606187520,
        "learning_rate": 0.0003044148008325695,
        "gradient_norm": 0.28801435232162476,
        "train_loss": 3.0783801078796387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16416,
        "tokens": 8606711808,
        "learning_rate": 0.00030438628410430136,
        "gradient_norm": 0.30619049072265625,
        "train_loss": 3.0978317260742188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16417,
        "tokens": 8607236096,
        "learning_rate": 0.0003043577676643476,
        "gradient_norm": 0.3077922463417053,
        "train_loss": 3.142948865890503,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16418,
        "tokens": 8607760384,
        "learning_rate": 0.00030432925151302904,
        "gradient_norm": 0.3055625855922699,
        "train_loss": 3.081636428833008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16419,
        "tokens": 8608284672,
        "learning_rate": 0.00030430073565066687,
        "gradient_norm": 0.3178471624851227,
        "train_loss": 3.093282699584961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16420,
        "tokens": 8608808960,
        "learning_rate": 0.0003042722200775818,
        "gradient_norm": 0.2816630005836487,
        "train_loss": 3.112165927886963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16421,
        "tokens": 8609333248,
        "learning_rate": 0.00030424370479409515,
        "gradient_norm": 0.3196013271808624,
        "train_loss": 3.079860210418701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16422,
        "tokens": 8609857536,
        "learning_rate": 0.0003042151898005275,
        "gradient_norm": 0.29517269134521484,
        "train_loss": 3.0984458923339844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16423,
        "tokens": 8610381824,
        "learning_rate": 0.0003041866750972002,
        "gradient_norm": 0.3040854036808014,
        "train_loss": 3.1295931339263916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16424,
        "tokens": 8610906112,
        "learning_rate": 0.000304158160684434,
        "gradient_norm": 0.3032240867614746,
        "train_loss": 3.1111416816711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16425,
        "tokens": 8611430400,
        "learning_rate": 0.0003041296465625498,
        "gradient_norm": 0.31107309460639954,
        "train_loss": 3.061450958251953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16426,
        "tokens": 8611954688,
        "learning_rate": 0.0003041011327318689,
        "gradient_norm": 0.33361420035362244,
        "train_loss": 3.1279780864715576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16427,
        "tokens": 8612478976,
        "learning_rate": 0.0003040726191927118,
        "gradient_norm": 0.33308160305023193,
        "train_loss": 3.089285135269165,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16428,
        "tokens": 8613003264,
        "learning_rate": 0.00030404410594539986,
        "gradient_norm": 0.33046504855155945,
        "train_loss": 3.0441431999206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16429,
        "tokens": 8613527552,
        "learning_rate": 0.0003040155929902537,
        "gradient_norm": 0.3443213105201721,
        "train_loss": 3.131936550140381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16430,
        "tokens": 8614051840,
        "learning_rate": 0.00030398708032759465,
        "gradient_norm": 0.33292555809020996,
        "train_loss": 3.1015701293945312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16431,
        "tokens": 8614576128,
        "learning_rate": 0.00030395856795774323,
        "gradient_norm": 0.3253139853477478,
        "train_loss": 3.114206075668335,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16432,
        "tokens": 8615100416,
        "learning_rate": 0.00030393005588102084,
        "gradient_norm": 0.33462825417518616,
        "train_loss": 3.181976079940796,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16433,
        "tokens": 8615624704,
        "learning_rate": 0.0003039015440977479,
        "gradient_norm": 0.34873083233833313,
        "train_loss": 3.0961413383483887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16434,
        "tokens": 8616148992,
        "learning_rate": 0.0003038730326082457,
        "gradient_norm": 0.3308403789997101,
        "train_loss": 3.0908737182617188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16435,
        "tokens": 8616673280,
        "learning_rate": 0.00030384452141283516,
        "gradient_norm": 0.2879912555217743,
        "train_loss": 3.107429027557373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16436,
        "tokens": 8617197568,
        "learning_rate": 0.0003038160105118371,
        "gradient_norm": 0.3344271183013916,
        "train_loss": 3.0565061569213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16437,
        "tokens": 8617721856,
        "learning_rate": 0.0003037874999055725,
        "gradient_norm": 0.2717357575893402,
        "train_loss": 3.102259635925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16438,
        "tokens": 8618246144,
        "learning_rate": 0.0003037589895943622,
        "gradient_norm": 0.2986298203468323,
        "train_loss": 3.1167707443237305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16439,
        "tokens": 8618770432,
        "learning_rate": 0.0003037304795785272,
        "gradient_norm": 0.3376084268093109,
        "train_loss": 3.064100742340088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16440,
        "tokens": 8619294720,
        "learning_rate": 0.00030370196985838845,
        "gradient_norm": 0.3121582567691803,
        "train_loss": 3.128392219543457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16441,
        "tokens": 8619819008,
        "learning_rate": 0.00030367346043426674,
        "gradient_norm": 0.32900869846343994,
        "train_loss": 3.128350257873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16442,
        "tokens": 8620343296,
        "learning_rate": 0.0003036449513064831,
        "gradient_norm": 0.29502031207084656,
        "train_loss": 3.117715835571289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16443,
        "tokens": 8620867584,
        "learning_rate": 0.00030361644247535837,
        "gradient_norm": 0.2989515960216522,
        "train_loss": 3.0533604621887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16444,
        "tokens": 8621391872,
        "learning_rate": 0.00030358793394121345,
        "gradient_norm": 0.29410648345947266,
        "train_loss": 3.066913604736328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16445,
        "tokens": 8621916160,
        "learning_rate": 0.00030355942570436923,
        "gradient_norm": 0.28960591554641724,
        "train_loss": 3.089175224304199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16446,
        "tokens": 8622440448,
        "learning_rate": 0.00030353091776514675,
        "gradient_norm": 0.3084312975406647,
        "train_loss": 3.1064586639404297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16447,
        "tokens": 8622964736,
        "learning_rate": 0.00030350241012386665,
        "gradient_norm": 0.302043080329895,
        "train_loss": 3.089235305786133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16448,
        "tokens": 8623489024,
        "learning_rate": 0.00030347390278085004,
        "gradient_norm": 0.3084045648574829,
        "train_loss": 3.1079354286193848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16449,
        "tokens": 8624013312,
        "learning_rate": 0.00030344539573641765,
        "gradient_norm": 0.27918681502342224,
        "train_loss": 3.065674304962158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16450,
        "tokens": 8624537600,
        "learning_rate": 0.00030341688899089054,
        "gradient_norm": 0.31164494156837463,
        "train_loss": 3.1056861877441406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16451,
        "tokens": 8625061888,
        "learning_rate": 0.00030338838254458935,
        "gradient_norm": 0.3656601011753082,
        "train_loss": 3.130242347717285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16452,
        "tokens": 8625586176,
        "learning_rate": 0.0003033598763978352,
        "gradient_norm": 0.31267493963241577,
        "train_loss": 3.1398556232452393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16453,
        "tokens": 8626110464,
        "learning_rate": 0.00030333137055094876,
        "gradient_norm": 0.3223135769367218,
        "train_loss": 3.0731658935546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16454,
        "tokens": 8626634752,
        "learning_rate": 0.000303302865004251,
        "gradient_norm": 0.35649973154067993,
        "train_loss": 3.0980782508850098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16455,
        "tokens": 8627159040,
        "learning_rate": 0.0003032743597580629,
        "gradient_norm": 0.27188611030578613,
        "train_loss": 3.1159121990203857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16456,
        "tokens": 8627683328,
        "learning_rate": 0.00030324585481270505,
        "gradient_norm": 0.34403863549232483,
        "train_loss": 3.0616438388824463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16457,
        "tokens": 8628207616,
        "learning_rate": 0.0003032173501684985,
        "gradient_norm": 0.2923823595046997,
        "train_loss": 3.0974624156951904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16458,
        "tokens": 8628731904,
        "learning_rate": 0.00030318884582576405,
        "gradient_norm": 0.30875933170318604,
        "train_loss": 3.0250186920166016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16459,
        "tokens": 8629256192,
        "learning_rate": 0.00030316034178482263,
        "gradient_norm": 0.3125956058502197,
        "train_loss": 3.0949299335479736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16460,
        "tokens": 8629780480,
        "learning_rate": 0.0003031318380459949,
        "gradient_norm": 0.27196502685546875,
        "train_loss": 3.1077237129211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16461,
        "tokens": 8630304768,
        "learning_rate": 0.00030310333460960195,
        "gradient_norm": 0.3220229744911194,
        "train_loss": 3.130280017852783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16462,
        "tokens": 8630829056,
        "learning_rate": 0.0003030748314759644,
        "gradient_norm": 0.29139596223831177,
        "train_loss": 3.1471915245056152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16463,
        "tokens": 8631353344,
        "learning_rate": 0.00030304632864540317,
        "gradient_norm": 0.32579439878463745,
        "train_loss": 3.1242480278015137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16464,
        "tokens": 8631877632,
        "learning_rate": 0.0003030178261182392,
        "gradient_norm": 0.2946140766143799,
        "train_loss": 3.0794081687927246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16465,
        "tokens": 8632401920,
        "learning_rate": 0.00030298932389479313,
        "gradient_norm": 0.31091034412384033,
        "train_loss": 3.084385633468628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16466,
        "tokens": 8632926208,
        "learning_rate": 0.000302960821975386,
        "gradient_norm": 0.31373268365859985,
        "train_loss": 3.0699832439422607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16467,
        "tokens": 8633450496,
        "learning_rate": 0.0003029323203603384,
        "gradient_norm": 0.2993675768375397,
        "train_loss": 3.169316291809082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16468,
        "tokens": 8633974784,
        "learning_rate": 0.00030290381904997144,
        "gradient_norm": 0.31147411465644836,
        "train_loss": 3.14197039604187,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16469,
        "tokens": 8634499072,
        "learning_rate": 0.0003028753180446056,
        "gradient_norm": 0.35572612285614014,
        "train_loss": 3.364259719848633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16470,
        "tokens": 8635023360,
        "learning_rate": 0.00030284681734456205,
        "gradient_norm": 0.3349613547325134,
        "train_loss": 3.1033670902252197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16471,
        "tokens": 8635547648,
        "learning_rate": 0.00030281831695016127,
        "gradient_norm": 0.32407253980636597,
        "train_loss": 3.0914711952209473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16472,
        "tokens": 8636071936,
        "learning_rate": 0.00030278981686172434,
        "gradient_norm": 0.32268470525741577,
        "train_loss": 3.0792927742004395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16473,
        "tokens": 8636596224,
        "learning_rate": 0.00030276131707957177,
        "gradient_norm": 0.3242731988430023,
        "train_loss": 3.081871509552002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16474,
        "tokens": 8637120512,
        "learning_rate": 0.0003027328176040246,
        "gradient_norm": 0.3603162169456482,
        "train_loss": 3.2970409393310547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16475,
        "tokens": 8637644800,
        "learning_rate": 0.0003027043184354036,
        "gradient_norm": 0.3887053430080414,
        "train_loss": 3.0584850311279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16476,
        "tokens": 8638169088,
        "learning_rate": 0.0003026758195740295,
        "gradient_norm": 0.34994229674339294,
        "train_loss": 3.1155500411987305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16477,
        "tokens": 8638693376,
        "learning_rate": 0.0003026473210202231,
        "gradient_norm": 0.35651591420173645,
        "train_loss": 3.072570323944092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16478,
        "tokens": 8639217664,
        "learning_rate": 0.0003026188227743052,
        "gradient_norm": 0.36569467186927795,
        "train_loss": 3.1287481784820557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16479,
        "tokens": 8639741952,
        "learning_rate": 0.00030259032483659663,
        "gradient_norm": 0.35716360807418823,
        "train_loss": 3.074284791946411,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16480,
        "tokens": 8640266240,
        "learning_rate": 0.00030256182720741803,
        "gradient_norm": 0.3388639986515045,
        "train_loss": 3.126807451248169,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16481,
        "tokens": 8640790528,
        "learning_rate": 0.00030253332988709037,
        "gradient_norm": 0.3400701582431793,
        "train_loss": 3.063666820526123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16482,
        "tokens": 8641314816,
        "learning_rate": 0.0003025048328759342,
        "gradient_norm": 0.3131266236305237,
        "train_loss": 3.085552215576172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16483,
        "tokens": 8641839104,
        "learning_rate": 0.0003024763361742705,
        "gradient_norm": 0.33639127016067505,
        "train_loss": 3.075212001800537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16484,
        "tokens": 8642363392,
        "learning_rate": 0.0003024478397824199,
        "gradient_norm": 0.33277207612991333,
        "train_loss": 3.0821290016174316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16485,
        "tokens": 8642887680,
        "learning_rate": 0.00030241934370070327,
        "gradient_norm": 0.3699226379394531,
        "train_loss": 3.0746188163757324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16486,
        "tokens": 8643411968,
        "learning_rate": 0.00030239084792944127,
        "gradient_norm": 0.3364934027194977,
        "train_loss": 3.098367214202881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16487,
        "tokens": 8643936256,
        "learning_rate": 0.0003023623524689547,
        "gradient_norm": 0.37691646814346313,
        "train_loss": 3.120877742767334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16488,
        "tokens": 8644460544,
        "learning_rate": 0.0003023338573195643,
        "gradient_norm": 0.282814621925354,
        "train_loss": 3.0629472732543945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16489,
        "tokens": 8644984832,
        "learning_rate": 0.00030230536248159086,
        "gradient_norm": 0.37256765365600586,
        "train_loss": 3.1269171237945557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16490,
        "tokens": 8645509120,
        "learning_rate": 0.000302276867955355,
        "gradient_norm": 0.30925989151000977,
        "train_loss": 3.0783307552337646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16491,
        "tokens": 8646033408,
        "learning_rate": 0.0003022483737411776,
        "gradient_norm": 0.33145853877067566,
        "train_loss": 3.0692689418792725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16492,
        "tokens": 8646557696,
        "learning_rate": 0.00030221987983937936,
        "gradient_norm": 0.2817670404911041,
        "train_loss": 3.062331199645996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16493,
        "tokens": 8647081984,
        "learning_rate": 0.000302191386250281,
        "gradient_norm": 0.3195221722126007,
        "train_loss": 3.1096458435058594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16494,
        "tokens": 8647606272,
        "learning_rate": 0.0003021628929742032,
        "gradient_norm": 0.3024643659591675,
        "train_loss": 3.0827672481536865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16495,
        "tokens": 8648130560,
        "learning_rate": 0.0003021344000114668,
        "gradient_norm": 0.29641473293304443,
        "train_loss": 3.1503219604492188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16496,
        "tokens": 8648654848,
        "learning_rate": 0.00030210590736239236,
        "gradient_norm": 0.28831008076667786,
        "train_loss": 3.0578622817993164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16497,
        "tokens": 8649179136,
        "learning_rate": 0.00030207741502730087,
        "gradient_norm": 0.28433406352996826,
        "train_loss": 3.0878427028656006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16498,
        "tokens": 8649703424,
        "learning_rate": 0.00030204892300651277,
        "gradient_norm": 0.3311336636543274,
        "train_loss": 3.101595401763916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16499,
        "tokens": 8650227712,
        "learning_rate": 0.0003020204313003489,
        "gradient_norm": 0.2744573652744293,
        "train_loss": 3.02955961227417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16500,
        "tokens": 8650752000,
        "learning_rate": 0.00030199193990912995,
        "gradient_norm": 0.3124951422214508,
        "train_loss": 3.066873073577881,
        "val_loss": 3.058150291442871,
        "hellaswag_acc": 0.2795259952545166,
        "hellaswag_acc_norm": 0.29247161746025085
    },
    {
        "step": 16501,
        "tokens": 8651276288,
        "learning_rate": 0.00030196344883317666,
        "gradient_norm": 0.3017459809780121,
        "train_loss": 3.114272117614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16502,
        "tokens": 8651800576,
        "learning_rate": 0.0003019349580728097,
        "gradient_norm": 0.32467755675315857,
        "train_loss": 3.0921270847320557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16503,
        "tokens": 8652324864,
        "learning_rate": 0.0003019064676283497,
        "gradient_norm": 0.29514622688293457,
        "train_loss": 3.100342273712158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16504,
        "tokens": 8652849152,
        "learning_rate": 0.0003018779775001175,
        "gradient_norm": 0.290286123752594,
        "train_loss": 3.074206829071045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16505,
        "tokens": 8653373440,
        "learning_rate": 0.0003018494876884336,
        "gradient_norm": 0.29369619488716125,
        "train_loss": 3.0680556297302246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16506,
        "tokens": 8653897728,
        "learning_rate": 0.00030182099819361897,
        "gradient_norm": 0.26100656390190125,
        "train_loss": 3.086660861968994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16507,
        "tokens": 8654422016,
        "learning_rate": 0.000301792509015994,
        "gradient_norm": 0.29361289739608765,
        "train_loss": 3.078673839569092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16508,
        "tokens": 8654946304,
        "learning_rate": 0.0003017640201558796,
        "gradient_norm": 0.29103511571884155,
        "train_loss": 3.1323888301849365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16509,
        "tokens": 8655470592,
        "learning_rate": 0.00030173553161359627,
        "gradient_norm": 0.2881931960582733,
        "train_loss": 3.134277820587158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16510,
        "tokens": 8655994880,
        "learning_rate": 0.0003017070433894649,
        "gradient_norm": 0.29998692870140076,
        "train_loss": 3.1075708866119385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16511,
        "tokens": 8656519168,
        "learning_rate": 0.00030167855548380587,
        "gradient_norm": 0.30499982833862305,
        "train_loss": 3.089046001434326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16512,
        "tokens": 8657043456,
        "learning_rate": 0.0003016500678969401,
        "gradient_norm": 0.3131633400917053,
        "train_loss": 3.0648560523986816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16513,
        "tokens": 8657567744,
        "learning_rate": 0.00030162158062918814,
        "gradient_norm": 0.29163658618927,
        "train_loss": 3.085927963256836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16514,
        "tokens": 8658092032,
        "learning_rate": 0.0003015930936808705,
        "gradient_norm": 0.31580477952957153,
        "train_loss": 3.060202121734619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16515,
        "tokens": 8658616320,
        "learning_rate": 0.0003015646070523083,
        "gradient_norm": 0.2812296450138092,
        "train_loss": 3.0266048908233643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16516,
        "tokens": 8659140608,
        "learning_rate": 0.00030153612074382166,
        "gradient_norm": 0.4154832363128662,
        "train_loss": 3.1053342819213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16517,
        "tokens": 8659664896,
        "learning_rate": 0.0003015076347557316,
        "gradient_norm": 0.3649201989173889,
        "train_loss": 3.08821177482605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16518,
        "tokens": 8660189184,
        "learning_rate": 0.0003014791490883585,
        "gradient_norm": 0.338227242231369,
        "train_loss": 3.149080276489258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16519,
        "tokens": 8660713472,
        "learning_rate": 0.0003014506637420233,
        "gradient_norm": 0.34778764843940735,
        "train_loss": 3.0427000522613525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16520,
        "tokens": 8661237760,
        "learning_rate": 0.0003014221787170463,
        "gradient_norm": 0.37040257453918457,
        "train_loss": 3.09965181350708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16521,
        "tokens": 8661762048,
        "learning_rate": 0.00030139369401374844,
        "gradient_norm": 0.3400523364543915,
        "train_loss": 3.1279332637786865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16522,
        "tokens": 8662286336,
        "learning_rate": 0.00030136520963245,
        "gradient_norm": 0.3510003089904785,
        "train_loss": 3.0876173973083496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16523,
        "tokens": 8662810624,
        "learning_rate": 0.000301336725573472,
        "gradient_norm": 0.35384514927864075,
        "train_loss": 3.093416929244995,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16524,
        "tokens": 8663334912,
        "learning_rate": 0.00030130824183713487,
        "gradient_norm": 0.3107018768787384,
        "train_loss": 3.1210060119628906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16525,
        "tokens": 8663859200,
        "learning_rate": 0.0003012797584237592,
        "gradient_norm": 0.36569273471832275,
        "train_loss": 3.078653335571289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16526,
        "tokens": 8664383488,
        "learning_rate": 0.0003012512753336657,
        "gradient_norm": 0.31809139251708984,
        "train_loss": 3.1001553535461426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16527,
        "tokens": 8664907776,
        "learning_rate": 0.00030122279256717484,
        "gradient_norm": 0.3393189013004303,
        "train_loss": 3.0448460578918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16528,
        "tokens": 8665432064,
        "learning_rate": 0.00030119431012460743,
        "gradient_norm": 0.303587943315506,
        "train_loss": 3.0902280807495117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16529,
        "tokens": 8665956352,
        "learning_rate": 0.00030116582800628387,
        "gradient_norm": 0.3499685823917389,
        "train_loss": 3.1444835662841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16530,
        "tokens": 8666480640,
        "learning_rate": 0.00030113734621252494,
        "gradient_norm": 0.28966471552848816,
        "train_loss": 3.0744261741638184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16531,
        "tokens": 8667004928,
        "learning_rate": 0.0003011088647436511,
        "gradient_norm": 0.3374461531639099,
        "train_loss": 3.1083970069885254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16532,
        "tokens": 8667529216,
        "learning_rate": 0.00030108038359998306,
        "gradient_norm": 0.30816665291786194,
        "train_loss": 3.0844802856445312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16533,
        "tokens": 8668053504,
        "learning_rate": 0.0003010519027818413,
        "gradient_norm": 0.3038564622402191,
        "train_loss": 3.0387377738952637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16534,
        "tokens": 8668577792,
        "learning_rate": 0.0003010234222895464,
        "gradient_norm": 0.3148021996021271,
        "train_loss": 3.0762648582458496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16535,
        "tokens": 8669102080,
        "learning_rate": 0.00030099494212341917,
        "gradient_norm": 0.3407565653324127,
        "train_loss": 3.1024622917175293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16536,
        "tokens": 8669626368,
        "learning_rate": 0.00030096646228377984,
        "gradient_norm": 0.36751094460487366,
        "train_loss": 3.149055004119873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16537,
        "tokens": 8670150656,
        "learning_rate": 0.0003009379827709493,
        "gradient_norm": 0.3414647877216339,
        "train_loss": 3.123544454574585,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16538,
        "tokens": 8670674944,
        "learning_rate": 0.0003009095035852479,
        "gradient_norm": 0.32836100459098816,
        "train_loss": 3.1153347492218018,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16539,
        "tokens": 8671199232,
        "learning_rate": 0.0003008810247269964,
        "gradient_norm": 0.3223329186439514,
        "train_loss": 3.129302740097046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16540,
        "tokens": 8671723520,
        "learning_rate": 0.0003008525461965152,
        "gradient_norm": 0.35584574937820435,
        "train_loss": 3.172048568725586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16541,
        "tokens": 8672247808,
        "learning_rate": 0.00030082406799412497,
        "gradient_norm": 0.3153356909751892,
        "train_loss": 3.092595100402832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16542,
        "tokens": 8672772096,
        "learning_rate": 0.0003007955901201462,
        "gradient_norm": 0.35141777992248535,
        "train_loss": 3.1256163120269775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16543,
        "tokens": 8673296384,
        "learning_rate": 0.0003007671125748994,
        "gradient_norm": 0.3196195960044861,
        "train_loss": 3.06534481048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16544,
        "tokens": 8673820672,
        "learning_rate": 0.00030073863535870526,
        "gradient_norm": 0.3076176643371582,
        "train_loss": 3.060115337371826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16545,
        "tokens": 8674344960,
        "learning_rate": 0.00030071015847188426,
        "gradient_norm": 0.3157750070095062,
        "train_loss": 3.1141910552978516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16546,
        "tokens": 8674869248,
        "learning_rate": 0.0003006816819147569,
        "gradient_norm": 0.3070942163467407,
        "train_loss": 3.144224166870117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16547,
        "tokens": 8675393536,
        "learning_rate": 0.0003006532056876438,
        "gradient_norm": 0.3279845118522644,
        "train_loss": 3.0699262619018555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16548,
        "tokens": 8675917824,
        "learning_rate": 0.0003006247297908654,
        "gradient_norm": 0.3115561902523041,
        "train_loss": 3.0954689979553223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16549,
        "tokens": 8676442112,
        "learning_rate": 0.0003005962542247423,
        "gradient_norm": 0.31300681829452515,
        "train_loss": 3.0712149143218994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16550,
        "tokens": 8676966400,
        "learning_rate": 0.000300567778989595,
        "gradient_norm": 0.3049107789993286,
        "train_loss": 3.050159454345703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16551,
        "tokens": 8677490688,
        "learning_rate": 0.00030053930408574406,
        "gradient_norm": 0.30599895119667053,
        "train_loss": 3.074431896209717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16552,
        "tokens": 8678014976,
        "learning_rate": 0.00030051082951351,
        "gradient_norm": 0.3057918846607208,
        "train_loss": 3.067835807800293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16553,
        "tokens": 8678539264,
        "learning_rate": 0.00030048235527321333,
        "gradient_norm": 0.30823400616645813,
        "train_loss": 3.06988787651062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16554,
        "tokens": 8679063552,
        "learning_rate": 0.0003004538813651744,
        "gradient_norm": 0.29693329334259033,
        "train_loss": 3.0909786224365234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16555,
        "tokens": 8679587840,
        "learning_rate": 0.00030042540778971405,
        "gradient_norm": 0.33100640773773193,
        "train_loss": 3.1255483627319336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16556,
        "tokens": 8680112128,
        "learning_rate": 0.0003003969345471524,
        "gradient_norm": 0.28167006373405457,
        "train_loss": 3.1298000812530518,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16557,
        "tokens": 8680636416,
        "learning_rate": 0.0003003684616378104,
        "gradient_norm": 0.3048969805240631,
        "train_loss": 3.1071624755859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16558,
        "tokens": 8681160704,
        "learning_rate": 0.00030033998906200813,
        "gradient_norm": 0.3000587224960327,
        "train_loss": 3.0943470001220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16559,
        "tokens": 8681684992,
        "learning_rate": 0.00030031151682006634,
        "gradient_norm": 0.31169548630714417,
        "train_loss": 3.0954959392547607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16560,
        "tokens": 8682209280,
        "learning_rate": 0.00030028304491230536,
        "gradient_norm": 0.3156162202358246,
        "train_loss": 3.0897674560546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16561,
        "tokens": 8682733568,
        "learning_rate": 0.00030025457333904585,
        "gradient_norm": 0.3155065178871155,
        "train_loss": 3.071072816848755,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16562,
        "tokens": 8683257856,
        "learning_rate": 0.00030022610210060803,
        "gradient_norm": 0.29008084535598755,
        "train_loss": 3.094503879547119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16563,
        "tokens": 8683782144,
        "learning_rate": 0.0003001976311973126,
        "gradient_norm": 0.31268808245658875,
        "train_loss": 3.0676395893096924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16564,
        "tokens": 8684306432,
        "learning_rate": 0.0003001691606294801,
        "gradient_norm": 0.27539321780204773,
        "train_loss": 3.0672810077667236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16565,
        "tokens": 8684830720,
        "learning_rate": 0.00030014069039743075,
        "gradient_norm": 0.2989460229873657,
        "train_loss": 3.1076555252075195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16566,
        "tokens": 8685355008,
        "learning_rate": 0.0003001122205014853,
        "gradient_norm": 0.32009539008140564,
        "train_loss": 3.173241138458252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16567,
        "tokens": 8685879296,
        "learning_rate": 0.00030008375094196386,
        "gradient_norm": 0.30093318223953247,
        "train_loss": 3.1440227031707764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16568,
        "tokens": 8686403584,
        "learning_rate": 0.0003000552817191873,
        "gradient_norm": 0.3380189836025238,
        "train_loss": 3.127542495727539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16569,
        "tokens": 8686927872,
        "learning_rate": 0.0003000268128334757,
        "gradient_norm": 0.3002541661262512,
        "train_loss": 3.064976692199707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16570,
        "tokens": 8687452160,
        "learning_rate": 0.00029999834428514986,
        "gradient_norm": 0.3123416602611542,
        "train_loss": 3.089921474456787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16571,
        "tokens": 8687976448,
        "learning_rate": 0.0002999698760745299,
        "gradient_norm": 0.31272417306900024,
        "train_loss": 3.0384416580200195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16572,
        "tokens": 8688500736,
        "learning_rate": 0.0002999414082019365,
        "gradient_norm": 0.3297242224216461,
        "train_loss": 3.0914065837860107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16573,
        "tokens": 8689025024,
        "learning_rate": 0.00029991294066768995,
        "gradient_norm": 0.29984050989151,
        "train_loss": 3.0855679512023926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16574,
        "tokens": 8689549312,
        "learning_rate": 0.00029988447347211074,
        "gradient_norm": 0.3278155028820038,
        "train_loss": 3.0740203857421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16575,
        "tokens": 8690073600,
        "learning_rate": 0.0002998560066155195,
        "gradient_norm": 0.3215157389640808,
        "train_loss": 3.088747978210449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16576,
        "tokens": 8690597888,
        "learning_rate": 0.0002998275400982363,
        "gradient_norm": 0.3055576980113983,
        "train_loss": 3.021528720855713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16577,
        "tokens": 8691122176,
        "learning_rate": 0.0002997990739205818,
        "gradient_norm": 0.29391446709632874,
        "train_loss": 3.0831305980682373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16578,
        "tokens": 8691646464,
        "learning_rate": 0.00029977060808287635,
        "gradient_norm": 0.3184669613838196,
        "train_loss": 3.111445426940918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16579,
        "tokens": 8692170752,
        "learning_rate": 0.0002997421425854405,
        "gradient_norm": 0.33745336532592773,
        "train_loss": 3.0801072120666504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16580,
        "tokens": 8692695040,
        "learning_rate": 0.0002997136774285944,
        "gradient_norm": 0.30626511573791504,
        "train_loss": 3.1148719787597656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16581,
        "tokens": 8693219328,
        "learning_rate": 0.00029968521261265876,
        "gradient_norm": 0.3447287976741791,
        "train_loss": 3.1349291801452637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16582,
        "tokens": 8693743616,
        "learning_rate": 0.00029965674813795375,
        "gradient_norm": 0.2921122908592224,
        "train_loss": 3.0807414054870605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16583,
        "tokens": 8694267904,
        "learning_rate": 0.00029962828400479974,
        "gradient_norm": 0.43525391817092896,
        "train_loss": 3.1393532752990723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16584,
        "tokens": 8694792192,
        "learning_rate": 0.00029959982021351755,
        "gradient_norm": 0.31332629919052124,
        "train_loss": 3.0579166412353516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16585,
        "tokens": 8695316480,
        "learning_rate": 0.000299571356764427,
        "gradient_norm": 0.3214355409145355,
        "train_loss": 3.0522751808166504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16586,
        "tokens": 8695840768,
        "learning_rate": 0.000299542893657849,
        "gradient_norm": 0.31769299507141113,
        "train_loss": 3.0860610008239746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16587,
        "tokens": 8696365056,
        "learning_rate": 0.00029951443089410346,
        "gradient_norm": 0.31359565258026123,
        "train_loss": 3.0648279190063477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16588,
        "tokens": 8696889344,
        "learning_rate": 0.0002994859684735112,
        "gradient_norm": 0.31966257095336914,
        "train_loss": 3.052051544189453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16589,
        "tokens": 8697413632,
        "learning_rate": 0.00029945750639639226,
        "gradient_norm": 0.31492331624031067,
        "train_loss": 3.087428569793701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16590,
        "tokens": 8697937920,
        "learning_rate": 0.0002994290446630673,
        "gradient_norm": 0.31884676218032837,
        "train_loss": 3.0673136711120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16591,
        "tokens": 8698462208,
        "learning_rate": 0.0002994005832738564,
        "gradient_norm": 0.310131311416626,
        "train_loss": 3.0636911392211914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16592,
        "tokens": 8698986496,
        "learning_rate": 0.0002993721222290802,
        "gradient_norm": 0.30302587151527405,
        "train_loss": 3.0974278450012207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16593,
        "tokens": 8699510784,
        "learning_rate": 0.00029934366152905884,
        "gradient_norm": 0.29631027579307556,
        "train_loss": 3.1046719551086426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16594,
        "tokens": 8700035072,
        "learning_rate": 0.0002993152011741128,
        "gradient_norm": 0.3833674192428589,
        "train_loss": 3.208512306213379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16595,
        "tokens": 8700559360,
        "learning_rate": 0.0002992867411645625,
        "gradient_norm": 0.3293011486530304,
        "train_loss": 3.049825668334961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16596,
        "tokens": 8701083648,
        "learning_rate": 0.00029925828150072816,
        "gradient_norm": 0.3271655738353729,
        "train_loss": 3.083399772644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16597,
        "tokens": 8701607936,
        "learning_rate": 0.0002992298221829302,
        "gradient_norm": 0.3189418315887451,
        "train_loss": 3.17636775970459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16598,
        "tokens": 8702132224,
        "learning_rate": 0.0002992013632114889,
        "gradient_norm": 0.3202003538608551,
        "train_loss": 3.135481595993042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16599,
        "tokens": 8702656512,
        "learning_rate": 0.00029917290458672475,
        "gradient_norm": 0.3053937554359436,
        "train_loss": 3.108919143676758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16600,
        "tokens": 8703180800,
        "learning_rate": 0.0002991444463089579,
        "gradient_norm": 0.331909716129303,
        "train_loss": 3.0890555381774902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16601,
        "tokens": 8703705088,
        "learning_rate": 0.0002991159883785088,
        "gradient_norm": 0.3096786439418793,
        "train_loss": 3.0475687980651855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16602,
        "tokens": 8704229376,
        "learning_rate": 0.0002990875307956977,
        "gradient_norm": 0.31632786989212036,
        "train_loss": 3.0936965942382812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16603,
        "tokens": 8704753664,
        "learning_rate": 0.000299059073560845,
        "gradient_norm": 0.2985345423221588,
        "train_loss": 3.1357674598693848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16604,
        "tokens": 8705277952,
        "learning_rate": 0.00029903061667427104,
        "gradient_norm": 0.31217408180236816,
        "train_loss": 3.1156716346740723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16605,
        "tokens": 8705802240,
        "learning_rate": 0.0002990021601362961,
        "gradient_norm": 0.31816986203193665,
        "train_loss": 3.053330421447754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16606,
        "tokens": 8706326528,
        "learning_rate": 0.00029897370394724046,
        "gradient_norm": 0.3066505491733551,
        "train_loss": 3.0275938510894775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16607,
        "tokens": 8706850816,
        "learning_rate": 0.00029894524810742437,
        "gradient_norm": 0.3231002986431122,
        "train_loss": 3.101985454559326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16608,
        "tokens": 8707375104,
        "learning_rate": 0.0002989167926171684,
        "gradient_norm": 0.33742523193359375,
        "train_loss": 3.086352825164795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16609,
        "tokens": 8707899392,
        "learning_rate": 0.00029888833747679247,
        "gradient_norm": 0.347960889339447,
        "train_loss": 3.0776195526123047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16610,
        "tokens": 8708423680,
        "learning_rate": 0.00029885988268661727,
        "gradient_norm": 0.32080382108688354,
        "train_loss": 3.098947048187256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16611,
        "tokens": 8708947968,
        "learning_rate": 0.0002988314282469628,
        "gradient_norm": 0.36453938484191895,
        "train_loss": 3.1266255378723145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16612,
        "tokens": 8709472256,
        "learning_rate": 0.0002988029741581495,
        "gradient_norm": 0.29775968194007874,
        "train_loss": 3.109818458557129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16613,
        "tokens": 8709996544,
        "learning_rate": 0.0002987745204204975,
        "gradient_norm": 0.3968826234340668,
        "train_loss": 3.2290868759155273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16614,
        "tokens": 8710520832,
        "learning_rate": 0.0002987460670343273,
        "gradient_norm": 0.3377733528614044,
        "train_loss": 3.0936989784240723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16615,
        "tokens": 8711045120,
        "learning_rate": 0.00029871761399995916,
        "gradient_norm": 0.327681303024292,
        "train_loss": 3.0747790336608887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16616,
        "tokens": 8711569408,
        "learning_rate": 0.0002986891613177131,
        "gradient_norm": 0.3252873420715332,
        "train_loss": 3.0892229080200195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16617,
        "tokens": 8712093696,
        "learning_rate": 0.0002986607089879097,
        "gradient_norm": 0.3455287516117096,
        "train_loss": 3.1550581455230713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16618,
        "tokens": 8712617984,
        "learning_rate": 0.0002986322570108689,
        "gradient_norm": 0.298467218875885,
        "train_loss": 3.105440855026245,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16619,
        "tokens": 8713142272,
        "learning_rate": 0.0002986038053869114,
        "gradient_norm": 0.3382904529571533,
        "train_loss": 3.1186695098876953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16620,
        "tokens": 8713666560,
        "learning_rate": 0.00029857535411635704,
        "gradient_norm": 0.35528331995010376,
        "train_loss": 3.075256824493408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16621,
        "tokens": 8714190848,
        "learning_rate": 0.00029854690319952636,
        "gradient_norm": 0.3540942370891571,
        "train_loss": 3.0631120204925537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16622,
        "tokens": 8714715136,
        "learning_rate": 0.0002985184526367393,
        "gradient_norm": 0.3420496881008148,
        "train_loss": 3.0634846687316895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16623,
        "tokens": 8715239424,
        "learning_rate": 0.0002984900024283164,
        "gradient_norm": 0.3521425426006317,
        "train_loss": 3.16391921043396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16624,
        "tokens": 8715763712,
        "learning_rate": 0.00029846155257457787,
        "gradient_norm": 0.3231957256793976,
        "train_loss": 3.1093382835388184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16625,
        "tokens": 8716288000,
        "learning_rate": 0.0002984331030758437,
        "gradient_norm": 0.3428609371185303,
        "train_loss": 3.076122283935547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16626,
        "tokens": 8716812288,
        "learning_rate": 0.0002984046539324345,
        "gradient_norm": 0.32928264141082764,
        "train_loss": 3.0722925662994385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16627,
        "tokens": 8717336576,
        "learning_rate": 0.0002983762051446702,
        "gradient_norm": 0.317993700504303,
        "train_loss": 3.0798048973083496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16628,
        "tokens": 8717860864,
        "learning_rate": 0.0002983477567128712,
        "gradient_norm": 0.3057912588119507,
        "train_loss": 3.0972681045532227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16629,
        "tokens": 8718385152,
        "learning_rate": 0.0002983193086373576,
        "gradient_norm": 0.36049070954322815,
        "train_loss": 3.0835134983062744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16630,
        "tokens": 8718909440,
        "learning_rate": 0.00029829086091844975,
        "gradient_norm": 0.29697665572166443,
        "train_loss": 3.121184825897217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16631,
        "tokens": 8719433728,
        "learning_rate": 0.0002982624135564677,
        "gradient_norm": 0.31425368785858154,
        "train_loss": 3.122166395187378,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16632,
        "tokens": 8719958016,
        "learning_rate": 0.0002982339665517318,
        "gradient_norm": 0.3230701684951782,
        "train_loss": 3.195302724838257,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16633,
        "tokens": 8720482304,
        "learning_rate": 0.00029820551990456206,
        "gradient_norm": 0.3154654800891876,
        "train_loss": 3.096656322479248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16634,
        "tokens": 8721006592,
        "learning_rate": 0.00029817707361527897,
        "gradient_norm": 0.3774021863937378,
        "train_loss": 3.0841054916381836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16635,
        "tokens": 8721530880,
        "learning_rate": 0.0002981486276842026,
        "gradient_norm": 0.3371909558773041,
        "train_loss": 3.0770983695983887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16636,
        "tokens": 8722055168,
        "learning_rate": 0.00029812018211165304,
        "gradient_norm": 0.2994767725467682,
        "train_loss": 3.125093460083008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16637,
        "tokens": 8722579456,
        "learning_rate": 0.00029809173689795065,
        "gradient_norm": 0.4052066206932068,
        "train_loss": 3.1024599075317383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16638,
        "tokens": 8723103744,
        "learning_rate": 0.0002980632920434155,
        "gradient_norm": 0.33848467469215393,
        "train_loss": 3.0977389812469482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16639,
        "tokens": 8723628032,
        "learning_rate": 0.00029803484754836783,
        "gradient_norm": 0.3508285582065582,
        "train_loss": 3.0673866271972656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16640,
        "tokens": 8724152320,
        "learning_rate": 0.00029800640341312774,
        "gradient_norm": 0.44404128193855286,
        "train_loss": 3.181288957595825,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16641,
        "tokens": 8724676608,
        "learning_rate": 0.0002979779596380155,
        "gradient_norm": 0.3613851070404053,
        "train_loss": 3.110490322113037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16642,
        "tokens": 8725200896,
        "learning_rate": 0.0002979495162233512,
        "gradient_norm": 0.35921311378479004,
        "train_loss": 3.1131858825683594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16643,
        "tokens": 8725725184,
        "learning_rate": 0.00029792107316945507,
        "gradient_norm": 0.36102017760276794,
        "train_loss": 3.088563919067383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16644,
        "tokens": 8726249472,
        "learning_rate": 0.00029789263047664725,
        "gradient_norm": 0.3505585193634033,
        "train_loss": 3.1127967834472656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16645,
        "tokens": 8726773760,
        "learning_rate": 0.000297864188145248,
        "gradient_norm": 0.3419675827026367,
        "train_loss": 3.064816474914551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16646,
        "tokens": 8727298048,
        "learning_rate": 0.00029783574617557726,
        "gradient_norm": 0.2977873682975769,
        "train_loss": 3.0807528495788574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16647,
        "tokens": 8727822336,
        "learning_rate": 0.00029780730456795525,
        "gradient_norm": 0.366026371717453,
        "train_loss": 3.1496033668518066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16648,
        "tokens": 8728346624,
        "learning_rate": 0.00029777886332270223,
        "gradient_norm": 0.31953057646751404,
        "train_loss": 3.1067821979522705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16649,
        "tokens": 8728870912,
        "learning_rate": 0.00029775042244013826,
        "gradient_norm": 0.3136763274669647,
        "train_loss": 3.1134085655212402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16650,
        "tokens": 8729395200,
        "learning_rate": 0.0002977219819205835,
        "gradient_norm": 0.3010035455226898,
        "train_loss": 3.0933828353881836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16651,
        "tokens": 8729919488,
        "learning_rate": 0.00029769354176435806,
        "gradient_norm": 0.2977306842803955,
        "train_loss": 3.139970064163208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16652,
        "tokens": 8730443776,
        "learning_rate": 0.00029766510197178206,
        "gradient_norm": 0.296566903591156,
        "train_loss": 3.1171722412109375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16653,
        "tokens": 8730968064,
        "learning_rate": 0.0002976366625431757,
        "gradient_norm": 0.29678553342819214,
        "train_loss": 3.049509286880493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16654,
        "tokens": 8731492352,
        "learning_rate": 0.0002976082234788589,
        "gradient_norm": 0.2825058698654175,
        "train_loss": 3.1323189735412598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16655,
        "tokens": 8732016640,
        "learning_rate": 0.0002975797847791521,
        "gradient_norm": 0.30648982524871826,
        "train_loss": 3.078287124633789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16656,
        "tokens": 8732540928,
        "learning_rate": 0.0002975513464443751,
        "gradient_norm": 0.2896045744419098,
        "train_loss": 3.079705238342285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16657,
        "tokens": 8733065216,
        "learning_rate": 0.00029752290847484823,
        "gradient_norm": 0.31689679622650146,
        "train_loss": 3.1423277854919434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16658,
        "tokens": 8733589504,
        "learning_rate": 0.00029749447087089147,
        "gradient_norm": 0.30000123381614685,
        "train_loss": 3.1269431114196777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16659,
        "tokens": 8734113792,
        "learning_rate": 0.00029746603363282496,
        "gradient_norm": 0.3268797993659973,
        "train_loss": 3.0400948524475098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16660,
        "tokens": 8734638080,
        "learning_rate": 0.00029743759676096877,
        "gradient_norm": 0.3368973731994629,
        "train_loss": 3.0271081924438477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16661,
        "tokens": 8735162368,
        "learning_rate": 0.00029740916025564317,
        "gradient_norm": 0.28332436084747314,
        "train_loss": 3.0966858863830566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16662,
        "tokens": 8735686656,
        "learning_rate": 0.0002973807241171679,
        "gradient_norm": 0.32622385025024414,
        "train_loss": 3.083458423614502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16663,
        "tokens": 8736210944,
        "learning_rate": 0.0002973522883458632,
        "gradient_norm": 0.2993812561035156,
        "train_loss": 3.0938303470611572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16664,
        "tokens": 8736735232,
        "learning_rate": 0.0002973238529420494,
        "gradient_norm": 0.33080965280532837,
        "train_loss": 3.1013824939727783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16665,
        "tokens": 8737259520,
        "learning_rate": 0.00029729541790604624,
        "gradient_norm": 0.3465907871723175,
        "train_loss": 3.118051528930664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16666,
        "tokens": 8737783808,
        "learning_rate": 0.000297266983238174,
        "gradient_norm": 0.3076063096523285,
        "train_loss": 3.047708034515381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16667,
        "tokens": 8738308096,
        "learning_rate": 0.0002972385489387526,
        "gradient_norm": 0.33446916937828064,
        "train_loss": 3.0496115684509277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16668,
        "tokens": 8738832384,
        "learning_rate": 0.0002972101150081022,
        "gradient_norm": 0.3352297842502594,
        "train_loss": 3.0660479068756104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16669,
        "tokens": 8739356672,
        "learning_rate": 0.0002971816814465428,
        "gradient_norm": 0.3277219533920288,
        "train_loss": 3.108765125274658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16670,
        "tokens": 8739880960,
        "learning_rate": 0.00029715324825439456,
        "gradient_norm": 0.30511489510536194,
        "train_loss": 3.0689382553100586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16671,
        "tokens": 8740405248,
        "learning_rate": 0.0002971248154319774,
        "gradient_norm": 0.3048160672187805,
        "train_loss": 3.0947611331939697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16672,
        "tokens": 8740929536,
        "learning_rate": 0.00029709638297961146,
        "gradient_norm": 0.297197163105011,
        "train_loss": 3.0811972618103027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16673,
        "tokens": 8741453824,
        "learning_rate": 0.00029706795089761665,
        "gradient_norm": 0.2951534688472748,
        "train_loss": 3.0990471839904785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16674,
        "tokens": 8741978112,
        "learning_rate": 0.0002970395191863131,
        "gradient_norm": 0.2995472252368927,
        "train_loss": 3.0715198516845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16675,
        "tokens": 8742502400,
        "learning_rate": 0.00029701108784602095,
        "gradient_norm": 0.380230188369751,
        "train_loss": 3.0992207527160645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16676,
        "tokens": 8743026688,
        "learning_rate": 0.00029698265687706007,
        "gradient_norm": 0.32033130526542664,
        "train_loss": 3.0673885345458984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16677,
        "tokens": 8743550976,
        "learning_rate": 0.0002969542262797506,
        "gradient_norm": 0.3399379849433899,
        "train_loss": 3.1266918182373047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16678,
        "tokens": 8744075264,
        "learning_rate": 0.0002969257960544124,
        "gradient_norm": 0.3638124167919159,
        "train_loss": 3.1047139167785645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16679,
        "tokens": 8744599552,
        "learning_rate": 0.00029689736620136574,
        "gradient_norm": 0.29447054862976074,
        "train_loss": 3.0618510246276855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16680,
        "tokens": 8745123840,
        "learning_rate": 0.00029686893672093036,
        "gradient_norm": 0.33439457416534424,
        "train_loss": 3.1176061630249023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16681,
        "tokens": 8745648128,
        "learning_rate": 0.0002968405076134265,
        "gradient_norm": 0.2955671548843384,
        "train_loss": 3.1313109397888184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16682,
        "tokens": 8746172416,
        "learning_rate": 0.00029681207887917395,
        "gradient_norm": 0.37889567017555237,
        "train_loss": 3.164263963699341,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16683,
        "tokens": 8746696704,
        "learning_rate": 0.0002967836505184928,
        "gradient_norm": 0.33307915925979614,
        "train_loss": 3.0854411125183105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16684,
        "tokens": 8747220992,
        "learning_rate": 0.00029675522253170324,
        "gradient_norm": 0.3571782112121582,
        "train_loss": 3.1053032875061035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16685,
        "tokens": 8747745280,
        "learning_rate": 0.00029672679491912497,
        "gradient_norm": 0.33163341879844666,
        "train_loss": 3.0891201496124268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16686,
        "tokens": 8748269568,
        "learning_rate": 0.00029669836768107815,
        "gradient_norm": 0.3431865870952606,
        "train_loss": 3.04852294921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16687,
        "tokens": 8748793856,
        "learning_rate": 0.00029666994081788264,
        "gradient_norm": 0.3241634666919708,
        "train_loss": 3.101365089416504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16688,
        "tokens": 8749318144,
        "learning_rate": 0.0002966415143298586,
        "gradient_norm": 0.3960777521133423,
        "train_loss": 3.0932698249816895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16689,
        "tokens": 8749842432,
        "learning_rate": 0.00029661308821732585,
        "gradient_norm": 0.3203377425670624,
        "train_loss": 3.0979974269866943,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16690,
        "tokens": 8750366720,
        "learning_rate": 0.0002965846624806044,
        "gradient_norm": 0.36329376697540283,
        "train_loss": 3.1168415546417236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16691,
        "tokens": 8750891008,
        "learning_rate": 0.0002965562371200142,
        "gradient_norm": 0.3221704959869385,
        "train_loss": 3.1832780838012695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16692,
        "tokens": 8751415296,
        "learning_rate": 0.0002965278121358753,
        "gradient_norm": 0.45772305130958557,
        "train_loss": 3.1089975833892822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16693,
        "tokens": 8751939584,
        "learning_rate": 0.00029649938752850753,
        "gradient_norm": 0.3477817475795746,
        "train_loss": 3.122018575668335,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16694,
        "tokens": 8752463872,
        "learning_rate": 0.00029647096329823096,
        "gradient_norm": 0.410253643989563,
        "train_loss": 3.163914203643799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16695,
        "tokens": 8752988160,
        "learning_rate": 0.0002964425394453655,
        "gradient_norm": 0.34727853536605835,
        "train_loss": 3.0434670448303223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16696,
        "tokens": 8753512448,
        "learning_rate": 0.0002964141159702311,
        "gradient_norm": 0.3767082691192627,
        "train_loss": 3.098128318786621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16697,
        "tokens": 8754036736,
        "learning_rate": 0.00029638569287314767,
        "gradient_norm": 0.329430490732193,
        "train_loss": 3.1182661056518555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16698,
        "tokens": 8754561024,
        "learning_rate": 0.0002963572701544351,
        "gradient_norm": 0.3581995666027069,
        "train_loss": 3.136887550354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16699,
        "tokens": 8755085312,
        "learning_rate": 0.0002963288478144135,
        "gradient_norm": 0.35504859685897827,
        "train_loss": 3.117647647857666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16700,
        "tokens": 8755609600,
        "learning_rate": 0.00029630042585340266,
        "gradient_norm": 0.3179376423358917,
        "train_loss": 3.0129330158233643,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16701,
        "tokens": 8756133888,
        "learning_rate": 0.0002962720042717225,
        "gradient_norm": 0.35407206416130066,
        "train_loss": 3.110183000564575,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16702,
        "tokens": 8756658176,
        "learning_rate": 0.00029624358306969297,
        "gradient_norm": 0.331167995929718,
        "train_loss": 3.1308116912841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16703,
        "tokens": 8757182464,
        "learning_rate": 0.000296215162247634,
        "gradient_norm": 0.3161289393901825,
        "train_loss": 3.0619657039642334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16704,
        "tokens": 8757706752,
        "learning_rate": 0.0002961867418058655,
        "gradient_norm": 0.3297470808029175,
        "train_loss": 3.125305652618408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16705,
        "tokens": 8758231040,
        "learning_rate": 0.00029615832174470735,
        "gradient_norm": 0.31687241792678833,
        "train_loss": 3.0944619178771973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16706,
        "tokens": 8758755328,
        "learning_rate": 0.00029612990206447955,
        "gradient_norm": 0.33856135606765747,
        "train_loss": 3.0956931114196777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16707,
        "tokens": 8759279616,
        "learning_rate": 0.00029610148276550184,
        "gradient_norm": 0.2887817621231079,
        "train_loss": 3.049504280090332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16708,
        "tokens": 8759803904,
        "learning_rate": 0.00029607306384809423,
        "gradient_norm": 0.33083751797676086,
        "train_loss": 3.1053900718688965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16709,
        "tokens": 8760328192,
        "learning_rate": 0.00029604464531257657,
        "gradient_norm": 0.3080838620662689,
        "train_loss": 3.1407413482666016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16710,
        "tokens": 8760852480,
        "learning_rate": 0.0002960162271592688,
        "gradient_norm": 0.3261561095714569,
        "train_loss": 3.0734946727752686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16711,
        "tokens": 8761376768,
        "learning_rate": 0.00029598780938849074,
        "gradient_norm": 0.31649038195610046,
        "train_loss": 3.0500571727752686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16712,
        "tokens": 8761901056,
        "learning_rate": 0.00029595939200056226,
        "gradient_norm": 0.320398211479187,
        "train_loss": 3.0852887630462646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16713,
        "tokens": 8762425344,
        "learning_rate": 0.0002959309749958032,
        "gradient_norm": 0.30070194602012634,
        "train_loss": 3.1302199363708496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16714,
        "tokens": 8762949632,
        "learning_rate": 0.0002959025583745335,
        "gradient_norm": 0.28960010409355164,
        "train_loss": 3.0933942794799805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16715,
        "tokens": 8763473920,
        "learning_rate": 0.00029587414213707306,
        "gradient_norm": 0.3162967562675476,
        "train_loss": 3.1057982444763184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16716,
        "tokens": 8763998208,
        "learning_rate": 0.0002958457262837417,
        "gradient_norm": 0.3023863136768341,
        "train_loss": 3.0875775814056396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16717,
        "tokens": 8764522496,
        "learning_rate": 0.0002958173108148593,
        "gradient_norm": 0.2836441993713379,
        "train_loss": 3.1423637866973877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16718,
        "tokens": 8765046784,
        "learning_rate": 0.00029578889573074555,
        "gradient_norm": 0.3071762025356293,
        "train_loss": 3.086427688598633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16719,
        "tokens": 8765571072,
        "learning_rate": 0.00029576048103172053,
        "gradient_norm": 0.301368772983551,
        "train_loss": 3.108525276184082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16720,
        "tokens": 8766095360,
        "learning_rate": 0.0002957320667181039,
        "gradient_norm": 0.284180223941803,
        "train_loss": 3.11523175239563,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16721,
        "tokens": 8766619648,
        "learning_rate": 0.0002957036527902157,
        "gradient_norm": 0.33831462264060974,
        "train_loss": 3.099734306335449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16722,
        "tokens": 8767143936,
        "learning_rate": 0.00029567523924837547,
        "gradient_norm": 0.3180873990058899,
        "train_loss": 3.0955467224121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16723,
        "tokens": 8767668224,
        "learning_rate": 0.0002956468260929033,
        "gradient_norm": 0.31224554777145386,
        "train_loss": 3.0998222827911377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16724,
        "tokens": 8768192512,
        "learning_rate": 0.00029561841332411895,
        "gradient_norm": 0.3330850601196289,
        "train_loss": 3.081648826599121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16725,
        "tokens": 8768716800,
        "learning_rate": 0.0002955900009423421,
        "gradient_norm": 0.32092100381851196,
        "train_loss": 3.094371795654297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16726,
        "tokens": 8769241088,
        "learning_rate": 0.00029556158894789285,
        "gradient_norm": 0.33533722162246704,
        "train_loss": 3.099381923675537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16727,
        "tokens": 8769765376,
        "learning_rate": 0.00029553317734109066,
        "gradient_norm": 0.32290202379226685,
        "train_loss": 3.055300235748291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16728,
        "tokens": 8770289664,
        "learning_rate": 0.00029550476612225573,
        "gradient_norm": 0.3426513373851776,
        "train_loss": 3.101688861846924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16729,
        "tokens": 8770813952,
        "learning_rate": 0.0002954763552917075,
        "gradient_norm": 0.3190706670284271,
        "train_loss": 3.0696449279785156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16730,
        "tokens": 8771338240,
        "learning_rate": 0.00029544794484976603,
        "gradient_norm": 0.29551032185554504,
        "train_loss": 3.070833206176758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16731,
        "tokens": 8771862528,
        "learning_rate": 0.00029541953479675094,
        "gradient_norm": 0.32580623030662537,
        "train_loss": 3.123495578765869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16732,
        "tokens": 8772386816,
        "learning_rate": 0.00029539112513298215,
        "gradient_norm": 0.32523879408836365,
        "train_loss": 3.0033204555511475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16733,
        "tokens": 8772911104,
        "learning_rate": 0.00029536271585877923,
        "gradient_norm": 0.31794533133506775,
        "train_loss": 3.0555472373962402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16734,
        "tokens": 8773435392,
        "learning_rate": 0.0002953343069744622,
        "gradient_norm": 0.30994749069213867,
        "train_loss": 3.084402322769165,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16735,
        "tokens": 8773959680,
        "learning_rate": 0.0002953058984803509,
        "gradient_norm": 0.34424933791160583,
        "train_loss": 3.076639175415039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16736,
        "tokens": 8774483968,
        "learning_rate": 0.0002952774903767648,
        "gradient_norm": 0.33477386832237244,
        "train_loss": 3.141961097717285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16737,
        "tokens": 8775008256,
        "learning_rate": 0.0002952490826640239,
        "gradient_norm": 0.317025363445282,
        "train_loss": 3.0828418731689453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16738,
        "tokens": 8775532544,
        "learning_rate": 0.0002952206753424478,
        "gradient_norm": 0.32203978300094604,
        "train_loss": 3.099324941635132,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16739,
        "tokens": 8776056832,
        "learning_rate": 0.0002951922684123565,
        "gradient_norm": 0.38330188393592834,
        "train_loss": 3.1692893505096436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16740,
        "tokens": 8776581120,
        "learning_rate": 0.0002951638618740695,
        "gradient_norm": 0.35801151394844055,
        "train_loss": 3.0910181999206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16741,
        "tokens": 8777105408,
        "learning_rate": 0.00029513545572790677,
        "gradient_norm": 0.3376174569129944,
        "train_loss": 3.0797276496887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16742,
        "tokens": 8777629696,
        "learning_rate": 0.00029510704997418784,
        "gradient_norm": 0.2939926087856293,
        "train_loss": 3.055881977081299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16743,
        "tokens": 8778153984,
        "learning_rate": 0.0002950786446132325,
        "gradient_norm": 0.36161935329437256,
        "train_loss": 3.1080634593963623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16744,
        "tokens": 8778678272,
        "learning_rate": 0.0002950502396453607,
        "gradient_norm": 0.3383941352367401,
        "train_loss": 3.1306748390197754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16745,
        "tokens": 8779202560,
        "learning_rate": 0.0002950218350708919,
        "gradient_norm": 0.33957403898239136,
        "train_loss": 3.122676372528076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16746,
        "tokens": 8779726848,
        "learning_rate": 0.00029499343089014606,
        "gradient_norm": 0.35853150486946106,
        "train_loss": 3.0819666385650635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16747,
        "tokens": 8780251136,
        "learning_rate": 0.00029496502710344265,
        "gradient_norm": 0.32544460892677307,
        "train_loss": 3.091249465942383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16748,
        "tokens": 8780775424,
        "learning_rate": 0.00029493662371110174,
        "gradient_norm": 0.32716691493988037,
        "train_loss": 3.0613296031951904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16749,
        "tokens": 8781299712,
        "learning_rate": 0.0002949082207134426,
        "gradient_norm": 0.3033716380596161,
        "train_loss": 3.0927765369415283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16750,
        "tokens": 8781824000,
        "learning_rate": 0.00029487981811078534,
        "gradient_norm": 0.31062638759613037,
        "train_loss": 3.098196506500244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16751,
        "tokens": 8782348288,
        "learning_rate": 0.00029485141590344943,
        "gradient_norm": 0.323457270860672,
        "train_loss": 3.0885307788848877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16752,
        "tokens": 8782872576,
        "learning_rate": 0.0002948230140917547,
        "gradient_norm": 0.3171015977859497,
        "train_loss": 3.0553975105285645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16753,
        "tokens": 8783396864,
        "learning_rate": 0.0002947946126760207,
        "gradient_norm": 0.3256360590457916,
        "train_loss": 3.0813560485839844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16754,
        "tokens": 8783921152,
        "learning_rate": 0.00029476621165656734,
        "gradient_norm": 0.32659000158309937,
        "train_loss": 3.0582809448242188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16755,
        "tokens": 8784445440,
        "learning_rate": 0.00029473781103371414,
        "gradient_norm": 0.31534281373023987,
        "train_loss": 3.100212574005127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16756,
        "tokens": 8784969728,
        "learning_rate": 0.0002947094108077808,
        "gradient_norm": 0.3284819722175598,
        "train_loss": 3.0946550369262695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16757,
        "tokens": 8785494016,
        "learning_rate": 0.0002946810109790871,
        "gradient_norm": 0.339472234249115,
        "train_loss": 3.080312728881836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16758,
        "tokens": 8786018304,
        "learning_rate": 0.00029465261154795264,
        "gradient_norm": 0.3271673619747162,
        "train_loss": 3.0772366523742676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16759,
        "tokens": 8786542592,
        "learning_rate": 0.0002946242125146971,
        "gradient_norm": 0.31835371255874634,
        "train_loss": 3.1074953079223633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16760,
        "tokens": 8787066880,
        "learning_rate": 0.00029459581387964004,
        "gradient_norm": 0.33130183815956116,
        "train_loss": 3.1341261863708496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16761,
        "tokens": 8787591168,
        "learning_rate": 0.00029456741564310134,
        "gradient_norm": 0.3016144037246704,
        "train_loss": 3.0930867195129395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16762,
        "tokens": 8788115456,
        "learning_rate": 0.0002945390178054005,
        "gradient_norm": 0.3202361464500427,
        "train_loss": 3.0654280185699463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16763,
        "tokens": 8788639744,
        "learning_rate": 0.00029451062036685717,
        "gradient_norm": 0.2847336530685425,
        "train_loss": 3.06906795501709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16764,
        "tokens": 8789164032,
        "learning_rate": 0.00029448222332779115,
        "gradient_norm": 0.33702602982521057,
        "train_loss": 3.0806360244750977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16765,
        "tokens": 8789688320,
        "learning_rate": 0.00029445382668852186,
        "gradient_norm": 0.2838144898414612,
        "train_loss": 3.08872127532959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16766,
        "tokens": 8790212608,
        "learning_rate": 0.0002944254304493692,
        "gradient_norm": 0.3130476474761963,
        "train_loss": 3.0650534629821777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16767,
        "tokens": 8790736896,
        "learning_rate": 0.0002943970346106525,
        "gradient_norm": 0.29995962977409363,
        "train_loss": 3.10709810256958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16768,
        "tokens": 8791261184,
        "learning_rate": 0.00029436863917269176,
        "gradient_norm": 0.2949018180370331,
        "train_loss": 3.051640033721924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16769,
        "tokens": 8791785472,
        "learning_rate": 0.0002943402441358062,
        "gradient_norm": 0.29249677062034607,
        "train_loss": 3.1270382404327393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16770,
        "tokens": 8792309760,
        "learning_rate": 0.0002943118495003158,
        "gradient_norm": 0.3082297444343567,
        "train_loss": 3.069401741027832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16771,
        "tokens": 8792834048,
        "learning_rate": 0.00029428345526653996,
        "gradient_norm": 0.33026617765426636,
        "train_loss": 3.0958609580993652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16772,
        "tokens": 8793358336,
        "learning_rate": 0.0002942550614347984,
        "gradient_norm": 0.3209971785545349,
        "train_loss": 3.0424227714538574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16773,
        "tokens": 8793882624,
        "learning_rate": 0.00029422666800541056,
        "gradient_norm": 0.3029884397983551,
        "train_loss": 3.0688672065734863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16774,
        "tokens": 8794406912,
        "learning_rate": 0.0002941982749786962,
        "gradient_norm": 0.3033788502216339,
        "train_loss": 3.088418960571289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16775,
        "tokens": 8794931200,
        "learning_rate": 0.00029416988235497494,
        "gradient_norm": 0.3076305687427521,
        "train_loss": 3.038262128829956,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16776,
        "tokens": 8795455488,
        "learning_rate": 0.0002941414901345662,
        "gradient_norm": 0.2931973934173584,
        "train_loss": 3.1149089336395264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16777,
        "tokens": 8795979776,
        "learning_rate": 0.0002941130983177899,
        "gradient_norm": 0.31222230195999146,
        "train_loss": 3.035285711288452,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16778,
        "tokens": 8796504064,
        "learning_rate": 0.00029408470690496524,
        "gradient_norm": 0.2994222044944763,
        "train_loss": 3.108628749847412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16779,
        "tokens": 8797028352,
        "learning_rate": 0.0002940563158964121,
        "gradient_norm": 0.3140084445476532,
        "train_loss": 3.1288559436798096,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16780,
        "tokens": 8797552640,
        "learning_rate": 0.0002940279252924498,
        "gradient_norm": 0.36366650462150574,
        "train_loss": 3.1269302368164062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16781,
        "tokens": 8798076928,
        "learning_rate": 0.00029399953509339817,
        "gradient_norm": 0.31533971428871155,
        "train_loss": 3.107630491256714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16782,
        "tokens": 8798601216,
        "learning_rate": 0.0002939711452995765,
        "gradient_norm": 0.345851331949234,
        "train_loss": 3.1585545539855957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16783,
        "tokens": 8799125504,
        "learning_rate": 0.0002939427559113045,
        "gradient_norm": 0.3946404755115509,
        "train_loss": 3.103102445602417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16784,
        "tokens": 8799649792,
        "learning_rate": 0.0002939143669289019,
        "gradient_norm": 0.3032236397266388,
        "train_loss": 3.1168065071105957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16785,
        "tokens": 8800174080,
        "learning_rate": 0.00029388597835268795,
        "gradient_norm": 0.42068156599998474,
        "train_loss": 2.986133098602295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16786,
        "tokens": 8800698368,
        "learning_rate": 0.0002938575901829824,
        "gradient_norm": 0.3150220513343811,
        "train_loss": 3.1221704483032227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16787,
        "tokens": 8801222656,
        "learning_rate": 0.00029382920242010467,
        "gradient_norm": 0.38152578473091125,
        "train_loss": 3.0845375061035156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16788,
        "tokens": 8801746944,
        "learning_rate": 0.00029380081506437443,
        "gradient_norm": 0.3162817656993866,
        "train_loss": 3.0974955558776855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16789,
        "tokens": 8802271232,
        "learning_rate": 0.000293772428116111,
        "gradient_norm": 0.34342247247695923,
        "train_loss": 3.1087639331817627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16790,
        "tokens": 8802795520,
        "learning_rate": 0.00029374404157563424,
        "gradient_norm": 0.3319615125656128,
        "train_loss": 3.1066150665283203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16791,
        "tokens": 8803319808,
        "learning_rate": 0.0002937156554432633,
        "gradient_norm": 0.3472961485385895,
        "train_loss": 3.089480400085449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16792,
        "tokens": 8803844096,
        "learning_rate": 0.00029368726971931806,
        "gradient_norm": 0.33415359258651733,
        "train_loss": 3.0881710052490234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16793,
        "tokens": 8804368384,
        "learning_rate": 0.00029365888440411773,
        "gradient_norm": 0.33708468079566956,
        "train_loss": 3.095367431640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16794,
        "tokens": 8804892672,
        "learning_rate": 0.00029363049949798195,
        "gradient_norm": 0.3393864333629608,
        "train_loss": 3.082026481628418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16795,
        "tokens": 8805416960,
        "learning_rate": 0.00029360211500123034,
        "gradient_norm": 0.31456178426742554,
        "train_loss": 3.1053171157836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16796,
        "tokens": 8805941248,
        "learning_rate": 0.0002935737309141822,
        "gradient_norm": 0.31682053208351135,
        "train_loss": 3.0323357582092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16797,
        "tokens": 8806465536,
        "learning_rate": 0.00029354534723715725,
        "gradient_norm": 0.3199838399887085,
        "train_loss": 3.1342344284057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16798,
        "tokens": 8806989824,
        "learning_rate": 0.0002935169639704747,
        "gradient_norm": 0.30841609835624695,
        "train_loss": 3.1170802116394043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16799,
        "tokens": 8807514112,
        "learning_rate": 0.00029348858111445436,
        "gradient_norm": 0.352924644947052,
        "train_loss": 3.0686533451080322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16800,
        "tokens": 8808038400,
        "learning_rate": 0.0002934601986694154,
        "gradient_norm": 0.34526386857032776,
        "train_loss": 3.121051788330078,
        "val_loss": 3.0558881759643555,
        "hellaswag_acc": 0.2837084233760834,
        "hellaswag_acc_norm": 0.29187414050102234
    },
    {
        "step": 16801,
        "tokens": 8808562688,
        "learning_rate": 0.0002934318166356776,
        "gradient_norm": 0.30625760555267334,
        "train_loss": 3.075167179107666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16802,
        "tokens": 8809086976,
        "learning_rate": 0.00029340343501356014,
        "gradient_norm": 0.3389253318309784,
        "train_loss": 3.1669623851776123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16803,
        "tokens": 8809611264,
        "learning_rate": 0.00029337505380338266,
        "gradient_norm": 0.3109404444694519,
        "train_loss": 3.059053421020508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16804,
        "tokens": 8810135552,
        "learning_rate": 0.0002933466730054647,
        "gradient_norm": 0.30939871072769165,
        "train_loss": 3.116133689880371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16805,
        "tokens": 8810659840,
        "learning_rate": 0.0002933182926201256,
        "gradient_norm": 0.3374287784099579,
        "train_loss": 3.1175637245178223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16806,
        "tokens": 8811184128,
        "learning_rate": 0.0002932899126476848,
        "gradient_norm": 0.30166828632354736,
        "train_loss": 3.031198501586914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16807,
        "tokens": 8811708416,
        "learning_rate": 0.0002932615330884618,
        "gradient_norm": 0.3244827389717102,
        "train_loss": 3.099346160888672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16808,
        "tokens": 8812232704,
        "learning_rate": 0.00029323315394277606,
        "gradient_norm": 0.3410704731941223,
        "train_loss": 3.1618411540985107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16809,
        "tokens": 8812756992,
        "learning_rate": 0.000293204775210947,
        "gradient_norm": 0.3014117479324341,
        "train_loss": 3.0868918895721436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16810,
        "tokens": 8813281280,
        "learning_rate": 0.0002931763968932941,
        "gradient_norm": 0.3479260206222534,
        "train_loss": 3.1296470165252686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16811,
        "tokens": 8813805568,
        "learning_rate": 0.00029314801899013663,
        "gradient_norm": 0.31365564465522766,
        "train_loss": 3.0674304962158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16812,
        "tokens": 8814329856,
        "learning_rate": 0.0002931196415017943,
        "gradient_norm": 0.32097315788269043,
        "train_loss": 3.0457301139831543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16813,
        "tokens": 8814854144,
        "learning_rate": 0.0002930912644285863,
        "gradient_norm": 0.31867679953575134,
        "train_loss": 3.049534320831299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16814,
        "tokens": 8815378432,
        "learning_rate": 0.0002930628877708321,
        "gradient_norm": 0.3088100552558899,
        "train_loss": 3.066054344177246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16815,
        "tokens": 8815902720,
        "learning_rate": 0.0002930345115288512,
        "gradient_norm": 0.30584916472435,
        "train_loss": 3.078223943710327,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16816,
        "tokens": 8816427008,
        "learning_rate": 0.0002930061357029628,
        "gradient_norm": 0.336023211479187,
        "train_loss": 3.0769975185394287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16817,
        "tokens": 8816951296,
        "learning_rate": 0.0002929777602934867,
        "gradient_norm": 0.310305655002594,
        "train_loss": 3.1278076171875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16818,
        "tokens": 8817475584,
        "learning_rate": 0.00029294938530074186,
        "gradient_norm": 0.326198011636734,
        "train_loss": 3.0850253105163574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16819,
        "tokens": 8817999872,
        "learning_rate": 0.00029292101072504804,
        "gradient_norm": 0.30577215552330017,
        "train_loss": 3.0752663612365723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16820,
        "tokens": 8818524160,
        "learning_rate": 0.0002928926365667243,
        "gradient_norm": 0.32028186321258545,
        "train_loss": 3.1062159538269043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16821,
        "tokens": 8819048448,
        "learning_rate": 0.0002928642628260903,
        "gradient_norm": 0.3375677168369293,
        "train_loss": 3.00101900100708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16822,
        "tokens": 8819572736,
        "learning_rate": 0.0002928358895034652,
        "gradient_norm": 0.30920809507369995,
        "train_loss": 3.0331077575683594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16823,
        "tokens": 8820097024,
        "learning_rate": 0.00029280751659916857,
        "gradient_norm": 0.32725024223327637,
        "train_loss": 3.0986814498901367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16824,
        "tokens": 8820621312,
        "learning_rate": 0.00029277914411351974,
        "gradient_norm": 0.29388925433158875,
        "train_loss": 3.0940518379211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16825,
        "tokens": 8821145600,
        "learning_rate": 0.00029275077204683796,
        "gradient_norm": 0.3211309313774109,
        "train_loss": 3.049262762069702,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16826,
        "tokens": 8821669888,
        "learning_rate": 0.00029272240039944275,
        "gradient_norm": 0.3082345426082611,
        "train_loss": 3.0407471656799316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16827,
        "tokens": 8822194176,
        "learning_rate": 0.0002926940291716533,
        "gradient_norm": 0.34490638971328735,
        "train_loss": 3.165292501449585,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16828,
        "tokens": 8822718464,
        "learning_rate": 0.00029266565836378916,
        "gradient_norm": 0.31818899512290955,
        "train_loss": 3.093842029571533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16829,
        "tokens": 8823242752,
        "learning_rate": 0.0002926372879761695,
        "gradient_norm": 0.3533223271369934,
        "train_loss": 3.078646183013916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16830,
        "tokens": 8823767040,
        "learning_rate": 0.0002926089180091138,
        "gradient_norm": 0.36177822947502136,
        "train_loss": 3.0957460403442383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16831,
        "tokens": 8824291328,
        "learning_rate": 0.00029258054846294126,
        "gradient_norm": 0.34782758355140686,
        "train_loss": 3.1067018508911133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16832,
        "tokens": 8824815616,
        "learning_rate": 0.0002925521793379714,
        "gradient_norm": 0.30804383754730225,
        "train_loss": 3.1550846099853516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16833,
        "tokens": 8825339904,
        "learning_rate": 0.0002925238106345233,
        "gradient_norm": 0.34956225752830505,
        "train_loss": 3.097749948501587,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16834,
        "tokens": 8825864192,
        "learning_rate": 0.0002924954423529164,
        "gradient_norm": 0.3203674256801605,
        "train_loss": 3.117931365966797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16835,
        "tokens": 8826388480,
        "learning_rate": 0.00029246707449347023,
        "gradient_norm": 0.34383881092071533,
        "train_loss": 3.0716052055358887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16836,
        "tokens": 8826912768,
        "learning_rate": 0.00029243870705650374,
        "gradient_norm": 0.29994747042655945,
        "train_loss": 3.1274468898773193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16837,
        "tokens": 8827437056,
        "learning_rate": 0.00029241034004233663,
        "gradient_norm": 0.3402952551841736,
        "train_loss": 3.0984725952148438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16838,
        "tokens": 8827961344,
        "learning_rate": 0.0002923819734512878,
        "gradient_norm": 0.30433133244514465,
        "train_loss": 3.091096878051758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16839,
        "tokens": 8828485632,
        "learning_rate": 0.000292353607283677,
        "gradient_norm": 0.3349410891532898,
        "train_loss": 3.090275764465332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16840,
        "tokens": 8829009920,
        "learning_rate": 0.000292325241539823,
        "gradient_norm": 0.3526194393634796,
        "train_loss": 3.0440673828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16841,
        "tokens": 8829534208,
        "learning_rate": 0.0002922968762200455,
        "gradient_norm": 0.3169030249118805,
        "train_loss": 3.0734670162200928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16842,
        "tokens": 8830058496,
        "learning_rate": 0.00029226851132466364,
        "gradient_norm": 0.4006844758987427,
        "train_loss": 3.1047396659851074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16843,
        "tokens": 8830582784,
        "learning_rate": 0.00029224014685399666,
        "gradient_norm": 0.3304407298564911,
        "train_loss": 3.0936458110809326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16844,
        "tokens": 8831107072,
        "learning_rate": 0.00029221178280836404,
        "gradient_norm": 0.36738893389701843,
        "train_loss": 3.1238718032836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16845,
        "tokens": 8831631360,
        "learning_rate": 0.00029218341918808475,
        "gradient_norm": 0.3606436252593994,
        "train_loss": 3.079911470413208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16846,
        "tokens": 8832155648,
        "learning_rate": 0.00029215505599347835,
        "gradient_norm": 0.4337950646877289,
        "train_loss": 3.241921901702881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16847,
        "tokens": 8832679936,
        "learning_rate": 0.0002921266932248639,
        "gradient_norm": 0.36828869581222534,
        "train_loss": 3.098264694213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16848,
        "tokens": 8833204224,
        "learning_rate": 0.00029209833088256074,
        "gradient_norm": 0.39066824316978455,
        "train_loss": 3.0719029903411865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16849,
        "tokens": 8833728512,
        "learning_rate": 0.00029206996896688806,
        "gradient_norm": 0.35007521510124207,
        "train_loss": 3.1154932975769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16850,
        "tokens": 8834252800,
        "learning_rate": 0.00029204160747816526,
        "gradient_norm": 0.38683637976646423,
        "train_loss": 3.060178756713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16851,
        "tokens": 8834777088,
        "learning_rate": 0.0002920132464167114,
        "gradient_norm": 0.35116663575172424,
        "train_loss": 3.133493423461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16852,
        "tokens": 8835301376,
        "learning_rate": 0.00029198488578284585,
        "gradient_norm": 0.385550320148468,
        "train_loss": 3.0507583618164062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16853,
        "tokens": 8835825664,
        "learning_rate": 0.0002919565255768878,
        "gradient_norm": 0.4152224361896515,
        "train_loss": 3.1133432388305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16854,
        "tokens": 8836349952,
        "learning_rate": 0.00029192816579915647,
        "gradient_norm": 0.31889069080352783,
        "train_loss": 3.0778462886810303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16855,
        "tokens": 8836874240,
        "learning_rate": 0.0002918998064499711,
        "gradient_norm": 0.3711252808570862,
        "train_loss": 3.0958034992218018,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16856,
        "tokens": 8837398528,
        "learning_rate": 0.0002918714475296509,
        "gradient_norm": 0.3576768636703491,
        "train_loss": 3.08660888671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16857,
        "tokens": 8837922816,
        "learning_rate": 0.000291843089038515,
        "gradient_norm": 0.3468247652053833,
        "train_loss": 3.07413911819458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16858,
        "tokens": 8838447104,
        "learning_rate": 0.0002918147309768828,
        "gradient_norm": 0.32261234521865845,
        "train_loss": 3.089966297149658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16859,
        "tokens": 8838971392,
        "learning_rate": 0.0002917863733450734,
        "gradient_norm": 0.3428122401237488,
        "train_loss": 3.13668155670166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16860,
        "tokens": 8839495680,
        "learning_rate": 0.000291758016143406,
        "gradient_norm": 0.29769250750541687,
        "train_loss": 3.0550456047058105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16861,
        "tokens": 8840019968,
        "learning_rate": 0.00029172965937219976,
        "gradient_norm": 0.30985429883003235,
        "train_loss": 3.11460280418396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16862,
        "tokens": 8840544256,
        "learning_rate": 0.00029170130303177394,
        "gradient_norm": 0.28286004066467285,
        "train_loss": 3.054603099822998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16863,
        "tokens": 8841068544,
        "learning_rate": 0.0002916729471224476,
        "gradient_norm": 0.2908211648464203,
        "train_loss": 3.103597640991211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16864,
        "tokens": 8841592832,
        "learning_rate": 0.0002916445916445402,
        "gradient_norm": 0.31632089614868164,
        "train_loss": 3.2006425857543945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16865,
        "tokens": 8842117120,
        "learning_rate": 0.00029161623659837053,
        "gradient_norm": 0.3243429660797119,
        "train_loss": 3.1573872566223145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16866,
        "tokens": 8842641408,
        "learning_rate": 0.00029158788198425814,
        "gradient_norm": 0.2989332973957062,
        "train_loss": 3.0570404529571533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16867,
        "tokens": 8843165696,
        "learning_rate": 0.0002915595278025219,
        "gradient_norm": 0.30662861466407776,
        "train_loss": 3.0749073028564453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16868,
        "tokens": 8843689984,
        "learning_rate": 0.0002915311740534812,
        "gradient_norm": 0.2863861620426178,
        "train_loss": 3.0398316383361816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16869,
        "tokens": 8844214272,
        "learning_rate": 0.0002915028207374549,
        "gradient_norm": 0.301151841878891,
        "train_loss": 3.053797721862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16870,
        "tokens": 8844738560,
        "learning_rate": 0.00029147446785476254,
        "gradient_norm": 0.32695141434669495,
        "train_loss": 3.081838607788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16871,
        "tokens": 8845262848,
        "learning_rate": 0.00029144611540572296,
        "gradient_norm": 0.35325726866722107,
        "train_loss": 3.123894691467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16872,
        "tokens": 8845787136,
        "learning_rate": 0.00029141776339065536,
        "gradient_norm": 0.3301966190338135,
        "train_loss": 3.058979034423828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16873,
        "tokens": 8846311424,
        "learning_rate": 0.00029138941180987903,
        "gradient_norm": 0.2951601445674896,
        "train_loss": 3.086768627166748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16874,
        "tokens": 8846835712,
        "learning_rate": 0.00029136106066371295,
        "gradient_norm": 0.3139895498752594,
        "train_loss": 3.0995705127716064,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16875,
        "tokens": 8847360000,
        "learning_rate": 0.0002913327099524764,
        "gradient_norm": 0.3139093220233917,
        "train_loss": 3.083284854888916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16876,
        "tokens": 8847884288,
        "learning_rate": 0.0002913043596764883,
        "gradient_norm": 0.32676833868026733,
        "train_loss": 3.0884695053100586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16877,
        "tokens": 8848408576,
        "learning_rate": 0.0002912760098360679,
        "gradient_norm": 0.341113418340683,
        "train_loss": 3.1135072708129883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16878,
        "tokens": 8848932864,
        "learning_rate": 0.00029124766043153423,
        "gradient_norm": 0.3104698061943054,
        "train_loss": 3.092008113861084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16879,
        "tokens": 8849457152,
        "learning_rate": 0.0002912193114632066,
        "gradient_norm": 0.3144189715385437,
        "train_loss": 3.0457370281219482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16880,
        "tokens": 8849981440,
        "learning_rate": 0.00029119096293140376,
        "gradient_norm": 0.29774466156959534,
        "train_loss": 3.114335060119629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16881,
        "tokens": 8850505728,
        "learning_rate": 0.00029116261483644513,
        "gradient_norm": 0.33551087975502014,
        "train_loss": 3.09087872505188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16882,
        "tokens": 8851030016,
        "learning_rate": 0.0002911342671786496,
        "gradient_norm": 0.3236178457736969,
        "train_loss": 3.117926836013794,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16883,
        "tokens": 8851554304,
        "learning_rate": 0.00029110591995833634,
        "gradient_norm": 0.30733951926231384,
        "train_loss": 3.0979788303375244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16884,
        "tokens": 8852078592,
        "learning_rate": 0.00029107757317582456,
        "gradient_norm": 0.2947241961956024,
        "train_loss": 3.057490348815918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16885,
        "tokens": 8852602880,
        "learning_rate": 0.00029104922683143307,
        "gradient_norm": 0.28163886070251465,
        "train_loss": 3.051309585571289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16886,
        "tokens": 8853127168,
        "learning_rate": 0.00029102088092548123,
        "gradient_norm": 0.28835663199424744,
        "train_loss": 3.053872585296631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16887,
        "tokens": 8853651456,
        "learning_rate": 0.0002909925354582878,
        "gradient_norm": 0.3005547821521759,
        "train_loss": 3.1303205490112305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16888,
        "tokens": 8854175744,
        "learning_rate": 0.0002909641904301722,
        "gradient_norm": 0.287494033575058,
        "train_loss": 3.124481201171875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16889,
        "tokens": 8854700032,
        "learning_rate": 0.00029093584584145306,
        "gradient_norm": 0.30802440643310547,
        "train_loss": 3.1091041564941406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16890,
        "tokens": 8855224320,
        "learning_rate": 0.00029090750169244987,
        "gradient_norm": 0.2966769337654114,
        "train_loss": 3.0893056392669678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16891,
        "tokens": 8855748608,
        "learning_rate": 0.0002908791579834814,
        "gradient_norm": 0.3059656620025635,
        "train_loss": 3.1105828285217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16892,
        "tokens": 8856272896,
        "learning_rate": 0.0002908508147148667,
        "gradient_norm": 0.334622323513031,
        "train_loss": 3.049264430999756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16893,
        "tokens": 8856797184,
        "learning_rate": 0.00029082247188692503,
        "gradient_norm": 0.31435948610305786,
        "train_loss": 3.093982458114624,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16894,
        "tokens": 8857321472,
        "learning_rate": 0.0002907941294999751,
        "gradient_norm": 0.2883697748184204,
        "train_loss": 3.061051368713379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16895,
        "tokens": 8857845760,
        "learning_rate": 0.0002907657875543363,
        "gradient_norm": 0.3005853593349457,
        "train_loss": 3.118887424468994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16896,
        "tokens": 8858370048,
        "learning_rate": 0.0002907374460503273,
        "gradient_norm": 0.29316380620002747,
        "train_loss": 3.0995216369628906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16897,
        "tokens": 8858894336,
        "learning_rate": 0.0002907091049882675,
        "gradient_norm": 0.3161131739616394,
        "train_loss": 3.0419058799743652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16898,
        "tokens": 8859418624,
        "learning_rate": 0.0002906807643684755,
        "gradient_norm": 0.2976153492927551,
        "train_loss": 2.9774680137634277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16899,
        "tokens": 8859942912,
        "learning_rate": 0.0002906524241912706,
        "gradient_norm": 0.3014906048774719,
        "train_loss": 3.102248191833496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16900,
        "tokens": 8860467200,
        "learning_rate": 0.00029062408445697165,
        "gradient_norm": 0.32978492975234985,
        "train_loss": 3.070106029510498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16901,
        "tokens": 8860991488,
        "learning_rate": 0.0002905957451658979,
        "gradient_norm": 0.3140166103839874,
        "train_loss": 3.1262807846069336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16902,
        "tokens": 8861515776,
        "learning_rate": 0.00029056740631836793,
        "gradient_norm": 0.3474453091621399,
        "train_loss": 3.149165391921997,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16903,
        "tokens": 8862040064,
        "learning_rate": 0.000290539067914701,
        "gradient_norm": 0.3202333152294159,
        "train_loss": 3.1077613830566406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16904,
        "tokens": 8862564352,
        "learning_rate": 0.0002905107299552161,
        "gradient_norm": 0.29757559299468994,
        "train_loss": 3.0765843391418457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16905,
        "tokens": 8863088640,
        "learning_rate": 0.00029048239244023217,
        "gradient_norm": 0.3238966464996338,
        "train_loss": 3.1127724647521973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16906,
        "tokens": 8863612928,
        "learning_rate": 0.0002904540553700681,
        "gradient_norm": 0.33203551173210144,
        "train_loss": 3.0631155967712402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16907,
        "tokens": 8864137216,
        "learning_rate": 0.00029042571874504305,
        "gradient_norm": 0.3055283725261688,
        "train_loss": 3.0730948448181152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16908,
        "tokens": 8864661504,
        "learning_rate": 0.0002903973825654758,
        "gradient_norm": 0.3106693625450134,
        "train_loss": 3.105283260345459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16909,
        "tokens": 8865185792,
        "learning_rate": 0.0002903690468316854,
        "gradient_norm": 0.3252583146095276,
        "train_loss": 3.076446533203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16910,
        "tokens": 8865710080,
        "learning_rate": 0.00029034071154399076,
        "gradient_norm": 0.2940237522125244,
        "train_loss": 3.058593511581421,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16911,
        "tokens": 8866234368,
        "learning_rate": 0.00029031237670271084,
        "gradient_norm": 0.3474659323692322,
        "train_loss": 3.1101250648498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16912,
        "tokens": 8866758656,
        "learning_rate": 0.00029028404230816454,
        "gradient_norm": 0.2936166226863861,
        "train_loss": 3.087993860244751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16913,
        "tokens": 8867282944,
        "learning_rate": 0.0002902557083606709,
        "gradient_norm": 0.32646849751472473,
        "train_loss": 3.094928026199341,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16914,
        "tokens": 8867807232,
        "learning_rate": 0.00029022737486054885,
        "gradient_norm": 0.32462725043296814,
        "train_loss": 3.1098947525024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16915,
        "tokens": 8868331520,
        "learning_rate": 0.0002901990418081172,
        "gradient_norm": 0.29593348503112793,
        "train_loss": 3.1254796981811523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16916,
        "tokens": 8868855808,
        "learning_rate": 0.000290170709203695,
        "gradient_norm": 0.3028445243835449,
        "train_loss": 3.084259033203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16917,
        "tokens": 8869380096,
        "learning_rate": 0.0002901423770476011,
        "gradient_norm": 0.3017506003379822,
        "train_loss": 3.0901689529418945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16918,
        "tokens": 8869904384,
        "learning_rate": 0.00029011404534015444,
        "gradient_norm": 0.2890804708003998,
        "train_loss": 3.129488468170166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16919,
        "tokens": 8870428672,
        "learning_rate": 0.00029008571408167393,
        "gradient_norm": 0.3243772089481354,
        "train_loss": 3.150341272354126,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16920,
        "tokens": 8870952960,
        "learning_rate": 0.00029005738327247846,
        "gradient_norm": 0.351741224527359,
        "train_loss": 3.0492544174194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16921,
        "tokens": 8871477248,
        "learning_rate": 0.0002900290529128869,
        "gradient_norm": 0.28203073143959045,
        "train_loss": 3.077070713043213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16922,
        "tokens": 8872001536,
        "learning_rate": 0.00029000072300321817,
        "gradient_norm": 0.3572100102901459,
        "train_loss": 3.111600399017334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16923,
        "tokens": 8872525824,
        "learning_rate": 0.00028997239354379114,
        "gradient_norm": 0.3175908625125885,
        "train_loss": 3.0751686096191406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16924,
        "tokens": 8873050112,
        "learning_rate": 0.0002899440645349248,
        "gradient_norm": 0.3131052255630493,
        "train_loss": 3.0516929626464844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16925,
        "tokens": 8873574400,
        "learning_rate": 0.0002899157359769379,
        "gradient_norm": 0.3477179706096649,
        "train_loss": 3.2346930503845215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16926,
        "tokens": 8874098688,
        "learning_rate": 0.0002898874078701494,
        "gradient_norm": 0.3481443226337433,
        "train_loss": 3.065279483795166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16927,
        "tokens": 8874622976,
        "learning_rate": 0.00028985908021487804,
        "gradient_norm": 0.3245695233345032,
        "train_loss": 3.110347270965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16928,
        "tokens": 8875147264,
        "learning_rate": 0.00028983075301144284,
        "gradient_norm": 0.35536813735961914,
        "train_loss": 3.0083436965942383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16929,
        "tokens": 8875671552,
        "learning_rate": 0.0002898024262601625,
        "gradient_norm": 0.31360548734664917,
        "train_loss": 3.142550468444824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16930,
        "tokens": 8876195840,
        "learning_rate": 0.0002897740999613561,
        "gradient_norm": 0.3293575942516327,
        "train_loss": 3.0529894828796387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16931,
        "tokens": 8876720128,
        "learning_rate": 0.00028974577411534225,
        "gradient_norm": 0.39011818170547485,
        "train_loss": 3.0911552906036377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16932,
        "tokens": 8877244416,
        "learning_rate": 0.00028971744872243984,
        "gradient_norm": 0.3617619276046753,
        "train_loss": 3.053020477294922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16933,
        "tokens": 8877768704,
        "learning_rate": 0.0002896891237829679,
        "gradient_norm": 0.29424989223480225,
        "train_loss": 3.1109328269958496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16934,
        "tokens": 8878292992,
        "learning_rate": 0.000289660799297245,
        "gradient_norm": 0.39953669905662537,
        "train_loss": 3.0891647338867188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16935,
        "tokens": 8878817280,
        "learning_rate": 0.0002896324752655902,
        "gradient_norm": 0.3385492265224457,
        "train_loss": 3.109799385070801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16936,
        "tokens": 8879341568,
        "learning_rate": 0.0002896041516883221,
        "gradient_norm": 0.34366995096206665,
        "train_loss": 3.088583469390869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16937,
        "tokens": 8879865856,
        "learning_rate": 0.0002895758285657597,
        "gradient_norm": 0.38454127311706543,
        "train_loss": 3.0940070152282715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16938,
        "tokens": 8880390144,
        "learning_rate": 0.00028954750589822167,
        "gradient_norm": 0.3224390149116516,
        "train_loss": 3.1136629581451416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16939,
        "tokens": 8880914432,
        "learning_rate": 0.000289519183686027,
        "gradient_norm": 0.3938133716583252,
        "train_loss": 3.1393260955810547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16940,
        "tokens": 8881438720,
        "learning_rate": 0.00028949086192949424,
        "gradient_norm": 0.31492897868156433,
        "train_loss": 3.0819785594940186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16941,
        "tokens": 8881963008,
        "learning_rate": 0.0002894625406289425,
        "gradient_norm": 0.35656338930130005,
        "train_loss": 3.0780229568481445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16942,
        "tokens": 8882487296,
        "learning_rate": 0.0002894342197846902,
        "gradient_norm": 0.3473586440086365,
        "train_loss": 3.033416986465454,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16943,
        "tokens": 8883011584,
        "learning_rate": 0.00028940589939705635,
        "gradient_norm": 0.33923768997192383,
        "train_loss": 3.1190125942230225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16944,
        "tokens": 8883535872,
        "learning_rate": 0.00028937757946635983,
        "gradient_norm": 0.31479719281196594,
        "train_loss": 3.0585267543792725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16945,
        "tokens": 8884060160,
        "learning_rate": 0.00028934925999291917,
        "gradient_norm": 0.3190937936306,
        "train_loss": 3.0850589275360107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16946,
        "tokens": 8884584448,
        "learning_rate": 0.00028932094097705336,
        "gradient_norm": 0.3493405282497406,
        "train_loss": 3.065181255340576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16947,
        "tokens": 8885108736,
        "learning_rate": 0.000289292622419081,
        "gradient_norm": 0.3371333181858063,
        "train_loss": 3.0539729595184326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16948,
        "tokens": 8885633024,
        "learning_rate": 0.00028926430431932106,
        "gradient_norm": 0.3308658003807068,
        "train_loss": 3.10014271736145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16949,
        "tokens": 8886157312,
        "learning_rate": 0.0002892359866780919,
        "gradient_norm": 0.3203370273113251,
        "train_loss": 3.1167855262756348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16950,
        "tokens": 8886681600,
        "learning_rate": 0.00028920766949571276,
        "gradient_norm": 0.3336746096611023,
        "train_loss": 3.0806894302368164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16951,
        "tokens": 8887205888,
        "learning_rate": 0.000289179352772502,
        "gradient_norm": 0.3442156910896301,
        "train_loss": 3.019484281539917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16952,
        "tokens": 8887730176,
        "learning_rate": 0.0002891510365087785,
        "gradient_norm": 0.346527636051178,
        "train_loss": 3.129348039627075,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16953,
        "tokens": 8888254464,
        "learning_rate": 0.0002891227207048611,
        "gradient_norm": 0.3496639132499695,
        "train_loss": 3.0937819480895996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16954,
        "tokens": 8888778752,
        "learning_rate": 0.00028909440536106833,
        "gradient_norm": 0.3485029339790344,
        "train_loss": 3.097646713256836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16955,
        "tokens": 8889303040,
        "learning_rate": 0.0002890660904777192,
        "gradient_norm": 0.36672213673591614,
        "train_loss": 3.173464775085449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16956,
        "tokens": 8889827328,
        "learning_rate": 0.00028903777605513207,
        "gradient_norm": 0.38358524441719055,
        "train_loss": 3.0825133323669434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16957,
        "tokens": 8890351616,
        "learning_rate": 0.00028900946209362596,
        "gradient_norm": 0.3396682143211365,
        "train_loss": 3.1533560752868652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16958,
        "tokens": 8890875904,
        "learning_rate": 0.00028898114859351933,
        "gradient_norm": 0.3589898943901062,
        "train_loss": 3.0770344734191895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16959,
        "tokens": 8891400192,
        "learning_rate": 0.00028895283555513114,
        "gradient_norm": 0.3272075355052948,
        "train_loss": 3.0433738231658936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16960,
        "tokens": 8891924480,
        "learning_rate": 0.0002889245229787797,
        "gradient_norm": 0.3383323550224304,
        "train_loss": 3.061105251312256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16961,
        "tokens": 8892448768,
        "learning_rate": 0.00028889621086478426,
        "gradient_norm": 0.317490816116333,
        "train_loss": 3.162642478942871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16962,
        "tokens": 8892973056,
        "learning_rate": 0.00028886789921346297,
        "gradient_norm": 0.33884096145629883,
        "train_loss": 3.112152576446533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16963,
        "tokens": 8893497344,
        "learning_rate": 0.0002888395880251349,
        "gradient_norm": 0.31308016180992126,
        "train_loss": 3.055338144302368,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16964,
        "tokens": 8894021632,
        "learning_rate": 0.00028881127730011856,
        "gradient_norm": 0.33482685685157776,
        "train_loss": 3.086951732635498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16965,
        "tokens": 8894545920,
        "learning_rate": 0.0002887829670387325,
        "gradient_norm": 0.318656861782074,
        "train_loss": 3.0869529247283936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16966,
        "tokens": 8895070208,
        "learning_rate": 0.0002887546572412957,
        "gradient_norm": 0.3435041010379791,
        "train_loss": 3.076580286026001,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16967,
        "tokens": 8895594496,
        "learning_rate": 0.00028872634790812657,
        "gradient_norm": 0.34347864985466003,
        "train_loss": 3.045693874359131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16968,
        "tokens": 8896118784,
        "learning_rate": 0.00028869803903954383,
        "gradient_norm": 0.34155794978141785,
        "train_loss": 3.0738728046417236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16969,
        "tokens": 8896643072,
        "learning_rate": 0.0002886697306358662,
        "gradient_norm": 0.30961310863494873,
        "train_loss": 3.0609259605407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16970,
        "tokens": 8897167360,
        "learning_rate": 0.0002886414226974122,
        "gradient_norm": 0.30769166350364685,
        "train_loss": 3.1064000129699707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16971,
        "tokens": 8897691648,
        "learning_rate": 0.0002886131152245006,
        "gradient_norm": 0.33824536204338074,
        "train_loss": 3.111185073852539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16972,
        "tokens": 8898215936,
        "learning_rate": 0.0002885848082174498,
        "gradient_norm": 0.3938748836517334,
        "train_loss": 3.1281657218933105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16973,
        "tokens": 8898740224,
        "learning_rate": 0.0002885565016765789,
        "gradient_norm": 0.3309827744960785,
        "train_loss": 3.084949016571045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16974,
        "tokens": 8899264512,
        "learning_rate": 0.000288528195602206,
        "gradient_norm": 0.37305447459220886,
        "train_loss": 3.0936598777770996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16975,
        "tokens": 8899788800,
        "learning_rate": 0.00028849988999465014,
        "gradient_norm": 0.3571207821369171,
        "train_loss": 3.2164323329925537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16976,
        "tokens": 8900313088,
        "learning_rate": 0.0002884715848542296,
        "gradient_norm": 0.341316819190979,
        "train_loss": 3.081404685974121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16977,
        "tokens": 8900837376,
        "learning_rate": 0.00028844328018126327,
        "gradient_norm": 0.3398135304450989,
        "train_loss": 3.064581871032715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16978,
        "tokens": 8901361664,
        "learning_rate": 0.00028841497597606946,
        "gradient_norm": 0.33060044050216675,
        "train_loss": 3.1602301597595215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16979,
        "tokens": 8901885952,
        "learning_rate": 0.00028838667223896703,
        "gradient_norm": 0.34084564447402954,
        "train_loss": 3.095057487487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16980,
        "tokens": 8902410240,
        "learning_rate": 0.0002883583689702744,
        "gradient_norm": 0.32208964228630066,
        "train_loss": 3.129634141921997,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16981,
        "tokens": 8902934528,
        "learning_rate": 0.00028833006617031044,
        "gradient_norm": 0.3306727409362793,
        "train_loss": 3.0655007362365723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16982,
        "tokens": 8903458816,
        "learning_rate": 0.00028830176383939335,
        "gradient_norm": 0.30568447709083557,
        "train_loss": 3.1403801441192627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16983,
        "tokens": 8903983104,
        "learning_rate": 0.00028827346197784186,
        "gradient_norm": 0.32428666949272156,
        "train_loss": 3.0897397994995117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16984,
        "tokens": 8904507392,
        "learning_rate": 0.00028824516058597466,
        "gradient_norm": 0.31940215826034546,
        "train_loss": 3.0973620414733887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16985,
        "tokens": 8905031680,
        "learning_rate": 0.0002882168596641102,
        "gradient_norm": 0.2880235016345978,
        "train_loss": 3.0874247550964355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16986,
        "tokens": 8905555968,
        "learning_rate": 0.0002881885592125671,
        "gradient_norm": 0.32553228735923767,
        "train_loss": 3.037946939468384,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16987,
        "tokens": 8906080256,
        "learning_rate": 0.0002881602592316638,
        "gradient_norm": 0.27928248047828674,
        "train_loss": 3.030165195465088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16988,
        "tokens": 8906604544,
        "learning_rate": 0.00028813195972171904,
        "gradient_norm": 0.347533643245697,
        "train_loss": 3.1524569988250732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16989,
        "tokens": 8907128832,
        "learning_rate": 0.0002881036606830512,
        "gradient_norm": 0.34150439500808716,
        "train_loss": 3.072716236114502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16990,
        "tokens": 8907653120,
        "learning_rate": 0.00028807536211597896,
        "gradient_norm": 0.33480021357536316,
        "train_loss": 3.172600269317627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16991,
        "tokens": 8908177408,
        "learning_rate": 0.00028804706402082064,
        "gradient_norm": 0.35814377665519714,
        "train_loss": 3.1231987476348877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16992,
        "tokens": 8908701696,
        "learning_rate": 0.00028801876639789493,
        "gradient_norm": 0.40267637372016907,
        "train_loss": 3.100831985473633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16993,
        "tokens": 8909225984,
        "learning_rate": 0.00028799046924752046,
        "gradient_norm": 0.3235754072666168,
        "train_loss": 3.13330078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16994,
        "tokens": 8909750272,
        "learning_rate": 0.0002879621725700155,
        "gradient_norm": 0.3359977602958679,
        "train_loss": 3.020042896270752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16995,
        "tokens": 8910274560,
        "learning_rate": 0.0002879338763656988,
        "gradient_norm": 0.3749238848686218,
        "train_loss": 3.1344001293182373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16996,
        "tokens": 8910798848,
        "learning_rate": 0.00028790558063488867,
        "gradient_norm": 0.38209888339042664,
        "train_loss": 3.1525073051452637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16997,
        "tokens": 8911323136,
        "learning_rate": 0.0002878772853779038,
        "gradient_norm": 0.3881172835826874,
        "train_loss": 3.1156609058380127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16998,
        "tokens": 8911847424,
        "learning_rate": 0.00028784899059506247,
        "gradient_norm": 0.36415529251098633,
        "train_loss": 3.0636584758758545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 16999,
        "tokens": 8912371712,
        "learning_rate": 0.0002878206962866834,
        "gradient_norm": 0.3292727470397949,
        "train_loss": 3.071070432662964,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17000,
        "tokens": 8912896000,
        "learning_rate": 0.0002877924024530849,
        "gradient_norm": 0.43403834104537964,
        "train_loss": 3.1790852546691895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17001,
        "tokens": 8913420288,
        "learning_rate": 0.0002877641090945856,
        "gradient_norm": 0.5055148601531982,
        "train_loss": 3.1531529426574707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17002,
        "tokens": 8913944576,
        "learning_rate": 0.0002877358162115038,
        "gradient_norm": 0.383376806974411,
        "train_loss": 3.109912395477295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17003,
        "tokens": 8914468864,
        "learning_rate": 0.00028770752380415804,
        "gradient_norm": 0.3773877024650574,
        "train_loss": 3.1047329902648926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17004,
        "tokens": 8914993152,
        "learning_rate": 0.00028767923187286693,
        "gradient_norm": 0.34390440583229065,
        "train_loss": 3.0978951454162598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17005,
        "tokens": 8915517440,
        "learning_rate": 0.0002876509404179488,
        "gradient_norm": 0.3436972498893738,
        "train_loss": 3.0910370349884033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17006,
        "tokens": 8916041728,
        "learning_rate": 0.0002876226494397221,
        "gradient_norm": 0.33974334597587585,
        "train_loss": 3.1478047370910645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17007,
        "tokens": 8916566016,
        "learning_rate": 0.0002875943589385053,
        "gradient_norm": 0.35619914531707764,
        "train_loss": 3.0642435550689697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17008,
        "tokens": 8917090304,
        "learning_rate": 0.0002875660689146169,
        "gradient_norm": 0.3416300415992737,
        "train_loss": 3.053730010986328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17009,
        "tokens": 8917614592,
        "learning_rate": 0.0002875377793683752,
        "gradient_norm": 0.31948453187942505,
        "train_loss": 3.1338143348693848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17010,
        "tokens": 8918138880,
        "learning_rate": 0.00028750949030009884,
        "gradient_norm": 0.3348160684108734,
        "train_loss": 3.0963528156280518,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17011,
        "tokens": 8918663168,
        "learning_rate": 0.0002874812017101061,
        "gradient_norm": 0.30436694622039795,
        "train_loss": 3.1038670539855957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17012,
        "tokens": 8919187456,
        "learning_rate": 0.0002874529135987154,
        "gradient_norm": 0.3234592080116272,
        "train_loss": 3.060647964477539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17013,
        "tokens": 8919711744,
        "learning_rate": 0.0002874246259662452,
        "gradient_norm": 0.32441022992134094,
        "train_loss": 3.15036678314209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17014,
        "tokens": 8920236032,
        "learning_rate": 0.00028739633881301387,
        "gradient_norm": 0.32387346029281616,
        "train_loss": 3.0941364765167236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17015,
        "tokens": 8920760320,
        "learning_rate": 0.0002873680521393399,
        "gradient_norm": 0.32369720935821533,
        "train_loss": 3.1514053344726562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17016,
        "tokens": 8921284608,
        "learning_rate": 0.00028733976594554165,
        "gradient_norm": 0.3244786262512207,
        "train_loss": 3.109389305114746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17017,
        "tokens": 8921808896,
        "learning_rate": 0.0002873114802319375,
        "gradient_norm": 0.3010571002960205,
        "train_loss": 3.103518009185791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17018,
        "tokens": 8922333184,
        "learning_rate": 0.0002872831949988459,
        "gradient_norm": 0.33607980608940125,
        "train_loss": 3.059400796890259,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17019,
        "tokens": 8922857472,
        "learning_rate": 0.00028725491024658516,
        "gradient_norm": 0.3037354052066803,
        "train_loss": 3.1016764640808105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17020,
        "tokens": 8923381760,
        "learning_rate": 0.0002872266259754736,
        "gradient_norm": 0.313337504863739,
        "train_loss": 3.0916318893432617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17021,
        "tokens": 8923906048,
        "learning_rate": 0.0002871983421858298,
        "gradient_norm": 0.30434778332710266,
        "train_loss": 3.0906715393066406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17022,
        "tokens": 8924430336,
        "learning_rate": 0.00028717005887797195,
        "gradient_norm": 0.29336339235305786,
        "train_loss": 3.096677780151367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17023,
        "tokens": 8924954624,
        "learning_rate": 0.00028714177605221845,
        "gradient_norm": 0.32595786452293396,
        "train_loss": 3.033726692199707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17024,
        "tokens": 8925478912,
        "learning_rate": 0.00028711349370888776,
        "gradient_norm": 0.2952682375907898,
        "train_loss": 3.089292526245117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17025,
        "tokens": 8926003200,
        "learning_rate": 0.0002870852118482981,
        "gradient_norm": 0.31318458914756775,
        "train_loss": 3.1023826599121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17026,
        "tokens": 8926527488,
        "learning_rate": 0.000287056930470768,
        "gradient_norm": 0.2973329424858093,
        "train_loss": 3.120588779449463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17027,
        "tokens": 8927051776,
        "learning_rate": 0.00028702864957661547,
        "gradient_norm": 0.33868518471717834,
        "train_loss": 3.1007447242736816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17028,
        "tokens": 8927576064,
        "learning_rate": 0.0002870003691661592,
        "gradient_norm": 0.40749579668045044,
        "train_loss": 3.11865496635437,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17029,
        "tokens": 8928100352,
        "learning_rate": 0.0002869720892397173,
        "gradient_norm": 0.3723565638065338,
        "train_loss": 3.1835789680480957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17030,
        "tokens": 8928624640,
        "learning_rate": 0.0002869438097976083,
        "gradient_norm": 0.48323875665664673,
        "train_loss": 2.9898548126220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17031,
        "tokens": 8929148928,
        "learning_rate": 0.0002869155308401502,
        "gradient_norm": 0.41628211736679077,
        "train_loss": 3.1116130352020264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17032,
        "tokens": 8929673216,
        "learning_rate": 0.0002868872523676616,
        "gradient_norm": 0.39256751537323,
        "train_loss": 3.039684295654297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17033,
        "tokens": 8930197504,
        "learning_rate": 0.0002868589743804608,
        "gradient_norm": 0.38371098041534424,
        "train_loss": 3.1743226051330566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17034,
        "tokens": 8930721792,
        "learning_rate": 0.0002868306968788659,
        "gradient_norm": 0.32675406336784363,
        "train_loss": 3.099867105484009,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17035,
        "tokens": 8931246080,
        "learning_rate": 0.0002868024198631954,
        "gradient_norm": 0.34770825505256653,
        "train_loss": 3.1361522674560547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17036,
        "tokens": 8931770368,
        "learning_rate": 0.0002867741433337674,
        "gradient_norm": 0.34538769721984863,
        "train_loss": 3.004075050354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17037,
        "tokens": 8932294656,
        "learning_rate": 0.0002867458672909004,
        "gradient_norm": 0.3229648768901825,
        "train_loss": 3.111739158630371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17038,
        "tokens": 8932818944,
        "learning_rate": 0.0002867175917349125,
        "gradient_norm": 0.33225682377815247,
        "train_loss": 3.0087461471557617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17039,
        "tokens": 8933343232,
        "learning_rate": 0.0002866893166661222,
        "gradient_norm": 0.32020893692970276,
        "train_loss": 3.0745797157287598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17040,
        "tokens": 8933867520,
        "learning_rate": 0.00028666104208484745,
        "gradient_norm": 0.34096962213516235,
        "train_loss": 3.1373250484466553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17041,
        "tokens": 8934391808,
        "learning_rate": 0.0002866327679914069,
        "gradient_norm": 0.33536645770072937,
        "train_loss": 3.1202194690704346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17042,
        "tokens": 8934916096,
        "learning_rate": 0.0002866044943861184,
        "gradient_norm": 0.3113020062446594,
        "train_loss": 3.0971593856811523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17043,
        "tokens": 8935440384,
        "learning_rate": 0.00028657622126930044,
        "gradient_norm": 0.3258044719696045,
        "train_loss": 3.0568740367889404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17044,
        "tokens": 8935964672,
        "learning_rate": 0.0002865479486412714,
        "gradient_norm": 0.3328840136528015,
        "train_loss": 3.0923051834106445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17045,
        "tokens": 8936488960,
        "learning_rate": 0.0002865196765023492,
        "gradient_norm": 0.36788153648376465,
        "train_loss": 3.0877881050109863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17046,
        "tokens": 8937013248,
        "learning_rate": 0.00028649140485285235,
        "gradient_norm": 0.3172314465045929,
        "train_loss": 3.074410915374756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17047,
        "tokens": 8937537536,
        "learning_rate": 0.00028646313369309884,
        "gradient_norm": 0.37004271149635315,
        "train_loss": 3.0774755477905273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17048,
        "tokens": 8938061824,
        "learning_rate": 0.0002864348630234072,
        "gradient_norm": 0.3531636893749237,
        "train_loss": 3.040264844894409,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17049,
        "tokens": 8938586112,
        "learning_rate": 0.00028640659284409533,
        "gradient_norm": 0.35288354754447937,
        "train_loss": 3.0539164543151855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17050,
        "tokens": 8939110400,
        "learning_rate": 0.00028637832315548176,
        "gradient_norm": 0.2930002808570862,
        "train_loss": 3.1256117820739746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17051,
        "tokens": 8939634688,
        "learning_rate": 0.0002863500539578844,
        "gradient_norm": 0.38307175040245056,
        "train_loss": 3.156193733215332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17052,
        "tokens": 8940158976,
        "learning_rate": 0.0002863217852516215,
        "gradient_norm": 0.3560480773448944,
        "train_loss": 3.109386682510376,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17053,
        "tokens": 8940683264,
        "learning_rate": 0.0002862935170370116,
        "gradient_norm": 0.35943564772605896,
        "train_loss": 3.117478370666504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17054,
        "tokens": 8941207552,
        "learning_rate": 0.0002862652493143725,
        "gradient_norm": 0.3325837254524231,
        "train_loss": 3.140092372894287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17055,
        "tokens": 8941731840,
        "learning_rate": 0.00028623698208402265,
        "gradient_norm": 0.3383202850818634,
        "train_loss": 3.0933704376220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17056,
        "tokens": 8942256128,
        "learning_rate": 0.00028620871534627997,
        "gradient_norm": 0.32577410340309143,
        "train_loss": 3.0603978633880615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17057,
        "tokens": 8942780416,
        "learning_rate": 0.0002861804491014629,
        "gradient_norm": 0.31863659620285034,
        "train_loss": 3.077664852142334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17058,
        "tokens": 8943304704,
        "learning_rate": 0.00028615218334988944,
        "gradient_norm": 0.37030884623527527,
        "train_loss": 3.133481979370117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17059,
        "tokens": 8943828992,
        "learning_rate": 0.00028612391809187786,
        "gradient_norm": 0.3023729622364044,
        "train_loss": 3.048673391342163,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17060,
        "tokens": 8944353280,
        "learning_rate": 0.00028609565332774617,
        "gradient_norm": 0.3211832344532013,
        "train_loss": 3.0915303230285645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17061,
        "tokens": 8944877568,
        "learning_rate": 0.0002860673890578128,
        "gradient_norm": 0.28940320014953613,
        "train_loss": 3.1287598609924316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17062,
        "tokens": 8945401856,
        "learning_rate": 0.00028603912528239555,
        "gradient_norm": 0.31562313437461853,
        "train_loss": 3.1089682579040527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17063,
        "tokens": 8945926144,
        "learning_rate": 0.0002860108620018129,
        "gradient_norm": 0.3597928285598755,
        "train_loss": 3.0655789375305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17064,
        "tokens": 8946450432,
        "learning_rate": 0.00028598259921638273,
        "gradient_norm": 0.32209378480911255,
        "train_loss": 3.07743501663208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17065,
        "tokens": 8946974720,
        "learning_rate": 0.00028595433692642333,
        "gradient_norm": 0.31746187806129456,
        "train_loss": 3.082645893096924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17066,
        "tokens": 8947499008,
        "learning_rate": 0.0002859260751322528,
        "gradient_norm": 0.3221418559551239,
        "train_loss": 3.067378520965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17067,
        "tokens": 8948023296,
        "learning_rate": 0.0002858978138341891,
        "gradient_norm": 0.3121032416820526,
        "train_loss": 3.1016032695770264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17068,
        "tokens": 8948547584,
        "learning_rate": 0.00028586955303255054,
        "gradient_norm": 0.33908921480178833,
        "train_loss": 3.0719265937805176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17069,
        "tokens": 8949071872,
        "learning_rate": 0.00028584129272765527,
        "gradient_norm": 0.3104202151298523,
        "train_loss": 3.078150749206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17070,
        "tokens": 8949596160,
        "learning_rate": 0.00028581303291982116,
        "gradient_norm": 0.34448617696762085,
        "train_loss": 3.0904953479766846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17071,
        "tokens": 8950120448,
        "learning_rate": 0.00028578477360936654,
        "gradient_norm": 0.2981951832771301,
        "train_loss": 3.132314682006836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17072,
        "tokens": 8950644736,
        "learning_rate": 0.0002857565147966093,
        "gradient_norm": 0.3201236128807068,
        "train_loss": 3.0328941345214844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17073,
        "tokens": 8951169024,
        "learning_rate": 0.00028572825648186777,
        "gradient_norm": 0.3041312098503113,
        "train_loss": 3.1124372482299805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17074,
        "tokens": 8951693312,
        "learning_rate": 0.00028569999866545983,
        "gradient_norm": 0.3320733308792114,
        "train_loss": 3.128148078918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17075,
        "tokens": 8952217600,
        "learning_rate": 0.00028567174134770364,
        "gradient_norm": 0.30884233117103577,
        "train_loss": 3.0337305068969727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17076,
        "tokens": 8952741888,
        "learning_rate": 0.00028564348452891724,
        "gradient_norm": 0.3304752707481384,
        "train_loss": 3.117015838623047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17077,
        "tokens": 8953266176,
        "learning_rate": 0.0002856152282094188,
        "gradient_norm": 0.3248794674873352,
        "train_loss": 3.088571548461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17078,
        "tokens": 8953790464,
        "learning_rate": 0.0002855869723895261,
        "gradient_norm": 0.3229009509086609,
        "train_loss": 3.0419600009918213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17079,
        "tokens": 8954314752,
        "learning_rate": 0.0002855587170695576,
        "gradient_norm": 0.340619832277298,
        "train_loss": 3.148540496826172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17080,
        "tokens": 8954839040,
        "learning_rate": 0.00028553046224983095,
        "gradient_norm": 0.3485998213291168,
        "train_loss": 3.0600056648254395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17081,
        "tokens": 8955363328,
        "learning_rate": 0.0002855022079306646,
        "gradient_norm": 0.29241788387298584,
        "train_loss": 3.1073873043060303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17082,
        "tokens": 8955887616,
        "learning_rate": 0.0002854739541123762,
        "gradient_norm": 0.324285089969635,
        "train_loss": 3.050597667694092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17083,
        "tokens": 8956411904,
        "learning_rate": 0.00028544570079528395,
        "gradient_norm": 0.32995104789733887,
        "train_loss": 3.063459873199463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17084,
        "tokens": 8956936192,
        "learning_rate": 0.0002854174479797059,
        "gradient_norm": 0.3336656987667084,
        "train_loss": 3.0694193840026855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17085,
        "tokens": 8957460480,
        "learning_rate": 0.00028538919566596004,
        "gradient_norm": 0.3384675681591034,
        "train_loss": 3.106353759765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17086,
        "tokens": 8957984768,
        "learning_rate": 0.0002853609438543645,
        "gradient_norm": 0.3135794997215271,
        "train_loss": 3.0631046295166016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17087,
        "tokens": 8958509056,
        "learning_rate": 0.000285332692545237,
        "gradient_norm": 0.31819793581962585,
        "train_loss": 3.0319466590881348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17088,
        "tokens": 8959033344,
        "learning_rate": 0.0002853044417388959,
        "gradient_norm": 0.30819445848464966,
        "train_loss": 3.0661282539367676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17089,
        "tokens": 8959557632,
        "learning_rate": 0.0002852761914356589,
        "gradient_norm": 0.3321118950843811,
        "train_loss": 3.120547294616699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17090,
        "tokens": 8960081920,
        "learning_rate": 0.0002852479416358442,
        "gradient_norm": 0.31654617190361023,
        "train_loss": 3.1251230239868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17091,
        "tokens": 8960606208,
        "learning_rate": 0.00028521969233976963,
        "gradient_norm": 0.36534103751182556,
        "train_loss": 3.1026253700256348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17092,
        "tokens": 8961130496,
        "learning_rate": 0.00028519144354775323,
        "gradient_norm": 0.3295690715312958,
        "train_loss": 3.1054649353027344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17093,
        "tokens": 8961654784,
        "learning_rate": 0.00028516319526011304,
        "gradient_norm": 0.34441283345222473,
        "train_loss": 3.107355833053589,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17094,
        "tokens": 8962179072,
        "learning_rate": 0.00028513494747716697,
        "gradient_norm": 0.3406367003917694,
        "train_loss": 3.055851936340332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17095,
        "tokens": 8962703360,
        "learning_rate": 0.00028510670019923304,
        "gradient_norm": 0.33031517267227173,
        "train_loss": 3.1196341514587402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17096,
        "tokens": 8963227648,
        "learning_rate": 0.00028507845342662906,
        "gradient_norm": 0.30113938450813293,
        "train_loss": 3.0977671146392822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17097,
        "tokens": 8963751936,
        "learning_rate": 0.0002850502071596732,
        "gradient_norm": 0.32786422967910767,
        "train_loss": 3.0548787117004395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17098,
        "tokens": 8964276224,
        "learning_rate": 0.00028502196139868315,
        "gradient_norm": 0.33568274974823,
        "train_loss": 3.1003894805908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17099,
        "tokens": 8964800512,
        "learning_rate": 0.0002849937161439771,
        "gradient_norm": 0.3491170108318329,
        "train_loss": 3.0975561141967773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17100,
        "tokens": 8965324800,
        "learning_rate": 0.00028496547139587284,
        "gradient_norm": 0.35168108344078064,
        "train_loss": 3.098186492919922,
        "val_loss": 3.0529603958129883,
        "hellaswag_acc": 0.2815176248550415,
        "hellaswag_acc_norm": 0.2893846035003662
    },
    {
        "step": 17101,
        "tokens": 8965849088,
        "learning_rate": 0.00028493722715468837,
        "gradient_norm": 0.28929346799850464,
        "train_loss": 3.051628589630127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17102,
        "tokens": 8966373376,
        "learning_rate": 0.0002849089834207415,
        "gradient_norm": 0.34769460558891296,
        "train_loss": 3.107546806335449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17103,
        "tokens": 8966897664,
        "learning_rate": 0.00028488074019435025,
        "gradient_norm": 0.2904232442378998,
        "train_loss": 3.1183974742889404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17104,
        "tokens": 8967421952,
        "learning_rate": 0.0002848524974758326,
        "gradient_norm": 0.3051646053791046,
        "train_loss": 3.0891056060791016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17105,
        "tokens": 8967946240,
        "learning_rate": 0.00028482425526550625,
        "gradient_norm": 0.32485416531562805,
        "train_loss": 3.1140871047973633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17106,
        "tokens": 8968470528,
        "learning_rate": 0.00028479601356368937,
        "gradient_norm": 0.33658766746520996,
        "train_loss": 3.097545862197876,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17107,
        "tokens": 8968994816,
        "learning_rate": 0.0002847677723706995,
        "gradient_norm": 0.43616941571235657,
        "train_loss": 3.040227174758911,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17108,
        "tokens": 8969519104,
        "learning_rate": 0.0002847395316868549,
        "gradient_norm": 0.3390348255634308,
        "train_loss": 3.045802593231201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17109,
        "tokens": 8970043392,
        "learning_rate": 0.0002847112915124732,
        "gradient_norm": 0.3212408423423767,
        "train_loss": 3.115556478500366,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17110,
        "tokens": 8970567680,
        "learning_rate": 0.0002846830518478725,
        "gradient_norm": 0.3595651686191559,
        "train_loss": 3.0909924507141113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17111,
        "tokens": 8971091968,
        "learning_rate": 0.0002846548126933704,
        "gradient_norm": 0.2999407649040222,
        "train_loss": 3.1041886806488037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17112,
        "tokens": 8971616256,
        "learning_rate": 0.00028462657404928495,
        "gradient_norm": 0.3488982915878296,
        "train_loss": 3.103325366973877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17113,
        "tokens": 8972140544,
        "learning_rate": 0.00028459833591593396,
        "gradient_norm": 0.32081443071365356,
        "train_loss": 3.1255297660827637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17114,
        "tokens": 8972664832,
        "learning_rate": 0.0002845700982936353,
        "gradient_norm": 0.31249749660491943,
        "train_loss": 3.0514168739318848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17115,
        "tokens": 8973189120,
        "learning_rate": 0.0002845418611827069,
        "gradient_norm": 0.3238126337528229,
        "train_loss": 3.105438232421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17116,
        "tokens": 8973713408,
        "learning_rate": 0.0002845136245834664,
        "gradient_norm": 0.3154972791671753,
        "train_loss": 3.1222360134124756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17117,
        "tokens": 8974237696,
        "learning_rate": 0.0002844853884962318,
        "gradient_norm": 0.32841014862060547,
        "train_loss": 3.0574779510498047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17118,
        "tokens": 8974761984,
        "learning_rate": 0.00028445715292132085,
        "gradient_norm": 0.3581278324127197,
        "train_loss": 3.134389877319336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17119,
        "tokens": 8975286272,
        "learning_rate": 0.00028442891785905144,
        "gradient_norm": 0.3411025106906891,
        "train_loss": 3.10119891166687,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17120,
        "tokens": 8975810560,
        "learning_rate": 0.00028440068330974134,
        "gradient_norm": 0.35129114985466003,
        "train_loss": 3.1641836166381836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17121,
        "tokens": 8976334848,
        "learning_rate": 0.0002843724492737085,
        "gradient_norm": 0.3730916976928711,
        "train_loss": 3.12081241607666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17122,
        "tokens": 8976859136,
        "learning_rate": 0.0002843442157512705,
        "gradient_norm": 0.34004005789756775,
        "train_loss": 3.0995330810546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17123,
        "tokens": 8977383424,
        "learning_rate": 0.0002843159827427453,
        "gradient_norm": 0.36453554034233093,
        "train_loss": 3.0700039863586426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17124,
        "tokens": 8977907712,
        "learning_rate": 0.00028428775024845064,
        "gradient_norm": 0.35648250579833984,
        "train_loss": 3.122866153717041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17125,
        "tokens": 8978432000,
        "learning_rate": 0.00028425951826870435,
        "gradient_norm": 0.33235663175582886,
        "train_loss": 3.1044762134552,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17126,
        "tokens": 8978956288,
        "learning_rate": 0.00028423128680382426,
        "gradient_norm": 0.401116281747818,
        "train_loss": 3.119173765182495,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17127,
        "tokens": 8979480576,
        "learning_rate": 0.0002842030558541281,
        "gradient_norm": 0.2839549779891968,
        "train_loss": 3.095757484436035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17128,
        "tokens": 8980004864,
        "learning_rate": 0.00028417482541993346,
        "gradient_norm": 0.3511882722377777,
        "train_loss": 3.050374984741211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17129,
        "tokens": 8980529152,
        "learning_rate": 0.0002841465955015584,
        "gradient_norm": 0.30134880542755127,
        "train_loss": 3.108701705932617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17130,
        "tokens": 8981053440,
        "learning_rate": 0.0002841183660993206,
        "gradient_norm": 0.3176819384098053,
        "train_loss": 3.102935314178467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17131,
        "tokens": 8981577728,
        "learning_rate": 0.00028409013721353776,
        "gradient_norm": 0.315376877784729,
        "train_loss": 3.054912567138672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17132,
        "tokens": 8982102016,
        "learning_rate": 0.0002840619088445276,
        "gradient_norm": 0.3185349702835083,
        "train_loss": 3.1540064811706543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17133,
        "tokens": 8982626304,
        "learning_rate": 0.000284033680992608,
        "gradient_norm": 0.2929157614707947,
        "train_loss": 3.0489611625671387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17134,
        "tokens": 8983150592,
        "learning_rate": 0.0002840054536580965,
        "gradient_norm": 0.3011164367198944,
        "train_loss": 3.1406664848327637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17135,
        "tokens": 8983674880,
        "learning_rate": 0.00028397722684131107,
        "gradient_norm": 0.32331526279449463,
        "train_loss": 3.0758538246154785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17136,
        "tokens": 8984199168,
        "learning_rate": 0.0002839490005425693,
        "gradient_norm": 0.36197197437286377,
        "train_loss": 3.1253879070281982,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17137,
        "tokens": 8984723456,
        "learning_rate": 0.0002839207747621889,
        "gradient_norm": 0.30569934844970703,
        "train_loss": 3.0890603065490723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17138,
        "tokens": 8985247744,
        "learning_rate": 0.0002838925495004876,
        "gradient_norm": 0.3174026310443878,
        "train_loss": 3.1535141468048096,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17139,
        "tokens": 8985772032,
        "learning_rate": 0.0002838643247577832,
        "gradient_norm": 0.30218902230262756,
        "train_loss": 3.084890842437744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17140,
        "tokens": 8986296320,
        "learning_rate": 0.00028383610053439324,
        "gradient_norm": 0.3363952934741974,
        "train_loss": 3.095000743865967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17141,
        "tokens": 8986820608,
        "learning_rate": 0.0002838078768306356,
        "gradient_norm": 0.30618688464164734,
        "train_loss": 3.0526275634765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17142,
        "tokens": 8987344896,
        "learning_rate": 0.00028377965364682786,
        "gradient_norm": 0.30581793189048767,
        "train_loss": 3.078760862350464,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17143,
        "tokens": 8987869184,
        "learning_rate": 0.00028375143098328763,
        "gradient_norm": 0.29189229011535645,
        "train_loss": 3.116933822631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17144,
        "tokens": 8988393472,
        "learning_rate": 0.0002837232088403329,
        "gradient_norm": 0.2934575378894806,
        "train_loss": 3.088111400604248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17145,
        "tokens": 8988917760,
        "learning_rate": 0.000283694987218281,
        "gradient_norm": 0.28194835782051086,
        "train_loss": 3.1178488731384277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17146,
        "tokens": 8989442048,
        "learning_rate": 0.00028366676611744977,
        "gradient_norm": 0.3001991808414459,
        "train_loss": 3.0542640686035156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17147,
        "tokens": 8989966336,
        "learning_rate": 0.00028363854553815687,
        "gradient_norm": 0.3008933961391449,
        "train_loss": 3.11374831199646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17148,
        "tokens": 8990490624,
        "learning_rate": 0.0002836103254807199,
        "gradient_norm": 0.3042125701904297,
        "train_loss": 3.1225948333740234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17149,
        "tokens": 8991014912,
        "learning_rate": 0.0002835821059454565,
        "gradient_norm": 0.3015170693397522,
        "train_loss": 3.0657193660736084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17150,
        "tokens": 8991539200,
        "learning_rate": 0.0002835538869326845,
        "gradient_norm": 0.30834847688674927,
        "train_loss": 3.0859978199005127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17151,
        "tokens": 8992063488,
        "learning_rate": 0.0002835256684427212,
        "gradient_norm": 0.3524971306324005,
        "train_loss": 3.0805747509002686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17152,
        "tokens": 8992587776,
        "learning_rate": 0.0002834974504758845,
        "gradient_norm": 0.3268272578716278,
        "train_loss": 3.072227954864502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17153,
        "tokens": 8993112064,
        "learning_rate": 0.00028346923303249207,
        "gradient_norm": 0.29470717906951904,
        "train_loss": 3.087533950805664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17154,
        "tokens": 8993636352,
        "learning_rate": 0.0002834410161128613,
        "gradient_norm": 0.3244709372520447,
        "train_loss": 3.068032741546631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17155,
        "tokens": 8994160640,
        "learning_rate": 0.00028341279971731004,
        "gradient_norm": 0.3053039014339447,
        "train_loss": 3.0256223678588867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17156,
        "tokens": 8994684928,
        "learning_rate": 0.0002833845838461557,
        "gradient_norm": 0.2988288402557373,
        "train_loss": 3.0960683822631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17157,
        "tokens": 8995209216,
        "learning_rate": 0.0002833563684997161,
        "gradient_norm": 0.3081079423427582,
        "train_loss": 3.101254463195801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17158,
        "tokens": 8995733504,
        "learning_rate": 0.0002833281536783086,
        "gradient_norm": 0.3529735505580902,
        "train_loss": 3.091346263885498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17159,
        "tokens": 8996257792,
        "learning_rate": 0.00028329993938225095,
        "gradient_norm": 0.3157851994037628,
        "train_loss": 3.0754785537719727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17160,
        "tokens": 8996782080,
        "learning_rate": 0.0002832717256118606,
        "gradient_norm": 0.3317364454269409,
        "train_loss": 3.037360191345215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17161,
        "tokens": 8997306368,
        "learning_rate": 0.0002832435123674554,
        "gradient_norm": 0.3896389901638031,
        "train_loss": 3.0445518493652344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17162,
        "tokens": 8997830656,
        "learning_rate": 0.0002832152996493526,
        "gradient_norm": 0.30074542760849,
        "train_loss": 3.014366865158081,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17163,
        "tokens": 8998354944,
        "learning_rate": 0.0002831870874578699,
        "gradient_norm": 0.37721243500709534,
        "train_loss": 3.0878844261169434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17164,
        "tokens": 8998879232,
        "learning_rate": 0.00028315887579332506,
        "gradient_norm": 0.3047146797180176,
        "train_loss": 3.05073881149292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17165,
        "tokens": 8999403520,
        "learning_rate": 0.0002831306646560353,
        "gradient_norm": 0.3787637948989868,
        "train_loss": 2.998004913330078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17166,
        "tokens": 8999927808,
        "learning_rate": 0.0002831024540463185,
        "gradient_norm": 0.3182486295700073,
        "train_loss": 3.083728551864624,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17167,
        "tokens": 9000452096,
        "learning_rate": 0.00028307424396449186,
        "gradient_norm": 0.3281032145023346,
        "train_loss": 3.0915780067443848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17168,
        "tokens": 9000976384,
        "learning_rate": 0.00028304603441087325,
        "gradient_norm": 0.33592966198921204,
        "train_loss": 3.146397113800049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17169,
        "tokens": 9001500672,
        "learning_rate": 0.0002830178253857799,
        "gradient_norm": 0.32273730635643005,
        "train_loss": 3.037487030029297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17170,
        "tokens": 9002024960,
        "learning_rate": 0.0002829896168895297,
        "gradient_norm": 0.3155750036239624,
        "train_loss": 3.0513808727264404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17171,
        "tokens": 9002549248,
        "learning_rate": 0.0002829614089224398,
        "gradient_norm": 0.3192126452922821,
        "train_loss": 3.0697708129882812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17172,
        "tokens": 9003073536,
        "learning_rate": 0.0002829332014848279,
        "gradient_norm": 0.3528403341770172,
        "train_loss": 2.9975719451904297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17173,
        "tokens": 9003597824,
        "learning_rate": 0.0002829049945770115,
        "gradient_norm": 0.49287453293800354,
        "train_loss": 3.044243574142456,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17174,
        "tokens": 9004122112,
        "learning_rate": 0.00028287678819930806,
        "gradient_norm": 0.3392165005207062,
        "train_loss": 3.1525862216949463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17175,
        "tokens": 9004646400,
        "learning_rate": 0.0002828485823520351,
        "gradient_norm": 0.35285791754722595,
        "train_loss": 3.1014461517333984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17176,
        "tokens": 9005170688,
        "learning_rate": 0.0002828203770355102,
        "gradient_norm": 0.34053903818130493,
        "train_loss": 3.0927586555480957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17177,
        "tokens": 9005694976,
        "learning_rate": 0.00028279217225005073,
        "gradient_norm": 0.33822202682495117,
        "train_loss": 3.0816049575805664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17178,
        "tokens": 9006219264,
        "learning_rate": 0.00028276396799597423,
        "gradient_norm": 0.3262450098991394,
        "train_loss": 3.089840888977051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17179,
        "tokens": 9006743552,
        "learning_rate": 0.0002827357642735982,
        "gradient_norm": 0.3244237005710602,
        "train_loss": 3.0795035362243652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17180,
        "tokens": 9007267840,
        "learning_rate": 0.00028270756108323997,
        "gradient_norm": 0.3167504668235779,
        "train_loss": 3.108271598815918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17181,
        "tokens": 9007792128,
        "learning_rate": 0.0002826793584252171,
        "gradient_norm": 0.3028675317764282,
        "train_loss": 3.0793752670288086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17182,
        "tokens": 9008316416,
        "learning_rate": 0.00028265115629984706,
        "gradient_norm": 0.34733080863952637,
        "train_loss": 3.129361629486084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17183,
        "tokens": 9008840704,
        "learning_rate": 0.00028262295470744716,
        "gradient_norm": 0.3176110088825226,
        "train_loss": 3.1190314292907715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17184,
        "tokens": 9009364992,
        "learning_rate": 0.00028259475364833514,
        "gradient_norm": 0.3533976972103119,
        "train_loss": 3.103203058242798,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17185,
        "tokens": 9009889280,
        "learning_rate": 0.00028256655312282813,
        "gradient_norm": 0.4173080027103424,
        "train_loss": 3.093924045562744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17186,
        "tokens": 9010413568,
        "learning_rate": 0.00028253835313124385,
        "gradient_norm": 0.31733545660972595,
        "train_loss": 3.0925681591033936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17187,
        "tokens": 9010937856,
        "learning_rate": 0.0002825101536738994,
        "gradient_norm": 0.366883248090744,
        "train_loss": 3.135660171508789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17188,
        "tokens": 9011462144,
        "learning_rate": 0.0002824819547511125,
        "gradient_norm": 0.30742374062538147,
        "train_loss": 3.1454594135284424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17189,
        "tokens": 9011986432,
        "learning_rate": 0.00028245375636320026,
        "gradient_norm": 0.3557899594306946,
        "train_loss": 3.0940513610839844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17190,
        "tokens": 9012510720,
        "learning_rate": 0.0002824255585104805,
        "gradient_norm": 0.3264094591140747,
        "train_loss": 3.1060311794281006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17191,
        "tokens": 9013035008,
        "learning_rate": 0.00028239736119327016,
        "gradient_norm": 0.3349267244338989,
        "train_loss": 3.1728768348693848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17192,
        "tokens": 9013559296,
        "learning_rate": 0.00028236916441188686,
        "gradient_norm": 0.3256864845752716,
        "train_loss": 3.1226515769958496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17193,
        "tokens": 9014083584,
        "learning_rate": 0.00028234096816664815,
        "gradient_norm": 0.3941015303134918,
        "train_loss": 3.0078701972961426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17194,
        "tokens": 9014607872,
        "learning_rate": 0.00028231277245787116,
        "gradient_norm": 0.3513760268688202,
        "train_loss": 3.131002902984619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17195,
        "tokens": 9015132160,
        "learning_rate": 0.00028228457728587345,
        "gradient_norm": 0.36521434783935547,
        "train_loss": 3.1325745582580566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17196,
        "tokens": 9015656448,
        "learning_rate": 0.00028225638265097215,
        "gradient_norm": 0.364250123500824,
        "train_loss": 3.1724190711975098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17197,
        "tokens": 9016180736,
        "learning_rate": 0.00028222818855348493,
        "gradient_norm": 0.35617905855178833,
        "train_loss": 3.0656909942626953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17198,
        "tokens": 9016705024,
        "learning_rate": 0.00028219999499372886,
        "gradient_norm": 0.33777326345443726,
        "train_loss": 3.134241819381714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17199,
        "tokens": 9017229312,
        "learning_rate": 0.00028217180197202157,
        "gradient_norm": 0.3785002827644348,
        "train_loss": 3.0941596031188965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17200,
        "tokens": 9017753600,
        "learning_rate": 0.0002821436094886801,
        "gradient_norm": 0.3227328062057495,
        "train_loss": 3.0924601554870605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17201,
        "tokens": 9018277888,
        "learning_rate": 0.00028211541754402214,
        "gradient_norm": 0.3724176585674286,
        "train_loss": 3.0835180282592773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17202,
        "tokens": 9018802176,
        "learning_rate": 0.0002820872261383647,
        "gradient_norm": 0.35072940587997437,
        "train_loss": 3.059353828430176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17203,
        "tokens": 9019326464,
        "learning_rate": 0.00028205903527202524,
        "gradient_norm": 0.33700892329216003,
        "train_loss": 3.070373296737671,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17204,
        "tokens": 9019850752,
        "learning_rate": 0.00028203084494532124,
        "gradient_norm": 0.40825536847114563,
        "train_loss": 3.139831066131592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17205,
        "tokens": 9020375040,
        "learning_rate": 0.00028200265515856976,
        "gradient_norm": 0.40263068675994873,
        "train_loss": 3.087319850921631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17206,
        "tokens": 9020899328,
        "learning_rate": 0.00028197446591208836,
        "gradient_norm": 0.34031590819358826,
        "train_loss": 3.1302788257598877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17207,
        "tokens": 9021423616,
        "learning_rate": 0.000281946277206194,
        "gradient_norm": 0.510861873626709,
        "train_loss": 3.0746030807495117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17208,
        "tokens": 9021947904,
        "learning_rate": 0.0002819180890412044,
        "gradient_norm": 0.43012940883636475,
        "train_loss": 3.1712217330932617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17209,
        "tokens": 9022472192,
        "learning_rate": 0.0002818899014174365,
        "gradient_norm": 0.4061417579650879,
        "train_loss": 3.08656644821167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17210,
        "tokens": 9022996480,
        "learning_rate": 0.00028186171433520785,
        "gradient_norm": 0.3504176437854767,
        "train_loss": 3.0512866973876953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17211,
        "tokens": 9023520768,
        "learning_rate": 0.0002818335277948355,
        "gradient_norm": 0.36753764748573303,
        "train_loss": 3.0664114952087402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17212,
        "tokens": 9024045056,
        "learning_rate": 0.00028180534179663683,
        "gradient_norm": 0.3230569660663605,
        "train_loss": 3.08311128616333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17213,
        "tokens": 9024569344,
        "learning_rate": 0.0002817771563409292,
        "gradient_norm": 0.36625078320503235,
        "train_loss": 3.180323600769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17214,
        "tokens": 9025093632,
        "learning_rate": 0.0002817489714280298,
        "gradient_norm": 0.35820895433425903,
        "train_loss": 3.1089491844177246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17215,
        "tokens": 9025617920,
        "learning_rate": 0.0002817207870582558,
        "gradient_norm": 0.3314315974712372,
        "train_loss": 3.072847843170166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17216,
        "tokens": 9026142208,
        "learning_rate": 0.00028169260323192453,
        "gradient_norm": 0.3262566328048706,
        "train_loss": 3.1139214038848877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17217,
        "tokens": 9026666496,
        "learning_rate": 0.00028166441994935333,
        "gradient_norm": 0.3585026264190674,
        "train_loss": 3.062800645828247,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17218,
        "tokens": 9027190784,
        "learning_rate": 0.0002816362372108592,
        "gradient_norm": 0.33424660563468933,
        "train_loss": 3.12123966217041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17219,
        "tokens": 9027715072,
        "learning_rate": 0.0002816080550167596,
        "gradient_norm": 0.33458879590034485,
        "train_loss": 3.108968734741211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17220,
        "tokens": 9028239360,
        "learning_rate": 0.0002815798733673716,
        "gradient_norm": 0.33809658885002136,
        "train_loss": 3.140613555908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17221,
        "tokens": 9028763648,
        "learning_rate": 0.0002815516922630125,
        "gradient_norm": 0.33170944452285767,
        "train_loss": 3.068324327468872,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17222,
        "tokens": 9029287936,
        "learning_rate": 0.0002815235117039995,
        "gradient_norm": 0.3777252733707428,
        "train_loss": 3.1155388355255127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17223,
        "tokens": 9029812224,
        "learning_rate": 0.00028149533169064976,
        "gradient_norm": 0.3363555371761322,
        "train_loss": 3.070307493209839,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17224,
        "tokens": 9030336512,
        "learning_rate": 0.0002814671522232806,
        "gradient_norm": 0.3372214436531067,
        "train_loss": 3.0986266136169434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17225,
        "tokens": 9030860800,
        "learning_rate": 0.0002814389733022091,
        "gradient_norm": 0.35816362500190735,
        "train_loss": 3.0803401470184326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17226,
        "tokens": 9031385088,
        "learning_rate": 0.00028141079492775253,
        "gradient_norm": 0.34913280606269836,
        "train_loss": 3.0878915786743164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17227,
        "tokens": 9031909376,
        "learning_rate": 0.000281382617100228,
        "gradient_norm": 0.4597407877445221,
        "train_loss": 3.1058411598205566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17228,
        "tokens": 9032433664,
        "learning_rate": 0.00028135443981995275,
        "gradient_norm": 0.41395050287246704,
        "train_loss": 3.0960516929626465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17229,
        "tokens": 9032957952,
        "learning_rate": 0.00028132626308724387,
        "gradient_norm": 0.33390867710113525,
        "train_loss": 3.0796432495117188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17230,
        "tokens": 9033482240,
        "learning_rate": 0.00028129808690241856,
        "gradient_norm": 0.37675952911376953,
        "train_loss": 3.050886631011963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17231,
        "tokens": 9034006528,
        "learning_rate": 0.00028126991126579406,
        "gradient_norm": 0.3099467158317566,
        "train_loss": 3.0313315391540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17232,
        "tokens": 9034530816,
        "learning_rate": 0.00028124173617768733,
        "gradient_norm": 0.3101590871810913,
        "train_loss": 3.0536251068115234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17233,
        "tokens": 9035055104,
        "learning_rate": 0.0002812135616384158,
        "gradient_norm": 0.3275439143180847,
        "train_loss": 3.0877418518066406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17234,
        "tokens": 9035579392,
        "learning_rate": 0.00028118538764829626,
        "gradient_norm": 0.31640103459358215,
        "train_loss": 3.0721375942230225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17235,
        "tokens": 9036103680,
        "learning_rate": 0.00028115721420764623,
        "gradient_norm": 0.31439152359962463,
        "train_loss": 3.075749397277832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17236,
        "tokens": 9036627968,
        "learning_rate": 0.0002811290413167825,
        "gradient_norm": 0.294815331697464,
        "train_loss": 3.061641216278076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17237,
        "tokens": 9037152256,
        "learning_rate": 0.00028110086897602243,
        "gradient_norm": 0.32372650504112244,
        "train_loss": 3.1336774826049805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17238,
        "tokens": 9037676544,
        "learning_rate": 0.00028107269718568293,
        "gradient_norm": 0.3036012053489685,
        "train_loss": 3.161120891571045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17239,
        "tokens": 9038200832,
        "learning_rate": 0.0002810445259460813,
        "gradient_norm": 0.3111482858657837,
        "train_loss": 3.078805923461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17240,
        "tokens": 9038725120,
        "learning_rate": 0.00028101635525753447,
        "gradient_norm": 0.3384673297405243,
        "train_loss": 3.082793712615967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17241,
        "tokens": 9039249408,
        "learning_rate": 0.0002809881851203596,
        "gradient_norm": 0.33016568422317505,
        "train_loss": 3.0616369247436523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17242,
        "tokens": 9039773696,
        "learning_rate": 0.00028096001553487397,
        "gradient_norm": 0.31166884303092957,
        "train_loss": 3.081423282623291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17243,
        "tokens": 9040297984,
        "learning_rate": 0.00028093184650139437,
        "gradient_norm": 0.3168680667877197,
        "train_loss": 3.093374729156494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17244,
        "tokens": 9040822272,
        "learning_rate": 0.00028090367802023803,
        "gradient_norm": 0.3362930417060852,
        "train_loss": 3.0748114585876465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17245,
        "tokens": 9041346560,
        "learning_rate": 0.00028087551009172194,
        "gradient_norm": 0.35142451524734497,
        "train_loss": 3.0896363258361816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17246,
        "tokens": 9041870848,
        "learning_rate": 0.00028084734271616337,
        "gradient_norm": 0.3263457417488098,
        "train_loss": 3.1719844341278076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17247,
        "tokens": 9042395136,
        "learning_rate": 0.0002808191758938791,
        "gradient_norm": 0.3561819791793823,
        "train_loss": 3.0903215408325195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17248,
        "tokens": 9042919424,
        "learning_rate": 0.00028079100962518635,
        "gradient_norm": 0.2909240126609802,
        "train_loss": 3.0975852012634277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17249,
        "tokens": 9043443712,
        "learning_rate": 0.00028076284391040206,
        "gradient_norm": 0.34827500581741333,
        "train_loss": 3.0214688777923584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17250,
        "tokens": 9043968000,
        "learning_rate": 0.0002807346787498435,
        "gradient_norm": 0.3160523474216461,
        "train_loss": 3.114102363586426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17251,
        "tokens": 9044492288,
        "learning_rate": 0.00028070651414382737,
        "gradient_norm": 0.30292364954948425,
        "train_loss": 3.09778094291687,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17252,
        "tokens": 9045016576,
        "learning_rate": 0.00028067835009267086,
        "gradient_norm": 0.35177555680274963,
        "train_loss": 3.0599844455718994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17253,
        "tokens": 9045540864,
        "learning_rate": 0.00028065018659669113,
        "gradient_norm": 0.3742545545101166,
        "train_loss": 3.073765516281128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17254,
        "tokens": 9046065152,
        "learning_rate": 0.00028062202365620494,
        "gradient_norm": 0.3196881115436554,
        "train_loss": 3.1210336685180664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17255,
        "tokens": 9046589440,
        "learning_rate": 0.00028059386127152956,
        "gradient_norm": 0.39598459005355835,
        "train_loss": 3.0938501358032227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17256,
        "tokens": 9047113728,
        "learning_rate": 0.00028056569944298176,
        "gradient_norm": 0.33221226930618286,
        "train_loss": 3.081732749938965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17257,
        "tokens": 9047638016,
        "learning_rate": 0.0002805375381708787,
        "gradient_norm": 0.3089693784713745,
        "train_loss": 3.1017332077026367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17258,
        "tokens": 9048162304,
        "learning_rate": 0.0002805093774555372,
        "gradient_norm": 0.3257264494895935,
        "train_loss": 3.0789992809295654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17259,
        "tokens": 9048686592,
        "learning_rate": 0.00028048121729727453,
        "gradient_norm": 0.3015623390674591,
        "train_loss": 3.056870460510254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17260,
        "tokens": 9049210880,
        "learning_rate": 0.0002804530576964073,
        "gradient_norm": 0.33512330055236816,
        "train_loss": 3.0867233276367188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17261,
        "tokens": 9049735168,
        "learning_rate": 0.0002804248986532527,
        "gradient_norm": 0.3127741813659668,
        "train_loss": 3.069089412689209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17262,
        "tokens": 9050259456,
        "learning_rate": 0.0002803967401681278,
        "gradient_norm": 0.3044099807739258,
        "train_loss": 3.056004047393799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17263,
        "tokens": 9050783744,
        "learning_rate": 0.00028036858224134923,
        "gradient_norm": 0.3188914656639099,
        "train_loss": 3.105494499206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17264,
        "tokens": 9051308032,
        "learning_rate": 0.00028034042487323427,
        "gradient_norm": 0.33225497603416443,
        "train_loss": 3.1311473846435547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17265,
        "tokens": 9051832320,
        "learning_rate": 0.0002803122680640997,
        "gradient_norm": 0.32269561290740967,
        "train_loss": 3.1238272190093994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17266,
        "tokens": 9052356608,
        "learning_rate": 0.0002802841118142625,
        "gradient_norm": 0.3404262661933899,
        "train_loss": 3.072953701019287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17267,
        "tokens": 9052880896,
        "learning_rate": 0.00028025595612403957,
        "gradient_norm": 0.3125675618648529,
        "train_loss": 3.090407371520996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17268,
        "tokens": 9053405184,
        "learning_rate": 0.0002802278009937479,
        "gradient_norm": 0.32019445300102234,
        "train_loss": 3.074172019958496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17269,
        "tokens": 9053929472,
        "learning_rate": 0.00028019964642370424,
        "gradient_norm": 0.3462763726711273,
        "train_loss": 3.064601182937622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17270,
        "tokens": 9054453760,
        "learning_rate": 0.0002801714924142259,
        "gradient_norm": 0.31341224908828735,
        "train_loss": 3.0247607231140137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17271,
        "tokens": 9054978048,
        "learning_rate": 0.0002801433389656293,
        "gradient_norm": 0.31900307536125183,
        "train_loss": 3.0296387672424316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17272,
        "tokens": 9055502336,
        "learning_rate": 0.0002801151860782316,
        "gradient_norm": 0.32847827672958374,
        "train_loss": 3.0739541053771973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17273,
        "tokens": 9056026624,
        "learning_rate": 0.0002800870337523497,
        "gradient_norm": 0.3060983419418335,
        "train_loss": 3.054226875305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17274,
        "tokens": 9056550912,
        "learning_rate": 0.00028005888198830045,
        "gradient_norm": 0.32059064507484436,
        "train_loss": 3.105348587036133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17275,
        "tokens": 9057075200,
        "learning_rate": 0.00028003073078640075,
        "gradient_norm": 0.29182639718055725,
        "train_loss": 3.0752711296081543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17276,
        "tokens": 9057599488,
        "learning_rate": 0.0002800025801469675,
        "gradient_norm": 0.3286762535572052,
        "train_loss": 3.0880041122436523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17277,
        "tokens": 9058123776,
        "learning_rate": 0.00027997443007031747,
        "gradient_norm": 0.30971360206604004,
        "train_loss": 3.1125245094299316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17278,
        "tokens": 9058648064,
        "learning_rate": 0.0002799462805567676,
        "gradient_norm": 0.3175589144229889,
        "train_loss": 3.1371660232543945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17279,
        "tokens": 9059172352,
        "learning_rate": 0.00027991813160663476,
        "gradient_norm": 0.2976767420768738,
        "train_loss": 3.1094307899475098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17280,
        "tokens": 9059696640,
        "learning_rate": 0.00027988998322023566,
        "gradient_norm": 0.33488544821739197,
        "train_loss": 3.290830135345459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17281,
        "tokens": 9060220928,
        "learning_rate": 0.0002798618353978874,
        "gradient_norm": 0.35951364040374756,
        "train_loss": 3.1054306030273438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17282,
        "tokens": 9060745216,
        "learning_rate": 0.00027983368813990666,
        "gradient_norm": 0.3414975702762604,
        "train_loss": 3.122957706451416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17283,
        "tokens": 9061269504,
        "learning_rate": 0.00027980554144661025,
        "gradient_norm": 0.4151531159877777,
        "train_loss": 3.081512928009033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17284,
        "tokens": 9061793792,
        "learning_rate": 0.0002797773953183151,
        "gradient_norm": 0.33296114206314087,
        "train_loss": 3.0340075492858887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17285,
        "tokens": 9062318080,
        "learning_rate": 0.00027974924975533787,
        "gradient_norm": 0.35181137919425964,
        "train_loss": 3.0995936393737793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17286,
        "tokens": 9062842368,
        "learning_rate": 0.0002797211047579956,
        "gradient_norm": 0.34246131777763367,
        "train_loss": 3.0951290130615234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17287,
        "tokens": 9063366656,
        "learning_rate": 0.0002796929603266048,
        "gradient_norm": 0.34169358015060425,
        "train_loss": 3.062587261199951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17288,
        "tokens": 9063890944,
        "learning_rate": 0.0002796648164614826,
        "gradient_norm": 0.3708115220069885,
        "train_loss": 3.0536692142486572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17289,
        "tokens": 9064415232,
        "learning_rate": 0.00027963667316294557,
        "gradient_norm": 0.3100944459438324,
        "train_loss": 3.036557197570801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17290,
        "tokens": 9064939520,
        "learning_rate": 0.0002796085304313106,
        "gradient_norm": 0.3257445693016052,
        "train_loss": 3.120662212371826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17291,
        "tokens": 9065463808,
        "learning_rate": 0.0002795803882668944,
        "gradient_norm": 0.34085801243782043,
        "train_loss": 3.0723490715026855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17292,
        "tokens": 9065988096,
        "learning_rate": 0.0002795522466700137,
        "gradient_norm": 0.32304567098617554,
        "train_loss": 3.0505285263061523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17293,
        "tokens": 9066512384,
        "learning_rate": 0.0002795241056409855,
        "gradient_norm": 0.3376845121383667,
        "train_loss": 3.0889322757720947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17294,
        "tokens": 9067036672,
        "learning_rate": 0.00027949596518012635,
        "gradient_norm": 0.352438360452652,
        "train_loss": 3.057884931564331,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17295,
        "tokens": 9067560960,
        "learning_rate": 0.0002794678252877531,
        "gradient_norm": 0.3750024139881134,
        "train_loss": 3.1030731201171875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17296,
        "tokens": 9068085248,
        "learning_rate": 0.0002794396859641824,
        "gradient_norm": 0.30306509137153625,
        "train_loss": 3.060661792755127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17297,
        "tokens": 9068609536,
        "learning_rate": 0.0002794115472097311,
        "gradient_norm": 0.4066849946975708,
        "train_loss": 3.1971800327301025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17298,
        "tokens": 9069133824,
        "learning_rate": 0.00027938340902471586,
        "gradient_norm": 0.36774757504463196,
        "train_loss": 3.053906202316284,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17299,
        "tokens": 9069658112,
        "learning_rate": 0.0002793552714094535,
        "gradient_norm": 0.3573642671108246,
        "train_loss": 3.0742886066436768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17300,
        "tokens": 9070182400,
        "learning_rate": 0.00027932713436426066,
        "gradient_norm": 0.4253910481929779,
        "train_loss": 3.129091262817383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17301,
        "tokens": 9070706688,
        "learning_rate": 0.000279298997889454,
        "gradient_norm": 0.3186243176460266,
        "train_loss": 3.095050573348999,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17302,
        "tokens": 9071230976,
        "learning_rate": 0.0002792708619853505,
        "gradient_norm": 0.4078443944454193,
        "train_loss": 3.1003880500793457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17303,
        "tokens": 9071755264,
        "learning_rate": 0.00027924272665226654,
        "gradient_norm": 0.33700016140937805,
        "train_loss": 3.0597023963928223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17304,
        "tokens": 9072279552,
        "learning_rate": 0.0002792145918905191,
        "gradient_norm": 0.425066202878952,
        "train_loss": 3.1410651206970215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17305,
        "tokens": 9072803840,
        "learning_rate": 0.0002791864577004246,
        "gradient_norm": 0.3209054470062256,
        "train_loss": 3.0342466831207275,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17306,
        "tokens": 9073328128,
        "learning_rate": 0.00027915832408229995,
        "gradient_norm": 0.3733927607536316,
        "train_loss": 3.136559009552002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17307,
        "tokens": 9073852416,
        "learning_rate": 0.00027913019103646165,
        "gradient_norm": 0.3169073760509491,
        "train_loss": 3.1058645248413086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17308,
        "tokens": 9074376704,
        "learning_rate": 0.0002791020585632266,
        "gradient_norm": 0.38661983609199524,
        "train_loss": 3.067141532897949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17309,
        "tokens": 9074900992,
        "learning_rate": 0.00027907392666291113,
        "gradient_norm": 0.34078752994537354,
        "train_loss": 3.0844945907592773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17310,
        "tokens": 9075425280,
        "learning_rate": 0.0002790457953358323,
        "gradient_norm": 0.345479279756546,
        "train_loss": 3.084479331970215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17311,
        "tokens": 9075949568,
        "learning_rate": 0.0002790176645823064,
        "gradient_norm": 0.31776145100593567,
        "train_loss": 3.044344902038574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17312,
        "tokens": 9076473856,
        "learning_rate": 0.0002789895344026503,
        "gradient_norm": 0.3762049674987793,
        "train_loss": 3.036558151245117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17313,
        "tokens": 9076998144,
        "learning_rate": 0.00027896140479718057,
        "gradient_norm": 0.351641446352005,
        "train_loss": 3.154404640197754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17314,
        "tokens": 9077522432,
        "learning_rate": 0.0002789332757662138,
        "gradient_norm": 0.34844544529914856,
        "train_loss": 3.062710762023926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17315,
        "tokens": 9078046720,
        "learning_rate": 0.0002789051473100668,
        "gradient_norm": 0.32089728116989136,
        "train_loss": 3.028506278991699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17316,
        "tokens": 9078571008,
        "learning_rate": 0.00027887701942905593,
        "gradient_norm": 0.3244682550430298,
        "train_loss": 3.030940055847168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17317,
        "tokens": 9079095296,
        "learning_rate": 0.00027884889212349807,
        "gradient_norm": 0.3595001697540283,
        "train_loss": 3.0814921855926514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17318,
        "tokens": 9079619584,
        "learning_rate": 0.0002788207653937095,
        "gradient_norm": 0.38207700848579407,
        "train_loss": 3.125580310821533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17319,
        "tokens": 9080143872,
        "learning_rate": 0.0002787926392400072,
        "gradient_norm": 0.32993021607398987,
        "train_loss": 3.107156276702881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17320,
        "tokens": 9080668160,
        "learning_rate": 0.00027876451366270745,
        "gradient_norm": 0.35571110248565674,
        "train_loss": 3.161499500274658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17321,
        "tokens": 9081192448,
        "learning_rate": 0.00027873638866212703,
        "gradient_norm": 0.31888455152511597,
        "train_loss": 3.092264175415039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17322,
        "tokens": 9081716736,
        "learning_rate": 0.0002787082642385824,
        "gradient_norm": 0.34430110454559326,
        "train_loss": 3.078068971633911,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17323,
        "tokens": 9082241024,
        "learning_rate": 0.0002786801403923902,
        "gradient_norm": 0.2987874746322632,
        "train_loss": 3.1254191398620605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17324,
        "tokens": 9082765312,
        "learning_rate": 0.0002786520171238671,
        "gradient_norm": 0.33458346128463745,
        "train_loss": 3.026886463165283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17325,
        "tokens": 9083289600,
        "learning_rate": 0.0002786238944333294,
        "gradient_norm": 0.3038078546524048,
        "train_loss": 3.0710020065307617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17326,
        "tokens": 9083813888,
        "learning_rate": 0.000278595772321094,
        "gradient_norm": 0.3235127925872803,
        "train_loss": 3.0497069358825684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17327,
        "tokens": 9084338176,
        "learning_rate": 0.00027856765078747704,
        "gradient_norm": 0.3416953384876251,
        "train_loss": 3.1251134872436523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17328,
        "tokens": 9084862464,
        "learning_rate": 0.0002785395298327955,
        "gradient_norm": 0.2920648753643036,
        "train_loss": 3.0451109409332275,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17329,
        "tokens": 9085386752,
        "learning_rate": 0.00027851140945736553,
        "gradient_norm": 0.34829476475715637,
        "train_loss": 3.1022355556488037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17330,
        "tokens": 9085911040,
        "learning_rate": 0.0002784832896615039,
        "gradient_norm": 0.31206464767456055,
        "train_loss": 3.1411657333374023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17331,
        "tokens": 9086435328,
        "learning_rate": 0.00027845517044552704,
        "gradient_norm": 0.3337237536907196,
        "train_loss": 3.0620408058166504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17332,
        "tokens": 9086959616,
        "learning_rate": 0.0002784270518097515,
        "gradient_norm": 0.31796857714653015,
        "train_loss": 3.067324638366699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17333,
        "tokens": 9087483904,
        "learning_rate": 0.00027839893375449377,
        "gradient_norm": 0.35773342847824097,
        "train_loss": 3.1187498569488525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17334,
        "tokens": 9088008192,
        "learning_rate": 0.00027837081628007034,
        "gradient_norm": 0.3431536853313446,
        "train_loss": 3.026059150695801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17335,
        "tokens": 9088532480,
        "learning_rate": 0.0002783426993867978,
        "gradient_norm": 0.3207029402256012,
        "train_loss": 3.058675765991211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17336,
        "tokens": 9089056768,
        "learning_rate": 0.00027831458307499247,
        "gradient_norm": 0.3662060499191284,
        "train_loss": 3.1342530250549316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17337,
        "tokens": 9089581056,
        "learning_rate": 0.0002782864673449711,
        "gradient_norm": 0.3556489050388336,
        "train_loss": 3.057030439376831,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17338,
        "tokens": 9090105344,
        "learning_rate": 0.0002782583521970499,
        "gradient_norm": 0.32381516695022583,
        "train_loss": 3.086824893951416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17339,
        "tokens": 9090629632,
        "learning_rate": 0.0002782302376315454,
        "gradient_norm": 0.4163721799850464,
        "train_loss": 3.050467014312744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17340,
        "tokens": 9091153920,
        "learning_rate": 0.0002782021236487741,
        "gradient_norm": 0.3080970048904419,
        "train_loss": 3.104228973388672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17341,
        "tokens": 9091678208,
        "learning_rate": 0.00027817401024905254,
        "gradient_norm": 0.40013137459754944,
        "train_loss": 3.1026127338409424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17342,
        "tokens": 9092202496,
        "learning_rate": 0.0002781458974326971,
        "gradient_norm": 0.3224807381629944,
        "train_loss": 3.0703208446502686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17343,
        "tokens": 9092726784,
        "learning_rate": 0.0002781177852000242,
        "gradient_norm": 0.37339499592781067,
        "train_loss": 3.1208038330078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17344,
        "tokens": 9093251072,
        "learning_rate": 0.00027808967355135036,
        "gradient_norm": 0.3765017092227936,
        "train_loss": 3.103480339050293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17345,
        "tokens": 9093775360,
        "learning_rate": 0.0002780615624869918,
        "gradient_norm": 0.3199833035469055,
        "train_loss": 3.0289218425750732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17346,
        "tokens": 9094299648,
        "learning_rate": 0.0002780334520072653,
        "gradient_norm": 0.4119984805583954,
        "train_loss": 3.0589380264282227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17347,
        "tokens": 9094823936,
        "learning_rate": 0.0002780053421124869,
        "gradient_norm": 0.40667250752449036,
        "train_loss": 3.174064874649048,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17348,
        "tokens": 9095348224,
        "learning_rate": 0.00027797723280297324,
        "gradient_norm": 0.41794130206108093,
        "train_loss": 3.098378896713257,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17349,
        "tokens": 9095872512,
        "learning_rate": 0.00027794912407904065,
        "gradient_norm": 0.3375537097454071,
        "train_loss": 3.0496134757995605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17350,
        "tokens": 9096396800,
        "learning_rate": 0.00027792101594100566,
        "gradient_norm": 0.3624962568283081,
        "train_loss": 3.1151621341705322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17351,
        "tokens": 9096921088,
        "learning_rate": 0.00027789290838918436,
        "gradient_norm": 0.3645249307155609,
        "train_loss": 3.111175060272217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17352,
        "tokens": 9097445376,
        "learning_rate": 0.0002778648014238934,
        "gradient_norm": 0.35784193873405457,
        "train_loss": 3.040181875228882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17353,
        "tokens": 9097969664,
        "learning_rate": 0.0002778366950454492,
        "gradient_norm": 0.3570430278778076,
        "train_loss": 3.0794677734375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17354,
        "tokens": 9098493952,
        "learning_rate": 0.00027780858925416797,
        "gradient_norm": 0.34794676303863525,
        "train_loss": 3.0518155097961426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17355,
        "tokens": 9099018240,
        "learning_rate": 0.00027778048405036613,
        "gradient_norm": 0.34392231702804565,
        "train_loss": 3.101219892501831,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17356,
        "tokens": 9099542528,
        "learning_rate": 0.00027775237943436,
        "gradient_norm": 0.4078715741634369,
        "train_loss": 3.1044492721557617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17357,
        "tokens": 9100066816,
        "learning_rate": 0.000277724275406466,
        "gradient_norm": 0.3838953673839569,
        "train_loss": 3.124206304550171,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17358,
        "tokens": 9100591104,
        "learning_rate": 0.0002776961719670004,
        "gradient_norm": 0.35058555006980896,
        "train_loss": 3.0635290145874023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17359,
        "tokens": 9101115392,
        "learning_rate": 0.00027766806911627966,
        "gradient_norm": 0.41518092155456543,
        "train_loss": 3.1025283336639404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17360,
        "tokens": 9101639680,
        "learning_rate": 0.0002776399668546199,
        "gradient_norm": 0.31508156657218933,
        "train_loss": 3.05123233795166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17361,
        "tokens": 9102163968,
        "learning_rate": 0.00027761186518233765,
        "gradient_norm": 0.32428228855133057,
        "train_loss": 3.082897186279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17362,
        "tokens": 9102688256,
        "learning_rate": 0.00027758376409974927,
        "gradient_norm": 0.3789202570915222,
        "train_loss": 3.1082184314727783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17363,
        "tokens": 9103212544,
        "learning_rate": 0.0002775556636071708,
        "gradient_norm": 0.32622694969177246,
        "train_loss": 3.0625362396240234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17364,
        "tokens": 9103736832,
        "learning_rate": 0.00027752756370491886,
        "gradient_norm": 0.3586577773094177,
        "train_loss": 3.1592204570770264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17365,
        "tokens": 9104261120,
        "learning_rate": 0.00027749946439330946,
        "gradient_norm": 0.330929160118103,
        "train_loss": 3.0225021839141846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17366,
        "tokens": 9104785408,
        "learning_rate": 0.00027747136567265915,
        "gradient_norm": 0.32510364055633545,
        "train_loss": 3.093790054321289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17367,
        "tokens": 9105309696,
        "learning_rate": 0.000277443267543284,
        "gradient_norm": 0.28836941719055176,
        "train_loss": 3.024998426437378,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17368,
        "tokens": 9105833984,
        "learning_rate": 0.0002774151700055005,
        "gradient_norm": 0.32743552327156067,
        "train_loss": 3.0842366218566895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17369,
        "tokens": 9106358272,
        "learning_rate": 0.0002773870730596247,
        "gradient_norm": 0.28743720054626465,
        "train_loss": 3.071798324584961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17370,
        "tokens": 9106882560,
        "learning_rate": 0.00027735897670597305,
        "gradient_norm": 0.3295760154724121,
        "train_loss": 3.091887950897217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17371,
        "tokens": 9107406848,
        "learning_rate": 0.00027733088094486166,
        "gradient_norm": 0.3069941997528076,
        "train_loss": 3.0737264156341553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17372,
        "tokens": 9107931136,
        "learning_rate": 0.0002773027857766068,
        "gradient_norm": 0.3477143347263336,
        "train_loss": 3.090580463409424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17373,
        "tokens": 9108455424,
        "learning_rate": 0.00027727469120152493,
        "gradient_norm": 0.3313530385494232,
        "train_loss": 3.042584180831909,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17374,
        "tokens": 9108979712,
        "learning_rate": 0.00027724659721993207,
        "gradient_norm": 0.3312361538410187,
        "train_loss": 3.0424647331237793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17375,
        "tokens": 9109504000,
        "learning_rate": 0.0002772185038321446,
        "gradient_norm": 0.32964009046554565,
        "train_loss": 3.0864546298980713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17376,
        "tokens": 9110028288,
        "learning_rate": 0.0002771904110384785,
        "gradient_norm": 0.30423158407211304,
        "train_loss": 3.1254870891571045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17377,
        "tokens": 9110552576,
        "learning_rate": 0.0002771623188392503,
        "gradient_norm": 0.39142662286758423,
        "train_loss": 3.107844591140747,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17378,
        "tokens": 9111076864,
        "learning_rate": 0.000277134227234776,
        "gradient_norm": 0.28096243739128113,
        "train_loss": 3.035738229751587,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17379,
        "tokens": 9111601152,
        "learning_rate": 0.0002771061362253719,
        "gradient_norm": 0.34735623002052307,
        "train_loss": 3.0750558376312256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17380,
        "tokens": 9112125440,
        "learning_rate": 0.0002770780458113541,
        "gradient_norm": 0.3132215738296509,
        "train_loss": 3.143460512161255,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17381,
        "tokens": 9112649728,
        "learning_rate": 0.00027704995599303893,
        "gradient_norm": 0.3186778128147125,
        "train_loss": 3.078993320465088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17382,
        "tokens": 9113174016,
        "learning_rate": 0.0002770218667707425,
        "gradient_norm": 0.3292187750339508,
        "train_loss": 3.062159776687622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17383,
        "tokens": 9113698304,
        "learning_rate": 0.000276993778144781,
        "gradient_norm": 0.3195815980434418,
        "train_loss": 3.081202268600464,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17384,
        "tokens": 9114222592,
        "learning_rate": 0.0002769656901154706,
        "gradient_norm": 0.3557187616825104,
        "train_loss": 3.074993848800659,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17385,
        "tokens": 9114746880,
        "learning_rate": 0.00027693760268312747,
        "gradient_norm": 0.30720940232276917,
        "train_loss": 3.103426218032837,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17386,
        "tokens": 9115271168,
        "learning_rate": 0.0002769095158480677,
        "gradient_norm": 0.39441388845443726,
        "train_loss": 3.0601437091827393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17387,
        "tokens": 9115795456,
        "learning_rate": 0.0002768814296106076,
        "gradient_norm": 0.3690473437309265,
        "train_loss": 3.136202096939087,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17388,
        "tokens": 9116319744,
        "learning_rate": 0.0002768533439710632,
        "gradient_norm": 0.327456533908844,
        "train_loss": 3.095301628112793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17389,
        "tokens": 9116844032,
        "learning_rate": 0.00027682525892975065,
        "gradient_norm": 0.4327039420604706,
        "train_loss": 3.1205408573150635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17390,
        "tokens": 9117368320,
        "learning_rate": 0.00027679717448698607,
        "gradient_norm": 0.31265172362327576,
        "train_loss": 3.11873197555542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17391,
        "tokens": 9117892608,
        "learning_rate": 0.00027676909064308565,
        "gradient_norm": 0.44253721833229065,
        "train_loss": 3.0719025135040283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17392,
        "tokens": 9118416896,
        "learning_rate": 0.0002767410073983654,
        "gradient_norm": 0.40418192744255066,
        "train_loss": 3.1070632934570312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17393,
        "tokens": 9118941184,
        "learning_rate": 0.0002767129247531416,
        "gradient_norm": 0.39169567823410034,
        "train_loss": 3.066318988800049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17394,
        "tokens": 9119465472,
        "learning_rate": 0.00027668484270773017,
        "gradient_norm": 0.3358966112136841,
        "train_loss": 3.1436705589294434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17395,
        "tokens": 9119989760,
        "learning_rate": 0.0002766567612624474,
        "gradient_norm": 0.3503003716468811,
        "train_loss": 3.0893001556396484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17396,
        "tokens": 9120514048,
        "learning_rate": 0.0002766286804176092,
        "gradient_norm": 0.3455455005168915,
        "train_loss": 3.0957541465759277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17397,
        "tokens": 9121038336,
        "learning_rate": 0.00027660060017353175,
        "gradient_norm": 0.3739255368709564,
        "train_loss": 3.1245694160461426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17398,
        "tokens": 9121562624,
        "learning_rate": 0.0002765725205305311,
        "gradient_norm": 0.370313823223114,
        "train_loss": 3.108330726623535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17399,
        "tokens": 9122086912,
        "learning_rate": 0.00027654444148892337,
        "gradient_norm": 0.3256852626800537,
        "train_loss": 3.010892868041992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17400,
        "tokens": 9122611200,
        "learning_rate": 0.00027651636304902447,
        "gradient_norm": 0.3419048488140106,
        "train_loss": 3.139739513397217,
        "val_loss": 3.0499701499938965,
        "hellaswag_acc": 0.2808205485343933,
        "hellaswag_acc_norm": 0.2936666011810303
    },
    {
        "step": 17401,
        "tokens": 9123135488,
        "learning_rate": 0.00027648828521115057,
        "gradient_norm": 0.2918992042541504,
        "train_loss": 3.0687718391418457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17402,
        "tokens": 9123659776,
        "learning_rate": 0.0002764602079756179,
        "gradient_norm": 0.3666897416114807,
        "train_loss": 3.0477797985076904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17403,
        "tokens": 9124184064,
        "learning_rate": 0.0002764321313427422,
        "gradient_norm": 0.307674765586853,
        "train_loss": 3.0623245239257812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17404,
        "tokens": 9124708352,
        "learning_rate": 0.0002764040553128397,
        "gradient_norm": 0.37867072224617004,
        "train_loss": 3.072018623352051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17405,
        "tokens": 9125232640,
        "learning_rate": 0.0002763759798862263,
        "gradient_norm": 0.3555293679237366,
        "train_loss": 3.0684423446655273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17406,
        "tokens": 9125756928,
        "learning_rate": 0.0002763479050632182,
        "gradient_norm": 0.3269670009613037,
        "train_loss": 3.0938751697540283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17407,
        "tokens": 9126281216,
        "learning_rate": 0.00027631983084413115,
        "gradient_norm": 0.3064958453178406,
        "train_loss": 3.080798625946045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17408,
        "tokens": 9126805504,
        "learning_rate": 0.00027629175722928146,
        "gradient_norm": 0.3178832232952118,
        "train_loss": 3.015030860900879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17409,
        "tokens": 9127329792,
        "learning_rate": 0.00027626368421898486,
        "gradient_norm": 0.2871592938899994,
        "train_loss": 3.0307180881500244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17410,
        "tokens": 9127854080,
        "learning_rate": 0.0002762356118135576,
        "gradient_norm": 0.3269289433956146,
        "train_loss": 3.0681612491607666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17411,
        "tokens": 9128378368,
        "learning_rate": 0.0002762075400133155,
        "gradient_norm": 0.31063246726989746,
        "train_loss": 3.1007485389709473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17412,
        "tokens": 9128902656,
        "learning_rate": 0.00027617946881857455,
        "gradient_norm": 0.33277782797813416,
        "train_loss": 3.106260299682617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17413,
        "tokens": 9129426944,
        "learning_rate": 0.00027615139822965084,
        "gradient_norm": 0.3161453604698181,
        "train_loss": 3.0828514099121094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17414,
        "tokens": 9129951232,
        "learning_rate": 0.0002761233282468602,
        "gradient_norm": 0.3310461640357971,
        "train_loss": 3.030266761779785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17415,
        "tokens": 9130475520,
        "learning_rate": 0.00027609525887051874,
        "gradient_norm": 0.31181272864341736,
        "train_loss": 3.0926671028137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17416,
        "tokens": 9130999808,
        "learning_rate": 0.0002760671901009422,
        "gradient_norm": 0.36571022868156433,
        "train_loss": 3.1065807342529297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17417,
        "tokens": 9131524096,
        "learning_rate": 0.0002760391219384468,
        "gradient_norm": 0.3251595199108124,
        "train_loss": 3.1698615550994873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17418,
        "tokens": 9132048384,
        "learning_rate": 0.00027601105438334825,
        "gradient_norm": 0.42326855659484863,
        "train_loss": 3.1018967628479004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17419,
        "tokens": 9132572672,
        "learning_rate": 0.0002759829874359627,
        "gradient_norm": 0.33552810549736023,
        "train_loss": 3.0821988582611084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17420,
        "tokens": 9133096960,
        "learning_rate": 0.00027595492109660586,
        "gradient_norm": 0.3653973340988159,
        "train_loss": 3.052175998687744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17421,
        "tokens": 9133621248,
        "learning_rate": 0.0002759268553655937,
        "gradient_norm": 0.326077938079834,
        "train_loss": 3.1184566020965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17422,
        "tokens": 9134145536,
        "learning_rate": 0.0002758987902432424,
        "gradient_norm": 0.3508872985839844,
        "train_loss": 3.0970969200134277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17423,
        "tokens": 9134669824,
        "learning_rate": 0.0002758707257298674,
        "gradient_norm": 0.3334532082080841,
        "train_loss": 3.078192710876465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17424,
        "tokens": 9135194112,
        "learning_rate": 0.0002758426618257851,
        "gradient_norm": 0.33901843428611755,
        "train_loss": 3.117434501647949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17425,
        "tokens": 9135718400,
        "learning_rate": 0.000275814598531311,
        "gradient_norm": 0.34334760904312134,
        "train_loss": 3.0349931716918945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17426,
        "tokens": 9136242688,
        "learning_rate": 0.00027578653584676115,
        "gradient_norm": 0.3173961043357849,
        "train_loss": 3.073301076889038,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17427,
        "tokens": 9136766976,
        "learning_rate": 0.0002757584737724514,
        "gradient_norm": 0.34609732031822205,
        "train_loss": 3.1266891956329346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17428,
        "tokens": 9137291264,
        "learning_rate": 0.0002757304123086978,
        "gradient_norm": 0.32877641916275024,
        "train_loss": 3.107947587966919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17429,
        "tokens": 9137815552,
        "learning_rate": 0.00027570235145581585,
        "gradient_norm": 0.39596816897392273,
        "train_loss": 3.0455617904663086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17430,
        "tokens": 9138339840,
        "learning_rate": 0.0002756742912141218,
        "gradient_norm": 0.38188084959983826,
        "train_loss": 3.1158716678619385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17431,
        "tokens": 9138864128,
        "learning_rate": 0.0002756462315839311,
        "gradient_norm": 0.34935808181762695,
        "train_loss": 3.122072696685791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17432,
        "tokens": 9139388416,
        "learning_rate": 0.00027561817256556,
        "gradient_norm": 0.3680708408355713,
        "train_loss": 3.271758794784546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17433,
        "tokens": 9139912704,
        "learning_rate": 0.00027559011415932407,
        "gradient_norm": 0.3929155170917511,
        "train_loss": 3.1372926235198975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17434,
        "tokens": 9140436992,
        "learning_rate": 0.0002755620563655393,
        "gradient_norm": 0.3334084451198578,
        "train_loss": 3.0569374561309814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17435,
        "tokens": 9140961280,
        "learning_rate": 0.00027553399918452137,
        "gradient_norm": 0.3538331389427185,
        "train_loss": 2.991781234741211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17436,
        "tokens": 9141485568,
        "learning_rate": 0.00027550594261658624,
        "gradient_norm": 0.3559303283691406,
        "train_loss": 3.0326411724090576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17437,
        "tokens": 9142009856,
        "learning_rate": 0.0002754778866620496,
        "gradient_norm": 0.34342631697654724,
        "train_loss": 3.0287528038024902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17438,
        "tokens": 9142534144,
        "learning_rate": 0.00027544983132122734,
        "gradient_norm": 0.3608504831790924,
        "train_loss": 3.032914161682129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17439,
        "tokens": 9143058432,
        "learning_rate": 0.0002754217765944352,
        "gradient_norm": 0.31794285774230957,
        "train_loss": 3.125194549560547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17440,
        "tokens": 9143582720,
        "learning_rate": 0.00027539372248198903,
        "gradient_norm": 0.39200007915496826,
        "train_loss": 3.0843498706817627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17441,
        "tokens": 9144107008,
        "learning_rate": 0.0002753656689842045,
        "gradient_norm": 0.3198357820510864,
        "train_loss": 3.120840072631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17442,
        "tokens": 9144631296,
        "learning_rate": 0.0002753376161013976,
        "gradient_norm": 0.34714728593826294,
        "train_loss": 3.119112491607666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17443,
        "tokens": 9145155584,
        "learning_rate": 0.0002753095638338839,
        "gradient_norm": 0.31307345628738403,
        "train_loss": 3.1123054027557373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17444,
        "tokens": 9145679872,
        "learning_rate": 0.0002752815121819793,
        "gradient_norm": 0.31222793459892273,
        "train_loss": 3.1344594955444336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17445,
        "tokens": 9146204160,
        "learning_rate": 0.00027525346114599936,
        "gradient_norm": 0.3177550733089447,
        "train_loss": 3.0697145462036133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17446,
        "tokens": 9146728448,
        "learning_rate": 0.00027522541072626006,
        "gradient_norm": 0.29280081391334534,
        "train_loss": 3.083462715148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17447,
        "tokens": 9147252736,
        "learning_rate": 0.00027519736092307694,
        "gradient_norm": 0.28726428747177124,
        "train_loss": 3.075265645980835,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17448,
        "tokens": 9147777024,
        "learning_rate": 0.000275169311736766,
        "gradient_norm": 0.32874009013175964,
        "train_loss": 3.07682466506958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17449,
        "tokens": 9148301312,
        "learning_rate": 0.00027514126316764264,
        "gradient_norm": 0.32334548234939575,
        "train_loss": 3.0720648765563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17450,
        "tokens": 9148825600,
        "learning_rate": 0.00027511321521602285,
        "gradient_norm": 0.30639591813087463,
        "train_loss": 3.0651440620422363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17451,
        "tokens": 9149349888,
        "learning_rate": 0.0002750851678822221,
        "gradient_norm": 0.3297412693500519,
        "train_loss": 3.09171199798584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17452,
        "tokens": 9149874176,
        "learning_rate": 0.00027505712116655633,
        "gradient_norm": 0.29781338572502136,
        "train_loss": 3.0871989727020264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17453,
        "tokens": 9150398464,
        "learning_rate": 0.00027502907506934125,
        "gradient_norm": 0.3315318524837494,
        "train_loss": 3.127161979675293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17454,
        "tokens": 9150922752,
        "learning_rate": 0.0002750010295908923,
        "gradient_norm": 0.29803481698036194,
        "train_loss": 3.0340280532836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17455,
        "tokens": 9151447040,
        "learning_rate": 0.00027497298473152544,
        "gradient_norm": 0.31219446659088135,
        "train_loss": 3.0818347930908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17456,
        "tokens": 9151971328,
        "learning_rate": 0.0002749449404915561,
        "gradient_norm": 0.33954328298568726,
        "train_loss": 3.1189565658569336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17457,
        "tokens": 9152495616,
        "learning_rate": 0.00027491689687130026,
        "gradient_norm": 0.30945634841918945,
        "train_loss": 3.073303461074829,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17458,
        "tokens": 9153019904,
        "learning_rate": 0.00027488885387107323,
        "gradient_norm": 0.3126148581504822,
        "train_loss": 3.0775508880615234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17459,
        "tokens": 9153544192,
        "learning_rate": 0.000274860811491191,
        "gradient_norm": 0.3279929459095001,
        "train_loss": 3.111006021499634,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17460,
        "tokens": 9154068480,
        "learning_rate": 0.00027483276973196895,
        "gradient_norm": 0.3186212182044983,
        "train_loss": 3.065711498260498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17461,
        "tokens": 9154592768,
        "learning_rate": 0.0002748047285937228,
        "gradient_norm": 0.35385268926620483,
        "train_loss": 3.036625862121582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17462,
        "tokens": 9155117056,
        "learning_rate": 0.00027477668807676843,
        "gradient_norm": 0.396518737077713,
        "train_loss": 3.0981106758117676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17463,
        "tokens": 9155641344,
        "learning_rate": 0.0002747486481814211,
        "gradient_norm": 0.3283722698688507,
        "train_loss": 3.0441536903381348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17464,
        "tokens": 9156165632,
        "learning_rate": 0.0002747206089079967,
        "gradient_norm": 0.3996351659297943,
        "train_loss": 3.0770788192749023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17465,
        "tokens": 9156689920,
        "learning_rate": 0.0002746925702568107,
        "gradient_norm": 0.33560287952423096,
        "train_loss": 3.161442279815674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17466,
        "tokens": 9157214208,
        "learning_rate": 0.00027466453222817883,
        "gradient_norm": 0.3336930274963379,
        "train_loss": 3.09494686126709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17467,
        "tokens": 9157738496,
        "learning_rate": 0.0002746364948224165,
        "gradient_norm": 0.32064875960350037,
        "train_loss": 3.1073527336120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17468,
        "tokens": 9158262784,
        "learning_rate": 0.0002746084580398396,
        "gradient_norm": 0.3457365930080414,
        "train_loss": 3.0959365367889404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17469,
        "tokens": 9158787072,
        "learning_rate": 0.00027458042188076336,
        "gradient_norm": 0.32637766003608704,
        "train_loss": 3.0710620880126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17470,
        "tokens": 9159311360,
        "learning_rate": 0.0002745523863455038,
        "gradient_norm": 0.31625184416770935,
        "train_loss": 3.12976336479187,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17471,
        "tokens": 9159835648,
        "learning_rate": 0.000274524351434376,
        "gradient_norm": 0.3276086747646332,
        "train_loss": 3.064187526702881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17472,
        "tokens": 9160359936,
        "learning_rate": 0.00027449631714769585,
        "gradient_norm": 0.29631373286247253,
        "train_loss": 3.090503692626953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17473,
        "tokens": 9160884224,
        "learning_rate": 0.00027446828348577895,
        "gradient_norm": 0.32598990201950073,
        "train_loss": 3.090364456176758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17474,
        "tokens": 9161408512,
        "learning_rate": 0.0002744402504489406,
        "gradient_norm": 0.30536603927612305,
        "train_loss": 3.087796449661255,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17475,
        "tokens": 9161932800,
        "learning_rate": 0.0002744122180374966,
        "gradient_norm": 0.40283116698265076,
        "train_loss": 3.1168270111083984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17476,
        "tokens": 9162457088,
        "learning_rate": 0.00027438418625176235,
        "gradient_norm": 0.44946879148483276,
        "train_loss": 3.088998794555664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17477,
        "tokens": 9162981376,
        "learning_rate": 0.00027435615509205347,
        "gradient_norm": 0.31958645582199097,
        "train_loss": 3.0152878761291504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17478,
        "tokens": 9163505664,
        "learning_rate": 0.00027432812455868526,
        "gradient_norm": 0.5100035071372986,
        "train_loss": 3.0748515129089355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17479,
        "tokens": 9164029952,
        "learning_rate": 0.00027430009465197354,
        "gradient_norm": 0.32638657093048096,
        "train_loss": 3.0999863147735596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17480,
        "tokens": 9164554240,
        "learning_rate": 0.00027427206537223366,
        "gradient_norm": 0.4642833173274994,
        "train_loss": 3.0849199295043945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17481,
        "tokens": 9165078528,
        "learning_rate": 0.00027424403671978106,
        "gradient_norm": 0.3740190267562866,
        "train_loss": 3.053161144256592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17482,
        "tokens": 9165602816,
        "learning_rate": 0.00027421600869493147,
        "gradient_norm": 0.3720830976963043,
        "train_loss": 3.0457236766815186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17483,
        "tokens": 9166127104,
        "learning_rate": 0.00027418798129800017,
        "gradient_norm": 0.34740620851516724,
        "train_loss": 3.056607484817505,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17484,
        "tokens": 9166651392,
        "learning_rate": 0.0002741599545293027,
        "gradient_norm": 0.34837889671325684,
        "train_loss": 3.118169069290161,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17485,
        "tokens": 9167175680,
        "learning_rate": 0.00027413192838915456,
        "gradient_norm": 0.36721327900886536,
        "train_loss": 3.0441551208496094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17486,
        "tokens": 9167699968,
        "learning_rate": 0.0002741039028778712,
        "gradient_norm": 0.3195469379425049,
        "train_loss": 3.091275215148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17487,
        "tokens": 9168224256,
        "learning_rate": 0.00027407587799576814,
        "gradient_norm": 0.3680901825428009,
        "train_loss": 3.0761094093322754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17488,
        "tokens": 9168748544,
        "learning_rate": 0.0002740478537431607,
        "gradient_norm": 0.337268203496933,
        "train_loss": 3.099517583847046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17489,
        "tokens": 9169272832,
        "learning_rate": 0.0002740198301203645,
        "gradient_norm": 0.34027615189552307,
        "train_loss": 3.104261875152588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17490,
        "tokens": 9169797120,
        "learning_rate": 0.0002739918071276948,
        "gradient_norm": 0.3302149772644043,
        "train_loss": 3.041839599609375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17491,
        "tokens": 9170321408,
        "learning_rate": 0.0002739637847654672,
        "gradient_norm": 0.3177059590816498,
        "train_loss": 3.080749988555908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17492,
        "tokens": 9170845696,
        "learning_rate": 0.000273935763033997,
        "gradient_norm": 0.3402157127857208,
        "train_loss": 3.0692968368530273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17493,
        "tokens": 9171369984,
        "learning_rate": 0.0002739077419335997,
        "gradient_norm": 0.3056985139846802,
        "train_loss": 3.0756759643554688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17494,
        "tokens": 9171894272,
        "learning_rate": 0.00027387972146459064,
        "gradient_norm": 0.3482201397418976,
        "train_loss": 3.123683452606201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17495,
        "tokens": 9172418560,
        "learning_rate": 0.00027385170162728544,
        "gradient_norm": 0.43672528862953186,
        "train_loss": 3.051028251647949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17496,
        "tokens": 9172942848,
        "learning_rate": 0.0002738236824219991,
        "gradient_norm": 0.30851468443870544,
        "train_loss": 3.0992965698242188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17497,
        "tokens": 9173467136,
        "learning_rate": 0.0002737956638490475,
        "gradient_norm": 0.3455126881599426,
        "train_loss": 3.0469164848327637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17498,
        "tokens": 9173991424,
        "learning_rate": 0.0002737676459087455,
        "gradient_norm": 0.31897443532943726,
        "train_loss": 3.052846670150757,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17499,
        "tokens": 9174515712,
        "learning_rate": 0.00027373962860140883,
        "gradient_norm": 0.3199019134044647,
        "train_loss": 3.107206344604492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17500,
        "tokens": 9175040000,
        "learning_rate": 0.0002737116119273528,
        "gradient_norm": 0.3186012804508209,
        "train_loss": 3.092369318008423,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17501,
        "tokens": 9175564288,
        "learning_rate": 0.0002736835958868927,
        "gradient_norm": 0.3042379319667816,
        "train_loss": 3.0747833251953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17502,
        "tokens": 9176088576,
        "learning_rate": 0.00027365558048034406,
        "gradient_norm": 0.33084771037101746,
        "train_loss": 3.122107982635498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17503,
        "tokens": 9176612864,
        "learning_rate": 0.0002736275657080219,
        "gradient_norm": 0.2918591797351837,
        "train_loss": 3.1076197624206543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17504,
        "tokens": 9177137152,
        "learning_rate": 0.0002735995515702419,
        "gradient_norm": 0.35855114459991455,
        "train_loss": 3.082442283630371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17505,
        "tokens": 9177661440,
        "learning_rate": 0.00027357153806731923,
        "gradient_norm": 0.3406654894351959,
        "train_loss": 3.058767318725586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17506,
        "tokens": 9178185728,
        "learning_rate": 0.0002735435251995692,
        "gradient_norm": 0.3165527582168579,
        "train_loss": 3.0944011211395264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17507,
        "tokens": 9178710016,
        "learning_rate": 0.0002735155129673072,
        "gradient_norm": 0.33470556139945984,
        "train_loss": 3.0676112174987793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17508,
        "tokens": 9179234304,
        "learning_rate": 0.0002734875013708486,
        "gradient_norm": 0.3500189483165741,
        "train_loss": 3.155055046081543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17509,
        "tokens": 9179758592,
        "learning_rate": 0.0002734594904105084,
        "gradient_norm": 0.3511422276496887,
        "train_loss": 3.0780599117279053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17510,
        "tokens": 9180282880,
        "learning_rate": 0.0002734314800866023,
        "gradient_norm": 0.33374595642089844,
        "train_loss": 3.081453800201416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17511,
        "tokens": 9180807168,
        "learning_rate": 0.0002734034703994453,
        "gradient_norm": 0.3363635838031769,
        "train_loss": 3.0946924686431885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17512,
        "tokens": 9181331456,
        "learning_rate": 0.0002733754613493528,
        "gradient_norm": 0.3423900306224823,
        "train_loss": 3.0811047554016113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17513,
        "tokens": 9181855744,
        "learning_rate": 0.0002733474529366401,
        "gradient_norm": 0.33601808547973633,
        "train_loss": 3.0859298706054688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17514,
        "tokens": 9182380032,
        "learning_rate": 0.00027331944516162236,
        "gradient_norm": 0.3535044193267822,
        "train_loss": 3.0968499183654785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17515,
        "tokens": 9182904320,
        "learning_rate": 0.0002732914380246151,
        "gradient_norm": 0.31663817167282104,
        "train_loss": 3.0835518836975098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17516,
        "tokens": 9183428608,
        "learning_rate": 0.0002732634315259332,
        "gradient_norm": 0.38278433680534363,
        "train_loss": 3.1079368591308594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17517,
        "tokens": 9183952896,
        "learning_rate": 0.0002732354256658922,
        "gradient_norm": 0.3959502577781677,
        "train_loss": 3.094722270965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17518,
        "tokens": 9184477184,
        "learning_rate": 0.00027320742044480725,
        "gradient_norm": 0.3342353105545044,
        "train_loss": 3.0903918743133545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17519,
        "tokens": 9185001472,
        "learning_rate": 0.0002731794158629936,
        "gradient_norm": 0.35004737973213196,
        "train_loss": 3.120086193084717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17520,
        "tokens": 9185525760,
        "learning_rate": 0.00027315141192076634,
        "gradient_norm": 0.34779593348503113,
        "train_loss": 3.1112279891967773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17521,
        "tokens": 9186050048,
        "learning_rate": 0.00027312340861844085,
        "gradient_norm": 0.3577553629875183,
        "train_loss": 3.0686583518981934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17522,
        "tokens": 9186574336,
        "learning_rate": 0.00027309540595633235,
        "gradient_norm": 0.3250472843647003,
        "train_loss": 3.0836331844329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17523,
        "tokens": 9187098624,
        "learning_rate": 0.00027306740393475586,
        "gradient_norm": 0.331536203622818,
        "train_loss": 3.1219334602355957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17524,
        "tokens": 9187622912,
        "learning_rate": 0.0002730394025540269,
        "gradient_norm": 0.33852618932724,
        "train_loss": 3.079230785369873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17525,
        "tokens": 9188147200,
        "learning_rate": 0.00027301140181446037,
        "gradient_norm": 0.3410322368144989,
        "train_loss": 3.072890520095825,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17526,
        "tokens": 9188671488,
        "learning_rate": 0.00027298340171637156,
        "gradient_norm": 0.33149853348731995,
        "train_loss": 3.1065893173217773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17527,
        "tokens": 9189195776,
        "learning_rate": 0.0002729554022600756,
        "gradient_norm": 0.4624788761138916,
        "train_loss": 3.0620274543762207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17528,
        "tokens": 9189720064,
        "learning_rate": 0.00027292740344588777,
        "gradient_norm": 0.3548886775970459,
        "train_loss": 3.048433780670166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17529,
        "tokens": 9190244352,
        "learning_rate": 0.000272899405274123,
        "gradient_norm": 0.3342781364917755,
        "train_loss": 3.081343650817871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17530,
        "tokens": 9190768640,
        "learning_rate": 0.00027287140774509685,
        "gradient_norm": 0.3160926401615143,
        "train_loss": 3.04046368598938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17531,
        "tokens": 9191292928,
        "learning_rate": 0.000272843410859124,
        "gradient_norm": 0.3507837951183319,
        "train_loss": 3.1177566051483154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17532,
        "tokens": 9191817216,
        "learning_rate": 0.0002728154146165198,
        "gradient_norm": 0.3231607675552368,
        "train_loss": 3.0829033851623535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17533,
        "tokens": 9192341504,
        "learning_rate": 0.0002727874190175996,
        "gradient_norm": 0.3591001033782959,
        "train_loss": 3.127800464630127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17534,
        "tokens": 9192865792,
        "learning_rate": 0.0002727594240626781,
        "gradient_norm": 0.367220401763916,
        "train_loss": 3.070676803588867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17535,
        "tokens": 9193390080,
        "learning_rate": 0.00027273142975207086,
        "gradient_norm": 0.32209452986717224,
        "train_loss": 3.098276138305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17536,
        "tokens": 9193914368,
        "learning_rate": 0.00027270343608609254,
        "gradient_norm": 0.3464600741863251,
        "train_loss": 3.0834429264068604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17537,
        "tokens": 9194438656,
        "learning_rate": 0.0002726754430650586,
        "gradient_norm": 0.33496686816215515,
        "train_loss": 3.066192150115967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17538,
        "tokens": 9194962944,
        "learning_rate": 0.00027264745068928395,
        "gradient_norm": 0.3563856780529022,
        "train_loss": 3.056643009185791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17539,
        "tokens": 9195487232,
        "learning_rate": 0.00027261945895908383,
        "gradient_norm": 0.3170090913772583,
        "train_loss": 3.1074705123901367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17540,
        "tokens": 9196011520,
        "learning_rate": 0.0002725914678747731,
        "gradient_norm": 0.34463033080101013,
        "train_loss": 3.053159713745117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17541,
        "tokens": 9196535808,
        "learning_rate": 0.000272563477436667,
        "gradient_norm": 0.3640986382961273,
        "train_loss": 3.090717077255249,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17542,
        "tokens": 9197060096,
        "learning_rate": 0.00027253548764508053,
        "gradient_norm": 0.2911781668663025,
        "train_loss": 3.12384033203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17543,
        "tokens": 9197584384,
        "learning_rate": 0.00027250749850032886,
        "gradient_norm": 0.3163580000400543,
        "train_loss": 3.114307403564453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17544,
        "tokens": 9198108672,
        "learning_rate": 0.0002724795100027269,
        "gradient_norm": 0.3059927523136139,
        "train_loss": 3.0573489665985107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17545,
        "tokens": 9198632960,
        "learning_rate": 0.00027245152215258977,
        "gradient_norm": 0.3374404013156891,
        "train_loss": 3.065192222595215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17546,
        "tokens": 9199157248,
        "learning_rate": 0.0002724235349502325,
        "gradient_norm": 0.27945083379745483,
        "train_loss": 3.0697803497314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17547,
        "tokens": 9199681536,
        "learning_rate": 0.00027239554839597017,
        "gradient_norm": 0.34813278913497925,
        "train_loss": 2.9903764724731445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17548,
        "tokens": 9200205824,
        "learning_rate": 0.00027236756249011766,
        "gradient_norm": 0.3100566864013672,
        "train_loss": 3.0925779342651367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17549,
        "tokens": 9200730112,
        "learning_rate": 0.0002723395772329901,
        "gradient_norm": 0.32971322536468506,
        "train_loss": 3.074889898300171,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17550,
        "tokens": 9201254400,
        "learning_rate": 0.0002723115926249025,
        "gradient_norm": 0.345397025346756,
        "train_loss": 3.1254189014434814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17551,
        "tokens": 9201778688,
        "learning_rate": 0.0002722836086661698,
        "gradient_norm": 0.2823886275291443,
        "train_loss": 3.074586868286133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17552,
        "tokens": 9202302976,
        "learning_rate": 0.00027225562535710703,
        "gradient_norm": 0.3004721999168396,
        "train_loss": 3.0760605335235596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17553,
        "tokens": 9202827264,
        "learning_rate": 0.00027222764269802923,
        "gradient_norm": 0.3566998839378357,
        "train_loss": 3.16203236579895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17554,
        "tokens": 9203351552,
        "learning_rate": 0.00027219966068925123,
        "gradient_norm": 0.3205973505973816,
        "train_loss": 3.118150234222412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17555,
        "tokens": 9203875840,
        "learning_rate": 0.0002721716793310882,
        "gradient_norm": 0.3406257629394531,
        "train_loss": 3.096951961517334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17556,
        "tokens": 9204400128,
        "learning_rate": 0.0002721436986238549,
        "gradient_norm": 0.3602932393550873,
        "train_loss": 3.045877695083618,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17557,
        "tokens": 9204924416,
        "learning_rate": 0.0002721157185678665,
        "gradient_norm": 0.36523544788360596,
        "train_loss": 3.079387664794922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17558,
        "tokens": 9205448704,
        "learning_rate": 0.00027208773916343777,
        "gradient_norm": 0.5863111615180969,
        "train_loss": 3.2959017753601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17559,
        "tokens": 9205972992,
        "learning_rate": 0.00027205976041088384,
        "gradient_norm": 0.5076643824577332,
        "train_loss": 3.0909016132354736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17560,
        "tokens": 9206497280,
        "learning_rate": 0.00027203178231051937,
        "gradient_norm": 0.39863675832748413,
        "train_loss": 3.120941162109375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17561,
        "tokens": 9207021568,
        "learning_rate": 0.0002720038048626595,
        "gradient_norm": 0.4855119287967682,
        "train_loss": 3.141353130340576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17562,
        "tokens": 9207545856,
        "learning_rate": 0.0002719758280676192,
        "gradient_norm": 0.36961716413497925,
        "train_loss": 3.0984129905700684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17563,
        "tokens": 9208070144,
        "learning_rate": 0.00027194785192571306,
        "gradient_norm": 0.43705058097839355,
        "train_loss": 3.0965709686279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17564,
        "tokens": 9208594432,
        "learning_rate": 0.00027191987643725645,
        "gradient_norm": 0.3519558012485504,
        "train_loss": 3.0903358459472656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17565,
        "tokens": 9209118720,
        "learning_rate": 0.0002718919016025639,
        "gradient_norm": 0.3965224623680115,
        "train_loss": 3.0875940322875977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17566,
        "tokens": 9209643008,
        "learning_rate": 0.0002718639274219505,
        "gradient_norm": 0.3660869300365448,
        "train_loss": 3.108354091644287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17567,
        "tokens": 9210167296,
        "learning_rate": 0.00027183595389573096,
        "gradient_norm": 0.3636005222797394,
        "train_loss": 3.127319097518921,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17568,
        "tokens": 9210691584,
        "learning_rate": 0.0002718079810242204,
        "gradient_norm": 0.36566397547721863,
        "train_loss": 3.0766539573669434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17569,
        "tokens": 9211215872,
        "learning_rate": 0.00027178000880773346,
        "gradient_norm": 0.36965620517730713,
        "train_loss": 3.1416563987731934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17570,
        "tokens": 9211740160,
        "learning_rate": 0.00027175203724658515,
        "gradient_norm": 0.353971928358078,
        "train_loss": 3.114987850189209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17571,
        "tokens": 9212264448,
        "learning_rate": 0.0002717240663410902,
        "gradient_norm": 0.34157097339630127,
        "train_loss": 3.0914478302001953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17572,
        "tokens": 9212788736,
        "learning_rate": 0.0002716960960915635,
        "gradient_norm": 0.3278915286064148,
        "train_loss": 3.0941123962402344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17573,
        "tokens": 9213313024,
        "learning_rate": 0.00027166812649832004,
        "gradient_norm": 0.3301357626914978,
        "train_loss": 3.0482664108276367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17574,
        "tokens": 9213837312,
        "learning_rate": 0.0002716401575616744,
        "gradient_norm": 0.3174961805343628,
        "train_loss": 3.0708303451538086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17575,
        "tokens": 9214361600,
        "learning_rate": 0.0002716121892819417,
        "gradient_norm": 0.33506518602371216,
        "train_loss": 3.095331907272339,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17576,
        "tokens": 9214885888,
        "learning_rate": 0.0002715842216594364,
        "gradient_norm": 0.3219912052154541,
        "train_loss": 3.129413604736328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17577,
        "tokens": 9215410176,
        "learning_rate": 0.0002715562546944737,
        "gradient_norm": 0.3307129442691803,
        "train_loss": 3.103881359100342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17578,
        "tokens": 9215934464,
        "learning_rate": 0.00027152828838736807,
        "gradient_norm": 0.33538341522216797,
        "train_loss": 3.0707175731658936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17579,
        "tokens": 9216458752,
        "learning_rate": 0.00027150032273843454,
        "gradient_norm": 0.34657639265060425,
        "train_loss": 3.126628875732422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17580,
        "tokens": 9216983040,
        "learning_rate": 0.0002714723577479877,
        "gradient_norm": 0.35136649012565613,
        "train_loss": 3.0455474853515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17581,
        "tokens": 9217507328,
        "learning_rate": 0.0002714443934163424,
        "gradient_norm": 0.3238176107406616,
        "train_loss": 3.099984884262085,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17582,
        "tokens": 9218031616,
        "learning_rate": 0.0002714164297438136,
        "gradient_norm": 0.3542105257511139,
        "train_loss": 3.0835702419281006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17583,
        "tokens": 9218555904,
        "learning_rate": 0.0002713884667307157,
        "gradient_norm": 0.3394491970539093,
        "train_loss": 3.0448622703552246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17584,
        "tokens": 9219080192,
        "learning_rate": 0.0002713605043773639,
        "gradient_norm": 0.32555556297302246,
        "train_loss": 3.100442886352539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17585,
        "tokens": 9219604480,
        "learning_rate": 0.0002713325426840725,
        "gradient_norm": 0.32615986466407776,
        "train_loss": 3.1149349212646484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17586,
        "tokens": 9220128768,
        "learning_rate": 0.00027130458165115665,
        "gradient_norm": 0.31675824522972107,
        "train_loss": 3.0790810585021973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17587,
        "tokens": 9220653056,
        "learning_rate": 0.00027127662127893074,
        "gradient_norm": 0.32580211758613586,
        "train_loss": 3.0808990001678467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17588,
        "tokens": 9221177344,
        "learning_rate": 0.0002712486615677098,
        "gradient_norm": 0.31348907947540283,
        "train_loss": 3.054684638977051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17589,
        "tokens": 9221701632,
        "learning_rate": 0.0002712207025178083,
        "gradient_norm": 0.3184341490268707,
        "train_loss": 3.112287998199463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17590,
        "tokens": 9222225920,
        "learning_rate": 0.00027119274412954115,
        "gradient_norm": 0.34722116589546204,
        "train_loss": 3.082453727722168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17591,
        "tokens": 9222750208,
        "learning_rate": 0.0002711647864032229,
        "gradient_norm": 0.29636919498443604,
        "train_loss": 3.050701141357422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17592,
        "tokens": 9223274496,
        "learning_rate": 0.00027113682933916836,
        "gradient_norm": 0.32872727513313293,
        "train_loss": 3.1058993339538574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17593,
        "tokens": 9223798784,
        "learning_rate": 0.0002711088729376921,
        "gradient_norm": 0.2910071909427643,
        "train_loss": 3.108020305633545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17594,
        "tokens": 9224323072,
        "learning_rate": 0.000271080917199109,
        "gradient_norm": 0.31230247020721436,
        "train_loss": 3.068922519683838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17595,
        "tokens": 9224847360,
        "learning_rate": 0.0002710529621237336,
        "gradient_norm": 0.28409481048583984,
        "train_loss": 3.020551919937134,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17596,
        "tokens": 9225371648,
        "learning_rate": 0.00027102500771188055,
        "gradient_norm": 0.3097632825374603,
        "train_loss": 3.082977771759033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17597,
        "tokens": 9225895936,
        "learning_rate": 0.00027099705396386455,
        "gradient_norm": 0.3343590199947357,
        "train_loss": 3.0681710243225098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17598,
        "tokens": 9226420224,
        "learning_rate": 0.00027096910088000034,
        "gradient_norm": 0.3053850829601288,
        "train_loss": 3.0144217014312744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17599,
        "tokens": 9226944512,
        "learning_rate": 0.0002709411484606024,
        "gradient_norm": 0.309834361076355,
        "train_loss": 3.045938014984131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17600,
        "tokens": 9227468800,
        "learning_rate": 0.0002709131967059855,
        "gradient_norm": 0.3323117792606354,
        "train_loss": 3.0639729499816895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17601,
        "tokens": 9227993088,
        "learning_rate": 0.00027088524561646413,
        "gradient_norm": 0.3116166293621063,
        "train_loss": 3.0733790397644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17602,
        "tokens": 9228517376,
        "learning_rate": 0.0002708572951923531,
        "gradient_norm": 0.30273476243019104,
        "train_loss": 3.067157745361328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17603,
        "tokens": 9229041664,
        "learning_rate": 0.0002708293454339669,
        "gradient_norm": 0.32290101051330566,
        "train_loss": 3.060624361038208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17604,
        "tokens": 9229565952,
        "learning_rate": 0.0002708013963416202,
        "gradient_norm": 0.3050599992275238,
        "train_loss": 3.043774127960205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17605,
        "tokens": 9230090240,
        "learning_rate": 0.0002707734479156275,
        "gradient_norm": 0.2997272312641144,
        "train_loss": 3.038053274154663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17606,
        "tokens": 9230614528,
        "learning_rate": 0.0002707455001563036,
        "gradient_norm": 0.3198436200618744,
        "train_loss": 3.146099328994751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17607,
        "tokens": 9231138816,
        "learning_rate": 0.00027071755306396286,
        "gradient_norm": 0.3380366861820221,
        "train_loss": 3.1322121620178223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17608,
        "tokens": 9231663104,
        "learning_rate": 0.00027068960663892004,
        "gradient_norm": 0.39040571451187134,
        "train_loss": 3.0773308277130127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17609,
        "tokens": 9232187392,
        "learning_rate": 0.00027066166088148956,
        "gradient_norm": 0.3094419240951538,
        "train_loss": 3.0600624084472656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17610,
        "tokens": 9232711680,
        "learning_rate": 0.000270633715791986,
        "gradient_norm": 0.35400286316871643,
        "train_loss": 3.1360340118408203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17611,
        "tokens": 9233235968,
        "learning_rate": 0.0002706057713707241,
        "gradient_norm": 0.4138754904270172,
        "train_loss": 3.078122615814209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17612,
        "tokens": 9233760256,
        "learning_rate": 0.0002705778276180182,
        "gradient_norm": 0.38601040840148926,
        "train_loss": 3.047724485397339,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17613,
        "tokens": 9234284544,
        "learning_rate": 0.000270549884534183,
        "gradient_norm": 0.3411259055137634,
        "train_loss": 3.0700931549072266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17614,
        "tokens": 9234808832,
        "learning_rate": 0.00027052194211953285,
        "gradient_norm": 0.3880986273288727,
        "train_loss": 3.1253721714019775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17615,
        "tokens": 9235333120,
        "learning_rate": 0.0002704940003743825,
        "gradient_norm": 0.3275741934776306,
        "train_loss": 3.0991382598876953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17616,
        "tokens": 9235857408,
        "learning_rate": 0.0002704660592990462,
        "gradient_norm": 0.43044063448905945,
        "train_loss": 3.0696682929992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17617,
        "tokens": 9236381696,
        "learning_rate": 0.0002704381188938388,
        "gradient_norm": 0.3889828622341156,
        "train_loss": 3.1656382083892822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17618,
        "tokens": 9236905984,
        "learning_rate": 0.00027041017915907447,
        "gradient_norm": 0.3935536742210388,
        "train_loss": 3.0871949195861816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17619,
        "tokens": 9237430272,
        "learning_rate": 0.00027038224009506796,
        "gradient_norm": 0.35683751106262207,
        "train_loss": 3.0538887977600098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17620,
        "tokens": 9237954560,
        "learning_rate": 0.00027035430170213354,
        "gradient_norm": 0.3520506024360657,
        "train_loss": 3.1045608520507812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17621,
        "tokens": 9238478848,
        "learning_rate": 0.0002703263639805858,
        "gradient_norm": 0.36727601289749146,
        "train_loss": 3.077521324157715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17622,
        "tokens": 9239003136,
        "learning_rate": 0.00027029842693073933,
        "gradient_norm": 0.34006941318511963,
        "train_loss": 3.0718703269958496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17623,
        "tokens": 9239527424,
        "learning_rate": 0.0002702704905529084,
        "gradient_norm": 0.34356406331062317,
        "train_loss": 3.036667823791504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17624,
        "tokens": 9240051712,
        "learning_rate": 0.0002702425548474077,
        "gradient_norm": 0.3355052173137665,
        "train_loss": 3.083789110183716,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17625,
        "tokens": 9240576000,
        "learning_rate": 0.0002702146198145513,
        "gradient_norm": 0.3060240149497986,
        "train_loss": 3.0895543098449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17626,
        "tokens": 9241100288,
        "learning_rate": 0.0002701866854546541,
        "gradient_norm": 0.3537999987602234,
        "train_loss": 2.9757652282714844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17627,
        "tokens": 9241624576,
        "learning_rate": 0.00027015875176803015,
        "gradient_norm": 0.33486491441726685,
        "train_loss": 3.1113717555999756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17628,
        "tokens": 9242148864,
        "learning_rate": 0.0002701308187549942,
        "gradient_norm": 0.31735002994537354,
        "train_loss": 3.0674617290496826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17629,
        "tokens": 9242673152,
        "learning_rate": 0.00027010288641586035,
        "gradient_norm": 0.7984666228294373,
        "train_loss": 3.120685577392578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17630,
        "tokens": 9243197440,
        "learning_rate": 0.00027007495475094316,
        "gradient_norm": 0.36625418066978455,
        "train_loss": 3.0711097717285156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17631,
        "tokens": 9243721728,
        "learning_rate": 0.0002700470237605572,
        "gradient_norm": 0.36159607768058777,
        "train_loss": 3.061249256134033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17632,
        "tokens": 9244246016,
        "learning_rate": 0.0002700190934450166,
        "gradient_norm": 0.3894832730293274,
        "train_loss": 3.0814037322998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17633,
        "tokens": 9244770304,
        "learning_rate": 0.000269991163804636,
        "gradient_norm": 0.32817766070365906,
        "train_loss": 3.109869956970215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17634,
        "tokens": 9245294592,
        "learning_rate": 0.00026996323483972955,
        "gradient_norm": 0.35005253553390503,
        "train_loss": 3.133497476577759,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17635,
        "tokens": 9245818880,
        "learning_rate": 0.00026993530655061184,
        "gradient_norm": 0.32369181513786316,
        "train_loss": 3.1111226081848145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17636,
        "tokens": 9246343168,
        "learning_rate": 0.000269907378937597,
        "gradient_norm": 0.3277883529663086,
        "train_loss": 3.068760871887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17637,
        "tokens": 9246867456,
        "learning_rate": 0.00026987945200099967,
        "gradient_norm": 0.2989622950553894,
        "train_loss": 3.087520122528076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17638,
        "tokens": 9247391744,
        "learning_rate": 0.0002698515257411339,
        "gradient_norm": 0.32473087310791016,
        "train_loss": 3.089118003845215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17639,
        "tokens": 9247916032,
        "learning_rate": 0.00026982360015831425,
        "gradient_norm": 0.28838738799095154,
        "train_loss": 3.091362476348877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17640,
        "tokens": 9248440320,
        "learning_rate": 0.0002697956752528549,
        "gradient_norm": 0.3349486291408539,
        "train_loss": 3.147371530532837,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17641,
        "tokens": 9248964608,
        "learning_rate": 0.00026976775102507033,
        "gradient_norm": 0.3021921217441559,
        "train_loss": 3.0378599166870117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17642,
        "tokens": 9249488896,
        "learning_rate": 0.0002697398274752749,
        "gradient_norm": 0.3235246241092682,
        "train_loss": 3.079721689224243,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17643,
        "tokens": 9250013184,
        "learning_rate": 0.0002697119046037828,
        "gradient_norm": 0.2979273796081543,
        "train_loss": 3.0775742530822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17644,
        "tokens": 9250537472,
        "learning_rate": 0.00026968398241090827,
        "gradient_norm": 0.3768460750579834,
        "train_loss": 3.1758031845092773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17645,
        "tokens": 9251061760,
        "learning_rate": 0.00026965606089696576,
        "gradient_norm": 0.3386240005493164,
        "train_loss": 3.10319185256958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17646,
        "tokens": 9251586048,
        "learning_rate": 0.0002696281400622695,
        "gradient_norm": 0.3780863583087921,
        "train_loss": 3.0701584815979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17647,
        "tokens": 9252110336,
        "learning_rate": 0.0002696002199071338,
        "gradient_norm": 0.35539963841438293,
        "train_loss": 3.0550589561462402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17648,
        "tokens": 9252634624,
        "learning_rate": 0.0002695723004318729,
        "gradient_norm": 0.3973742723464966,
        "train_loss": 3.0954084396362305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17649,
        "tokens": 9253158912,
        "learning_rate": 0.0002695443816368011,
        "gradient_norm": 0.32000595331192017,
        "train_loss": 3.081094264984131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17650,
        "tokens": 9253683200,
        "learning_rate": 0.00026951646352223256,
        "gradient_norm": 0.3181551396846771,
        "train_loss": 3.044160842895508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17651,
        "tokens": 9254207488,
        "learning_rate": 0.0002694885460884817,
        "gradient_norm": 0.30064502358436584,
        "train_loss": 3.0662999153137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17652,
        "tokens": 9254731776,
        "learning_rate": 0.0002694606293358626,
        "gradient_norm": 0.35509559512138367,
        "train_loss": 3.1257801055908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17653,
        "tokens": 9255256064,
        "learning_rate": 0.0002694327132646897,
        "gradient_norm": 0.3323461711406708,
        "train_loss": 3.120683193206787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17654,
        "tokens": 9255780352,
        "learning_rate": 0.000269404797875277,
        "gradient_norm": 0.35924649238586426,
        "train_loss": 3.0996856689453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17655,
        "tokens": 9256304640,
        "learning_rate": 0.00026937688316793894,
        "gradient_norm": 0.3066529929637909,
        "train_loss": 3.118675708770752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17656,
        "tokens": 9256828928,
        "learning_rate": 0.0002693489691429896,
        "gradient_norm": 0.3441862463951111,
        "train_loss": 3.083962917327881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17657,
        "tokens": 9257353216,
        "learning_rate": 0.0002693210558007432,
        "gradient_norm": 0.3011152744293213,
        "train_loss": 3.0791187286376953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17658,
        "tokens": 9257877504,
        "learning_rate": 0.00026929314314151387,
        "gradient_norm": 0.3477088510990143,
        "train_loss": 3.0640642642974854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17659,
        "tokens": 9258401792,
        "learning_rate": 0.00026926523116561603,
        "gradient_norm": 0.31776008009910583,
        "train_loss": 3.055860996246338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17660,
        "tokens": 9258926080,
        "learning_rate": 0.00026923731987336366,
        "gradient_norm": 0.34786221385002136,
        "train_loss": 3.0709211826324463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17661,
        "tokens": 9259450368,
        "learning_rate": 0.0002692094092650709,
        "gradient_norm": 0.35850536823272705,
        "train_loss": 3.081559181213379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17662,
        "tokens": 9259974656,
        "learning_rate": 0.0002691814993410522,
        "gradient_norm": 0.61575847864151,
        "train_loss": 3.1760504245758057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17663,
        "tokens": 9260498944,
        "learning_rate": 0.0002691535901016214,
        "gradient_norm": 0.37702620029449463,
        "train_loss": 3.058802366256714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17664,
        "tokens": 9261023232,
        "learning_rate": 0.00026912568154709285,
        "gradient_norm": 0.3990391194820404,
        "train_loss": 3.0820796489715576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17665,
        "tokens": 9261547520,
        "learning_rate": 0.0002690977736777806,
        "gradient_norm": 0.3671855032444,
        "train_loss": 3.0629758834838867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17666,
        "tokens": 9262071808,
        "learning_rate": 0.0002690698664939989,
        "gradient_norm": 0.39661285281181335,
        "train_loss": 3.1341500282287598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17667,
        "tokens": 9262596096,
        "learning_rate": 0.0002690419599960617,
        "gradient_norm": 0.38306039571762085,
        "train_loss": 3.077463150024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17668,
        "tokens": 9263120384,
        "learning_rate": 0.0002690140541842833,
        "gradient_norm": 0.37687644362449646,
        "train_loss": 3.103806972503662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17669,
        "tokens": 9263644672,
        "learning_rate": 0.00026898614905897765,
        "gradient_norm": 0.336196631193161,
        "train_loss": 3.0712954998016357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17670,
        "tokens": 9264168960,
        "learning_rate": 0.000268958244620459,
        "gradient_norm": 0.4037880301475525,
        "train_loss": 3.053609609603882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17671,
        "tokens": 9264693248,
        "learning_rate": 0.00026893034086904145,
        "gradient_norm": 0.3720970153808594,
        "train_loss": 3.1728782653808594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17672,
        "tokens": 9265217536,
        "learning_rate": 0.000268902437805039,
        "gradient_norm": 0.44566279649734497,
        "train_loss": 3.1269121170043945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17673,
        "tokens": 9265741824,
        "learning_rate": 0.0002688745354287658,
        "gradient_norm": 0.3849509060382843,
        "train_loss": 3.101199150085449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17674,
        "tokens": 9266266112,
        "learning_rate": 0.00026884663374053585,
        "gradient_norm": 0.40061214566230774,
        "train_loss": 3.0482852458953857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17675,
        "tokens": 9266790400,
        "learning_rate": 0.0002688187327406633,
        "gradient_norm": 0.3923492133617401,
        "train_loss": 3.067805528640747,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17676,
        "tokens": 9267314688,
        "learning_rate": 0.00026879083242946215,
        "gradient_norm": 0.4043639302253723,
        "train_loss": 3.075521945953369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17677,
        "tokens": 9267838976,
        "learning_rate": 0.00026876293280724657,
        "gradient_norm": 0.3754425048828125,
        "train_loss": 3.061208724975586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17678,
        "tokens": 9268363264,
        "learning_rate": 0.0002687350338743304,
        "gradient_norm": 0.3751881420612335,
        "train_loss": 3.0803864002227783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17679,
        "tokens": 9268887552,
        "learning_rate": 0.00026870713563102787,
        "gradient_norm": 0.32772186398506165,
        "train_loss": 3.0793001651763916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17680,
        "tokens": 9269411840,
        "learning_rate": 0.00026867923807765283,
        "gradient_norm": 0.3762754201889038,
        "train_loss": 3.0516905784606934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17681,
        "tokens": 9269936128,
        "learning_rate": 0.00026865134121451943,
        "gradient_norm": 0.3111658990383148,
        "train_loss": 3.0395169258117676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17682,
        "tokens": 9270460416,
        "learning_rate": 0.00026862344504194173,
        "gradient_norm": 0.340205579996109,
        "train_loss": 3.0757436752319336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17683,
        "tokens": 9270984704,
        "learning_rate": 0.00026859554956023364,
        "gradient_norm": 0.3779921233654022,
        "train_loss": 3.0937204360961914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17684,
        "tokens": 9271508992,
        "learning_rate": 0.0002685676547697092,
        "gradient_norm": 0.31191933155059814,
        "train_loss": 3.112334728240967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17685,
        "tokens": 9272033280,
        "learning_rate": 0.0002685397606706823,
        "gradient_norm": 0.3512398898601532,
        "train_loss": 3.073117256164551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17686,
        "tokens": 9272557568,
        "learning_rate": 0.00026851186726346713,
        "gradient_norm": 0.3416768014431,
        "train_loss": 3.0867857933044434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17687,
        "tokens": 9273081856,
        "learning_rate": 0.00026848397454837746,
        "gradient_norm": 0.35385966300964355,
        "train_loss": 3.0732438564300537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17688,
        "tokens": 9273606144,
        "learning_rate": 0.0002684560825257274,
        "gradient_norm": 0.29976433515548706,
        "train_loss": 3.0879979133605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17689,
        "tokens": 9274130432,
        "learning_rate": 0.0002684281911958308,
        "gradient_norm": 0.3316909074783325,
        "train_loss": 3.036916732788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17690,
        "tokens": 9274654720,
        "learning_rate": 0.00026840030055900164,
        "gradient_norm": 0.29547813534736633,
        "train_loss": 3.0501291751861572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17691,
        "tokens": 9275179008,
        "learning_rate": 0.0002683724106155539,
        "gradient_norm": 0.3281875252723694,
        "train_loss": 3.030801296234131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17692,
        "tokens": 9275703296,
        "learning_rate": 0.0002683445213658015,
        "gradient_norm": 0.3174183964729309,
        "train_loss": 3.0588886737823486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17693,
        "tokens": 9276227584,
        "learning_rate": 0.00026831663281005837,
        "gradient_norm": 0.3039737939834595,
        "train_loss": 3.075288772583008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17694,
        "tokens": 9276751872,
        "learning_rate": 0.0002682887449486384,
        "gradient_norm": 0.34330689907073975,
        "train_loss": 3.070474147796631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17695,
        "tokens": 9277276160,
        "learning_rate": 0.0002682608577818556,
        "gradient_norm": 0.2979540228843689,
        "train_loss": 3.0539398193359375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17696,
        "tokens": 9277800448,
        "learning_rate": 0.00026823297131002376,
        "gradient_norm": 0.37818577885627747,
        "train_loss": 3.1467347145080566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17697,
        "tokens": 9278324736,
        "learning_rate": 0.0002682050855334568,
        "gradient_norm": 0.3576209843158722,
        "train_loss": 3.084005832672119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17698,
        "tokens": 9278849024,
        "learning_rate": 0.00026817720045246873,
        "gradient_norm": 0.3272886276245117,
        "train_loss": 3.134934425354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17699,
        "tokens": 9279373312,
        "learning_rate": 0.00026814931606737325,
        "gradient_norm": 0.3600459396839142,
        "train_loss": 3.083507537841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17700,
        "tokens": 9279897600,
        "learning_rate": 0.0002681214323784843,
        "gradient_norm": 0.31236594915390015,
        "train_loss": 3.037015914916992,
        "val_loss": 3.0456881523132324,
        "hellaswag_acc": 0.28052181005477905,
        "hellaswag_acc_norm": 0.29316869378089905
    },
    {
        "step": 17701,
        "tokens": 9280421888,
        "learning_rate": 0.00026809354938611577,
        "gradient_norm": 0.3227687478065491,
        "train_loss": 3.00516939163208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17702,
        "tokens": 9280946176,
        "learning_rate": 0.0002680656670905816,
        "gradient_norm": 0.396019846200943,
        "train_loss": 3.0421018600463867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17703,
        "tokens": 9281470464,
        "learning_rate": 0.0002680377854921954,
        "gradient_norm": 0.3554965555667877,
        "train_loss": 3.07236385345459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17704,
        "tokens": 9281994752,
        "learning_rate": 0.0002680099045912713,
        "gradient_norm": 0.34671491384506226,
        "train_loss": 3.096266269683838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17705,
        "tokens": 9282519040,
        "learning_rate": 0.00026798202438812287,
        "gradient_norm": 0.3511008024215698,
        "train_loss": 3.0412416458129883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17706,
        "tokens": 9283043328,
        "learning_rate": 0.00026795414488306414,
        "gradient_norm": 0.33794429898262024,
        "train_loss": 3.092193365097046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17707,
        "tokens": 9283567616,
        "learning_rate": 0.0002679262660764089,
        "gradient_norm": 0.3584069609642029,
        "train_loss": 3.1324210166931152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17708,
        "tokens": 9284091904,
        "learning_rate": 0.00026789838796847086,
        "gradient_norm": 0.3037526309490204,
        "train_loss": 3.059722900390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17709,
        "tokens": 9284616192,
        "learning_rate": 0.00026787051055956383,
        "gradient_norm": 0.3203730583190918,
        "train_loss": 3.082702875137329,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17710,
        "tokens": 9285140480,
        "learning_rate": 0.0002678426338500017,
        "gradient_norm": 0.3407442569732666,
        "train_loss": 3.156907796859741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17711,
        "tokens": 9285664768,
        "learning_rate": 0.0002678147578400982,
        "gradient_norm": 0.3175346851348877,
        "train_loss": 3.0782313346862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17712,
        "tokens": 9286189056,
        "learning_rate": 0.0002677868825301671,
        "gradient_norm": 0.34403181076049805,
        "train_loss": 3.086949348449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17713,
        "tokens": 9286713344,
        "learning_rate": 0.0002677590079205222,
        "gradient_norm": 0.32996314764022827,
        "train_loss": 3.1081392765045166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17714,
        "tokens": 9287237632,
        "learning_rate": 0.00026773113401147726,
        "gradient_norm": 0.33872056007385254,
        "train_loss": 3.0266623497009277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17715,
        "tokens": 9287761920,
        "learning_rate": 0.0002677032608033461,
        "gradient_norm": 0.343536376953125,
        "train_loss": 3.043868064880371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17716,
        "tokens": 9288286208,
        "learning_rate": 0.00026767538829644224,
        "gradient_norm": 0.3555908799171448,
        "train_loss": 3.087439775466919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17717,
        "tokens": 9288810496,
        "learning_rate": 0.0002676475164910797,
        "gradient_norm": 0.31075695157051086,
        "train_loss": 3.0676424503326416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17718,
        "tokens": 9289334784,
        "learning_rate": 0.000267619645387572,
        "gradient_norm": 0.39917728304862976,
        "train_loss": 3.041118621826172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17719,
        "tokens": 9289859072,
        "learning_rate": 0.00026759177498623303,
        "gradient_norm": 0.3534177541732788,
        "train_loss": 3.086179494857788,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17720,
        "tokens": 9290383360,
        "learning_rate": 0.0002675639052873764,
        "gradient_norm": 0.3864029347896576,
        "train_loss": 3.060203790664673,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17721,
        "tokens": 9290907648,
        "learning_rate": 0.00026753603629131573,
        "gradient_norm": 0.3212894797325134,
        "train_loss": 3.079932928085327,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17722,
        "tokens": 9291431936,
        "learning_rate": 0.00026750816799836496,
        "gradient_norm": 0.3737391233444214,
        "train_loss": 3.0207858085632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17723,
        "tokens": 9291956224,
        "learning_rate": 0.0002674803004088376,
        "gradient_norm": 0.3509441018104553,
        "train_loss": 3.0964179039001465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17724,
        "tokens": 9292480512,
        "learning_rate": 0.0002674524335230475,
        "gradient_norm": 0.36867159605026245,
        "train_loss": 3.063934803009033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17725,
        "tokens": 9293004800,
        "learning_rate": 0.0002674245673413081,
        "gradient_norm": 0.36335355043411255,
        "train_loss": 3.077967643737793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17726,
        "tokens": 9293529088,
        "learning_rate": 0.00026739670186393333,
        "gradient_norm": 0.33631160855293274,
        "train_loss": 3.0265378952026367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17727,
        "tokens": 9294053376,
        "learning_rate": 0.00026736883709123653,
        "gradient_norm": 0.30688631534576416,
        "train_loss": 3.059772491455078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17728,
        "tokens": 9294577664,
        "learning_rate": 0.00026734097302353173,
        "gradient_norm": 0.312923789024353,
        "train_loss": 3.021557569503784,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17729,
        "tokens": 9295101952,
        "learning_rate": 0.0002673131096611322,
        "gradient_norm": 0.32533419132232666,
        "train_loss": 2.9905781745910645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17730,
        "tokens": 9295626240,
        "learning_rate": 0.0002672852470043519,
        "gradient_norm": 0.346662700176239,
        "train_loss": 3.035184383392334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17731,
        "tokens": 9296150528,
        "learning_rate": 0.0002672573850535043,
        "gradient_norm": 0.3141850233078003,
        "train_loss": 3.094001293182373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17732,
        "tokens": 9296674816,
        "learning_rate": 0.00026722952380890295,
        "gradient_norm": 0.35022568702697754,
        "train_loss": 3.0334362983703613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17733,
        "tokens": 9297199104,
        "learning_rate": 0.00026720166327086174,
        "gradient_norm": 0.3054630756378174,
        "train_loss": 3.025099754333496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17734,
        "tokens": 9297723392,
        "learning_rate": 0.0002671738034396939,
        "gradient_norm": 0.34380990266799927,
        "train_loss": 3.076443672180176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17735,
        "tokens": 9298247680,
        "learning_rate": 0.00026714594431571334,
        "gradient_norm": 0.34986183047294617,
        "train_loss": 3.1044559478759766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17736,
        "tokens": 9298771968,
        "learning_rate": 0.00026711808589923347,
        "gradient_norm": 0.3204980492591858,
        "train_loss": 3.0342512130737305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17737,
        "tokens": 9299296256,
        "learning_rate": 0.000267090228190568,
        "gradient_norm": 0.4450741410255432,
        "train_loss": 3.0425877571105957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17738,
        "tokens": 9299820544,
        "learning_rate": 0.0002670623711900303,
        "gradient_norm": 0.3388248383998871,
        "train_loss": 3.0673036575317383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17739,
        "tokens": 9300344832,
        "learning_rate": 0.00026703451489793416,
        "gradient_norm": 0.35399067401885986,
        "train_loss": 3.0367274284362793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17740,
        "tokens": 9300869120,
        "learning_rate": 0.000267006659314593,
        "gradient_norm": 0.32946404814720154,
        "train_loss": 3.0898423194885254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17741,
        "tokens": 9301393408,
        "learning_rate": 0.00026697880444032036,
        "gradient_norm": 0.3596034646034241,
        "train_loss": 2.949167490005493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17742,
        "tokens": 9301917696,
        "learning_rate": 0.00026695095027542997,
        "gradient_norm": 0.32471519708633423,
        "train_loss": 3.038698673248291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17743,
        "tokens": 9302441984,
        "learning_rate": 0.00026692309682023517,
        "gradient_norm": 0.3437425196170807,
        "train_loss": 3.0164103507995605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17744,
        "tokens": 9302966272,
        "learning_rate": 0.00026689524407504957,
        "gradient_norm": 0.3478721082210541,
        "train_loss": 3.066711187362671,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17745,
        "tokens": 9303490560,
        "learning_rate": 0.00026686739204018656,
        "gradient_norm": 0.3260633647441864,
        "train_loss": 3.054478645324707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17746,
        "tokens": 9304014848,
        "learning_rate": 0.0002668395407159599,
        "gradient_norm": 0.3497273027896881,
        "train_loss": 3.035396099090576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17747,
        "tokens": 9304539136,
        "learning_rate": 0.0002668116901026828,
        "gradient_norm": 0.34446826577186584,
        "train_loss": 3.060051441192627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17748,
        "tokens": 9305063424,
        "learning_rate": 0.000266783840200669,
        "gradient_norm": 0.31260475516319275,
        "train_loss": 3.0202717781066895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17749,
        "tokens": 9305587712,
        "learning_rate": 0.0002667559910102318,
        "gradient_norm": 0.3250143826007843,
        "train_loss": 3.0820460319519043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17750,
        "tokens": 9306112000,
        "learning_rate": 0.00026672814253168474,
        "gradient_norm": 0.33216822147369385,
        "train_loss": 3.050633430480957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17751,
        "tokens": 9306636288,
        "learning_rate": 0.0002667002947653414,
        "gradient_norm": 0.3568028211593628,
        "train_loss": 3.0586507320404053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17752,
        "tokens": 9307160576,
        "learning_rate": 0.00026667244771151513,
        "gradient_norm": 0.3758620619773865,
        "train_loss": 3.1232669353485107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17753,
        "tokens": 9307684864,
        "learning_rate": 0.00026664460137051937,
        "gradient_norm": 0.3544957935810089,
        "train_loss": 3.0137853622436523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17754,
        "tokens": 9308209152,
        "learning_rate": 0.00026661675574266757,
        "gradient_norm": 0.36182451248168945,
        "train_loss": 3.1356301307678223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17755,
        "tokens": 9308733440,
        "learning_rate": 0.00026658891082827327,
        "gradient_norm": 0.3751426935195923,
        "train_loss": 3.05961275100708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17756,
        "tokens": 9309257728,
        "learning_rate": 0.00026656106662764975,
        "gradient_norm": 0.3386431336402893,
        "train_loss": 3.0219597816467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17757,
        "tokens": 9309782016,
        "learning_rate": 0.0002665332231411105,
        "gradient_norm": 0.34810271859169006,
        "train_loss": 3.0243544578552246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17758,
        "tokens": 9310306304,
        "learning_rate": 0.00026650538036896907,
        "gradient_norm": 0.42030462622642517,
        "train_loss": 3.1068906784057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17759,
        "tokens": 9310830592,
        "learning_rate": 0.00026647753831153856,
        "gradient_norm": 0.3325388431549072,
        "train_loss": 3.0611300468444824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17760,
        "tokens": 9311354880,
        "learning_rate": 0.00026644969696913267,
        "gradient_norm": 0.38634759187698364,
        "train_loss": 3.010312080383301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17761,
        "tokens": 9311879168,
        "learning_rate": 0.0002664218563420645,
        "gradient_norm": 0.3063178062438965,
        "train_loss": 3.0621256828308105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17762,
        "tokens": 9312403456,
        "learning_rate": 0.00026639401643064773,
        "gradient_norm": 0.3400518298149109,
        "train_loss": 3.0352935791015625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17763,
        "tokens": 9312927744,
        "learning_rate": 0.0002663661772351955,
        "gradient_norm": 0.31531545519828796,
        "train_loss": 3.0626964569091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17764,
        "tokens": 9313452032,
        "learning_rate": 0.0002663383387560214,
        "gradient_norm": 0.3306848406791687,
        "train_loss": 3.053894519805908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17765,
        "tokens": 9313976320,
        "learning_rate": 0.00026631050099343854,
        "gradient_norm": 0.3802854120731354,
        "train_loss": 3.094705104827881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17766,
        "tokens": 9314500608,
        "learning_rate": 0.00026628266394776044,
        "gradient_norm": 0.32056066393852234,
        "train_loss": 3.0894062519073486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17767,
        "tokens": 9315024896,
        "learning_rate": 0.0002662548276193003,
        "gradient_norm": 0.32982558012008667,
        "train_loss": 2.9782819747924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17768,
        "tokens": 9315549184,
        "learning_rate": 0.00026622699200837166,
        "gradient_norm": 0.3492489457130432,
        "train_loss": 3.09635591506958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17769,
        "tokens": 9316073472,
        "learning_rate": 0.00026619915711528763,
        "gradient_norm": 0.3285617530345917,
        "train_loss": 3.0267789363861084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17770,
        "tokens": 9316597760,
        "learning_rate": 0.00026617132294036157,
        "gradient_norm": 0.42589670419692993,
        "train_loss": 3.0198283195495605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17771,
        "tokens": 9317122048,
        "learning_rate": 0.00026614348948390696,
        "gradient_norm": 0.3697454631328583,
        "train_loss": 3.0245461463928223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17772,
        "tokens": 9317646336,
        "learning_rate": 0.00026611565674623686,
        "gradient_norm": 0.36747124791145325,
        "train_loss": 3.037125587463379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17773,
        "tokens": 9318170624,
        "learning_rate": 0.00026608782472766477,
        "gradient_norm": 0.3595516085624695,
        "train_loss": 2.974388599395752,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17774,
        "tokens": 9318694912,
        "learning_rate": 0.00026605999342850376,
        "gradient_norm": 0.3240709900856018,
        "train_loss": 3.1053829193115234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17775,
        "tokens": 9319219200,
        "learning_rate": 0.0002660321628490674,
        "gradient_norm": 0.33611050248146057,
        "train_loss": 3.021167755126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17776,
        "tokens": 9319743488,
        "learning_rate": 0.00026600433298966863,
        "gradient_norm": 0.35264134407043457,
        "train_loss": 3.1056466102600098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17777,
        "tokens": 9320267776,
        "learning_rate": 0.000265976503850621,
        "gradient_norm": 0.39111393690109253,
        "train_loss": 3.0978610515594482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17778,
        "tokens": 9320792064,
        "learning_rate": 0.0002659486754322375,
        "gradient_norm": 0.35142964124679565,
        "train_loss": 3.010829448699951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17779,
        "tokens": 9321316352,
        "learning_rate": 0.00026592084773483166,
        "gradient_norm": 0.3869604766368866,
        "train_loss": 3.0415167808532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17780,
        "tokens": 9321840640,
        "learning_rate": 0.00026589302075871637,
        "gradient_norm": 0.3630352318286896,
        "train_loss": 3.1063623428344727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17781,
        "tokens": 9322364928,
        "learning_rate": 0.00026586519450420506,
        "gradient_norm": 0.3148675858974457,
        "train_loss": 3.0620012283325195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17782,
        "tokens": 9322889216,
        "learning_rate": 0.0002658373689716111,
        "gradient_norm": 0.32664966583251953,
        "train_loss": 3.0660698413848877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17783,
        "tokens": 9323413504,
        "learning_rate": 0.00026580954416124736,
        "gradient_norm": 0.3380897045135498,
        "train_loss": 3.033000946044922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17784,
        "tokens": 9323937792,
        "learning_rate": 0.00026578172007342735,
        "gradient_norm": 0.322939395904541,
        "train_loss": 3.078341484069824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17785,
        "tokens": 9324462080,
        "learning_rate": 0.000265753896708464,
        "gradient_norm": 0.3303806781768799,
        "train_loss": 3.0608105659484863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17786,
        "tokens": 9324986368,
        "learning_rate": 0.00026572607406667075,
        "gradient_norm": 0.33541253209114075,
        "train_loss": 3.0619778633117676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17787,
        "tokens": 9325510656,
        "learning_rate": 0.00026569825214836054,
        "gradient_norm": 0.35130825638771057,
        "train_loss": 3.021118640899658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17788,
        "tokens": 9326034944,
        "learning_rate": 0.0002656704309538468,
        "gradient_norm": 0.3183271884918213,
        "train_loss": 3.0605416297912598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17789,
        "tokens": 9326559232,
        "learning_rate": 0.0002656426104834424,
        "gradient_norm": 0.37891629338264465,
        "train_loss": 3.098189115524292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17790,
        "tokens": 9327083520,
        "learning_rate": 0.00026561479073746065,
        "gradient_norm": 0.4132031798362732,
        "train_loss": 3.0929083824157715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17791,
        "tokens": 9327607808,
        "learning_rate": 0.0002655869717162148,
        "gradient_norm": 0.31734415888786316,
        "train_loss": 3.0465779304504395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17792,
        "tokens": 9328132096,
        "learning_rate": 0.00026555915342001786,
        "gradient_norm": 0.32504844665527344,
        "train_loss": 3.091111183166504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17793,
        "tokens": 9328656384,
        "learning_rate": 0.00026553133584918294,
        "gradient_norm": 0.3245278298854828,
        "train_loss": 3.0665812492370605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17794,
        "tokens": 9329180672,
        "learning_rate": 0.0002655035190040232,
        "gradient_norm": 0.34574684500694275,
        "train_loss": 3.058407783508301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17795,
        "tokens": 9329704960,
        "learning_rate": 0.00026547570288485176,
        "gradient_norm": 0.2844700515270233,
        "train_loss": 3.0824947357177734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17796,
        "tokens": 9330229248,
        "learning_rate": 0.00026544788749198163,
        "gradient_norm": 0.33366021513938904,
        "train_loss": 3.029015302658081,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17797,
        "tokens": 9330753536,
        "learning_rate": 0.0002654200728257261,
        "gradient_norm": 0.2914767265319824,
        "train_loss": 3.061781883239746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17798,
        "tokens": 9331277824,
        "learning_rate": 0.00026539225888639814,
        "gradient_norm": 0.35193827748298645,
        "train_loss": 3.1584768295288086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17799,
        "tokens": 9331802112,
        "learning_rate": 0.00026536444567431085,
        "gradient_norm": 0.3285404443740845,
        "train_loss": 3.1033217906951904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17800,
        "tokens": 9332326400,
        "learning_rate": 0.0002653366331897772,
        "gradient_norm": 0.33101189136505127,
        "train_loss": 3.064797878265381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17801,
        "tokens": 9332850688,
        "learning_rate": 0.00026530882143311046,
        "gradient_norm": 0.3452756702899933,
        "train_loss": 3.031712770462036,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17802,
        "tokens": 9333374976,
        "learning_rate": 0.0002652810104046235,
        "gradient_norm": 0.3093980848789215,
        "train_loss": 3.0528581142425537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17803,
        "tokens": 9333899264,
        "learning_rate": 0.0002652532001046295,
        "gradient_norm": 0.3389345705509186,
        "train_loss": 3.0253853797912598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17804,
        "tokens": 9334423552,
        "learning_rate": 0.00026522539053344137,
        "gradient_norm": 0.31559720635414124,
        "train_loss": 3.0849056243896484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17805,
        "tokens": 9334947840,
        "learning_rate": 0.00026519758169137226,
        "gradient_norm": 0.3588067889213562,
        "train_loss": 3.0949301719665527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17806,
        "tokens": 9335472128,
        "learning_rate": 0.00026516977357873514,
        "gradient_norm": 0.3430940806865692,
        "train_loss": 3.088038444519043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17807,
        "tokens": 9335996416,
        "learning_rate": 0.00026514196619584305,
        "gradient_norm": 0.301272451877594,
        "train_loss": 3.116807222366333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17808,
        "tokens": 9336520704,
        "learning_rate": 0.000265114159543009,
        "gradient_norm": 0.28999465703964233,
        "train_loss": 3.0119357109069824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17809,
        "tokens": 9337044992,
        "learning_rate": 0.0002650863536205459,
        "gradient_norm": 0.30138498544692993,
        "train_loss": 3.0149807929992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17810,
        "tokens": 9337569280,
        "learning_rate": 0.0002650585484287668,
        "gradient_norm": 0.333016574382782,
        "train_loss": 2.9906671047210693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17811,
        "tokens": 9338093568,
        "learning_rate": 0.00026503074396798474,
        "gradient_norm": 0.3250303566455841,
        "train_loss": 3.008401870727539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17812,
        "tokens": 9338617856,
        "learning_rate": 0.0002650029402385126,
        "gradient_norm": 0.30378448963165283,
        "train_loss": 3.0142951011657715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17813,
        "tokens": 9339142144,
        "learning_rate": 0.00026497513724066347,
        "gradient_norm": 0.32351547479629517,
        "train_loss": 2.9906423091888428,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17814,
        "tokens": 9339666432,
        "learning_rate": 0.0002649473349747501,
        "gradient_norm": 0.3272852599620819,
        "train_loss": 3.0006611347198486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17815,
        "tokens": 9340190720,
        "learning_rate": 0.00026491953344108575,
        "gradient_norm": 0.347459614276886,
        "train_loss": 3.0622823238372803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17816,
        "tokens": 9340715008,
        "learning_rate": 0.0002648917326399829,
        "gradient_norm": 0.3544314503669739,
        "train_loss": 3.0269198417663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17817,
        "tokens": 9341239296,
        "learning_rate": 0.000264863932571755,
        "gradient_norm": 0.3612515926361084,
        "train_loss": 3.047135591506958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17818,
        "tokens": 9341763584,
        "learning_rate": 0.00026483613323671464,
        "gradient_norm": 0.47312265634536743,
        "train_loss": 3.05045223236084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17819,
        "tokens": 9342287872,
        "learning_rate": 0.0002648083346351749,
        "gradient_norm": 0.4015176594257355,
        "train_loss": 3.0455727577209473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17820,
        "tokens": 9342812160,
        "learning_rate": 0.0002647805367674485,
        "gradient_norm": 0.3528907895088196,
        "train_loss": 3.068739652633667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17821,
        "tokens": 9343336448,
        "learning_rate": 0.00026475273963384846,
        "gradient_norm": 0.3440980017185211,
        "train_loss": 3.0377602577209473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17822,
        "tokens": 9343860736,
        "learning_rate": 0.00026472494323468777,
        "gradient_norm": 0.35433876514434814,
        "train_loss": 3.0225467681884766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17823,
        "tokens": 9344385024,
        "learning_rate": 0.0002646971475702792,
        "gradient_norm": 0.39988139271736145,
        "train_loss": 3.0362377166748047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17824,
        "tokens": 9344909312,
        "learning_rate": 0.0002646693526409356,
        "gradient_norm": 0.3313695192337036,
        "train_loss": 3.0000698566436768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17825,
        "tokens": 9345433600,
        "learning_rate": 0.00026464155844696985,
        "gradient_norm": 0.3796956539154053,
        "train_loss": 3.0481982231140137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17826,
        "tokens": 9345957888,
        "learning_rate": 0.0002646137649886949,
        "gradient_norm": 0.3009148836135864,
        "train_loss": 3.028050661087036,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17827,
        "tokens": 9346482176,
        "learning_rate": 0.0002645859722664234,
        "gradient_norm": 0.347100168466568,
        "train_loss": 3.0042495727539062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17828,
        "tokens": 9347006464,
        "learning_rate": 0.00026455818028046853,
        "gradient_norm": 0.3066881597042084,
        "train_loss": 3.064594268798828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17829,
        "tokens": 9347530752,
        "learning_rate": 0.0002645303890311427,
        "gradient_norm": 0.34401488304138184,
        "train_loss": 3.0192790031433105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17830,
        "tokens": 9348055040,
        "learning_rate": 0.000264502598518759,
        "gradient_norm": 0.36029717326164246,
        "train_loss": 3.0234522819519043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17831,
        "tokens": 9348579328,
        "learning_rate": 0.00026447480874363034,
        "gradient_norm": 0.3394845426082611,
        "train_loss": 3.031494140625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17832,
        "tokens": 9349103616,
        "learning_rate": 0.00026444701970606925,
        "gradient_norm": 0.33095476031303406,
        "train_loss": 3.037980556488037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17833,
        "tokens": 9349627904,
        "learning_rate": 0.00026441923140638874,
        "gradient_norm": 0.33951887488365173,
        "train_loss": 3.1546273231506348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17834,
        "tokens": 9350152192,
        "learning_rate": 0.0002643914438449015,
        "gradient_norm": 0.3696802258491516,
        "train_loss": 3.050241708755493,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17835,
        "tokens": 9350676480,
        "learning_rate": 0.00026436365702192037,
        "gradient_norm": 0.31272080540657043,
        "train_loss": 3.072345733642578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17836,
        "tokens": 9351200768,
        "learning_rate": 0.000264335870937758,
        "gradient_norm": 0.39148378372192383,
        "train_loss": 3.064732551574707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17837,
        "tokens": 9351725056,
        "learning_rate": 0.0002643080855927274,
        "gradient_norm": 0.3407335877418518,
        "train_loss": 3.026848316192627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17838,
        "tokens": 9352249344,
        "learning_rate": 0.000264280300987141,
        "gradient_norm": 0.33821195363998413,
        "train_loss": 3.0890207290649414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17839,
        "tokens": 9352773632,
        "learning_rate": 0.00026425251712131195,
        "gradient_norm": 0.38848620653152466,
        "train_loss": 3.0237739086151123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17840,
        "tokens": 9353297920,
        "learning_rate": 0.0002642247339955526,
        "gradient_norm": 0.39764076471328735,
        "train_loss": 3.0979628562927246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17841,
        "tokens": 9353822208,
        "learning_rate": 0.00026419695161017593,
        "gradient_norm": 0.3493402302265167,
        "train_loss": 3.055382251739502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17842,
        "tokens": 9354346496,
        "learning_rate": 0.0002641691699654946,
        "gradient_norm": 0.3587523400783539,
        "train_loss": 3.024867534637451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17843,
        "tokens": 9354870784,
        "learning_rate": 0.00026414138906182124,
        "gradient_norm": 0.3484306335449219,
        "train_loss": 3.0610103607177734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17844,
        "tokens": 9355395072,
        "learning_rate": 0.0002641136088994688,
        "gradient_norm": 0.39629554748535156,
        "train_loss": 3.050722599029541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17845,
        "tokens": 9355919360,
        "learning_rate": 0.00026408582947874974,
        "gradient_norm": 0.3526192307472229,
        "train_loss": 3.042478084564209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17846,
        "tokens": 9356443648,
        "learning_rate": 0.0002640580507999768,
        "gradient_norm": 0.3419629633426666,
        "train_loss": 3.038884162902832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17847,
        "tokens": 9356967936,
        "learning_rate": 0.0002640302728634627,
        "gradient_norm": 0.3470613956451416,
        "train_loss": 3.0366830825805664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17848,
        "tokens": 9357492224,
        "learning_rate": 0.00026400249566952024,
        "gradient_norm": 0.3280717730522156,
        "train_loss": 3.021869659423828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17849,
        "tokens": 9358016512,
        "learning_rate": 0.0002639747192184618,
        "gradient_norm": 0.3654690980911255,
        "train_loss": 3.0931944847106934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17850,
        "tokens": 9358540800,
        "learning_rate": 0.00026394694351060025,
        "gradient_norm": 0.34957942366600037,
        "train_loss": 3.0769553184509277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17851,
        "tokens": 9359065088,
        "learning_rate": 0.0002639191685462482,
        "gradient_norm": 0.33880189061164856,
        "train_loss": 3.0686023235321045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17852,
        "tokens": 9359589376,
        "learning_rate": 0.0002638913943257183,
        "gradient_norm": 0.3443523645401001,
        "train_loss": 2.996352195739746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17853,
        "tokens": 9360113664,
        "learning_rate": 0.00026386362084932316,
        "gradient_norm": 0.3868267834186554,
        "train_loss": 3.072340488433838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17854,
        "tokens": 9360637952,
        "learning_rate": 0.0002638358481173754,
        "gradient_norm": 0.3425649106502533,
        "train_loss": 3.086709499359131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17855,
        "tokens": 9361162240,
        "learning_rate": 0.0002638080761301876,
        "gradient_norm": 0.40180355310440063,
        "train_loss": 3.0960693359375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17856,
        "tokens": 9361686528,
        "learning_rate": 0.0002637803048880725,
        "gradient_norm": 0.3778817653656006,
        "train_loss": 3.0619378089904785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17857,
        "tokens": 9362210816,
        "learning_rate": 0.0002637525343913425,
        "gradient_norm": 0.30693379044532776,
        "train_loss": 3.014925241470337,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17858,
        "tokens": 9362735104,
        "learning_rate": 0.0002637247646403104,
        "gradient_norm": 0.3468073904514313,
        "train_loss": 3.065436840057373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17859,
        "tokens": 9363259392,
        "learning_rate": 0.0002636969956352887,
        "gradient_norm": 0.31841328740119934,
        "train_loss": 3.146686553955078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17860,
        "tokens": 9363783680,
        "learning_rate": 0.0002636692273765899,
        "gradient_norm": 0.3647249937057495,
        "train_loss": 3.0567941665649414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17861,
        "tokens": 9364307968,
        "learning_rate": 0.00026364145986452656,
        "gradient_norm": 0.36115512251853943,
        "train_loss": 3.0308876037597656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17862,
        "tokens": 9364832256,
        "learning_rate": 0.00026361369309941147,
        "gradient_norm": 0.3346897065639496,
        "train_loss": 3.03641939163208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17863,
        "tokens": 9365356544,
        "learning_rate": 0.0002635859270815569,
        "gradient_norm": 0.36505603790283203,
        "train_loss": 3.0794153213500977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17864,
        "tokens": 9365880832,
        "learning_rate": 0.00026355816181127564,
        "gradient_norm": 0.32559317350387573,
        "train_loss": 3.051440954208374,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17865,
        "tokens": 9366405120,
        "learning_rate": 0.0002635303972888799,
        "gradient_norm": 0.3704794943332672,
        "train_loss": 2.9785327911376953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17866,
        "tokens": 9366929408,
        "learning_rate": 0.00026350263351468254,
        "gradient_norm": 0.3624016046524048,
        "train_loss": 3.0711827278137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17867,
        "tokens": 9367453696,
        "learning_rate": 0.00026347487048899586,
        "gradient_norm": 0.3262614905834198,
        "train_loss": 3.0096230506896973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17868,
        "tokens": 9367977984,
        "learning_rate": 0.0002634471082121325,
        "gradient_norm": 0.39274314045906067,
        "train_loss": 3.0104010105133057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17869,
        "tokens": 9368502272,
        "learning_rate": 0.0002634193466844048,
        "gradient_norm": 0.32882416248321533,
        "train_loss": 3.017225742340088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17870,
        "tokens": 9369026560,
        "learning_rate": 0.00026339158590612535,
        "gradient_norm": 0.31592971086502075,
        "train_loss": 3.041679859161377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17871,
        "tokens": 9369550848,
        "learning_rate": 0.00026336382587760683,
        "gradient_norm": 0.40723446011543274,
        "train_loss": 3.0446557998657227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17872,
        "tokens": 9370075136,
        "learning_rate": 0.00026333606659916127,
        "gradient_norm": 0.38356447219848633,
        "train_loss": 3.0420823097229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17873,
        "tokens": 9370599424,
        "learning_rate": 0.0002633083080711016,
        "gradient_norm": 0.32838618755340576,
        "train_loss": 3.007143974304199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17874,
        "tokens": 9371123712,
        "learning_rate": 0.00026328055029373984,
        "gradient_norm": 0.43427425622940063,
        "train_loss": 3.0628814697265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17875,
        "tokens": 9371648000,
        "learning_rate": 0.0002632527932673888,
        "gradient_norm": 0.3329586982727051,
        "train_loss": 3.047497272491455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17876,
        "tokens": 9372172288,
        "learning_rate": 0.0002632250369923607,
        "gradient_norm": 0.35451310873031616,
        "train_loss": 3.032491683959961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17877,
        "tokens": 9372696576,
        "learning_rate": 0.0002631972814689681,
        "gradient_norm": 0.3543378412723541,
        "train_loss": 3.083202362060547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17878,
        "tokens": 9373220864,
        "learning_rate": 0.0002631695266975233,
        "gradient_norm": 0.3341626226902008,
        "train_loss": 3.006923198699951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17879,
        "tokens": 9373745152,
        "learning_rate": 0.0002631417726783389,
        "gradient_norm": 0.3829229474067688,
        "train_loss": 3.0196943283081055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17880,
        "tokens": 9374269440,
        "learning_rate": 0.00026311401941172706,
        "gradient_norm": 0.38954150676727295,
        "train_loss": 3.0386407375335693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17881,
        "tokens": 9374793728,
        "learning_rate": 0.0002630862668980003,
        "gradient_norm": 0.34417465329170227,
        "train_loss": 3.073521852493286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17882,
        "tokens": 9375318016,
        "learning_rate": 0.00026305851513747113,
        "gradient_norm": 0.3528486490249634,
        "train_loss": 3.1134591102600098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17883,
        "tokens": 9375842304,
        "learning_rate": 0.00026303076413045177,
        "gradient_norm": 0.34614694118499756,
        "train_loss": 3.026153326034546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17884,
        "tokens": 9376366592,
        "learning_rate": 0.00026300301387725464,
        "gradient_norm": 0.3384731411933899,
        "train_loss": 3.0810437202453613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17885,
        "tokens": 9376890880,
        "learning_rate": 0.00026297526437819206,
        "gradient_norm": 0.3317687213420868,
        "train_loss": 3.018765449523926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17886,
        "tokens": 9377415168,
        "learning_rate": 0.0002629475156335765,
        "gradient_norm": 0.32728317379951477,
        "train_loss": 3.103987216949463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17887,
        "tokens": 9377939456,
        "learning_rate": 0.0002629197676437202,
        "gradient_norm": 0.326193630695343,
        "train_loss": 3.0795817375183105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17888,
        "tokens": 9378463744,
        "learning_rate": 0.00026289202040893553,
        "gradient_norm": 0.33315446972846985,
        "train_loss": 3.0159521102905273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17889,
        "tokens": 9378988032,
        "learning_rate": 0.0002628642739295348,
        "gradient_norm": 0.31407153606414795,
        "train_loss": 3.037261486053467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17890,
        "tokens": 9379512320,
        "learning_rate": 0.00026283652820583033,
        "gradient_norm": 0.3262138366699219,
        "train_loss": 3.0806431770324707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17891,
        "tokens": 9380036608,
        "learning_rate": 0.00026280878323813457,
        "gradient_norm": 0.31317558884620667,
        "train_loss": 3.082287311553955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17892,
        "tokens": 9380560896,
        "learning_rate": 0.0002627810390267596,
        "gradient_norm": 0.33313754200935364,
        "train_loss": 3.0324339866638184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17893,
        "tokens": 9381085184,
        "learning_rate": 0.00026275329557201793,
        "gradient_norm": 0.31876468658447266,
        "train_loss": 3.071326732635498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17894,
        "tokens": 9381609472,
        "learning_rate": 0.00026272555287422167,
        "gradient_norm": 0.32128244638442993,
        "train_loss": 3.0491297245025635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17895,
        "tokens": 9382133760,
        "learning_rate": 0.0002626978109336832,
        "gradient_norm": 0.3130093514919281,
        "train_loss": 3.0919957160949707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17896,
        "tokens": 9382658048,
        "learning_rate": 0.0002626700697507147,
        "gradient_norm": 0.34496408700942993,
        "train_loss": 3.042499542236328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17897,
        "tokens": 9383182336,
        "learning_rate": 0.0002626423293256286,
        "gradient_norm": 0.3460358679294586,
        "train_loss": 3.0449061393737793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17898,
        "tokens": 9383706624,
        "learning_rate": 0.000262614589658737,
        "gradient_norm": 0.33534762263298035,
        "train_loss": 3.018218994140625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17899,
        "tokens": 9384230912,
        "learning_rate": 0.0002625868507503522,
        "gradient_norm": 0.34318527579307556,
        "train_loss": 3.053288698196411,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17900,
        "tokens": 9384755200,
        "learning_rate": 0.0002625591126007863,
        "gradient_norm": 0.3105311393737793,
        "train_loss": 3.0470709800720215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17901,
        "tokens": 9385279488,
        "learning_rate": 0.0002625313752103518,
        "gradient_norm": 0.3648841679096222,
        "train_loss": 3.11295223236084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17902,
        "tokens": 9385803776,
        "learning_rate": 0.00026250363857936075,
        "gradient_norm": 0.3299870789051056,
        "train_loss": 3.070220708847046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17903,
        "tokens": 9386328064,
        "learning_rate": 0.0002624759027081254,
        "gradient_norm": 0.3609478175640106,
        "train_loss": 3.0598888397216797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17904,
        "tokens": 9386852352,
        "learning_rate": 0.0002624481675969579,
        "gradient_norm": 0.3054835796356201,
        "train_loss": 3.0350465774536133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17905,
        "tokens": 9387376640,
        "learning_rate": 0.00026242043324617046,
        "gradient_norm": 0.42507052421569824,
        "train_loss": 3.0429041385650635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17906,
        "tokens": 9387900928,
        "learning_rate": 0.00026239269965607534,
        "gradient_norm": 0.344472736120224,
        "train_loss": 3.0905568599700928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17907,
        "tokens": 9388425216,
        "learning_rate": 0.00026236496682698464,
        "gradient_norm": 0.345577597618103,
        "train_loss": 3.1007590293884277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17908,
        "tokens": 9388949504,
        "learning_rate": 0.0002623372347592105,
        "gradient_norm": 0.3306047320365906,
        "train_loss": 3.0547008514404297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17909,
        "tokens": 9389473792,
        "learning_rate": 0.0002623095034530652,
        "gradient_norm": 0.30737337470054626,
        "train_loss": 3.0515763759613037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17910,
        "tokens": 9389998080,
        "learning_rate": 0.0002622817729088607,
        "gradient_norm": 0.30254754424095154,
        "train_loss": 3.1043992042541504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17911,
        "tokens": 9390522368,
        "learning_rate": 0.00026225404312690945,
        "gradient_norm": 0.286396861076355,
        "train_loss": 3.051175594329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17912,
        "tokens": 9391046656,
        "learning_rate": 0.00026222631410752326,
        "gradient_norm": 0.2794162929058075,
        "train_loss": 3.106660842895508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17913,
        "tokens": 9391570944,
        "learning_rate": 0.00026219858585101435,
        "gradient_norm": 0.3073364198207855,
        "train_loss": 3.061941623687744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17914,
        "tokens": 9392095232,
        "learning_rate": 0.00026217085835769497,
        "gradient_norm": 0.3574214577674866,
        "train_loss": 3.0523605346679688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17915,
        "tokens": 9392619520,
        "learning_rate": 0.00026214313162787706,
        "gradient_norm": 0.3224187195301056,
        "train_loss": 3.054351568222046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17916,
        "tokens": 9393143808,
        "learning_rate": 0.0002621154056618729,
        "gradient_norm": 0.32251304388046265,
        "train_loss": 3.052593946456909,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17917,
        "tokens": 9393668096,
        "learning_rate": 0.0002620876804599944,
        "gradient_norm": 0.42750605940818787,
        "train_loss": 3.097405433654785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17918,
        "tokens": 9394192384,
        "learning_rate": 0.0002620599560225537,
        "gradient_norm": 0.34633803367614746,
        "train_loss": 3.1143932342529297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17919,
        "tokens": 9394716672,
        "learning_rate": 0.0002620322323498629,
        "gradient_norm": 0.3872743248939514,
        "train_loss": 3.119256019592285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17920,
        "tokens": 9395240960,
        "learning_rate": 0.00026200450944223404,
        "gradient_norm": 0.3394549787044525,
        "train_loss": 3.0322365760803223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17921,
        "tokens": 9395765248,
        "learning_rate": 0.00026197678729997914,
        "gradient_norm": 0.4054049551486969,
        "train_loss": 3.1080539226531982,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17922,
        "tokens": 9396289536,
        "learning_rate": 0.0002619490659234104,
        "gradient_norm": 0.393930047750473,
        "train_loss": 3.150916814804077,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17923,
        "tokens": 9396813824,
        "learning_rate": 0.0002619213453128396,
        "gradient_norm": 0.3635317385196686,
        "train_loss": 3.0632734298706055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17924,
        "tokens": 9397338112,
        "learning_rate": 0.0002618936254685791,
        "gradient_norm": 0.4257880449295044,
        "train_loss": 3.1076297760009766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17925,
        "tokens": 9397862400,
        "learning_rate": 0.0002618659063909406,
        "gradient_norm": 0.32091909646987915,
        "train_loss": 3.0750792026519775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17926,
        "tokens": 9398386688,
        "learning_rate": 0.00026183818808023636,
        "gradient_norm": 0.4112292528152466,
        "train_loss": 3.050753355026245,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17927,
        "tokens": 9398910976,
        "learning_rate": 0.0002618104705367781,
        "gradient_norm": 0.3438628017902374,
        "train_loss": 3.1258974075317383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17928,
        "tokens": 9399435264,
        "learning_rate": 0.00026178275376087827,
        "gradient_norm": 0.4371351897716522,
        "train_loss": 3.1288137435913086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17929,
        "tokens": 9399959552,
        "learning_rate": 0.0002617550377528483,
        "gradient_norm": 0.34625259041786194,
        "train_loss": 3.121399402618408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17930,
        "tokens": 9400483840,
        "learning_rate": 0.0002617273225130006,
        "gradient_norm": 0.4059770107269287,
        "train_loss": 3.08156156539917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17931,
        "tokens": 9401008128,
        "learning_rate": 0.000261699608041647,
        "gradient_norm": 0.33471062779426575,
        "train_loss": 3.0736889839172363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17932,
        "tokens": 9401532416,
        "learning_rate": 0.0002616718943390994,
        "gradient_norm": 0.3796252906322479,
        "train_loss": 3.129988670349121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17933,
        "tokens": 9402056704,
        "learning_rate": 0.00026164418140566984,
        "gradient_norm": 0.37875667214393616,
        "train_loss": 3.130377769470215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17934,
        "tokens": 9402580992,
        "learning_rate": 0.00026161646924167015,
        "gradient_norm": 0.39199692010879517,
        "train_loss": 3.0585851669311523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17935,
        "tokens": 9403105280,
        "learning_rate": 0.0002615887578474125,
        "gradient_norm": 0.3872866630554199,
        "train_loss": 3.101447582244873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17936,
        "tokens": 9403629568,
        "learning_rate": 0.00026156104722320847,
        "gradient_norm": 0.33667945861816406,
        "train_loss": 3.08821177482605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17937,
        "tokens": 9404153856,
        "learning_rate": 0.0002615333373693703,
        "gradient_norm": 0.3923015594482422,
        "train_loss": 3.0505099296569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17938,
        "tokens": 9404678144,
        "learning_rate": 0.0002615056282862097,
        "gradient_norm": 0.3672631084918976,
        "train_loss": 3.1006665229797363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17939,
        "tokens": 9405202432,
        "learning_rate": 0.00026147791997403866,
        "gradient_norm": 0.3712369203567505,
        "train_loss": 2.9944117069244385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17940,
        "tokens": 9405726720,
        "learning_rate": 0.000261450212433169,
        "gradient_norm": 0.3873651623725891,
        "train_loss": 3.1261935234069824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17941,
        "tokens": 9406251008,
        "learning_rate": 0.00026142250566391263,
        "gradient_norm": 0.40631890296936035,
        "train_loss": 3.101327419281006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17942,
        "tokens": 9406775296,
        "learning_rate": 0.00026139479966658157,
        "gradient_norm": 0.3782871961593628,
        "train_loss": 3.1147654056549072,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17943,
        "tokens": 9407299584,
        "learning_rate": 0.00026136709444148743,
        "gradient_norm": 0.3796398639678955,
        "train_loss": 3.1283035278320312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17944,
        "tokens": 9407823872,
        "learning_rate": 0.0002613393899889423,
        "gradient_norm": 0.36425092816352844,
        "train_loss": 3.1187846660614014,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17945,
        "tokens": 9408348160,
        "learning_rate": 0.0002613116863092578,
        "gradient_norm": 0.3858524560928345,
        "train_loss": 3.022921562194824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17946,
        "tokens": 9408872448,
        "learning_rate": 0.000261283983402746,
        "gradient_norm": 0.368705153465271,
        "train_loss": 3.056684970855713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17947,
        "tokens": 9409396736,
        "learning_rate": 0.0002612562812697186,
        "gradient_norm": 0.4000495374202728,
        "train_loss": 3.110567808151245,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17948,
        "tokens": 9409921024,
        "learning_rate": 0.0002612285799104875,
        "gradient_norm": 0.34466850757598877,
        "train_loss": 3.1147565841674805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17949,
        "tokens": 9410445312,
        "learning_rate": 0.0002612008793253643,
        "gradient_norm": 0.4003329575061798,
        "train_loss": 3.076491355895996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17950,
        "tokens": 9410969600,
        "learning_rate": 0.000261173179514661,
        "gradient_norm": 0.33922263979911804,
        "train_loss": 3.09454083442688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17951,
        "tokens": 9411493888,
        "learning_rate": 0.0002611454804786895,
        "gradient_norm": 0.3865620791912079,
        "train_loss": 3.0702338218688965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17952,
        "tokens": 9412018176,
        "learning_rate": 0.0002611177822177613,
        "gradient_norm": 0.35386839509010315,
        "train_loss": 3.092139720916748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17953,
        "tokens": 9412542464,
        "learning_rate": 0.00026109008473218845,
        "gradient_norm": 0.388901948928833,
        "train_loss": 3.0129661560058594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17954,
        "tokens": 9413066752,
        "learning_rate": 0.00026106238802228244,
        "gradient_norm": 0.35979747772216797,
        "train_loss": 3.058356761932373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17955,
        "tokens": 9413591040,
        "learning_rate": 0.0002610346920883554,
        "gradient_norm": 0.3769530951976776,
        "train_loss": 3.0881500244140625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17956,
        "tokens": 9414115328,
        "learning_rate": 0.0002610069969307187,
        "gradient_norm": 0.35356613993644714,
        "train_loss": 3.0855093002319336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17957,
        "tokens": 9414639616,
        "learning_rate": 0.00026097930254968436,
        "gradient_norm": 0.33686137199401855,
        "train_loss": 3.0952162742614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17958,
        "tokens": 9415163904,
        "learning_rate": 0.0002609516089455639,
        "gradient_norm": 0.33567845821380615,
        "train_loss": 3.130743980407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17959,
        "tokens": 9415688192,
        "learning_rate": 0.00026092391611866913,
        "gradient_norm": 0.3386746048927307,
        "train_loss": 3.045581340789795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17960,
        "tokens": 9416212480,
        "learning_rate": 0.0002608962240693119,
        "gradient_norm": 0.33254387974739075,
        "train_loss": 3.0662295818328857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17961,
        "tokens": 9416736768,
        "learning_rate": 0.0002608685327978038,
        "gradient_norm": 0.33016642928123474,
        "train_loss": 3.1087512969970703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17962,
        "tokens": 9417261056,
        "learning_rate": 0.00026084084230445647,
        "gradient_norm": 0.3469478189945221,
        "train_loss": 3.051729202270508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17963,
        "tokens": 9417785344,
        "learning_rate": 0.00026081315258958174,
        "gradient_norm": 0.32104501128196716,
        "train_loss": 3.053502082824707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17964,
        "tokens": 9418309632,
        "learning_rate": 0.0002607854636534912,
        "gradient_norm": 0.31781089305877686,
        "train_loss": 3.0608768463134766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17965,
        "tokens": 9418833920,
        "learning_rate": 0.00026075777549649647,
        "gradient_norm": 0.4245048463344574,
        "train_loss": 3.172999382019043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17966,
        "tokens": 9419358208,
        "learning_rate": 0.0002607300881189094,
        "gradient_norm": 0.4309495985507965,
        "train_loss": 3.079648971557617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17967,
        "tokens": 9419882496,
        "learning_rate": 0.0002607024015210415,
        "gradient_norm": 0.34980714321136475,
        "train_loss": 3.0878748893737793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17968,
        "tokens": 9420406784,
        "learning_rate": 0.0002606747157032044,
        "gradient_norm": 0.46339333057403564,
        "train_loss": 3.0996575355529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17969,
        "tokens": 9420931072,
        "learning_rate": 0.0002606470306657098,
        "gradient_norm": 0.41594013571739197,
        "train_loss": 3.0981740951538086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17970,
        "tokens": 9421455360,
        "learning_rate": 0.0002606193464088694,
        "gradient_norm": 0.3481917977333069,
        "train_loss": 3.0938072204589844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17971,
        "tokens": 9421979648,
        "learning_rate": 0.0002605916629329947,
        "gradient_norm": 0.38042813539505005,
        "train_loss": 3.0799400806427,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17972,
        "tokens": 9422503936,
        "learning_rate": 0.0002605639802383973,
        "gradient_norm": 0.3582376539707184,
        "train_loss": 3.0665712356567383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17973,
        "tokens": 9423028224,
        "learning_rate": 0.00026053629832538893,
        "gradient_norm": 0.3138374090194702,
        "train_loss": 3.1331543922424316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17974,
        "tokens": 9423552512,
        "learning_rate": 0.00026050861719428104,
        "gradient_norm": 0.3272159695625305,
        "train_loss": 3.073685646057129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17975,
        "tokens": 9424076800,
        "learning_rate": 0.0002604809368453854,
        "gradient_norm": 0.36639606952667236,
        "train_loss": 3.126633644104004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17976,
        "tokens": 9424601088,
        "learning_rate": 0.0002604532572790133,
        "gradient_norm": 0.3537086844444275,
        "train_loss": 3.0645601749420166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17977,
        "tokens": 9425125376,
        "learning_rate": 0.0002604255784954767,
        "gradient_norm": 0.45803505182266235,
        "train_loss": 3.3043642044067383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17978,
        "tokens": 9425649664,
        "learning_rate": 0.00026039790049508675,
        "gradient_norm": 0.3958653211593628,
        "train_loss": 3.093381881713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17979,
        "tokens": 9426173952,
        "learning_rate": 0.0002603702232781552,
        "gradient_norm": 0.381788045167923,
        "train_loss": 3.0934934616088867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17980,
        "tokens": 9426698240,
        "learning_rate": 0.0002603425468449937,
        "gradient_norm": 0.37256017327308655,
        "train_loss": 3.1132078170776367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17981,
        "tokens": 9427222528,
        "learning_rate": 0.0002603148711959136,
        "gradient_norm": 0.37544557452201843,
        "train_loss": 3.070249319076538,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17982,
        "tokens": 9427746816,
        "learning_rate": 0.00026028719633122656,
        "gradient_norm": 0.32959064841270447,
        "train_loss": 3.149102210998535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17983,
        "tokens": 9428271104,
        "learning_rate": 0.00026025952225124387,
        "gradient_norm": 0.3701730966567993,
        "train_loss": 3.0516819953918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17984,
        "tokens": 9428795392,
        "learning_rate": 0.00026023184895627733,
        "gradient_norm": 0.34015390276908875,
        "train_loss": 3.0607526302337646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17985,
        "tokens": 9429319680,
        "learning_rate": 0.0002602041764466382,
        "gradient_norm": 0.32984820008277893,
        "train_loss": 3.098644733428955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17986,
        "tokens": 9429843968,
        "learning_rate": 0.00026017650472263823,
        "gradient_norm": 0.3145376145839691,
        "train_loss": 3.0867671966552734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17987,
        "tokens": 9430368256,
        "learning_rate": 0.00026014883378458855,
        "gradient_norm": 0.327623575925827,
        "train_loss": 3.0706543922424316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17988,
        "tokens": 9430892544,
        "learning_rate": 0.000260121163632801,
        "gradient_norm": 0.33092594146728516,
        "train_loss": 3.10374116897583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17989,
        "tokens": 9431416832,
        "learning_rate": 0.0002600934942675867,
        "gradient_norm": 0.314609169960022,
        "train_loss": 3.065173625946045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17990,
        "tokens": 9431941120,
        "learning_rate": 0.0002600658256892572,
        "gradient_norm": 0.33620065450668335,
        "train_loss": 3.0564136505126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17991,
        "tokens": 9432465408,
        "learning_rate": 0.00026003815789812424,
        "gradient_norm": 0.33713990449905396,
        "train_loss": 3.1043925285339355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17992,
        "tokens": 9432989696,
        "learning_rate": 0.00026001049089449885,
        "gradient_norm": 0.3193104565143585,
        "train_loss": 3.0185179710388184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17993,
        "tokens": 9433513984,
        "learning_rate": 0.00025998282467869276,
        "gradient_norm": 0.34379926323890686,
        "train_loss": 3.053955554962158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17994,
        "tokens": 9434038272,
        "learning_rate": 0.0002599551592510171,
        "gradient_norm": 0.39496564865112305,
        "train_loss": 3.0732240676879883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17995,
        "tokens": 9434562560,
        "learning_rate": 0.0002599274946117836,
        "gradient_norm": 0.3469618260860443,
        "train_loss": 3.049867630004883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17996,
        "tokens": 9435086848,
        "learning_rate": 0.00025989983076130335,
        "gradient_norm": 0.3154664933681488,
        "train_loss": 3.0143322944641113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17997,
        "tokens": 9435611136,
        "learning_rate": 0.000259872167699888,
        "gradient_norm": 0.3532142639160156,
        "train_loss": 3.1338419914245605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17998,
        "tokens": 9436135424,
        "learning_rate": 0.00025984450542784873,
        "gradient_norm": 0.34280574321746826,
        "train_loss": 3.104743719100952,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 17999,
        "tokens": 9436659712,
        "learning_rate": 0.000259816843945497,
        "gradient_norm": 0.3302885591983795,
        "train_loss": 3.0957911014556885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18000,
        "tokens": 9437184000,
        "learning_rate": 0.0002597891832531443,
        "gradient_norm": 0.37128469347953796,
        "train_loss": 3.0517678260803223,
        "val_loss": 3.040520191192627,
        "hellaswag_acc": 0.28121888637542725,
        "hellaswag_acc_norm": 0.28858792781829834
    },
    {
        "step": 18001,
        "tokens": 9437708288,
        "learning_rate": 0.0002597615233511017,
        "gradient_norm": 0.3447263538837433,
        "train_loss": 3.1003165245056152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18002,
        "tokens": 9438232576,
        "learning_rate": 0.00025973386423968085,
        "gradient_norm": 0.34064343571662903,
        "train_loss": 3.083773612976074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18003,
        "tokens": 9438756864,
        "learning_rate": 0.0002597062059191929,
        "gradient_norm": 0.3522875905036926,
        "train_loss": 3.107081890106201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18004,
        "tokens": 9439281152,
        "learning_rate": 0.00025967854838994923,
        "gradient_norm": 0.3307606875896454,
        "train_loss": 3.0861682891845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18005,
        "tokens": 9439805440,
        "learning_rate": 0.0002596508916522611,
        "gradient_norm": 0.32571327686309814,
        "train_loss": 3.0569169521331787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18006,
        "tokens": 9440329728,
        "learning_rate": 0.00025962323570644,
        "gradient_norm": 0.33860456943511963,
        "train_loss": 3.0556201934814453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18007,
        "tokens": 9440854016,
        "learning_rate": 0.00025959558055279697,
        "gradient_norm": 0.3262825608253479,
        "train_loss": 3.1099939346313477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18008,
        "tokens": 9441378304,
        "learning_rate": 0.0002595679261916435,
        "gradient_norm": 0.38061457872390747,
        "train_loss": 3.0926971435546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18009,
        "tokens": 9441902592,
        "learning_rate": 0.00025954027262329086,
        "gradient_norm": 0.3801274001598358,
        "train_loss": 3.0199522972106934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18010,
        "tokens": 9442426880,
        "learning_rate": 0.0002595126198480502,
        "gradient_norm": 0.3695376515388489,
        "train_loss": 3.0714824199676514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18011,
        "tokens": 9442951168,
        "learning_rate": 0.00025948496786623294,
        "gradient_norm": 0.35760554671287537,
        "train_loss": 3.0807433128356934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18012,
        "tokens": 9443475456,
        "learning_rate": 0.0002594573166781502,
        "gradient_norm": 0.41846877336502075,
        "train_loss": 3.0869622230529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18013,
        "tokens": 9443999744,
        "learning_rate": 0.0002594296662841133,
        "gradient_norm": 0.3727530539035797,
        "train_loss": 3.0567712783813477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18014,
        "tokens": 9444524032,
        "learning_rate": 0.00025940201668443356,
        "gradient_norm": 0.33653783798217773,
        "train_loss": 3.0635151863098145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18015,
        "tokens": 9445048320,
        "learning_rate": 0.00025937436787942206,
        "gradient_norm": 0.3803379535675049,
        "train_loss": 3.0904784202575684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18016,
        "tokens": 9445572608,
        "learning_rate": 0.0002593467198693901,
        "gradient_norm": 0.29939860105514526,
        "train_loss": 3.0833206176757812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18017,
        "tokens": 9446096896,
        "learning_rate": 0.00025931907265464883,
        "gradient_norm": 0.3695926070213318,
        "train_loss": 3.0870230197906494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18018,
        "tokens": 9446621184,
        "learning_rate": 0.0002592914262355096,
        "gradient_norm": 0.3074624836444855,
        "train_loss": 3.0775656700134277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18019,
        "tokens": 9447145472,
        "learning_rate": 0.0002592637806122834,
        "gradient_norm": 0.38207629323005676,
        "train_loss": 3.1031603813171387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18020,
        "tokens": 9447669760,
        "learning_rate": 0.00025923613578528166,
        "gradient_norm": 0.3038111925125122,
        "train_loss": 3.0760011672973633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18021,
        "tokens": 9448194048,
        "learning_rate": 0.00025920849175481523,
        "gradient_norm": 0.32851237058639526,
        "train_loss": 3.0918755531311035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18022,
        "tokens": 9448718336,
        "learning_rate": 0.00025918084852119566,
        "gradient_norm": 0.39408183097839355,
        "train_loss": 3.125075101852417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18023,
        "tokens": 9449242624,
        "learning_rate": 0.00025915320608473384,
        "gradient_norm": 0.43977075815200806,
        "train_loss": 3.039074420928955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18024,
        "tokens": 9449766912,
        "learning_rate": 0.00025912556444574104,
        "gradient_norm": 0.3290596902370453,
        "train_loss": 3.091614246368408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18025,
        "tokens": 9450291200,
        "learning_rate": 0.00025909792360452827,
        "gradient_norm": 0.42515504360198975,
        "train_loss": 3.108461618423462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18026,
        "tokens": 9450815488,
        "learning_rate": 0.0002590702835614068,
        "gradient_norm": 0.35241609811782837,
        "train_loss": 3.088535785675049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18027,
        "tokens": 9451339776,
        "learning_rate": 0.0002590426443166877,
        "gradient_norm": 0.34200921654701233,
        "train_loss": 3.062775135040283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18028,
        "tokens": 9451864064,
        "learning_rate": 0.0002590150058706821,
        "gradient_norm": 0.3361821174621582,
        "train_loss": 3.073235034942627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18029,
        "tokens": 9452388352,
        "learning_rate": 0.00025898736822370106,
        "gradient_norm": 0.3595048189163208,
        "train_loss": 3.0873405933380127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18030,
        "tokens": 9452912640,
        "learning_rate": 0.00025895973137605565,
        "gradient_norm": 0.33673936128616333,
        "train_loss": 3.0593225955963135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18031,
        "tokens": 9453436928,
        "learning_rate": 0.0002589320953280572,
        "gradient_norm": 0.32699763774871826,
        "train_loss": 3.1082067489624023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18032,
        "tokens": 9453961216,
        "learning_rate": 0.0002589044600800164,
        "gradient_norm": 0.33094528317451477,
        "train_loss": 3.099853038787842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18033,
        "tokens": 9454485504,
        "learning_rate": 0.00025887682563224476,
        "gradient_norm": 0.3327834904193878,
        "train_loss": 3.0721237659454346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18034,
        "tokens": 9455009792,
        "learning_rate": 0.00025884919198505287,
        "gradient_norm": 0.32727813720703125,
        "train_loss": 3.113882541656494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18035,
        "tokens": 9455534080,
        "learning_rate": 0.00025882155913875223,
        "gradient_norm": 0.3539220690727234,
        "train_loss": 3.0799334049224854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18036,
        "tokens": 9456058368,
        "learning_rate": 0.00025879392709365353,
        "gradient_norm": 0.3040081262588501,
        "train_loss": 3.102876663208008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18037,
        "tokens": 9456582656,
        "learning_rate": 0.00025876629585006803,
        "gradient_norm": 0.37444978952407837,
        "train_loss": 3.0995235443115234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18038,
        "tokens": 9457106944,
        "learning_rate": 0.00025873866540830653,
        "gradient_norm": 0.7655528783798218,
        "train_loss": 2.964724540710449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18039,
        "tokens": 9457631232,
        "learning_rate": 0.0002587110357686802,
        "gradient_norm": 0.4195021092891693,
        "train_loss": 3.083735942840576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18040,
        "tokens": 9458155520,
        "learning_rate": 0.00025868340693150016,
        "gradient_norm": 0.39662882685661316,
        "train_loss": 3.0914740562438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18041,
        "tokens": 9458679808,
        "learning_rate": 0.00025865577889707715,
        "gradient_norm": 0.36708420515060425,
        "train_loss": 3.12001371383667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18042,
        "tokens": 9459204096,
        "learning_rate": 0.0002586281516657224,
        "gradient_norm": 0.3944169580936432,
        "train_loss": 3.095104932785034,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18043,
        "tokens": 9459728384,
        "learning_rate": 0.00025860052523774663,
        "gradient_norm": 0.5179060697555542,
        "train_loss": 3.1539852619171143,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18044,
        "tokens": 9460252672,
        "learning_rate": 0.0002585728996134611,
        "gradient_norm": 0.3959152102470398,
        "train_loss": 3.0746681690216064,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18045,
        "tokens": 9460776960,
        "learning_rate": 0.0002585452747931765,
        "gradient_norm": 0.3793018162250519,
        "train_loss": 3.132327079772949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18046,
        "tokens": 9461301248,
        "learning_rate": 0.000258517650777204,
        "gradient_norm": 0.33725547790527344,
        "train_loss": 3.1027722358703613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18047,
        "tokens": 9461825536,
        "learning_rate": 0.00025849002756585433,
        "gradient_norm": 0.3850157856941223,
        "train_loss": 3.101146697998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18048,
        "tokens": 9462349824,
        "learning_rate": 0.00025846240515943865,
        "gradient_norm": 0.36402976512908936,
        "train_loss": 3.0700783729553223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18049,
        "tokens": 9462874112,
        "learning_rate": 0.0002584347835582676,
        "gradient_norm": 0.4049549102783203,
        "train_loss": 3.1034860610961914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18050,
        "tokens": 9463398400,
        "learning_rate": 0.0002584071627626524,
        "gradient_norm": 0.3741692304611206,
        "train_loss": 3.0789682865142822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18051,
        "tokens": 9463922688,
        "learning_rate": 0.00025837954277290387,
        "gradient_norm": 0.3229074478149414,
        "train_loss": 3.08945369720459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18052,
        "tokens": 9464446976,
        "learning_rate": 0.00025835192358933276,
        "gradient_norm": 0.3942388594150543,
        "train_loss": 3.080235004425049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18053,
        "tokens": 9464971264,
        "learning_rate": 0.0002583243052122502,
        "gradient_norm": 0.34589359164237976,
        "train_loss": 3.104609489440918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18054,
        "tokens": 9465495552,
        "learning_rate": 0.0002582966876419668,
        "gradient_norm": 0.38184067606925964,
        "train_loss": 3.0920352935791016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18055,
        "tokens": 9466019840,
        "learning_rate": 0.0002582690708787936,
        "gradient_norm": 0.34406188130378723,
        "train_loss": 3.061910629272461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18056,
        "tokens": 9466544128,
        "learning_rate": 0.0002582414549230414,
        "gradient_norm": 0.42197880148887634,
        "train_loss": 3.060396194458008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18057,
        "tokens": 9467068416,
        "learning_rate": 0.0002582138397750212,
        "gradient_norm": 0.32404154539108276,
        "train_loss": 3.045804023742676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18058,
        "tokens": 9467592704,
        "learning_rate": 0.00025818622543504356,
        "gradient_norm": 0.35907649993896484,
        "train_loss": 3.0959091186523438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18059,
        "tokens": 9468116992,
        "learning_rate": 0.0002581586119034195,
        "gradient_norm": 0.36090365052223206,
        "train_loss": 3.056286334991455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18060,
        "tokens": 9468641280,
        "learning_rate": 0.0002581309991804599,
        "gradient_norm": 0.34340640902519226,
        "train_loss": 3.0843005180358887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18061,
        "tokens": 9469165568,
        "learning_rate": 0.00025810338726647543,
        "gradient_norm": 0.3950949013233185,
        "train_loss": 3.09611177444458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18062,
        "tokens": 9469689856,
        "learning_rate": 0.00025807577616177696,
        "gradient_norm": 0.3482772707939148,
        "train_loss": 3.0991556644439697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18063,
        "tokens": 9470214144,
        "learning_rate": 0.0002580481658666753,
        "gradient_norm": 0.3852179944515228,
        "train_loss": 3.054847240447998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18064,
        "tokens": 9470738432,
        "learning_rate": 0.0002580205563814812,
        "gradient_norm": 0.35116809606552124,
        "train_loss": 3.0842647552490234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18065,
        "tokens": 9471262720,
        "learning_rate": 0.00025799294770650547,
        "gradient_norm": 0.34272584319114685,
        "train_loss": 3.119439125061035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18066,
        "tokens": 9471787008,
        "learning_rate": 0.00025796533984205893,
        "gradient_norm": 0.302334725856781,
        "train_loss": 3.1027896404266357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18067,
        "tokens": 9472311296,
        "learning_rate": 0.0002579377327884522,
        "gradient_norm": 0.36392414569854736,
        "train_loss": 3.0780463218688965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18068,
        "tokens": 9472835584,
        "learning_rate": 0.0002579101265459962,
        "gradient_norm": 0.29982396960258484,
        "train_loss": 3.1032116413116455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18069,
        "tokens": 9473359872,
        "learning_rate": 0.0002578825211150015,
        "gradient_norm": 0.3766520321369171,
        "train_loss": 3.1594600677490234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18070,
        "tokens": 9473884160,
        "learning_rate": 0.0002578549164957789,
        "gradient_norm": 0.3071945905685425,
        "train_loss": 3.0511598587036133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18071,
        "tokens": 9474408448,
        "learning_rate": 0.0002578273126886393,
        "gradient_norm": 0.36293360590934753,
        "train_loss": 3.0384297370910645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18072,
        "tokens": 9474932736,
        "learning_rate": 0.00025779970969389313,
        "gradient_norm": 0.3199250400066376,
        "train_loss": 3.0536043643951416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18073,
        "tokens": 9475457024,
        "learning_rate": 0.0002577721075118513,
        "gradient_norm": 0.3247928321361542,
        "train_loss": 3.0493767261505127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18074,
        "tokens": 9475981312,
        "learning_rate": 0.00025774450614282434,
        "gradient_norm": 0.3104100227355957,
        "train_loss": 3.0734729766845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18075,
        "tokens": 9476505600,
        "learning_rate": 0.00025771690558712315,
        "gradient_norm": 0.3314211964607239,
        "train_loss": 3.124148368835449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18076,
        "tokens": 9477029888,
        "learning_rate": 0.0002576893058450582,
        "gradient_norm": 0.2987198233604431,
        "train_loss": 3.075061321258545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18077,
        "tokens": 9477554176,
        "learning_rate": 0.0002576617069169403,
        "gradient_norm": 0.3154730796813965,
        "train_loss": 3.0595192909240723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18078,
        "tokens": 9478078464,
        "learning_rate": 0.00025763410880308,
        "gradient_norm": 0.34731048345565796,
        "train_loss": 3.044524908065796,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18079,
        "tokens": 9478602752,
        "learning_rate": 0.00025760651150378796,
        "gradient_norm": 0.3176942467689514,
        "train_loss": 3.162092447280884,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18080,
        "tokens": 9479127040,
        "learning_rate": 0.0002575789150193751,
        "gradient_norm": 0.34725889563560486,
        "train_loss": 3.1270265579223633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18081,
        "tokens": 9479651328,
        "learning_rate": 0.0002575513193501516,
        "gradient_norm": 0.3244940936565399,
        "train_loss": 3.105436325073242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18082,
        "tokens": 9480175616,
        "learning_rate": 0.00025752372449642846,
        "gradient_norm": 0.34917697310447693,
        "train_loss": 3.040456533432007,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18083,
        "tokens": 9480699904,
        "learning_rate": 0.000257496130458516,
        "gradient_norm": 0.34229302406311035,
        "train_loss": 3.063978672027588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18084,
        "tokens": 9481224192,
        "learning_rate": 0.00025746853723672517,
        "gradient_norm": 0.3438918888568878,
        "train_loss": 3.087792158126831,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18085,
        "tokens": 9481748480,
        "learning_rate": 0.0002574409448313662,
        "gradient_norm": 0.3308762311935425,
        "train_loss": 3.1022119522094727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18086,
        "tokens": 9482272768,
        "learning_rate": 0.00025741335324275,
        "gradient_norm": 0.3236595392227173,
        "train_loss": 3.0541508197784424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18087,
        "tokens": 9482797056,
        "learning_rate": 0.0002573857624711868,
        "gradient_norm": 0.3142557740211487,
        "train_loss": 3.030155658721924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18088,
        "tokens": 9483321344,
        "learning_rate": 0.0002573581725169875,
        "gradient_norm": 0.33732300996780396,
        "train_loss": 3.0842208862304688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18089,
        "tokens": 9483845632,
        "learning_rate": 0.00025733058338046243,
        "gradient_norm": 0.409626305103302,
        "train_loss": 3.2605957984924316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18090,
        "tokens": 9484369920,
        "learning_rate": 0.00025730299506192223,
        "gradient_norm": 0.37700366973876953,
        "train_loss": 3.034362316131592,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18091,
        "tokens": 9484894208,
        "learning_rate": 0.0002572754075616775,
        "gradient_norm": 0.34152594208717346,
        "train_loss": 3.071536064147949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18092,
        "tokens": 9485418496,
        "learning_rate": 0.00025724782088003864,
        "gradient_norm": 0.4297848641872406,
        "train_loss": 3.10626220703125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18093,
        "tokens": 9485942784,
        "learning_rate": 0.0002572202350173163,
        "gradient_norm": 0.40553155541419983,
        "train_loss": 3.0940752029418945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18094,
        "tokens": 9486467072,
        "learning_rate": 0.0002571926499738209,
        "gradient_norm": 0.43613675236701965,
        "train_loss": 3.12559175491333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18095,
        "tokens": 9486991360,
        "learning_rate": 0.0002571650657498631,
        "gradient_norm": 0.40957140922546387,
        "train_loss": 3.065861940383911,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18096,
        "tokens": 9487515648,
        "learning_rate": 0.00025713748234575313,
        "gradient_norm": 0.3696303069591522,
        "train_loss": 3.061692237854004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18097,
        "tokens": 9488039936,
        "learning_rate": 0.00025710989976180173,
        "gradient_norm": 0.3909032344818115,
        "train_loss": 3.03139066696167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18098,
        "tokens": 9488564224,
        "learning_rate": 0.0002570823179983192,
        "gradient_norm": 0.32533568143844604,
        "train_loss": 3.071384906768799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18099,
        "tokens": 9489088512,
        "learning_rate": 0.000257054737055616,
        "gradient_norm": 0.3885178864002228,
        "train_loss": 3.0761733055114746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18100,
        "tokens": 9489612800,
        "learning_rate": 0.00025702715693400285,
        "gradient_norm": 0.3404386043548584,
        "train_loss": 3.0220203399658203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18101,
        "tokens": 9490137088,
        "learning_rate": 0.0002569995776337898,
        "gradient_norm": 0.4153738021850586,
        "train_loss": 3.156425952911377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18102,
        "tokens": 9490661376,
        "learning_rate": 0.00025697199915528774,
        "gradient_norm": 0.3992140293121338,
        "train_loss": 3.099177360534668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18103,
        "tokens": 9491185664,
        "learning_rate": 0.00025694442149880667,
        "gradient_norm": 0.32808220386505127,
        "train_loss": 2.998809814453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18104,
        "tokens": 9491709952,
        "learning_rate": 0.00025691684466465733,
        "gradient_norm": 0.3458353877067566,
        "train_loss": 3.0788912773132324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18105,
        "tokens": 9492234240,
        "learning_rate": 0.0002568892686531499,
        "gradient_norm": 0.31583476066589355,
        "train_loss": 3.078357219696045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18106,
        "tokens": 9492758528,
        "learning_rate": 0.000256861693464595,
        "gradient_norm": 0.3719070851802826,
        "train_loss": 3.085798740386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18107,
        "tokens": 9493282816,
        "learning_rate": 0.0002568341190993028,
        "gradient_norm": 0.3490002751350403,
        "train_loss": 3.1110177040100098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18108,
        "tokens": 9493807104,
        "learning_rate": 0.00025680654555758386,
        "gradient_norm": 0.36614492535591125,
        "train_loss": 3.0930237770080566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18109,
        "tokens": 9494331392,
        "learning_rate": 0.0002567789728397484,
        "gradient_norm": 0.36028149724006653,
        "train_loss": 3.053694486618042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18110,
        "tokens": 9494855680,
        "learning_rate": 0.000256751400946107,
        "gradient_norm": 0.3645092248916626,
        "train_loss": 3.095400810241699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18111,
        "tokens": 9495379968,
        "learning_rate": 0.0002567238298769698,
        "gradient_norm": 0.3676161766052246,
        "train_loss": 3.1189017295837402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18112,
        "tokens": 9495904256,
        "learning_rate": 0.00025669625963264725,
        "gradient_norm": 0.3629384934902191,
        "train_loss": 3.1176648139953613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18113,
        "tokens": 9496428544,
        "learning_rate": 0.0002566686902134497,
        "gradient_norm": 0.3605892062187195,
        "train_loss": 3.0369210243225098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18114,
        "tokens": 9496952832,
        "learning_rate": 0.00025664112161968736,
        "gradient_norm": 0.36461693048477173,
        "train_loss": 3.1046934127807617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18115,
        "tokens": 9497477120,
        "learning_rate": 0.00025661355385167073,
        "gradient_norm": 0.36827149987220764,
        "train_loss": 3.1457457542419434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18116,
        "tokens": 9498001408,
        "learning_rate": 0.00025658598690971,
        "gradient_norm": 0.3482213020324707,
        "train_loss": 3.0745151042938232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18117,
        "tokens": 9498525696,
        "learning_rate": 0.0002565584207941156,
        "gradient_norm": 0.4142325818538666,
        "train_loss": 3.002826690673828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18118,
        "tokens": 9499049984,
        "learning_rate": 0.00025653085550519754,
        "gradient_norm": 0.33412155508995056,
        "train_loss": 3.0794169902801514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18119,
        "tokens": 9499574272,
        "learning_rate": 0.0002565032910432664,
        "gradient_norm": 0.397222101688385,
        "train_loss": 3.0824131965637207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18120,
        "tokens": 9500098560,
        "learning_rate": 0.00025647572740863234,
        "gradient_norm": 0.38106849789619446,
        "train_loss": 3.0998287200927734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18121,
        "tokens": 9500622848,
        "learning_rate": 0.0002564481646016056,
        "gradient_norm": 0.4291824400424957,
        "train_loss": 3.060492515563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18122,
        "tokens": 9501147136,
        "learning_rate": 0.00025642060262249643,
        "gradient_norm": 0.3524666726589203,
        "train_loss": 3.0579190254211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18123,
        "tokens": 9501671424,
        "learning_rate": 0.00025639304147161515,
        "gradient_norm": 0.37802648544311523,
        "train_loss": 3.0696771144866943,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18124,
        "tokens": 9502195712,
        "learning_rate": 0.0002563654811492719,
        "gradient_norm": 0.358021080493927,
        "train_loss": 3.0351758003234863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18125,
        "tokens": 9502720000,
        "learning_rate": 0.0002563379216557769,
        "gradient_norm": 0.3265177309513092,
        "train_loss": 3.108062267303467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18126,
        "tokens": 9503244288,
        "learning_rate": 0.00025631036299144055,
        "gradient_norm": 0.37795522809028625,
        "train_loss": 3.1018943786621094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18127,
        "tokens": 9503768576,
        "learning_rate": 0.00025628280515657275,
        "gradient_norm": 0.29562908411026,
        "train_loss": 3.0437958240509033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18128,
        "tokens": 9504292864,
        "learning_rate": 0.000256255248151484,
        "gradient_norm": 0.3871719241142273,
        "train_loss": 3.022645950317383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18129,
        "tokens": 9504817152,
        "learning_rate": 0.00025622769197648434,
        "gradient_norm": 0.30412718653678894,
        "train_loss": 3.0743911266326904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18130,
        "tokens": 9505341440,
        "learning_rate": 0.00025620013663188386,
        "gradient_norm": 0.352577269077301,
        "train_loss": 3.0835819244384766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18131,
        "tokens": 9505865728,
        "learning_rate": 0.000256172582117993,
        "gradient_norm": 0.3622322380542755,
        "train_loss": 2.995328426361084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18132,
        "tokens": 9506390016,
        "learning_rate": 0.0002561450284351216,
        "gradient_norm": 0.31538015604019165,
        "train_loss": 3.1131532192230225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18133,
        "tokens": 9506914304,
        "learning_rate": 0.0002561174755835801,
        "gradient_norm": 0.3338753879070282,
        "train_loss": 3.0752265453338623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18134,
        "tokens": 9507438592,
        "learning_rate": 0.00025608992356367837,
        "gradient_norm": 0.2986240088939667,
        "train_loss": 3.0002870559692383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18135,
        "tokens": 9507962880,
        "learning_rate": 0.00025606237237572687,
        "gradient_norm": 0.3482341468334198,
        "train_loss": 3.0967507362365723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18136,
        "tokens": 9508487168,
        "learning_rate": 0.00025603482202003536,
        "gradient_norm": 0.32138797640800476,
        "train_loss": 3.1333770751953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18137,
        "tokens": 9509011456,
        "learning_rate": 0.0002560072724969143,
        "gradient_norm": 0.4006468951702118,
        "train_loss": 3.0976428985595703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18138,
        "tokens": 9509535744,
        "learning_rate": 0.0002559797238066734,
        "gradient_norm": 0.34402063488960266,
        "train_loss": 3.1020007133483887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18139,
        "tokens": 9510060032,
        "learning_rate": 0.0002559521759496231,
        "gradient_norm": 0.3372669219970703,
        "train_loss": 3.072359800338745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18140,
        "tokens": 9510584320,
        "learning_rate": 0.00025592462892607337,
        "gradient_norm": 0.33025792241096497,
        "train_loss": 3.0906381607055664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18141,
        "tokens": 9511108608,
        "learning_rate": 0.0002558970827363342,
        "gradient_norm": 0.33536407351493835,
        "train_loss": 3.093078374862671,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18142,
        "tokens": 9511632896,
        "learning_rate": 0.0002558695373807158,
        "gradient_norm": 0.33054766058921814,
        "train_loss": 3.0330917835235596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18143,
        "tokens": 9512157184,
        "learning_rate": 0.00025584199285952813,
        "gradient_norm": 0.307496041059494,
        "train_loss": 3.0851526260375977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18144,
        "tokens": 9512681472,
        "learning_rate": 0.00025581444917308137,
        "gradient_norm": 0.3131212592124939,
        "train_loss": 3.070779800415039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18145,
        "tokens": 9513205760,
        "learning_rate": 0.0002557869063216854,
        "gradient_norm": 0.3265473246574402,
        "train_loss": 3.0707898139953613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18146,
        "tokens": 9513730048,
        "learning_rate": 0.00025575936430565036,
        "gradient_norm": 0.346680611371994,
        "train_loss": 3.0656864643096924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18147,
        "tokens": 9514254336,
        "learning_rate": 0.00025573182312528607,
        "gradient_norm": 0.3245358169078827,
        "train_loss": 3.0930700302124023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18148,
        "tokens": 9514778624,
        "learning_rate": 0.00025570428278090285,
        "gradient_norm": 0.4221701920032501,
        "train_loss": 3.0795412063598633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18149,
        "tokens": 9515302912,
        "learning_rate": 0.0002556767432728104,
        "gradient_norm": 0.37111419439315796,
        "train_loss": 3.0907578468322754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18150,
        "tokens": 9515827200,
        "learning_rate": 0.0002556492046013189,
        "gradient_norm": 0.33334487676620483,
        "train_loss": 3.1303060054779053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18151,
        "tokens": 9516351488,
        "learning_rate": 0.0002556216667667383,
        "gradient_norm": 0.4081341028213501,
        "train_loss": 3.0769824981689453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18152,
        "tokens": 9516875776,
        "learning_rate": 0.00025559412976937856,
        "gradient_norm": 0.36780989170074463,
        "train_loss": 3.088139533996582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18153,
        "tokens": 9517400064,
        "learning_rate": 0.0002555665936095497,
        "gradient_norm": 0.322793573141098,
        "train_loss": 3.104252338409424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18154,
        "tokens": 9517924352,
        "learning_rate": 0.00025553905828756146,
        "gradient_norm": 0.3677103817462921,
        "train_loss": 3.0510663986206055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18155,
        "tokens": 9518448640,
        "learning_rate": 0.00025551152380372407,
        "gradient_norm": 0.3263462483882904,
        "train_loss": 3.081794500350952,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18156,
        "tokens": 9518972928,
        "learning_rate": 0.0002554839901583473,
        "gradient_norm": 0.4038146734237671,
        "train_loss": 3.073314905166626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18157,
        "tokens": 9519497216,
        "learning_rate": 0.0002554564573517411,
        "gradient_norm": 0.33545705676078796,
        "train_loss": 3.056304454803467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18158,
        "tokens": 9520021504,
        "learning_rate": 0.00025542892538421536,
        "gradient_norm": 0.35042718052864075,
        "train_loss": 3.0256290435791016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18159,
        "tokens": 9520545792,
        "learning_rate": 0.00025540139425608,
        "gradient_norm": 0.3327075242996216,
        "train_loss": 3.1292152404785156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18160,
        "tokens": 9521070080,
        "learning_rate": 0.000255373863967645,
        "gradient_norm": 0.35220593214035034,
        "train_loss": 3.0432026386260986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18161,
        "tokens": 9521594368,
        "learning_rate": 0.00025534633451922015,
        "gradient_norm": 0.3652717173099518,
        "train_loss": 3.0735464096069336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18162,
        "tokens": 9522118656,
        "learning_rate": 0.00025531880591111544,
        "gradient_norm": 0.35266703367233276,
        "train_loss": 3.164463520050049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18163,
        "tokens": 9522642944,
        "learning_rate": 0.00025529127814364054,
        "gradient_norm": 0.35622406005859375,
        "train_loss": 3.0904104709625244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18164,
        "tokens": 9523167232,
        "learning_rate": 0.0002552637512171056,
        "gradient_norm": 0.33905425667762756,
        "train_loss": 3.081646203994751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18165,
        "tokens": 9523691520,
        "learning_rate": 0.00025523622513182014,
        "gradient_norm": 0.36196061968803406,
        "train_loss": 3.029064655303955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18166,
        "tokens": 9524215808,
        "learning_rate": 0.00025520869988809424,
        "gradient_norm": 0.3346433639526367,
        "train_loss": 3.0444633960723877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18167,
        "tokens": 9524740096,
        "learning_rate": 0.00025518117548623757,
        "gradient_norm": 0.36959710717201233,
        "train_loss": 3.025958776473999,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18168,
        "tokens": 9525264384,
        "learning_rate": 0.00025515365192656014,
        "gradient_norm": 0.35751304030418396,
        "train_loss": 3.033172607421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18169,
        "tokens": 9525788672,
        "learning_rate": 0.00025512612920937155,
        "gradient_norm": 0.34629639983177185,
        "train_loss": 3.073237895965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18170,
        "tokens": 9526312960,
        "learning_rate": 0.00025509860733498183,
        "gradient_norm": 0.37688639760017395,
        "train_loss": 3.0751163959503174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18171,
        "tokens": 9526837248,
        "learning_rate": 0.00025507108630370057,
        "gradient_norm": 0.35158950090408325,
        "train_loss": 3.0986828804016113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18172,
        "tokens": 9527361536,
        "learning_rate": 0.00025504356611583763,
        "gradient_norm": 0.3645872473716736,
        "train_loss": 3.0711565017700195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18173,
        "tokens": 9527885824,
        "learning_rate": 0.0002550160467717029,
        "gradient_norm": 0.3222593069076538,
        "train_loss": 3.072242021560669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18174,
        "tokens": 9528410112,
        "learning_rate": 0.00025498852827160587,
        "gradient_norm": 0.3612031042575836,
        "train_loss": 3.049686908721924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18175,
        "tokens": 9528934400,
        "learning_rate": 0.00025496101061585656,
        "gradient_norm": 0.37492406368255615,
        "train_loss": 3.050908088684082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18176,
        "tokens": 9529458688,
        "learning_rate": 0.0002549334938047646,
        "gradient_norm": 0.3347737193107605,
        "train_loss": 3.048692226409912,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18177,
        "tokens": 9529982976,
        "learning_rate": 0.00025490597783863974,
        "gradient_norm": 0.41067183017730713,
        "train_loss": 3.0799155235290527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18178,
        "tokens": 9530507264,
        "learning_rate": 0.00025487846271779176,
        "gradient_norm": 0.3101222813129425,
        "train_loss": 3.066669464111328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18179,
        "tokens": 9531031552,
        "learning_rate": 0.0002548509484425302,
        "gradient_norm": 0.33148378133773804,
        "train_loss": 3.1229262351989746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18180,
        "tokens": 9531555840,
        "learning_rate": 0.00025482343501316497,
        "gradient_norm": 0.33069556951522827,
        "train_loss": 3.043818950653076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18181,
        "tokens": 9532080128,
        "learning_rate": 0.0002547959224300056,
        "gradient_norm": 0.30605435371398926,
        "train_loss": 3.0819036960601807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18182,
        "tokens": 9532604416,
        "learning_rate": 0.00025476841069336197,
        "gradient_norm": 0.3314276933670044,
        "train_loss": 3.1456079483032227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18183,
        "tokens": 9533128704,
        "learning_rate": 0.0002547408998035436,
        "gradient_norm": 0.3437857925891876,
        "train_loss": 3.0649514198303223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18184,
        "tokens": 9533652992,
        "learning_rate": 0.00025471338976086036,
        "gradient_norm": 0.3272598385810852,
        "train_loss": 3.1120638847351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18185,
        "tokens": 9534177280,
        "learning_rate": 0.00025468588056562155,
        "gradient_norm": 0.34382230043411255,
        "train_loss": 3.0364906787872314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18186,
        "tokens": 9534701568,
        "learning_rate": 0.0002546583722181372,
        "gradient_norm": 0.3413880169391632,
        "train_loss": 3.106609344482422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18187,
        "tokens": 9535225856,
        "learning_rate": 0.00025463086471871665,
        "gradient_norm": 0.41426733136177063,
        "train_loss": 3.1993818283081055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18188,
        "tokens": 9535750144,
        "learning_rate": 0.0002546033580676698,
        "gradient_norm": 0.4694553017616272,
        "train_loss": 3.0443735122680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18189,
        "tokens": 9536274432,
        "learning_rate": 0.000254575852265306,
        "gradient_norm": 0.37192943692207336,
        "train_loss": 3.1154110431671143,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18190,
        "tokens": 9536798720,
        "learning_rate": 0.000254548347311935,
        "gradient_norm": 0.38591378927230835,
        "train_loss": 3.0292270183563232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18191,
        "tokens": 9537323008,
        "learning_rate": 0.00025452084320786664,
        "gradient_norm": 0.39575088024139404,
        "train_loss": 3.037105083465576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18192,
        "tokens": 9537847296,
        "learning_rate": 0.00025449333995341004,
        "gradient_norm": 0.3800325095653534,
        "train_loss": 3.0908737182617188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18193,
        "tokens": 9538371584,
        "learning_rate": 0.00025446583754887514,
        "gradient_norm": 0.38606929779052734,
        "train_loss": 3.0783252716064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18194,
        "tokens": 9538895872,
        "learning_rate": 0.0002544383359945713,
        "gradient_norm": 0.34401124715805054,
        "train_loss": 3.0272445678710938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18195,
        "tokens": 9539420160,
        "learning_rate": 0.00025441083529080825,
        "gradient_norm": 0.37814509868621826,
        "train_loss": 3.0921952724456787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18196,
        "tokens": 9539944448,
        "learning_rate": 0.00025438333543789546,
        "gradient_norm": 0.37147971987724304,
        "train_loss": 3.0793404579162598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18197,
        "tokens": 9540468736,
        "learning_rate": 0.0002543558364361425,
        "gradient_norm": 0.3439999222755432,
        "train_loss": 3.050046920776367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18198,
        "tokens": 9540993024,
        "learning_rate": 0.00025432833828585886,
        "gradient_norm": 0.383044958114624,
        "train_loss": 3.093094825744629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18199,
        "tokens": 9541517312,
        "learning_rate": 0.0002543008409873541,
        "gradient_norm": 0.30304354429244995,
        "train_loss": 3.0873782634735107,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18200,
        "tokens": 9542041600,
        "learning_rate": 0.00025427334454093773,
        "gradient_norm": 0.3429982662200928,
        "train_loss": 3.0744619369506836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18201,
        "tokens": 9542565888,
        "learning_rate": 0.0002542458489469193,
        "gradient_norm": 0.31931930780410767,
        "train_loss": 3.0545084476470947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18202,
        "tokens": 9543090176,
        "learning_rate": 0.00025421835420560827,
        "gradient_norm": 0.33924221992492676,
        "train_loss": 3.0318470001220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18203,
        "tokens": 9543614464,
        "learning_rate": 0.0002541908603173141,
        "gradient_norm": 0.3538973331451416,
        "train_loss": 3.110870838165283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18204,
        "tokens": 9544138752,
        "learning_rate": 0.0002541633672823463,
        "gradient_norm": 0.371643602848053,
        "train_loss": 3.0849180221557617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18205,
        "tokens": 9544663040,
        "learning_rate": 0.00025413587510101434,
        "gradient_norm": 0.3851982057094574,
        "train_loss": 3.044468879699707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18206,
        "tokens": 9545187328,
        "learning_rate": 0.00025410838377362775,
        "gradient_norm": 0.3352757692337036,
        "train_loss": 3.0501866340637207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18207,
        "tokens": 9545711616,
        "learning_rate": 0.00025408089330049576,
        "gradient_norm": 0.46870914101600647,
        "train_loss": 3.071822166442871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18208,
        "tokens": 9546235904,
        "learning_rate": 0.00025405340368192807,
        "gradient_norm": 0.40710213780403137,
        "train_loss": 3.075016498565674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18209,
        "tokens": 9546760192,
        "learning_rate": 0.0002540259149182339,
        "gradient_norm": 0.3812449872493744,
        "train_loss": 3.123526096343994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18210,
        "tokens": 9547284480,
        "learning_rate": 0.0002539984270097228,
        "gradient_norm": 0.5393475294113159,
        "train_loss": 3.0680627822875977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18211,
        "tokens": 9547808768,
        "learning_rate": 0.00025397093995670417,
        "gradient_norm": 0.4112485349178314,
        "train_loss": 3.1010332107543945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18212,
        "tokens": 9548333056,
        "learning_rate": 0.00025394345375948725,
        "gradient_norm": 0.38157710433006287,
        "train_loss": 3.1158690452575684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18213,
        "tokens": 9548857344,
        "learning_rate": 0.0002539159684183818,
        "gradient_norm": 0.3793756663799286,
        "train_loss": 3.108503818511963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18214,
        "tokens": 9549381632,
        "learning_rate": 0.0002538884839336968,
        "gradient_norm": 0.3606100082397461,
        "train_loss": 3.085664749145508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18215,
        "tokens": 9549905920,
        "learning_rate": 0.00025386100030574184,
        "gradient_norm": 0.31663578748703003,
        "train_loss": 3.0666728019714355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18216,
        "tokens": 9550430208,
        "learning_rate": 0.00025383351753482616,
        "gradient_norm": 0.33082136511802673,
        "train_loss": 3.078645706176758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18217,
        "tokens": 9550954496,
        "learning_rate": 0.0002538060356212593,
        "gradient_norm": 0.3125559985637665,
        "train_loss": 3.105518341064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18218,
        "tokens": 9551478784,
        "learning_rate": 0.0002537785545653504,
        "gradient_norm": 0.3598127067089081,
        "train_loss": 3.022307872772217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18219,
        "tokens": 9552003072,
        "learning_rate": 0.0002537510743674089,
        "gradient_norm": 0.3357763886451721,
        "train_loss": 3.110891342163086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18220,
        "tokens": 9552527360,
        "learning_rate": 0.00025372359502774417,
        "gradient_norm": 0.3556269705295563,
        "train_loss": 3.05256986618042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18221,
        "tokens": 9553051648,
        "learning_rate": 0.00025369611654666536,
        "gradient_norm": 0.3106653094291687,
        "train_loss": 3.0765695571899414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18222,
        "tokens": 9553575936,
        "learning_rate": 0.000253668638924482,
        "gradient_norm": 0.3109719157218933,
        "train_loss": 3.0918798446655273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18223,
        "tokens": 9554100224,
        "learning_rate": 0.0002536411621615031,
        "gradient_norm": 0.30867400765419006,
        "train_loss": 3.067948818206787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18224,
        "tokens": 9554624512,
        "learning_rate": 0.0002536136862580382,
        "gradient_norm": 0.32839709520339966,
        "train_loss": 3.0544276237487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18225,
        "tokens": 9555148800,
        "learning_rate": 0.00025358621121439643,
        "gradient_norm": 0.30031391978263855,
        "train_loss": 3.019946575164795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18226,
        "tokens": 9555673088,
        "learning_rate": 0.0002535587370308872,
        "gradient_norm": 0.3295719623565674,
        "train_loss": 3.1121504306793213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18227,
        "tokens": 9556197376,
        "learning_rate": 0.00025353126370781956,
        "gradient_norm": 0.32340097427368164,
        "train_loss": 3.054995059967041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18228,
        "tokens": 9556721664,
        "learning_rate": 0.00025350379124550296,
        "gradient_norm": 0.3164714276790619,
        "train_loss": 3.0571212768554688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18229,
        "tokens": 9557245952,
        "learning_rate": 0.0002534763196442465,
        "gradient_norm": 0.3116084039211273,
        "train_loss": 3.0790929794311523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18230,
        "tokens": 9557770240,
        "learning_rate": 0.00025344884890435944,
        "gradient_norm": 0.324690043926239,
        "train_loss": 3.13596248626709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18231,
        "tokens": 9558294528,
        "learning_rate": 0.00025342137902615105,
        "gradient_norm": 0.40718069672584534,
        "train_loss": 3.0359814167022705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18232,
        "tokens": 9558818816,
        "learning_rate": 0.0002533939100099304,
        "gradient_norm": 0.3710741102695465,
        "train_loss": 3.0758819580078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18233,
        "tokens": 9559343104,
        "learning_rate": 0.0002533664418560069,
        "gradient_norm": 0.40599924325942993,
        "train_loss": 3.0700154304504395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18234,
        "tokens": 9559867392,
        "learning_rate": 0.0002533389745646895,
        "gradient_norm": 0.6331913471221924,
        "train_loss": 3.0759634971618652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18235,
        "tokens": 9560391680,
        "learning_rate": 0.0002533115081362877,
        "gradient_norm": 0.3230257034301758,
        "train_loss": 3.0304763317108154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18236,
        "tokens": 9560915968,
        "learning_rate": 0.00025328404257111026,
        "gradient_norm": 0.4983929991722107,
        "train_loss": 3.0434207916259766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18237,
        "tokens": 9561440256,
        "learning_rate": 0.0002532565778694667,
        "gradient_norm": 0.4011085331439972,
        "train_loss": 3.0912957191467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18238,
        "tokens": 9561964544,
        "learning_rate": 0.00025322911403166594,
        "gradient_norm": 0.38126689195632935,
        "train_loss": 3.09250807762146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18239,
        "tokens": 9562488832,
        "learning_rate": 0.00025320165105801717,
        "gradient_norm": 0.3996598720550537,
        "train_loss": 3.0515241622924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18240,
        "tokens": 9563013120,
        "learning_rate": 0.0002531741889488296,
        "gradient_norm": 0.3654393255710602,
        "train_loss": 3.0308499336242676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18241,
        "tokens": 9563537408,
        "learning_rate": 0.00025314672770441224,
        "gradient_norm": 0.36418047547340393,
        "train_loss": 3.1084604263305664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18242,
        "tokens": 9564061696,
        "learning_rate": 0.0002531192673250744,
        "gradient_norm": 0.3132185935974121,
        "train_loss": 3.0774197578430176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18243,
        "tokens": 9564585984,
        "learning_rate": 0.00025309180781112484,
        "gradient_norm": 0.3756246268749237,
        "train_loss": 3.1741886138916016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18244,
        "tokens": 9565110272,
        "learning_rate": 0.0002530643491628731,
        "gradient_norm": 0.35189205408096313,
        "train_loss": 3.005202293395996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18245,
        "tokens": 9565634560,
        "learning_rate": 0.0002530368913806278,
        "gradient_norm": 0.44629019498825073,
        "train_loss": 3.1409151554107666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18246,
        "tokens": 9566158848,
        "learning_rate": 0.0002530094344646984,
        "gradient_norm": 0.4177452027797699,
        "train_loss": 3.1478729248046875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18247,
        "tokens": 9566683136,
        "learning_rate": 0.0002529819784153936,
        "gradient_norm": 0.362348347902298,
        "train_loss": 3.031118392944336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18248,
        "tokens": 9567207424,
        "learning_rate": 0.0002529545232330228,
        "gradient_norm": 0.3866993188858032,
        "train_loss": 3.070124626159668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18249,
        "tokens": 9567731712,
        "learning_rate": 0.00025292706891789473,
        "gradient_norm": 0.3709588348865509,
        "train_loss": 3.0917649269104004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18250,
        "tokens": 9568256000,
        "learning_rate": 0.0002528996154703186,
        "gradient_norm": 0.4869191348552704,
        "train_loss": 3.080958843231201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18251,
        "tokens": 9568780288,
        "learning_rate": 0.0002528721628906035,
        "gradient_norm": 0.4136068522930145,
        "train_loss": 3.0199880599975586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18252,
        "tokens": 9569304576,
        "learning_rate": 0.00025284471117905825,
        "gradient_norm": 0.3435109257698059,
        "train_loss": 3.0232348442077637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18253,
        "tokens": 9569828864,
        "learning_rate": 0.00025281726033599215,
        "gradient_norm": 0.39327332377433777,
        "train_loss": 3.0556769371032715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18254,
        "tokens": 9570353152,
        "learning_rate": 0.0002527898103617137,
        "gradient_norm": 0.3564186990261078,
        "train_loss": 3.1202027797698975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18255,
        "tokens": 9570877440,
        "learning_rate": 0.00025276236125653246,
        "gradient_norm": 0.42800596356391907,
        "train_loss": 3.0162525177001953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18256,
        "tokens": 9571401728,
        "learning_rate": 0.00025273491302075694,
        "gradient_norm": 0.3299868404865265,
        "train_loss": 3.1060709953308105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18257,
        "tokens": 9571926016,
        "learning_rate": 0.00025270746565469635,
        "gradient_norm": 0.3573437035083771,
        "train_loss": 3.1023528575897217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18258,
        "tokens": 9572450304,
        "learning_rate": 0.0002526800191586596,
        "gradient_norm": 0.37503328919410706,
        "train_loss": 3.12572979927063,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18259,
        "tokens": 9572974592,
        "learning_rate": 0.0002526525735329555,
        "gradient_norm": 0.31963545083999634,
        "train_loss": 3.0383410453796387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18260,
        "tokens": 9573498880,
        "learning_rate": 0.00025262512877789327,
        "gradient_norm": 0.3576255142688751,
        "train_loss": 3.1526405811309814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18261,
        "tokens": 9574023168,
        "learning_rate": 0.0002525976848937816,
        "gradient_norm": 0.3412809669971466,
        "train_loss": 3.0742340087890625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18262,
        "tokens": 9574547456,
        "learning_rate": 0.0002525702418809295,
        "gradient_norm": 0.31708788871765137,
        "train_loss": 3.058215618133545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18263,
        "tokens": 9575071744,
        "learning_rate": 0.00025254279973964573,
        "gradient_norm": 0.3412930369377136,
        "train_loss": 3.0587103366851807,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18264,
        "tokens": 9575596032,
        "learning_rate": 0.0002525153584702394,
        "gradient_norm": 0.31816282868385315,
        "train_loss": 3.0756030082702637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18265,
        "tokens": 9576120320,
        "learning_rate": 0.00025248791807301927,
        "gradient_norm": 0.34532034397125244,
        "train_loss": 3.107858657836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18266,
        "tokens": 9576644608,
        "learning_rate": 0.0002524604785482943,
        "gradient_norm": 0.3195398151874542,
        "train_loss": 3.0770480632781982,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18267,
        "tokens": 9577168896,
        "learning_rate": 0.0002524330398963732,
        "gradient_norm": 0.34734046459198,
        "train_loss": 3.101759433746338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18268,
        "tokens": 9577693184,
        "learning_rate": 0.00025240560211756504,
        "gradient_norm": 0.3282194137573242,
        "train_loss": 3.057560920715332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18269,
        "tokens": 9578217472,
        "learning_rate": 0.0002523781652121784,
        "gradient_norm": 0.3009839355945587,
        "train_loss": 3.0790328979492188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18270,
        "tokens": 9578741760,
        "learning_rate": 0.0002523507291805224,
        "gradient_norm": 0.3113451600074768,
        "train_loss": 3.071178674697876,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18271,
        "tokens": 9579266048,
        "learning_rate": 0.0002523232940229057,
        "gradient_norm": 0.29464608430862427,
        "train_loss": 3.0767464637756348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18272,
        "tokens": 9579790336,
        "learning_rate": 0.00025229585973963716,
        "gradient_norm": 0.3315170705318451,
        "train_loss": 3.0725502967834473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18273,
        "tokens": 9580314624,
        "learning_rate": 0.00025226842633102554,
        "gradient_norm": 0.33105504512786865,
        "train_loss": 3.091742515563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18274,
        "tokens": 9580838912,
        "learning_rate": 0.0002522409937973797,
        "gradient_norm": 0.32770398259162903,
        "train_loss": 3.08975887298584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18275,
        "tokens": 9581363200,
        "learning_rate": 0.0002522135621390084,
        "gradient_norm": 0.32919782400131226,
        "train_loss": 3.026182174682617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18276,
        "tokens": 9581887488,
        "learning_rate": 0.00025218613135622044,
        "gradient_norm": 0.37410447001457214,
        "train_loss": 3.0641322135925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18277,
        "tokens": 9582411776,
        "learning_rate": 0.00025215870144932456,
        "gradient_norm": 0.3498114347457886,
        "train_loss": 3.084764003753662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18278,
        "tokens": 9582936064,
        "learning_rate": 0.0002521312724186295,
        "gradient_norm": 0.34687936305999756,
        "train_loss": 3.0885210037231445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18279,
        "tokens": 9583460352,
        "learning_rate": 0.000252103844264444,
        "gradient_norm": 0.3415968120098114,
        "train_loss": 3.0300002098083496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18280,
        "tokens": 9583984640,
        "learning_rate": 0.000252076416987077,
        "gradient_norm": 0.3749460279941559,
        "train_loss": 3.1050236225128174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18281,
        "tokens": 9584508928,
        "learning_rate": 0.0002520489905868369,
        "gradient_norm": 0.38368549942970276,
        "train_loss": 3.089906930923462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18282,
        "tokens": 9585033216,
        "learning_rate": 0.0002520215650640327,
        "gradient_norm": 0.4013044536113739,
        "train_loss": 3.0972185134887695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18283,
        "tokens": 9585557504,
        "learning_rate": 0.00025199414041897285,
        "gradient_norm": 0.4058200716972351,
        "train_loss": 3.0751090049743652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18284,
        "tokens": 9586081792,
        "learning_rate": 0.0002519667166519663,
        "gradient_norm": 0.3541753888130188,
        "train_loss": 3.16269588470459,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18285,
        "tokens": 9586606080,
        "learning_rate": 0.0002519392937633215,
        "gradient_norm": 0.3185825049877167,
        "train_loss": 3.0745351314544678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18286,
        "tokens": 9587130368,
        "learning_rate": 0.0002519118717533474,
        "gradient_norm": 0.32667553424835205,
        "train_loss": 3.0670077800750732,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18287,
        "tokens": 9587654656,
        "learning_rate": 0.00025188445062235244,
        "gradient_norm": 0.35771554708480835,
        "train_loss": 3.0892062187194824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18288,
        "tokens": 9588178944,
        "learning_rate": 0.0002518570303706454,
        "gradient_norm": 0.34985318779945374,
        "train_loss": 3.0825204849243164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18289,
        "tokens": 9588703232,
        "learning_rate": 0.0002518296109985348,
        "gradient_norm": 0.38008198142051697,
        "train_loss": 3.04046630859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18290,
        "tokens": 9589227520,
        "learning_rate": 0.0002518021925063294,
        "gradient_norm": 0.3360954523086548,
        "train_loss": 3.1044039726257324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18291,
        "tokens": 9589751808,
        "learning_rate": 0.0002517747748943379,
        "gradient_norm": 0.3700745105743408,
        "train_loss": 3.068455219268799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18292,
        "tokens": 9590276096,
        "learning_rate": 0.00025174735816286875,
        "gradient_norm": 0.4361037611961365,
        "train_loss": 3.0963268280029297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18293,
        "tokens": 9590800384,
        "learning_rate": 0.0002517199423122307,
        "gradient_norm": 0.33920058608055115,
        "train_loss": 3.056802749633789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18294,
        "tokens": 9591324672,
        "learning_rate": 0.0002516925273427322,
        "gradient_norm": 0.44270026683807373,
        "train_loss": 3.099411725997925,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18295,
        "tokens": 9591848960,
        "learning_rate": 0.00025166511325468193,
        "gradient_norm": 0.34635496139526367,
        "train_loss": 3.132474899291992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18296,
        "tokens": 9592373248,
        "learning_rate": 0.0002516377000483884,
        "gradient_norm": 0.47821661829948425,
        "train_loss": 3.1012535095214844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18297,
        "tokens": 9592897536,
        "learning_rate": 0.00025161028772416035,
        "gradient_norm": 0.4408358037471771,
        "train_loss": 3.075310707092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18298,
        "tokens": 9593421824,
        "learning_rate": 0.00025158287628230613,
        "gradient_norm": 0.3297867476940155,
        "train_loss": 3.0393638610839844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18299,
        "tokens": 9593946112,
        "learning_rate": 0.00025155546572313436,
        "gradient_norm": 0.3413294553756714,
        "train_loss": 3.080784320831299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18300,
        "tokens": 9594470400,
        "learning_rate": 0.00025152805604695375,
        "gradient_norm": 0.3296523094177246,
        "train_loss": 3.080012559890747,
        "val_loss": 3.0378479957580566,
        "hellaswag_acc": 0.28181636333465576,
        "hellaswag_acc_norm": 0.29247161746025085
    },
    {
        "step": 18301,
        "tokens": 9594994688,
        "learning_rate": 0.0002515006472540726,
        "gradient_norm": 0.42775726318359375,
        "train_loss": 3.0493521690368652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18302,
        "tokens": 9595518976,
        "learning_rate": 0.00025147323934479956,
        "gradient_norm": 0.34851163625717163,
        "train_loss": 3.058851718902588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18303,
        "tokens": 9596043264,
        "learning_rate": 0.000251445832319443,
        "gradient_norm": 0.4845547676086426,
        "train_loss": 3.070735454559326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18304,
        "tokens": 9596567552,
        "learning_rate": 0.00025141842617831166,
        "gradient_norm": 0.4473912715911865,
        "train_loss": 3.129507064819336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18305,
        "tokens": 9597091840,
        "learning_rate": 0.00025139102092171375,
        "gradient_norm": 0.4688381254673004,
        "train_loss": 3.048795700073242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18306,
        "tokens": 9597616128,
        "learning_rate": 0.000251363616549958,
        "gradient_norm": 0.527738094329834,
        "train_loss": 3.1030566692352295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18307,
        "tokens": 9598140416,
        "learning_rate": 0.00025133621306335267,
        "gradient_norm": 0.393419086933136,
        "train_loss": 3.010030746459961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18308,
        "tokens": 9598664704,
        "learning_rate": 0.00025130881046220646,
        "gradient_norm": 0.43966159224510193,
        "train_loss": 3.072016716003418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18309,
        "tokens": 9599188992,
        "learning_rate": 0.0002512814087468275,
        "gradient_norm": 0.38270536065101624,
        "train_loss": 3.0448882579803467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18310,
        "tokens": 9599713280,
        "learning_rate": 0.0002512540079175245,
        "gradient_norm": 0.4286426305770874,
        "train_loss": 3.095179557800293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18311,
        "tokens": 9600237568,
        "learning_rate": 0.00025122660797460584,
        "gradient_norm": 0.3471476137638092,
        "train_loss": 3.0902700424194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18312,
        "tokens": 9600761856,
        "learning_rate": 0.0002511992089183798,
        "gradient_norm": 0.40092548727989197,
        "train_loss": 3.163733959197998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18313,
        "tokens": 9601286144,
        "learning_rate": 0.000251171810749155,
        "gradient_norm": 0.4362199604511261,
        "train_loss": 3.072772979736328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18314,
        "tokens": 9601810432,
        "learning_rate": 0.00025114441346723963,
        "gradient_norm": 0.4408193826675415,
        "train_loss": 3.123744010925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18315,
        "tokens": 9602334720,
        "learning_rate": 0.00025111701707294226,
        "gradient_norm": 0.38995853066444397,
        "train_loss": 3.0758578777313232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18316,
        "tokens": 9602859008,
        "learning_rate": 0.0002510896215665712,
        "gradient_norm": 0.3691696524620056,
        "train_loss": 3.0362534523010254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18317,
        "tokens": 9603383296,
        "learning_rate": 0.0002510622269484348,
        "gradient_norm": 0.3743050992488861,
        "train_loss": 3.058671236038208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18318,
        "tokens": 9603907584,
        "learning_rate": 0.0002510348332188414,
        "gradient_norm": 0.37408462166786194,
        "train_loss": 3.0945851802825928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18319,
        "tokens": 9604431872,
        "learning_rate": 0.00025100744037809925,
        "gradient_norm": 0.39487287402153015,
        "train_loss": 3.071317434310913,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18320,
        "tokens": 9604956160,
        "learning_rate": 0.00025098004842651707,
        "gradient_norm": 0.39187899231910706,
        "train_loss": 3.0893330574035645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18321,
        "tokens": 9605480448,
        "learning_rate": 0.00025095265736440285,
        "gradient_norm": 0.3679220378398895,
        "train_loss": 3.07187819480896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18322,
        "tokens": 9606004736,
        "learning_rate": 0.00025092526719206506,
        "gradient_norm": 0.34950217604637146,
        "train_loss": 3.091146945953369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18323,
        "tokens": 9606529024,
        "learning_rate": 0.00025089787790981183,
        "gradient_norm": 0.3320489823818207,
        "train_loss": 3.084078550338745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18324,
        "tokens": 9607053312,
        "learning_rate": 0.0002508704895179517,
        "gradient_norm": 0.35404855012893677,
        "train_loss": 3.1268744468688965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18325,
        "tokens": 9607577600,
        "learning_rate": 0.0002508431020167928,
        "gradient_norm": 0.3388941287994385,
        "train_loss": 3.1742238998413086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18326,
        "tokens": 9608101888,
        "learning_rate": 0.0002508157154066435,
        "gradient_norm": 0.40486419200897217,
        "train_loss": 3.1016502380371094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18327,
        "tokens": 9608626176,
        "learning_rate": 0.00025078832968781193,
        "gradient_norm": 0.3331799805164337,
        "train_loss": 3.050509452819824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18328,
        "tokens": 9609150464,
        "learning_rate": 0.00025076094486060663,
        "gradient_norm": 0.417294979095459,
        "train_loss": 3.142246961593628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18329,
        "tokens": 9609674752,
        "learning_rate": 0.00025073356092533553,
        "gradient_norm": 0.343765527009964,
        "train_loss": 3.082453727722168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18330,
        "tokens": 9610199040,
        "learning_rate": 0.00025070617788230704,
        "gradient_norm": 0.3494254946708679,
        "train_loss": 3.0230350494384766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18331,
        "tokens": 9610723328,
        "learning_rate": 0.00025067879573182933,
        "gradient_norm": 0.37484729290008545,
        "train_loss": 2.997292995452881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18332,
        "tokens": 9611247616,
        "learning_rate": 0.00025065141447421066,
        "gradient_norm": 0.3664586544036865,
        "train_loss": 3.0981647968292236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18333,
        "tokens": 9611771904,
        "learning_rate": 0.00025062403410975925,
        "gradient_norm": 0.35536691546440125,
        "train_loss": 3.0208568572998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18334,
        "tokens": 9612296192,
        "learning_rate": 0.0002505966546387833,
        "gradient_norm": 0.35837265849113464,
        "train_loss": 3.0860190391540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18335,
        "tokens": 9612820480,
        "learning_rate": 0.000250569276061591,
        "gradient_norm": 0.3484415113925934,
        "train_loss": 3.078967571258545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18336,
        "tokens": 9613344768,
        "learning_rate": 0.0002505418983784904,
        "gradient_norm": 0.3623342514038086,
        "train_loss": 3.122246265411377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18337,
        "tokens": 9613869056,
        "learning_rate": 0.0002505145215897899,
        "gradient_norm": 0.3838355243206024,
        "train_loss": 3.0955517292022705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18338,
        "tokens": 9614393344,
        "learning_rate": 0.0002504871456957975,
        "gradient_norm": 0.3353404104709625,
        "train_loss": 3.042187452316284,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18339,
        "tokens": 9614917632,
        "learning_rate": 0.0002504597706968213,
        "gradient_norm": 0.39015763998031616,
        "train_loss": 3.090273380279541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18340,
        "tokens": 9615441920,
        "learning_rate": 0.00025043239659316974,
        "gradient_norm": 0.34425315260887146,
        "train_loss": 3.045795440673828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18341,
        "tokens": 9615966208,
        "learning_rate": 0.00025040502338515057,
        "gradient_norm": 0.35755103826522827,
        "train_loss": 3.1219234466552734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18342,
        "tokens": 9616490496,
        "learning_rate": 0.00025037765107307217,
        "gradient_norm": 0.36294665932655334,
        "train_loss": 3.1022281646728516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18343,
        "tokens": 9617014784,
        "learning_rate": 0.00025035027965724245,
        "gradient_norm": 0.3553890585899353,
        "train_loss": 3.03784441947937,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18344,
        "tokens": 9617539072,
        "learning_rate": 0.00025032290913796975,
        "gradient_norm": 0.3787790536880493,
        "train_loss": 3.100616455078125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18345,
        "tokens": 9618063360,
        "learning_rate": 0.0002502955395155619,
        "gradient_norm": 0.33492764830589294,
        "train_loss": 3.021812915802002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18346,
        "tokens": 9618587648,
        "learning_rate": 0.0002502681707903272,
        "gradient_norm": 0.38034161925315857,
        "train_loss": 3.076805353164673,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18347,
        "tokens": 9619111936,
        "learning_rate": 0.00025024080296257354,
        "gradient_norm": 0.31760987639427185,
        "train_loss": 3.132978916168213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18348,
        "tokens": 9619636224,
        "learning_rate": 0.0002502134360326091,
        "gradient_norm": 0.4150550961494446,
        "train_loss": 3.0224666595458984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18349,
        "tokens": 9620160512,
        "learning_rate": 0.0002501860700007419,
        "gradient_norm": 0.3261330723762512,
        "train_loss": 3.036792278289795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18350,
        "tokens": 9620684800,
        "learning_rate": 0.00025015870486728,
        "gradient_norm": 0.35967007279396057,
        "train_loss": 3.1021814346313477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18351,
        "tokens": 9621209088,
        "learning_rate": 0.0002501313406325314,
        "gradient_norm": 0.3895840644836426,
        "train_loss": 3.0308310985565186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18352,
        "tokens": 9621733376,
        "learning_rate": 0.0002501039772968041,
        "gradient_norm": 0.39689573645591736,
        "train_loss": 3.103914260864258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18353,
        "tokens": 9622257664,
        "learning_rate": 0.0002500766148604062,
        "gradient_norm": 0.33032262325286865,
        "train_loss": 3.053189277648926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18354,
        "tokens": 9622781952,
        "learning_rate": 0.0002500492533236455,
        "gradient_norm": 0.3781319558620453,
        "train_loss": 3.0563840866088867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18355,
        "tokens": 9623306240,
        "learning_rate": 0.0002500218926868302,
        "gradient_norm": 0.32557764649391174,
        "train_loss": 2.969381332397461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18356,
        "tokens": 9623830528,
        "learning_rate": 0.00024999453295026814,
        "gradient_norm": 0.3366051912307739,
        "train_loss": 3.0354814529418945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18357,
        "tokens": 9624354816,
        "learning_rate": 0.0002499671741142674,
        "gradient_norm": 0.5053380131721497,
        "train_loss": 3.165234088897705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18358,
        "tokens": 9624879104,
        "learning_rate": 0.0002499398161791358,
        "gradient_norm": 0.4077417254447937,
        "train_loss": 3.1150577068328857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18359,
        "tokens": 9625403392,
        "learning_rate": 0.0002499124591451814,
        "gradient_norm": 0.36908453702926636,
        "train_loss": 3.058523178100586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18360,
        "tokens": 9625927680,
        "learning_rate": 0.00024988510301271217,
        "gradient_norm": 0.43950173258781433,
        "train_loss": 3.078360080718994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18361,
        "tokens": 9626451968,
        "learning_rate": 0.00024985774778203587,
        "gradient_norm": 0.40829458832740784,
        "train_loss": 3.06461763381958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18362,
        "tokens": 9626976256,
        "learning_rate": 0.0002498303934534606,
        "gradient_norm": 0.31699520349502563,
        "train_loss": 3.0544674396514893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18363,
        "tokens": 9627500544,
        "learning_rate": 0.00024980304002729414,
        "gradient_norm": 0.37517601251602173,
        "train_loss": 3.0814666748046875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18364,
        "tokens": 9628024832,
        "learning_rate": 0.0002497756875038445,
        "gradient_norm": 0.332584410905838,
        "train_loss": 3.085217237472534,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18365,
        "tokens": 9628549120,
        "learning_rate": 0.0002497483358834194,
        "gradient_norm": 0.37227290868759155,
        "train_loss": 3.039522647857666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18366,
        "tokens": 9629073408,
        "learning_rate": 0.0002497209851663269,
        "gradient_norm": 0.3553503155708313,
        "train_loss": 3.1297245025634766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18367,
        "tokens": 9629597696,
        "learning_rate": 0.00024969363535287475,
        "gradient_norm": 0.33159711956977844,
        "train_loss": 3.0423879623413086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18368,
        "tokens": 9630121984,
        "learning_rate": 0.00024966628644337076,
        "gradient_norm": 0.39120250940322876,
        "train_loss": 3.1331863403320312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18369,
        "tokens": 9630646272,
        "learning_rate": 0.00024963893843812294,
        "gradient_norm": 0.34668129682540894,
        "train_loss": 3.092374086380005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18370,
        "tokens": 9631170560,
        "learning_rate": 0.00024961159133743904,
        "gradient_norm": 0.35468584299087524,
        "train_loss": 3.0972554683685303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18371,
        "tokens": 9631694848,
        "learning_rate": 0.0002495842451416269,
        "gradient_norm": 0.3256460726261139,
        "train_loss": 3.107663869857788,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18372,
        "tokens": 9632219136,
        "learning_rate": 0.00024955689985099424,
        "gradient_norm": 0.35002899169921875,
        "train_loss": 3.049342155456543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18373,
        "tokens": 9632743424,
        "learning_rate": 0.00024952955546584906,
        "gradient_norm": 0.33856111764907837,
        "train_loss": 2.9970076084136963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18374,
        "tokens": 9633267712,
        "learning_rate": 0.00024950221198649896,
        "gradient_norm": 0.37430062890052795,
        "train_loss": 3.084981918334961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18375,
        "tokens": 9633792000,
        "learning_rate": 0.0002494748694132519,
        "gradient_norm": 0.36373499035835266,
        "train_loss": 3.0357089042663574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18376,
        "tokens": 9634316288,
        "learning_rate": 0.00024944752774641544,
        "gradient_norm": 0.3680523633956909,
        "train_loss": 3.080104351043701,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18377,
        "tokens": 9634840576,
        "learning_rate": 0.0002494201869862976,
        "gradient_norm": 0.35096365213394165,
        "train_loss": 3.0482256412506104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18378,
        "tokens": 9635364864,
        "learning_rate": 0.0002493928471332058,
        "gradient_norm": 0.32747402787208557,
        "train_loss": 3.090503692626953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18379,
        "tokens": 9635889152,
        "learning_rate": 0.00024936550818744816,
        "gradient_norm": 0.41833066940307617,
        "train_loss": 3.1364307403564453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18380,
        "tokens": 9636413440,
        "learning_rate": 0.0002493381701493322,
        "gradient_norm": 0.3994986414909363,
        "train_loss": 3.1177988052368164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18381,
        "tokens": 9636937728,
        "learning_rate": 0.0002493108330191657,
        "gradient_norm": 0.33004817366600037,
        "train_loss": 3.073223114013672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18382,
        "tokens": 9637462016,
        "learning_rate": 0.00024928349679725627,
        "gradient_norm": 0.3644888997077942,
        "train_loss": 3.086906909942627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18383,
        "tokens": 9637986304,
        "learning_rate": 0.00024925616148391175,
        "gradient_norm": 0.34802812337875366,
        "train_loss": 3.086082935333252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18384,
        "tokens": 9638510592,
        "learning_rate": 0.00024922882707943987,
        "gradient_norm": 0.403830885887146,
        "train_loss": 3.108464241027832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18385,
        "tokens": 9639034880,
        "learning_rate": 0.0002492014935841481,
        "gradient_norm": 0.3429360091686249,
        "train_loss": 3.0651936531066895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18386,
        "tokens": 9639559168,
        "learning_rate": 0.0002491741609983442,
        "gradient_norm": 0.344317227602005,
        "train_loss": 3.093952178955078,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18387,
        "tokens": 9640083456,
        "learning_rate": 0.00024914682932233607,
        "gradient_norm": 0.37761640548706055,
        "train_loss": 3.0214505195617676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18388,
        "tokens": 9640607744,
        "learning_rate": 0.00024911949855643096,
        "gradient_norm": 0.3352418839931488,
        "train_loss": 3.0926270484924316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18389,
        "tokens": 9641132032,
        "learning_rate": 0.00024909216870093687,
        "gradient_norm": 0.41926053166389465,
        "train_loss": 3.0374231338500977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18390,
        "tokens": 9641656320,
        "learning_rate": 0.00024906483975616116,
        "gradient_norm": 0.32058921456336975,
        "train_loss": 3.0658364295959473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18391,
        "tokens": 9642180608,
        "learning_rate": 0.00024903751172241164,
        "gradient_norm": 0.42473065853118896,
        "train_loss": 3.0665550231933594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18392,
        "tokens": 9642704896,
        "learning_rate": 0.0002490101845999958,
        "gradient_norm": 0.3612862527370453,
        "train_loss": 3.0806760787963867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18393,
        "tokens": 9643229184,
        "learning_rate": 0.0002489828583892213,
        "gradient_norm": 0.3302825689315796,
        "train_loss": 3.0622386932373047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18394,
        "tokens": 9643753472,
        "learning_rate": 0.0002489555330903957,
        "gradient_norm": 0.3354050815105438,
        "train_loss": 3.064971923828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18395,
        "tokens": 9644277760,
        "learning_rate": 0.0002489282087038267,
        "gradient_norm": 0.37449124455451965,
        "train_loss": 3.025867462158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18396,
        "tokens": 9644802048,
        "learning_rate": 0.00024890088522982166,
        "gradient_norm": 0.33991339802742004,
        "train_loss": 3.0641696453094482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18397,
        "tokens": 9645326336,
        "learning_rate": 0.0002488735626686883,
        "gradient_norm": 0.33363842964172363,
        "train_loss": 3.0080575942993164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18398,
        "tokens": 9645850624,
        "learning_rate": 0.0002488462410207341,
        "gradient_norm": 0.394481897354126,
        "train_loss": 3.0853166580200195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18399,
        "tokens": 9646374912,
        "learning_rate": 0.0002488189202862665,
        "gradient_norm": 0.35782694816589355,
        "train_loss": 3.1267502307891846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18400,
        "tokens": 9646899200,
        "learning_rate": 0.00024879160046559337,
        "gradient_norm": 0.3685814142227173,
        "train_loss": 3.0918664932250977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18401,
        "tokens": 9647423488,
        "learning_rate": 0.0002487642815590218,
        "gradient_norm": 0.3827560842037201,
        "train_loss": 3.087339162826538,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18402,
        "tokens": 9647947776,
        "learning_rate": 0.0002487369635668597,
        "gradient_norm": 0.40439942479133606,
        "train_loss": 3.1980559825897217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18403,
        "tokens": 9648472064,
        "learning_rate": 0.00024870964648941426,
        "gradient_norm": 0.3659612238407135,
        "train_loss": 3.0748724937438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18404,
        "tokens": 9648996352,
        "learning_rate": 0.00024868233032699315,
        "gradient_norm": 0.3283846974372864,
        "train_loss": 3.0418663024902344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18405,
        "tokens": 9649520640,
        "learning_rate": 0.00024865501507990366,
        "gradient_norm": 0.3467785120010376,
        "train_loss": 2.9898715019226074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18406,
        "tokens": 9650044928,
        "learning_rate": 0.0002486277007484535,
        "gradient_norm": 0.3319628834724426,
        "train_loss": 3.1005096435546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18407,
        "tokens": 9650569216,
        "learning_rate": 0.0002486003873329499,
        "gradient_norm": 0.3508394658565521,
        "train_loss": 3.0426173210144043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18408,
        "tokens": 9651093504,
        "learning_rate": 0.0002485730748337004,
        "gradient_norm": 0.3465418219566345,
        "train_loss": 3.0323147773742676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18409,
        "tokens": 9651617792,
        "learning_rate": 0.0002485457632510126,
        "gradient_norm": 0.3616715371608734,
        "train_loss": 3.1124987602233887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18410,
        "tokens": 9652142080,
        "learning_rate": 0.0002485184525851936,
        "gradient_norm": 0.31849613785743713,
        "train_loss": 3.113677978515625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18411,
        "tokens": 9652666368,
        "learning_rate": 0.00024849114283655106,
        "gradient_norm": 0.35446420311927795,
        "train_loss": 3.097390651702881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18412,
        "tokens": 9653190656,
        "learning_rate": 0.0002484638340053923,
        "gradient_norm": 0.42900440096855164,
        "train_loss": 3.044914484024048,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18413,
        "tokens": 9653714944,
        "learning_rate": 0.00024843652609202475,
        "gradient_norm": 0.3620448410511017,
        "train_loss": 3.0839481353759766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18414,
        "tokens": 9654239232,
        "learning_rate": 0.0002484092190967557,
        "gradient_norm": 0.37344059348106384,
        "train_loss": 3.0332908630371094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18415,
        "tokens": 9654763520,
        "learning_rate": 0.00024838191301989276,
        "gradient_norm": 0.41031044721603394,
        "train_loss": 3.096430778503418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18416,
        "tokens": 9655287808,
        "learning_rate": 0.00024835460786174293,
        "gradient_norm": 0.39228129386901855,
        "train_loss": 3.0989370346069336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18417,
        "tokens": 9655812096,
        "learning_rate": 0.0002483273036226139,
        "gradient_norm": 0.4137657880783081,
        "train_loss": 3.035383701324463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18418,
        "tokens": 9656336384,
        "learning_rate": 0.00024830000030281275,
        "gradient_norm": 0.4343932271003723,
        "train_loss": 3.1100120544433594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18419,
        "tokens": 9656860672,
        "learning_rate": 0.0002482726979026469,
        "gradient_norm": 0.3597266674041748,
        "train_loss": 3.018620014190674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18420,
        "tokens": 9657384960,
        "learning_rate": 0.0002482453964224239,
        "gradient_norm": 0.4044143557548523,
        "train_loss": 3.0201618671417236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18421,
        "tokens": 9657909248,
        "learning_rate": 0.0002482180958624508,
        "gradient_norm": 0.3743758499622345,
        "train_loss": 3.038649559020996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18422,
        "tokens": 9658433536,
        "learning_rate": 0.000248190796223035,
        "gradient_norm": 0.4100069999694824,
        "train_loss": 3.0481038093566895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18423,
        "tokens": 9658957824,
        "learning_rate": 0.00024816349750448366,
        "gradient_norm": 0.3823443651199341,
        "train_loss": 3.049300193786621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18424,
        "tokens": 9659482112,
        "learning_rate": 0.0002481361997071043,
        "gradient_norm": 0.43402138352394104,
        "train_loss": 3.081338405609131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18425,
        "tokens": 9660006400,
        "learning_rate": 0.0002481089028312039,
        "gradient_norm": 0.3687567114830017,
        "train_loss": 3.0707106590270996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18426,
        "tokens": 9660530688,
        "learning_rate": 0.00024808160687709007,
        "gradient_norm": 0.38941726088523865,
        "train_loss": 3.0771431922912598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18427,
        "tokens": 9661054976,
        "learning_rate": 0.0002480543118450697,
        "gradient_norm": 0.3375985324382782,
        "train_loss": 3.1197972297668457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18428,
        "tokens": 9661579264,
        "learning_rate": 0.0002480270177354503,
        "gradient_norm": 0.4735852777957916,
        "train_loss": 3.1023192405700684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18429,
        "tokens": 9662103552,
        "learning_rate": 0.00024799972454853895,
        "gradient_norm": 0.3446575105190277,
        "train_loss": 3.113710403442383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18430,
        "tokens": 9662627840,
        "learning_rate": 0.000247972432284643,
        "gradient_norm": 0.42649513483047485,
        "train_loss": 3.1366372108459473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18431,
        "tokens": 9663152128,
        "learning_rate": 0.0002479451409440695,
        "gradient_norm": 0.34063994884490967,
        "train_loss": 3.145205497741699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18432,
        "tokens": 9663676416,
        "learning_rate": 0.00024791785052712573,
        "gradient_norm": 0.4648062288761139,
        "train_loss": 3.0693955421447754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18433,
        "tokens": 9664200704,
        "learning_rate": 0.00024789056103411886,
        "gradient_norm": 0.3264857232570648,
        "train_loss": 3.071101665496826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18434,
        "tokens": 9664724992,
        "learning_rate": 0.0002478632724653561,
        "gradient_norm": 0.38148030638694763,
        "train_loss": 3.076589584350586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18435,
        "tokens": 9665249280,
        "learning_rate": 0.0002478359848211446,
        "gradient_norm": 0.36312103271484375,
        "train_loss": 3.0753376483917236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18436,
        "tokens": 9665773568,
        "learning_rate": 0.0002478086981017915,
        "gradient_norm": 0.32780155539512634,
        "train_loss": 3.0701584815979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18437,
        "tokens": 9666297856,
        "learning_rate": 0.00024778141230760394,
        "gradient_norm": 0.3423387408256531,
        "train_loss": 3.0563604831695557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18438,
        "tokens": 9666822144,
        "learning_rate": 0.00024775412743888907,
        "gradient_norm": 0.3227589726448059,
        "train_loss": 3.0720443725585938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18439,
        "tokens": 9667346432,
        "learning_rate": 0.00024772684349595405,
        "gradient_norm": 0.33886227011680603,
        "train_loss": 3.063535690307617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18440,
        "tokens": 9667870720,
        "learning_rate": 0.00024769956047910593,
        "gradient_norm": 0.33167245984077454,
        "train_loss": 3.110647201538086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18441,
        "tokens": 9668395008,
        "learning_rate": 0.00024767227838865186,
        "gradient_norm": 0.32706162333488464,
        "train_loss": 3.0504491329193115,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18442,
        "tokens": 9668919296,
        "learning_rate": 0.000247644997224899,
        "gradient_norm": 0.3333577513694763,
        "train_loss": 3.058328628540039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18443,
        "tokens": 9669443584,
        "learning_rate": 0.00024761771698815423,
        "gradient_norm": 0.3256770670413971,
        "train_loss": 3.0285110473632812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18444,
        "tokens": 9669967872,
        "learning_rate": 0.00024759043767872487,
        "gradient_norm": 0.31664830446243286,
        "train_loss": 3.085873603820801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18445,
        "tokens": 9670492160,
        "learning_rate": 0.0002475631592969177,
        "gradient_norm": 0.33796676993370056,
        "train_loss": 3.089578628540039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18446,
        "tokens": 9671016448,
        "learning_rate": 0.0002475358818430401,
        "gradient_norm": 0.3233964145183563,
        "train_loss": 3.0966575145721436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18447,
        "tokens": 9671540736,
        "learning_rate": 0.00024750860531739876,
        "gradient_norm": 0.31713443994522095,
        "train_loss": 3.0893311500549316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18448,
        "tokens": 9672065024,
        "learning_rate": 0.000247481329720301,
        "gradient_norm": 0.311784029006958,
        "train_loss": 3.1140027046203613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18449,
        "tokens": 9672589312,
        "learning_rate": 0.00024745405505205377,
        "gradient_norm": 0.342402845621109,
        "train_loss": 3.0917110443115234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18450,
        "tokens": 9673113600,
        "learning_rate": 0.00024742678131296395,
        "gradient_norm": 0.3606880009174347,
        "train_loss": 3.0561513900756836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18451,
        "tokens": 9673637888,
        "learning_rate": 0.00024739950850333875,
        "gradient_norm": 0.3355931043624878,
        "train_loss": 3.071807384490967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18452,
        "tokens": 9674162176,
        "learning_rate": 0.00024737223662348496,
        "gradient_norm": 0.32717642188072205,
        "train_loss": 3.0485167503356934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18453,
        "tokens": 9674686464,
        "learning_rate": 0.00024734496567370976,
        "gradient_norm": 0.35058772563934326,
        "train_loss": 3.018246650695801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18454,
        "tokens": 9675210752,
        "learning_rate": 0.0002473176956543199,
        "gradient_norm": 0.32652977108955383,
        "train_loss": 3.031043291091919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18455,
        "tokens": 9675735040,
        "learning_rate": 0.0002472904265656225,
        "gradient_norm": 0.4009196162223816,
        "train_loss": 3.1025502681732178,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18456,
        "tokens": 9676259328,
        "learning_rate": 0.0002472631584079243,
        "gradient_norm": 0.37366318702697754,
        "train_loss": 3.1159746646881104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18457,
        "tokens": 9676783616,
        "learning_rate": 0.0002472358911815326,
        "gradient_norm": 0.3718094527721405,
        "train_loss": 3.0060086250305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18458,
        "tokens": 9677307904,
        "learning_rate": 0.00024720862488675395,
        "gradient_norm": 0.42724671959877014,
        "train_loss": 3.0874009132385254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18459,
        "tokens": 9677832192,
        "learning_rate": 0.0002471813595238955,
        "gradient_norm": 0.33606475591659546,
        "train_loss": 3.1148595809936523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18460,
        "tokens": 9678356480,
        "learning_rate": 0.00024715409509326407,
        "gradient_norm": 0.3921254575252533,
        "train_loss": 3.105508327484131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18461,
        "tokens": 9678880768,
        "learning_rate": 0.00024712683159516655,
        "gradient_norm": 0.43499550223350525,
        "train_loss": 3.0742719173431396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18462,
        "tokens": 9679405056,
        "learning_rate": 0.00024709956902990997,
        "gradient_norm": 0.3431476652622223,
        "train_loss": 3.1229920387268066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18463,
        "tokens": 9679929344,
        "learning_rate": 0.0002470723073978009,
        "gradient_norm": 0.3885866701602936,
        "train_loss": 3.092297315597534,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18464,
        "tokens": 9680453632,
        "learning_rate": 0.0002470450466991465,
        "gradient_norm": 0.3529673218727112,
        "train_loss": 3.0609350204467773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18465,
        "tokens": 9680977920,
        "learning_rate": 0.0002470177869342534,
        "gradient_norm": 0.37774622440338135,
        "train_loss": 3.0873169898986816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18466,
        "tokens": 9681502208,
        "learning_rate": 0.0002469905281034287,
        "gradient_norm": 0.4306522607803345,
        "train_loss": 3.1072990894317627,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18467,
        "tokens": 9682026496,
        "learning_rate": 0.0002469632702069789,
        "gradient_norm": 0.31793123483657837,
        "train_loss": 3.042379379272461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18468,
        "tokens": 9682550784,
        "learning_rate": 0.0002469360132452111,
        "gradient_norm": 0.3926134407520294,
        "train_loss": 3.0807344913482666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18469,
        "tokens": 9683075072,
        "learning_rate": 0.00024690875721843206,
        "gradient_norm": 0.33400896191596985,
        "train_loss": 3.050398826599121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18470,
        "tokens": 9683599360,
        "learning_rate": 0.00024688150212694843,
        "gradient_norm": 0.39810436964035034,
        "train_loss": 3.1130802631378174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18471,
        "tokens": 9684123648,
        "learning_rate": 0.0002468542479710672,
        "gradient_norm": 0.36236268281936646,
        "train_loss": 3.0394163131713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18472,
        "tokens": 9684647936,
        "learning_rate": 0.000246826994751095,
        "gradient_norm": 0.3589462339878082,
        "train_loss": 3.085028648376465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18473,
        "tokens": 9685172224,
        "learning_rate": 0.0002467997424673387,
        "gradient_norm": 0.39332300424575806,
        "train_loss": 3.0292611122131348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18474,
        "tokens": 9685696512,
        "learning_rate": 0.0002467724911201049,
        "gradient_norm": 0.34308522939682007,
        "train_loss": 3.052389621734619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18475,
        "tokens": 9686220800,
        "learning_rate": 0.0002467452407097006,
        "gradient_norm": 0.3905845284461975,
        "train_loss": 3.1057043075561523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18476,
        "tokens": 9686745088,
        "learning_rate": 0.00024671799123643227,
        "gradient_norm": 0.40925392508506775,
        "train_loss": 3.1083297729492188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18477,
        "tokens": 9687269376,
        "learning_rate": 0.0002466907427006069,
        "gradient_norm": 0.3745221793651581,
        "train_loss": 3.0763211250305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18478,
        "tokens": 9687793664,
        "learning_rate": 0.00024666349510253096,
        "gradient_norm": 0.3837689757347107,
        "train_loss": 3.086498737335205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18479,
        "tokens": 9688317952,
        "learning_rate": 0.00024663624844251125,
        "gradient_norm": 0.38154131174087524,
        "train_loss": 3.0497920513153076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18480,
        "tokens": 9688842240,
        "learning_rate": 0.00024660900272085453,
        "gradient_norm": 0.3153120279312134,
        "train_loss": 3.077679395675659,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18481,
        "tokens": 9689366528,
        "learning_rate": 0.0002465817579378675,
        "gradient_norm": 0.3792378008365631,
        "train_loss": 3.1299848556518555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18482,
        "tokens": 9689890816,
        "learning_rate": 0.00024655451409385663,
        "gradient_norm": 0.3369516432285309,
        "train_loss": 3.102029323577881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18483,
        "tokens": 9690415104,
        "learning_rate": 0.0002465272711891288,
        "gradient_norm": 0.3561263084411621,
        "train_loss": 3.0874404907226562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18484,
        "tokens": 9690939392,
        "learning_rate": 0.0002465000292239906,
        "gradient_norm": 0.36850088834762573,
        "train_loss": 3.098471164703369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18485,
        "tokens": 9691463680,
        "learning_rate": 0.00024647278819874864,
        "gradient_norm": 0.4007386267185211,
        "train_loss": 3.084519624710083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18486,
        "tokens": 9691987968,
        "learning_rate": 0.0002464455481137095,
        "gradient_norm": 0.45416584610939026,
        "train_loss": 3.018794059753418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18487,
        "tokens": 9692512256,
        "learning_rate": 0.00024641830896918,
        "gradient_norm": 0.33402523398399353,
        "train_loss": 3.0997142791748047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18488,
        "tokens": 9693036544,
        "learning_rate": 0.0002463910707654664,
        "gradient_norm": 0.4850136935710907,
        "train_loss": 3.042914867401123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18489,
        "tokens": 9693560832,
        "learning_rate": 0.00024636383350287575,
        "gradient_norm": 0.33591270446777344,
        "train_loss": 3.153474807739258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18490,
        "tokens": 9694085120,
        "learning_rate": 0.0002463365971817143,
        "gradient_norm": 0.4167915880680084,
        "train_loss": 3.0713753700256348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18491,
        "tokens": 9694609408,
        "learning_rate": 0.0002463093618022888,
        "gradient_norm": 0.33051663637161255,
        "train_loss": 3.1016640663146973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18492,
        "tokens": 9695133696,
        "learning_rate": 0.00024628212736490563,
        "gradient_norm": 0.456513911485672,
        "train_loss": 3.026884078979492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18493,
        "tokens": 9695657984,
        "learning_rate": 0.0002462548938698716,
        "gradient_norm": 0.3603276312351227,
        "train_loss": 3.0022873878479004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18494,
        "tokens": 9696182272,
        "learning_rate": 0.0002462276613174931,
        "gradient_norm": 0.36420610547065735,
        "train_loss": 3.095442295074463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18495,
        "tokens": 9696706560,
        "learning_rate": 0.00024620042970807665,
        "gradient_norm": 0.3337223529815674,
        "train_loss": 3.1426820755004883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18496,
        "tokens": 9697230848,
        "learning_rate": 0.0002461731990419289,
        "gradient_norm": 0.4058975875377655,
        "train_loss": 3.090986728668213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18497,
        "tokens": 9697755136,
        "learning_rate": 0.00024614596931935625,
        "gradient_norm": 0.37007611989974976,
        "train_loss": 3.090982675552368,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18498,
        "tokens": 9698279424,
        "learning_rate": 0.0002461187405406653,
        "gradient_norm": 0.3661127984523773,
        "train_loss": 3.0411503314971924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18499,
        "tokens": 9698803712,
        "learning_rate": 0.0002460915127061623,
        "gradient_norm": 0.33544668555259705,
        "train_loss": 3.036525249481201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18500,
        "tokens": 9699328000,
        "learning_rate": 0.0002460642858161541,
        "gradient_norm": 0.36122068762779236,
        "train_loss": 3.0857510566711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18501,
        "tokens": 9699852288,
        "learning_rate": 0.0002460370598709469,
        "gradient_norm": 0.30776628851890564,
        "train_loss": 3.0382285118103027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18502,
        "tokens": 9700376576,
        "learning_rate": 0.0002460098348708473,
        "gradient_norm": 0.33952537178993225,
        "train_loss": 3.0943896770477295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18503,
        "tokens": 9700900864,
        "learning_rate": 0.0002459826108161617,
        "gradient_norm": 0.3151912987232208,
        "train_loss": 3.0405964851379395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18504,
        "tokens": 9701425152,
        "learning_rate": 0.0002459553877071966,
        "gradient_norm": 0.3518812358379364,
        "train_loss": 3.0963499546051025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18505,
        "tokens": 9701949440,
        "learning_rate": 0.0002459281655442583,
        "gradient_norm": 0.31468069553375244,
        "train_loss": 3.068047523498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18506,
        "tokens": 9702473728,
        "learning_rate": 0.00024590094432765336,
        "gradient_norm": 0.35595718026161194,
        "train_loss": 3.0815718173980713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18507,
        "tokens": 9702998016,
        "learning_rate": 0.000245873724057688,
        "gradient_norm": 0.3232390284538269,
        "train_loss": 3.040266990661621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18508,
        "tokens": 9703522304,
        "learning_rate": 0.00024584650473466875,
        "gradient_norm": 0.3552388846874237,
        "train_loss": 3.053328514099121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18509,
        "tokens": 9704046592,
        "learning_rate": 0.0002458192863589021,
        "gradient_norm": 0.40129441022872925,
        "train_loss": 3.0783441066741943,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18510,
        "tokens": 9704570880,
        "learning_rate": 0.00024579206893069426,
        "gradient_norm": 0.3336411118507385,
        "train_loss": 3.056511878967285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18511,
        "tokens": 9705095168,
        "learning_rate": 0.00024576485245035167,
        "gradient_norm": 0.3590492010116577,
        "train_loss": 3.0603854656219482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18512,
        "tokens": 9705619456,
        "learning_rate": 0.0002457376369181806,
        "gradient_norm": 0.3624629080295563,
        "train_loss": 3.0994973182678223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18513,
        "tokens": 9706143744,
        "learning_rate": 0.0002457104223344876,
        "gradient_norm": 0.35662537813186646,
        "train_loss": 3.054560661315918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18514,
        "tokens": 9706668032,
        "learning_rate": 0.0002456832086995788,
        "gradient_norm": 0.40738987922668457,
        "train_loss": 3.0712432861328125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18515,
        "tokens": 9707192320,
        "learning_rate": 0.0002456559960137606,
        "gradient_norm": 0.3661944270133972,
        "train_loss": 3.122241258621216,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18516,
        "tokens": 9707716608,
        "learning_rate": 0.0002456287842773392,
        "gradient_norm": 0.40361759066581726,
        "train_loss": 3.0425643920898438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18517,
        "tokens": 9708240896,
        "learning_rate": 0.00024560157349062117,
        "gradient_norm": 0.33466291427612305,
        "train_loss": 3.0954623222351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18518,
        "tokens": 9708765184,
        "learning_rate": 0.0002455743636539125,
        "gradient_norm": 0.443097859621048,
        "train_loss": 3.1860411167144775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18519,
        "tokens": 9709289472,
        "learning_rate": 0.00024554715476751964,
        "gradient_norm": 0.3386476933956146,
        "train_loss": 3.0440726280212402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18520,
        "tokens": 9709813760,
        "learning_rate": 0.0002455199468317489,
        "gradient_norm": 0.42679405212402344,
        "train_loss": 3.075634241104126,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18521,
        "tokens": 9710338048,
        "learning_rate": 0.00024549273984690633,
        "gradient_norm": 0.44504740834236145,
        "train_loss": 3.073101043701172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18522,
        "tokens": 9710862336,
        "learning_rate": 0.00024546553381329846,
        "gradient_norm": 0.3554692268371582,
        "train_loss": 3.026075601577759,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18523,
        "tokens": 9711386624,
        "learning_rate": 0.00024543832873123126,
        "gradient_norm": 0.4160400927066803,
        "train_loss": 3.129887104034424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18524,
        "tokens": 9711910912,
        "learning_rate": 0.0002454111246010112,
        "gradient_norm": 0.3179265856742859,
        "train_loss": 3.072277069091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18525,
        "tokens": 9712435200,
        "learning_rate": 0.0002453839214229443,
        "gradient_norm": 0.40563830733299255,
        "train_loss": 3.0474982261657715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18526,
        "tokens": 9712959488,
        "learning_rate": 0.00024535671919733684,
        "gradient_norm": 0.3217547833919525,
        "train_loss": 3.072018623352051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18527,
        "tokens": 9713483776,
        "learning_rate": 0.00024532951792449503,
        "gradient_norm": 0.35719773173332214,
        "train_loss": 3.0807242393493652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18528,
        "tokens": 9714008064,
        "learning_rate": 0.00024530231760472494,
        "gradient_norm": 0.34362339973449707,
        "train_loss": 3.0903072357177734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18529,
        "tokens": 9714532352,
        "learning_rate": 0.00024527511823833306,
        "gradient_norm": 0.3841194808483124,
        "train_loss": 3.0608720779418945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18530,
        "tokens": 9715056640,
        "learning_rate": 0.00024524791982562515,
        "gradient_norm": 0.3341621458530426,
        "train_loss": 3.056633949279785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18531,
        "tokens": 9715580928,
        "learning_rate": 0.0002452207223669077,
        "gradient_norm": 0.3346787393093109,
        "train_loss": 3.064547300338745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18532,
        "tokens": 9716105216,
        "learning_rate": 0.0002451935258624865,
        "gradient_norm": 0.3518461585044861,
        "train_loss": 3.0902607440948486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18533,
        "tokens": 9716629504,
        "learning_rate": 0.0002451663303126681,
        "gradient_norm": 0.3059661388397217,
        "train_loss": 3.0233683586120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18534,
        "tokens": 9717153792,
        "learning_rate": 0.0002451391357177582,
        "gradient_norm": 0.3356594741344452,
        "train_loss": 3.096433162689209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18535,
        "tokens": 9717678080,
        "learning_rate": 0.0002451119420780633,
        "gradient_norm": 0.3395631015300751,
        "train_loss": 3.087583541870117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18536,
        "tokens": 9718202368,
        "learning_rate": 0.0002450847493938892,
        "gradient_norm": 0.33017203211784363,
        "train_loss": 3.0797438621520996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18537,
        "tokens": 9718726656,
        "learning_rate": 0.00024505755766554213,
        "gradient_norm": 0.3368363082408905,
        "train_loss": 3.064638137817383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18538,
        "tokens": 9719250944,
        "learning_rate": 0.00024503036689332803,
        "gradient_norm": 0.3205086290836334,
        "train_loss": 3.110874652862549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18539,
        "tokens": 9719775232,
        "learning_rate": 0.0002450031770775532,
        "gradient_norm": 0.31834179162979126,
        "train_loss": 3.0698554515838623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18540,
        "tokens": 9720299520,
        "learning_rate": 0.00024497598821852354,
        "gradient_norm": 0.3212135136127472,
        "train_loss": 3.0404181480407715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18541,
        "tokens": 9720823808,
        "learning_rate": 0.00024494880031654506,
        "gradient_norm": 0.34430360794067383,
        "train_loss": 3.0407376289367676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18542,
        "tokens": 9721348096,
        "learning_rate": 0.0002449216133719239,
        "gradient_norm": 0.35748085379600525,
        "train_loss": 3.0602872371673584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18543,
        "tokens": 9721872384,
        "learning_rate": 0.000244894427384966,
        "gradient_norm": 0.3381797969341278,
        "train_loss": 3.090543508529663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18544,
        "tokens": 9722396672,
        "learning_rate": 0.0002448672423559775,
        "gradient_norm": 0.34149491786956787,
        "train_loss": 3.1186304092407227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18545,
        "tokens": 9722920960,
        "learning_rate": 0.00024484005828526417,
        "gradient_norm": 0.35682934522628784,
        "train_loss": 3.04841685295105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18546,
        "tokens": 9723445248,
        "learning_rate": 0.0002448128751731322,
        "gradient_norm": 0.3117596507072449,
        "train_loss": 3.0729238986968994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18547,
        "tokens": 9723969536,
        "learning_rate": 0.00024478569301988754,
        "gradient_norm": 0.34850946068763733,
        "train_loss": 3.0336294174194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18548,
        "tokens": 9724493824,
        "learning_rate": 0.00024475851182583603,
        "gradient_norm": 0.30970796942710876,
        "train_loss": 3.105921745300293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18549,
        "tokens": 9725018112,
        "learning_rate": 0.0002447313315912838,
        "gradient_norm": 0.39579516649246216,
        "train_loss": 3.041388511657715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18550,
        "tokens": 9725542400,
        "learning_rate": 0.0002447041523165367,
        "gradient_norm": 0.3374006152153015,
        "train_loss": 3.0588908195495605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18551,
        "tokens": 9726066688,
        "learning_rate": 0.00024467697400190077,
        "gradient_norm": 0.39303064346313477,
        "train_loss": 3.100306510925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18552,
        "tokens": 9726590976,
        "learning_rate": 0.00024464979664768174,
        "gradient_norm": 0.36491039395332336,
        "train_loss": 3.0447349548339844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18553,
        "tokens": 9727115264,
        "learning_rate": 0.0002446226202541858,
        "gradient_norm": 0.3603571653366089,
        "train_loss": 3.0566811561584473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18554,
        "tokens": 9727639552,
        "learning_rate": 0.00024459544482171853,
        "gradient_norm": 0.3474772274494171,
        "train_loss": 3.0691189765930176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18555,
        "tokens": 9728163840,
        "learning_rate": 0.0002445682703505861,
        "gradient_norm": 0.325557142496109,
        "train_loss": 3.031923294067383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18556,
        "tokens": 9728688128,
        "learning_rate": 0.00024454109684109415,
        "gradient_norm": 0.338521808385849,
        "train_loss": 3.123508930206299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18557,
        "tokens": 9729212416,
        "learning_rate": 0.00024451392429354884,
        "gradient_norm": 0.346316933631897,
        "train_loss": 3.0075457096099854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18558,
        "tokens": 9729736704,
        "learning_rate": 0.00024448675270825567,
        "gradient_norm": 0.47405800223350525,
        "train_loss": 3.0966198444366455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18559,
        "tokens": 9730260992,
        "learning_rate": 0.00024445958208552083,
        "gradient_norm": 0.40564092993736267,
        "train_loss": 3.0454349517822266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18560,
        "tokens": 9730785280,
        "learning_rate": 0.00024443241242565005,
        "gradient_norm": 0.34038498997688293,
        "train_loss": 3.0862886905670166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18561,
        "tokens": 9731309568,
        "learning_rate": 0.00024440524372894897,
        "gradient_norm": 0.42530205845832825,
        "train_loss": 3.0805070400238037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18562,
        "tokens": 9731833856,
        "learning_rate": 0.0002443780759957238,
        "gradient_norm": 0.3641981780529022,
        "train_loss": 3.0905442237854004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18563,
        "tokens": 9732358144,
        "learning_rate": 0.00024435090922627994,
        "gradient_norm": 0.3734542727470398,
        "train_loss": 3.127138376235962,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18564,
        "tokens": 9732882432,
        "learning_rate": 0.0002443237434209235,
        "gradient_norm": 0.4219558537006378,
        "train_loss": 3.0997323989868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18565,
        "tokens": 9733406720,
        "learning_rate": 0.00024429657857995995,
        "gradient_norm": 0.324124276638031,
        "train_loss": 3.0854172706604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18566,
        "tokens": 9733931008,
        "learning_rate": 0.0002442694147036954,
        "gradient_norm": 0.3592335879802704,
        "train_loss": 3.064026355743408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18567,
        "tokens": 9734455296,
        "learning_rate": 0.00024424225179243536,
        "gradient_norm": 0.4307613968849182,
        "train_loss": 3.0727462768554688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18568,
        "tokens": 9734979584,
        "learning_rate": 0.0002442150898464857,
        "gradient_norm": 0.37360379099845886,
        "train_loss": 3.0620296001434326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18569,
        "tokens": 9735503872,
        "learning_rate": 0.00024418792886615217,
        "gradient_norm": 0.3774462938308716,
        "train_loss": 3.096858024597168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18570,
        "tokens": 9736028160,
        "learning_rate": 0.0002441607688517404,
        "gradient_norm": 0.39640817046165466,
        "train_loss": 3.061906099319458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18571,
        "tokens": 9736552448,
        "learning_rate": 0.00024413360980355629,
        "gradient_norm": 0.3521392345428467,
        "train_loss": 3.061603546142578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18572,
        "tokens": 9737076736,
        "learning_rate": 0.00024410645172190533,
        "gradient_norm": 0.3991047441959381,
        "train_loss": 3.075319766998291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18573,
        "tokens": 9737601024,
        "learning_rate": 0.0002440792946070934,
        "gradient_norm": 0.4173876941204071,
        "train_loss": 3.0905489921569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18574,
        "tokens": 9738125312,
        "learning_rate": 0.00024405213845942603,
        "gradient_norm": 0.42940229177474976,
        "train_loss": 3.1205129623413086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18575,
        "tokens": 9738649600,
        "learning_rate": 0.00024402498327920908,
        "gradient_norm": 0.37415769696235657,
        "train_loss": 3.038656711578369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18576,
        "tokens": 9739173888,
        "learning_rate": 0.000243997829066748,
        "gradient_norm": 0.38522616028785706,
        "train_loss": 3.1111669540405273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18577,
        "tokens": 9739698176,
        "learning_rate": 0.0002439706758223487,
        "gradient_norm": 0.36219653487205505,
        "train_loss": 3.0730395317077637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18578,
        "tokens": 9740222464,
        "learning_rate": 0.00024394352354631653,
        "gradient_norm": 0.34970542788505554,
        "train_loss": 3.0457162857055664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18579,
        "tokens": 9740746752,
        "learning_rate": 0.00024391637223895727,
        "gradient_norm": 0.34755924344062805,
        "train_loss": 3.0600900650024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18580,
        "tokens": 9741271040,
        "learning_rate": 0.0002438892219005767,
        "gradient_norm": 0.3243798613548279,
        "train_loss": 3.020613193511963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18581,
        "tokens": 9741795328,
        "learning_rate": 0.00024386207253148013,
        "gradient_norm": 0.3582068383693695,
        "train_loss": 3.1534013748168945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18582,
        "tokens": 9742319616,
        "learning_rate": 0.00024383492413197343,
        "gradient_norm": 0.4764438271522522,
        "train_loss": 3.282686471939087,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18583,
        "tokens": 9742843904,
        "learning_rate": 0.00024380777670236198,
        "gradient_norm": 0.39431294798851013,
        "train_loss": 3.097522258758545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18584,
        "tokens": 9743368192,
        "learning_rate": 0.00024378063024295152,
        "gradient_norm": 0.4114193618297577,
        "train_loss": 3.0782265663146973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18585,
        "tokens": 9743892480,
        "learning_rate": 0.00024375348475404746,
        "gradient_norm": 0.3241559565067291,
        "train_loss": 3.1005358695983887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18586,
        "tokens": 9744416768,
        "learning_rate": 0.00024372634023595553,
        "gradient_norm": 0.42381036281585693,
        "train_loss": 3.1870479583740234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18587,
        "tokens": 9744941056,
        "learning_rate": 0.00024369919668898107,
        "gradient_norm": 0.36689284443855286,
        "train_loss": 3.0466697216033936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18588,
        "tokens": 9745465344,
        "learning_rate": 0.0002436720541134298,
        "gradient_norm": 0.3178523778915405,
        "train_loss": 3.0353755950927734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18589,
        "tokens": 9745989632,
        "learning_rate": 0.00024364491250960716,
        "gradient_norm": 0.36146166920661926,
        "train_loss": 3.0373919010162354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18590,
        "tokens": 9746513920,
        "learning_rate": 0.0002436177718778187,
        "gradient_norm": 0.40226125717163086,
        "train_loss": 3.0815000534057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18591,
        "tokens": 9747038208,
        "learning_rate": 0.00024359063221836988,
        "gradient_norm": 0.4438854455947876,
        "train_loss": 3.064202308654785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18592,
        "tokens": 9747562496,
        "learning_rate": 0.00024356349353156617,
        "gradient_norm": 0.3612729609012604,
        "train_loss": 3.052511215209961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18593,
        "tokens": 9748086784,
        "learning_rate": 0.00024353635581771314,
        "gradient_norm": 0.37889108061790466,
        "train_loss": 3.0610673427581787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18594,
        "tokens": 9748611072,
        "learning_rate": 0.00024350921907711616,
        "gradient_norm": 0.46317675709724426,
        "train_loss": 3.0259172916412354,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18595,
        "tokens": 9749135360,
        "learning_rate": 0.00024348208331008076,
        "gradient_norm": 0.4106244742870331,
        "train_loss": 3.1263952255249023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18596,
        "tokens": 9749659648,
        "learning_rate": 0.00024345494851691236,
        "gradient_norm": 0.37982842326164246,
        "train_loss": 3.1209142208099365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18597,
        "tokens": 9750183936,
        "learning_rate": 0.00024342781469791636,
        "gradient_norm": 0.41992583870887756,
        "train_loss": 3.1551153659820557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18598,
        "tokens": 9750708224,
        "learning_rate": 0.00024340068185339827,
        "gradient_norm": 0.38511109352111816,
        "train_loss": 3.1886682510375977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18599,
        "tokens": 9751232512,
        "learning_rate": 0.0002433735499836634,
        "gradient_norm": 0.42897680401802063,
        "train_loss": 3.101391077041626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18600,
        "tokens": 9751756800,
        "learning_rate": 0.00024334641908901726,
        "gradient_norm": 0.3647916913032532,
        "train_loss": 3.006014347076416,
        "val_loss": 3.0372085571289062,
        "hellaswag_acc": 0.28131845593452454,
        "hellaswag_acc_norm": 0.2881895899772644
    },
    {
        "step": 18601,
        "tokens": 9752281088,
        "learning_rate": 0.00024331928916976512,
        "gradient_norm": 0.33676382899284363,
        "train_loss": 3.085653781890869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18602,
        "tokens": 9752805376,
        "learning_rate": 0.00024329216022621257,
        "gradient_norm": 0.43800368905067444,
        "train_loss": 3.1614341735839844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18603,
        "tokens": 9753329664,
        "learning_rate": 0.00024326503225866468,
        "gradient_norm": 0.3545021414756775,
        "train_loss": 3.081707000732422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18604,
        "tokens": 9753853952,
        "learning_rate": 0.0002432379052674271,
        "gradient_norm": 0.36437225341796875,
        "train_loss": 3.071610450744629,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18605,
        "tokens": 9754378240,
        "learning_rate": 0.0002432107792528049,
        "gradient_norm": 0.35961291193962097,
        "train_loss": 3.113870143890381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18606,
        "tokens": 9754902528,
        "learning_rate": 0.00024318365421510373,
        "gradient_norm": 0.3675415813922882,
        "train_loss": 3.052412986755371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18607,
        "tokens": 9755426816,
        "learning_rate": 0.0002431565301546286,
        "gradient_norm": 0.33429405093193054,
        "train_loss": 3.078357219696045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18608,
        "tokens": 9755951104,
        "learning_rate": 0.00024312940707168503,
        "gradient_norm": 0.38806334137916565,
        "train_loss": 3.0587105751037598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18609,
        "tokens": 9756475392,
        "learning_rate": 0.00024310228496657836,
        "gradient_norm": 0.34205108880996704,
        "train_loss": 3.0637941360473633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18610,
        "tokens": 9756999680,
        "learning_rate": 0.00024307516383961366,
        "gradient_norm": 0.3781355917453766,
        "train_loss": 3.067074775695801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18611,
        "tokens": 9757523968,
        "learning_rate": 0.00024304804369109647,
        "gradient_norm": 0.3599775433540344,
        "train_loss": 3.039092779159546,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18612,
        "tokens": 9758048256,
        "learning_rate": 0.00024302092452133182,
        "gradient_norm": 0.3462640047073364,
        "train_loss": 3.097985029220581,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18613,
        "tokens": 9758572544,
        "learning_rate": 0.0002429938063306252,
        "gradient_norm": 0.3616216480731964,
        "train_loss": 3.0390262603759766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18614,
        "tokens": 9759096832,
        "learning_rate": 0.00024296668911928164,
        "gradient_norm": 0.3248087465763092,
        "train_loss": 3.0705771446228027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18615,
        "tokens": 9759621120,
        "learning_rate": 0.00024293957288760656,
        "gradient_norm": 0.3536742925643921,
        "train_loss": 3.0335888862609863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18616,
        "tokens": 9760145408,
        "learning_rate": 0.00024291245763590508,
        "gradient_norm": 0.3291724920272827,
        "train_loss": 3.116894245147705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18617,
        "tokens": 9760669696,
        "learning_rate": 0.0002428853433644825,
        "gradient_norm": 0.35029345750808716,
        "train_loss": 3.0589599609375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18618,
        "tokens": 9761193984,
        "learning_rate": 0.00024285823007364385,
        "gradient_norm": 0.37163978815078735,
        "train_loss": 3.061436653137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18619,
        "tokens": 9761718272,
        "learning_rate": 0.00024283111776369446,
        "gradient_norm": 0.33553701639175415,
        "train_loss": 3.0673046112060547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18620,
        "tokens": 9762242560,
        "learning_rate": 0.00024280400643493963,
        "gradient_norm": 0.34809044003486633,
        "train_loss": 3.007932186126709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18621,
        "tokens": 9762766848,
        "learning_rate": 0.00024277689608768427,
        "gradient_norm": 0.3716298043727875,
        "train_loss": 3.077277183532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18622,
        "tokens": 9763291136,
        "learning_rate": 0.0002427497867222338,
        "gradient_norm": 0.3472541570663452,
        "train_loss": 3.0223276615142822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18623,
        "tokens": 9763815424,
        "learning_rate": 0.0002427226783388931,
        "gradient_norm": 0.3362014591693878,
        "train_loss": 3.058051586151123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18624,
        "tokens": 9764339712,
        "learning_rate": 0.00024269557093796758,
        "gradient_norm": 0.38305947184562683,
        "train_loss": 3.080165147781372,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18625,
        "tokens": 9764864000,
        "learning_rate": 0.00024266846451976212,
        "gradient_norm": 0.3478688895702362,
        "train_loss": 3.0946624279022217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18626,
        "tokens": 9765388288,
        "learning_rate": 0.00024264135908458207,
        "gradient_norm": 0.36984026432037354,
        "train_loss": 3.1506686210632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18627,
        "tokens": 9765912576,
        "learning_rate": 0.0002426142546327323,
        "gradient_norm": 0.35092195868492126,
        "train_loss": 3.0072576999664307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18628,
        "tokens": 9766436864,
        "learning_rate": 0.00024258715116451805,
        "gradient_norm": 0.35215139389038086,
        "train_loss": 3.115805149078369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18629,
        "tokens": 9766961152,
        "learning_rate": 0.00024256004868024447,
        "gradient_norm": 0.35707351565361023,
        "train_loss": 3.102212905883789,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18630,
        "tokens": 9767485440,
        "learning_rate": 0.0002425329471802164,
        "gradient_norm": 0.3233890235424042,
        "train_loss": 3.0625412464141846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18631,
        "tokens": 9768009728,
        "learning_rate": 0.00024250584666473917,
        "gradient_norm": 0.34209585189819336,
        "train_loss": 3.0969815254211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18632,
        "tokens": 9768534016,
        "learning_rate": 0.0002424787471341176,
        "gradient_norm": 0.3735348880290985,
        "train_loss": 3.0421528816223145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18633,
        "tokens": 9769058304,
        "learning_rate": 0.00024245164858865693,
        "gradient_norm": 0.3526131212711334,
        "train_loss": 3.04313325881958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18634,
        "tokens": 9769582592,
        "learning_rate": 0.000242424551028662,
        "gradient_norm": 0.3179565370082855,
        "train_loss": 3.051966905593872,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18635,
        "tokens": 9770106880,
        "learning_rate": 0.000242397454454438,
        "gradient_norm": 0.3825254440307617,
        "train_loss": 3.0946431159973145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18636,
        "tokens": 9770631168,
        "learning_rate": 0.00024237035886628974,
        "gradient_norm": 0.4167262017726898,
        "train_loss": 3.0174365043640137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18637,
        "tokens": 9771155456,
        "learning_rate": 0.0002423432642645224,
        "gradient_norm": 0.3783073127269745,
        "train_loss": 3.0930891036987305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18638,
        "tokens": 9771679744,
        "learning_rate": 0.00024231617064944086,
        "gradient_norm": 0.3749505579471588,
        "train_loss": 3.0779995918273926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18639,
        "tokens": 9772204032,
        "learning_rate": 0.0002422890780213501,
        "gradient_norm": 0.4113708734512329,
        "train_loss": 3.01519775390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18640,
        "tokens": 9772728320,
        "learning_rate": 0.00024226198638055516,
        "gradient_norm": 0.3545714318752289,
        "train_loss": 3.09594988822937,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18641,
        "tokens": 9773252608,
        "learning_rate": 0.00024223489572736088,
        "gradient_norm": 0.4176449477672577,
        "train_loss": 3.0404815673828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18642,
        "tokens": 9773776896,
        "learning_rate": 0.00024220780606207227,
        "gradient_norm": 0.3644026815891266,
        "train_loss": 3.0268096923828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18643,
        "tokens": 9774301184,
        "learning_rate": 0.00024218071738499425,
        "gradient_norm": 0.38743162155151367,
        "train_loss": 3.069880247116089,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18644,
        "tokens": 9774825472,
        "learning_rate": 0.0002421536296964317,
        "gradient_norm": 0.3932967483997345,
        "train_loss": 3.072082757949829,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18645,
        "tokens": 9775349760,
        "learning_rate": 0.00024212654299668958,
        "gradient_norm": 0.4530969560146332,
        "train_loss": 3.080843448638916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18646,
        "tokens": 9775874048,
        "learning_rate": 0.00024209945728607274,
        "gradient_norm": 0.42180657386779785,
        "train_loss": 3.0392985343933105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18647,
        "tokens": 9776398336,
        "learning_rate": 0.0002420723725648861,
        "gradient_norm": 0.372920423746109,
        "train_loss": 3.090325355529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18648,
        "tokens": 9776922624,
        "learning_rate": 0.00024204528883343441,
        "gradient_norm": 0.3979431092739105,
        "train_loss": 3.0874485969543457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18649,
        "tokens": 9777446912,
        "learning_rate": 0.00024201820609202283,
        "gradient_norm": 0.35485124588012695,
        "train_loss": 3.076516628265381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18650,
        "tokens": 9777971200,
        "learning_rate": 0.0002419911243409558,
        "gradient_norm": 0.35902127623558044,
        "train_loss": 3.079627513885498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18651,
        "tokens": 9778495488,
        "learning_rate": 0.00024196404358053854,
        "gradient_norm": 0.3235524594783783,
        "train_loss": 3.0459375381469727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18652,
        "tokens": 9779019776,
        "learning_rate": 0.0002419369638110756,
        "gradient_norm": 0.3688810467720032,
        "train_loss": 3.0241200923919678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18653,
        "tokens": 9779544064,
        "learning_rate": 0.000241909885032872,
        "gradient_norm": 0.3345991373062134,
        "train_loss": 3.0812530517578125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18654,
        "tokens": 9780068352,
        "learning_rate": 0.00024188280724623233,
        "gradient_norm": 0.3674469292163849,
        "train_loss": 3.032933235168457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18655,
        "tokens": 9780592640,
        "learning_rate": 0.00024185573045146163,
        "gradient_norm": 0.381004273891449,
        "train_loss": 3.085023880004883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18656,
        "tokens": 9781116928,
        "learning_rate": 0.00024182865464886444,
        "gradient_norm": 0.335606187582016,
        "train_loss": 3.061074733734131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18657,
        "tokens": 9781641216,
        "learning_rate": 0.0002418015798387458,
        "gradient_norm": 0.3523808717727661,
        "train_loss": 3.086677312850952,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18658,
        "tokens": 9782165504,
        "learning_rate": 0.00024177450602141015,
        "gradient_norm": 0.32667627930641174,
        "train_loss": 3.046562910079956,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18659,
        "tokens": 9782689792,
        "learning_rate": 0.00024174743319716244,
        "gradient_norm": 0.32461684942245483,
        "train_loss": 3.0597620010375977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18660,
        "tokens": 9783214080,
        "learning_rate": 0.0002417203613663075,
        "gradient_norm": 0.30533185601234436,
        "train_loss": 3.0468783378601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18661,
        "tokens": 9783738368,
        "learning_rate": 0.0002416932905291498,
        "gradient_norm": 0.3170647919178009,
        "train_loss": 3.1040053367614746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18662,
        "tokens": 9784262656,
        "learning_rate": 0.00024166622068599433,
        "gradient_norm": 0.3816673457622528,
        "train_loss": 3.0838499069213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18663,
        "tokens": 9784786944,
        "learning_rate": 0.0002416391518371455,
        "gradient_norm": 0.37343457341194153,
        "train_loss": 3.0654263496398926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18664,
        "tokens": 9785311232,
        "learning_rate": 0.00024161208398290832,
        "gradient_norm": 0.3566160202026367,
        "train_loss": 3.074350118637085,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18665,
        "tokens": 9785835520,
        "learning_rate": 0.0002415850171235872,
        "gradient_norm": 0.3974250853061676,
        "train_loss": 3.0584073066711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18666,
        "tokens": 9786359808,
        "learning_rate": 0.00024155795125948703,
        "gradient_norm": 0.3626258969306946,
        "train_loss": 3.01483154296875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18667,
        "tokens": 9786884096,
        "learning_rate": 0.00024153088639091225,
        "gradient_norm": 0.40369096398353577,
        "train_loss": 3.083178997039795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18668,
        "tokens": 9787408384,
        "learning_rate": 0.0002415038225181676,
        "gradient_norm": 0.40958189964294434,
        "train_loss": 3.0655760765075684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18669,
        "tokens": 9787932672,
        "learning_rate": 0.00024147675964155787,
        "gradient_norm": 0.3530191481113434,
        "train_loss": 3.0614991188049316,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18670,
        "tokens": 9788456960,
        "learning_rate": 0.00024144969776138746,
        "gradient_norm": 0.46042600274086,
        "train_loss": 3.0651111602783203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18671,
        "tokens": 9788981248,
        "learning_rate": 0.00024142263687796118,
        "gradient_norm": 0.34593865275382996,
        "train_loss": 3.0789732933044434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18672,
        "tokens": 9789505536,
        "learning_rate": 0.0002413955769915834,
        "gradient_norm": 0.3759842813014984,
        "train_loss": 3.0621719360351562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18673,
        "tokens": 9790029824,
        "learning_rate": 0.000241368518102559,
        "gradient_norm": 0.3324151039123535,
        "train_loss": 3.0659661293029785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18674,
        "tokens": 9790554112,
        "learning_rate": 0.0002413414602111923,
        "gradient_norm": 0.3766380846500397,
        "train_loss": 3.1140708923339844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18675,
        "tokens": 9791078400,
        "learning_rate": 0.00024131440331778806,
        "gradient_norm": 0.389295369386673,
        "train_loss": 3.0883307456970215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18676,
        "tokens": 9791602688,
        "learning_rate": 0.0002412873474226507,
        "gradient_norm": 0.36444059014320374,
        "train_loss": 3.0862386226654053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18677,
        "tokens": 9792126976,
        "learning_rate": 0.0002412602925260849,
        "gradient_norm": 0.325662225484848,
        "train_loss": 3.068868637084961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18678,
        "tokens": 9792651264,
        "learning_rate": 0.000241233238628395,
        "gradient_norm": 0.3515402674674988,
        "train_loss": 3.093038558959961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18679,
        "tokens": 9793175552,
        "learning_rate": 0.00024120618572988568,
        "gradient_norm": 0.3311459720134735,
        "train_loss": 3.094507932662964,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18680,
        "tokens": 9793699840,
        "learning_rate": 0.00024117913383086152,
        "gradient_norm": 0.38611117005348206,
        "train_loss": 3.1374783515930176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18681,
        "tokens": 9794224128,
        "learning_rate": 0.00024115208293162683,
        "gradient_norm": 0.34974947571754456,
        "train_loss": 3.072289228439331,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18682,
        "tokens": 9794748416,
        "learning_rate": 0.00024112503303248633,
        "gradient_norm": 0.3692757785320282,
        "train_loss": 3.0716099739074707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18683,
        "tokens": 9795272704,
        "learning_rate": 0.0002410979841337442,
        "gradient_norm": 0.35911041498184204,
        "train_loss": 3.0689451694488525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18684,
        "tokens": 9795796992,
        "learning_rate": 0.00024107093623570522,
        "gradient_norm": 0.4073772132396698,
        "train_loss": 3.051046371459961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18685,
        "tokens": 9796321280,
        "learning_rate": 0.0002410438893386736,
        "gradient_norm": 0.3633100390434265,
        "train_loss": 3.135129928588867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18686,
        "tokens": 9796845568,
        "learning_rate": 0.000241016843442954,
        "gradient_norm": 0.345917671918869,
        "train_loss": 3.0622310638427734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18687,
        "tokens": 9797369856,
        "learning_rate": 0.00024098979854885063,
        "gradient_norm": 0.3625392019748688,
        "train_loss": 3.0714008808135986,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18688,
        "tokens": 9797894144,
        "learning_rate": 0.00024096275465666808,
        "gradient_norm": 0.3550734519958496,
        "train_loss": 3.055898904800415,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18689,
        "tokens": 9798418432,
        "learning_rate": 0.00024093571176671074,
        "gradient_norm": 0.3612557351589203,
        "train_loss": 3.1146042346954346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18690,
        "tokens": 9798942720,
        "learning_rate": 0.00024090866987928295,
        "gradient_norm": 0.348861426115036,
        "train_loss": 3.0562691688537598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18691,
        "tokens": 9799467008,
        "learning_rate": 0.00024088162899468915,
        "gradient_norm": 0.38154998421669006,
        "train_loss": 3.0735814571380615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18692,
        "tokens": 9799991296,
        "learning_rate": 0.00024085458911323374,
        "gradient_norm": 0.38229820132255554,
        "train_loss": 3.097550392150879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18693,
        "tokens": 9800515584,
        "learning_rate": 0.000240827550235221,
        "gradient_norm": 0.417967289686203,
        "train_loss": 3.0652735233306885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18694,
        "tokens": 9801039872,
        "learning_rate": 0.00024080051236095534,
        "gradient_norm": 0.3447597324848175,
        "train_loss": 3.0746536254882812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18695,
        "tokens": 9801564160,
        "learning_rate": 0.00024077347549074116,
        "gradient_norm": 0.3687881529331207,
        "train_loss": 3.06484317779541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18696,
        "tokens": 9802088448,
        "learning_rate": 0.00024074643962488268,
        "gradient_norm": 0.4791344702243805,
        "train_loss": 3.116842269897461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18697,
        "tokens": 9802612736,
        "learning_rate": 0.0002407194047636843,
        "gradient_norm": 0.406727135181427,
        "train_loss": 3.0127766132354736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18698,
        "tokens": 9803137024,
        "learning_rate": 0.00024069237090745032,
        "gradient_norm": 0.3709842562675476,
        "train_loss": 3.062516689300537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18699,
        "tokens": 9803661312,
        "learning_rate": 0.00024066533805648495,
        "gradient_norm": 0.3601633310317993,
        "train_loss": 3.0860278606414795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18700,
        "tokens": 9804185600,
        "learning_rate": 0.00024063830621109264,
        "gradient_norm": 0.3419966399669647,
        "train_loss": 3.059596061706543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18701,
        "tokens": 9804709888,
        "learning_rate": 0.00024061127537157757,
        "gradient_norm": 0.35092663764953613,
        "train_loss": 3.06473970413208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18702,
        "tokens": 9805234176,
        "learning_rate": 0.00024058424553824402,
        "gradient_norm": 0.31904637813568115,
        "train_loss": 3.0961687564849854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18703,
        "tokens": 9805758464,
        "learning_rate": 0.00024055721671139627,
        "gradient_norm": 0.34169629216194153,
        "train_loss": 3.103816032409668,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18704,
        "tokens": 9806282752,
        "learning_rate": 0.0002405301888913385,
        "gradient_norm": 0.31849777698516846,
        "train_loss": 3.042412757873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18705,
        "tokens": 9806807040,
        "learning_rate": 0.000240503162078375,
        "gradient_norm": 0.3525465428829193,
        "train_loss": 3.1365697383880615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18706,
        "tokens": 9807331328,
        "learning_rate": 0.00024047613627281,
        "gradient_norm": 0.3419075310230255,
        "train_loss": 3.053976535797119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18707,
        "tokens": 9807855616,
        "learning_rate": 0.00024044911147494763,
        "gradient_norm": 0.36384129524230957,
        "train_loss": 3.0719337463378906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18708,
        "tokens": 9808379904,
        "learning_rate": 0.00024042208768509213,
        "gradient_norm": 0.33740562200546265,
        "train_loss": 3.101583957672119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18709,
        "tokens": 9808904192,
        "learning_rate": 0.0002403950649035478,
        "gradient_norm": 0.3657046854496002,
        "train_loss": 3.0108275413513184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18710,
        "tokens": 9809428480,
        "learning_rate": 0.00024036804313061854,
        "gradient_norm": 0.35785844922065735,
        "train_loss": 3.0935046672821045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18711,
        "tokens": 9809952768,
        "learning_rate": 0.00024034102236660887,
        "gradient_norm": 0.36106443405151367,
        "train_loss": 3.178770065307617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18712,
        "tokens": 9810477056,
        "learning_rate": 0.0002403140026118226,
        "gradient_norm": 0.4500015676021576,
        "train_loss": 3.080902576446533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18713,
        "tokens": 9811001344,
        "learning_rate": 0.00024028698386656416,
        "gradient_norm": 0.4760071635246277,
        "train_loss": 3.09122896194458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18714,
        "tokens": 9811525632,
        "learning_rate": 0.00024025996613113743,
        "gradient_norm": 0.3343307077884674,
        "train_loss": 3.062901496887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18715,
        "tokens": 9812049920,
        "learning_rate": 0.00024023294940584675,
        "gradient_norm": 0.41106322407722473,
        "train_loss": 3.06539249420166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18716,
        "tokens": 9812574208,
        "learning_rate": 0.00024020593369099603,
        "gradient_norm": 0.34577345848083496,
        "train_loss": 3.1069254875183105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18717,
        "tokens": 9813098496,
        "learning_rate": 0.00024017891898688942,
        "gradient_norm": 0.43191537261009216,
        "train_loss": 3.0515499114990234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18718,
        "tokens": 9813622784,
        "learning_rate": 0.00024015190529383122,
        "gradient_norm": 0.33181071281433105,
        "train_loss": 3.053107261657715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18719,
        "tokens": 9814147072,
        "learning_rate": 0.00024012489261212512,
        "gradient_norm": 0.4129558801651001,
        "train_loss": 3.102294921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18720,
        "tokens": 9814671360,
        "learning_rate": 0.00024009788094207554,
        "gradient_norm": 0.34379345178604126,
        "train_loss": 3.047532081604004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18721,
        "tokens": 9815195648,
        "learning_rate": 0.00024007087028398628,
        "gradient_norm": 0.36775505542755127,
        "train_loss": 3.1437337398529053,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18722,
        "tokens": 9815719936,
        "learning_rate": 0.00024004386063816157,
        "gradient_norm": 0.38618016242980957,
        "train_loss": 3.1112782955169678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18723,
        "tokens": 9816244224,
        "learning_rate": 0.00024001685200490523,
        "gradient_norm": 0.34222444891929626,
        "train_loss": 3.0905795097351074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18724,
        "tokens": 9816768512,
        "learning_rate": 0.0002399898443845215,
        "gradient_norm": 0.3845880925655365,
        "train_loss": 3.0717928409576416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18725,
        "tokens": 9817292800,
        "learning_rate": 0.0002399628377773142,
        "gradient_norm": 0.35606807470321655,
        "train_loss": 3.0872530937194824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18726,
        "tokens": 9817817088,
        "learning_rate": 0.0002399358321835875,
        "gradient_norm": 0.37456539273262024,
        "train_loss": 3.061246633529663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18727,
        "tokens": 9818341376,
        "learning_rate": 0.00023990882760364511,
        "gradient_norm": 0.317143052816391,
        "train_loss": 3.0286619663238525,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18728,
        "tokens": 9818865664,
        "learning_rate": 0.00023988182403779118,
        "gradient_norm": 0.35851386189460754,
        "train_loss": 3.062333583831787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18729,
        "tokens": 9819389952,
        "learning_rate": 0.0002398548214863298,
        "gradient_norm": 0.30747997760772705,
        "train_loss": 3.0634493827819824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18730,
        "tokens": 9819914240,
        "learning_rate": 0.00023982781994956465,
        "gradient_norm": 0.3408101499080658,
        "train_loss": 3.0520009994506836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18731,
        "tokens": 9820438528,
        "learning_rate": 0.00023980081942779987,
        "gradient_norm": 0.3410536050796509,
        "train_loss": 3.1115095615386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18732,
        "tokens": 9820962816,
        "learning_rate": 0.00023977381992133925,
        "gradient_norm": 0.3187641501426697,
        "train_loss": 3.0610127449035645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18733,
        "tokens": 9821487104,
        "learning_rate": 0.00023974682143048683,
        "gradient_norm": 0.32859674096107483,
        "train_loss": 3.050464153289795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18734,
        "tokens": 9822011392,
        "learning_rate": 0.0002397198239555463,
        "gradient_norm": 0.3333124816417694,
        "train_loss": 3.040041923522949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18735,
        "tokens": 9822535680,
        "learning_rate": 0.00023969282749682183,
        "gradient_norm": 0.340412974357605,
        "train_loss": 3.0769057273864746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18736,
        "tokens": 9823059968,
        "learning_rate": 0.00023966583205461706,
        "gradient_norm": 0.3984537720680237,
        "train_loss": 3.064807891845703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18737,
        "tokens": 9823584256,
        "learning_rate": 0.0002396388376292359,
        "gradient_norm": 0.34407302737236023,
        "train_loss": 3.125713586807251,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18738,
        "tokens": 9824108544,
        "learning_rate": 0.00023961184422098246,
        "gradient_norm": 0.3997989594936371,
        "train_loss": 3.0853636264801025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18739,
        "tokens": 9824632832,
        "learning_rate": 0.00023958485183016024,
        "gradient_norm": 0.3140539228916168,
        "train_loss": 3.137338399887085,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18740,
        "tokens": 9825157120,
        "learning_rate": 0.00023955786045707332,
        "gradient_norm": 0.3776406943798065,
        "train_loss": 3.086366891860962,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18741,
        "tokens": 9825681408,
        "learning_rate": 0.00023953087010202527,
        "gradient_norm": 0.35559791326522827,
        "train_loss": 3.101015329360962,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18742,
        "tokens": 9826205696,
        "learning_rate": 0.0002395038807653202,
        "gradient_norm": 0.41128626465797424,
        "train_loss": 3.0607810020446777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18743,
        "tokens": 9826729984,
        "learning_rate": 0.00023947689244726165,
        "gradient_norm": 0.5034490823745728,
        "train_loss": 2.9800891876220703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18744,
        "tokens": 9827254272,
        "learning_rate": 0.00023944990514815364,
        "gradient_norm": 0.35705435276031494,
        "train_loss": 3.109654188156128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18745,
        "tokens": 9827778560,
        "learning_rate": 0.00023942291886829968,
        "gradient_norm": 0.3705013692378998,
        "train_loss": 3.060030460357666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18746,
        "tokens": 9828302848,
        "learning_rate": 0.00023939593360800378,
        "gradient_norm": 0.33205193281173706,
        "train_loss": 3.0455756187438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18747,
        "tokens": 9828827136,
        "learning_rate": 0.0002393689493675695,
        "gradient_norm": 0.4181959629058838,
        "train_loss": 2.947237491607666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18748,
        "tokens": 9829351424,
        "learning_rate": 0.0002393419661473007,
        "gradient_norm": 0.33086103200912476,
        "train_loss": 3.0394835472106934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18749,
        "tokens": 9829875712,
        "learning_rate": 0.00023931498394750113,
        "gradient_norm": 0.32368412613868713,
        "train_loss": 3.0778708457946777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18750,
        "tokens": 9830400000,
        "learning_rate": 0.0002392880027684744,
        "gradient_norm": 0.34059494733810425,
        "train_loss": 3.0996103286743164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18751,
        "tokens": 9830924288,
        "learning_rate": 0.00023926102261052432,
        "gradient_norm": 0.33064165711402893,
        "train_loss": 3.0530643463134766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18752,
        "tokens": 9831448576,
        "learning_rate": 0.0002392340434739545,
        "gradient_norm": 0.33845990896224976,
        "train_loss": 3.117185592651367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18753,
        "tokens": 9831972864,
        "learning_rate": 0.00023920706535906873,
        "gradient_norm": 0.3669763207435608,
        "train_loss": 3.0940332412719727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18754,
        "tokens": 9832497152,
        "learning_rate": 0.00023918008826617055,
        "gradient_norm": 0.3662845194339752,
        "train_loss": 3.121772289276123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18755,
        "tokens": 9833021440,
        "learning_rate": 0.0002391531121955637,
        "gradient_norm": 0.39197301864624023,
        "train_loss": 3.066570281982422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18756,
        "tokens": 9833545728,
        "learning_rate": 0.00023912613714755182,
        "gradient_norm": 0.3812675178050995,
        "train_loss": 3.072913646697998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18757,
        "tokens": 9834070016,
        "learning_rate": 0.00023909916312243849,
        "gradient_norm": 0.4591308832168579,
        "train_loss": 3.0602316856384277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18758,
        "tokens": 9834594304,
        "learning_rate": 0.0002390721901205275,
        "gradient_norm": 0.44414329528808594,
        "train_loss": 3.085050582885742,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18759,
        "tokens": 9835118592,
        "learning_rate": 0.00023904521814212224,
        "gradient_norm": 0.4203210771083832,
        "train_loss": 3.041064500808716,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18760,
        "tokens": 9835642880,
        "learning_rate": 0.00023901824718752652,
        "gradient_norm": 0.47688281536102295,
        "train_loss": 3.181783437728882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18761,
        "tokens": 9836167168,
        "learning_rate": 0.00023899127725704377,
        "gradient_norm": 0.3579617738723755,
        "train_loss": 2.997040271759033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18762,
        "tokens": 9836691456,
        "learning_rate": 0.00023896430835097774,
        "gradient_norm": 0.47101062536239624,
        "train_loss": 3.137007713317871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18763,
        "tokens": 9837215744,
        "learning_rate": 0.00023893734046963178,
        "gradient_norm": 0.37084007263183594,
        "train_loss": 3.107733726501465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18764,
        "tokens": 9837740032,
        "learning_rate": 0.00023891037361330967,
        "gradient_norm": 0.44318288564682007,
        "train_loss": 3.070622205734253,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18765,
        "tokens": 9838264320,
        "learning_rate": 0.00023888340778231473,
        "gradient_norm": 0.3875236511230469,
        "train_loss": 3.040132522583008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18766,
        "tokens": 9838788608,
        "learning_rate": 0.00023885644297695074,
        "gradient_norm": 0.33584973216056824,
        "train_loss": 3.026237964630127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18767,
        "tokens": 9839312896,
        "learning_rate": 0.000238829479197521,
        "gradient_norm": 0.35372859239578247,
        "train_loss": 3.0809717178344727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18768,
        "tokens": 9839837184,
        "learning_rate": 0.0002388025164443291,
        "gradient_norm": 0.32368481159210205,
        "train_loss": 3.096677780151367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18769,
        "tokens": 9840361472,
        "learning_rate": 0.00023877555471767868,
        "gradient_norm": 0.3402674198150635,
        "train_loss": 3.0681090354919434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18770,
        "tokens": 9840885760,
        "learning_rate": 0.000238748594017873,
        "gradient_norm": 0.3696993291378021,
        "train_loss": 3.0620064735412598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18771,
        "tokens": 9841410048,
        "learning_rate": 0.00023872163434521574,
        "gradient_norm": 0.31067705154418945,
        "train_loss": 3.086808443069458,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18772,
        "tokens": 9841934336,
        "learning_rate": 0.00023869467570001017,
        "gradient_norm": 0.36100277304649353,
        "train_loss": 3.073856830596924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18773,
        "tokens": 9842458624,
        "learning_rate": 0.00023866771808255996,
        "gradient_norm": 0.3532632291316986,
        "train_loss": 3.0768165588378906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18774,
        "tokens": 9842982912,
        "learning_rate": 0.00023864076149316828,
        "gradient_norm": 0.4408210515975952,
        "train_loss": 3.09911847114563,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18775,
        "tokens": 9843507200,
        "learning_rate": 0.00023861380593213883,
        "gradient_norm": 0.40846261382102966,
        "train_loss": 3.05975341796875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18776,
        "tokens": 9844031488,
        "learning_rate": 0.00023858685139977484,
        "gradient_norm": 0.3395616114139557,
        "train_loss": 3.08074951171875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18777,
        "tokens": 9844555776,
        "learning_rate": 0.00023855989789637976,
        "gradient_norm": 0.3661714494228363,
        "train_loss": 3.0663414001464844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18778,
        "tokens": 9845080064,
        "learning_rate": 0.00023853294542225715,
        "gradient_norm": 0.3635765016078949,
        "train_loss": 3.04815673828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18779,
        "tokens": 9845604352,
        "learning_rate": 0.00023850599397771008,
        "gradient_norm": 0.33105072379112244,
        "train_loss": 3.0560519695281982,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18780,
        "tokens": 9846128640,
        "learning_rate": 0.00023847904356304224,
        "gradient_norm": 0.33765891194343567,
        "train_loss": 3.052004814147949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18781,
        "tokens": 9846652928,
        "learning_rate": 0.00023845209417855674,
        "gradient_norm": 0.3475368022918701,
        "train_loss": 3.1070556640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18782,
        "tokens": 9847177216,
        "learning_rate": 0.0002384251458245572,
        "gradient_norm": 0.3935528099536896,
        "train_loss": 3.0759124755859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18783,
        "tokens": 9847701504,
        "learning_rate": 0.00023839819850134662,
        "gradient_norm": 0.33612245321273804,
        "train_loss": 3.0451369285583496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18784,
        "tokens": 9848225792,
        "learning_rate": 0.00023837125220922865,
        "gradient_norm": 0.3234438896179199,
        "train_loss": 3.009965419769287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18785,
        "tokens": 9848750080,
        "learning_rate": 0.0002383443069485063,
        "gradient_norm": 0.3284043073654175,
        "train_loss": 3.1242945194244385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18786,
        "tokens": 9849274368,
        "learning_rate": 0.00023831736271948318,
        "gradient_norm": 0.34766313433647156,
        "train_loss": 3.064225196838379,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18787,
        "tokens": 9849798656,
        "learning_rate": 0.00023829041952246229,
        "gradient_norm": 0.36395591497421265,
        "train_loss": 3.063948392868042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18788,
        "tokens": 9850322944,
        "learning_rate": 0.00023826347735774703,
        "gradient_norm": 0.3435247540473938,
        "train_loss": 3.072019338607788,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18789,
        "tokens": 9850847232,
        "learning_rate": 0.00023823653622564084,
        "gradient_norm": 0.3592357039451599,
        "train_loss": 3.057051658630371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18790,
        "tokens": 9851371520,
        "learning_rate": 0.00023820959612644668,
        "gradient_norm": 0.33308860659599304,
        "train_loss": 3.0508804321289062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18791,
        "tokens": 9851895808,
        "learning_rate": 0.00023818265706046808,
        "gradient_norm": 0.388264000415802,
        "train_loss": 3.1116342544555664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18792,
        "tokens": 9852420096,
        "learning_rate": 0.000238155719028008,
        "gradient_norm": 0.4179782271385193,
        "train_loss": 3.0676231384277344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18793,
        "tokens": 9852944384,
        "learning_rate": 0.00023812878202936986,
        "gradient_norm": 0.3816560208797455,
        "train_loss": 3.070046901702881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18794,
        "tokens": 9853468672,
        "learning_rate": 0.00023810184606485677,
        "gradient_norm": 0.380991131067276,
        "train_loss": 3.0071990489959717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18795,
        "tokens": 9853992960,
        "learning_rate": 0.00023807491113477197,
        "gradient_norm": 0.40241920948028564,
        "train_loss": 3.05379581451416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18796,
        "tokens": 9854517248,
        "learning_rate": 0.00023804797723941858,
        "gradient_norm": 0.36464327573776245,
        "train_loss": 3.112769842147827,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18797,
        "tokens": 9855041536,
        "learning_rate": 0.00023802104437909989,
        "gradient_norm": 0.4011014401912689,
        "train_loss": 3.0812137126922607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18798,
        "tokens": 9855565824,
        "learning_rate": 0.000237994112554119,
        "gradient_norm": 0.4246842563152313,
        "train_loss": 3.0855109691619873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18799,
        "tokens": 9856090112,
        "learning_rate": 0.00023796718176477904,
        "gradient_norm": 0.3698772192001343,
        "train_loss": 3.1281280517578125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18800,
        "tokens": 9856614400,
        "learning_rate": 0.00023794025201138319,
        "gradient_norm": 0.3874843716621399,
        "train_loss": 3.0662429332733154,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18801,
        "tokens": 9857138688,
        "learning_rate": 0.00023791332329423453,
        "gradient_norm": 0.3295057713985443,
        "train_loss": 3.1033458709716797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18802,
        "tokens": 9857662976,
        "learning_rate": 0.00023788639561363623,
        "gradient_norm": 0.35901954770088196,
        "train_loss": 3.0767595767974854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18803,
        "tokens": 9858187264,
        "learning_rate": 0.00023785946896989136,
        "gradient_norm": 0.3517131209373474,
        "train_loss": 3.074507474899292,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18804,
        "tokens": 9858711552,
        "learning_rate": 0.00023783254336330305,
        "gradient_norm": 0.33453676104545593,
        "train_loss": 3.067559003829956,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18805,
        "tokens": 9859235840,
        "learning_rate": 0.0002378056187941743,
        "gradient_norm": 0.33514633774757385,
        "train_loss": 3.060542106628418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18806,
        "tokens": 9859760128,
        "learning_rate": 0.00023777869526280828,
        "gradient_norm": 0.36135461926460266,
        "train_loss": 3.1005167961120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18807,
        "tokens": 9860284416,
        "learning_rate": 0.00023775177276950796,
        "gradient_norm": 0.3535459041595459,
        "train_loss": 3.0855484008789062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18808,
        "tokens": 9860808704,
        "learning_rate": 0.00023772485131457643,
        "gradient_norm": 0.39293596148490906,
        "train_loss": 3.048360824584961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18809,
        "tokens": 9861332992,
        "learning_rate": 0.00023769793089831678,
        "gradient_norm": 0.3369051218032837,
        "train_loss": 3.0461082458496094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18810,
        "tokens": 9861857280,
        "learning_rate": 0.0002376710115210319,
        "gradient_norm": 0.36274635791778564,
        "train_loss": 3.085827112197876,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18811,
        "tokens": 9862381568,
        "learning_rate": 0.00023764409318302495,
        "gradient_norm": 0.32204583287239075,
        "train_loss": 3.0330822467803955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18812,
        "tokens": 9862905856,
        "learning_rate": 0.0002376171758845988,
        "gradient_norm": 0.39769798517227173,
        "train_loss": 3.0597386360168457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18813,
        "tokens": 9863430144,
        "learning_rate": 0.00023759025962605658,
        "gradient_norm": 0.3696053624153137,
        "train_loss": 3.06003475189209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18814,
        "tokens": 9863954432,
        "learning_rate": 0.00023756334440770102,
        "gradient_norm": 0.34578579664230347,
        "train_loss": 3.041577100753784,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18815,
        "tokens": 9864478720,
        "learning_rate": 0.00023753643022983542,
        "gradient_norm": 0.36650142073631287,
        "train_loss": 3.1082077026367188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18816,
        "tokens": 9865003008,
        "learning_rate": 0.0002375095170927624,
        "gradient_norm": 0.39116156101226807,
        "train_loss": 3.166877269744873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18817,
        "tokens": 9865527296,
        "learning_rate": 0.0002374826049967851,
        "gradient_norm": 0.4048120677471161,
        "train_loss": 3.0754854679107666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18818,
        "tokens": 9866051584,
        "learning_rate": 0.00023745569394220648,
        "gradient_norm": 0.3423769176006317,
        "train_loss": 3.0483269691467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18819,
        "tokens": 9866575872,
        "learning_rate": 0.00023742878392932928,
        "gradient_norm": 0.3611748516559601,
        "train_loss": 3.0967400074005127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18820,
        "tokens": 9867100160,
        "learning_rate": 0.00023740187495845667,
        "gradient_norm": 0.33306047320365906,
        "train_loss": 3.0967612266540527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18821,
        "tokens": 9867624448,
        "learning_rate": 0.00023737496702989122,
        "gradient_norm": 0.3455798327922821,
        "train_loss": 3.044513702392578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18822,
        "tokens": 9868148736,
        "learning_rate": 0.00023734806014393607,
        "gradient_norm": 0.3195917010307312,
        "train_loss": 3.054931163787842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18823,
        "tokens": 9868673024,
        "learning_rate": 0.00023732115430089395,
        "gradient_norm": 0.39293503761291504,
        "train_loss": 3.089163303375244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18824,
        "tokens": 9869197312,
        "learning_rate": 0.00023729424950106782,
        "gradient_norm": 0.33969247341156006,
        "train_loss": 3.094045877456665,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18825,
        "tokens": 9869721600,
        "learning_rate": 0.0002372673457447604,
        "gradient_norm": 0.391593873500824,
        "train_loss": 3.0846152305603027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18826,
        "tokens": 9870245888,
        "learning_rate": 0.0002372404430322747,
        "gradient_norm": 0.3538510799407959,
        "train_loss": 3.1281023025512695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18827,
        "tokens": 9870770176,
        "learning_rate": 0.0002372135413639133,
        "gradient_norm": 0.3462288975715637,
        "train_loss": 3.064718723297119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18828,
        "tokens": 9871294464,
        "learning_rate": 0.00023718664073997918,
        "gradient_norm": 0.4047272801399231,
        "train_loss": 3.0810766220092773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18829,
        "tokens": 9871818752,
        "learning_rate": 0.00023715974116077525,
        "gradient_norm": 0.36864399909973145,
        "train_loss": 3.147839307785034,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18830,
        "tokens": 9872343040,
        "learning_rate": 0.00023713284262660402,
        "gradient_norm": 0.35842886567115784,
        "train_loss": 3.063472270965576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18831,
        "tokens": 9872867328,
        "learning_rate": 0.00023710594513776852,
        "gradient_norm": 0.37684065103530884,
        "train_loss": 3.053201913833618,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18832,
        "tokens": 9873391616,
        "learning_rate": 0.00023707904869457128,
        "gradient_norm": 0.34969615936279297,
        "train_loss": 3.062432289123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18833,
        "tokens": 9873915904,
        "learning_rate": 0.00023705215329731532,
        "gradient_norm": 0.3892672657966614,
        "train_loss": 3.067251205444336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18834,
        "tokens": 9874440192,
        "learning_rate": 0.00023702525894630312,
        "gradient_norm": 0.44037511944770813,
        "train_loss": 3.0432653427124023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18835,
        "tokens": 9874964480,
        "learning_rate": 0.00023699836564183762,
        "gradient_norm": 0.3744860887527466,
        "train_loss": 3.0927505493164062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18836,
        "tokens": 9875488768,
        "learning_rate": 0.00023697147338422135,
        "gradient_norm": 0.3309893012046814,
        "train_loss": 3.0583577156066895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18837,
        "tokens": 9876013056,
        "learning_rate": 0.0002369445821737571,
        "gradient_norm": 0.36813926696777344,
        "train_loss": 3.084404230117798,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18838,
        "tokens": 9876537344,
        "learning_rate": 0.00023691769201074765,
        "gradient_norm": 0.3485267162322998,
        "train_loss": 3.0567774772644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18839,
        "tokens": 9877061632,
        "learning_rate": 0.00023689080289549555,
        "gradient_norm": 0.3950558304786682,
        "train_loss": 2.983598232269287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18840,
        "tokens": 9877585920,
        "learning_rate": 0.00023686391482830363,
        "gradient_norm": 0.40569326281547546,
        "train_loss": 3.140603542327881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18841,
        "tokens": 9878110208,
        "learning_rate": 0.0002368370278094743,
        "gradient_norm": 0.41502171754837036,
        "train_loss": 3.1340177059173584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18842,
        "tokens": 9878634496,
        "learning_rate": 0.00023681014183931048,
        "gradient_norm": 0.41304221749305725,
        "train_loss": 3.0597033500671387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18843,
        "tokens": 9879158784,
        "learning_rate": 0.0002367832569181146,
        "gradient_norm": 0.389877587556839,
        "train_loss": 3.0881807804107666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18844,
        "tokens": 9879683072,
        "learning_rate": 0.00023675637304618942,
        "gradient_norm": 0.3751063048839569,
        "train_loss": 3.053046226501465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18845,
        "tokens": 9880207360,
        "learning_rate": 0.0002367294902238374,
        "gradient_norm": 0.40924370288848877,
        "train_loss": 3.0535995960235596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18846,
        "tokens": 9880731648,
        "learning_rate": 0.00023670260845136135,
        "gradient_norm": 0.3736256957054138,
        "train_loss": 3.0828890800476074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18847,
        "tokens": 9881255936,
        "learning_rate": 0.00023667572772906366,
        "gradient_norm": 0.41092386841773987,
        "train_loss": 3.0637831687927246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18848,
        "tokens": 9881780224,
        "learning_rate": 0.000236648848057247,
        "gradient_norm": 0.4171464145183563,
        "train_loss": 3.0167226791381836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18849,
        "tokens": 9882304512,
        "learning_rate": 0.00023662196943621393,
        "gradient_norm": 0.3553813695907593,
        "train_loss": 3.0661349296569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18850,
        "tokens": 9882828800,
        "learning_rate": 0.000236595091866267,
        "gradient_norm": 0.4784516394138336,
        "train_loss": 3.034985065460205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18851,
        "tokens": 9883353088,
        "learning_rate": 0.0002365682153477087,
        "gradient_norm": 0.3815895617008209,
        "train_loss": 3.1537067890167236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18852,
        "tokens": 9883877376,
        "learning_rate": 0.00023654133988084165,
        "gradient_norm": 0.4119257628917694,
        "train_loss": 3.113863229751587,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18853,
        "tokens": 9884401664,
        "learning_rate": 0.0002365144654659683,
        "gradient_norm": 0.3685007691383362,
        "train_loss": 3.085458755493164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18854,
        "tokens": 9884925952,
        "learning_rate": 0.00023648759210339118,
        "gradient_norm": 0.4019426703453064,
        "train_loss": 3.0259156227111816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18855,
        "tokens": 9885450240,
        "learning_rate": 0.00023646071979341278,
        "gradient_norm": 0.3701569139957428,
        "train_loss": 3.0873169898986816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18856,
        "tokens": 9885974528,
        "learning_rate": 0.0002364338485363356,
        "gradient_norm": 0.3346632719039917,
        "train_loss": 3.0645596981048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18857,
        "tokens": 9886498816,
        "learning_rate": 0.000236406978332462,
        "gradient_norm": 0.5322721004486084,
        "train_loss": 3.14133358001709,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18858,
        "tokens": 9887023104,
        "learning_rate": 0.00023638010918209466,
        "gradient_norm": 0.36764371395111084,
        "train_loss": 3.053314208984375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18859,
        "tokens": 9887547392,
        "learning_rate": 0.00023635324108553575,
        "gradient_norm": 0.4129333198070526,
        "train_loss": 3.1012649536132812,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18860,
        "tokens": 9888071680,
        "learning_rate": 0.00023632637404308798,
        "gradient_norm": 0.3635031580924988,
        "train_loss": 3.0329060554504395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18861,
        "tokens": 9888595968,
        "learning_rate": 0.0002362995080550535,
        "gradient_norm": 0.3815747797489166,
        "train_loss": 3.055143117904663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18862,
        "tokens": 9889120256,
        "learning_rate": 0.000236272643121735,
        "gradient_norm": 0.3773345947265625,
        "train_loss": 3.0616297721862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18863,
        "tokens": 9889644544,
        "learning_rate": 0.00023624577924343464,
        "gradient_norm": 0.33254122734069824,
        "train_loss": 3.0831334590911865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18864,
        "tokens": 9890168832,
        "learning_rate": 0.000236218916420455,
        "gradient_norm": 0.3880573809146881,
        "train_loss": 3.1336379051208496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18865,
        "tokens": 9890693120,
        "learning_rate": 0.00023619205465309821,
        "gradient_norm": 0.33722084760665894,
        "train_loss": 3.008530616760254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18866,
        "tokens": 9891217408,
        "learning_rate": 0.0002361651939416669,
        "gradient_norm": 0.368612140417099,
        "train_loss": 3.0545430183410645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18867,
        "tokens": 9891741696,
        "learning_rate": 0.0002361383342864632,
        "gradient_norm": 0.3438138961791992,
        "train_loss": 3.0237016677856445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18868,
        "tokens": 9892265984,
        "learning_rate": 0.00023611147568778956,
        "gradient_norm": 0.3956110179424286,
        "train_loss": 3.1159517765045166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18869,
        "tokens": 9892790272,
        "learning_rate": 0.00023608461814594837,
        "gradient_norm": 0.3750138580799103,
        "train_loss": 3.131594657897949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18870,
        "tokens": 9893314560,
        "learning_rate": 0.00023605776166124183,
        "gradient_norm": 0.32295843958854675,
        "train_loss": 3.123152256011963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18871,
        "tokens": 9893838848,
        "learning_rate": 0.00023603090623397233,
        "gradient_norm": 0.3677166998386383,
        "train_loss": 3.0743348598480225,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18872,
        "tokens": 9894363136,
        "learning_rate": 0.00023600405186444202,
        "gradient_norm": 0.34654802083969116,
        "train_loss": 3.04217267036438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18873,
        "tokens": 9894887424,
        "learning_rate": 0.0002359771985529534,
        "gradient_norm": 0.33954477310180664,
        "train_loss": 3.0671839714050293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18874,
        "tokens": 9895411712,
        "learning_rate": 0.0002359503462998085,
        "gradient_norm": 0.3453110158443451,
        "train_loss": 3.0430874824523926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18875,
        "tokens": 9895936000,
        "learning_rate": 0.0002359234951053098,
        "gradient_norm": 0.32900020480155945,
        "train_loss": 3.0149073600769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18876,
        "tokens": 9896460288,
        "learning_rate": 0.0002358966449697593,
        "gradient_norm": 0.34465909004211426,
        "train_loss": 3.0735208988189697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18877,
        "tokens": 9896984576,
        "learning_rate": 0.0002358697958934594,
        "gradient_norm": 0.3976016044616699,
        "train_loss": 3.100975513458252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18878,
        "tokens": 9897508864,
        "learning_rate": 0.0002358429478767124,
        "gradient_norm": 0.3708235025405884,
        "train_loss": 3.096087694168091,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18879,
        "tokens": 9898033152,
        "learning_rate": 0.00023581610091982024,
        "gradient_norm": 0.3449072539806366,
        "train_loss": 3.0486860275268555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18880,
        "tokens": 9898557440,
        "learning_rate": 0.00023578925502308541,
        "gradient_norm": 0.4077480435371399,
        "train_loss": 3.0418577194213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18881,
        "tokens": 9899081728,
        "learning_rate": 0.00023576241018680982,
        "gradient_norm": 0.3278960585594177,
        "train_loss": 3.0311596393585205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18882,
        "tokens": 9899606016,
        "learning_rate": 0.0002357355664112959,
        "gradient_norm": 0.36637425422668457,
        "train_loss": 3.0800909996032715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18883,
        "tokens": 9900130304,
        "learning_rate": 0.00023570872369684553,
        "gradient_norm": 0.3466293513774872,
        "train_loss": 3.0904273986816406,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18884,
        "tokens": 9900654592,
        "learning_rate": 0.00023568188204376115,
        "gradient_norm": 0.35282883048057556,
        "train_loss": 3.0796828269958496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18885,
        "tokens": 9901178880,
        "learning_rate": 0.00023565504145234468,
        "gradient_norm": 0.3752489387989044,
        "train_loss": 3.0681376457214355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18886,
        "tokens": 9901703168,
        "learning_rate": 0.00023562820192289842,
        "gradient_norm": 0.3526657521724701,
        "train_loss": 3.083047866821289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18887,
        "tokens": 9902227456,
        "learning_rate": 0.00023560136345572425,
        "gradient_norm": 0.3583223521709442,
        "train_loss": 3.0853686332702637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18888,
        "tokens": 9902751744,
        "learning_rate": 0.0002355745260511244,
        "gradient_norm": 0.37238484621047974,
        "train_loss": 3.0762195587158203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18889,
        "tokens": 9903276032,
        "learning_rate": 0.0002355476897094011,
        "gradient_norm": 0.3367042541503906,
        "train_loss": 3.1101021766662598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18890,
        "tokens": 9903800320,
        "learning_rate": 0.00023552085443085617,
        "gradient_norm": 0.36797571182250977,
        "train_loss": 3.0849547386169434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18891,
        "tokens": 9904324608,
        "learning_rate": 0.00023549402021579192,
        "gradient_norm": 0.4050462245941162,
        "train_loss": 3.0893068313598633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18892,
        "tokens": 9904848896,
        "learning_rate": 0.00023546718706451012,
        "gradient_norm": 0.3499630093574524,
        "train_loss": 3.0430197715759277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18893,
        "tokens": 9905373184,
        "learning_rate": 0.00023544035497731315,
        "gradient_norm": 0.32508042454719543,
        "train_loss": 3.0562291145324707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18894,
        "tokens": 9905897472,
        "learning_rate": 0.00023541352395450266,
        "gradient_norm": 0.3275814354419708,
        "train_loss": 3.0650510787963867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18895,
        "tokens": 9906421760,
        "learning_rate": 0.00023538669399638103,
        "gradient_norm": 0.3287624418735504,
        "train_loss": 3.097306728363037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18896,
        "tokens": 9906946048,
        "learning_rate": 0.00023535986510325,
        "gradient_norm": 0.35503432154655457,
        "train_loss": 3.0933613777160645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18897,
        "tokens": 9907470336,
        "learning_rate": 0.0002353330372754117,
        "gradient_norm": 0.3443032503128052,
        "train_loss": 3.0880346298217773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18898,
        "tokens": 9907994624,
        "learning_rate": 0.00023530621051316805,
        "gradient_norm": 0.3147852122783661,
        "train_loss": 3.028484344482422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18899,
        "tokens": 9908518912,
        "learning_rate": 0.00023527938481682104,
        "gradient_norm": 0.3378327190876007,
        "train_loss": 3.0435967445373535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18900,
        "tokens": 9909043200,
        "learning_rate": 0.00023525256018667266,
        "gradient_norm": 0.3256639540195465,
        "train_loss": 3.056372880935669,
        "val_loss": 3.031282901763916,
        "hellaswag_acc": 0.28111928701400757,
        "hellaswag_acc_norm": 0.2926707863807678
    },
    {
        "step": 18901,
        "tokens": 9909567488,
        "learning_rate": 0.0002352257366230248,
        "gradient_norm": 0.356995165348053,
        "train_loss": 3.069916248321533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18902,
        "tokens": 9910091776,
        "learning_rate": 0.00023519891412617942,
        "gradient_norm": 0.3290383517742157,
        "train_loss": 3.0701823234558105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18903,
        "tokens": 9910616064,
        "learning_rate": 0.00023517209269643843,
        "gradient_norm": 0.3462356925010681,
        "train_loss": 3.072628974914551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18904,
        "tokens": 9911140352,
        "learning_rate": 0.00023514527233410373,
        "gradient_norm": 0.3301336169242859,
        "train_loss": 3.1302971839904785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18905,
        "tokens": 9911664640,
        "learning_rate": 0.0002351184530394772,
        "gradient_norm": 0.3306332528591156,
        "train_loss": 3.0769898891448975,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18906,
        "tokens": 9912188928,
        "learning_rate": 0.00023509163481286082,
        "gradient_norm": 0.30644771456718445,
        "train_loss": 3.1009833812713623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18907,
        "tokens": 9912713216,
        "learning_rate": 0.00023506481765455634,
        "gradient_norm": 0.3306960463523865,
        "train_loss": 3.093738079071045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18908,
        "tokens": 9913237504,
        "learning_rate": 0.0002350380015648657,
        "gradient_norm": 0.371322900056839,
        "train_loss": 3.138082504272461,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18909,
        "tokens": 9913761792,
        "learning_rate": 0.0002350111865440907,
        "gradient_norm": 0.3653642237186432,
        "train_loss": 3.0905232429504395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18910,
        "tokens": 9914286080,
        "learning_rate": 0.00023498437259253325,
        "gradient_norm": 0.3482056260108948,
        "train_loss": 3.013831615447998,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18911,
        "tokens": 9914810368,
        "learning_rate": 0.00023495755971049512,
        "gradient_norm": 0.4222399890422821,
        "train_loss": 3.051809310913086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18912,
        "tokens": 9915334656,
        "learning_rate": 0.00023493074789827811,
        "gradient_norm": 0.3835129141807556,
        "train_loss": 3.0633254051208496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18913,
        "tokens": 9915858944,
        "learning_rate": 0.00023490393715618405,
        "gradient_norm": 0.36691296100616455,
        "train_loss": 3.040984630584717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18914,
        "tokens": 9916383232,
        "learning_rate": 0.00023487712748451473,
        "gradient_norm": 0.36194342374801636,
        "train_loss": 3.0496773719787598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18915,
        "tokens": 9916907520,
        "learning_rate": 0.00023485031888357188,
        "gradient_norm": 0.3222522735595703,
        "train_loss": 3.107006549835205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18916,
        "tokens": 9917431808,
        "learning_rate": 0.00023482351135365736,
        "gradient_norm": 0.34547460079193115,
        "train_loss": 3.13561749458313,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18917,
        "tokens": 9917956096,
        "learning_rate": 0.00023479670489507274,
        "gradient_norm": 0.35537469387054443,
        "train_loss": 3.078166961669922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18918,
        "tokens": 9918480384,
        "learning_rate": 0.00023476989950812002,
        "gradient_norm": 0.34204190969467163,
        "train_loss": 3.096666097640991,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18919,
        "tokens": 9919004672,
        "learning_rate": 0.0002347430951931007,
        "gradient_norm": 0.336397260427475,
        "train_loss": 3.038548469543457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18920,
        "tokens": 9919528960,
        "learning_rate": 0.00023471629195031664,
        "gradient_norm": 0.33378931879997253,
        "train_loss": 3.0846991539001465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18921,
        "tokens": 9920053248,
        "learning_rate": 0.00023468948978006942,
        "gradient_norm": 0.3575534522533417,
        "train_loss": 3.0687806606292725,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18922,
        "tokens": 9920577536,
        "learning_rate": 0.0002346626886826609,
        "gradient_norm": 0.35983192920684814,
        "train_loss": 3.0632004737854004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18923,
        "tokens": 9921101824,
        "learning_rate": 0.00023463588865839255,
        "gradient_norm": 0.3777262568473816,
        "train_loss": 3.1064610481262207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18924,
        "tokens": 9921626112,
        "learning_rate": 0.00023460908970756623,
        "gradient_norm": 0.3865455090999603,
        "train_loss": 3.045684337615967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18925,
        "tokens": 9922150400,
        "learning_rate": 0.00023458229183048344,
        "gradient_norm": 0.3385397791862488,
        "train_loss": 3.0893712043762207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18926,
        "tokens": 9922674688,
        "learning_rate": 0.000234555495027446,
        "gradient_norm": 0.3533744215965271,
        "train_loss": 3.0950918197631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18927,
        "tokens": 9923198976,
        "learning_rate": 0.00023452869929875534,
        "gradient_norm": 0.36725765466690063,
        "train_loss": 3.0808210372924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18928,
        "tokens": 9923723264,
        "learning_rate": 0.00023450190464471314,
        "gradient_norm": 0.35115835070610046,
        "train_loss": 3.0261850357055664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18929,
        "tokens": 9924247552,
        "learning_rate": 0.00023447511106562118,
        "gradient_norm": 0.3942197263240814,
        "train_loss": 3.0587430000305176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18930,
        "tokens": 9924771840,
        "learning_rate": 0.0002344483185617808,
        "gradient_norm": 0.3993262052536011,
        "train_loss": 3.0894107818603516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18931,
        "tokens": 9925296128,
        "learning_rate": 0.0002344215271334938,
        "gradient_norm": 0.3732317388057709,
        "train_loss": 3.081545114517212,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18932,
        "tokens": 9925820416,
        "learning_rate": 0.00023439473678106155,
        "gradient_norm": 0.3276364505290985,
        "train_loss": 3.0557403564453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18933,
        "tokens": 9926344704,
        "learning_rate": 0.00023436794750478587,
        "gradient_norm": 0.3970986306667328,
        "train_loss": 3.1527743339538574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18934,
        "tokens": 9926868992,
        "learning_rate": 0.000234341159304968,
        "gradient_norm": 0.3597257733345032,
        "train_loss": 3.0636816024780273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18935,
        "tokens": 9927393280,
        "learning_rate": 0.00023431437218190976,
        "gradient_norm": 0.3468749225139618,
        "train_loss": 3.0497617721557617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18936,
        "tokens": 9927917568,
        "learning_rate": 0.00023428758613591236,
        "gradient_norm": 0.34470677375793457,
        "train_loss": 3.006559371948242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18937,
        "tokens": 9928441856,
        "learning_rate": 0.00023426080116727756,
        "gradient_norm": 0.38104870915412903,
        "train_loss": 3.0854384899139404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18938,
        "tokens": 9928966144,
        "learning_rate": 0.00023423401727630687,
        "gradient_norm": 0.38045960664749146,
        "train_loss": 3.067835807800293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18939,
        "tokens": 9929490432,
        "learning_rate": 0.0002342072344633016,
        "gradient_norm": 0.3915503919124603,
        "train_loss": 3.068312883377075,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18940,
        "tokens": 9930014720,
        "learning_rate": 0.00023418045272856336,
        "gradient_norm": 0.4305697977542877,
        "train_loss": 3.035994052886963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18941,
        "tokens": 9930539008,
        "learning_rate": 0.00023415367207239347,
        "gradient_norm": 0.3390134572982788,
        "train_loss": 3.0411534309387207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18942,
        "tokens": 9931063296,
        "learning_rate": 0.00023412689249509365,
        "gradient_norm": 0.3787112832069397,
        "train_loss": 3.0707573890686035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18943,
        "tokens": 9931587584,
        "learning_rate": 0.000234100113996965,
        "gradient_norm": 0.3331090211868286,
        "train_loss": 3.0123353004455566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18944,
        "tokens": 9932111872,
        "learning_rate": 0.00023407333657830926,
        "gradient_norm": 0.3728020489215851,
        "train_loss": 2.987908124923706,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18945,
        "tokens": 9932636160,
        "learning_rate": 0.00023404656023942754,
        "gradient_norm": 0.36284855008125305,
        "train_loss": 3.0853161811828613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18946,
        "tokens": 9933160448,
        "learning_rate": 0.00023401978498062154,
        "gradient_norm": 0.3523842692375183,
        "train_loss": 3.025517463684082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18947,
        "tokens": 9933684736,
        "learning_rate": 0.00023399301080219236,
        "gradient_norm": 0.3864331543445587,
        "train_loss": 3.042985439300537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18948,
        "tokens": 9934209024,
        "learning_rate": 0.00023396623770444158,
        "gradient_norm": 0.3626300096511841,
        "train_loss": 3.0614073276519775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18949,
        "tokens": 9934733312,
        "learning_rate": 0.00023393946568767054,
        "gradient_norm": 0.32576969265937805,
        "train_loss": 3.0594334602355957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18950,
        "tokens": 9935257600,
        "learning_rate": 0.00023391269475218047,
        "gradient_norm": 0.34770622849464417,
        "train_loss": 3.0325217247009277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18951,
        "tokens": 9935781888,
        "learning_rate": 0.0002338859248982729,
        "gradient_norm": 0.33999958634376526,
        "train_loss": 3.036600351333618,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18952,
        "tokens": 9936306176,
        "learning_rate": 0.000233859156126249,
        "gradient_norm": 0.32672032713890076,
        "train_loss": 3.057840347290039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18953,
        "tokens": 9936830464,
        "learning_rate": 0.0002338323884364102,
        "gradient_norm": 0.3803209662437439,
        "train_loss": 3.0558860301971436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18954,
        "tokens": 9937354752,
        "learning_rate": 0.0002338056218290576,
        "gradient_norm": 0.33019721508026123,
        "train_loss": 3.061084747314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18955,
        "tokens": 9937879040,
        "learning_rate": 0.0002337788563044928,
        "gradient_norm": 0.3540339767932892,
        "train_loss": 3.1688976287841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18956,
        "tokens": 9938403328,
        "learning_rate": 0.0002337520918630168,
        "gradient_norm": 0.3496917188167572,
        "train_loss": 3.037093162536621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18957,
        "tokens": 9938927616,
        "learning_rate": 0.00023372532850493102,
        "gradient_norm": 0.4030010998249054,
        "train_loss": 3.062203884124756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18958,
        "tokens": 9939451904,
        "learning_rate": 0.00023369856623053673,
        "gradient_norm": 0.4278534948825836,
        "train_loss": 3.109104871749878,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18959,
        "tokens": 9939976192,
        "learning_rate": 0.00023367180504013505,
        "gradient_norm": 0.3373458981513977,
        "train_loss": 3.076857566833496,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18960,
        "tokens": 9940500480,
        "learning_rate": 0.0002336450449340273,
        "gradient_norm": 0.49081388115882874,
        "train_loss": 3.0225250720977783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18961,
        "tokens": 9941024768,
        "learning_rate": 0.0002336182859125147,
        "gradient_norm": 0.45725467801094055,
        "train_loss": 3.0271027088165283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18962,
        "tokens": 9941549056,
        "learning_rate": 0.00023359152797589841,
        "gradient_norm": 0.3757099211215973,
        "train_loss": 3.0664377212524414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18963,
        "tokens": 9942073344,
        "learning_rate": 0.00023356477112447966,
        "gradient_norm": 0.595961332321167,
        "train_loss": 3.0590217113494873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18964,
        "tokens": 9942597632,
        "learning_rate": 0.00023353801535855965,
        "gradient_norm": 0.4703819453716278,
        "train_loss": 3.0676279067993164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18965,
        "tokens": 9943121920,
        "learning_rate": 0.00023351126067843947,
        "gradient_norm": 0.41071730852127075,
        "train_loss": 3.056373119354248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18966,
        "tokens": 9943646208,
        "learning_rate": 0.00023348450708442035,
        "gradient_norm": 0.43444299697875977,
        "train_loss": 3.0486207008361816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18967,
        "tokens": 9944170496,
        "learning_rate": 0.00023345775457680342,
        "gradient_norm": 0.4416765570640564,
        "train_loss": 3.0743281841278076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18968,
        "tokens": 9944694784,
        "learning_rate": 0.00023343100315588973,
        "gradient_norm": 0.39777448773384094,
        "train_loss": 3.0920190811157227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18969,
        "tokens": 9945219072,
        "learning_rate": 0.0002334042528219806,
        "gradient_norm": 0.48022928833961487,
        "train_loss": 3.0815181732177734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18970,
        "tokens": 9945743360,
        "learning_rate": 0.00023337750357537693,
        "gradient_norm": 0.36454081535339355,
        "train_loss": 2.992563486099243,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18971,
        "tokens": 9946267648,
        "learning_rate": 0.00023335075541637996,
        "gradient_norm": 0.4668257236480713,
        "train_loss": 3.0292768478393555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18972,
        "tokens": 9946791936,
        "learning_rate": 0.00023332400834529064,
        "gradient_norm": 0.3926982283592224,
        "train_loss": 3.042468786239624,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18973,
        "tokens": 9947316224,
        "learning_rate": 0.00023329726236241018,
        "gradient_norm": 0.3625298738479614,
        "train_loss": 3.060157060623169,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18974,
        "tokens": 9947840512,
        "learning_rate": 0.0002332705174680395,
        "gradient_norm": 0.3987773060798645,
        "train_loss": 3.115682601928711,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18975,
        "tokens": 9948364800,
        "learning_rate": 0.00023324377366247984,
        "gradient_norm": 0.37915846705436707,
        "train_loss": 3.0586471557617188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18976,
        "tokens": 9948889088,
        "learning_rate": 0.000233217030946032,
        "gradient_norm": 0.378528356552124,
        "train_loss": 3.0822837352752686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18977,
        "tokens": 9949413376,
        "learning_rate": 0.0002331902893189971,
        "gradient_norm": 0.35712212324142456,
        "train_loss": 3.0667896270751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18978,
        "tokens": 9949937664,
        "learning_rate": 0.00023316354878167631,
        "gradient_norm": 0.34118491411209106,
        "train_loss": 3.1030337810516357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18979,
        "tokens": 9950461952,
        "learning_rate": 0.00023313680933437035,
        "gradient_norm": 0.4003538489341736,
        "train_loss": 3.1061758995056152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18980,
        "tokens": 9950986240,
        "learning_rate": 0.0002331100709773805,
        "gradient_norm": 0.33821403980255127,
        "train_loss": 3.0759167671203613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18981,
        "tokens": 9951510528,
        "learning_rate": 0.0002330833337110074,
        "gradient_norm": 0.40071025490760803,
        "train_loss": 3.0589966773986816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18982,
        "tokens": 9952034816,
        "learning_rate": 0.00023305659753555238,
        "gradient_norm": 0.3244057893753052,
        "train_loss": 3.090085029602051,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18983,
        "tokens": 9952559104,
        "learning_rate": 0.00023302986245131603,
        "gradient_norm": 0.3789568245410919,
        "train_loss": 3.0756936073303223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18984,
        "tokens": 9953083392,
        "learning_rate": 0.00023300312845859954,
        "gradient_norm": 0.351115345954895,
        "train_loss": 3.0709803104400635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18985,
        "tokens": 9953607680,
        "learning_rate": 0.00023297639555770373,
        "gradient_norm": 0.3594987690448761,
        "train_loss": 3.021697998046875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18986,
        "tokens": 9954131968,
        "learning_rate": 0.00023294966374892958,
        "gradient_norm": 0.36594080924987793,
        "train_loss": 3.093169927597046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18987,
        "tokens": 9954656256,
        "learning_rate": 0.0002329229330325778,
        "gradient_norm": 0.39284592866897583,
        "train_loss": 3.1082205772399902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18988,
        "tokens": 9955180544,
        "learning_rate": 0.00023289620340894947,
        "gradient_norm": 0.36726197600364685,
        "train_loss": 3.0678796768188477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18989,
        "tokens": 9955704832,
        "learning_rate": 0.0002328694748783455,
        "gradient_norm": 0.36746418476104736,
        "train_loss": 3.022106170654297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18990,
        "tokens": 9956229120,
        "learning_rate": 0.0002328427474410666,
        "gradient_norm": 0.3396303057670593,
        "train_loss": 2.988409996032715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18991,
        "tokens": 9956753408,
        "learning_rate": 0.00023281602109741375,
        "gradient_norm": 0.3716607987880707,
        "train_loss": 3.027371883392334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18992,
        "tokens": 9957277696,
        "learning_rate": 0.0002327892958476876,
        "gradient_norm": 0.3097570836544037,
        "train_loss": 3.071223735809326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18993,
        "tokens": 9957801984,
        "learning_rate": 0.00023276257169218927,
        "gradient_norm": 0.3552517592906952,
        "train_loss": 3.087406635284424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18994,
        "tokens": 9958326272,
        "learning_rate": 0.00023273584863121925,
        "gradient_norm": 0.3724193871021271,
        "train_loss": 3.1029911041259766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18995,
        "tokens": 9958850560,
        "learning_rate": 0.00023270912666507865,
        "gradient_norm": 0.4254814684391022,
        "train_loss": 3.1079540252685547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18996,
        "tokens": 9959374848,
        "learning_rate": 0.00023268240579406795,
        "gradient_norm": 0.44908636808395386,
        "train_loss": 3.0961966514587402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18997,
        "tokens": 9959899136,
        "learning_rate": 0.00023265568601848812,
        "gradient_norm": 0.35506126284599304,
        "train_loss": 3.04903507232666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18998,
        "tokens": 9960423424,
        "learning_rate": 0.00023262896733863996,
        "gradient_norm": 0.42456960678100586,
        "train_loss": 3.1448419094085693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 18999,
        "tokens": 9960947712,
        "learning_rate": 0.00023260224975482407,
        "gradient_norm": 0.38739603757858276,
        "train_loss": 3.0607872009277344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19000,
        "tokens": 9961472000,
        "learning_rate": 0.0002325755332673414,
        "gradient_norm": 0.3780297338962555,
        "train_loss": 3.0353751182556152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19001,
        "tokens": 9961996288,
        "learning_rate": 0.00023254881787649237,
        "gradient_norm": 0.475495308637619,
        "train_loss": 3.118669033050537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19002,
        "tokens": 9962520576,
        "learning_rate": 0.00023252210358257802,
        "gradient_norm": 0.39682459831237793,
        "train_loss": 3.0593950748443604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19003,
        "tokens": 9963044864,
        "learning_rate": 0.00023249539038589875,
        "gradient_norm": 0.40327319502830505,
        "train_loss": 3.056915283203125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19004,
        "tokens": 9963569152,
        "learning_rate": 0.00023246867828675556,
        "gradient_norm": 0.39125362038612366,
        "train_loss": 3.070091485977173,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19005,
        "tokens": 9964093440,
        "learning_rate": 0.00023244196728544887,
        "gradient_norm": 0.375357061624527,
        "train_loss": 3.102994918823242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19006,
        "tokens": 9964617728,
        "learning_rate": 0.00023241525738227956,
        "gradient_norm": 0.36069270968437195,
        "train_loss": 3.014117956161499,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19007,
        "tokens": 9965142016,
        "learning_rate": 0.000232388548577548,
        "gradient_norm": 0.34781384468078613,
        "train_loss": 3.0833160877227783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19008,
        "tokens": 9965666304,
        "learning_rate": 0.00023236184087155513,
        "gradient_norm": 0.38308316469192505,
        "train_loss": 3.1237571239471436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19009,
        "tokens": 9966190592,
        "learning_rate": 0.0002323351342646014,
        "gradient_norm": 0.35191774368286133,
        "train_loss": 3.0623159408569336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19010,
        "tokens": 9966714880,
        "learning_rate": 0.0002323084287569875,
        "gradient_norm": 0.3673005700111389,
        "train_loss": 3.082984209060669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19011,
        "tokens": 9967239168,
        "learning_rate": 0.000232281724349014,
        "gradient_norm": 0.34098440408706665,
        "train_loss": 3.0557613372802734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19012,
        "tokens": 9967763456,
        "learning_rate": 0.0002322550210409815,
        "gradient_norm": 0.3838120698928833,
        "train_loss": 3.0620412826538086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19013,
        "tokens": 9968287744,
        "learning_rate": 0.00023222831883319058,
        "gradient_norm": 0.3300670087337494,
        "train_loss": 3.0762670040130615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19014,
        "tokens": 9968812032,
        "learning_rate": 0.00023220161772594182,
        "gradient_norm": 0.3610887825489044,
        "train_loss": 3.0983800888061523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19015,
        "tokens": 9969336320,
        "learning_rate": 0.00023217491771953573,
        "gradient_norm": 0.3661322593688965,
        "train_loss": 3.056940793991089,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19016,
        "tokens": 9969860608,
        "learning_rate": 0.00023214821881427294,
        "gradient_norm": 0.41225630044937134,
        "train_loss": 3.082261562347412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19017,
        "tokens": 9970384896,
        "learning_rate": 0.00023212152101045384,
        "gradient_norm": 0.41737353801727295,
        "train_loss": 3.072317600250244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19018,
        "tokens": 9970909184,
        "learning_rate": 0.00023209482430837911,
        "gradient_norm": 0.37060996890068054,
        "train_loss": 3.1041061878204346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19019,
        "tokens": 9971433472,
        "learning_rate": 0.00023206812870834912,
        "gradient_norm": 0.5245808362960815,
        "train_loss": 3.090473175048828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19020,
        "tokens": 9971957760,
        "learning_rate": 0.00023204143421066446,
        "gradient_norm": 0.3818672001361847,
        "train_loss": 3.121048927307129,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19021,
        "tokens": 9972482048,
        "learning_rate": 0.0002320147408156255,
        "gradient_norm": 0.38608723878860474,
        "train_loss": 3.0525271892547607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19022,
        "tokens": 9973006336,
        "learning_rate": 0.0002319880485235329,
        "gradient_norm": 0.37953290343284607,
        "train_loss": 3.04428768157959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19023,
        "tokens": 9973530624,
        "learning_rate": 0.00023196135733468683,
        "gradient_norm": 0.36395493149757385,
        "train_loss": 3.073841094970703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19024,
        "tokens": 9974054912,
        "learning_rate": 0.00023193466724938803,
        "gradient_norm": 0.36181432008743286,
        "train_loss": 3.0710089206695557,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19025,
        "tokens": 9974579200,
        "learning_rate": 0.00023190797826793668,
        "gradient_norm": 0.3876437246799469,
        "train_loss": 3.1162285804748535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19026,
        "tokens": 9975103488,
        "learning_rate": 0.0002318812903906334,
        "gradient_norm": 0.41955482959747314,
        "train_loss": 3.1313672065734863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19027,
        "tokens": 9975627776,
        "learning_rate": 0.00023185460361777846,
        "gradient_norm": 0.3555412292480469,
        "train_loss": 3.0764400959014893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19028,
        "tokens": 9976152064,
        "learning_rate": 0.0002318279179496722,
        "gradient_norm": 0.3795951008796692,
        "train_loss": 3.0570735931396484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19029,
        "tokens": 9976676352,
        "learning_rate": 0.00023180123338661528,
        "gradient_norm": 0.3693414032459259,
        "train_loss": 3.153059244155884,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19030,
        "tokens": 9977200640,
        "learning_rate": 0.00023177454992890777,
        "gradient_norm": 0.44966596364974976,
        "train_loss": 3.1161556243896484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19031,
        "tokens": 9977724928,
        "learning_rate": 0.00023174786757685023,
        "gradient_norm": 0.3855755031108856,
        "train_loss": 3.096713066101074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19032,
        "tokens": 9978249216,
        "learning_rate": 0.00023172118633074283,
        "gradient_norm": 0.36318397521972656,
        "train_loss": 3.1306686401367188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19033,
        "tokens": 9978773504,
        "learning_rate": 0.00023169450619088606,
        "gradient_norm": 0.3807127773761749,
        "train_loss": 3.086085796356201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19034,
        "tokens": 9979297792,
        "learning_rate": 0.00023166782715758008,
        "gradient_norm": 0.3631913363933563,
        "train_loss": 3.0973644256591797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19035,
        "tokens": 9979822080,
        "learning_rate": 0.00023164114923112538,
        "gradient_norm": 0.36085042357444763,
        "train_loss": 3.120474338531494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19036,
        "tokens": 9980346368,
        "learning_rate": 0.00023161447241182203,
        "gradient_norm": 0.3586377799510956,
        "train_loss": 3.043853759765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19037,
        "tokens": 9980870656,
        "learning_rate": 0.00023158779669997043,
        "gradient_norm": 0.40531179308891296,
        "train_loss": 3.0496270656585693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19038,
        "tokens": 9981394944,
        "learning_rate": 0.00023156112209587099,
        "gradient_norm": 0.34664344787597656,
        "train_loss": 3.108717203140259,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19039,
        "tokens": 9981919232,
        "learning_rate": 0.00023153444859982372,
        "gradient_norm": 0.3785228431224823,
        "train_loss": 3.0753796100616455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19040,
        "tokens": 9982443520,
        "learning_rate": 0.00023150777621212907,
        "gradient_norm": 0.364773154258728,
        "train_loss": 3.0742249488830566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19041,
        "tokens": 9982967808,
        "learning_rate": 0.00023148110493308706,
        "gradient_norm": 0.4274665117263794,
        "train_loss": 3.049913167953491,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19042,
        "tokens": 9983492096,
        "learning_rate": 0.00023145443476299814,
        "gradient_norm": 0.3377346992492676,
        "train_loss": 3.08384108543396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19043,
        "tokens": 9984016384,
        "learning_rate": 0.00023142776570216227,
        "gradient_norm": 0.37117037177085876,
        "train_loss": 3.1435112953186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19044,
        "tokens": 9984540672,
        "learning_rate": 0.00023140109775087988,
        "gradient_norm": 0.38322287797927856,
        "train_loss": 3.077706813812256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19045,
        "tokens": 9985064960,
        "learning_rate": 0.00023137443090945095,
        "gradient_norm": 0.33323800563812256,
        "train_loss": 3.08886981010437,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19046,
        "tokens": 9985589248,
        "learning_rate": 0.00023134776517817586,
        "gradient_norm": 0.5537301301956177,
        "train_loss": 3.0733494758605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19047,
        "tokens": 9986113536,
        "learning_rate": 0.0002313211005573545,
        "gradient_norm": 0.3773999512195587,
        "train_loss": 3.0580008029937744,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19048,
        "tokens": 9986637824,
        "learning_rate": 0.00023129443704728717,
        "gradient_norm": 0.40201422572135925,
        "train_loss": 3.0625405311584473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19049,
        "tokens": 9987162112,
        "learning_rate": 0.00023126777464827414,
        "gradient_norm": 0.32816699147224426,
        "train_loss": 3.0782341957092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19050,
        "tokens": 9987686400,
        "learning_rate": 0.00023124111336061522,
        "gradient_norm": 0.47713303565979004,
        "train_loss": 3.0427405834198,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19051,
        "tokens": 9988210688,
        "learning_rate": 0.0002312144531846108,
        "gradient_norm": 0.318531334400177,
        "train_loss": 3.020824909210205,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19052,
        "tokens": 9988734976,
        "learning_rate": 0.00023118779412056075,
        "gradient_norm": 0.3818073868751526,
        "train_loss": 3.0101065635681152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19053,
        "tokens": 9989259264,
        "learning_rate": 0.00023116113616876533,
        "gradient_norm": 0.3146857023239136,
        "train_loss": 3.1279211044311523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19054,
        "tokens": 9989783552,
        "learning_rate": 0.00023113447932952445,
        "gradient_norm": 0.373778373003006,
        "train_loss": 3.0887486934661865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19055,
        "tokens": 9990307840,
        "learning_rate": 0.00023110782360313833,
        "gradient_norm": 0.3277274966239929,
        "train_loss": 3.0659642219543457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19056,
        "tokens": 9990832128,
        "learning_rate": 0.00023108116898990684,
        "gradient_norm": 0.3241901993751526,
        "train_loss": 3.053861141204834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19057,
        "tokens": 9991356416,
        "learning_rate": 0.00023105451549013014,
        "gradient_norm": 0.35317671298980713,
        "train_loss": 3.0791163444519043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19058,
        "tokens": 9991880704,
        "learning_rate": 0.00023102786310410823,
        "gradient_norm": 0.36685702204704285,
        "train_loss": 3.081845283508301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19059,
        "tokens": 9992404992,
        "learning_rate": 0.00023100121183214104,
        "gradient_norm": 0.37533560395240784,
        "train_loss": 3.0708837509155273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19060,
        "tokens": 9992929280,
        "learning_rate": 0.0002309745616745287,
        "gradient_norm": 0.3430239260196686,
        "train_loss": 3.032078742980957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19061,
        "tokens": 9993453568,
        "learning_rate": 0.00023094791263157105,
        "gradient_norm": 0.32237282395362854,
        "train_loss": 3.087556838989258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19062,
        "tokens": 9993977856,
        "learning_rate": 0.0002309212647035681,
        "gradient_norm": 0.37191757559776306,
        "train_loss": 3.0660691261291504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19063,
        "tokens": 9994502144,
        "learning_rate": 0.00023089461789081988,
        "gradient_norm": 0.36327293515205383,
        "train_loss": 3.1104977130889893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19064,
        "tokens": 9995026432,
        "learning_rate": 0.00023086797219362622,
        "gradient_norm": 0.35340312123298645,
        "train_loss": 3.0019967555999756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19065,
        "tokens": 9995550720,
        "learning_rate": 0.00023084132761228712,
        "gradient_norm": 0.34501293301582336,
        "train_loss": 3.106236696243286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19066,
        "tokens": 9996075008,
        "learning_rate": 0.00023081468414710247,
        "gradient_norm": 0.3296135365962982,
        "train_loss": 3.0673060417175293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19067,
        "tokens": 9996599296,
        "learning_rate": 0.00023078804179837222,
        "gradient_norm": 0.3352328836917877,
        "train_loss": 3.1093921661376953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19068,
        "tokens": 9997123584,
        "learning_rate": 0.00023076140056639617,
        "gradient_norm": 0.3635079562664032,
        "train_loss": 3.120584011077881,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19069,
        "tokens": 9997647872,
        "learning_rate": 0.00023073476045147432,
        "gradient_norm": 0.35700568556785583,
        "train_loss": 3.118098497390747,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19070,
        "tokens": 9998172160,
        "learning_rate": 0.0002307081214539064,
        "gradient_norm": 0.35946905612945557,
        "train_loss": 3.0371627807617188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19071,
        "tokens": 9998696448,
        "learning_rate": 0.0002306814835739925,
        "gradient_norm": 0.3367388844490051,
        "train_loss": 3.119446039199829,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19072,
        "tokens": 9999220736,
        "learning_rate": 0.00023065484681203215,
        "gradient_norm": 0.3808913826942444,
        "train_loss": 3.1316566467285156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19073,
        "tokens": 9999745024,
        "learning_rate": 0.00023062821116832542,
        "gradient_norm": 0.3461400270462036,
        "train_loss": 3.0941948890686035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19074,
        "tokens": 10000269312,
        "learning_rate": 0.00023060157664317197,
        "gradient_norm": 0.3624468147754669,
        "train_loss": 3.1045408248901367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19075,
        "tokens": 10000793600,
        "learning_rate": 0.0002305749432368718,
        "gradient_norm": 0.3773992657661438,
        "train_loss": 3.022087574005127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19076,
        "tokens": 10001317888,
        "learning_rate": 0.00023054831094972445,
        "gradient_norm": 0.41185420751571655,
        "train_loss": 3.0953516960144043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19077,
        "tokens": 10001842176,
        "learning_rate": 0.00023052167978202987,
        "gradient_norm": 0.3669281303882599,
        "train_loss": 3.062657117843628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19078,
        "tokens": 10002366464,
        "learning_rate": 0.0002304950497340878,
        "gradient_norm": 0.43534085154533386,
        "train_loss": 3.066202402114868,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19079,
        "tokens": 10002890752,
        "learning_rate": 0.00023046842080619794,
        "gradient_norm": 0.3911648690700531,
        "train_loss": 3.1205649375915527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19080,
        "tokens": 10003415040,
        "learning_rate": 0.00023044179299866018,
        "gradient_norm": 0.47188931703567505,
        "train_loss": 3.1203763484954834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19081,
        "tokens": 10003939328,
        "learning_rate": 0.00023041516631177404,
        "gradient_norm": 0.38027966022491455,
        "train_loss": 3.038184881210327,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19082,
        "tokens": 10004463616,
        "learning_rate": 0.00023038854074583943,
        "gradient_norm": 0.520912766456604,
        "train_loss": 3.06691837310791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19083,
        "tokens": 10004987904,
        "learning_rate": 0.00023036191630115588,
        "gradient_norm": 0.373982697725296,
        "train_loss": 3.0320024490356445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19084,
        "tokens": 10005512192,
        "learning_rate": 0.00023033529297802327,
        "gradient_norm": 0.4597023129463196,
        "train_loss": 3.105329990386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19085,
        "tokens": 10006036480,
        "learning_rate": 0.00023030867077674104,
        "gradient_norm": 0.41645073890686035,
        "train_loss": 3.0913753509521484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19086,
        "tokens": 10006560768,
        "learning_rate": 0.00023028204969760899,
        "gradient_norm": 0.4779241979122162,
        "train_loss": 3.0918195247650146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19087,
        "tokens": 10007085056,
        "learning_rate": 0.00023025542974092688,
        "gradient_norm": 0.4143175780773163,
        "train_loss": 3.091068983078003,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19088,
        "tokens": 10007609344,
        "learning_rate": 0.00023022881090699413,
        "gradient_norm": 0.3881402909755707,
        "train_loss": 3.0691001415252686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19089,
        "tokens": 10008133632,
        "learning_rate": 0.00023020219319611063,
        "gradient_norm": 0.3960302472114563,
        "train_loss": 3.0768778324127197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19090,
        "tokens": 10008657920,
        "learning_rate": 0.00023017557660857572,
        "gradient_norm": 0.3917197287082672,
        "train_loss": 3.101050853729248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19091,
        "tokens": 10009182208,
        "learning_rate": 0.00023014896114468918,
        "gradient_norm": 0.35517334938049316,
        "train_loss": 3.065035820007324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19092,
        "tokens": 10009706496,
        "learning_rate": 0.00023012234680475053,
        "gradient_norm": 0.3784443736076355,
        "train_loss": 3.079057216644287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19093,
        "tokens": 10010230784,
        "learning_rate": 0.00023009573358905944,
        "gradient_norm": 0.4045852720737457,
        "train_loss": 3.102626323699951,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19094,
        "tokens": 10010755072,
        "learning_rate": 0.00023006912149791528,
        "gradient_norm": 0.37649568915367126,
        "train_loss": 3.025629997253418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19095,
        "tokens": 10011279360,
        "learning_rate": 0.0002300425105316178,
        "gradient_norm": 0.37279996275901794,
        "train_loss": 3.072208881378174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19096,
        "tokens": 10011803648,
        "learning_rate": 0.00023001590069046644,
        "gradient_norm": 0.37326687574386597,
        "train_loss": 3.0496888160705566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19097,
        "tokens": 10012327936,
        "learning_rate": 0.00022998929197476072,
        "gradient_norm": 0.3951651155948639,
        "train_loss": 3.1240763664245605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19098,
        "tokens": 10012852224,
        "learning_rate": 0.00022996268438480027,
        "gradient_norm": 0.3442813754081726,
        "train_loss": 3.029766798019409,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19099,
        "tokens": 10013376512,
        "learning_rate": 0.0002299360779208844,
        "gradient_norm": 0.3400111496448517,
        "train_loss": 3.0213727951049805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19100,
        "tokens": 10013900800,
        "learning_rate": 0.00022990947258331285,
        "gradient_norm": 0.35882678627967834,
        "train_loss": 3.0513710975646973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19101,
        "tokens": 10014425088,
        "learning_rate": 0.00022988286837238481,
        "gradient_norm": 0.39997243881225586,
        "train_loss": 3.0738871097564697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19102,
        "tokens": 10014949376,
        "learning_rate": 0.00022985626528840002,
        "gradient_norm": 0.3032709062099457,
        "train_loss": 3.075364828109741,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19103,
        "tokens": 10015473664,
        "learning_rate": 0.00022982966333165767,
        "gradient_norm": 0.34925463795661926,
        "train_loss": 3.0671465396881104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19104,
        "tokens": 10015997952,
        "learning_rate": 0.00022980306250245741,
        "gradient_norm": 0.3515016436576843,
        "train_loss": 3.1073622703552246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19105,
        "tokens": 10016522240,
        "learning_rate": 0.0002297764628010985,
        "gradient_norm": 0.33821800351142883,
        "train_loss": 3.1004910469055176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19106,
        "tokens": 10017046528,
        "learning_rate": 0.00022974986422788052,
        "gradient_norm": 0.36251965165138245,
        "train_loss": 3.1045734882354736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19107,
        "tokens": 10017570816,
        "learning_rate": 0.00022972326678310273,
        "gradient_norm": 0.3838757574558258,
        "train_loss": 3.0949277877807617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19108,
        "tokens": 10018095104,
        "learning_rate": 0.00022969667046706456,
        "gradient_norm": 0.40963223576545715,
        "train_loss": 3.052762746810913,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19109,
        "tokens": 10018619392,
        "learning_rate": 0.00022967007528006545,
        "gradient_norm": 0.3646849989891052,
        "train_loss": 3.102086305618286,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19110,
        "tokens": 10019143680,
        "learning_rate": 0.0002296434812224046,
        "gradient_norm": 0.37900257110595703,
        "train_loss": 3.061396598815918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19111,
        "tokens": 10019667968,
        "learning_rate": 0.00022961688829438163,
        "gradient_norm": 0.389169842004776,
        "train_loss": 3.070728302001953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19112,
        "tokens": 10020192256,
        "learning_rate": 0.0002295902964962956,
        "gradient_norm": 0.3402177691459656,
        "train_loss": 3.0768351554870605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19113,
        "tokens": 10020716544,
        "learning_rate": 0.000229563705828446,
        "gradient_norm": 0.362565815448761,
        "train_loss": 3.0742926597595215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19114,
        "tokens": 10021240832,
        "learning_rate": 0.000229537116291132,
        "gradient_norm": 0.34926891326904297,
        "train_loss": 3.05904221534729,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19115,
        "tokens": 10021765120,
        "learning_rate": 0.0002295105278846531,
        "gradient_norm": 0.34964504837989807,
        "train_loss": 3.0634665489196777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19116,
        "tokens": 10022289408,
        "learning_rate": 0.0002294839406093084,
        "gradient_norm": 0.33791685104370117,
        "train_loss": 3.0786828994750977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19117,
        "tokens": 10022813696,
        "learning_rate": 0.00022945735446539727,
        "gradient_norm": 0.36004820466041565,
        "train_loss": 3.0418858528137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19118,
        "tokens": 10023337984,
        "learning_rate": 0.00022943076945321892,
        "gradient_norm": 0.3302551209926605,
        "train_loss": 3.049788475036621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19119,
        "tokens": 10023862272,
        "learning_rate": 0.00022940418557307267,
        "gradient_norm": 0.3387688398361206,
        "train_loss": 3.080714464187622,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19120,
        "tokens": 10024386560,
        "learning_rate": 0.00022937760282525766,
        "gradient_norm": 0.32752883434295654,
        "train_loss": 3.0918498039245605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19121,
        "tokens": 10024910848,
        "learning_rate": 0.00022935102121007323,
        "gradient_norm": 0.3455091118812561,
        "train_loss": 3.079021692276001,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19122,
        "tokens": 10025435136,
        "learning_rate": 0.00022932444072781846,
        "gradient_norm": 0.3766799569129944,
        "train_loss": 3.061150550842285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19123,
        "tokens": 10025959424,
        "learning_rate": 0.00022929786137879262,
        "gradient_norm": 0.32881924510002136,
        "train_loss": 3.07342267036438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19124,
        "tokens": 10026483712,
        "learning_rate": 0.00022927128316329486,
        "gradient_norm": 0.3861485421657562,
        "train_loss": 3.0799760818481445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19125,
        "tokens": 10027008000,
        "learning_rate": 0.00022924470608162438,
        "gradient_norm": 0.356189489364624,
        "train_loss": 3.06805419921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19126,
        "tokens": 10027532288,
        "learning_rate": 0.0002292181301340803,
        "gradient_norm": 0.39544618129730225,
        "train_loss": 3.0954089164733887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19127,
        "tokens": 10028056576,
        "learning_rate": 0.00022919155532096186,
        "gradient_norm": 0.32423505187034607,
        "train_loss": 3.0411248207092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19128,
        "tokens": 10028580864,
        "learning_rate": 0.00022916498164256806,
        "gradient_norm": 0.37735480070114136,
        "train_loss": 3.0846831798553467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19129,
        "tokens": 10029105152,
        "learning_rate": 0.00022913840909919816,
        "gradient_norm": 0.3709733188152313,
        "train_loss": 3.1067428588867188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19130,
        "tokens": 10029629440,
        "learning_rate": 0.00022911183769115111,
        "gradient_norm": 0.31491485238075256,
        "train_loss": 3.113842248916626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19131,
        "tokens": 10030153728,
        "learning_rate": 0.00022908526741872618,
        "gradient_norm": 0.34340259432792664,
        "train_loss": 3.012247085571289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19132,
        "tokens": 10030678016,
        "learning_rate": 0.00022905869828222222,
        "gradient_norm": 0.3293040692806244,
        "train_loss": 3.0495448112487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19133,
        "tokens": 10031202304,
        "learning_rate": 0.0002290321302819386,
        "gradient_norm": 0.3688095510005951,
        "train_loss": 3.1017348766326904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19134,
        "tokens": 10031726592,
        "learning_rate": 0.0002290055634181741,
        "gradient_norm": 0.3376101851463318,
        "train_loss": 3.081547260284424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19135,
        "tokens": 10032250880,
        "learning_rate": 0.00022897899769122796,
        "gradient_norm": 0.3781132698059082,
        "train_loss": 3.0690441131591797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19136,
        "tokens": 10032775168,
        "learning_rate": 0.00022895243310139902,
        "gradient_norm": 0.3571763336658478,
        "train_loss": 3.0013790130615234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19137,
        "tokens": 10033299456,
        "learning_rate": 0.00022892586964898644,
        "gradient_norm": 0.36657586693763733,
        "train_loss": 3.0713694095611572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19138,
        "tokens": 10033823744,
        "learning_rate": 0.00022889930733428925,
        "gradient_norm": 0.350841224193573,
        "train_loss": 3.037442207336426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19139,
        "tokens": 10034348032,
        "learning_rate": 0.0002288727461576063,
        "gradient_norm": 0.3606164753437042,
        "train_loss": 3.037461280822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19140,
        "tokens": 10034872320,
        "learning_rate": 0.00022884618611923675,
        "gradient_norm": 0.3585048317909241,
        "train_loss": 3.051919460296631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19141,
        "tokens": 10035396608,
        "learning_rate": 0.00022881962721947935,
        "gradient_norm": 0.3701927959918976,
        "train_loss": 3.0771636962890625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19142,
        "tokens": 10035920896,
        "learning_rate": 0.00022879306945863327,
        "gradient_norm": 0.352591335773468,
        "train_loss": 3.078651189804077,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19143,
        "tokens": 10036445184,
        "learning_rate": 0.0002287665128369973,
        "gradient_norm": 0.34491172432899475,
        "train_loss": 3.0557198524475098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19144,
        "tokens": 10036969472,
        "learning_rate": 0.00022873995735487048,
        "gradient_norm": 0.3575454652309418,
        "train_loss": 3.064601421356201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19145,
        "tokens": 10037493760,
        "learning_rate": 0.00022871340301255157,
        "gradient_norm": 0.3960360288619995,
        "train_loss": 3.094566822052002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19146,
        "tokens": 10038018048,
        "learning_rate": 0.00022868684981033953,
        "gradient_norm": 0.29787585139274597,
        "train_loss": 3.067291259765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19147,
        "tokens": 10038542336,
        "learning_rate": 0.00022866029774853343,
        "gradient_norm": 0.38354137539863586,
        "train_loss": 2.998579978942871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19148,
        "tokens": 10039066624,
        "learning_rate": 0.0002286337468274319,
        "gradient_norm": 0.3526975214481354,
        "train_loss": 3.0706329345703125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19149,
        "tokens": 10039590912,
        "learning_rate": 0.00022860719704733402,
        "gradient_norm": 0.3513607382774353,
        "train_loss": 3.091045379638672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19150,
        "tokens": 10040115200,
        "learning_rate": 0.00022858064840853838,
        "gradient_norm": 0.369595468044281,
        "train_loss": 3.054227828979492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19151,
        "tokens": 10040639488,
        "learning_rate": 0.00022855410091134407,
        "gradient_norm": 0.30562183260917664,
        "train_loss": 3.056391716003418,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19152,
        "tokens": 10041163776,
        "learning_rate": 0.00022852755455604975,
        "gradient_norm": 0.329878032207489,
        "train_loss": 3.1151652336120605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19153,
        "tokens": 10041688064,
        "learning_rate": 0.00022850100934295437,
        "gradient_norm": 0.3501656651496887,
        "train_loss": 3.0572197437286377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19154,
        "tokens": 10042212352,
        "learning_rate": 0.00022847446527235655,
        "gradient_norm": 0.3113660514354706,
        "train_loss": 3.0874900817871094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19155,
        "tokens": 10042736640,
        "learning_rate": 0.00022844792234455528,
        "gradient_norm": 0.38071689009666443,
        "train_loss": 3.11618709564209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19156,
        "tokens": 10043260928,
        "learning_rate": 0.00022842138055984915,
        "gradient_norm": 0.33920368552207947,
        "train_loss": 3.0574264526367188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19157,
        "tokens": 10043785216,
        "learning_rate": 0.00022839483991853697,
        "gradient_norm": 0.3680352568626404,
        "train_loss": 3.054598331451416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19158,
        "tokens": 10044309504,
        "learning_rate": 0.00022836830042091764,
        "gradient_norm": 0.35016506910324097,
        "train_loss": 3.082265853881836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19159,
        "tokens": 10044833792,
        "learning_rate": 0.00022834176206728966,
        "gradient_norm": 0.455970823764801,
        "train_loss": 3.0397732257843018,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19160,
        "tokens": 10045358080,
        "learning_rate": 0.00022831522485795199,
        "gradient_norm": 0.38799914717674255,
        "train_loss": 3.0169453620910645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19161,
        "tokens": 10045882368,
        "learning_rate": 0.00022828868879320308,
        "gradient_norm": 0.4050547480583191,
        "train_loss": 3.088134765625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19162,
        "tokens": 10046406656,
        "learning_rate": 0.00022826215387334193,
        "gradient_norm": 0.38527026772499084,
        "train_loss": 3.089864730834961,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19163,
        "tokens": 10046930944,
        "learning_rate": 0.0002282356200986669,
        "gradient_norm": 0.34864363074302673,
        "train_loss": 3.079047441482544,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19164,
        "tokens": 10047455232,
        "learning_rate": 0.00022820908746947697,
        "gradient_norm": 0.45368361473083496,
        "train_loss": 3.0633044242858887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19165,
        "tokens": 10047979520,
        "learning_rate": 0.00022818255598607047,
        "gradient_norm": 0.3429411053657532,
        "train_loss": 3.036281108856201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19166,
        "tokens": 10048503808,
        "learning_rate": 0.00022815602564874634,
        "gradient_norm": 0.44068658351898193,
        "train_loss": 3.1160852909088135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19167,
        "tokens": 10049028096,
        "learning_rate": 0.00022812949645780307,
        "gradient_norm": 0.3455331027507782,
        "train_loss": 3.0530881881713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19168,
        "tokens": 10049552384,
        "learning_rate": 0.0002281029684135393,
        "gradient_norm": 0.3348730504512787,
        "train_loss": 3.021892547607422,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19169,
        "tokens": 10050076672,
        "learning_rate": 0.00022807644151625367,
        "gradient_norm": 0.34033969044685364,
        "train_loss": 3.092560291290283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19170,
        "tokens": 10050600960,
        "learning_rate": 0.0002280499157662447,
        "gradient_norm": 0.3619184195995331,
        "train_loss": 3.0536136627197266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19171,
        "tokens": 10051125248,
        "learning_rate": 0.00022802339116381103,
        "gradient_norm": 0.3199317455291748,
        "train_loss": 3.0405449867248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19172,
        "tokens": 10051649536,
        "learning_rate": 0.00022799686770925116,
        "gradient_norm": 0.35566505789756775,
        "train_loss": 3.0825366973876953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19173,
        "tokens": 10052173824,
        "learning_rate": 0.00022797034540286378,
        "gradient_norm": 0.34261655807495117,
        "train_loss": 3.0037760734558105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19174,
        "tokens": 10052698112,
        "learning_rate": 0.0002279438242449473,
        "gradient_norm": 0.42908021807670593,
        "train_loss": 3.1636853218078613,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19175,
        "tokens": 10053222400,
        "learning_rate": 0.0002279173042358003,
        "gradient_norm": 0.36498308181762695,
        "train_loss": 3.014777183532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19176,
        "tokens": 10053746688,
        "learning_rate": 0.00022789078537572126,
        "gradient_norm": 0.3707195818424225,
        "train_loss": 3.0497426986694336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19177,
        "tokens": 10054270976,
        "learning_rate": 0.0002278642676650087,
        "gradient_norm": 0.38340437412261963,
        "train_loss": 3.088834524154663,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19178,
        "tokens": 10054795264,
        "learning_rate": 0.00022783775110396122,
        "gradient_norm": 0.39096683263778687,
        "train_loss": 3.140460729598999,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19179,
        "tokens": 10055319552,
        "learning_rate": 0.0002278112356928771,
        "gradient_norm": 0.3779905140399933,
        "train_loss": 3.0520849227905273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19180,
        "tokens": 10055843840,
        "learning_rate": 0.00022778472143205502,
        "gradient_norm": 0.36767521500587463,
        "train_loss": 3.0887932777404785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19181,
        "tokens": 10056368128,
        "learning_rate": 0.00022775820832179316,
        "gradient_norm": 0.41414573788642883,
        "train_loss": 3.106480598449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19182,
        "tokens": 10056892416,
        "learning_rate": 0.00022773169636239023,
        "gradient_norm": 0.3680882751941681,
        "train_loss": 3.0969676971435547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19183,
        "tokens": 10057416704,
        "learning_rate": 0.00022770518555414448,
        "gradient_norm": 0.4390726089477539,
        "train_loss": 3.0284013748168945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19184,
        "tokens": 10057940992,
        "learning_rate": 0.00022767867589735443,
        "gradient_norm": 0.3817482590675354,
        "train_loss": 3.0447983741760254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19185,
        "tokens": 10058465280,
        "learning_rate": 0.00022765216739231836,
        "gradient_norm": 0.4321582019329071,
        "train_loss": 3.13364315032959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19186,
        "tokens": 10058989568,
        "learning_rate": 0.00022762566003933473,
        "gradient_norm": 0.4026336669921875,
        "train_loss": 3.054241180419922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19187,
        "tokens": 10059513856,
        "learning_rate": 0.000227599153838702,
        "gradient_norm": 0.38672590255737305,
        "train_loss": 3.086357593536377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19188,
        "tokens": 10060038144,
        "learning_rate": 0.00022757264879071836,
        "gradient_norm": 0.3801077902317047,
        "train_loss": 3.10170316696167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19189,
        "tokens": 10060562432,
        "learning_rate": 0.0002275461448956823,
        "gradient_norm": 0.3966352343559265,
        "train_loss": 3.1136507987976074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19190,
        "tokens": 10061086720,
        "learning_rate": 0.000227519642153892,
        "gradient_norm": 0.3906959295272827,
        "train_loss": 3.0230584144592285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19191,
        "tokens": 10061611008,
        "learning_rate": 0.00022749314056564598,
        "gradient_norm": 0.38478830456733704,
        "train_loss": 3.0504183769226074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19192,
        "tokens": 10062135296,
        "learning_rate": 0.00022746664013124235,
        "gradient_norm": 0.35468313097953796,
        "train_loss": 3.090958595275879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19193,
        "tokens": 10062659584,
        "learning_rate": 0.0002274401408509796,
        "gradient_norm": 0.3934658467769623,
        "train_loss": 3.043884754180908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19194,
        "tokens": 10063183872,
        "learning_rate": 0.00022741364272515577,
        "gradient_norm": 0.381000280380249,
        "train_loss": 3.019089698791504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19195,
        "tokens": 10063708160,
        "learning_rate": 0.0002273871457540694,
        "gradient_norm": 0.42573022842407227,
        "train_loss": 3.067011833190918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19196,
        "tokens": 10064232448,
        "learning_rate": 0.0002273606499380185,
        "gradient_norm": 0.38350215554237366,
        "train_loss": 3.061944007873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19197,
        "tokens": 10064756736,
        "learning_rate": 0.00022733415527730145,
        "gradient_norm": 0.3855660855770111,
        "train_loss": 3.0844736099243164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19198,
        "tokens": 10065281024,
        "learning_rate": 0.00022730766177221656,
        "gradient_norm": 0.3188220262527466,
        "train_loss": 3.035916805267334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19199,
        "tokens": 10065805312,
        "learning_rate": 0.0002272811694230618,
        "gradient_norm": 0.351462721824646,
        "train_loss": 3.0108699798583984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19200,
        "tokens": 10066329600,
        "learning_rate": 0.00022725467823013566,
        "gradient_norm": 0.3400159478187561,
        "train_loss": 3.0613481998443604,
        "val_loss": 3.029355525970459,
        "hellaswag_acc": 0.2824138402938843,
        "hellaswag_acc_norm": 0.29506075382232666
    },
    {
        "step": 19201,
        "tokens": 10066853888,
        "learning_rate": 0.00022722818819373607,
        "gradient_norm": 0.3878224492073059,
        "train_loss": 3.0377631187438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19202,
        "tokens": 10067378176,
        "learning_rate": 0.00022720169931416146,
        "gradient_norm": 0.3371162414550781,
        "train_loss": 3.0679969787597656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19203,
        "tokens": 10067902464,
        "learning_rate": 0.00022717521159170976,
        "gradient_norm": 0.3856886923313141,
        "train_loss": 3.0924229621887207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19204,
        "tokens": 10068426752,
        "learning_rate": 0.0002271487250266793,
        "gradient_norm": 0.3250900208950043,
        "train_loss": 3.1058037281036377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19205,
        "tokens": 10068951040,
        "learning_rate": 0.0002271222396193681,
        "gradient_norm": 0.36161455512046814,
        "train_loss": 3.093069553375244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19206,
        "tokens": 10069475328,
        "learning_rate": 0.0002270957553700743,
        "gradient_norm": 0.41086435317993164,
        "train_loss": 3.0538783073425293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19207,
        "tokens": 10069999616,
        "learning_rate": 0.00022706927227909612,
        "gradient_norm": 0.3310409486293793,
        "train_loss": 3.079319953918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19208,
        "tokens": 10070523904,
        "learning_rate": 0.00022704279034673153,
        "gradient_norm": 0.3717111051082611,
        "train_loss": 3.0611777305603027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19209,
        "tokens": 10071048192,
        "learning_rate": 0.00022701630957327876,
        "gradient_norm": 0.3249801695346832,
        "train_loss": 3.0807182788848877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19210,
        "tokens": 10071572480,
        "learning_rate": 0.0002269898299590357,
        "gradient_norm": 0.43988722562789917,
        "train_loss": 3.091705322265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19211,
        "tokens": 10072096768,
        "learning_rate": 0.0002269633515043006,
        "gradient_norm": 0.3686732351779938,
        "train_loss": 3.0545389652252197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19212,
        "tokens": 10072621056,
        "learning_rate": 0.00022693687420937133,
        "gradient_norm": 0.37671196460723877,
        "train_loss": 3.044410228729248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19213,
        "tokens": 10073145344,
        "learning_rate": 0.0002269103980745461,
        "gradient_norm": 0.3646068871021271,
        "train_loss": 3.0751595497131348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19214,
        "tokens": 10073669632,
        "learning_rate": 0.00022688392310012275,
        "gradient_norm": 0.33613038063049316,
        "train_loss": 3.095945358276367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19215,
        "tokens": 10074193920,
        "learning_rate": 0.0002268574492863995,
        "gradient_norm": 0.3588472008705139,
        "train_loss": 3.0624806880950928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19216,
        "tokens": 10074718208,
        "learning_rate": 0.0002268309766336741,
        "gradient_norm": 0.39046669006347656,
        "train_loss": 3.1231729984283447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19217,
        "tokens": 10075242496,
        "learning_rate": 0.00022680450514224473,
        "gradient_norm": 0.3500382900238037,
        "train_loss": 3.1054439544677734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19218,
        "tokens": 10075766784,
        "learning_rate": 0.0002267780348124093,
        "gradient_norm": 0.3623901903629303,
        "train_loss": 3.0745444297790527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19219,
        "tokens": 10076291072,
        "learning_rate": 0.00022675156564446573,
        "gradient_norm": 0.3452896177768707,
        "train_loss": 3.0780043601989746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19220,
        "tokens": 10076815360,
        "learning_rate": 0.00022672509763871197,
        "gradient_norm": 0.3591442108154297,
        "train_loss": 3.1106104850769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19221,
        "tokens": 10077339648,
        "learning_rate": 0.00022669863079544602,
        "gradient_norm": 0.4120958149433136,
        "train_loss": 3.070427417755127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19222,
        "tokens": 10077863936,
        "learning_rate": 0.00022667216511496573,
        "gradient_norm": 0.3947271406650543,
        "train_loss": 3.044565200805664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19223,
        "tokens": 10078388224,
        "learning_rate": 0.000226645700597569,
        "gradient_norm": 0.3974933922290802,
        "train_loss": 3.0428884029388428,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19224,
        "tokens": 10078912512,
        "learning_rate": 0.0002266192372435538,
        "gradient_norm": 0.3991338610649109,
        "train_loss": 3.1225719451904297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19225,
        "tokens": 10079436800,
        "learning_rate": 0.00022659277505321794,
        "gradient_norm": 0.3587513864040375,
        "train_loss": 3.079414129257202,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19226,
        "tokens": 10079961088,
        "learning_rate": 0.00022656631402685924,
        "gradient_norm": 0.3567548394203186,
        "train_loss": 3.049152374267578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19227,
        "tokens": 10080485376,
        "learning_rate": 0.0002265398541647757,
        "gradient_norm": 0.3291909694671631,
        "train_loss": 3.0633740425109863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19228,
        "tokens": 10081009664,
        "learning_rate": 0.00022651339546726494,
        "gradient_norm": 0.4004215896129608,
        "train_loss": 3.071838140487671,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19229,
        "tokens": 10081533952,
        "learning_rate": 0.00022648693793462507,
        "gradient_norm": 0.3612689673900604,
        "train_loss": 3.097665309906006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19230,
        "tokens": 10082058240,
        "learning_rate": 0.00022646048156715358,
        "gradient_norm": 0.362643837928772,
        "train_loss": 3.044908046722412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19231,
        "tokens": 10082582528,
        "learning_rate": 0.0002264340263651486,
        "gradient_norm": 0.344918817281723,
        "train_loss": 3.097910165786743,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19232,
        "tokens": 10083106816,
        "learning_rate": 0.00022640757232890763,
        "gradient_norm": 0.4041232466697693,
        "train_loss": 3.052849531173706,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19233,
        "tokens": 10083631104,
        "learning_rate": 0.00022638111945872866,
        "gradient_norm": 0.37376633286476135,
        "train_loss": 3.08693265914917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19234,
        "tokens": 10084155392,
        "learning_rate": 0.00022635466775490924,
        "gradient_norm": 0.39485278725624084,
        "train_loss": 3.074324607849121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19235,
        "tokens": 10084679680,
        "learning_rate": 0.00022632821721774732,
        "gradient_norm": 0.39694204926490784,
        "train_loss": 3.08418607711792,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19236,
        "tokens": 10085203968,
        "learning_rate": 0.0002263017678475405,
        "gradient_norm": 0.3940146565437317,
        "train_loss": 3.1187052726745605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19237,
        "tokens": 10085728256,
        "learning_rate": 0.00022627531964458653,
        "gradient_norm": 0.37449678778648376,
        "train_loss": 3.0502567291259766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19238,
        "tokens": 10086252544,
        "learning_rate": 0.0002262488726091832,
        "gradient_norm": 0.3668305575847626,
        "train_loss": 3.102372646331787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19239,
        "tokens": 10086776832,
        "learning_rate": 0.00022622242674162805,
        "gradient_norm": 0.3861941695213318,
        "train_loss": 3.0730643272399902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19240,
        "tokens": 10087301120,
        "learning_rate": 0.00022619598204221897,
        "gradient_norm": 0.38646289706230164,
        "train_loss": 3.0847835540771484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19241,
        "tokens": 10087825408,
        "learning_rate": 0.00022616953851125338,
        "gradient_norm": 0.36295247077941895,
        "train_loss": 3.0238537788391113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19242,
        "tokens": 10088349696,
        "learning_rate": 0.00022614309614902922,
        "gradient_norm": 0.43423500657081604,
        "train_loss": 3.1780154705047607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19243,
        "tokens": 10088873984,
        "learning_rate": 0.0002261166549558438,
        "gradient_norm": 0.4555307924747467,
        "train_loss": 3.045579433441162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19244,
        "tokens": 10089398272,
        "learning_rate": 0.00022609021493199505,
        "gradient_norm": 0.3596494495868683,
        "train_loss": 3.0450496673583984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19245,
        "tokens": 10089922560,
        "learning_rate": 0.0002260637760777804,
        "gradient_norm": 0.424106240272522,
        "train_loss": 3.0162100791931152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19246,
        "tokens": 10090446848,
        "learning_rate": 0.00022603733839349742,
        "gradient_norm": 0.362516850233078,
        "train_loss": 3.1631317138671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19247,
        "tokens": 10090971136,
        "learning_rate": 0.00022601090187944394,
        "gradient_norm": 0.4935161769390106,
        "train_loss": 3.0689663887023926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19248,
        "tokens": 10091495424,
        "learning_rate": 0.0002259844665359173,
        "gradient_norm": 0.3897019624710083,
        "train_loss": 3.0705151557922363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19249,
        "tokens": 10092019712,
        "learning_rate": 0.00022595803236321522,
        "gradient_norm": 0.4117691218852997,
        "train_loss": 3.1601390838623047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19250,
        "tokens": 10092544000,
        "learning_rate": 0.0002259315993616351,
        "gradient_norm": 0.39263343811035156,
        "train_loss": 3.0698986053466797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19251,
        "tokens": 10093068288,
        "learning_rate": 0.00022590516753147465,
        "gradient_norm": 0.38108155131340027,
        "train_loss": 3.181002616882324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19252,
        "tokens": 10093592576,
        "learning_rate": 0.0002258787368730312,
        "gradient_norm": 0.413318395614624,
        "train_loss": 3.0618178844451904,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19253,
        "tokens": 10094116864,
        "learning_rate": 0.00022585230738660246,
        "gradient_norm": 0.3502894639968872,
        "train_loss": 3.0586893558502197,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19254,
        "tokens": 10094641152,
        "learning_rate": 0.0002258258790724857,
        "gradient_norm": 0.3802541494369507,
        "train_loss": 3.1056177616119385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19255,
        "tokens": 10095165440,
        "learning_rate": 0.00022579945193097864,
        "gradient_norm": 0.35580191016197205,
        "train_loss": 3.065850257873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19256,
        "tokens": 10095689728,
        "learning_rate": 0.00022577302596237854,
        "gradient_norm": 0.3385917544364929,
        "train_loss": 3.1342110633850098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19257,
        "tokens": 10096214016,
        "learning_rate": 0.00022574660116698295,
        "gradient_norm": 0.36102208495140076,
        "train_loss": 3.0837860107421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19258,
        "tokens": 10096738304,
        "learning_rate": 0.00022572017754508942,
        "gradient_norm": 0.35535964369773865,
        "train_loss": 3.1211795806884766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19259,
        "tokens": 10097262592,
        "learning_rate": 0.00022569375509699517,
        "gradient_norm": 0.4148699939250946,
        "train_loss": 3.0608983039855957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19260,
        "tokens": 10097786880,
        "learning_rate": 0.00022566733382299784,
        "gradient_norm": 0.3915184438228607,
        "train_loss": 3.0668535232543945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19261,
        "tokens": 10098311168,
        "learning_rate": 0.00022564091372339465,
        "gradient_norm": 0.40459901094436646,
        "train_loss": 3.125699520111084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19262,
        "tokens": 10098835456,
        "learning_rate": 0.00022561449479848312,
        "gradient_norm": 0.4869583249092102,
        "train_loss": 3.048069477081299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19263,
        "tokens": 10099359744,
        "learning_rate": 0.0002255880770485605,
        "gradient_norm": 0.3449634611606598,
        "train_loss": 3.049990177154541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19264,
        "tokens": 10099884032,
        "learning_rate": 0.0002255616604739243,
        "gradient_norm": 0.3658529818058014,
        "train_loss": 3.0511975288391113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19265,
        "tokens": 10100408320,
        "learning_rate": 0.00022553524507487173,
        "gradient_norm": 0.3954901099205017,
        "train_loss": 3.095191717147827,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19266,
        "tokens": 10100932608,
        "learning_rate": 0.0002255088308517002,
        "gradient_norm": 0.4090552031993866,
        "train_loss": 3.0843138694763184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19267,
        "tokens": 10101456896,
        "learning_rate": 0.00022548241780470706,
        "gradient_norm": 0.3223061263561249,
        "train_loss": 3.0155725479125977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19268,
        "tokens": 10101981184,
        "learning_rate": 0.0002254560059341896,
        "gradient_norm": 0.37334463000297546,
        "train_loss": 3.1157708168029785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19269,
        "tokens": 10102505472,
        "learning_rate": 0.0002254295952404451,
        "gradient_norm": 0.3711826503276825,
        "train_loss": 3.1236019134521484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19270,
        "tokens": 10103029760,
        "learning_rate": 0.00022540318572377083,
        "gradient_norm": 0.36262497305870056,
        "train_loss": 3.0670390129089355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19271,
        "tokens": 10103554048,
        "learning_rate": 0.00022537677738446413,
        "gradient_norm": 0.3625500202178955,
        "train_loss": 3.068427562713623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19272,
        "tokens": 10104078336,
        "learning_rate": 0.00022535037022282218,
        "gradient_norm": 0.3514903485774994,
        "train_loss": 3.101957321166992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19273,
        "tokens": 10104602624,
        "learning_rate": 0.00022532396423914232,
        "gradient_norm": 0.33386221528053284,
        "train_loss": 3.045701742172241,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19274,
        "tokens": 10105126912,
        "learning_rate": 0.00022529755943372166,
        "gradient_norm": 0.3337665796279907,
        "train_loss": 3.035658359527588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19275,
        "tokens": 10105651200,
        "learning_rate": 0.00022527115580685752,
        "gradient_norm": 0.3423473536968231,
        "train_loss": 3.0574283599853516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19276,
        "tokens": 10106175488,
        "learning_rate": 0.00022524475335884705,
        "gradient_norm": 0.3384664058685303,
        "train_loss": 3.1150245666503906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19277,
        "tokens": 10106699776,
        "learning_rate": 0.00022521835208998744,
        "gradient_norm": 0.3965986967086792,
        "train_loss": 3.081190586090088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19278,
        "tokens": 10107224064,
        "learning_rate": 0.00022519195200057594,
        "gradient_norm": 0.3681313693523407,
        "train_loss": 3.084257125854492,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19279,
        "tokens": 10107748352,
        "learning_rate": 0.0002251655530909096,
        "gradient_norm": 0.3797270357608795,
        "train_loss": 3.066002368927002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19280,
        "tokens": 10108272640,
        "learning_rate": 0.00022513915536128575,
        "gradient_norm": 0.3303581476211548,
        "train_loss": 3.0631208419799805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19281,
        "tokens": 10108796928,
        "learning_rate": 0.0002251127588120013,
        "gradient_norm": 0.3599163889884949,
        "train_loss": 3.0674986839294434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19282,
        "tokens": 10109321216,
        "learning_rate": 0.0002250863634433536,
        "gradient_norm": 0.3463813066482544,
        "train_loss": 3.0577893257141113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19283,
        "tokens": 10109845504,
        "learning_rate": 0.00022505996925563956,
        "gradient_norm": 0.3704577684402466,
        "train_loss": 3.0909929275512695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19284,
        "tokens": 10110369792,
        "learning_rate": 0.00022503357624915646,
        "gradient_norm": 0.33941417932510376,
        "train_loss": 3.0402286052703857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19285,
        "tokens": 10110894080,
        "learning_rate": 0.00022500718442420125,
        "gradient_norm": 0.3492646813392639,
        "train_loss": 3.0666613578796387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19286,
        "tokens": 10111418368,
        "learning_rate": 0.00022498079378107102,
        "gradient_norm": 0.32874855399131775,
        "train_loss": 3.0858073234558105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19287,
        "tokens": 10111942656,
        "learning_rate": 0.00022495440432006295,
        "gradient_norm": 0.3502384424209595,
        "train_loss": 3.099971055984497,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19288,
        "tokens": 10112466944,
        "learning_rate": 0.00022492801604147392,
        "gradient_norm": 0.36064302921295166,
        "train_loss": 3.076453685760498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19289,
        "tokens": 10112991232,
        "learning_rate": 0.0002249016289456012,
        "gradient_norm": 0.386247843503952,
        "train_loss": 3.132875442504883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19290,
        "tokens": 10113515520,
        "learning_rate": 0.00022487524303274145,
        "gradient_norm": 0.38602229952812195,
        "train_loss": 3.07565975189209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19291,
        "tokens": 10114039808,
        "learning_rate": 0.00022484885830319207,
        "gradient_norm": 0.345304012298584,
        "train_loss": 3.0790939331054688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19292,
        "tokens": 10114564096,
        "learning_rate": 0.00022482247475724972,
        "gradient_norm": 0.35710474848747253,
        "train_loss": 3.0357351303100586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19293,
        "tokens": 10115088384,
        "learning_rate": 0.00022479609239521163,
        "gradient_norm": 0.3988705277442932,
        "train_loss": 3.068816900253296,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19294,
        "tokens": 10115612672,
        "learning_rate": 0.0002247697112173746,
        "gradient_norm": 0.34845203161239624,
        "train_loss": 3.0640785694122314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19295,
        "tokens": 10116136960,
        "learning_rate": 0.00022474333122403565,
        "gradient_norm": 0.3804723620414734,
        "train_loss": 3.007744789123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19296,
        "tokens": 10116661248,
        "learning_rate": 0.00022471695241549166,
        "gradient_norm": 0.39682725071907043,
        "train_loss": 3.1233725547790527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19297,
        "tokens": 10117185536,
        "learning_rate": 0.00022469057479203964,
        "gradient_norm": 0.38818004727363586,
        "train_loss": 3.031195640563965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19298,
        "tokens": 10117709824,
        "learning_rate": 0.00022466419835397654,
        "gradient_norm": 0.35981202125549316,
        "train_loss": 3.0415737628936768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19299,
        "tokens": 10118234112,
        "learning_rate": 0.00022463782310159908,
        "gradient_norm": 0.35428422689437866,
        "train_loss": 3.058412790298462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19300,
        "tokens": 10118758400,
        "learning_rate": 0.0002246114490352044,
        "gradient_norm": 0.3543645143508911,
        "train_loss": 3.068479537963867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19301,
        "tokens": 10119282688,
        "learning_rate": 0.00022458507615508912,
        "gradient_norm": 0.34747710824012756,
        "train_loss": 3.0562877655029297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19302,
        "tokens": 10119806976,
        "learning_rate": 0.00022455870446155035,
        "gradient_norm": 0.3408537805080414,
        "train_loss": 3.032827854156494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19303,
        "tokens": 10120331264,
        "learning_rate": 0.0002245323339548846,
        "gradient_norm": 0.3346738815307617,
        "train_loss": 3.0841479301452637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19304,
        "tokens": 10120855552,
        "learning_rate": 0.00022450596463538907,
        "gradient_norm": 0.36005356907844543,
        "train_loss": 3.0375170707702637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19305,
        "tokens": 10121379840,
        "learning_rate": 0.0002244795965033603,
        "gradient_norm": 0.4111931622028351,
        "train_loss": 3.084280490875244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19306,
        "tokens": 10121904128,
        "learning_rate": 0.00022445322955909518,
        "gradient_norm": 0.33450600504875183,
        "train_loss": 3.056255578994751,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19307,
        "tokens": 10122428416,
        "learning_rate": 0.00022442686380289066,
        "gradient_norm": 0.43453314900398254,
        "train_loss": 3.037755012512207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19308,
        "tokens": 10122952704,
        "learning_rate": 0.00022440049923504326,
        "gradient_norm": 0.37122178077697754,
        "train_loss": 3.1118552684783936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19309,
        "tokens": 10123476992,
        "learning_rate": 0.00022437413585584998,
        "gradient_norm": 0.4161624014377594,
        "train_loss": 3.078464984893799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19310,
        "tokens": 10124001280,
        "learning_rate": 0.00022434777366560737,
        "gradient_norm": 0.36128056049346924,
        "train_loss": 3.062807559967041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19311,
        "tokens": 10124525568,
        "learning_rate": 0.0002243214126646124,
        "gradient_norm": 0.43559530377388,
        "train_loss": 3.0143022537231445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19312,
        "tokens": 10125049856,
        "learning_rate": 0.00022429505285316155,
        "gradient_norm": 0.3226648271083832,
        "train_loss": 3.036644697189331,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19313,
        "tokens": 10125574144,
        "learning_rate": 0.00022426869423155174,
        "gradient_norm": 0.41579991579055786,
        "train_loss": 3.067317485809326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19314,
        "tokens": 10126098432,
        "learning_rate": 0.0002242423368000794,
        "gradient_norm": 0.33949151635169983,
        "train_loss": 3.0370430946350098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19315,
        "tokens": 10126622720,
        "learning_rate": 0.0002242159805590416,
        "gradient_norm": 0.45048943161964417,
        "train_loss": 3.0798423290252686,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19316,
        "tokens": 10127147008,
        "learning_rate": 0.00022418962550873464,
        "gradient_norm": 0.3365076780319214,
        "train_loss": 3.0151586532592773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19317,
        "tokens": 10127671296,
        "learning_rate": 0.00022416327164945533,
        "gradient_norm": 0.38686737418174744,
        "train_loss": 2.9841885566711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19318,
        "tokens": 10128195584,
        "learning_rate": 0.00022413691898150049,
        "gradient_norm": 0.41191917657852173,
        "train_loss": 3.0840234756469727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19319,
        "tokens": 10128719872,
        "learning_rate": 0.00022411056750516644,
        "gradient_norm": 0.37134161591529846,
        "train_loss": 3.0498931407928467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19320,
        "tokens": 10129244160,
        "learning_rate": 0.00022408421722075006,
        "gradient_norm": 0.34110772609710693,
        "train_loss": 3.0842843055725098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19321,
        "tokens": 10129768448,
        "learning_rate": 0.00022405786812854773,
        "gradient_norm": 0.3354310989379883,
        "train_loss": 3.0404319763183594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19322,
        "tokens": 10130292736,
        "learning_rate": 0.00022403152022885627,
        "gradient_norm": 0.3497488498687744,
        "train_loss": 3.0361764430999756,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19323,
        "tokens": 10130817024,
        "learning_rate": 0.000224005173521972,
        "gradient_norm": 0.3381616473197937,
        "train_loss": 3.086946964263916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19324,
        "tokens": 10131341312,
        "learning_rate": 0.00022397882800819183,
        "gradient_norm": 0.3880951404571533,
        "train_loss": 3.0227549076080322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19325,
        "tokens": 10131865600,
        "learning_rate": 0.00022395248368781192,
        "gradient_norm": 0.33293846249580383,
        "train_loss": 3.050934314727783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19326,
        "tokens": 10132389888,
        "learning_rate": 0.00022392614056112909,
        "gradient_norm": 0.3615208566188812,
        "train_loss": 3.026078701019287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19327,
        "tokens": 10132914176,
        "learning_rate": 0.00022389979862843973,
        "gradient_norm": 0.3243531286716461,
        "train_loss": 3.1508078575134277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19328,
        "tokens": 10133438464,
        "learning_rate": 0.00022387345789004042,
        "gradient_norm": 0.34503623843193054,
        "train_loss": 3.010976791381836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19329,
        "tokens": 10133962752,
        "learning_rate": 0.00022384711834622765,
        "gradient_norm": 0.36779916286468506,
        "train_loss": 3.0264177322387695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19330,
        "tokens": 10134487040,
        "learning_rate": 0.00022382077999729785,
        "gradient_norm": 0.35076281428337097,
        "train_loss": 3.0572288036346436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19331,
        "tokens": 10135011328,
        "learning_rate": 0.00022379444284354754,
        "gradient_norm": 0.3815653920173645,
        "train_loss": 3.1016287803649902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19332,
        "tokens": 10135535616,
        "learning_rate": 0.00022376810688527318,
        "gradient_norm": 0.3803902566432953,
        "train_loss": 3.0846614837646484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19333,
        "tokens": 10136059904,
        "learning_rate": 0.0002237417721227712,
        "gradient_norm": 0.4098372161388397,
        "train_loss": 3.0690228939056396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19334,
        "tokens": 10136584192,
        "learning_rate": 0.000223715438556338,
        "gradient_norm": 0.3463176190853119,
        "train_loss": 3.03206205368042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19335,
        "tokens": 10137108480,
        "learning_rate": 0.00022368910618627007,
        "gradient_norm": 0.3608172833919525,
        "train_loss": 3.0721142292022705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19336,
        "tokens": 10137632768,
        "learning_rate": 0.00022366277501286374,
        "gradient_norm": 0.3577113151550293,
        "train_loss": 3.016627311706543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19337,
        "tokens": 10138157056,
        "learning_rate": 0.00022363644503641536,
        "gradient_norm": 0.47718778252601624,
        "train_loss": 2.9515256881713867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19338,
        "tokens": 10138681344,
        "learning_rate": 0.00022361011625722152,
        "gradient_norm": 0.44705212116241455,
        "train_loss": 3.045567274093628,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19339,
        "tokens": 10139205632,
        "learning_rate": 0.0002235837886755783,
        "gradient_norm": 0.35580557584762573,
        "train_loss": 3.067960262298584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19340,
        "tokens": 10139729920,
        "learning_rate": 0.00022355746229178232,
        "gradient_norm": 0.4168286919593811,
        "train_loss": 3.047698497772217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19341,
        "tokens": 10140254208,
        "learning_rate": 0.00022353113710612968,
        "gradient_norm": 0.37174591422080994,
        "train_loss": 3.081826686859131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19342,
        "tokens": 10140778496,
        "learning_rate": 0.00022350481311891692,
        "gradient_norm": 0.39270058274269104,
        "train_loss": 3.0558223724365234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19343,
        "tokens": 10141302784,
        "learning_rate": 0.0002234784903304401,
        "gradient_norm": 0.39128541946411133,
        "train_loss": 3.084193706512451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19344,
        "tokens": 10141827072,
        "learning_rate": 0.0002234521687409958,
        "gradient_norm": 0.3945678472518921,
        "train_loss": 3.106426954269409,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19345,
        "tokens": 10142351360,
        "learning_rate": 0.00022342584835088,
        "gradient_norm": 0.3791842758655548,
        "train_loss": 3.0648365020751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19346,
        "tokens": 10142875648,
        "learning_rate": 0.00022339952916038914,
        "gradient_norm": 0.3763614296913147,
        "train_loss": 3.003793239593506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19347,
        "tokens": 10143399936,
        "learning_rate": 0.00022337321116981963,
        "gradient_norm": 0.35145875811576843,
        "train_loss": 3.0779917240142822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19348,
        "tokens": 10143924224,
        "learning_rate": 0.00022334689437946738,
        "gradient_norm": 0.37896713614463806,
        "train_loss": 3.0780954360961914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19349,
        "tokens": 10144448512,
        "learning_rate": 0.00022332057878962888,
        "gradient_norm": 0.4504448473453522,
        "train_loss": 3.037752866744995,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19350,
        "tokens": 10144972800,
        "learning_rate": 0.00022329426440060015,
        "gradient_norm": 0.35611146688461304,
        "train_loss": 3.0738911628723145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19351,
        "tokens": 10145497088,
        "learning_rate": 0.00022326795121267758,
        "gradient_norm": 0.37440773844718933,
        "train_loss": 3.0919783115386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19352,
        "tokens": 10146021376,
        "learning_rate": 0.00022324163922615717,
        "gradient_norm": 0.3576674461364746,
        "train_loss": 3.0427517890930176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19353,
        "tokens": 10146545664,
        "learning_rate": 0.0002232153284413353,
        "gradient_norm": 0.36621302366256714,
        "train_loss": 3.1075422763824463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19354,
        "tokens": 10147069952,
        "learning_rate": 0.00022318901885850793,
        "gradient_norm": 0.3712514340877533,
        "train_loss": 3.1978909969329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19355,
        "tokens": 10147594240,
        "learning_rate": 0.00022316271047797138,
        "gradient_norm": 0.3883437216281891,
        "train_loss": 3.08712100982666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19356,
        "tokens": 10148118528,
        "learning_rate": 0.0002231364033000216,
        "gradient_norm": 0.3434949815273285,
        "train_loss": 3.0131664276123047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19357,
        "tokens": 10148642816,
        "learning_rate": 0.00022311009732495481,
        "gradient_norm": 0.34476444125175476,
        "train_loss": 3.065483570098877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19358,
        "tokens": 10149167104,
        "learning_rate": 0.0002230837925530672,
        "gradient_norm": 0.5246759653091431,
        "train_loss": 3.0923914909362793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19359,
        "tokens": 10149691392,
        "learning_rate": 0.0002230574889846547,
        "gradient_norm": 0.6674810647964478,
        "train_loss": 2.991908550262451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19360,
        "tokens": 10150215680,
        "learning_rate": 0.00022303118662001358,
        "gradient_norm": 0.4721234440803528,
        "train_loss": 3.078758716583252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19361,
        "tokens": 10150739968,
        "learning_rate": 0.00022300488545943967,
        "gradient_norm": 0.43872904777526855,
        "train_loss": 3.1409103870391846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19362,
        "tokens": 10151264256,
        "learning_rate": 0.00022297858550322924,
        "gradient_norm": 0.3960123360157013,
        "train_loss": 3.0749757289886475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19363,
        "tokens": 10151788544,
        "learning_rate": 0.00022295228675167815,
        "gradient_norm": 0.4527522027492523,
        "train_loss": 3.049689769744873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19364,
        "tokens": 10152312832,
        "learning_rate": 0.00022292598920508263,
        "gradient_norm": 0.3776179850101471,
        "train_loss": 3.088900089263916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19365,
        "tokens": 10152837120,
        "learning_rate": 0.00022289969286373845,
        "gradient_norm": 0.3856840431690216,
        "train_loss": 3.088559150695801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19366,
        "tokens": 10153361408,
        "learning_rate": 0.00022287339772794173,
        "gradient_norm": 0.36425498127937317,
        "train_loss": 3.021592855453491,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19367,
        "tokens": 10153885696,
        "learning_rate": 0.0002228471037979886,
        "gradient_norm": 0.416124165058136,
        "train_loss": 3.1246519088745117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19368,
        "tokens": 10154409984,
        "learning_rate": 0.0002228208110741747,
        "gradient_norm": 0.3679841458797455,
        "train_loss": 3.059195041656494,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19369,
        "tokens": 10154934272,
        "learning_rate": 0.00022279451955679633,
        "gradient_norm": 0.39927512407302856,
        "train_loss": 3.0538344383239746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19370,
        "tokens": 10155458560,
        "learning_rate": 0.00022276822924614917,
        "gradient_norm": 0.3564268946647644,
        "train_loss": 3.1018600463867188,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19371,
        "tokens": 10155982848,
        "learning_rate": 0.00022274194014252935,
        "gradient_norm": 0.40774551033973694,
        "train_loss": 3.0681982040405273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19372,
        "tokens": 10156507136,
        "learning_rate": 0.00022271565224623262,
        "gradient_norm": 0.36107563972473145,
        "train_loss": 3.131927967071533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19373,
        "tokens": 10157031424,
        "learning_rate": 0.00022268936555755505,
        "gradient_norm": 0.4040170907974243,
        "train_loss": 3.080077648162842,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19374,
        "tokens": 10157555712,
        "learning_rate": 0.00022266308007679232,
        "gradient_norm": 0.40821385383605957,
        "train_loss": 3.0442259311676025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19375,
        "tokens": 10158080000,
        "learning_rate": 0.0002226367958042405,
        "gradient_norm": 0.3646999001502991,
        "train_loss": 3.0691914558410645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19376,
        "tokens": 10158604288,
        "learning_rate": 0.00022261051274019534,
        "gradient_norm": 0.38263463973999023,
        "train_loss": 3.1279664039611816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19377,
        "tokens": 10159128576,
        "learning_rate": 0.0002225842308849527,
        "gradient_norm": 0.34842491149902344,
        "train_loss": 3.052874803543091,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19378,
        "tokens": 10159652864,
        "learning_rate": 0.0002225579502388085,
        "gradient_norm": 0.4011516869068146,
        "train_loss": 3.1320996284484863,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19379,
        "tokens": 10160177152,
        "learning_rate": 0.00022253167080205847,
        "gradient_norm": 0.34571218490600586,
        "train_loss": 3.0419328212738037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19380,
        "tokens": 10160701440,
        "learning_rate": 0.00022250539257499843,
        "gradient_norm": 0.35593387484550476,
        "train_loss": 3.0443265438079834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19381,
        "tokens": 10161225728,
        "learning_rate": 0.00022247911555792424,
        "gradient_norm": 0.33770790696144104,
        "train_loss": 3.0664095878601074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19382,
        "tokens": 10161750016,
        "learning_rate": 0.0002224528397511316,
        "gradient_norm": 0.3844901919364929,
        "train_loss": 3.116671562194824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19383,
        "tokens": 10162274304,
        "learning_rate": 0.00022242656515491632,
        "gradient_norm": 0.34348198771476746,
        "train_loss": 3.0601108074188232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19384,
        "tokens": 10162798592,
        "learning_rate": 0.00022240029176957414,
        "gradient_norm": 0.3897930681705475,
        "train_loss": 3.114145278930664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19385,
        "tokens": 10163322880,
        "learning_rate": 0.00022237401959540083,
        "gradient_norm": 0.3752838969230652,
        "train_loss": 3.085336208343506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19386,
        "tokens": 10163847168,
        "learning_rate": 0.000222347748632692,
        "gradient_norm": 0.38331568241119385,
        "train_loss": 3.0414085388183594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19387,
        "tokens": 10164371456,
        "learning_rate": 0.00022232147888174357,
        "gradient_norm": 0.3288806676864624,
        "train_loss": 3.0654640197753906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19388,
        "tokens": 10164895744,
        "learning_rate": 0.00022229521034285098,
        "gradient_norm": 0.39418789744377136,
        "train_loss": 3.0691473484039307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19389,
        "tokens": 10165420032,
        "learning_rate": 0.00022226894301631022,
        "gradient_norm": 0.3063613772392273,
        "train_loss": 3.082176446914673,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19390,
        "tokens": 10165944320,
        "learning_rate": 0.00022224267690241662,
        "gradient_norm": 0.37560799717903137,
        "train_loss": 3.136765718460083,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19391,
        "tokens": 10166468608,
        "learning_rate": 0.0002222164120014662,
        "gradient_norm": 0.3566780984401703,
        "train_loss": 3.092613697052002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19392,
        "tokens": 10166992896,
        "learning_rate": 0.00022219014831375428,
        "gradient_norm": 0.33658382296562195,
        "train_loss": 3.0577521324157715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19393,
        "tokens": 10167517184,
        "learning_rate": 0.0002221638858395767,
        "gradient_norm": 0.34516021609306335,
        "train_loss": 3.037569999694824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19394,
        "tokens": 10168041472,
        "learning_rate": 0.00022213762457922893,
        "gradient_norm": 0.35954612493515015,
        "train_loss": 3.0566511154174805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19395,
        "tokens": 10168565760,
        "learning_rate": 0.00022211136453300677,
        "gradient_norm": 0.3545181155204773,
        "train_loss": 3.0576696395874023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19396,
        "tokens": 10169090048,
        "learning_rate": 0.00022208510570120559,
        "gradient_norm": 0.360099196434021,
        "train_loss": 3.068009376525879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19397,
        "tokens": 10169614336,
        "learning_rate": 0.00022205884808412102,
        "gradient_norm": 0.3271369934082031,
        "train_loss": 3.0452709197998047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19398,
        "tokens": 10170138624,
        "learning_rate": 0.0002220325916820488,
        "gradient_norm": 0.39786121249198914,
        "train_loss": 3.069932222366333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19399,
        "tokens": 10170662912,
        "learning_rate": 0.00022200633649528423,
        "gradient_norm": 0.365876704454422,
        "train_loss": 3.08351469039917,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19400,
        "tokens": 10171187200,
        "learning_rate": 0.00022198008252412307,
        "gradient_norm": 0.35722342133522034,
        "train_loss": 3.0989785194396973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19401,
        "tokens": 10171711488,
        "learning_rate": 0.00022195382976886063,
        "gradient_norm": 0.3871552050113678,
        "train_loss": 3.0050418376922607,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19402,
        "tokens": 10172235776,
        "learning_rate": 0.00022192757822979262,
        "gradient_norm": 0.3993208706378937,
        "train_loss": 3.0802254676818848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19403,
        "tokens": 10172760064,
        "learning_rate": 0.00022190132790721436,
        "gradient_norm": 0.37726452946662903,
        "train_loss": 3.002025842666626,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19404,
        "tokens": 10173284352,
        "learning_rate": 0.00022187507880142146,
        "gradient_norm": 0.33648422360420227,
        "train_loss": 3.0512521266937256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19405,
        "tokens": 10173808640,
        "learning_rate": 0.00022184883091270924,
        "gradient_norm": 0.36649802327156067,
        "train_loss": 3.0663833618164062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19406,
        "tokens": 10174332928,
        "learning_rate": 0.00022182258424137324,
        "gradient_norm": 0.4067493677139282,
        "train_loss": 3.209322929382324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19407,
        "tokens": 10174857216,
        "learning_rate": 0.000221796338787709,
        "gradient_norm": 0.34577301144599915,
        "train_loss": 3.0322160720825195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19408,
        "tokens": 10175381504,
        "learning_rate": 0.00022177009455201177,
        "gradient_norm": 0.3664873540401459,
        "train_loss": 3.0662336349487305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19409,
        "tokens": 10175905792,
        "learning_rate": 0.0002217438515345771,
        "gradient_norm": 0.3597390055656433,
        "train_loss": 3.0753350257873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19410,
        "tokens": 10176430080,
        "learning_rate": 0.00022171760973570026,
        "gradient_norm": 0.3821263313293457,
        "train_loss": 3.0553178787231445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19411,
        "tokens": 10176954368,
        "learning_rate": 0.0002216913691556768,
        "gradient_norm": 0.3857748210430145,
        "train_loss": 3.0459418296813965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19412,
        "tokens": 10177478656,
        "learning_rate": 0.00022166512979480187,
        "gradient_norm": 0.3603546917438507,
        "train_loss": 3.0719759464263916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19413,
        "tokens": 10178002944,
        "learning_rate": 0.00022163889165337106,
        "gradient_norm": 0.39939218759536743,
        "train_loss": 3.044544219970703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19414,
        "tokens": 10178527232,
        "learning_rate": 0.0002216126547316795,
        "gradient_norm": 0.43816348910331726,
        "train_loss": 3.073765277862549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19415,
        "tokens": 10179051520,
        "learning_rate": 0.00022158641903002272,
        "gradient_norm": 0.40607598423957825,
        "train_loss": 3.0558271408081055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19416,
        "tokens": 10179575808,
        "learning_rate": 0.00022156018454869584,
        "gradient_norm": 0.34040284156799316,
        "train_loss": 3.0672507286071777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19417,
        "tokens": 10180100096,
        "learning_rate": 0.00022153395128799423,
        "gradient_norm": 0.37370264530181885,
        "train_loss": 3.065880298614502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19418,
        "tokens": 10180624384,
        "learning_rate": 0.00022150771924821333,
        "gradient_norm": 0.3752368688583374,
        "train_loss": 3.07889986038208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19419,
        "tokens": 10181148672,
        "learning_rate": 0.00022148148842964814,
        "gradient_norm": 0.38418737053871155,
        "train_loss": 3.1432158946990967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19420,
        "tokens": 10181672960,
        "learning_rate": 0.00022145525883259423,
        "gradient_norm": 0.41089892387390137,
        "train_loss": 3.0805039405822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19421,
        "tokens": 10182197248,
        "learning_rate": 0.0002214290304573466,
        "gradient_norm": 0.36034417152404785,
        "train_loss": 3.0856456756591797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19422,
        "tokens": 10182721536,
        "learning_rate": 0.0002214028033042006,
        "gradient_norm": 0.4358579218387604,
        "train_loss": 3.028564929962158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19423,
        "tokens": 10183245824,
        "learning_rate": 0.00022137657737345137,
        "gradient_norm": 0.3616434633731842,
        "train_loss": 3.0839452743530273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19424,
        "tokens": 10183770112,
        "learning_rate": 0.00022135035266539427,
        "gradient_norm": 0.35651397705078125,
        "train_loss": 3.0905539989471436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19425,
        "tokens": 10184294400,
        "learning_rate": 0.00022132412918032424,
        "gradient_norm": 0.3810248076915741,
        "train_loss": 3.145742893218994,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19426,
        "tokens": 10184818688,
        "learning_rate": 0.00022129790691853668,
        "gradient_norm": 0.39624524116516113,
        "train_loss": 3.0921630859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19427,
        "tokens": 10185342976,
        "learning_rate": 0.00022127168588032667,
        "gradient_norm": 0.3510283827781677,
        "train_loss": 3.0658037662506104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19428,
        "tokens": 10185867264,
        "learning_rate": 0.0002212454660659894,
        "gradient_norm": 0.40812617540359497,
        "train_loss": 3.0817298889160156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19429,
        "tokens": 10186391552,
        "learning_rate": 0.00022121924747581993,
        "gradient_norm": 0.3655896484851837,
        "train_loss": 3.054454803466797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19430,
        "tokens": 10186915840,
        "learning_rate": 0.00022119303011011344,
        "gradient_norm": 0.3490849435329437,
        "train_loss": 3.0220389366149902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19431,
        "tokens": 10187440128,
        "learning_rate": 0.00022116681396916506,
        "gradient_norm": 0.355885773897171,
        "train_loss": 3.066688060760498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19432,
        "tokens": 10187964416,
        "learning_rate": 0.0002211405990532698,
        "gradient_norm": 0.35215115547180176,
        "train_loss": 3.0834085941314697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19433,
        "tokens": 10188488704,
        "learning_rate": 0.00022111438536272286,
        "gradient_norm": 0.3614806830883026,
        "train_loss": 3.0468204021453857,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19434,
        "tokens": 10189012992,
        "learning_rate": 0.0002210881728978192,
        "gradient_norm": 0.3124745190143585,
        "train_loss": 2.9919731616973877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19435,
        "tokens": 10189537280,
        "learning_rate": 0.0002210619616588539,
        "gradient_norm": 0.38290566205978394,
        "train_loss": 3.0741493701934814,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19436,
        "tokens": 10190061568,
        "learning_rate": 0.00022103575164612207,
        "gradient_norm": 0.3212343454360962,
        "train_loss": 3.0773723125457764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19437,
        "tokens": 10190585856,
        "learning_rate": 0.0002210095428599186,
        "gradient_norm": 0.3354993760585785,
        "train_loss": 3.080200672149658,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19438,
        "tokens": 10191110144,
        "learning_rate": 0.0002209833353005387,
        "gradient_norm": 0.3394422233104706,
        "train_loss": 3.091498374938965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19439,
        "tokens": 10191634432,
        "learning_rate": 0.00022095712896827714,
        "gradient_norm": 0.3851729929447174,
        "train_loss": 3.1137921810150146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19440,
        "tokens": 10192158720,
        "learning_rate": 0.00022093092386342913,
        "gradient_norm": 0.408602237701416,
        "train_loss": 3.0737102031707764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19441,
        "tokens": 10192683008,
        "learning_rate": 0.0002209047199862894,
        "gradient_norm": 0.36966174840927124,
        "train_loss": 3.033022403717041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19442,
        "tokens": 10193207296,
        "learning_rate": 0.00022087851733715316,
        "gradient_norm": 0.36834704875946045,
        "train_loss": 3.0642662048339844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19443,
        "tokens": 10193731584,
        "learning_rate": 0.00022085231591631514,
        "gradient_norm": 0.3422478437423706,
        "train_loss": 3.0574936866760254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19444,
        "tokens": 10194255872,
        "learning_rate": 0.00022082611572407047,
        "gradient_norm": 0.4075455963611603,
        "train_loss": 3.0234997272491455,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19445,
        "tokens": 10194780160,
        "learning_rate": 0.0002207999167607138,
        "gradient_norm": 0.36547067761421204,
        "train_loss": 3.0449628829956055,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19446,
        "tokens": 10195304448,
        "learning_rate": 0.00022077371902654022,
        "gradient_norm": 0.39299631118774414,
        "train_loss": 3.0544514656066895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19447,
        "tokens": 10195828736,
        "learning_rate": 0.00022074752252184473,
        "gradient_norm": 0.38829633593559265,
        "train_loss": 3.075584888458252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19448,
        "tokens": 10196353024,
        "learning_rate": 0.0002207213272469219,
        "gradient_norm": 0.3757418692111969,
        "train_loss": 3.061798572540283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19449,
        "tokens": 10196877312,
        "learning_rate": 0.00022069513320206684,
        "gradient_norm": 0.3387692868709564,
        "train_loss": 3.151003360748291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19450,
        "tokens": 10197401600,
        "learning_rate": 0.0002206689403875743,
        "gradient_norm": 0.3864433765411377,
        "train_loss": 3.1638336181640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19451,
        "tokens": 10197925888,
        "learning_rate": 0.00022064274880373913,
        "gradient_norm": 0.3829962909221649,
        "train_loss": 3.0791079998016357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19452,
        "tokens": 10198450176,
        "learning_rate": 0.00022061655845085606,
        "gradient_norm": 0.3673354387283325,
        "train_loss": 3.083188533782959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19453,
        "tokens": 10198974464,
        "learning_rate": 0.00022059036932922012,
        "gradient_norm": 0.37796270847320557,
        "train_loss": 3.0354247093200684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19454,
        "tokens": 10199498752,
        "learning_rate": 0.0002205641814391258,
        "gradient_norm": 0.3679247498512268,
        "train_loss": 3.0878875255584717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19455,
        "tokens": 10200023040,
        "learning_rate": 0.00022053799478086815,
        "gradient_norm": 0.4171048402786255,
        "train_loss": 3.0942697525024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19456,
        "tokens": 10200547328,
        "learning_rate": 0.00022051180935474173,
        "gradient_norm": 0.3243867754936218,
        "train_loss": 3.04154896736145,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19457,
        "tokens": 10201071616,
        "learning_rate": 0.00022048562516104137,
        "gradient_norm": 0.4136269688606262,
        "train_loss": 3.0679447650909424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19458,
        "tokens": 10201595904,
        "learning_rate": 0.0002204594422000619,
        "gradient_norm": 0.3623410165309906,
        "train_loss": 3.089317560195923,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19459,
        "tokens": 10202120192,
        "learning_rate": 0.00022043326047209785,
        "gradient_norm": 0.387938529253006,
        "train_loss": 3.0740742683410645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19460,
        "tokens": 10202644480,
        "learning_rate": 0.00022040707997744417,
        "gradient_norm": 0.3874319791793823,
        "train_loss": 3.0746774673461914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19461,
        "tokens": 10203168768,
        "learning_rate": 0.0002203809007163953,
        "gradient_norm": 0.35385560989379883,
        "train_loss": 3.010624885559082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19462,
        "tokens": 10203693056,
        "learning_rate": 0.00022035472268924612,
        "gradient_norm": 0.37036797404289246,
        "train_loss": 3.0895938873291016,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19463,
        "tokens": 10204217344,
        "learning_rate": 0.00022032854589629108,
        "gradient_norm": 0.3806328773498535,
        "train_loss": 3.04860782623291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19464,
        "tokens": 10204741632,
        "learning_rate": 0.00022030237033782515,
        "gradient_norm": 0.36229249835014343,
        "train_loss": 3.063425064086914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19465,
        "tokens": 10205265920,
        "learning_rate": 0.00022027619601414262,
        "gradient_norm": 0.35714831948280334,
        "train_loss": 3.0807034969329834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19466,
        "tokens": 10205790208,
        "learning_rate": 0.00022025002292553833,
        "gradient_norm": 0.38159534335136414,
        "train_loss": 3.123213768005371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19467,
        "tokens": 10206314496,
        "learning_rate": 0.0002202238510723069,
        "gradient_norm": 0.3533029854297638,
        "train_loss": 3.0434367656707764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19468,
        "tokens": 10206838784,
        "learning_rate": 0.00022019768045474273,
        "gradient_norm": 0.39036792516708374,
        "train_loss": 3.046886920928955,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19469,
        "tokens": 10207363072,
        "learning_rate": 0.00022017151107314072,
        "gradient_norm": 0.3622734248638153,
        "train_loss": 3.072572708129883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19470,
        "tokens": 10207887360,
        "learning_rate": 0.00022014534292779512,
        "gradient_norm": 0.3464871346950531,
        "train_loss": 3.0530381202697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19471,
        "tokens": 10208411648,
        "learning_rate": 0.0002201191760190007,
        "gradient_norm": 0.3592834770679474,
        "train_loss": 3.04176664352417,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19472,
        "tokens": 10208935936,
        "learning_rate": 0.00022009301034705184,
        "gradient_norm": 0.3856600224971771,
        "train_loss": 3.0577073097229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19473,
        "tokens": 10209460224,
        "learning_rate": 0.0002200668459122433,
        "gradient_norm": 0.4112251400947571,
        "train_loss": 3.0777645111083984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19474,
        "tokens": 10209984512,
        "learning_rate": 0.00022004068271486927,
        "gradient_norm": 0.3463159501552582,
        "train_loss": 3.0450572967529297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19475,
        "tokens": 10210508800,
        "learning_rate": 0.0002200145207552245,
        "gradient_norm": 0.3557538390159607,
        "train_loss": 3.0466575622558594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19476,
        "tokens": 10211033088,
        "learning_rate": 0.00021998836003360342,
        "gradient_norm": 0.33793383836746216,
        "train_loss": 3.0549545288085938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19477,
        "tokens": 10211557376,
        "learning_rate": 0.00021996220055030047,
        "gradient_norm": 0.37257224321365356,
        "train_loss": 3.141111373901367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19478,
        "tokens": 10212081664,
        "learning_rate": 0.0002199360423056101,
        "gradient_norm": 0.3543189465999603,
        "train_loss": 3.049630880355835,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19479,
        "tokens": 10212605952,
        "learning_rate": 0.00021990988529982679,
        "gradient_norm": 0.35925108194351196,
        "train_loss": 3.084475517272949,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19480,
        "tokens": 10213130240,
        "learning_rate": 0.0002198837295332449,
        "gradient_norm": 0.3468208312988281,
        "train_loss": 3.0863759517669678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19481,
        "tokens": 10213654528,
        "learning_rate": 0.000219857575006159,
        "gradient_norm": 0.3883565664291382,
        "train_loss": 3.0680179595947266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19482,
        "tokens": 10214178816,
        "learning_rate": 0.00021983142171886334,
        "gradient_norm": 0.3586418926715851,
        "train_loss": 3.120954990386963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19483,
        "tokens": 10214703104,
        "learning_rate": 0.00021980526967165236,
        "gradient_norm": 0.3219946622848511,
        "train_loss": 3.1061551570892334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19484,
        "tokens": 10215227392,
        "learning_rate": 0.00021977911886482038,
        "gradient_norm": 0.3586927652359009,
        "train_loss": 3.016493797302246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19485,
        "tokens": 10215751680,
        "learning_rate": 0.00021975296929866188,
        "gradient_norm": 0.3218345046043396,
        "train_loss": 3.0487546920776367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19486,
        "tokens": 10216275968,
        "learning_rate": 0.00021972682097347107,
        "gradient_norm": 0.34417784214019775,
        "train_loss": 3.001828193664551,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19487,
        "tokens": 10216800256,
        "learning_rate": 0.00021970067388954242,
        "gradient_norm": 0.3449520468711853,
        "train_loss": 3.1057982444763184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19488,
        "tokens": 10217324544,
        "learning_rate": 0.00021967452804717012,
        "gradient_norm": 0.32272782921791077,
        "train_loss": 3.096529722213745,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19489,
        "tokens": 10217848832,
        "learning_rate": 0.0002196483834466486,
        "gradient_norm": 0.3335300087928772,
        "train_loss": 3.063730001449585,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19490,
        "tokens": 10218373120,
        "learning_rate": 0.00021962224008827196,
        "gradient_norm": 0.3332999348640442,
        "train_loss": 3.0980732440948486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19491,
        "tokens": 10218897408,
        "learning_rate": 0.0002195960979723347,
        "gradient_norm": 0.37481406331062317,
        "train_loss": 3.1571993827819824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19492,
        "tokens": 10219421696,
        "learning_rate": 0.00021956995709913093,
        "gradient_norm": 0.39641109108924866,
        "train_loss": 3.0998411178588867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19493,
        "tokens": 10219945984,
        "learning_rate": 0.00021954381746895502,
        "gradient_norm": 0.3702254295349121,
        "train_loss": 3.006324291229248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19494,
        "tokens": 10220470272,
        "learning_rate": 0.00021951767908210106,
        "gradient_norm": 0.36122336983680725,
        "train_loss": 3.032926559448242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19495,
        "tokens": 10220994560,
        "learning_rate": 0.00021949154193886332,
        "gradient_norm": 0.33408045768737793,
        "train_loss": 3.0581183433532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19496,
        "tokens": 10221518848,
        "learning_rate": 0.00021946540603953613,
        "gradient_norm": 0.38675668835639954,
        "train_loss": 2.993947982788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19497,
        "tokens": 10222043136,
        "learning_rate": 0.00021943927138441346,
        "gradient_norm": 0.34603744745254517,
        "train_loss": 3.0590929985046387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19498,
        "tokens": 10222567424,
        "learning_rate": 0.0002194131379737897,
        "gradient_norm": 0.3615310788154602,
        "train_loss": 3.082188606262207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19499,
        "tokens": 10223091712,
        "learning_rate": 0.00021938700580795888,
        "gradient_norm": 0.4021329879760742,
        "train_loss": 3.055152416229248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19500,
        "tokens": 10223616000,
        "learning_rate": 0.0002193608748872153,
        "gradient_norm": 0.35679537057876587,
        "train_loss": 3.089660167694092,
        "val_loss": 3.0260558128356934,
        "hellaswag_acc": 0.2834096848964691,
        "hellaswag_acc_norm": 0.2927703559398651
    },
    {
        "step": 19501,
        "tokens": 10224140288,
        "learning_rate": 0.00021933474521185282,
        "gradient_norm": 0.3396839499473572,
        "train_loss": 2.980930805206299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19502,
        "tokens": 10224664576,
        "learning_rate": 0.00021930861678216585,
        "gradient_norm": 0.34448105096817017,
        "train_loss": 3.022263526916504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19503,
        "tokens": 10225188864,
        "learning_rate": 0.0002192824895984483,
        "gradient_norm": 0.3696082830429077,
        "train_loss": 3.132962703704834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19504,
        "tokens": 10225713152,
        "learning_rate": 0.00021925636366099441,
        "gradient_norm": 0.36672544479370117,
        "train_loss": 3.071690559387207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19505,
        "tokens": 10226237440,
        "learning_rate": 0.0002192302389700981,
        "gradient_norm": 0.36241427063941956,
        "train_loss": 3.0454416275024414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19506,
        "tokens": 10226761728,
        "learning_rate": 0.0002192041155260535,
        "gradient_norm": 0.34112268686294556,
        "train_loss": 3.031606674194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19507,
        "tokens": 10227286016,
        "learning_rate": 0.00021917799332915486,
        "gradient_norm": 0.37084320187568665,
        "train_loss": 3.031007766723633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19508,
        "tokens": 10227810304,
        "learning_rate": 0.00021915187237969596,
        "gradient_norm": 0.3325514495372772,
        "train_loss": 3.029937267303467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19509,
        "tokens": 10228334592,
        "learning_rate": 0.00021912575267797095,
        "gradient_norm": 0.37749049067497253,
        "train_loss": 3.0301389694213867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19510,
        "tokens": 10228858880,
        "learning_rate": 0.0002190996342242737,
        "gradient_norm": 0.37473171949386597,
        "train_loss": 3.130474090576172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19511,
        "tokens": 10229383168,
        "learning_rate": 0.00021907351701889845,
        "gradient_norm": 0.40166372060775757,
        "train_loss": 3.0941147804260254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19512,
        "tokens": 10229907456,
        "learning_rate": 0.00021904740106213892,
        "gradient_norm": 0.3371489942073822,
        "train_loss": 3.0868749618530273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19513,
        "tokens": 10230431744,
        "learning_rate": 0.0002190212863542893,
        "gradient_norm": 0.4199845790863037,
        "train_loss": 3.105917453765869,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19514,
        "tokens": 10230956032,
        "learning_rate": 0.00021899517289564334,
        "gradient_norm": 0.3691868782043457,
        "train_loss": 3.056077003479004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19515,
        "tokens": 10231480320,
        "learning_rate": 0.00021896906068649504,
        "gradient_norm": 0.37424859404563904,
        "train_loss": 3.0694024562835693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19516,
        "tokens": 10232004608,
        "learning_rate": 0.0002189429497271385,
        "gradient_norm": 0.4176952540874481,
        "train_loss": 3.0247175693511963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19517,
        "tokens": 10232528896,
        "learning_rate": 0.00021891684001786743,
        "gradient_norm": 0.3766559958457947,
        "train_loss": 3.010911464691162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19518,
        "tokens": 10233053184,
        "learning_rate": 0.00021889073155897587,
        "gradient_norm": 0.32781827449798584,
        "train_loss": 3.0538573265075684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19519,
        "tokens": 10233577472,
        "learning_rate": 0.00021886462435075752,
        "gradient_norm": 0.34903478622436523,
        "train_loss": 3.0617189407348633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19520,
        "tokens": 10234101760,
        "learning_rate": 0.00021883851839350646,
        "gradient_norm": 0.3768727779388428,
        "train_loss": 3.067967414855957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19521,
        "tokens": 10234626048,
        "learning_rate": 0.00021881241368751632,
        "gradient_norm": 0.32988497614860535,
        "train_loss": 3.0841917991638184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19522,
        "tokens": 10235150336,
        "learning_rate": 0.00021878631023308122,
        "gradient_norm": 0.44233348965644836,
        "train_loss": 3.085935592651367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19523,
        "tokens": 10235674624,
        "learning_rate": 0.00021876020803049466,
        "gradient_norm": 0.4226472079753876,
        "train_loss": 3.0517702102661133,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19524,
        "tokens": 10236198912,
        "learning_rate": 0.00021873410708005077,
        "gradient_norm": 0.34425342082977295,
        "train_loss": 3.0454750061035156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19525,
        "tokens": 10236723200,
        "learning_rate": 0.0002187080073820431,
        "gradient_norm": 0.37378811836242676,
        "train_loss": 3.169437885284424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19526,
        "tokens": 10237247488,
        "learning_rate": 0.0002186819089367655,
        "gradient_norm": 0.3801722526550293,
        "train_loss": 3.104858160018921,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19527,
        "tokens": 10237771776,
        "learning_rate": 0.0002186558117445119,
        "gradient_norm": 0.39092791080474854,
        "train_loss": 3.094221353530884,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19528,
        "tokens": 10238296064,
        "learning_rate": 0.00021862971580557586,
        "gradient_norm": 0.42566466331481934,
        "train_loss": 3.079850435256958,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19529,
        "tokens": 10238820352,
        "learning_rate": 0.00021860362112025125,
        "gradient_norm": 0.38846975564956665,
        "train_loss": 3.027315139770508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19530,
        "tokens": 10239344640,
        "learning_rate": 0.00021857752768883167,
        "gradient_norm": 0.3565308451652527,
        "train_loss": 3.0761771202087402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19531,
        "tokens": 10239868928,
        "learning_rate": 0.000218551435511611,
        "gradient_norm": 0.3754156529903412,
        "train_loss": 3.053281784057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19532,
        "tokens": 10240393216,
        "learning_rate": 0.00021852534458888275,
        "gradient_norm": 0.3779430389404297,
        "train_loss": 3.087068557739258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19533,
        "tokens": 10240917504,
        "learning_rate": 0.0002184992549209408,
        "gradient_norm": 0.39331305027008057,
        "train_loss": 3.065354347229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19534,
        "tokens": 10241441792,
        "learning_rate": 0.0002184731665080786,
        "gradient_norm": 0.34960705041885376,
        "train_loss": 3.083303213119507,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19535,
        "tokens": 10241966080,
        "learning_rate": 0.00021844707935059001,
        "gradient_norm": 0.3913128972053528,
        "train_loss": 3.082289218902588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19536,
        "tokens": 10242490368,
        "learning_rate": 0.00021842099344876863,
        "gradient_norm": 0.3978990316390991,
        "train_loss": 3.020972490310669,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19537,
        "tokens": 10243014656,
        "learning_rate": 0.000218394908802908,
        "gradient_norm": 0.36023208498954773,
        "train_loss": 3.078554630279541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19538,
        "tokens": 10243538944,
        "learning_rate": 0.00021836882541330182,
        "gradient_norm": 0.3758627474308014,
        "train_loss": 3.0363104343414307,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19539,
        "tokens": 10244063232,
        "learning_rate": 0.00021834274328024365,
        "gradient_norm": 0.36481648683547974,
        "train_loss": 3.0554938316345215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19540,
        "tokens": 10244587520,
        "learning_rate": 0.00021831666240402708,
        "gradient_norm": 0.3684571087360382,
        "train_loss": 3.057589292526245,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19541,
        "tokens": 10245111808,
        "learning_rate": 0.00021829058278494573,
        "gradient_norm": 0.37489432096481323,
        "train_loss": 3.094670295715332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19542,
        "tokens": 10245636096,
        "learning_rate": 0.0002182645044232931,
        "gradient_norm": 0.36490657925605774,
        "train_loss": 3.0193793773651123,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19543,
        "tokens": 10246160384,
        "learning_rate": 0.00021823842731936275,
        "gradient_norm": 0.3807842433452606,
        "train_loss": 3.075164794921875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19544,
        "tokens": 10246684672,
        "learning_rate": 0.0002182123514734482,
        "gradient_norm": 0.3373214602470398,
        "train_loss": 3.0288617610931396,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19545,
        "tokens": 10247208960,
        "learning_rate": 0.000218186276885843,
        "gradient_norm": 0.44598495960235596,
        "train_loss": 3.0516576766967773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19546,
        "tokens": 10247733248,
        "learning_rate": 0.00021816020355684053,
        "gradient_norm": 0.4230234920978546,
        "train_loss": 3.092735767364502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19547,
        "tokens": 10248257536,
        "learning_rate": 0.0002181341314867346,
        "gradient_norm": 0.3880116641521454,
        "train_loss": 3.0236263275146484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19548,
        "tokens": 10248781824,
        "learning_rate": 0.00021810806067581824,
        "gradient_norm": 0.40709051489830017,
        "train_loss": 3.02823805809021,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19549,
        "tokens": 10249306112,
        "learning_rate": 0.0002180819911243853,
        "gradient_norm": 0.3460208773612976,
        "train_loss": 3.064133882522583,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19550,
        "tokens": 10249830400,
        "learning_rate": 0.00021805592283272895,
        "gradient_norm": 0.364367812871933,
        "train_loss": 3.074902057647705,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19551,
        "tokens": 10250354688,
        "learning_rate": 0.0002180298558011428,
        "gradient_norm": 0.3707810640335083,
        "train_loss": 3.043980598449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19552,
        "tokens": 10250878976,
        "learning_rate": 0.00021800379002992018,
        "gradient_norm": 0.38287603855133057,
        "train_loss": 3.0629005432128906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19553,
        "tokens": 10251403264,
        "learning_rate": 0.00021797772551935453,
        "gradient_norm": 0.3484443128108978,
        "train_loss": 3.061636209487915,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19554,
        "tokens": 10251927552,
        "learning_rate": 0.00021795166226973913,
        "gradient_norm": 0.4130265712738037,
        "train_loss": 3.0897634029388428,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19555,
        "tokens": 10252451840,
        "learning_rate": 0.00021792560028136744,
        "gradient_norm": 0.3532051146030426,
        "train_loss": 3.057915687561035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19556,
        "tokens": 10252976128,
        "learning_rate": 0.00021789953955453296,
        "gradient_norm": 0.3438895046710968,
        "train_loss": 3.0013175010681152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19557,
        "tokens": 10253500416,
        "learning_rate": 0.00021787348008952878,
        "gradient_norm": 0.34023618698120117,
        "train_loss": 3.058037757873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19558,
        "tokens": 10254024704,
        "learning_rate": 0.00021784742188664846,
        "gradient_norm": 0.3704361617565155,
        "train_loss": 3.09237003326416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19559,
        "tokens": 10254548992,
        "learning_rate": 0.0002178213649461851,
        "gradient_norm": 0.39576658606529236,
        "train_loss": 3.005368709564209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19560,
        "tokens": 10255073280,
        "learning_rate": 0.0002177953092684322,
        "gradient_norm": 0.37691783905029297,
        "train_loss": 3.059696674346924,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19561,
        "tokens": 10255597568,
        "learning_rate": 0.00021776925485368287,
        "gradient_norm": 0.3812999725341797,
        "train_loss": 3.0852527618408203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19562,
        "tokens": 10256121856,
        "learning_rate": 0.00021774320170223058,
        "gradient_norm": 0.3500722646713257,
        "train_loss": 3.027872085571289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19563,
        "tokens": 10256646144,
        "learning_rate": 0.00021771714981436838,
        "gradient_norm": 0.3601602017879486,
        "train_loss": 3.0481438636779785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19564,
        "tokens": 10257170432,
        "learning_rate": 0.00021769109919038973,
        "gradient_norm": 0.39287862181663513,
        "train_loss": 3.0815987586975098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19565,
        "tokens": 10257694720,
        "learning_rate": 0.00021766504983058765,
        "gradient_norm": 0.3575427830219269,
        "train_loss": 3.079003095626831,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19566,
        "tokens": 10258219008,
        "learning_rate": 0.0002176390017352555,
        "gradient_norm": 0.37877726554870605,
        "train_loss": 3.0346055030822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19567,
        "tokens": 10258743296,
        "learning_rate": 0.00021761295490468652,
        "gradient_norm": 0.37963002920150757,
        "train_loss": 3.080012798309326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19568,
        "tokens": 10259267584,
        "learning_rate": 0.0002175869093391737,
        "gradient_norm": 0.34868699312210083,
        "train_loss": 3.0674185752868652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19569,
        "tokens": 10259791872,
        "learning_rate": 0.0002175608650390105,
        "gradient_norm": 0.38477736711502075,
        "train_loss": 3.064815044403076,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19570,
        "tokens": 10260316160,
        "learning_rate": 0.00021753482200448975,
        "gradient_norm": 0.36055195331573486,
        "train_loss": 3.115516424179077,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19571,
        "tokens": 10260840448,
        "learning_rate": 0.00021750878023590493,
        "gradient_norm": 0.3708362281322479,
        "train_loss": 3.0367698669433594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19572,
        "tokens": 10261364736,
        "learning_rate": 0.0002174827397335489,
        "gradient_norm": 0.4293825924396515,
        "train_loss": 3.055227756500244,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19573,
        "tokens": 10261889024,
        "learning_rate": 0.000217456700497715,
        "gradient_norm": 0.3688204288482666,
        "train_loss": 3.0489706993103027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19574,
        "tokens": 10262413312,
        "learning_rate": 0.00021743066252869606,
        "gradient_norm": 0.3667786717414856,
        "train_loss": 3.079418182373047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19575,
        "tokens": 10262937600,
        "learning_rate": 0.0002174046258267854,
        "gradient_norm": 0.357185959815979,
        "train_loss": 3.057011604309082,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19576,
        "tokens": 10263461888,
        "learning_rate": 0.00021737859039227612,
        "gradient_norm": 0.37133508920669556,
        "train_loss": 3.087686061859131,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19577,
        "tokens": 10263986176,
        "learning_rate": 0.00021735255622546106,
        "gradient_norm": 0.3401853144168854,
        "train_loss": 3.0795979499816895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19578,
        "tokens": 10264510464,
        "learning_rate": 0.0002173265233266335,
        "gradient_norm": 0.3638274371623993,
        "train_loss": 3.0342607498168945,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19579,
        "tokens": 10265034752,
        "learning_rate": 0.0002173004916960863,
        "gradient_norm": 0.3694882392883301,
        "train_loss": 3.0802016258239746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19580,
        "tokens": 10265559040,
        "learning_rate": 0.00021727446133411262,
        "gradient_norm": 0.3217816948890686,
        "train_loss": 3.0562944412231445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19581,
        "tokens": 10266083328,
        "learning_rate": 0.00021724843224100535,
        "gradient_norm": 0.41091907024383545,
        "train_loss": 3.0756309032440186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19582,
        "tokens": 10266607616,
        "learning_rate": 0.00021722240441705756,
        "gradient_norm": 0.369131475687027,
        "train_loss": 3.069985866546631,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19583,
        "tokens": 10267131904,
        "learning_rate": 0.0002171963778625621,
        "gradient_norm": 0.3874494731426239,
        "train_loss": 3.059983730316162,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19584,
        "tokens": 10267656192,
        "learning_rate": 0.00021717035257781214,
        "gradient_norm": 0.3405357003211975,
        "train_loss": 3.061007022857666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19585,
        "tokens": 10268180480,
        "learning_rate": 0.0002171443285631004,
        "gradient_norm": 0.33528241515159607,
        "train_loss": 3.0531232357025146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19586,
        "tokens": 10268704768,
        "learning_rate": 0.00021711830581871993,
        "gradient_norm": 0.3431144058704376,
        "train_loss": 3.0739102363586426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19587,
        "tokens": 10269229056,
        "learning_rate": 0.00021709228434496373,
        "gradient_norm": 0.3628726303577423,
        "train_loss": 3.0453672409057617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19588,
        "tokens": 10269753344,
        "learning_rate": 0.00021706626414212454,
        "gradient_norm": 0.3748117685317993,
        "train_loss": 3.06282901763916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19589,
        "tokens": 10270277632,
        "learning_rate": 0.00021704024521049538,
        "gradient_norm": 0.34367212653160095,
        "train_loss": 3.017190456390381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19590,
        "tokens": 10270801920,
        "learning_rate": 0.00021701422755036898,
        "gradient_norm": 0.3671259582042694,
        "train_loss": 3.111764907836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19591,
        "tokens": 10271326208,
        "learning_rate": 0.0002169882111620384,
        "gradient_norm": 0.3798155188560486,
        "train_loss": 3.0617332458496094,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19592,
        "tokens": 10271850496,
        "learning_rate": 0.00021696219604579628,
        "gradient_norm": 0.3347613215446472,
        "train_loss": 3.103982925415039,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19593,
        "tokens": 10272374784,
        "learning_rate": 0.0002169361822019356,
        "gradient_norm": 0.3517346680164337,
        "train_loss": 3.1107070446014404,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19594,
        "tokens": 10272899072,
        "learning_rate": 0.00021691016963074907,
        "gradient_norm": 0.33309102058410645,
        "train_loss": 3.019473075866699,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19595,
        "tokens": 10273423360,
        "learning_rate": 0.00021688415833252957,
        "gradient_norm": 0.3187512159347534,
        "train_loss": 3.0609242916107178,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19596,
        "tokens": 10273947648,
        "learning_rate": 0.00021685814830756995,
        "gradient_norm": 0.33099377155303955,
        "train_loss": 3.1111531257629395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19597,
        "tokens": 10274471936,
        "learning_rate": 0.00021683213955616282,
        "gradient_norm": 0.37071409821510315,
        "train_loss": 3.0324807167053223,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19598,
        "tokens": 10274996224,
        "learning_rate": 0.0002168061320786011,
        "gradient_norm": 0.3550885319709778,
        "train_loss": 3.012803077697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19599,
        "tokens": 10275520512,
        "learning_rate": 0.00021678012587517736,
        "gradient_norm": 0.33241555094718933,
        "train_loss": 3.1065573692321777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19600,
        "tokens": 10276044800,
        "learning_rate": 0.00021675412094618456,
        "gradient_norm": 0.3593306839466095,
        "train_loss": 3.0509438514709473,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19601,
        "tokens": 10276569088,
        "learning_rate": 0.00021672811729191518,
        "gradient_norm": 0.3575516939163208,
        "train_loss": 3.0445914268493652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19602,
        "tokens": 10277093376,
        "learning_rate": 0.00021670211491266214,
        "gradient_norm": 0.3352676331996918,
        "train_loss": 3.0937085151672363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19603,
        "tokens": 10277617664,
        "learning_rate": 0.00021667611380871794,
        "gradient_norm": 0.35677069425582886,
        "train_loss": 3.0724809169769287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19604,
        "tokens": 10278141952,
        "learning_rate": 0.00021665011398037538,
        "gradient_norm": 0.34162434935569763,
        "train_loss": 3.045198440551758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19605,
        "tokens": 10278666240,
        "learning_rate": 0.00021662411542792704,
        "gradient_norm": 0.37134745717048645,
        "train_loss": 3.0452213287353516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19606,
        "tokens": 10279190528,
        "learning_rate": 0.00021659811815166562,
        "gradient_norm": 0.3686831295490265,
        "train_loss": 3.13016676902771,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19607,
        "tokens": 10279714816,
        "learning_rate": 0.0002165721221518838,
        "gradient_norm": 0.42495670914649963,
        "train_loss": 3.075579881668091,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19608,
        "tokens": 10280239104,
        "learning_rate": 0.00021654612742887406,
        "gradient_norm": 0.37279027700424194,
        "train_loss": 3.0585360527038574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19609,
        "tokens": 10280763392,
        "learning_rate": 0.00021652013398292918,
        "gradient_norm": 0.46551820635795593,
        "train_loss": 3.0915257930755615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19610,
        "tokens": 10281287680,
        "learning_rate": 0.00021649414181434154,
        "gradient_norm": 0.38341769576072693,
        "train_loss": 3.0658047199249268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19611,
        "tokens": 10281811968,
        "learning_rate": 0.00021646815092340394,
        "gradient_norm": 0.3885166347026825,
        "train_loss": 3.0614259243011475,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19612,
        "tokens": 10282336256,
        "learning_rate": 0.00021644216131040867,
        "gradient_norm": 0.3686254322528839,
        "train_loss": 3.1759819984436035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19613,
        "tokens": 10282860544,
        "learning_rate": 0.00021641617297564857,
        "gradient_norm": 0.41464415192604065,
        "train_loss": 3.030938148498535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19614,
        "tokens": 10283384832,
        "learning_rate": 0.0002163901859194159,
        "gradient_norm": 0.3968750238418579,
        "train_loss": 3.049302816390991,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19615,
        "tokens": 10283909120,
        "learning_rate": 0.00021636420014200337,
        "gradient_norm": 0.38402867317199707,
        "train_loss": 3.0917110443115234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19616,
        "tokens": 10284433408,
        "learning_rate": 0.00021633821564370347,
        "gradient_norm": 0.35514914989471436,
        "train_loss": 3.076427459716797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19617,
        "tokens": 10284957696,
        "learning_rate": 0.0002163122324248085,
        "gradient_norm": 0.36838993430137634,
        "train_loss": 3.0316314697265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19618,
        "tokens": 10285481984,
        "learning_rate": 0.00021628625048561125,
        "gradient_norm": 0.3563048243522644,
        "train_loss": 3.0684080123901367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19619,
        "tokens": 10286006272,
        "learning_rate": 0.00021626026982640383,
        "gradient_norm": 0.47616976499557495,
        "train_loss": 3.140069007873535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19620,
        "tokens": 10286530560,
        "learning_rate": 0.000216234290447479,
        "gradient_norm": 0.3825839161872864,
        "train_loss": 3.0202770233154297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19621,
        "tokens": 10287054848,
        "learning_rate": 0.00021620831234912892,
        "gradient_norm": 0.4529602825641632,
        "train_loss": 3.12764835357666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19622,
        "tokens": 10287579136,
        "learning_rate": 0.00021618233553164626,
        "gradient_norm": 0.47918373346328735,
        "train_loss": 3.032815933227539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19623,
        "tokens": 10288103424,
        "learning_rate": 0.00021615635999532314,
        "gradient_norm": 0.4013892114162445,
        "train_loss": 3.0714309215545654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19624,
        "tokens": 10288627712,
        "learning_rate": 0.00021613038574045225,
        "gradient_norm": 0.45343294739723206,
        "train_loss": 3.1140482425689697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19625,
        "tokens": 10289152000,
        "learning_rate": 0.00021610441276732567,
        "gradient_norm": 0.46570807695388794,
        "train_loss": 3.048394203186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19626,
        "tokens": 10289676288,
        "learning_rate": 0.00021607844107623595,
        "gradient_norm": 0.48496612906455994,
        "train_loss": 3.1600351333618164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19627,
        "tokens": 10290200576,
        "learning_rate": 0.00021605247066747545,
        "gradient_norm": 0.4262526035308838,
        "train_loss": 3.0620577335357666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19628,
        "tokens": 10290724864,
        "learning_rate": 0.00021602650154133632,
        "gradient_norm": 0.4053066670894623,
        "train_loss": 3.1465673446655273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19629,
        "tokens": 10291249152,
        "learning_rate": 0.0002160005336981111,
        "gradient_norm": 0.44431072473526,
        "train_loss": 3.0445809364318848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19630,
        "tokens": 10291773440,
        "learning_rate": 0.00021597456713809185,
        "gradient_norm": 0.3787325322628021,
        "train_loss": 3.0864555835723877,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19631,
        "tokens": 10292297728,
        "learning_rate": 0.00021594860186157112,
        "gradient_norm": 0.4273996651172638,
        "train_loss": 3.1150736808776855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19632,
        "tokens": 10292822016,
        "learning_rate": 0.00021592263786884096,
        "gradient_norm": 0.4268328547477722,
        "train_loss": 3.0860440731048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19633,
        "tokens": 10293346304,
        "learning_rate": 0.00021589667516019374,
        "gradient_norm": 0.5049390196800232,
        "train_loss": 3.1735308170318604,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19634,
        "tokens": 10293870592,
        "learning_rate": 0.00021587071373592163,
        "gradient_norm": 0.42456474900245667,
        "train_loss": 3.0248825550079346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19635,
        "tokens": 10294394880,
        "learning_rate": 0.00021584475359631692,
        "gradient_norm": 0.4253670573234558,
        "train_loss": 3.1023082733154297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19636,
        "tokens": 10294919168,
        "learning_rate": 0.00021581879474167186,
        "gradient_norm": 0.4192952513694763,
        "train_loss": 3.053795576095581,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19637,
        "tokens": 10295443456,
        "learning_rate": 0.00021579283717227852,
        "gradient_norm": 0.3896031379699707,
        "train_loss": 3.052062511444092,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19638,
        "tokens": 10295967744,
        "learning_rate": 0.00021576688088842925,
        "gradient_norm": 0.383253276348114,
        "train_loss": 3.0765891075134277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19639,
        "tokens": 10296492032,
        "learning_rate": 0.00021574092589041603,
        "gradient_norm": 0.3698490858078003,
        "train_loss": 3.074000358581543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19640,
        "tokens": 10297016320,
        "learning_rate": 0.00021571497217853122,
        "gradient_norm": 0.3588266372680664,
        "train_loss": 3.1105611324310303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19641,
        "tokens": 10297540608,
        "learning_rate": 0.00021568901975306675,
        "gradient_norm": 0.38798338174819946,
        "train_loss": 3.0279502868652344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19642,
        "tokens": 10298064896,
        "learning_rate": 0.000215663068614315,
        "gradient_norm": 0.3390350043773651,
        "train_loss": 3.0581295490264893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19643,
        "tokens": 10298589184,
        "learning_rate": 0.00021563711876256778,
        "gradient_norm": 0.3679232895374298,
        "train_loss": 3.094376564025879,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19644,
        "tokens": 10299113472,
        "learning_rate": 0.00021561117019811747,
        "gradient_norm": 0.3899324834346771,
        "train_loss": 3.1152312755584717,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19645,
        "tokens": 10299637760,
        "learning_rate": 0.00021558522292125593,
        "gradient_norm": 0.3551417589187622,
        "train_loss": 3.010746955871582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19646,
        "tokens": 10300162048,
        "learning_rate": 0.0002155592769322753,
        "gradient_norm": 0.39174601435661316,
        "train_loss": 3.1094930171966553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19647,
        "tokens": 10300686336,
        "learning_rate": 0.00021553333223146783,
        "gradient_norm": 0.3626243770122528,
        "train_loss": 2.998548746109009,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19648,
        "tokens": 10301210624,
        "learning_rate": 0.00021550738881912523,
        "gradient_norm": 0.3499249517917633,
        "train_loss": 3.0600881576538086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19649,
        "tokens": 10301734912,
        "learning_rate": 0.0002154814466955398,
        "gradient_norm": 0.3343212902545929,
        "train_loss": 3.0444798469543457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19650,
        "tokens": 10302259200,
        "learning_rate": 0.00021545550586100334,
        "gradient_norm": 0.35289305448532104,
        "train_loss": 3.079627752304077,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19651,
        "tokens": 10302783488,
        "learning_rate": 0.00021542956631580805,
        "gradient_norm": 0.34435155987739563,
        "train_loss": 3.0639028549194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19652,
        "tokens": 10303307776,
        "learning_rate": 0.00021540362806024574,
        "gradient_norm": 0.33663907647132874,
        "train_loss": 3.0493979454040527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19653,
        "tokens": 10303832064,
        "learning_rate": 0.0002153776910946085,
        "gradient_norm": 0.3578505516052246,
        "train_loss": 3.089735984802246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19654,
        "tokens": 10304356352,
        "learning_rate": 0.00021535175541918816,
        "gradient_norm": 0.3546982407569885,
        "train_loss": 3.0267112255096436,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19655,
        "tokens": 10304880640,
        "learning_rate": 0.0002153258210342767,
        "gradient_norm": 0.345643013715744,
        "train_loss": 3.057732105255127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19656,
        "tokens": 10305404928,
        "learning_rate": 0.00021529988794016615,
        "gradient_norm": 0.335335910320282,
        "train_loss": 3.0772223472595215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19657,
        "tokens": 10305929216,
        "learning_rate": 0.00021527395613714828,
        "gradient_norm": 0.33782535791397095,
        "train_loss": 3.0191874504089355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19658,
        "tokens": 10306453504,
        "learning_rate": 0.00021524802562551513,
        "gradient_norm": 0.3167567849159241,
        "train_loss": 3.018571615219116,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19659,
        "tokens": 10306977792,
        "learning_rate": 0.0002152220964055584,
        "gradient_norm": 0.3121873140335083,
        "train_loss": 3.080693483352661,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19660,
        "tokens": 10307502080,
        "learning_rate": 0.00021519616847757013,
        "gradient_norm": 0.35862094163894653,
        "train_loss": 3.040764093399048,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19661,
        "tokens": 10308026368,
        "learning_rate": 0.00021517024184184198,
        "gradient_norm": 0.3072669208049774,
        "train_loss": 3.043246269226074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19662,
        "tokens": 10308550656,
        "learning_rate": 0.00021514431649866605,
        "gradient_norm": 0.38648101687431335,
        "train_loss": 3.1887834072113037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19663,
        "tokens": 10309074944,
        "learning_rate": 0.00021511839244833385,
        "gradient_norm": 0.3723226487636566,
        "train_loss": 3.068331241607666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19664,
        "tokens": 10309599232,
        "learning_rate": 0.00021509246969113747,
        "gradient_norm": 0.43628737330436707,
        "train_loss": 3.0474209785461426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19665,
        "tokens": 10310123520,
        "learning_rate": 0.0002150665482273685,
        "gradient_norm": 0.3537112772464752,
        "train_loss": 3.029125213623047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19666,
        "tokens": 10310647808,
        "learning_rate": 0.00021504062805731888,
        "gradient_norm": 0.36065149307250977,
        "train_loss": 3.035222053527832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19667,
        "tokens": 10311172096,
        "learning_rate": 0.00021501470918128016,
        "gradient_norm": 0.3442822992801666,
        "train_loss": 3.053131341934204,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19668,
        "tokens": 10311696384,
        "learning_rate": 0.00021498879159954437,
        "gradient_norm": 0.33495691418647766,
        "train_loss": 3.0817699432373047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19669,
        "tokens": 10312220672,
        "learning_rate": 0.00021496287531240298,
        "gradient_norm": 0.39206787943840027,
        "train_loss": 3.033137083053589,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19670,
        "tokens": 10312744960,
        "learning_rate": 0.00021493696032014794,
        "gradient_norm": 0.3103586435317993,
        "train_loss": 3.0415639877319336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19671,
        "tokens": 10313269248,
        "learning_rate": 0.00021491104662307072,
        "gradient_norm": 0.3665805160999298,
        "train_loss": 3.0321662425994873,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19672,
        "tokens": 10313793536,
        "learning_rate": 0.00021488513422146326,
        "gradient_norm": 0.32017719745635986,
        "train_loss": 3.0066418647766113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19673,
        "tokens": 10314317824,
        "learning_rate": 0.000214859223115617,
        "gradient_norm": 0.3773067891597748,
        "train_loss": 3.0736680030822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19674,
        "tokens": 10314842112,
        "learning_rate": 0.00021483331330582377,
        "gradient_norm": 0.34915193915367126,
        "train_loss": 3.061899185180664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19675,
        "tokens": 10315366400,
        "learning_rate": 0.0002148074047923751,
        "gradient_norm": 0.36388084292411804,
        "train_loss": 3.0254855155944824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19676,
        "tokens": 10315890688,
        "learning_rate": 0.00021478149757556275,
        "gradient_norm": 0.34845519065856934,
        "train_loss": 3.033600330352783,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19677,
        "tokens": 10316414976,
        "learning_rate": 0.00021475559165567819,
        "gradient_norm": 0.35447660088539124,
        "train_loss": 3.065264940261841,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19678,
        "tokens": 10316939264,
        "learning_rate": 0.00021472968703301323,
        "gradient_norm": 0.3634510040283203,
        "train_loss": 3.077674150466919,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19679,
        "tokens": 10317463552,
        "learning_rate": 0.00021470378370785917,
        "gradient_norm": 0.3453119993209839,
        "train_loss": 3.061183452606201,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19680,
        "tokens": 10317987840,
        "learning_rate": 0.00021467788168050788,
        "gradient_norm": 0.43188679218292236,
        "train_loss": 3.176791191101074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19681,
        "tokens": 10318512128,
        "learning_rate": 0.00021465198095125068,
        "gradient_norm": 0.39162999391555786,
        "train_loss": 3.07041597366333,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19682,
        "tokens": 10319036416,
        "learning_rate": 0.0002146260815203793,
        "gradient_norm": 0.340625137090683,
        "train_loss": 3.062671184539795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19683,
        "tokens": 10319560704,
        "learning_rate": 0.0002146001833881851,
        "gradient_norm": 0.3457881510257721,
        "train_loss": 3.0848886966705322,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19684,
        "tokens": 10320084992,
        "learning_rate": 0.0002145742865549598,
        "gradient_norm": 0.3657052516937256,
        "train_loss": 3.0268659591674805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19685,
        "tokens": 10320609280,
        "learning_rate": 0.00021454839102099467,
        "gradient_norm": 0.3224833607673645,
        "train_loss": 2.975325584411621,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19686,
        "tokens": 10321133568,
        "learning_rate": 0.0002145224967865813,
        "gradient_norm": 0.379269540309906,
        "train_loss": 3.0491786003112793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19687,
        "tokens": 10321657856,
        "learning_rate": 0.00021449660385201134,
        "gradient_norm": 0.3281981945037842,
        "train_loss": 3.039280891418457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19688,
        "tokens": 10322182144,
        "learning_rate": 0.00021447071221757593,
        "gradient_norm": 0.36216750741004944,
        "train_loss": 3.0725996494293213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19689,
        "tokens": 10322706432,
        "learning_rate": 0.0002144448218835668,
        "gradient_norm": 0.35040736198425293,
        "train_loss": 3.1513752937316895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19690,
        "tokens": 10323230720,
        "learning_rate": 0.0002144189328502751,
        "gradient_norm": 0.3909429907798767,
        "train_loss": 3.1213016510009766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19691,
        "tokens": 10323755008,
        "learning_rate": 0.0002143930451179925,
        "gradient_norm": 0.3400033116340637,
        "train_loss": 3.0575459003448486,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19692,
        "tokens": 10324279296,
        "learning_rate": 0.00021436715868701018,
        "gradient_norm": 0.3845345377922058,
        "train_loss": 3.063542604446411,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19693,
        "tokens": 10324803584,
        "learning_rate": 0.00021434127355761975,
        "gradient_norm": 0.33265164494514465,
        "train_loss": 3.0596399307250977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19694,
        "tokens": 10325327872,
        "learning_rate": 0.00021431538973011236,
        "gradient_norm": 0.34846368432044983,
        "train_loss": 3.055482864379883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19695,
        "tokens": 10325852160,
        "learning_rate": 0.00021428950720477942,
        "gradient_norm": 0.3489623963832855,
        "train_loss": 3.0877459049224854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19696,
        "tokens": 10326376448,
        "learning_rate": 0.00021426362598191246,
        "gradient_norm": 0.33349886536598206,
        "train_loss": 3.0783939361572266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19697,
        "tokens": 10326900736,
        "learning_rate": 0.00021423774606180252,
        "gradient_norm": 0.33939313888549805,
        "train_loss": 3.0535364151000977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19698,
        "tokens": 10327425024,
        "learning_rate": 0.00021421186744474119,
        "gradient_norm": 0.3792433440685272,
        "train_loss": 3.0855963230133057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19699,
        "tokens": 10327949312,
        "learning_rate": 0.0002141859901310195,
        "gradient_norm": 0.38676759600639343,
        "train_loss": 3.1142196655273438,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19700,
        "tokens": 10328473600,
        "learning_rate": 0.00021416011412092896,
        "gradient_norm": 0.38726502656936646,
        "train_loss": 3.0887832641601562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19701,
        "tokens": 10328997888,
        "learning_rate": 0.00021413423941476066,
        "gradient_norm": 0.36179274320602417,
        "train_loss": 3.0500102043151855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19702,
        "tokens": 10329522176,
        "learning_rate": 0.00021410836601280596,
        "gradient_norm": 0.373592734336853,
        "train_loss": 3.0356860160827637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19703,
        "tokens": 10330046464,
        "learning_rate": 0.00021408249391535603,
        "gradient_norm": 0.3639802634716034,
        "train_loss": 3.0007572174072266,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19704,
        "tokens": 10330570752,
        "learning_rate": 0.0002140566231227022,
        "gradient_norm": 0.3834437131881714,
        "train_loss": 3.069096803665161,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19705,
        "tokens": 10331095040,
        "learning_rate": 0.00021403075363513553,
        "gradient_norm": 0.38449642062187195,
        "train_loss": 3.0803918838500977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19706,
        "tokens": 10331619328,
        "learning_rate": 0.00021400488545294724,
        "gradient_norm": 0.331738144159317,
        "train_loss": 3.0668206214904785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19707,
        "tokens": 10332143616,
        "learning_rate": 0.0002139790185764287,
        "gradient_norm": 0.3315257132053375,
        "train_loss": 3.07655668258667,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19708,
        "tokens": 10332667904,
        "learning_rate": 0.0002139531530058708,
        "gradient_norm": 0.3288407623767853,
        "train_loss": 3.1114821434020996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19709,
        "tokens": 10333192192,
        "learning_rate": 0.00021392728874156493,
        "gradient_norm": 0.33972179889678955,
        "train_loss": 3.033247947692871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19710,
        "tokens": 10333716480,
        "learning_rate": 0.000213901425783802,
        "gradient_norm": 0.3389926552772522,
        "train_loss": 3.1028265953063965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19711,
        "tokens": 10334240768,
        "learning_rate": 0.00021387556413287334,
        "gradient_norm": 0.3386576771736145,
        "train_loss": 3.035341262817383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19712,
        "tokens": 10334765056,
        "learning_rate": 0.0002138497037890699,
        "gradient_norm": 0.35944563150405884,
        "train_loss": 3.066091537475586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19713,
        "tokens": 10335289344,
        "learning_rate": 0.00021382384475268293,
        "gradient_norm": 0.3688124716281891,
        "train_loss": 3.024099349975586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19714,
        "tokens": 10335813632,
        "learning_rate": 0.00021379798702400325,
        "gradient_norm": 0.33391866087913513,
        "train_loss": 3.0343031883239746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19715,
        "tokens": 10336337920,
        "learning_rate": 0.00021377213060332212,
        "gradient_norm": 0.4062696695327759,
        "train_loss": 3.030059814453125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19716,
        "tokens": 10336862208,
        "learning_rate": 0.00021374627549093061,
        "gradient_norm": 0.39190730452537537,
        "train_loss": 3.058255910873413,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19717,
        "tokens": 10337386496,
        "learning_rate": 0.0002137204216871196,
        "gradient_norm": 0.37445464730262756,
        "train_loss": 3.0395772457122803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19718,
        "tokens": 10337910784,
        "learning_rate": 0.0002136945691921803,
        "gradient_norm": 0.3551706075668335,
        "train_loss": 3.0876569747924805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19719,
        "tokens": 10338435072,
        "learning_rate": 0.0002136687180064035,
        "gradient_norm": 0.3848712742328644,
        "train_loss": 2.9674086570739746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19720,
        "tokens": 10338959360,
        "learning_rate": 0.00021364286813008038,
        "gradient_norm": 0.33468034863471985,
        "train_loss": 3.0780627727508545,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19721,
        "tokens": 10339483648,
        "learning_rate": 0.00021361701956350174,
        "gradient_norm": 0.33663058280944824,
        "train_loss": 3.063645362854004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19722,
        "tokens": 10340007936,
        "learning_rate": 0.00021359117230695867,
        "gradient_norm": 0.3837180435657501,
        "train_loss": 3.0893280506134033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19723,
        "tokens": 10340532224,
        "learning_rate": 0.00021356532636074199,
        "gradient_norm": 0.3562794327735901,
        "train_loss": 3.0461206436157227,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19724,
        "tokens": 10341056512,
        "learning_rate": 0.00021353948172514282,
        "gradient_norm": 0.3561042845249176,
        "train_loss": 3.0541958808898926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19725,
        "tokens": 10341580800,
        "learning_rate": 0.00021351363840045183,
        "gradient_norm": 0.3474085032939911,
        "train_loss": 3.0447444915771484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19726,
        "tokens": 10342105088,
        "learning_rate": 0.00021348779638696006,
        "gradient_norm": 0.3618547022342682,
        "train_loss": 3.0460028648376465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19727,
        "tokens": 10342629376,
        "learning_rate": 0.0002134619556849585,
        "gradient_norm": 0.37016168236732483,
        "train_loss": 3.081477165222168,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19728,
        "tokens": 10343153664,
        "learning_rate": 0.00021343611629473774,
        "gradient_norm": 0.4501255452632904,
        "train_loss": 3.1404659748077393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19729,
        "tokens": 10343677952,
        "learning_rate": 0.0002134102782165889,
        "gradient_norm": 0.36981067061424255,
        "train_loss": 3.0929017066955566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19730,
        "tokens": 10344202240,
        "learning_rate": 0.00021338444145080267,
        "gradient_norm": 0.3903898596763611,
        "train_loss": 3.0142736434936523,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19731,
        "tokens": 10344726528,
        "learning_rate": 0.00021335860599766999,
        "gradient_norm": 0.334648996591568,
        "train_loss": 3.0687828063964844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19732,
        "tokens": 10345250816,
        "learning_rate": 0.00021333277185748146,
        "gradient_norm": 0.4096159040927887,
        "train_loss": 3.0229074954986572,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19733,
        "tokens": 10345775104,
        "learning_rate": 0.00021330693903052816,
        "gradient_norm": 0.379422664642334,
        "train_loss": 3.1045918464660645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19734,
        "tokens": 10346299392,
        "learning_rate": 0.00021328110751710062,
        "gradient_norm": 0.34767892956733704,
        "train_loss": 3.0617780685424805,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19735,
        "tokens": 10346823680,
        "learning_rate": 0.0002132552773174897,
        "gradient_norm": 0.4433031976222992,
        "train_loss": 3.093845844268799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19736,
        "tokens": 10347347968,
        "learning_rate": 0.00021322944843198623,
        "gradient_norm": 0.33012160658836365,
        "train_loss": 3.060621738433838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19737,
        "tokens": 10347872256,
        "learning_rate": 0.00021320362086088077,
        "gradient_norm": 0.3640398383140564,
        "train_loss": 3.038038492202759,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19738,
        "tokens": 10348396544,
        "learning_rate": 0.00021317779460446428,
        "gradient_norm": 0.32517310976982117,
        "train_loss": 3.0360894203186035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19739,
        "tokens": 10348920832,
        "learning_rate": 0.00021315196966302725,
        "gradient_norm": 0.35839858651161194,
        "train_loss": 3.080796718597412,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19740,
        "tokens": 10349445120,
        "learning_rate": 0.00021312614603686053,
        "gradient_norm": 0.3533896207809448,
        "train_loss": 3.0585992336273193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19741,
        "tokens": 10349969408,
        "learning_rate": 0.00021310032372625465,
        "gradient_norm": 0.3256903290748596,
        "train_loss": 3.0700106620788574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19742,
        "tokens": 10350493696,
        "learning_rate": 0.00021307450273150044,
        "gradient_norm": 0.3725150227546692,
        "train_loss": 3.092526912689209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19743,
        "tokens": 10351017984,
        "learning_rate": 0.00021304868305288834,
        "gradient_norm": 0.36788931488990784,
        "train_loss": 3.062354564666748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19744,
        "tokens": 10351542272,
        "learning_rate": 0.0002130228646907092,
        "gradient_norm": 0.3735169768333435,
        "train_loss": 3.0667295455932617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19745,
        "tokens": 10352066560,
        "learning_rate": 0.00021299704764525342,
        "gradient_norm": 0.32567283511161804,
        "train_loss": 3.0632224082946777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19746,
        "tokens": 10352590848,
        "learning_rate": 0.00021297123191681171,
        "gradient_norm": 0.3435477018356323,
        "train_loss": 3.0594067573547363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19747,
        "tokens": 10353115136,
        "learning_rate": 0.00021294541750567478,
        "gradient_norm": 0.36080726981163025,
        "train_loss": 3.0773019790649414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19748,
        "tokens": 10353639424,
        "learning_rate": 0.00021291960441213303,
        "gradient_norm": 0.3873114287853241,
        "train_loss": 3.0078132152557373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19749,
        "tokens": 10354163712,
        "learning_rate": 0.0002128937926364771,
        "gradient_norm": 0.3738466501235962,
        "train_loss": 3.0636096000671387,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19750,
        "tokens": 10354688000,
        "learning_rate": 0.00021286798217899744,
        "gradient_norm": 0.42813271284103394,
        "train_loss": 3.093432903289795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19751,
        "tokens": 10355212288,
        "learning_rate": 0.00021284217303998477,
        "gradient_norm": 0.39628148078918457,
        "train_loss": 3.06052303314209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19752,
        "tokens": 10355736576,
        "learning_rate": 0.00021281636521972935,
        "gradient_norm": 0.4020683169364929,
        "train_loss": 3.0600738525390625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19753,
        "tokens": 10356260864,
        "learning_rate": 0.00021279055871852197,
        "gradient_norm": 0.3814682364463806,
        "train_loss": 3.1053524017333984,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19754,
        "tokens": 10356785152,
        "learning_rate": 0.00021276475353665278,
        "gradient_norm": 0.42218175530433655,
        "train_loss": 3.1364669799804688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19755,
        "tokens": 10357309440,
        "learning_rate": 0.00021273894967441248,
        "gradient_norm": 0.3818250000476837,
        "train_loss": 3.014610767364502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19756,
        "tokens": 10357833728,
        "learning_rate": 0.00021271314713209154,
        "gradient_norm": 0.422985315322876,
        "train_loss": 3.074833631515503,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19757,
        "tokens": 10358358016,
        "learning_rate": 0.00021268734590998024,
        "gradient_norm": 0.4311399459838867,
        "train_loss": 3.001608371734619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19758,
        "tokens": 10358882304,
        "learning_rate": 0.00021266154600836924,
        "gradient_norm": 0.3963668644428253,
        "train_loss": 3.0838677883148193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19759,
        "tokens": 10359406592,
        "learning_rate": 0.00021263574742754867,
        "gradient_norm": 0.34905320405960083,
        "train_loss": 3.043210506439209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19760,
        "tokens": 10359930880,
        "learning_rate": 0.00021260995016780918,
        "gradient_norm": 0.3600867986679077,
        "train_loss": 3.089263916015625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19761,
        "tokens": 10360455168,
        "learning_rate": 0.00021258415422944086,
        "gradient_norm": 0.36963218450546265,
        "train_loss": 3.0246100425720215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19762,
        "tokens": 10360979456,
        "learning_rate": 0.00021255835961273443,
        "gradient_norm": 0.37281906604766846,
        "train_loss": 3.044414520263672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19763,
        "tokens": 10361503744,
        "learning_rate": 0.0002125325663179799,
        "gradient_norm": 0.3810194730758667,
        "train_loss": 3.1272284984588623,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19764,
        "tokens": 10362028032,
        "learning_rate": 0.00021250677434546793,
        "gradient_norm": 0.3737187087535858,
        "train_loss": 3.0868911743164062,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19765,
        "tokens": 10362552320,
        "learning_rate": 0.0002124809836954885,
        "gradient_norm": 0.3527149260044098,
        "train_loss": 3.0693366527557373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19766,
        "tokens": 10363076608,
        "learning_rate": 0.00021245519436833226,
        "gradient_norm": 0.3490486145019531,
        "train_loss": 3.076531410217285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19767,
        "tokens": 10363600896,
        "learning_rate": 0.0002124294063642892,
        "gradient_norm": 0.3543156087398529,
        "train_loss": 2.999330520629883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19768,
        "tokens": 10364125184,
        "learning_rate": 0.00021240361968364978,
        "gradient_norm": 0.3280751407146454,
        "train_loss": 3.0398478507995605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19769,
        "tokens": 10364649472,
        "learning_rate": 0.0002123778343267042,
        "gradient_norm": 0.35285118222236633,
        "train_loss": 3.060333251953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19770,
        "tokens": 10365173760,
        "learning_rate": 0.00021235205029374274,
        "gradient_norm": 0.3268531262874603,
        "train_loss": 3.011026620864868,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19771,
        "tokens": 10365698048,
        "learning_rate": 0.00021232626758505553,
        "gradient_norm": 0.3426834046840668,
        "train_loss": 3.0807912349700928,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19772,
        "tokens": 10366222336,
        "learning_rate": 0.00021230048620093296,
        "gradient_norm": 0.35137584805488586,
        "train_loss": 3.1003570556640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19773,
        "tokens": 10366746624,
        "learning_rate": 0.00021227470614166503,
        "gradient_norm": 0.3738415837287903,
        "train_loss": 3.0605533123016357,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19774,
        "tokens": 10367270912,
        "learning_rate": 0.00021224892740754215,
        "gradient_norm": 0.4050499498844147,
        "train_loss": 3.0524449348449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19775,
        "tokens": 10367795200,
        "learning_rate": 0.00021222314999885426,
        "gradient_norm": 0.389607310295105,
        "train_loss": 3.087860107421875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19776,
        "tokens": 10368319488,
        "learning_rate": 0.0002121973739158917,
        "gradient_norm": 0.37039798498153687,
        "train_loss": 3.084672689437866,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19777,
        "tokens": 10368843776,
        "learning_rate": 0.0002121715991589445,
        "gradient_norm": 0.3939429819583893,
        "train_loss": 3.047849655151367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19778,
        "tokens": 10369368064,
        "learning_rate": 0.0002121458257283029,
        "gradient_norm": 0.3772520422935486,
        "train_loss": 3.0602030754089355,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19779,
        "tokens": 10369892352,
        "learning_rate": 0.00021212005362425686,
        "gradient_norm": 0.37369275093078613,
        "train_loss": 3.0601887702941895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19780,
        "tokens": 10370416640,
        "learning_rate": 0.00021209428284709662,
        "gradient_norm": 0.40334853529930115,
        "train_loss": 3.090945243835449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19781,
        "tokens": 10370940928,
        "learning_rate": 0.0002120685133971121,
        "gradient_norm": 0.37158188223838806,
        "train_loss": 3.075336456298828,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19782,
        "tokens": 10371465216,
        "learning_rate": 0.0002120427452745935,
        "gradient_norm": 0.35452958941459656,
        "train_loss": 3.0847132205963135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19783,
        "tokens": 10371989504,
        "learning_rate": 0.00021201697847983092,
        "gradient_norm": 0.38158050179481506,
        "train_loss": 3.04494571685791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19784,
        "tokens": 10372513792,
        "learning_rate": 0.00021199121301311422,
        "gradient_norm": 0.3694806396961212,
        "train_loss": 3.0610570907592773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19785,
        "tokens": 10373038080,
        "learning_rate": 0.00021196544887473363,
        "gradient_norm": 0.3623523414134979,
        "train_loss": 3.0646958351135254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19786,
        "tokens": 10373562368,
        "learning_rate": 0.0002119396860649789,
        "gradient_norm": 0.3631397783756256,
        "train_loss": 3.0556883811950684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19787,
        "tokens": 10374086656,
        "learning_rate": 0.00021191392458414033,
        "gradient_norm": 0.40877681970596313,
        "train_loss": 3.087709903717041,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19788,
        "tokens": 10374610944,
        "learning_rate": 0.0002118881644325076,
        "gradient_norm": 0.36043912172317505,
        "train_loss": 3.060377597808838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19789,
        "tokens": 10375135232,
        "learning_rate": 0.00021186240561037095,
        "gradient_norm": 0.45335134863853455,
        "train_loss": 3.1371610164642334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19790,
        "tokens": 10375659520,
        "learning_rate": 0.00021183664811802005,
        "gradient_norm": 0.4049668312072754,
        "train_loss": 3.0762298107147217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19791,
        "tokens": 10376183808,
        "learning_rate": 0.00021181089195574507,
        "gradient_norm": 0.37169674038887024,
        "train_loss": 3.0681777000427246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19792,
        "tokens": 10376708096,
        "learning_rate": 0.00021178513712383573,
        "gradient_norm": 0.4076027274131775,
        "train_loss": 3.078491449356079,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19793,
        "tokens": 10377232384,
        "learning_rate": 0.00021175938362258214,
        "gradient_norm": 0.33056607842445374,
        "train_loss": 3.1032729148864746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19794,
        "tokens": 10377756672,
        "learning_rate": 0.00021173363145227401,
        "gradient_norm": 0.42766356468200684,
        "train_loss": 3.0588908195495605,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19795,
        "tokens": 10378280960,
        "learning_rate": 0.00021170788061320123,
        "gradient_norm": 0.3738912045955658,
        "train_loss": 3.0688343048095703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19796,
        "tokens": 10378805248,
        "learning_rate": 0.00021168213110565382,
        "gradient_norm": 0.37550288438796997,
        "train_loss": 3.087468147277832,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19797,
        "tokens": 10379329536,
        "learning_rate": 0.0002116563829299214,
        "gradient_norm": 0.3864436149597168,
        "train_loss": 3.082427501678467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19798,
        "tokens": 10379853824,
        "learning_rate": 0.00021163063608629405,
        "gradient_norm": 0.38247430324554443,
        "train_loss": 3.1011109352111816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19799,
        "tokens": 10380378112,
        "learning_rate": 0.00021160489057506132,
        "gradient_norm": 0.36711612343788147,
        "train_loss": 3.049226760864258,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19800,
        "tokens": 10380902400,
        "learning_rate": 0.00021157914639651323,
        "gradient_norm": 0.3868016302585602,
        "train_loss": 3.099231243133545,
        "val_loss": 3.02343487739563,
        "hellaswag_acc": 0.2841067612171173,
        "hellaswag_acc_norm": 0.2966540455818176
    },
    {
        "step": 19801,
        "tokens": 10381426688,
        "learning_rate": 0.00021155340355093934,
        "gradient_norm": 0.33892661333084106,
        "train_loss": 3.013491630554199,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19802,
        "tokens": 10381950976,
        "learning_rate": 0.00021152766203862968,
        "gradient_norm": 0.36081641912460327,
        "train_loss": 3.0691819190979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19803,
        "tokens": 10382475264,
        "learning_rate": 0.00021150192185987374,
        "gradient_norm": 0.362215518951416,
        "train_loss": 3.115703582763672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19804,
        "tokens": 10382999552,
        "learning_rate": 0.00021147618301496147,
        "gradient_norm": 0.4183829128742218,
        "train_loss": 3.0519542694091797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19805,
        "tokens": 10383523840,
        "learning_rate": 0.00021145044550418242,
        "gradient_norm": 0.3598170578479767,
        "train_loss": 3.0585739612579346,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19806,
        "tokens": 10384048128,
        "learning_rate": 0.0002114247093278264,
        "gradient_norm": 0.40804263949394226,
        "train_loss": 3.08829402923584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19807,
        "tokens": 10384572416,
        "learning_rate": 0.00021139897448618316,
        "gradient_norm": 0.395575612783432,
        "train_loss": 3.1035594940185547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19808,
        "tokens": 10385096704,
        "learning_rate": 0.00021137324097954223,
        "gradient_norm": 0.3861888647079468,
        "train_loss": 3.048764228820801,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19809,
        "tokens": 10385620992,
        "learning_rate": 0.0002113475088081934,
        "gradient_norm": 0.36419999599456787,
        "train_loss": 3.054692268371582,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19810,
        "tokens": 10386145280,
        "learning_rate": 0.00021132177797242616,
        "gradient_norm": 0.34370413422584534,
        "train_loss": 3.0255956649780273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19811,
        "tokens": 10386669568,
        "learning_rate": 0.0002112960484725304,
        "gradient_norm": 0.37383994460105896,
        "train_loss": 3.043720245361328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19812,
        "tokens": 10387193856,
        "learning_rate": 0.00021127032030879547,
        "gradient_norm": 0.35857200622558594,
        "train_loss": 3.0242526531219482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19813,
        "tokens": 10387718144,
        "learning_rate": 0.0002112445934815112,
        "gradient_norm": 0.31163290143013,
        "train_loss": 3.0310521125793457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19814,
        "tokens": 10388242432,
        "learning_rate": 0.00021121886799096689,
        "gradient_norm": 0.3517923057079315,
        "train_loss": 3.0290133953094482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19815,
        "tokens": 10388766720,
        "learning_rate": 0.00021119314383745232,
        "gradient_norm": 0.35661324858665466,
        "train_loss": 3.0365939140319824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19816,
        "tokens": 10389291008,
        "learning_rate": 0.00021116742102125714,
        "gradient_norm": 0.34229984879493713,
        "train_loss": 2.9896140098571777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19817,
        "tokens": 10389815296,
        "learning_rate": 0.00021114169954267065,
        "gradient_norm": 0.3517824113368988,
        "train_loss": 3.0372118949890137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19818,
        "tokens": 10390339584,
        "learning_rate": 0.00021111597940198256,
        "gradient_norm": 0.38439252972602844,
        "train_loss": 3.0523695945739746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19819,
        "tokens": 10390863872,
        "learning_rate": 0.00021109026059948227,
        "gradient_norm": 0.4261191785335541,
        "train_loss": 3.010197639465332,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19820,
        "tokens": 10391388160,
        "learning_rate": 0.0002110645431354594,
        "gradient_norm": 0.36532238125801086,
        "train_loss": 3.035804510116577,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19821,
        "tokens": 10391912448,
        "learning_rate": 0.00021103882701020322,
        "gradient_norm": 0.3430560529232025,
        "train_loss": 2.999967098236084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19822,
        "tokens": 10392436736,
        "learning_rate": 0.0002110131122240035,
        "gradient_norm": 0.3433595597743988,
        "train_loss": 3.0301122665405273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19823,
        "tokens": 10392961024,
        "learning_rate": 0.00021098739877714937,
        "gradient_norm": 0.36344829201698303,
        "train_loss": 2.9892778396606445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19824,
        "tokens": 10393485312,
        "learning_rate": 0.00021096168666993054,
        "gradient_norm": 0.35195448994636536,
        "train_loss": 2.9700260162353516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19825,
        "tokens": 10394009600,
        "learning_rate": 0.0002109359759026362,
        "gradient_norm": 0.40630042552948,
        "train_loss": 3.037606716156006,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19826,
        "tokens": 10394533888,
        "learning_rate": 0.00021091026647555587,
        "gradient_norm": 0.3775840103626251,
        "train_loss": 3.0072622299194336,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19827,
        "tokens": 10395058176,
        "learning_rate": 0.00021088455838897904,
        "gradient_norm": 0.37328997254371643,
        "train_loss": 2.9943675994873047,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19828,
        "tokens": 10395582464,
        "learning_rate": 0.0002108588516431949,
        "gradient_norm": 0.36104512214660645,
        "train_loss": 3.0137133598327637,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19829,
        "tokens": 10396106752,
        "learning_rate": 0.00021083314623849295,
        "gradient_norm": 0.38581517338752747,
        "train_loss": 3.0659942626953125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19830,
        "tokens": 10396631040,
        "learning_rate": 0.00021080744217516243,
        "gradient_norm": 0.37475085258483887,
        "train_loss": 2.9581029415130615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19831,
        "tokens": 10397155328,
        "learning_rate": 0.00021078173945349282,
        "gradient_norm": 0.39005425572395325,
        "train_loss": 3.079714775085449,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19832,
        "tokens": 10397679616,
        "learning_rate": 0.00021075603807377323,
        "gradient_norm": 0.32042983174324036,
        "train_loss": 3.0059406757354736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19833,
        "tokens": 10398203904,
        "learning_rate": 0.00021073033803629322,
        "gradient_norm": 0.37259402871131897,
        "train_loss": 3.0276594161987305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19834,
        "tokens": 10398728192,
        "learning_rate": 0.00021070463934134178,
        "gradient_norm": 0.3561563789844513,
        "train_loss": 2.9895665645599365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19835,
        "tokens": 10399252480,
        "learning_rate": 0.00021067894198920832,
        "gradient_norm": 0.3354426622390747,
        "train_loss": 3.006702423095703,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19836,
        "tokens": 10399776768,
        "learning_rate": 0.0002106532459801822,
        "gradient_norm": 0.3872273862361908,
        "train_loss": 3.0196194648742676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19837,
        "tokens": 10400301056,
        "learning_rate": 0.0002106275513145525,
        "gradient_norm": 0.36888810992240906,
        "train_loss": 3.0368313789367676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19838,
        "tokens": 10400825344,
        "learning_rate": 0.00021060185799260867,
        "gradient_norm": 0.3324413299560547,
        "train_loss": 3.0599822998046875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19839,
        "tokens": 10401349632,
        "learning_rate": 0.00021057616601463953,
        "gradient_norm": 0.34389182925224304,
        "train_loss": 3.0354435443878174,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19840,
        "tokens": 10401873920,
        "learning_rate": 0.0002105504753809347,
        "gradient_norm": 0.3603781461715698,
        "train_loss": 2.9885706901550293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19841,
        "tokens": 10402398208,
        "learning_rate": 0.00021052478609178305,
        "gradient_norm": 0.3307359218597412,
        "train_loss": 3.0765609741210938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19842,
        "tokens": 10402922496,
        "learning_rate": 0.00021049909814747396,
        "gradient_norm": 0.3805099129676819,
        "train_loss": 3.0112557411193848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19843,
        "tokens": 10403446784,
        "learning_rate": 0.00021047341154829637,
        "gradient_norm": 0.3266385793685913,
        "train_loss": 3.0196542739868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19844,
        "tokens": 10403971072,
        "learning_rate": 0.0002104477262945395,
        "gradient_norm": 0.35560232400894165,
        "train_loss": 3.0599637031555176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19845,
        "tokens": 10404495360,
        "learning_rate": 0.00021042204238649263,
        "gradient_norm": 0.38201606273651123,
        "train_loss": 3.026621103286743,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19846,
        "tokens": 10405019648,
        "learning_rate": 0.00021039635982444466,
        "gradient_norm": 0.3521098792552948,
        "train_loss": 3.051833391189575,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19847,
        "tokens": 10405543936,
        "learning_rate": 0.0002103706786086848,
        "gradient_norm": 0.34277892112731934,
        "train_loss": 2.9778223037719727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19848,
        "tokens": 10406068224,
        "learning_rate": 0.00021034499873950202,
        "gradient_norm": 0.39905545115470886,
        "train_loss": 3.0027151107788086,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19849,
        "tokens": 10406592512,
        "learning_rate": 0.00021031932021718552,
        "gradient_norm": 0.3850601613521576,
        "train_loss": 2.967972993850708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19850,
        "tokens": 10407116800,
        "learning_rate": 0.0002102936430420241,
        "gradient_norm": 0.34714460372924805,
        "train_loss": 2.982008934020996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19851,
        "tokens": 10407641088,
        "learning_rate": 0.0002102679672143071,
        "gradient_norm": 0.3303937315940857,
        "train_loss": 3.0211386680603027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19852,
        "tokens": 10408165376,
        "learning_rate": 0.00021024229273432327,
        "gradient_norm": 0.36687198281288147,
        "train_loss": 3.0424275398254395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19853,
        "tokens": 10408689664,
        "learning_rate": 0.00021021661960236182,
        "gradient_norm": 0.3311343789100647,
        "train_loss": 3.0908799171447754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19854,
        "tokens": 10409213952,
        "learning_rate": 0.00021019094781871153,
        "gradient_norm": 0.347275048494339,
        "train_loss": 3.078606605529785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19855,
        "tokens": 10409738240,
        "learning_rate": 0.00021016527738366148,
        "gradient_norm": 0.32854074239730835,
        "train_loss": 3.013671875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19856,
        "tokens": 10410262528,
        "learning_rate": 0.00021013960829750067,
        "gradient_norm": 0.3139125108718872,
        "train_loss": 2.9950764179229736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19857,
        "tokens": 10410786816,
        "learning_rate": 0.00021011394056051792,
        "gradient_norm": 0.33452481031417847,
        "train_loss": 3.051933765411377,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19858,
        "tokens": 10411311104,
        "learning_rate": 0.0002100882741730023,
        "gradient_norm": 0.3164173662662506,
        "train_loss": 3.0181422233581543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19859,
        "tokens": 10411835392,
        "learning_rate": 0.0002100626091352425,
        "gradient_norm": 0.3841192424297333,
        "train_loss": 3.0436935424804688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19860,
        "tokens": 10412359680,
        "learning_rate": 0.00021003694544752765,
        "gradient_norm": 0.32384249567985535,
        "train_loss": 3.0931596755981445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19861,
        "tokens": 10412883968,
        "learning_rate": 0.00021001128311014643,
        "gradient_norm": 0.37110549211502075,
        "train_loss": 3.093825340270996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19862,
        "tokens": 10413408256,
        "learning_rate": 0.00020998562212338792,
        "gradient_norm": 0.36292558908462524,
        "train_loss": 3.0721874237060547,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19863,
        "tokens": 10413932544,
        "learning_rate": 0.00020995996248754066,
        "gradient_norm": 0.34825822710990906,
        "train_loss": 3.0332093238830566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19864,
        "tokens": 10414456832,
        "learning_rate": 0.00020993430420289372,
        "gradient_norm": 0.3243494927883148,
        "train_loss": 2.9754714965820312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19865,
        "tokens": 10414981120,
        "learning_rate": 0.00020990864726973593,
        "gradient_norm": 0.36139729619026184,
        "train_loss": 3.069870948791504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19866,
        "tokens": 10415505408,
        "learning_rate": 0.00020988299168835588,
        "gradient_norm": 0.33289316296577454,
        "train_loss": 3.044456720352173,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19867,
        "tokens": 10416029696,
        "learning_rate": 0.00020985733745904268,
        "gradient_norm": 0.36086800694465637,
        "train_loss": 3.00886869430542,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19868,
        "tokens": 10416553984,
        "learning_rate": 0.0002098316845820847,
        "gradient_norm": 0.33719462156295776,
        "train_loss": 2.999582529067993,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19869,
        "tokens": 10417078272,
        "learning_rate": 0.00020980603305777108,
        "gradient_norm": 0.3297029733657837,
        "train_loss": 3.0398995876312256,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19870,
        "tokens": 10417602560,
        "learning_rate": 0.00020978038288639025,
        "gradient_norm": 0.31515464186668396,
        "train_loss": 3.0353565216064453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19871,
        "tokens": 10418126848,
        "learning_rate": 0.00020975473406823115,
        "gradient_norm": 0.3054678738117218,
        "train_loss": 3.0449013710021973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19872,
        "tokens": 10418651136,
        "learning_rate": 0.00020972908660358235,
        "gradient_norm": 0.3507659435272217,
        "train_loss": 3.048893451690674,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19873,
        "tokens": 10419175424,
        "learning_rate": 0.0002097034404927327,
        "gradient_norm": 0.371133416891098,
        "train_loss": 3.022641658782959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19874,
        "tokens": 10419699712,
        "learning_rate": 0.00020967779573597065,
        "gradient_norm": 0.37925055623054504,
        "train_loss": 3.0054430961608887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19875,
        "tokens": 10420224000,
        "learning_rate": 0.00020965215233358512,
        "gradient_norm": 0.37895846366882324,
        "train_loss": 3.0386223793029785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19876,
        "tokens": 10420748288,
        "learning_rate": 0.00020962651028586454,
        "gradient_norm": 0.3852890133857727,
        "train_loss": 3.020230293273926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19877,
        "tokens": 10421272576,
        "learning_rate": 0.00020960086959309772,
        "gradient_norm": 0.34268367290496826,
        "train_loss": 3.045562505722046,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19878,
        "tokens": 10421796864,
        "learning_rate": 0.00020957523025557308,
        "gradient_norm": 0.3874877393245697,
        "train_loss": 3.007770299911499,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19879,
        "tokens": 10422321152,
        "learning_rate": 0.00020954959227357947,
        "gradient_norm": 0.34257417917251587,
        "train_loss": 2.949481964111328,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19880,
        "tokens": 10422845440,
        "learning_rate": 0.0002095239556474052,
        "gradient_norm": 0.3941609859466553,
        "train_loss": 3.0052897930145264,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19881,
        "tokens": 10423369728,
        "learning_rate": 0.00020949832037733915,
        "gradient_norm": 0.41646450757980347,
        "train_loss": 3.007704734802246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19882,
        "tokens": 10423894016,
        "learning_rate": 0.00020947268646366956,
        "gradient_norm": 0.3759516775608063,
        "train_loss": 3.053501844406128,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19883,
        "tokens": 10424418304,
        "learning_rate": 0.00020944705390668522,
        "gradient_norm": 0.36998221278190613,
        "train_loss": 3.114838123321533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19884,
        "tokens": 10424942592,
        "learning_rate": 0.0002094214227066745,
        "gradient_norm": 0.37213069200515747,
        "train_loss": 3.0219976902008057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19885,
        "tokens": 10425466880,
        "learning_rate": 0.00020939579286392607,
        "gradient_norm": 0.34960126876831055,
        "train_loss": 3.0634560585021973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19886,
        "tokens": 10425991168,
        "learning_rate": 0.0002093701643787282,
        "gradient_norm": 0.36691638827323914,
        "train_loss": 3.0199337005615234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19887,
        "tokens": 10426515456,
        "learning_rate": 0.00020934453725136962,
        "gradient_norm": 0.4016661047935486,
        "train_loss": 3.068142890930176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19888,
        "tokens": 10427039744,
        "learning_rate": 0.00020931891148213855,
        "gradient_norm": 0.41322290897369385,
        "train_loss": 2.9974985122680664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19889,
        "tokens": 10427564032,
        "learning_rate": 0.00020929328707132368,
        "gradient_norm": 0.36636337637901306,
        "train_loss": 3.0649375915527344,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19890,
        "tokens": 10428088320,
        "learning_rate": 0.00020926766401921325,
        "gradient_norm": 0.45502543449401855,
        "train_loss": 3.0419669151306152,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19891,
        "tokens": 10428612608,
        "learning_rate": 0.0002092420423260958,
        "gradient_norm": 0.34794536232948303,
        "train_loss": 3.049365282058716,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19892,
        "tokens": 10429136896,
        "learning_rate": 0.00020921642199225963,
        "gradient_norm": 0.3743942081928253,
        "train_loss": 3.055722236633301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19893,
        "tokens": 10429661184,
        "learning_rate": 0.0002091908030179933,
        "gradient_norm": 0.3887791037559509,
        "train_loss": 3.020871877670288,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19894,
        "tokens": 10430185472,
        "learning_rate": 0.00020916518540358496,
        "gradient_norm": 0.42928534746170044,
        "train_loss": 3.0546483993530273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19895,
        "tokens": 10430709760,
        "learning_rate": 0.00020913956914932308,
        "gradient_norm": 0.3589250147342682,
        "train_loss": 3.0232858657836914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19896,
        "tokens": 10431234048,
        "learning_rate": 0.00020911395425549613,
        "gradient_norm": 0.3838960528373718,
        "train_loss": 3.0238380432128906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19897,
        "tokens": 10431758336,
        "learning_rate": 0.0002090883407223922,
        "gradient_norm": 0.34840551018714905,
        "train_loss": 3.0407276153564453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19898,
        "tokens": 10432282624,
        "learning_rate": 0.0002090627285502998,
        "gradient_norm": 0.3781454265117645,
        "train_loss": 3.0257372856140137,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19899,
        "tokens": 10432806912,
        "learning_rate": 0.00020903711773950705,
        "gradient_norm": 0.3536163866519928,
        "train_loss": 3.018197774887085,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19900,
        "tokens": 10433331200,
        "learning_rate": 0.00020901150829030245,
        "gradient_norm": 0.3866965174674988,
        "train_loss": 3.049903392791748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19901,
        "tokens": 10433855488,
        "learning_rate": 0.000208985900202974,
        "gradient_norm": 0.3421213626861572,
        "train_loss": 3.0390572547912598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19902,
        "tokens": 10434379776,
        "learning_rate": 0.00020896029347781026,
        "gradient_norm": 0.37349098920822144,
        "train_loss": 3.0179429054260254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19903,
        "tokens": 10434904064,
        "learning_rate": 0.0002089346881150991,
        "gradient_norm": 0.3650780916213989,
        "train_loss": 2.983912467956543,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19904,
        "tokens": 10435428352,
        "learning_rate": 0.000208909084115129,
        "gradient_norm": 0.34270551800727844,
        "train_loss": 3.073187828063965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19905,
        "tokens": 10435952640,
        "learning_rate": 0.0002088834814781882,
        "gradient_norm": 0.6471090316772461,
        "train_loss": 3.092787265777588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19906,
        "tokens": 10436476928,
        "learning_rate": 0.00020885788020456465,
        "gradient_norm": 0.39476051926612854,
        "train_loss": 3.0796027183532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19907,
        "tokens": 10437001216,
        "learning_rate": 0.00020883228029454682,
        "gradient_norm": 0.36917737126350403,
        "train_loss": 3.0339832305908203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19908,
        "tokens": 10437525504,
        "learning_rate": 0.00020880668174842257,
        "gradient_norm": 0.3713444173336029,
        "train_loss": 3.0924506187438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19909,
        "tokens": 10438049792,
        "learning_rate": 0.00020878108456648032,
        "gradient_norm": 0.36535733938217163,
        "train_loss": 3.0747780799865723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19910,
        "tokens": 10438574080,
        "learning_rate": 0.00020875548874900796,
        "gradient_norm": 0.4125036597251892,
        "train_loss": 3.0569722652435303,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19911,
        "tokens": 10439098368,
        "learning_rate": 0.00020872989429629378,
        "gradient_norm": 0.3818581700325012,
        "train_loss": 3.024646759033203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19912,
        "tokens": 10439622656,
        "learning_rate": 0.00020870430120862576,
        "gradient_norm": 0.3766945004463196,
        "train_loss": 3.028287410736084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19913,
        "tokens": 10440146944,
        "learning_rate": 0.0002086787094862921,
        "gradient_norm": 0.38726744055747986,
        "train_loss": 3.0100674629211426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19914,
        "tokens": 10440671232,
        "learning_rate": 0.00020865311912958068,
        "gradient_norm": 0.34974077343940735,
        "train_loss": 3.050344228744507,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19915,
        "tokens": 10441195520,
        "learning_rate": 0.00020862753013877968,
        "gradient_norm": 0.36421525478363037,
        "train_loss": 2.9964170455932617,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19916,
        "tokens": 10441719808,
        "learning_rate": 0.00020860194251417724,
        "gradient_norm": 0.3470269739627838,
        "train_loss": 2.991124153137207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19917,
        "tokens": 10442244096,
        "learning_rate": 0.00020857635625606114,
        "gradient_norm": 0.32141563296318054,
        "train_loss": 2.981977701187134,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19918,
        "tokens": 10442768384,
        "learning_rate": 0.0002085507713647196,
        "gradient_norm": 0.4056413173675537,
        "train_loss": 3.0422511100769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19919,
        "tokens": 10443292672,
        "learning_rate": 0.00020852518784044045,
        "gradient_norm": 0.36405447125434875,
        "train_loss": 3.0773086547851562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19920,
        "tokens": 10443816960,
        "learning_rate": 0.00020849960568351185,
        "gradient_norm": 0.3986366093158722,
        "train_loss": 3.011889696121216,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19921,
        "tokens": 10444341248,
        "learning_rate": 0.00020847402489422147,
        "gradient_norm": 0.39052820205688477,
        "train_loss": 3.0459251403808594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19922,
        "tokens": 10444865536,
        "learning_rate": 0.0002084484454728576,
        "gradient_norm": 0.3605612516403198,
        "train_loss": 3.02146053314209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19923,
        "tokens": 10445389824,
        "learning_rate": 0.00020842286741970783,
        "gradient_norm": 0.38443753123283386,
        "train_loss": 3.0261402130126953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19924,
        "tokens": 10445914112,
        "learning_rate": 0.0002083972907350603,
        "gradient_norm": 0.3625442385673523,
        "train_loss": 3.0279173851013184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19925,
        "tokens": 10446438400,
        "learning_rate": 0.00020837171541920288,
        "gradient_norm": 0.36729156970977783,
        "train_loss": 3.0051350593566895,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19926,
        "tokens": 10446962688,
        "learning_rate": 0.00020834614147242336,
        "gradient_norm": 0.3711634576320648,
        "train_loss": 3.0477402210235596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19927,
        "tokens": 10447486976,
        "learning_rate": 0.00020832056889500975,
        "gradient_norm": 0.4146459102630615,
        "train_loss": 3.002856969833374,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19928,
        "tokens": 10448011264,
        "learning_rate": 0.0002082949976872497,
        "gradient_norm": 0.3309757709503174,
        "train_loss": 2.9984803199768066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19929,
        "tokens": 10448535552,
        "learning_rate": 0.00020826942784943128,
        "gradient_norm": 0.40071210265159607,
        "train_loss": 3.011261463165283,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19930,
        "tokens": 10449059840,
        "learning_rate": 0.00020824385938184213,
        "gradient_norm": 0.37013110518455505,
        "train_loss": 3.0129785537719727,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19931,
        "tokens": 10449584128,
        "learning_rate": 0.00020821829228477015,
        "gradient_norm": 0.4338957369327545,
        "train_loss": 3.126997947692871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19932,
        "tokens": 10450108416,
        "learning_rate": 0.00020819272655850303,
        "gradient_norm": 0.37824299931526184,
        "train_loss": 3.1091203689575195,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19933,
        "tokens": 10450632704,
        "learning_rate": 0.0002081671622033287,
        "gradient_norm": 0.4005596935749054,
        "train_loss": 3.0080466270446777,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19934,
        "tokens": 10451156992,
        "learning_rate": 0.00020814159921953473,
        "gradient_norm": 0.36716699600219727,
        "train_loss": 3.057745933532715,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19935,
        "tokens": 10451681280,
        "learning_rate": 0.00020811603760740894,
        "gradient_norm": 0.4333464801311493,
        "train_loss": 3.029877185821533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19936,
        "tokens": 10452205568,
        "learning_rate": 0.00020809047736723918,
        "gradient_norm": 0.3420107960700989,
        "train_loss": 3.061605453491211,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19937,
        "tokens": 10452729856,
        "learning_rate": 0.00020806491849931298,
        "gradient_norm": 0.36062154173851013,
        "train_loss": 3.034245252609253,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19938,
        "tokens": 10453254144,
        "learning_rate": 0.00020803936100391825,
        "gradient_norm": 0.37830406427383423,
        "train_loss": 3.065042495727539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19939,
        "tokens": 10453778432,
        "learning_rate": 0.0002080138048813424,
        "gradient_norm": 0.3599027991294861,
        "train_loss": 3.0066776275634766,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19940,
        "tokens": 10454302720,
        "learning_rate": 0.00020798825013187332,
        "gradient_norm": 0.38429078459739685,
        "train_loss": 3.034287452697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19941,
        "tokens": 10454827008,
        "learning_rate": 0.00020796269675579852,
        "gradient_norm": 0.35708707571029663,
        "train_loss": 3.0572328567504883,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19942,
        "tokens": 10455351296,
        "learning_rate": 0.00020793714475340574,
        "gradient_norm": 0.39353910088539124,
        "train_loss": 2.991593837738037,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19943,
        "tokens": 10455875584,
        "learning_rate": 0.0002079115941249825,
        "gradient_norm": 0.3577999472618103,
        "train_loss": 2.9843006134033203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19944,
        "tokens": 10456399872,
        "learning_rate": 0.00020788604487081646,
        "gradient_norm": 0.36322784423828125,
        "train_loss": 3.0925958156585693,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19945,
        "tokens": 10456924160,
        "learning_rate": 0.00020786049699119527,
        "gradient_norm": 0.36187079548835754,
        "train_loss": 3.0124661922454834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19946,
        "tokens": 10457448448,
        "learning_rate": 0.00020783495048640633,
        "gradient_norm": 0.3556267023086548,
        "train_loss": 2.9850735664367676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19947,
        "tokens": 10457972736,
        "learning_rate": 0.00020780940535673745,
        "gradient_norm": 0.3731836676597595,
        "train_loss": 3.033447027206421,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19948,
        "tokens": 10458497024,
        "learning_rate": 0.00020778386160247587,
        "gradient_norm": 0.3494696021080017,
        "train_loss": 2.931918144226074,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19949,
        "tokens": 10459021312,
        "learning_rate": 0.00020775831922390943,
        "gradient_norm": 0.33349114656448364,
        "train_loss": 3.0004122257232666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19950,
        "tokens": 10459545600,
        "learning_rate": 0.00020773277822132535,
        "gradient_norm": 0.39456844329833984,
        "train_loss": 2.9912025928497314,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19951,
        "tokens": 10460069888,
        "learning_rate": 0.00020770723859501138,
        "gradient_norm": 0.35808560252189636,
        "train_loss": 2.9974617958068848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19952,
        "tokens": 10460594176,
        "learning_rate": 0.00020768170034525478,
        "gradient_norm": 0.3550175428390503,
        "train_loss": 3.011735439300537,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19953,
        "tokens": 10461118464,
        "learning_rate": 0.00020765616347234318,
        "gradient_norm": 0.3784661293029785,
        "train_loss": 3.056032657623291,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19954,
        "tokens": 10461642752,
        "learning_rate": 0.0002076306279765639,
        "gradient_norm": 0.3821088671684265,
        "train_loss": 3.096367835998535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19955,
        "tokens": 10462167040,
        "learning_rate": 0.00020760509385820447,
        "gradient_norm": 0.38634324073791504,
        "train_loss": 3.1165287494659424,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19956,
        "tokens": 10462691328,
        "learning_rate": 0.0002075795611175523,
        "gradient_norm": 0.39974352717399597,
        "train_loss": 3.0378365516662598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19957,
        "tokens": 10463215616,
        "learning_rate": 0.00020755402975489474,
        "gradient_norm": 0.3813309073448181,
        "train_loss": 3.006572723388672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19958,
        "tokens": 10463739904,
        "learning_rate": 0.00020752849977051925,
        "gradient_norm": 0.37614014744758606,
        "train_loss": 3.0271573066711426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19959,
        "tokens": 10464264192,
        "learning_rate": 0.00020750297116471314,
        "gradient_norm": 0.3625074625015259,
        "train_loss": 2.997401237487793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19960,
        "tokens": 10464788480,
        "learning_rate": 0.00020747744393776382,
        "gradient_norm": 0.41684791445732117,
        "train_loss": 3.035733222961426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19961,
        "tokens": 10465312768,
        "learning_rate": 0.0002074519180899585,
        "gradient_norm": 0.4694901704788208,
        "train_loss": 2.974013328552246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19962,
        "tokens": 10465837056,
        "learning_rate": 0.0002074263936215847,
        "gradient_norm": 0.40955740213394165,
        "train_loss": 3.081017017364502,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19963,
        "tokens": 10466361344,
        "learning_rate": 0.00020740087053292954,
        "gradient_norm": 0.4288850724697113,
        "train_loss": 3.054053783416748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19964,
        "tokens": 10466885632,
        "learning_rate": 0.00020737534882428043,
        "gradient_norm": 0.378703773021698,
        "train_loss": 2.9895341396331787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19965,
        "tokens": 10467409920,
        "learning_rate": 0.0002073498284959247,
        "gradient_norm": 0.4436904191970825,
        "train_loss": 3.162602186203003,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19966,
        "tokens": 10467934208,
        "learning_rate": 0.00020732430954814948,
        "gradient_norm": 0.4214952886104584,
        "train_loss": 3.08194899559021,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19967,
        "tokens": 10468458496,
        "learning_rate": 0.0002072987919812421,
        "gradient_norm": 0.4149312973022461,
        "train_loss": 3.010854959487915,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19968,
        "tokens": 10468982784,
        "learning_rate": 0.00020727327579548972,
        "gradient_norm": 0.3777896463871002,
        "train_loss": 3.013577938079834,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19969,
        "tokens": 10469507072,
        "learning_rate": 0.00020724776099117972,
        "gradient_norm": 0.37371906638145447,
        "train_loss": 3.0241785049438477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19970,
        "tokens": 10470031360,
        "learning_rate": 0.00020722224756859902,
        "gradient_norm": 0.3863329291343689,
        "train_loss": 3.043393611907959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19971,
        "tokens": 10470555648,
        "learning_rate": 0.00020719673552803514,
        "gradient_norm": 0.3919425904750824,
        "train_loss": 3.035930633544922,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19972,
        "tokens": 10471079936,
        "learning_rate": 0.00020717122486977493,
        "gradient_norm": 0.38896918296813965,
        "train_loss": 3.0470118522644043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19973,
        "tokens": 10471604224,
        "learning_rate": 0.00020714571559410583,
        "gradient_norm": 0.36212119460105896,
        "train_loss": 3.0705771446228027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19974,
        "tokens": 10472128512,
        "learning_rate": 0.0002071202077013147,
        "gradient_norm": 0.39774736762046814,
        "train_loss": 3.0272483825683594,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19975,
        "tokens": 10472652800,
        "learning_rate": 0.00020709470119168895,
        "gradient_norm": 0.34198427200317383,
        "train_loss": 3.0506160259246826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19976,
        "tokens": 10473177088,
        "learning_rate": 0.0002070691960655154,
        "gradient_norm": 0.42533135414123535,
        "train_loss": 3.022402286529541,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19977,
        "tokens": 10473701376,
        "learning_rate": 0.00020704369232308142,
        "gradient_norm": 0.33939284086227417,
        "train_loss": 3.0302841663360596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19978,
        "tokens": 10474225664,
        "learning_rate": 0.00020701818996467385,
        "gradient_norm": 0.39674150943756104,
        "train_loss": 3.0316944122314453,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19979,
        "tokens": 10474749952,
        "learning_rate": 0.00020699268899057995,
        "gradient_norm": 0.35601091384887695,
        "train_loss": 3.024507999420166,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19980,
        "tokens": 10475274240,
        "learning_rate": 0.00020696718940108654,
        "gradient_norm": 0.399050235748291,
        "train_loss": 3.0473246574401855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19981,
        "tokens": 10475798528,
        "learning_rate": 0.00020694169119648092,
        "gradient_norm": 0.3495370149612427,
        "train_loss": 3.0658679008483887,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19982,
        "tokens": 10476322816,
        "learning_rate": 0.00020691619437704985,
        "gradient_norm": 0.34376510977745056,
        "train_loss": 2.977548837661743,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19983,
        "tokens": 10476847104,
        "learning_rate": 0.00020689069894308054,
        "gradient_norm": 0.39902353286743164,
        "train_loss": 3.083846092224121,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19984,
        "tokens": 10477371392,
        "learning_rate": 0.00020686520489485977,
        "gradient_norm": 0.3520791828632355,
        "train_loss": 3.0273802280426025,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19985,
        "tokens": 10477895680,
        "learning_rate": 0.00020683971223267467,
        "gradient_norm": 0.36139896512031555,
        "train_loss": 3.0315823554992676,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19986,
        "tokens": 10478419968,
        "learning_rate": 0.00020681422095681208,
        "gradient_norm": 0.3439512848854065,
        "train_loss": 3.0578866004943848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19987,
        "tokens": 10478944256,
        "learning_rate": 0.0002067887310675591,
        "gradient_norm": 0.35254359245300293,
        "train_loss": 3.0361952781677246,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19988,
        "tokens": 10479468544,
        "learning_rate": 0.00020676324256520238,
        "gradient_norm": 0.3647474944591522,
        "train_loss": 3.017817735671997,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19989,
        "tokens": 10479992832,
        "learning_rate": 0.00020673775545002903,
        "gradient_norm": 0.3462539613246918,
        "train_loss": 3.0301401615142822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19990,
        "tokens": 10480517120,
        "learning_rate": 0.000206712269722326,
        "gradient_norm": 0.3923162519931793,
        "train_loss": 2.99471378326416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19991,
        "tokens": 10481041408,
        "learning_rate": 0.0002066867853823799,
        "gradient_norm": 0.4112354516983032,
        "train_loss": 3.023207187652588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19992,
        "tokens": 10481565696,
        "learning_rate": 0.00020666130243047787,
        "gradient_norm": 0.36059895157814026,
        "train_loss": 3.013826847076416,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19993,
        "tokens": 10482089984,
        "learning_rate": 0.00020663582086690658,
        "gradient_norm": 0.3789546489715576,
        "train_loss": 3.019277572631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19994,
        "tokens": 10482614272,
        "learning_rate": 0.00020661034069195295,
        "gradient_norm": 0.34017857909202576,
        "train_loss": 2.995546579360962,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19995,
        "tokens": 10483138560,
        "learning_rate": 0.00020658486190590364,
        "gradient_norm": 0.3924652338027954,
        "train_loss": 3.1391353607177734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19996,
        "tokens": 10483662848,
        "learning_rate": 0.0002065593845090457,
        "gradient_norm": 0.35668864846229553,
        "train_loss": 3.0147364139556885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19997,
        "tokens": 10484187136,
        "learning_rate": 0.00020653390850166562,
        "gradient_norm": 0.34778285026550293,
        "train_loss": 2.976938009262085,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19998,
        "tokens": 10484711424,
        "learning_rate": 0.0002065084338840504,
        "gradient_norm": 0.3476108908653259,
        "train_loss": 2.997659206390381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 19999,
        "tokens": 10485235712,
        "learning_rate": 0.00020648296065648662,
        "gradient_norm": 0.34668052196502686,
        "train_loss": 3.020853042602539,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20000,
        "tokens": 10485760000,
        "learning_rate": 0.00020645748881926114,
        "gradient_norm": 0.34484580159187317,
        "train_loss": 3.006884813308716,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20001,
        "tokens": 10486284288,
        "learning_rate": 0.00020643201837266056,
        "gradient_norm": 0.34757882356643677,
        "train_loss": 3.010129690170288,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20002,
        "tokens": 10486808576,
        "learning_rate": 0.00020640654931697175,
        "gradient_norm": 0.3461344242095947,
        "train_loss": 3.05362606048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20003,
        "tokens": 10487332864,
        "learning_rate": 0.00020638108165248116,
        "gradient_norm": 0.34889519214630127,
        "train_loss": 3.0379509925842285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20004,
        "tokens": 10487857152,
        "learning_rate": 0.00020635561537947562,
        "gradient_norm": 0.3591824471950531,
        "train_loss": 3.100663661956787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20005,
        "tokens": 10488381440,
        "learning_rate": 0.00020633015049824186,
        "gradient_norm": 0.36767226457595825,
        "train_loss": 3.0480732917785645,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20006,
        "tokens": 10488905728,
        "learning_rate": 0.0002063046870090663,
        "gradient_norm": 0.35442882776260376,
        "train_loss": 3.0264573097229004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20007,
        "tokens": 10489430016,
        "learning_rate": 0.00020627922491223578,
        "gradient_norm": 0.3626779615879059,
        "train_loss": 3.0764498710632324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20008,
        "tokens": 10489954304,
        "learning_rate": 0.0002062537642080367,
        "gradient_norm": 0.3948586583137512,
        "train_loss": 3.05999755859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20009,
        "tokens": 10490478592,
        "learning_rate": 0.00020622830489675588,
        "gradient_norm": 0.31848815083503723,
        "train_loss": 3.0143003463745117,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20010,
        "tokens": 10491002880,
        "learning_rate": 0.00020620284697867963,
        "gradient_norm": 0.4156312644481659,
        "train_loss": 3.008401393890381,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20011,
        "tokens": 10491527168,
        "learning_rate": 0.0002061773904540948,
        "gradient_norm": 0.3280363976955414,
        "train_loss": 3.0916099548339844,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20012,
        "tokens": 10492051456,
        "learning_rate": 0.00020615193532328764,
        "gradient_norm": 0.36560359597206116,
        "train_loss": 3.0914316177368164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20013,
        "tokens": 10492575744,
        "learning_rate": 0.00020612648158654495,
        "gradient_norm": 0.38583481311798096,
        "train_loss": 3.0827131271362305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20014,
        "tokens": 10493100032,
        "learning_rate": 0.00020610102924415306,
        "gradient_norm": 0.3512824475765228,
        "train_loss": 3.0753188133239746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20015,
        "tokens": 10493624320,
        "learning_rate": 0.0002060755782963985,
        "gradient_norm": 0.33933785557746887,
        "train_loss": 3.0571789741516113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20016,
        "tokens": 10494148608,
        "learning_rate": 0.00020605012874356788,
        "gradient_norm": 0.35160863399505615,
        "train_loss": 3.1248464584350586,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20017,
        "tokens": 10494672896,
        "learning_rate": 0.00020602468058594745,
        "gradient_norm": 0.37593334913253784,
        "train_loss": 3.0695271492004395,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20018,
        "tokens": 10495197184,
        "learning_rate": 0.00020599923382382391,
        "gradient_norm": 0.3295590281486511,
        "train_loss": 3.054456949234009,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20019,
        "tokens": 10495721472,
        "learning_rate": 0.00020597378845748347,
        "gradient_norm": 0.35788270831108093,
        "train_loss": 3.086717128753662,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20020,
        "tokens": 10496245760,
        "learning_rate": 0.00020594834448721272,
        "gradient_norm": 0.36669713258743286,
        "train_loss": 3.101677417755127,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20021,
        "tokens": 10496770048,
        "learning_rate": 0.00020592290191329788,
        "gradient_norm": 0.4287121295928955,
        "train_loss": 3.0904619693756104,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20022,
        "tokens": 10497294336,
        "learning_rate": 0.00020589746073602558,
        "gradient_norm": 0.41290146112442017,
        "train_loss": 3.046142816543579,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20023,
        "tokens": 10497818624,
        "learning_rate": 0.00020587202095568192,
        "gradient_norm": 0.3955894112586975,
        "train_loss": 3.0713183879852295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20024,
        "tokens": 10498342912,
        "learning_rate": 0.00020584658257255344,
        "gradient_norm": 0.4900203347206116,
        "train_loss": 3.024890422821045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20025,
        "tokens": 10498867200,
        "learning_rate": 0.0002058211455869265,
        "gradient_norm": 0.3893544673919678,
        "train_loss": 3.0905771255493164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20026,
        "tokens": 10499391488,
        "learning_rate": 0.00020579570999908726,
        "gradient_norm": 0.4469265639781952,
        "train_loss": 3.0794272422790527,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20027,
        "tokens": 10499915776,
        "learning_rate": 0.00020577027580932224,
        "gradient_norm": 0.37407535314559937,
        "train_loss": 3.0051217079162598,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20028,
        "tokens": 10500440064,
        "learning_rate": 0.0002057448430179175,
        "gradient_norm": 0.3871913552284241,
        "train_loss": 3.019892692565918,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20029,
        "tokens": 10500964352,
        "learning_rate": 0.0002057194116251596,
        "gradient_norm": 0.3507048189640045,
        "train_loss": 3.0252954959869385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20030,
        "tokens": 10501488640,
        "learning_rate": 0.00020569398163133444,
        "gradient_norm": 0.3783590495586395,
        "train_loss": 3.0267486572265625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20031,
        "tokens": 10502012928,
        "learning_rate": 0.00020566855303672866,
        "gradient_norm": 0.34363895654678345,
        "train_loss": 3.0152547359466553,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20032,
        "tokens": 10502537216,
        "learning_rate": 0.00020564312584162814,
        "gradient_norm": 0.3864390254020691,
        "train_loss": 3.067627429962158,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20033,
        "tokens": 10503061504,
        "learning_rate": 0.00020561770004631942,
        "gradient_norm": 0.38829368352890015,
        "train_loss": 3.051971435546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20034,
        "tokens": 10503585792,
        "learning_rate": 0.00020559227565108835,
        "gradient_norm": 0.36640533804893494,
        "train_loss": 3.0918195247650146,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20035,
        "tokens": 10504110080,
        "learning_rate": 0.00020556685265622133,
        "gradient_norm": 0.36506131291389465,
        "train_loss": 3.1172947883605957,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20036,
        "tokens": 10504634368,
        "learning_rate": 0.00020554143106200464,
        "gradient_norm": 0.34690019488334656,
        "train_loss": 3.078547954559326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20037,
        "tokens": 10505158656,
        "learning_rate": 0.00020551601086872412,
        "gradient_norm": 0.4796335995197296,
        "train_loss": 3.0902810096740723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20038,
        "tokens": 10505682944,
        "learning_rate": 0.0002054905920766662,
        "gradient_norm": 0.44869253039360046,
        "train_loss": 3.0628833770751953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20039,
        "tokens": 10506207232,
        "learning_rate": 0.00020546517468611675,
        "gradient_norm": 0.34312620759010315,
        "train_loss": 3.0604822635650635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20040,
        "tokens": 10506731520,
        "learning_rate": 0.00020543975869736212,
        "gradient_norm": 0.4095273017883301,
        "train_loss": 3.0590996742248535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20041,
        "tokens": 10507255808,
        "learning_rate": 0.00020541434411068817,
        "gradient_norm": 0.3678300678730011,
        "train_loss": 3.0592403411865234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20042,
        "tokens": 10507780096,
        "learning_rate": 0.0002053889309263812,
        "gradient_norm": 0.36750105023384094,
        "train_loss": 3.04325008392334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20043,
        "tokens": 10508304384,
        "learning_rate": 0.000205363519144727,
        "gradient_norm": 0.3653196394443512,
        "train_loss": 3.0808334350585938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20044,
        "tokens": 10508828672,
        "learning_rate": 0.00020533810876601177,
        "gradient_norm": 0.39737874269485474,
        "train_loss": 3.0530271530151367,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20045,
        "tokens": 10509352960,
        "learning_rate": 0.00020531269979052165,
        "gradient_norm": 0.37726590037345886,
        "train_loss": 3.104581356048584,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20046,
        "tokens": 10509877248,
        "learning_rate": 0.00020528729221854237,
        "gradient_norm": 0.37665730714797974,
        "train_loss": 2.990302085876465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20047,
        "tokens": 10510401536,
        "learning_rate": 0.00020526188605036024,
        "gradient_norm": 0.46475812792778015,
        "train_loss": 3.098008155822754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20048,
        "tokens": 10510925824,
        "learning_rate": 0.0002052364812862609,
        "gradient_norm": 0.36989155411720276,
        "train_loss": 3.0519251823425293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20049,
        "tokens": 10511450112,
        "learning_rate": 0.00020521107792653064,
        "gradient_norm": 0.373874694108963,
        "train_loss": 3.0670628547668457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20050,
        "tokens": 10511974400,
        "learning_rate": 0.00020518567597145512,
        "gradient_norm": 0.35269367694854736,
        "train_loss": 3.051722288131714,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20051,
        "tokens": 10512498688,
        "learning_rate": 0.00020516027542132048,
        "gradient_norm": 0.3480546474456787,
        "train_loss": 3.0557491779327393,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20052,
        "tokens": 10513022976,
        "learning_rate": 0.0002051348762764125,
        "gradient_norm": 0.3328231871128082,
        "train_loss": 3.049473285675049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20053,
        "tokens": 10513547264,
        "learning_rate": 0.00020510947853701723,
        "gradient_norm": 0.3584510385990143,
        "train_loss": 3.058276653289795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20054,
        "tokens": 10514071552,
        "learning_rate": 0.00020508408220342038,
        "gradient_norm": 0.36547985672950745,
        "train_loss": 3.090186595916748,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20055,
        "tokens": 10514595840,
        "learning_rate": 0.00020505868727590786,
        "gradient_norm": 0.37290695309638977,
        "train_loss": 3.054464817047119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20056,
        "tokens": 10515120128,
        "learning_rate": 0.00020503329375476566,
        "gradient_norm": 0.3538477420806885,
        "train_loss": 3.0748775005340576,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20057,
        "tokens": 10515644416,
        "learning_rate": 0.0002050079016402794,
        "gradient_norm": 0.35448208451271057,
        "train_loss": 3.096219539642334,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20058,
        "tokens": 10516168704,
        "learning_rate": 0.00020498251093273515,
        "gradient_norm": 0.3444080948829651,
        "train_loss": 3.0472488403320312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20059,
        "tokens": 10516692992,
        "learning_rate": 0.0002049571216324185,
        "gradient_norm": 0.363701194524765,
        "train_loss": 3.082207679748535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20060,
        "tokens": 10517217280,
        "learning_rate": 0.00020493173373961536,
        "gradient_norm": 0.35493695735931396,
        "train_loss": 3.035693883895874,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20061,
        "tokens": 10517741568,
        "learning_rate": 0.00020490634725461138,
        "gradient_norm": 0.3607635200023651,
        "train_loss": 3.0687179565429688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20062,
        "tokens": 10518265856,
        "learning_rate": 0.00020488096217769248,
        "gradient_norm": 0.414203405380249,
        "train_loss": 3.0225255489349365,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20063,
        "tokens": 10518790144,
        "learning_rate": 0.00020485557850914422,
        "gradient_norm": 0.47354912757873535,
        "train_loss": 3.0654184818267822,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20064,
        "tokens": 10519314432,
        "learning_rate": 0.00020483019624925242,
        "gradient_norm": 0.3590593934059143,
        "train_loss": 3.017045497894287,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20065,
        "tokens": 10519838720,
        "learning_rate": 0.00020480481539830291,
        "gradient_norm": 0.4073062837123871,
        "train_loss": 3.0627853870391846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20066,
        "tokens": 10520363008,
        "learning_rate": 0.00020477943595658115,
        "gradient_norm": 0.34388962388038635,
        "train_loss": 3.0346810817718506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20067,
        "tokens": 10520887296,
        "learning_rate": 0.00020475405792437303,
        "gradient_norm": 0.4088703989982605,
        "train_loss": 3.1374993324279785,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20068,
        "tokens": 10521411584,
        "learning_rate": 0.000204728681301964,
        "gradient_norm": 0.3909846246242523,
        "train_loss": 3.1163206100463867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20069,
        "tokens": 10521935872,
        "learning_rate": 0.00020470330608963994,
        "gradient_norm": 0.36063963174819946,
        "train_loss": 3.0709774494171143,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20070,
        "tokens": 10522460160,
        "learning_rate": 0.00020467793228768624,
        "gradient_norm": 0.3477613031864166,
        "train_loss": 3.022338628768921,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20071,
        "tokens": 10522984448,
        "learning_rate": 0.00020465255989638877,
        "gradient_norm": 0.3842507004737854,
        "train_loss": 3.070283889770508,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20072,
        "tokens": 10523508736,
        "learning_rate": 0.00020462718891603283,
        "gradient_norm": 0.35119470953941345,
        "train_loss": 3.0214593410491943,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20073,
        "tokens": 10524033024,
        "learning_rate": 0.0002046018193469043,
        "gradient_norm": 0.37386375665664673,
        "train_loss": 3.052887201309204,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20074,
        "tokens": 10524557312,
        "learning_rate": 0.00020457645118928847,
        "gradient_norm": 0.34526771306991577,
        "train_loss": 3.0217859745025635,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20075,
        "tokens": 10525081600,
        "learning_rate": 0.00020455108444347104,
        "gradient_norm": 0.3662945330142975,
        "train_loss": 3.131519317626953,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20076,
        "tokens": 10525605888,
        "learning_rate": 0.00020452571910973763,
        "gradient_norm": 0.37282413244247437,
        "train_loss": 3.07828426361084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20077,
        "tokens": 10526130176,
        "learning_rate": 0.0002045003551883736,
        "gradient_norm": 0.36080577969551086,
        "train_loss": 3.0615437030792236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20078,
        "tokens": 10526654464,
        "learning_rate": 0.00020447499267966455,
        "gradient_norm": 0.35636404156684875,
        "train_loss": 3.098083972930908,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20079,
        "tokens": 10527178752,
        "learning_rate": 0.00020444963158389588,
        "gradient_norm": 0.34057143330574036,
        "train_loss": 3.0464367866516113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20080,
        "tokens": 10527703040,
        "learning_rate": 0.0002044242719013532,
        "gradient_norm": 0.4177171289920807,
        "train_loss": 3.153578281402588,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20081,
        "tokens": 10528227328,
        "learning_rate": 0.0002043989136323217,
        "gradient_norm": 0.35780754685401917,
        "train_loss": 3.017348051071167,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20082,
        "tokens": 10528751616,
        "learning_rate": 0.0002043735567770872,
        "gradient_norm": 0.42265933752059937,
        "train_loss": 3.1033987998962402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20083,
        "tokens": 10529275904,
        "learning_rate": 0.00020434820133593477,
        "gradient_norm": 0.3898909091949463,
        "train_loss": 3.20589017868042,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20084,
        "tokens": 10529800192,
        "learning_rate": 0.00020432284730915006,
        "gradient_norm": 0.42988452315330505,
        "train_loss": 3.0506250858306885,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20085,
        "tokens": 10530324480,
        "learning_rate": 0.00020429749469701825,
        "gradient_norm": 0.3891924321651459,
        "train_loss": 3.03485369682312,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20086,
        "tokens": 10530848768,
        "learning_rate": 0.00020427214349982498,
        "gradient_norm": 0.4088483154773712,
        "train_loss": 3.1087839603424072,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20087,
        "tokens": 10531373056,
        "learning_rate": 0.0002042467937178553,
        "gradient_norm": 0.45333781838417053,
        "train_loss": 3.0293006896972656,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20088,
        "tokens": 10531897344,
        "learning_rate": 0.00020422144535139482,
        "gradient_norm": 0.5733054280281067,
        "train_loss": 3.142061710357666,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20089,
        "tokens": 10532421632,
        "learning_rate": 0.0002041960984007287,
        "gradient_norm": 0.47238507866859436,
        "train_loss": 3.0386404991149902,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20090,
        "tokens": 10532945920,
        "learning_rate": 0.00020417075286614239,
        "gradient_norm": 0.4827936887741089,
        "train_loss": 3.093626022338867,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20091,
        "tokens": 10533470208,
        "learning_rate": 0.000204145408747921,
        "gradient_norm": 0.4656135141849518,
        "train_loss": 3.055264711380005,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20092,
        "tokens": 10533994496,
        "learning_rate": 0.00020412006604635002,
        "gradient_norm": 0.4032822847366333,
        "train_loss": 3.108555793762207,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20093,
        "tokens": 10534518784,
        "learning_rate": 0.0002040947247617145,
        "gradient_norm": 0.4064827859401703,
        "train_loss": 3.0721898078918457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20094,
        "tokens": 10535043072,
        "learning_rate": 0.00020406938489429992,
        "gradient_norm": 0.38189777731895447,
        "train_loss": 3.0418245792388916,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20095,
        "tokens": 10535567360,
        "learning_rate": 0.0002040440464443913,
        "gradient_norm": 0.3761948347091675,
        "train_loss": 3.063690185546875,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20096,
        "tokens": 10536091648,
        "learning_rate": 0.000204018709412274,
        "gradient_norm": 0.3801841735839844,
        "train_loss": 3.0917391777038574,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20097,
        "tokens": 10536615936,
        "learning_rate": 0.00020399337379823309,
        "gradient_norm": 0.3559471368789673,
        "train_loss": 3.0588715076446533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20098,
        "tokens": 10537140224,
        "learning_rate": 0.00020396803960255394,
        "gradient_norm": 0.3482406735420227,
        "train_loss": 3.0781612396240234,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20099,
        "tokens": 10537664512,
        "learning_rate": 0.00020394270682552146,
        "gradient_norm": 0.3351566791534424,
        "train_loss": 3.1235404014587402,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20100,
        "tokens": 10538188800,
        "learning_rate": 0.00020391737546742112,
        "gradient_norm": 0.40131059288978577,
        "train_loss": 3.0301289558410645,
        "val_loss": 3.020932674407959,
        "hellaswag_acc": 0.2834096848964691,
        "hellaswag_acc_norm": 0.2942640781402588
    },
    {
        "step": 20101,
        "tokens": 10538713088,
        "learning_rate": 0.00020389204552853773,
        "gradient_norm": 0.40819811820983887,
        "train_loss": 3.1035122871398926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20102,
        "tokens": 10539237376,
        "learning_rate": 0.0002038667170091567,
        "gradient_norm": 0.36517322063446045,
        "train_loss": 3.055387020111084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20103,
        "tokens": 10539761664,
        "learning_rate": 0.00020384138990956288,
        "gradient_norm": 0.37934955954551697,
        "train_loss": 3.108379364013672,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20104,
        "tokens": 10540285952,
        "learning_rate": 0.00020381606423004148,
        "gradient_norm": 0.3544059097766876,
        "train_loss": 3.016587257385254,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20105,
        "tokens": 10540810240,
        "learning_rate": 0.00020379073997087768,
        "gradient_norm": 0.40648970007896423,
        "train_loss": 3.0618984699249268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20106,
        "tokens": 10541334528,
        "learning_rate": 0.00020376541713235628,
        "gradient_norm": 0.33625903725624084,
        "train_loss": 3.075310707092285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20107,
        "tokens": 10541858816,
        "learning_rate": 0.00020374009571476264,
        "gradient_norm": 0.3612114489078522,
        "train_loss": 3.064047336578369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20108,
        "tokens": 10542383104,
        "learning_rate": 0.00020371477571838145,
        "gradient_norm": 0.35119104385375977,
        "train_loss": 3.1197474002838135,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20109,
        "tokens": 10542907392,
        "learning_rate": 0.000203689457143498,
        "gradient_norm": 0.3802410066127777,
        "train_loss": 3.098494052886963,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20110,
        "tokens": 10543431680,
        "learning_rate": 0.0002036641399903971,
        "gradient_norm": 0.4060882329940796,
        "train_loss": 3.070751905441284,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20111,
        "tokens": 10543955968,
        "learning_rate": 0.00020363882425936385,
        "gradient_norm": 0.4135667085647583,
        "train_loss": 3.0649006366729736,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20112,
        "tokens": 10544480256,
        "learning_rate": 0.000203613509950683,
        "gradient_norm": 0.34363853931427,
        "train_loss": 3.0107779502868652,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20113,
        "tokens": 10545004544,
        "learning_rate": 0.0002035881970646398,
        "gradient_norm": 0.438974529504776,
        "train_loss": 3.0802323818206787,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20114,
        "tokens": 10545528832,
        "learning_rate": 0.0002035628856015189,
        "gradient_norm": 0.3500705063343048,
        "train_loss": 3.141167402267456,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20115,
        "tokens": 10546053120,
        "learning_rate": 0.00020353757556160532,
        "gradient_norm": 0.45523354411125183,
        "train_loss": 3.028031587600708,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20116,
        "tokens": 10546577408,
        "learning_rate": 0.00020351226694518412,
        "gradient_norm": 0.38662248849868774,
        "train_loss": 3.0615739822387695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20117,
        "tokens": 10547101696,
        "learning_rate": 0.00020348695975253985,
        "gradient_norm": 0.364721417427063,
        "train_loss": 3.0107245445251465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20118,
        "tokens": 10547625984,
        "learning_rate": 0.00020346165398395772,
        "gradient_norm": 0.33750268816947937,
        "train_loss": 3.092621326446533,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20119,
        "tokens": 10548150272,
        "learning_rate": 0.00020343634963972224,
        "gradient_norm": 0.3977682590484619,
        "train_loss": 3.0746216773986816,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20120,
        "tokens": 10548674560,
        "learning_rate": 0.00020341104672011855,
        "gradient_norm": 0.3583545684814453,
        "train_loss": 3.0371336936950684,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20121,
        "tokens": 10549198848,
        "learning_rate": 0.00020338574522543124,
        "gradient_norm": 0.36723610758781433,
        "train_loss": 3.037801742553711,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20122,
        "tokens": 10549723136,
        "learning_rate": 0.00020336044515594529,
        "gradient_norm": 0.3598414659500122,
        "train_loss": 3.0868053436279297,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20123,
        "tokens": 10550247424,
        "learning_rate": 0.00020333514651194525,
        "gradient_norm": 0.39463865756988525,
        "train_loss": 3.045982837677002,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20124,
        "tokens": 10550771712,
        "learning_rate": 0.00020330984929371604,
        "gradient_norm": 0.3631785809993744,
        "train_loss": 3.08715558052063,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20125,
        "tokens": 10551296000,
        "learning_rate": 0.00020328455350154253,
        "gradient_norm": 0.38015347719192505,
        "train_loss": 3.0281455516815186,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20126,
        "tokens": 10551820288,
        "learning_rate": 0.00020325925913570921,
        "gradient_norm": 0.35944974422454834,
        "train_loss": 3.0568454265594482,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20127,
        "tokens": 10552344576,
        "learning_rate": 0.00020323396619650102,
        "gradient_norm": 0.4038812816143036,
        "train_loss": 3.002171516418457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20128,
        "tokens": 10552868864,
        "learning_rate": 0.00020320867468420246,
        "gradient_norm": 0.374625027179718,
        "train_loss": 3.098768472671509,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20129,
        "tokens": 10553393152,
        "learning_rate": 0.0002031833845990984,
        "gradient_norm": 0.3763216435909271,
        "train_loss": 2.9893131256103516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20130,
        "tokens": 10553917440,
        "learning_rate": 0.00020315809594147335,
        "gradient_norm": 0.34836575388908386,
        "train_loss": 3.068302869796753,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20131,
        "tokens": 10554441728,
        "learning_rate": 0.00020313280871161213,
        "gradient_norm": 0.3664296269416809,
        "train_loss": 3.1172571182250977,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20132,
        "tokens": 10554966016,
        "learning_rate": 0.00020310752290979918,
        "gradient_norm": 0.37714293599128723,
        "train_loss": 3.064385414123535,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20133,
        "tokens": 10555490304,
        "learning_rate": 0.00020308223853631935,
        "gradient_norm": 0.3894024193286896,
        "train_loss": 3.072678565979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20134,
        "tokens": 10556014592,
        "learning_rate": 0.00020305695559145705,
        "gradient_norm": 0.3543907403945923,
        "train_loss": 3.069655418395996,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20135,
        "tokens": 10556538880,
        "learning_rate": 0.0002030316740754969,
        "gradient_norm": 0.3835683763027191,
        "train_loss": 3.0851478576660156,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20136,
        "tokens": 10557063168,
        "learning_rate": 0.00020300639398872369,
        "gradient_norm": 0.39606472849845886,
        "train_loss": 3.0486109256744385,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20137,
        "tokens": 10557587456,
        "learning_rate": 0.00020298111533142169,
        "gradient_norm": 0.33864259719848633,
        "train_loss": 3.0444540977478027,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20138,
        "tokens": 10558111744,
        "learning_rate": 0.00020295583810387569,
        "gradient_norm": 0.3963087797164917,
        "train_loss": 3.082005023956299,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20139,
        "tokens": 10558636032,
        "learning_rate": 0.00020293056230636996,
        "gradient_norm": 0.44553497433662415,
        "train_loss": 3.1156716346740723,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20140,
        "tokens": 10559160320,
        "learning_rate": 0.00020290528793918925,
        "gradient_norm": 0.4258688986301422,
        "train_loss": 3.1093671321868896,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20141,
        "tokens": 10559684608,
        "learning_rate": 0.0002028800150026179,
        "gradient_norm": 0.41473516821861267,
        "train_loss": 3.1265792846679688,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20142,
        "tokens": 10560208896,
        "learning_rate": 0.00020285474349694045,
        "gradient_norm": 0.45507797598838806,
        "train_loss": 3.0672287940979004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20143,
        "tokens": 10560733184,
        "learning_rate": 0.00020282947342244132,
        "gradient_norm": 0.36395925283432007,
        "train_loss": 3.0661418437957764,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20144,
        "tokens": 10561257472,
        "learning_rate": 0.00020280420477940497,
        "gradient_norm": 0.4045526385307312,
        "train_loss": 3.0921640396118164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20145,
        "tokens": 10561781760,
        "learning_rate": 0.00020277893756811597,
        "gradient_norm": 0.3821313679218292,
        "train_loss": 3.097377300262451,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20146,
        "tokens": 10562306048,
        "learning_rate": 0.0002027536717888585,
        "gradient_norm": 0.3776462972164154,
        "train_loss": 3.1094212532043457,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20147,
        "tokens": 10562830336,
        "learning_rate": 0.00020272840744191717,
        "gradient_norm": 0.432971715927124,
        "train_loss": 3.05765700340271,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20148,
        "tokens": 10563354624,
        "learning_rate": 0.00020270314452757617,
        "gradient_norm": 0.38283655047416687,
        "train_loss": 3.0525009632110596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20149,
        "tokens": 10563878912,
        "learning_rate": 0.00020267788304612007,
        "gradient_norm": 0.4673682451248169,
        "train_loss": 3.074432849884033,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20150,
        "tokens": 10564403200,
        "learning_rate": 0.00020265262299783298,
        "gradient_norm": 0.3865368366241455,
        "train_loss": 3.0882883071899414,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20151,
        "tokens": 10564927488,
        "learning_rate": 0.00020262736438299945,
        "gradient_norm": 0.3612258732318878,
        "train_loss": 3.0591492652893066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20152,
        "tokens": 10565451776,
        "learning_rate": 0.00020260210720190363,
        "gradient_norm": 0.42374399304389954,
        "train_loss": 3.103259801864624,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20153,
        "tokens": 10565976064,
        "learning_rate": 0.00020257685145483,
        "gradient_norm": 0.417906254529953,
        "train_loss": 3.0423264503479004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20154,
        "tokens": 10566500352,
        "learning_rate": 0.00020255159714206264,
        "gradient_norm": 0.4240078926086426,
        "train_loss": 3.065885543823242,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20155,
        "tokens": 10567024640,
        "learning_rate": 0.00020252634426388592,
        "gradient_norm": 0.3421579599380493,
        "train_loss": 3.065168857574463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20156,
        "tokens": 10567548928,
        "learning_rate": 0.00020250109282058418,
        "gradient_norm": 0.3579462170600891,
        "train_loss": 3.0035853385925293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20157,
        "tokens": 10568073216,
        "learning_rate": 0.0002024758428124415,
        "gradient_norm": 0.33976611495018005,
        "train_loss": 3.0360851287841797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20158,
        "tokens": 10568597504,
        "learning_rate": 0.00020245059423974228,
        "gradient_norm": 0.3561958074569702,
        "train_loss": 3.0570740699768066,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20159,
        "tokens": 10569121792,
        "learning_rate": 0.0002024253471027705,
        "gradient_norm": 0.3652421832084656,
        "train_loss": 3.0752675533294678,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20160,
        "tokens": 10569646080,
        "learning_rate": 0.00020240010140181055,
        "gradient_norm": 0.3608878552913666,
        "train_loss": 3.0163609981536865,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20161,
        "tokens": 10570170368,
        "learning_rate": 0.00020237485713714645,
        "gradient_norm": 0.41640791296958923,
        "train_loss": 3.132052421569824,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20162,
        "tokens": 10570694656,
        "learning_rate": 0.0002023496143090625,
        "gradient_norm": 0.37921491265296936,
        "train_loss": 3.0331153869628906,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20163,
        "tokens": 10571218944,
        "learning_rate": 0.00020232437291784267,
        "gradient_norm": 0.3583618104457855,
        "train_loss": 3.091858386993408,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20164,
        "tokens": 10571743232,
        "learning_rate": 0.00020229913296377115,
        "gradient_norm": 0.3799669146537781,
        "train_loss": 3.025434970855713,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20165,
        "tokens": 10572267520,
        "learning_rate": 0.00020227389444713218,
        "gradient_norm": 0.35654497146606445,
        "train_loss": 3.0825393199920654,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20166,
        "tokens": 10572791808,
        "learning_rate": 0.00020224865736820962,
        "gradient_norm": 0.4043024480342865,
        "train_loss": 3.0966098308563232,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20167,
        "tokens": 10573316096,
        "learning_rate": 0.00020222342172728785,
        "gradient_norm": 0.39897680282592773,
        "train_loss": 3.081146478652954,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20168,
        "tokens": 10573840384,
        "learning_rate": 0.0002021981875246506,
        "gradient_norm": 0.38140779733657837,
        "train_loss": 3.018425941467285,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20169,
        "tokens": 10574364672,
        "learning_rate": 0.00020217295476058212,
        "gradient_norm": 0.40685373544692993,
        "train_loss": 3.065708637237549,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20170,
        "tokens": 10574888960,
        "learning_rate": 0.00020214772343536634,
        "gradient_norm": 0.3897615373134613,
        "train_loss": 3.092689275741577,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20171,
        "tokens": 10575413248,
        "learning_rate": 0.00020212249354928735,
        "gradient_norm": 0.352809339761734,
        "train_loss": 3.050950050354004,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20172,
        "tokens": 10575937536,
        "learning_rate": 0.00020209726510262904,
        "gradient_norm": 0.35817858576774597,
        "train_loss": 3.105320453643799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20173,
        "tokens": 10576461824,
        "learning_rate": 0.00020207203809567554,
        "gradient_norm": 0.35282042622566223,
        "train_loss": 3.0332775115966797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20174,
        "tokens": 10576986112,
        "learning_rate": 0.0002020468125287106,
        "gradient_norm": 0.3586057126522064,
        "train_loss": 3.0525412559509277,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20175,
        "tokens": 10577510400,
        "learning_rate": 0.00020202158840201828,
        "gradient_norm": 0.3869030475616455,
        "train_loss": 3.151488780975342,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20176,
        "tokens": 10578034688,
        "learning_rate": 0.0002019963657158826,
        "gradient_norm": 0.32796069979667664,
        "train_loss": 3.0800485610961914,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20177,
        "tokens": 10578558976,
        "learning_rate": 0.00020197114447058733,
        "gradient_norm": 0.3914817273616791,
        "train_loss": 2.9890377521514893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20178,
        "tokens": 10579083264,
        "learning_rate": 0.0002019459246664165,
        "gradient_norm": 0.3572460412979126,
        "train_loss": 3.10013747215271,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20179,
        "tokens": 10579607552,
        "learning_rate": 0.0002019207063036538,
        "gradient_norm": 0.3771851062774658,
        "train_loss": 3.0935654640197754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20180,
        "tokens": 10580131840,
        "learning_rate": 0.0002018954893825833,
        "gradient_norm": 0.4186815321445465,
        "train_loss": 3.019824743270874,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20181,
        "tokens": 10580656128,
        "learning_rate": 0.0002018702739034887,
        "gradient_norm": 0.3351947069168091,
        "train_loss": 3.049748659133911,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20182,
        "tokens": 10581180416,
        "learning_rate": 0.00020184505986665393,
        "gradient_norm": 0.34816476702690125,
        "train_loss": 3.0292012691497803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20183,
        "tokens": 10581704704,
        "learning_rate": 0.00020181984727236268,
        "gradient_norm": 0.3922405540943146,
        "train_loss": 3.1264688968658447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20184,
        "tokens": 10582228992,
        "learning_rate": 0.00020179463612089894,
        "gradient_norm": 0.3634330630302429,
        "train_loss": 3.128232002258301,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20185,
        "tokens": 10582753280,
        "learning_rate": 0.00020176942641254625,
        "gradient_norm": 0.354562371969223,
        "train_loss": 3.046814203262329,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20186,
        "tokens": 10583277568,
        "learning_rate": 0.00020174421814758863,
        "gradient_norm": 0.387363463640213,
        "train_loss": 3.0959558486938477,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20187,
        "tokens": 10583801856,
        "learning_rate": 0.00020171901132630965,
        "gradient_norm": 0.3848511576652527,
        "train_loss": 3.066070079803467,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20188,
        "tokens": 10584326144,
        "learning_rate": 0.00020169380594899317,
        "gradient_norm": 0.35233092308044434,
        "train_loss": 3.093550682067871,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20189,
        "tokens": 10584850432,
        "learning_rate": 0.00020166860201592272,
        "gradient_norm": 0.3914946913719177,
        "train_loss": 3.04325532913208,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20190,
        "tokens": 10585374720,
        "learning_rate": 0.00020164339952738223,
        "gradient_norm": 0.36336421966552734,
        "train_loss": 3.054847002029419,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20191,
        "tokens": 10585899008,
        "learning_rate": 0.0002016181984836552,
        "gradient_norm": 0.33730971813201904,
        "train_loss": 3.034050226211548,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20192,
        "tokens": 10586423296,
        "learning_rate": 0.0002015929988850255,
        "gradient_norm": 0.36139118671417236,
        "train_loss": 3.073881149291992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20193,
        "tokens": 10586947584,
        "learning_rate": 0.0002015678007317765,
        "gradient_norm": 0.3494487404823303,
        "train_loss": 3.1156768798828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20194,
        "tokens": 10587471872,
        "learning_rate": 0.00020154260402419202,
        "gradient_norm": 0.3484087288379669,
        "train_loss": 3.1245172023773193,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20195,
        "tokens": 10587996160,
        "learning_rate": 0.0002015174087625558,
        "gradient_norm": 0.37641987204551697,
        "train_loss": 3.0231289863586426,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20196,
        "tokens": 10588520448,
        "learning_rate": 0.00020149221494715117,
        "gradient_norm": 0.3428724706172943,
        "train_loss": 3.0358400344848633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20197,
        "tokens": 10589044736,
        "learning_rate": 0.00020146702257826195,
        "gradient_norm": 0.37101733684539795,
        "train_loss": 3.0608057975769043,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20198,
        "tokens": 10589569024,
        "learning_rate": 0.00020144183165617149,
        "gradient_norm": 0.36517858505249023,
        "train_loss": 3.071665048599243,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20199,
        "tokens": 10590093312,
        "learning_rate": 0.0002014166421811636,
        "gradient_norm": 0.3393898606300354,
        "train_loss": 3.071469783782959,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20200,
        "tokens": 10590617600,
        "learning_rate": 0.00020139145415352155,
        "gradient_norm": 0.3880695104598999,
        "train_loss": 3.022413730621338,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20201,
        "tokens": 10591141888,
        "learning_rate": 0.00020136626757352917,
        "gradient_norm": 0.36417487263679504,
        "train_loss": 3.091926336288452,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20202,
        "tokens": 10591666176,
        "learning_rate": 0.00020134108244146962,
        "gradient_norm": 0.3958137035369873,
        "train_loss": 3.0389463901519775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20203,
        "tokens": 10592190464,
        "learning_rate": 0.00020131589875762668,
        "gradient_norm": 0.35219287872314453,
        "train_loss": 3.1027112007141113,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20204,
        "tokens": 10592714752,
        "learning_rate": 0.0002012907165222836,
        "gradient_norm": 0.35517051815986633,
        "train_loss": 3.0760605335235596,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20205,
        "tokens": 10593239040,
        "learning_rate": 0.0002012655357357241,
        "gradient_norm": 0.39207544922828674,
        "train_loss": 3.0685648918151855,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20206,
        "tokens": 10593763328,
        "learning_rate": 0.0002012403563982313,
        "gradient_norm": 0.39151009917259216,
        "train_loss": 3.0669643878936768,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20207,
        "tokens": 10594287616,
        "learning_rate": 0.00020121517851008896,
        "gradient_norm": 0.3428646922111511,
        "train_loss": 3.07867431640625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20208,
        "tokens": 10594811904,
        "learning_rate": 0.00020119000207158017,
        "gradient_norm": 0.39827024936676025,
        "train_loss": 3.0419936180114746,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20209,
        "tokens": 10595336192,
        "learning_rate": 0.0002011648270829886,
        "gradient_norm": 0.3918312191963196,
        "train_loss": 3.0721044540405273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20210,
        "tokens": 10595860480,
        "learning_rate": 0.00020113965354459737,
        "gradient_norm": 0.3867076635360718,
        "train_loss": 3.0304219722747803,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20211,
        "tokens": 10596384768,
        "learning_rate": 0.00020111448145669012,
        "gradient_norm": 0.36357781291007996,
        "train_loss": 3.049326181411743,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20212,
        "tokens": 10596909056,
        "learning_rate": 0.00020108931081954987,
        "gradient_norm": 0.36760973930358887,
        "train_loss": 3.05226993560791,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20213,
        "tokens": 10597433344,
        "learning_rate": 0.00020106414163346018,
        "gradient_norm": 0.3566422462463379,
        "train_loss": 3.0491552352905273,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20214,
        "tokens": 10597957632,
        "learning_rate": 0.00020103897389870434,
        "gradient_norm": 0.399501234292984,
        "train_loss": 3.095252513885498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20215,
        "tokens": 10598481920,
        "learning_rate": 0.00020101380761556554,
        "gradient_norm": 0.3670816421508789,
        "train_loss": 3.0893170833587646,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20216,
        "tokens": 10599006208,
        "learning_rate": 0.0002009886427843272,
        "gradient_norm": 0.33566367626190186,
        "train_loss": 3.025209665298462,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20217,
        "tokens": 10599530496,
        "learning_rate": 0.00020096347940527244,
        "gradient_norm": 0.38492289185523987,
        "train_loss": 3.0764451026916504,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20218,
        "tokens": 10600054784,
        "learning_rate": 0.00020093831747868462,
        "gradient_norm": 0.344901978969574,
        "train_loss": 3.0705718994140625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20219,
        "tokens": 10600579072,
        "learning_rate": 0.00020091315700484683,
        "gradient_norm": 0.3484625220298767,
        "train_loss": 3.0229554176330566,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20220,
        "tokens": 10601103360,
        "learning_rate": 0.0002008879979840425,
        "gradient_norm": 0.3355274796485901,
        "train_loss": 3.0580222606658936,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20221,
        "tokens": 10601627648,
        "learning_rate": 0.00020086284041655457,
        "gradient_norm": 0.34091588854789734,
        "train_loss": 3.073697566986084,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20222,
        "tokens": 10602151936,
        "learning_rate": 0.00020083768430266647,
        "gradient_norm": 0.4786936342716217,
        "train_loss": 3.154834270477295,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20223,
        "tokens": 10602676224,
        "learning_rate": 0.0002008125296426611,
        "gradient_norm": 0.42615750432014465,
        "train_loss": 3.061445713043213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20224,
        "tokens": 10603200512,
        "learning_rate": 0.00020078737643682178,
        "gradient_norm": 0.37680885195732117,
        "train_loss": 3.075361728668213,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20225,
        "tokens": 10603724800,
        "learning_rate": 0.00020076222468543166,
        "gradient_norm": 0.36862337589263916,
        "train_loss": 3.073768138885498,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20226,
        "tokens": 10604249088,
        "learning_rate": 0.00020073707438877375,
        "gradient_norm": 0.34972766041755676,
        "train_loss": 3.0710537433624268,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20227,
        "tokens": 10604773376,
        "learning_rate": 0.0002007119255471313,
        "gradient_norm": 0.379822313785553,
        "train_loss": 3.0596446990966797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20228,
        "tokens": 10605297664,
        "learning_rate": 0.00020068677816078716,
        "gradient_norm": 0.34950435161590576,
        "train_loss": 3.0932846069335938,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20229,
        "tokens": 10605821952,
        "learning_rate": 0.0002006616322300246,
        "gradient_norm": 0.44160082936286926,
        "train_loss": 3.2127604484558105,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20230,
        "tokens": 10606346240,
        "learning_rate": 0.00020063648775512654,
        "gradient_norm": 0.474742591381073,
        "train_loss": 3.0566205978393555,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20231,
        "tokens": 10606870528,
        "learning_rate": 0.00020061134473637617,
        "gradient_norm": 0.3836672604084015,
        "train_loss": 3.0911240577697754,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20232,
        "tokens": 10607394816,
        "learning_rate": 0.00020058620317405624,
        "gradient_norm": 0.42471379041671753,
        "train_loss": 3.0763792991638184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20233,
        "tokens": 10607919104,
        "learning_rate": 0.00020056106306845,
        "gradient_norm": 0.3920557200908661,
        "train_loss": 3.0631537437438965,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20234,
        "tokens": 10608443392,
        "learning_rate": 0.00020053592441984038,
        "gradient_norm": 0.4066503345966339,
        "train_loss": 3.0949695110321045,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20235,
        "tokens": 10608967680,
        "learning_rate": 0.00020051078722851026,
        "gradient_norm": 0.4287206828594208,
        "train_loss": 3.009212017059326,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20236,
        "tokens": 10609491968,
        "learning_rate": 0.00020048565149474268,
        "gradient_norm": 0.38818198442459106,
        "train_loss": 3.0690078735351562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20237,
        "tokens": 10610016256,
        "learning_rate": 0.0002004605172188205,
        "gradient_norm": 0.4373916685581207,
        "train_loss": 3.1395998001098633,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20238,
        "tokens": 10610540544,
        "learning_rate": 0.00020043538440102674,
        "gradient_norm": 0.4437594413757324,
        "train_loss": 3.1267056465148926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20239,
        "tokens": 10611064832,
        "learning_rate": 0.00020041025304164413,
        "gradient_norm": 0.4199993312358856,
        "train_loss": 3.048496723175049,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20240,
        "tokens": 10611589120,
        "learning_rate": 0.00020038512314095577,
        "gradient_norm": 0.44130030274391174,
        "train_loss": 3.065824508666992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20241,
        "tokens": 10612113408,
        "learning_rate": 0.00020035999469924433,
        "gradient_norm": 0.37731972336769104,
        "train_loss": 3.0635111331939697,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20242,
        "tokens": 10612637696,
        "learning_rate": 0.00020033486771679285,
        "gradient_norm": 0.42167356610298157,
        "train_loss": 3.0459024906158447,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20243,
        "tokens": 10613161984,
        "learning_rate": 0.00020030974219388393,
        "gradient_norm": 0.36994174122810364,
        "train_loss": 3.034313440322876,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20244,
        "tokens": 10613686272,
        "learning_rate": 0.00020028461813080054,
        "gradient_norm": 0.3739207983016968,
        "train_loss": 3.042511224746704,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20245,
        "tokens": 10614210560,
        "learning_rate": 0.0002002594955278256,
        "gradient_norm": 0.34254634380340576,
        "train_loss": 3.0607969760894775,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20246,
        "tokens": 10614734848,
        "learning_rate": 0.00020023437438524162,
        "gradient_norm": 0.40088075399398804,
        "train_loss": 3.0426764488220215,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20247,
        "tokens": 10615259136,
        "learning_rate": 0.00020020925470333166,
        "gradient_norm": 0.356906533241272,
        "train_loss": 3.0989837646484375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20248,
        "tokens": 10615783424,
        "learning_rate": 0.0002001841364823782,
        "gradient_norm": 0.3465806841850281,
        "train_loss": 3.057764768600464,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20249,
        "tokens": 10616307712,
        "learning_rate": 0.00020015901972266417,
        "gradient_norm": 0.3770541250705719,
        "train_loss": 3.0239052772521973,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20250,
        "tokens": 10616832000,
        "learning_rate": 0.00020013390442447218,
        "gradient_norm": 0.3569108545780182,
        "train_loss": 3.115401268005371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20251,
        "tokens": 10617356288,
        "learning_rate": 0.00020010879058808504,
        "gradient_norm": 0.3830646276473999,
        "train_loss": 3.034506320953369,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20252,
        "tokens": 10617880576,
        "learning_rate": 0.0002000836782137853,
        "gradient_norm": 0.38595154881477356,
        "train_loss": 3.0729000568389893,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20253,
        "tokens": 10618404864,
        "learning_rate": 0.0002000585673018557,
        "gradient_norm": 0.3922249376773834,
        "train_loss": 3.1154985427856445,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20254,
        "tokens": 10618929152,
        "learning_rate": 0.000200033457852579,
        "gradient_norm": 0.37725016474723816,
        "train_loss": 3.087430238723755,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20255,
        "tokens": 10619453440,
        "learning_rate": 0.00020000834986623763,
        "gradient_norm": 0.406141072511673,
        "train_loss": 3.090542793273926,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20256,
        "tokens": 10619977728,
        "learning_rate": 0.00019998324334311444,
        "gradient_norm": 0.34283116459846497,
        "train_loss": 3.0403308868408203,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20257,
        "tokens": 10620502016,
        "learning_rate": 0.00019995813828349178,
        "gradient_norm": 0.38635578751564026,
        "train_loss": 3.0530757904052734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20258,
        "tokens": 10621026304,
        "learning_rate": 0.00019993303468765253,
        "gradient_norm": 0.3458768427371979,
        "train_loss": 3.045747756958008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20259,
        "tokens": 10621550592,
        "learning_rate": 0.000199907932555879,
        "gradient_norm": 0.37494948506355286,
        "train_loss": 3.041161060333252,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20260,
        "tokens": 10622074880,
        "learning_rate": 0.0001998828318884539,
        "gradient_norm": 0.3516821563243866,
        "train_loss": 3.026538372039795,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20261,
        "tokens": 10622599168,
        "learning_rate": 0.00019985773268565968,
        "gradient_norm": 0.3604566752910614,
        "train_loss": 3.0610857009887695,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20262,
        "tokens": 10623123456,
        "learning_rate": 0.00019983263494777897,
        "gradient_norm": 0.3484675884246826,
        "train_loss": 3.028562068939209,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20263,
        "tokens": 10623647744,
        "learning_rate": 0.00019980753867509415,
        "gradient_norm": 0.35359910130500793,
        "train_loss": 3.0682005882263184,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20264,
        "tokens": 10624172032,
        "learning_rate": 0.00019978244386788772,
        "gradient_norm": 0.3730498254299164,
        "train_loss": 3.078953266143799,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20265,
        "tokens": 10624696320,
        "learning_rate": 0.00019975735052644232,
        "gradient_norm": 0.40691104531288147,
        "train_loss": 3.0705060958862305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20266,
        "tokens": 10625220608,
        "learning_rate": 0.0001997322586510402,
        "gradient_norm": 0.3764660060405731,
        "train_loss": 2.979811191558838,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20267,
        "tokens": 10625744896,
        "learning_rate": 0.000199707168241964,
        "gradient_norm": 0.3699245750904083,
        "train_loss": 3.0242486000061035,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20268,
        "tokens": 10626269184,
        "learning_rate": 0.00019968207929949591,
        "gradient_norm": 0.3621784448623657,
        "train_loss": 3.0961456298828125,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20269,
        "tokens": 10626793472,
        "learning_rate": 0.00019965699182391858,
        "gradient_norm": 0.36560243368148804,
        "train_loss": 3.059493064880371,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20270,
        "tokens": 10627317760,
        "learning_rate": 0.00019963190581551418,
        "gradient_norm": 0.3781253695487976,
        "train_loss": 3.0655012130737305,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20271,
        "tokens": 10627842048,
        "learning_rate": 0.0001996068212745653,
        "gradient_norm": 0.376296728849411,
        "train_loss": 3.01770281791687,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20272,
        "tokens": 10628366336,
        "learning_rate": 0.00019958173820135407,
        "gradient_norm": 0.37481889128685,
        "train_loss": 3.0595855712890625,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20273,
        "tokens": 10628890624,
        "learning_rate": 0.00019955665659616298,
        "gradient_norm": 0.3357158899307251,
        "train_loss": 3.0530214309692383,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20274,
        "tokens": 10629414912,
        "learning_rate": 0.00019953157645927438,
        "gradient_norm": 0.3381960690021515,
        "train_loss": 3.023709297180176,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20275,
        "tokens": 10629939200,
        "learning_rate": 0.00019950649779097043,
        "gradient_norm": 0.3571634590625763,
        "train_loss": 3.0641422271728516,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20276,
        "tokens": 10630463488,
        "learning_rate": 0.0001994814205915336,
        "gradient_norm": 0.3363882005214691,
        "train_loss": 3.0336756706237793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20277,
        "tokens": 10630987776,
        "learning_rate": 0.00019945634486124601,
        "gradient_norm": 0.3549391031265259,
        "train_loss": 3.0317373275756836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20278,
        "tokens": 10631512064,
        "learning_rate": 0.00019943127060039007,
        "gradient_norm": 0.3194608688354492,
        "train_loss": 3.012002944946289,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20279,
        "tokens": 10632036352,
        "learning_rate": 0.00019940619780924783,
        "gradient_norm": 0.37541458010673523,
        "train_loss": 3.0848162174224854,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20280,
        "tokens": 10632560640,
        "learning_rate": 0.00019938112648810175,
        "gradient_norm": 0.3699477016925812,
        "train_loss": 2.9904277324676514,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20281,
        "tokens": 10633084928,
        "learning_rate": 0.00019935605663723378,
        "gradient_norm": 0.3299559950828552,
        "train_loss": 3.0408942699432373,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20282,
        "tokens": 10633609216,
        "learning_rate": 0.00019933098825692638,
        "gradient_norm": 0.34802502393722534,
        "train_loss": 3.0618295669555664,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20283,
        "tokens": 10634133504,
        "learning_rate": 0.00019930592134746148,
        "gradient_norm": 0.33596518635749817,
        "train_loss": 3.1022276878356934,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20284,
        "tokens": 10634657792,
        "learning_rate": 0.0001992808559091213,
        "gradient_norm": 0.3785504102706909,
        "train_loss": 3.0504424571990967,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20285,
        "tokens": 10635182080,
        "learning_rate": 0.00019925579194218822,
        "gradient_norm": 0.37305811047554016,
        "train_loss": 3.099012851715088,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20286,
        "tokens": 10635706368,
        "learning_rate": 0.000199230729446944,
        "gradient_norm": 0.41418346762657166,
        "train_loss": 3.2014410495758057,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20287,
        "tokens": 10636230656,
        "learning_rate": 0.00019920566842367108,
        "gradient_norm": 0.49676257371902466,
        "train_loss": 3.0454483032226562,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20288,
        "tokens": 10636754944,
        "learning_rate": 0.00019918060887265127,
        "gradient_norm": 0.5209616422653198,
        "train_loss": 2.907614231109619,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20289,
        "tokens": 10637279232,
        "learning_rate": 0.00019915555079416688,
        "gradient_norm": 0.4456278681755066,
        "train_loss": 3.0616297721862793,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20290,
        "tokens": 10637803520,
        "learning_rate": 0.00019913049418849975,
        "gradient_norm": 0.42671045660972595,
        "train_loss": 3.0410568714141846,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20291,
        "tokens": 10638327808,
        "learning_rate": 0.0001991054390559322,
        "gradient_norm": 0.49212250113487244,
        "train_loss": 3.1306354999542236,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20292,
        "tokens": 10638852096,
        "learning_rate": 0.00019908038539674593,
        "gradient_norm": 0.42441388964653015,
        "train_loss": 3.0792489051818848,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20293,
        "tokens": 10639376384,
        "learning_rate": 0.0001990553332112233,
        "gradient_norm": 0.465762197971344,
        "train_loss": 3.0333261489868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20294,
        "tokens": 10639900672,
        "learning_rate": 0.00019903028249964593,
        "gradient_norm": 0.4527877867221832,
        "train_loss": 3.040503978729248,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20295,
        "tokens": 10640424960,
        "learning_rate": 0.00019900523326229613,
        "gradient_norm": 0.4269656836986542,
        "train_loss": 3.055002450942993,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20296,
        "tokens": 10640949248,
        "learning_rate": 0.00019898018549945564,
        "gradient_norm": 0.39200201630592346,
        "train_loss": 3.0666487216949463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20297,
        "tokens": 10641473536,
        "learning_rate": 0.00019895513921140654,
        "gradient_norm": 0.458639919757843,
        "train_loss": 3.089254140853882,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20298,
        "tokens": 10641997824,
        "learning_rate": 0.00019893009439843064,
        "gradient_norm": 0.38516533374786377,
        "train_loss": 3.0008187294006348,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20299,
        "tokens": 10642522112,
        "learning_rate": 0.00019890505106081,
        "gradient_norm": 0.4120883047580719,
        "train_loss": 3.0278971195220947,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20300,
        "tokens": 10643046400,
        "learning_rate": 0.00019888000919882632,
        "gradient_norm": 0.4124012589454651,
        "train_loss": 3.0670933723449707,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20301,
        "tokens": 10643570688,
        "learning_rate": 0.00019885496881276167,
        "gradient_norm": 0.3737305700778961,
        "train_loss": 3.0029854774475098,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20302,
        "tokens": 10644094976,
        "learning_rate": 0.00019882992990289774,
        "gradient_norm": 0.41516977548599243,
        "train_loss": 3.057394504547119,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20303,
        "tokens": 10644619264,
        "learning_rate": 0.00019880489246951655,
        "gradient_norm": 0.3599044382572174,
        "train_loss": 3.0758395195007324,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20304,
        "tokens": 10645143552,
        "learning_rate": 0.00019877985651289972,
        "gradient_norm": 0.4107096195220947,
        "train_loss": 3.034433364868164,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20305,
        "tokens": 10645667840,
        "learning_rate": 0.00019875482203332928,
        "gradient_norm": 0.3366740643978119,
        "train_loss": 3.0792689323425293,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20306,
        "tokens": 10646192128,
        "learning_rate": 0.00019872978903108683,
        "gradient_norm": 0.38592952489852905,
        "train_loss": 3.0814876556396484,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20307,
        "tokens": 10646716416,
        "learning_rate": 0.00019870475750645436,
        "gradient_norm": 0.373145192861557,
        "train_loss": 3.0349910259246826,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20308,
        "tokens": 10647240704,
        "learning_rate": 0.00019867972745971337,
        "gradient_norm": 0.3617187440395355,
        "train_loss": 3.0910396575927734,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20309,
        "tokens": 10647764992,
        "learning_rate": 0.00019865469889114584,
        "gradient_norm": 0.3448333442211151,
        "train_loss": 3.0782408714294434,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20310,
        "tokens": 10648289280,
        "learning_rate": 0.0001986296718010333,
        "gradient_norm": 0.4153343439102173,
        "train_loss": 3.000568389892578,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20311,
        "tokens": 10648813568,
        "learning_rate": 0.00019860464618965768,
        "gradient_norm": 0.39896687865257263,
        "train_loss": 3.0874829292297363,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20312,
        "tokens": 10649337856,
        "learning_rate": 0.0001985796220573005,
        "gradient_norm": 0.36343643069267273,
        "train_loss": 2.9877753257751465,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20313,
        "tokens": 10649862144,
        "learning_rate": 0.0001985545994042434,
        "gradient_norm": 0.3553246557712555,
        "train_loss": 3.0003652572631836,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20314,
        "tokens": 10650386432,
        "learning_rate": 0.0001985295782307683,
        "gradient_norm": 0.33990973234176636,
        "train_loss": 3.1144750118255615,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20315,
        "tokens": 10650910720,
        "learning_rate": 0.00019850455853715656,
        "gradient_norm": 0.42534342408180237,
        "train_loss": 3.061626434326172,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20316,
        "tokens": 10651435008,
        "learning_rate": 0.00019847954032369,
        "gradient_norm": 0.38128215074539185,
        "train_loss": 3.0379858016967773,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20317,
        "tokens": 10651959296,
        "learning_rate": 0.0001984545235906501,
        "gradient_norm": 0.4436831474304199,
        "train_loss": 2.976411819458008,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20318,
        "tokens": 10652483584,
        "learning_rate": 0.0001984295083383186,
        "gradient_norm": 0.4045165181159973,
        "train_loss": 3.060335159301758,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20319,
        "tokens": 10653007872,
        "learning_rate": 0.0001984044945669769,
        "gradient_norm": 0.3689384460449219,
        "train_loss": 3.024301052093506,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20320,
        "tokens": 10653532160,
        "learning_rate": 0.00019837948227690674,
        "gradient_norm": 0.3910978436470032,
        "train_loss": 3.0631086826324463,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20321,
        "tokens": 10654056448,
        "learning_rate": 0.00019835447146838948,
        "gradient_norm": 0.35554617643356323,
        "train_loss": 3.113780975341797,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20322,
        "tokens": 10654580736,
        "learning_rate": 0.00019832946214170684,
        "gradient_norm": 0.37693139910697937,
        "train_loss": 3.1375091075897217,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20323,
        "tokens": 10655105024,
        "learning_rate": 0.00019830445429714014,
        "gradient_norm": 0.352234810590744,
        "train_loss": 3.0681676864624023,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20324,
        "tokens": 10655629312,
        "learning_rate": 0.00019827944793497095,
        "gradient_norm": 0.3566948175430298,
        "train_loss": 3.063138961791992,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    },
    {
        "step": 20325,
        "tokens": 10656153600,
        "learning_rate": 0.00019825444305548087,
        "gradient_norm": 0.3927781581878662,
        "train_loss": 3.0531005859375,
        "val_loss": null,
        "hellaswag_acc": null,
        "hellaswag_acc_norm": null
    }
]